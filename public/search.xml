<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>可变形卷积网络</title>
      <link href="/2022/04/26/obj_det/deformable_conv/"/>
      <url>/2022/04/26/obj_det/deformable_conv/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1703.06211">Deformable Convlutional Networks</a><br>源码：<a href="https://github.com/msracver/Deformable-ConvNets">Deformable-ConvNets</a></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>传统 CNN 的固定几何结构：固定的卷积单元（window），固定的池化，以及固定的 RoI pooling。某些时候这并不是我们想要的，例如 CNN 的高层 layer 对语义特征进行编码，不同的目标具有不同的 scale 和形状，此时，需要自动调节感受野 size。</p><p>本文提出两个新模块：可变形卷积和可变性 RoI pooling，增强了 CNN 的几何变换的建模能力。</p><h1 id="2-可变形卷积网络"><a href="#2-可变形卷积网络" class="headerlink" title="2. 可变形卷积网络"></a>2. 可变形卷积网络</h1><p>在标准卷积的 grid 采样位置上增加一个 2D offsets（位移），使得采样 grid 可以自由变形，如图 1，</p><p><img src="/images/obj_det/deformable_conv1.png" alt=""></p><center>图 1. (a) 规则采样 grid；(2) 变形采样点（深蓝色点），offsets 为浅蓝色箭头; (c) (d) 为 (b) 的特例。</center><p>在 3D 特征的每个 channel 上均做相同的可变形卷积，以下仅考虑 2D 情况。</p><h2 id="2-1-可变形卷积"><a href="#2-1-可变形卷积" class="headerlink" title="2.1 可变形卷积"></a>2.1 可变形卷积</h2><p>普通的 2D 卷积过程：在输入特征上使用规则 grid $\mathcal R$ 采样，计算采样点的加权和，例如 <code>3x3</code> 卷积，</p><script type="math/tex; mode=display">\mathcal R = \{(-1, -1),(-1,0),\ldots, (0,1),(1,1)\}</script><p>输出特征平面 $\mathbf y$ 上一位置点 $\mathbf p_0$，有</p><script type="math/tex; mode=display">\mathbf y(\mathbf p_0)=\sum_{\mathbf p_n \in \mathcal R} \mathbf w(\mathbf p_n) \cdot \mathbf x(\mathbf p_0+\mathbf p_n)\tag{1}</script><p>可变形卷积中，使用 offset $\{\Delta \mathbf p_n |n=1,\ldots, N\}$ 对规则 grid $\mathcal R$ 进行增强，</p><script type="math/tex; mode=display">\mathbf y(\mathbf p_0)=\sum_{\mathbf p_n \in \mathcal R} \mathbf w(\mathbf p_n) \cdot \mathbf x(\mathbf p_0+\mathbf p_n+\Delta \mathbf p_n) \tag{2}</script><p>$\Delta \mathbf p_n$ 是分数，故 (2) 式计算还需要通常线性插值来完成，记 $\mathbf p = \mathbf p_0+\mathbf p_n+\Delta \mathbf p_n$ 为目标位置处（分数），$\mathbf q$ 是特征平面 $\mathbf x$ 上所有的整数位置，$G(\cdot, \cdot)$ 是双线性插值 kernel，那么插值结果为</p><script type="math/tex; mode=display">\mathbf x(\mathbf p)=\sum_{\mathbf q}G(\mathbf p, \mathbf q) \cdot \mathbf x(\mathbf q) \tag{3}</script><p>由于坐标位置是 2D 的，可以将 $G$ 写成</p><script type="math/tex; mode=display">G(\mathbf p, \mathbf q)=g(q^x, p^x)\cdot g(q^y, p^y) \tag{4}</script><p>其中 $g(a,b)=\max (0, 1- |a-b|)$，即只需要 $\mathbf p$ 四周最近的 4 个点即可计算 $\mathbf x(\mathbf p)$ 的值。</p><h3 id="2-1-1-获得-offsets"><a href="#2-1-1-获得-offsets" class="headerlink" title="2.1.1 获得 offsets"></a>2.1.1 获得 offsets</h3><p>如图 2，<strong>通过一个卷积层对输入特征进行卷积，得到这个输入特征的 offset</strong>，</p><p><img src="/images/obj_det/deformable_conv2.png" alt=""></p><center>图 2. 3x3 的可变形卷积</center><p>输出的 offsets 与输入特征平面具有相同的 spatial size，通道维度 $2N$ 表示卷积核中采样点数量 $N$ 个 2D offset（x,y 方向），参见 (2) 式中的 $\Delta \mathbf p_n$，注意，输出特征平面上的每一个点 $\mathbf p_0$，均有对应的独立的 $N$ 个 $\Delta \mathbf p_n$。</p><h2 id="2-2-可变形-RoI-Pooling"><a href="#2-2-可变形-RoI-Pooling" class="headerlink" title="2.2 可变形 RoI Pooling"></a>2.2 可变形 RoI Pooling</h2><p>RoI pooling 是将 backbone 的输出特征上的 RoI 部分 pooling 为一个固定 size 的特征。</p><p>输入特征 $\mathbf x$，一个 RoI 其 size 为 $w \times h$，左上角坐标 $\mathbf p_0$，RoI pooling 将其分成 $k \times k$ 的 bins，输出 $k \times k$ 的特征 $\mathbf y$，对输出特征上一位置 $(i,j)$ 有</p><script type="math/tex; mode=display">\mathbf y(i,j)=\sum_{\mathbf p_n \in bin(i,j)} \mathbf x(\mathbf p_0+\mathbf p_n) /n_{ij} \tag{5}</script><p>可见这是一个 均值 pooling，$n_{ij}$ 表示这个 bin 中像素的数量，bin 索引满足 $0 \le i,j &lt; k$，<code>bin(i,j)</code> 内像素的相对坐标 $\mathbf p_n$ 满足</p><script type="math/tex; mode=display">\lfloor i \frac w k \rfloor \le p_n^x < \lceil (i+1) \frac w k \rceil, \quad \lfloor j \frac h k \rfloor \le p_n^y < \lceil (j+1) \frac h k \rceil</script><p><strong>可变形 RoI pooling</strong> 是给普通 RoI pooling 增加一个 offsets $\{\Delta \mathbf p_{ij}|0 \le i,j &lt; k\}$，即 RoI 中每个 bin 有一个独立的 2D offset，那么 (5) 式变为</p><script type="math/tex; mode=display">\mathbf y(i,j)=\sum_{\mathbf p_n \in bin(i,j)} \mathbf x(\mathbf p_0+ \mathbf p_n + \Delta \mathbf p_{ij})/n_{ij} \tag{6}</script><p>同样地，由于 $\Delta \mathbf p_{ij}$ 是分数，(6) 式计算需要使用 (3),(4) 式的双线性插值计算。</p><p>图 3 显示了可变形 RoI pooling 过程：首先 RoI pooling 生成池化后特征，即 (5) 式；然后池化特征经过一个 <code>fc</code> layer 生成归一化的 offsets $\Delta \hat {\mathbf p}_{ij}$，然后再变换到 $\Delta \mathbf p_{ij}$，</p><script type="math/tex; mode=display">\Delta \mathbf p_{ij}=\gamma \cdot \Delta \hat {\mathbf p}_{ij} \circ (w, h) \tag{7}</script><p>其中 $\gamma$ 是一个预定义标量用于调节 offset 的幅值，根据经验设置为 $\gamma=0.1$。这个 offset 归一化的设置使得 offset 与 RoI size 大小无关。</p><p><img src="/images/obj_det/deformable_conv3.png" alt=""></p><p>代码见源码中的函数 <code>get_deformable_roipooling</code>。</p><h3 id="2-2-1-PS-RoI-pooling"><a href="#2-2-1-PS-RoI-pooling" class="headerlink" title="2.2.1 PS RoI pooling"></a>2.2.1 PS RoI pooling</h3><p>position-sensitive RoI pooling，输入特征平面上每一个 location，其对应的 offset 与这个位置所属分类以及 RoI pooling 后所属 bin 均相关。</p><p>输入特征经过一个 conv layer，得到 $k^2$ 个分类相关的 score maps，其中 $k^2$ 为 RoI pooling 后的 bin 数量，即 score maps 一共有 $k^2 \cdot (C+1)$ 个 channel，这里 $C$ 表示分类总数，$+1$ 表示背景分类。</p><p>使用 $(i,j)$ 表示 RoI pooling 后的 bin，RoI pooling 之后所有 bin 对应的 score maps 记为 $\{\mathbf x_{i,j}| 0\le i,j &lt; k\}$。</p><p>在这些 score maps 上执行 RoI pooling，<code>(i,j)-th</code> bin 的值使用 $\mathbf x_{ij}$ 上对应 bin 的像素之和得到（笔者注：这里应该是求平均）。</p><p>简单而言，将 (5) 式中的 $\mathbf x$ 改为 $\mathbf x_{ij}$。</p><p><strong>可变形 PS RoI pooling</strong></p><ol><li><p>将 (6) 式中的 $\mathbf x$ 替换为 $\mathbf x_{ij}$。</p></li><li><p>如何确定 (6) 式中的 $\Delta \mathbf p_{ij}$？</p><p> 输入特征经另一个 conv layer 得到 channel 为 $2k^2 \cdot (C+1)$ 的输出 offset fields，如图 4 中上面那个分支，对每个 RoI，使用 PS RoI pooling 作用于 RoI，过程为：</p><ul><li>$k \times k$ 个 bins，每个 bin 使用独立的 offset fields，求 bin 内的像素均值，得到归一化的 offsets $\Delta \hat {\mathbf p}_{ij}$。单个 RoI 的 offsets 的 shape 为 $2(C+1) \times k \times k$</li><li>使用 (7) 式转变为最终的 offsets。</li></ul></li><li>使用 (6) 式（$\mathbf x$ 替换为 $\mathbf x_{ij}$）得到最终的池化特征，其 shape 为 $(C+1)\times k \times k$</li></ol><p><img src="/images/obj_det/deformable_conv4.png" alt=""></p><center>图 4. 3x3 可变形 PS RoI pooling</center><h3 id="2-2-2-RoI-pooling-小结"><a href="#2-2-2-RoI-pooling-小结" class="headerlink" title="2.2.2 RoI pooling 小结"></a>2.2.2 RoI pooling 小结</h3><p>四种 RoI pooling：</p><ol><li>(普通) RoI pooling</li><li>可变形 RoI pooling<ul><li>输入特征经 RoI pooling 后的特征再经 fc 得到 offsets</li><li>offsets 作用于输入特征，实现可变形 RoI pooling</li></ul></li><li>PS RoI pooling<ul><li>输入特征经 conv 得到 $k^2(C+1) \times h \times w$ 的 score maps</li><li>每个 bin 使用对应的 score map 进行均值池化，得到 $(C+1) \times k \times k$ 的池化特征 </li></ul></li><li>可变形 PS RoI pooling<ul><li>输入特征经 conv 得到 $k^2(C+1) \times h \times w$ 的 score maps</li><li>输入特征经另一 conv 得到 $2k^2(C+1) \times h \times w$ 的 offset fields</li><li>对 offset fields 执行 PS RoI pooling，得到 $2(C+1) \times k \times k$ 的 offsets</li><li>每个 bin 有独立的 score maps，shape 为 $(C+1)\times h \times w$，以及独立的 offset，shape 为 $C+1$，求均值得到这个 bin 的池化结果 shape 为 $C+1$</li><li>最终的特征 shape 为 $(C+1)\times k \times k$</li></ul></li></ol><p><strong>注意：</strong><br>以上 PS RoI pooling 中的 $(C+1)$ 表示是在分类分支中执行的 PS RoI pooling，如果是在坐标回归分支中，那么将 $(C+1)$ 替换为 $4 \cdot N_{reg}$，其中 $N_{reg}$ 表示回归分支上的分类数量，如果配置是类别不可知（），那么 $N_{reg}=2$ 表示 fg/bg 两个类别，如果是类别可知的，那么 $N_{reg}=C+1$。 $4$ 表示 4 个坐标。</p><p>可变形 PS RoI pooling 有上下两个分支如图 4，在坐标回归分支中，下分支中的 $(C+1)$ 替换为 $4\cdot N_{reg}$；上分支中的 $(C+1)$ 替换为 $1$，表示同一个 bin 中，不分类别不分坐标（x1 y1 x2 y2），共享同一个 offset $\Delta \mathbf p_{ij}$。</p><h2 id="2-3-可变形卷积网络"><a href="#2-3-可变形卷积网络" class="headerlink" title="2.3 可变形卷积网络"></a>2.3 可变形卷积网络</h2><p>本文提出的可变形卷积和可变形 RoI pooling 与普通版本均具有相同的输入输出，故容易用在现有的 CNN 中。训练时，这些新增的用于学习 offsets 的 conv 和 fc 的权重初始化为 0，这些权重的学习率为其他 layer 的 $\beta$ 倍，默认情况下 $\beta=1$，作者特别指出在 Faster R-CNN 中，新增的 fc 的权重学习率倍数 $\beta=0.01$。</p><p>SOTA CNN 框架通常包含两部分：深度全卷积网络用于从图像抽取特征；任务相关的浅网络，根据特征生成结果。</p><h3 id="2-3-1-用于特征抽取的可变形-conv"><a href="#2-3-1-用于特征抽取的可变形-conv" class="headerlink" title="2.3.1 用于特征抽取的可变形 conv"></a>2.3.1 用于特征抽取的可变形 conv</h3><p>作者采用两个 SOTA 框架进行特征抽取：ResNet-101 和 Inception-ResNet，在 ImageNet 上预训练。</p><p>Inception-ResNet 原本用于图像识别，使用了多个 valid conv/pooling，导致特征不对齐，在密集预测任务中存在特征不对齐的问题，使用对齐版本的网络 (参见论文 《Aligned-inception-resnet model》)，记为 “Aligned-Inception-ResNet”。</p><p>对于这两个网络的改造：</p><ol><li><p>将网络最后的 全局均值池化和 1000-way fc 层移除，然后附加 <code>1x1</code> conv 将 channel 降为 <code>1024</code>。</p></li><li><p>将最后一个 block（conv5）中第一个 layer 的 stride 从 <code>2</code> 降为 <code>1</code>，从而使得整个网络的 stride 由 <code>32</code> 变为 <code>16</code>，以便增加特征平面分辨率。为了补偿这种变化，将 <code>conv5</code> 中的所有的 kernel size &gt; 1 的卷积层的 dilation 从 <code>1</code> 变为 <code>2</code>。</p></li></ol><p>可变形卷积用在最后的 $n$ 个 kernel size &gt; 1 的 conv layer 上，作者实验了几个不同的 $n$ 值，发现 $n=3$ 在性能和复杂之间取得较好的平衡。如图 5，</p><p><img src="/images/obj_det/deformable_conv5.png" alt=""></p><center>图 5. 不同可变形 conv 数量的结果。数据集为 VOC2007 test</center><p><strong>分割和检测网络</strong></p><p>在特征抽取网络之上是一个任务相关的网络。记 $C$ 为目标类别数量。</p><p>DeepLab 是一个语义分割的 SOTA 方法，在特征平面上使用 <code>1x1</code> conv 生成 <code>(C+1)</code> 个 maps，表示每个像素的分类得分，然后使用 softmax 输出每个像素的分类概率。</p><p>Category-Aware RPN 与 Faster R-CNN 的 RPN 几乎相同，只是将 二分类（bg/fg）改为 <code>(C+1)</code> 分类，即，由 RPN 预测最终的 anchor 的坐标和分类，属于 one-stage 目标检测，类似于一个简化版的 SSD（单 level 的 feature maps 进行预测）</p><p>Faster R-CNN，使用 RPN 得到 RoI，然后使用 RoI pooling + 2 fc layers，得到 <code>1024</code> 维度特征，然后是分类和坐标回归两个分支。这里的 RoI pooling 可被替换为 deformable RoI pooling。</p><p>R-FCN，由于 per-RoI 的计算量较小，可以将 RoI pooling 改为 可变形 PS RoI pooling。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>梯度反向传播到输出特征平面 $\mathbf y$， 得到 $\frac {\partial L}{\partial \mathbf y}$，其中 $L$ 是目标函数，</p><p><strong>可变形卷积</strong></p><p>根据 (2) 式，</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial \mathbf y(\mathbf p_0)}{\partial \Delta \mathbf p_n}&=\sum_{\mathbf p_n \in \mathcal R} \mathbf w(\mathbf p_n) \cdot \frac {\partial \mathbf x(\mathbf p_0+\mathbf p_n+\Delta \mathbf p_n)}{\partial \Delta \mathbf p_n}\\ &=\sum_{\mathbf p_n \in \mathcal R} \left[\mathbf w(\mathbf p_n) \cdot \sum_{\mathbf q} \frac {\partial G(\mathbf q, \mathbf p_0+\mathbf p_n+\Delta \mathbf p_n)}{\partial \Delta \mathbf p_n} \mathbf x(\mathbf q)\right]\end{aligned} \tag{8}</script><p>根据 (4) 式计算 $\frac {\partial G(\mathbf q, \mathbf p_0+\mathbf p_n+\Delta \mathbf p_n)}{\partial \Delta \mathbf p_n}$，注意 $\partial \Delta \mathbf p_n$ 是 2D vector，</p><script type="math/tex; mode=display">\frac {\partial G(\mathbf q, \mathbf p_0+\mathbf p_n+\Delta \mathbf p_n)}{\partial \Delta p_n^x}=\begin{cases} g(q^y,p_0^y+p_n^y+\Delta p_n^y) & p^x \le q^x <1+p^x \\ -g(q^y,p_0^y+p_n^y+\Delta p_n^y) & q^x < p^x <1+q^x \\ 0 & \text{otherwise} \end{cases} \tag{9}</script><p>其中 $p^x=p_0^x+p_n^x+\Delta p_n^x$。注意 $p^x=q^x$ 时使用的是次梯度，不过这一情况实际几乎不会出现。</p><p><strong>可变形 RoI pooling</strong></p><p>根据 (6) 式，</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial \mathbf y(i,j)}{\partial \Delta \mathbf p_{ij}}&=\frac 1 {n_{ij}}\sum_{\mathbf p_n \in bin(i,j)} \frac {\partial \mathbf x(\mathbf p_0+ \mathbf p_n + \Delta \mathbf p_{ij})} {\partial \Delta \mathbf p_{ij}}\\&= \frac 1 {n_{ij}} \sum_{\mathbf p_n \in bin(i,j)} \left[\sum_{\mathbf q} \frac {\partial G(\mathbf q, \mathbf p_0+\mathbf p_n+\Delta \mathbf p_n)}{\partial \Delta \mathbf p_{ij}} \mathbf x(\mathbf q)\right]\end{aligned} \tag{10}</script><p>其中 $\frac {\partial G(\mathbf q, \mathbf p_0+\mathbf p_n+\Delta \mathbf p_n)}{\partial \Delta \mathbf p_{ij}}$ 的计算与 (8) 式类似。</p><p>然后计算对归一化 offset 的梯度，</p><script type="math/tex; mode=display">\frac {\partial \Delta \mathbf p_{ij}}{\partial \Delta \hat {\mathbf p}_{ij}}=\begin{bmatrix}\gamma w & 0 \\ 0 & \gamma h\end{bmatrix}</script>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conditional DETR 解读</title>
      <link href="/2022/04/22/transformer/conditional_detr/"/>
      <url>/2022/04/22/transformer/conditional_detr/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2108.06152">Conditional DETR for Fast Training Convergence</a><br>源码：<a href="https://github.com/Atten4Vis/ConditionalDETR">Atten4Vis/ConditionalDETR</a></p><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>DETR 将 transformer 引入目标检测任务中，实现一种 anchor free 且无需 post-processing（例如 NMS），但是 DETR 的缺点是训练太慢。</p><p>作者通过研究发现 DETR decoder 的 cross-attention（第二个 attention） 的权重很难准确的定位到目标 box 的 extremities（上下左右），如图 1，</p><p><img src="/images/transformer/conditional_detr1.png" alt=""></p><center>图 1. cross-attention 的 attention weight maps</center><p>图 1 中：</p><p>第一行是 conditional DETR-R50 训练 50 次后的 attention 权重 map， <code>spatial keys</code> 与 <code>spatial queries</code> 之间的点积 $\mathbf p_q^{\top} \cdot \mathbf p_k$ 的 soft-max 归一化</p><p>第二行是原生 DETR-50 训练 50 次后的 attention 权重 map，<code>query</code> 与 <code>spatial key</code> 之间的点积 $(\mathbf o_q + \mathbf c_q)^{\top} \mathbf p_k$ 的 soft-max 归一化。这里，$\mathbf o_q$ 是可学习的 object queries。</p><p>由于 $\mathbf p_q$ 在本文 conditional DETR 中由上一层的 <code>content embedding</code> 学习得到，而原生 DETR 中 $\mathbf o_q$ 没有包含 content 信息，故原生 DETR 中使用 $(\mathbf o_q + \mathbf c_q)$ 即 <code>query</code> 来对应 conditional DETR 中的 <code>spatial query</code>。（如果对部分变量不太了解，可以阅读完下文后再回头看看。）</p><p>第三行是原生 DETR-50 训练 500 次后的 attention 权重 map。</p><p>可见原生 DETR 在训练 50 时，目标 box 的左右边缘并不能被 attention weight 很好的表征。</p><h1 id="2-Conditional-DETR"><a href="#2-Conditional-DETR" class="headerlink" title="2. Conditional DETR"></a>2. Conditional DETR</h1><p>图 2 是 conditional DETR 中一个 decoder layer 的结构图，</p><p><img src="/images/transformer/conditional_detr2.png" alt=""></p><center>图 2</center><p><code>layer</code>：Decoder 是由若干个 layer 堆叠（stack）组成。每个 layer 包含三个部分：</p><pre><code>- `self-attention`- `cross-attention`- `FFN`</code></pre><h2 id="2-1-cross-attention"><a href="#2-1-cross-attention" class="headerlink" title="2.1 cross-attention"></a>2.1 cross-attention</h2><p>图 2 中 <code>cross-attention</code> 的 query 和 key 均不采用相加，而是 concatenate 操作。</p><p>query = [content query, spatial query]<br>key   = [content key, spatial key]<br>value = [content value]</p><p>变量说明：</p><ol><li><code>content query</code>($\mathbf c_q$) ：layer 中 <code>self-attention</code> 的输出。 </li><li><code>spatial query</code>($\mathbf p_q$) ：原生 DETR 中采用一个可学习的 object query，在 conditional DETR 中，这个变量由两个因素决定：<ul><li>decoder embedding($\mathbf f$)</li><li>reference point($\mathbf s$)</li></ul></li><li><code>content key</code>($\mathbf c_k$) ：Encoder 的输出</li><li><code>spatial key</code>($\mathbf p_k$) ：(sine) Position Embedding</li><li><code>content value</code>：Encoder 的输出</li><li><code>decoder embedding</code>($\mathbf f$) ：decoder layer 的输出</li><li><code>content embedding</code>: decoder layer 的一个（content）输入</li></ol><p>cross-attention weight 为</p><script type="math/tex; mode=display">\mathbf c_q^{\top} \mathbf c_k+\mathbf p_q^{\top} \mathbf p_k</script><p>将第一项看作是 content attention，第二项为 spatial attention。</p><p><code>decoder embedding</code> 包含了目标 box 与参考点 reference point 之间的位移信息，首先将 <code>decoder embedding</code> 映射，然后与参考点相加，得到非归一化位置，那么预测 box 为</p><script type="math/tex; mode=display">\mathbf b = \text{sigmoid}(FFN(\mathbf f)+[\mathbf s^{\top} \ 0 \ 0]^{\top})</script><p>其中 $\mathbf b = [b_{cx}, b_{cy}, b_w, b_h]^{\top}$</p><p><code>decoder embedding</code> 还包含了四个 extremities 所含区域信息，以此用来预测分类得分，</p><script type="math/tex; mode=display">\mathbf e=FFN(\mathbf f)</script><h2 id="2-2-Conditional-spatial-query"><a href="#2-2-Conditional-spatial-query" class="headerlink" title="2.2 Conditional spatial query"></a>2.2 Conditional spatial query</h2><p>cross-attention 的 <code>spatial query</code> $\mathbf p_q$ 由两个因素决定：</p><script type="math/tex; mode=display">(\mathbf s,\mathbf f) \rightarrow \mathbf p_q</script><p>先将 reference point $\mathbf s$ 从 2d 映射到 256d，</p><script type="math/tex; mode=display">\mathbf p_s = \text{sinusoidal(sigmoid}(\mathbf s))</script><p>然后将 $\mathbf f$ 经过一个 FFN 变换，这个 FFN 为：<code>FC+ReLU+FC</code></p><script type="math/tex; mode=display">T = FFN(\mathbf f)</script><p>这里将 256d 的向量 $\lambda_q$ 转为对角矩阵 $T$，这样做矩阵相乘，即可得到向量内积，且计算效率更高，</p><script type="math/tex; mode=display">\mathbf p_q = T \mathbf p_s = \lambda_q \cdot \mathbf p_s</script><h2 id="2-3-reference-point"><a href="#2-3-reference-point" class="headerlink" title="2.3 reference point"></a>2.3 reference point</h2><p>原生 DETR 中，$\mathbf s = [0 \ 0]^{\top}$。</p><p>conditional DETR 中，作者研究了两种生成 reference point $\mathbf s$ 的方法：</p><ol><li>将 $\mathbf s$ 看作是可学习的参数</li><li><p>使用 object queries 预测得到，</p><script type="math/tex; mode=display">\mathbf s=FFN(\mathbf o_q)</script><p> 其中 FFN 为 <code>FC+ReLU+FC</code>。</p></li></ol><h2 id="2-4-Loss"><a href="#2-4-Loss" class="headerlink" title="2.4 Loss"></a>2.4 Loss</h2><p>根据原生 DETR 一样，使用预测和 gt 之间的二分类匹配（匈牙利算法），然后根据匹配结果计算用于反向传播的损失函数。</p><p>损失函数与 deformable DETR 中一样：相同的匹配损失函数，相同的 $N=300$ object queries 的损失函数 (L1+GIoU)，相同的 trade-off 参数（各类型损失的平衡因子）。分类损失使用 focal loss。</p>]]></content>
      
      
      
        <tags>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像数据在送入网络之前的处理</title>
      <link href="/2022/04/16/pytorch/prepro_img/"/>
      <url>/2022/04/16/pytorch/prepro_img/</url>
      
        <content type="html"><![CDATA[<p>本文总结 PyTorch 和 TorchVision 中常用的图像处理的方法。</p><h1 id="1-Resize"><a href="#1-Resize" class="headerlink" title="1. Resize"></a>1. Resize</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">CLASS <span class="token class-name">torchvision</span><span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>size<span class="token punctuation">,</span> interpolation<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> antialias<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><ol><li><code>size</code>：如果是 (h,w)，那么图像被 resize 到这个 size；如果是 int，那么图像短边 rescale 到这个 size，长边保持相同的比例进行 rescale。</li><li><p><code>interpolation</code>：插值方式，枚举类型，可取值为</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python">BILINEAR （默认值）NEAREATBICUBIC<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><code>max_size</code>： resize 之后的长边最大值。</p></li><li><p><code>antialias</code>：是否使用 antialias 滤镜效果，从而可得到高质量的 resized 图像（若使用，会降低处理速度）。</p><p> 如果图像是 PIL 类型，那么这个参数值被忽略，且总是使用 <code>anti-alias</code>；如果图像是 Tensor 类型，那么这个参数默认为 <code>False</code>。仅在插值模式为 <code>BILINEAR</code> 时可设置为 <code>True</code>，</p></li></ol><p><strong>forward(img)</strong></p><p><code>img</code>：图像，PIL 或者 Tensor</p><p>返回：rescaled 图像，PIL 或 Tensor</p><h1 id="2-ToTensor"><a href="#2-ToTensor" class="headerlink" title="2. ToTensor"></a>2. ToTensor</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">CLASS <span class="token class-name">torchvision</span><span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将一个 PIL 图像（例如通过 Image.open 得到）或者 numpy.ndarray (<code>HxWxC</code>，范围为 <code>[0, 255]</code>，类型为 <code>np.uint8</code>) 转为 torch.FloatTensor，shape 为 <code>CxHxW</code>，范围为 <code>[0.0, 1.0]</code>。</p><p>对于其他情况，<code>ToTensor</code> 返回 tensor，但是不进行 scaling（即，不归一化到 <code>[0.0, 1.0]</code> 范围内）。</p><h1 id="3-Normalize"><a href="#3-Normalize" class="headerlink" title="3. Normalize"></a>3. Normalize</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">CLASS <span class="token class-name">torchvision</span><span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token punctuation">,</span> std<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><ol><li><code>mean</code>：每个通道的均值序列</li><li><code>std</code>：每个通道的标准差序列</li><li><code>inplace</code>：bool</li></ol><p>归一化如下：</p><script type="math/tex; mode=display">\mathbf y_c = (\mathbf x_c - \mu_c)/ \sigma_c, \ c=1,\ldots, C</script><p><strong>forward(tensor)</strong></p><p><code>tensor</code>：被归一化的 tensor</p><p>返回：归一化后的 tensor</p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PANet 论文解读</title>
      <link href="/2022/04/13/obj_det/PANet/"/>
      <url>/2022/04/13/obj_det/PANet/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSPNet 论文解读</title>
      <link href="/2022/04/12/obj_det/CSPNet/"/>
      <url>/2022/04/12/obj_det/CSPNet/</url>
      
        <content type="html"><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>模型为了强大而变得更宽更深，但是同时也带来了很大的计算负担。深度分离卷积是常用的降低计算量的一种方法，然而这种方法并不兼容当前的工业 IC 设计。</p><p>研究团队介绍了 Cross Stage Partial Network（CSPNet），目的是为了降低计算量的同时能获得丰富的梯度，实现方式是：将 base layer 的特征分为两个部分，然后经过一个 cross-stage 层级后再进行融合。CSPNet 处理以下三个问题：</p><ol><li><p>加强 CNN 的学习能力</p><p> 现有的 CNN 在轻量化后准确性也下降了。故研究团队希望可以增强 CNN 的学习能力，使得轻量化后依然维持足够高的准确率。CSPNet 可以应用于 ResNet，ResNeXt 以及 DenseNet 等。</p></li><li><p>去除计算瓶颈</p><p> 给 CNN 中每个 layer 分配相当的计算量。</p></li><li><p>降低内存消耗</p></li></ol><h1 id="2-方法"><a href="#2-方法" class="headerlink" title="2. 方法"></a>2. 方法</h1><h2 id="2-1-CSPNet"><a href="#2-1-CSPNet" class="headerlink" title="2.1 CSPNet"></a>2.1 CSPNet</h2><p>图 1 是 DenseNet 的结构（仅显示了一个 stage），</p><p><img src="/images/obj_det/CSPNet_1.png" alt=""></p><center>图 1. DenseNet 的 one-stage</center><p>DenseNet 中每个 stage 包含一个 dense block 和一个 transition layer，dense block 由 k 个 dense layers 组成。第 <code>i</code> 个 dense layer 的输出与其输入进行 concatenate，作为第 <code>i+1</code> 个 dense layer 的输入，数学表示如下，</p><script type="math/tex; mode=display">\mathbf x_1=\mathbf w_1\star \mathbf x_0\\\mathbf x_2=\mathbf w_2 \star [\mathbf x_0, \mathbf x_1]\\ \vdots\\\mathbf x_k=\mathbf w_k \star [\mathbf x_0, \ldots,\mathbf x_{k-1}]</script><p>反向传播梯度时，参数更新写为</p><script type="math/tex; mode=display">\mathbf w_1'=f(\mathbf w_1, \mathbf g_0)\\\mathbf w_2'=f(\mathbf w_2, \mathbf g_0, \mathbf g_1)\\\vdots\\\mathbf w_k'=f(\mathbf w_k, \mathbf g_0, \ldots, \mathbf g_{k-1})</script><p>其中 $\mathbf g_i$ 为第 <code>i</code> 个 dense layer 的梯度值。作者给出结论：大量的梯度信息在更新参数时被重复使用，不同的 dense layer 重复学习相同的梯度信息。</p><p>注意：这里的 $\mathbf g_i, \ i=0,1,\ldots, k-1$ 全部由 <code>k-th</code> layer 生成的梯度，这些梯度分别反向传播到 <code>i-th</code> layer。</p><h2 id="2-2-CSPDenseNet"><a href="#2-2-CSPDenseNet" class="headerlink" title="2.2 CSPDenseNet"></a>2.2 CSPDenseNet</h2><p>图 2 是在 DenseNet 上使用 CSP 结构，</p><p><img src="/images/obj_det/CSPNet_2.png" alt=""></p><center>图 2. CSPDenseNet</center><p>CSPDenseNet 的一个 stage 是由一个分部 dense block 和一个分部 transition layer 组成。在分部 dense block 中，输入沿通道切分为两部分 $x_0=[x_0’,x_0’’]$，其中前者 $x_0’$ 直接链接到这个 stage 的尾部，后者  $x_0’’$ 则穿过 dense block 和 transition layer，然后与  $x_0’$ 进行 concatenate 并作为下一 stage 的输入。</p><p>分部 transition layer 中的执行步骤：</p><ol><li>dense block 的输出 $[x_0’’,x_1,\ldots, x_k]$ 经过一个转移层</li><li>第 <code>1</code> 步中转移层的输出 $x_T$ 与 $x_0’$ 进行 concatenate，然后再经过一个转移层，输出 $x_U$</li></ol><script type="math/tex; mode=display">\frac {\partial \mathbf w_{k\_i} \star \mathbf x_i}{\partial \mathbf x_i}</script>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv4 论文解读</title>
      <link href="/2022/04/11/obj_det/yolov4/"/>
      <url>/2022/04/11/obj_det/yolov4/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2004.10934">YOLOv4: Optimal Speed and Accuracy of Object Detection</a></p><p>源码：<a href="https://github.com/AlexeyAB/darknet">AlexeyAB/darknet</a></p><p><strong>摘要：</strong></p><p>有很多特性可以用来提高 CNN 准确率，在大型数据集上综合这些特征需要实际测试并对结果进行理论说明。有的特性仅仅针对某种模型或问题而设计的，而有些特性如 residual connection、BN 是普适的，我们认为这类普适的特性包括：</p><ol><li>Weighted-Residual-Connections (WRC) 带权残差连接</li><li>Cross-Stage-Partial-connections (CSP) 跨阶段部分连接</li><li>Cross mini-Batch Normalization (CmBN) 跨批次归一化</li><li>Self-adversarial-training (SAT) 自对抗训练</li><li>Mish-activation</li><li>Mosaic 数据增强</li><li>DropBlock 正则</li><li>CIoU 损失</li></ol><p>作者综合使用了这些特性，并获得了 SOTA 结果：MS COCO 数据集上 43.5% AP，在 Tesla V100 上实时速度为 ~65 FPS。</p><p>文章贡献点：</p><ol><li>设计了一个高效且强大的目标检测模型。</li><li>验证了目标检测训练中 Bag-of-Freebies 和 Bag-of-Specials 方法的影响。</li><li>修改之前的 SOTA 模型使得更加高效且适用于单 GPU 训练。</li></ol><p>总结目标检测的组成部分：</p><p><strong>Input:</strong> Image, Patches, Image Pyramid</p><p><strong>Backbones:</strong> VGG16, ResNet-50, SpineNet, EfficientNet-B0/B7, CSPResNeXt50, CSPDarknet53</p><p><strong>Neck:</strong></p><ol><li>新增块： SPP, ASPP, RFB, SAM</li><li>路径聚合块：FPN, PAN, NAS-FPN, Fully-connected FPN, BiFPN, ASFF, SFAM</li></ol><p><strong>Heads:</strong></p><ol><li><p>密集预测（一阶段）</p><ul><li>RPN, SSD, YOLO, RetinaNet (anchor based)</li><li>CornerNet, CenterNet, MatrixNet, FCOS (anchor free)</li></ul></li><li><p>稀疏预测（二阶段）</p><ul><li>Faster R-CNN, R-FCN, Mask R-CNN (anchor based)</li><li>RepPoints (anchor free)</li></ul></li></ol><h1 id="1-Bag-of-freebies"><a href="#1-Bag-of-freebies" class="headerlink" title="1. Bag of freebies"></a>1. Bag of freebies</h1><p>仅仅是改变训练策略或者说仅增加训练成本而不增加推断成本的方法，称为 Bag of freebies。目标检测中常用的 Bag of freebies 为数据增强。两种常用的数据增加方式：</p><h2 id="1-1-光照变化"><a href="#1-1-光照变化" class="headerlink" title="1.1 光照变化"></a>1.1 光照变化</h2><p>亮度，对比度，hue，饱和度，噪声</p><h2 id="1-2-几何畸变"><a href="#1-2-几何畸变" class="headerlink" title="1.2 几何畸变"></a>1.2 几何畸变</h2><p>随机伸缩，裁剪，翻转，旋转</p><h2 id="1-3-目标遮挡"><a href="#1-3-目标遮挡" class="headerlink" title="1.3 目标遮挡"></a>1.3 目标遮挡</h2><p>此外，还有其他研究者使用目标遮挡进行数据增强，具体方法包括：</p><h3 id="1-3-1-random-erase"><a href="#1-3-1-random-erase" class="headerlink" title="1.3.1 random erase"></a>1.3.1 random erase</h3><p>arxiv：<a href="https://arxiv.org/pdf/1708.04896v2.pdf">https://arxiv.org/pdf/1708.04896v2.pdf</a></p><p>源码：<a href="https://github.com/zhunzhong07/Random-Erasing">https://github.com/zhunzhong07/Random-Erasing</a></p><p>在图像内随机选择一个矩形区域，将区域内像素值改为随机值或者数据集像素均值（RGB三通道均值）</p><h3 id="1-3-2-Cutout"><a href="#1-3-2-Cutout" class="headerlink" title="1.3.2 Cutout"></a>1.3.2 Cutout</h3><p>arxiv：<a href="https://arxiv.org/pdf/1708.04552v2.pdf">https://arxiv.org/pdf/1708.04552v2.pdf</a></p><p>源码：<a href="https://github.com/uoguelph-mlrg/Cutout">https://github.com/uoguelph-mlrg/Cutout</a></p><p>固定 size 的正方形区域，随机选择位置，然后将区域内像素 0 填充。为了降低 cutout 的影响，在 cutout 之前先将数据集归一化处理。</p><script type="math/tex; mode=display">x:= \frac {x-\mu} {v}</script><p>其中 $x$ 是归一化后的像素值，$x:=x/255$，$\mu$ 是 ImageNet RGB 通道平均，</p><script type="math/tex; mode=display">\mu=[109.9/255,109.7/255,113.8/255]</script><p>$v$ 是标准差，</p><script type="math/tex; mode=display">v=[50.1/255, 50.6/255, 50.8/255]</script><p>代码片段：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>data_augmentation<span class="token punctuation">:</span>    train_transform<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    train_transform<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>train_transform<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>train_transform<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>normalize<span class="token punctuation">)</span><span class="token keyword">if</span> args<span class="token punctuation">.</span>cutout<span class="token punctuation">:</span>    train_transform<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Cutout<span class="token punctuation">(</span>n_holes<span class="token operator">=</span>args<span class="token punctuation">.</span>n_holes<span class="token punctuation">,</span> length<span class="token operator">=</span>args<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h3 id="1-3-3-Hide-and-Seek"><a href="#1-3-3-Hide-and-Seek" class="headerlink" title="1.3.3 Hide-and-Seek"></a>1.3.3 Hide-and-Seek</h3><p>arxiv：<a href="https://arxiv.org/pdf/1811.02545.pdf">https://arxiv.org/pdf/1811.02545.pdf</a></p><p>源码：<a href="https://github.com/kkanshul/Hide-and-Seek">https://github.com/kkanshul/Hide-and-Seek</a></p><p>将图像划分成 $S \times S$ 网格，每个网格有一定概率被遮挡，遮挡部分使用整个数据集的均值。</p><h3 id="1-3-4-Grid-Mask"><a href="#1-3-4-Grid-Mask" class="headerlink" title="1.3.4 Grid Mask"></a>1.3.4 Grid Mask</h3><p>arxiv: <a href="https://arxiv.org/abs/2001.04086">https://arxiv.org/abs/2001.04086</a></p><p>源码：<a href="https://github.com/akuxcw/GridMask">https://github.com/akuxcw/GridMask</a></p><p>如图 1，将原输入图像乘上 mask，得到 Grid Mask 的图，<br><img src="/images/obj_det/yolov4_1.png" alt=""></p><center>图 1. Grid Mask</center><p>数学表达为 </p><script type="math/tex; mode=display">\tilde {\mathbf x}=\mathbf x \times M</script><p>其中 $\mathbf x \in \mathbb R^{H \times W \times C}$ 表示一图像，$M \in \{0,1\}^{H \times W}$。如何生成这个 binary mask $M$？如图 2，</p><p><img src="/images/obj_det/yolov4_2.png" alt=""></p><center>图 2. 黄色虚线表示 mask 的一个 unit</center><p>使用 $(r,d,\delta_x, \delta_y)$ 4 个参数表征 $M$，$r$ 是一个 unit 内灰度边的比例（灰度边长相对于 $d$ 的比例），灰度表示 mask 像素值为 <code>1</code>，$d$ 是 unit 的长度。$\delta_x, \ \delta_y$ 是完整 unit 到图像边界的距离。</p><p>对于一个给定的 mask $M$，定义保留率 $k$ 如下：</p><script type="math/tex; mode=display">k=\frac {sum(M)} {H \times W}</script><p>表示图像中像素值被保留的比例。$k$ 太大，CNN 可能仍会过拟合，$k$ 太小则会丢失较多信息从而导致欠拟合。忽略图像左侧和上侧的不完整 units，那么 $r, \ k$ 的关系如下，</p><script type="math/tex; mode=display">k=1-(1-r)^2=2r-r^2</script><p>其中 $1-r$ 表示 unit 中黑块的 size。</p><h3 id="1-3-5-正则"><a href="#1-3-5-正则" class="headerlink" title="1.3.5 正则"></a>1.3.5 正则</h3><p>对网络中间层的 features 进行 mask，例如 Dropout，DropConnect， DropBlock</p><h3 id="1-3-6-多图像"><a href="#1-3-6-多图像" class="headerlink" title="1.3.6 多图像"></a>1.3.6 多图像</h3><p>利用多个图像进行数据增强，例如 MixUp 使用两个图像分别乘以不同的系数，然后进行叠加，同时 gt labels 也根据系数进行调整。</p><h2 id="1-4-GAN"><a href="#1-4-GAN" class="headerlink" title="1.4 GAN"></a>1.4 GAN</h2><p>style transfer GAN 用于数据增强。</p><h2 id="1-5-OHEM"><a href="#1-5-OHEM" class="headerlink" title="1.5 OHEM"></a>1.5 OHEM</h2><p>对于具有语义分布偏向的问题，例如数据分类不均衡，使用难负例挖掘，或者在线难负例挖掘。</p><p>Focal loss 是另一种解决分类不均衡的方法，对于少数分类的样本，其损失的系数比多数分类样本的系数大。</p><h2 id="1-6-label-表征"><a href="#1-6-label-表征" class="headerlink" title="1.6 label 表征"></a>1.6 label 表征</h2><p>one-hot 表征不能体现不同分类之间的关系度。<a href="https://arxiv.org/abs/1512.00567">Rethinking the inception architecture for computer vision</a> 在训练过程中将 hard label 转换为 soft label，这是模型更加 robust。<a href="https://arxiv.org/abs/1703.00551">Label refinement network for coarse-to-fine semantic segmentation</a> 利用知识蒸馏来设计网络以优化 label 表征。</p><h2 id="1-7-目标函数"><a href="#1-7-目标函数" class="headerlink" title="1.7 目标函数"></a>1.7 目标函数</h2><p>BBox 回归的目标函数通常采用 MSE 对 BBox 的中心点坐标和宽高或者左上右下坐标进行回归。这种方法将 4 个坐标独立对待分别进行回归，没有考虑到目标整体，后来有了 IoU 损失，IoU 损失具有尺度不变性这个优势。</p><p>为了进一步改善 IoU 损失，又提出了 GIoU 以及 DIoU 损失。GIoU 解决了 IoU 损失与 BBox 参数的距离损失不等价问题，且对无重叠的 BBox 也可进行优化（详情可参考这篇博文 <a href="https://jianjiansha.github.io/2019/06/13/obj_det/GIoU/">GIoU</a>）。</p><p>DIoU 则额外考虑了目标中心点的距离。CIoU 则同时考虑了重叠区域面积，中心点距离以及 aspect ratio。</p><p>如图 3，</p><p><img src="/images/obj_det/yolov4_3.png" alt=""></p><center>图 3. IoU, GIoU, DIoU 对比。绿色为 gt box，红色为预测 box</center><script type="math/tex; mode=display">L_{DIoU}=1-IoU+\frac {\rho^2(\mathbf b, \mathbf b^{gt})} {c^2}</script><p>其中 $\mathbf b, \mathbf b^{gt}$ 是预测 box 和 gt box 的中心点，$\rho$ 是欧氏距离，$c$ 是包含预测box 和 gt box 的最小框的对角线长度。</p><script type="math/tex; mode=display">L_{CIoU}=1-IoU+\frac {\rho^2(\mathbf b, \mathbf b^{gt})} {c^2}+\alpha v</script><p>其中 $\alpha$ 是一个正 trade-off 参数，$v$ 是预测 box 与 gt box aspect ratio 一致性的测度，</p><script type="math/tex; mode=display">\alpha=\frac v {(1-IoU)+v}</script><script type="math/tex; mode=display">v=\frac 4 {\pi^2}(\arctan \frac {w^{gt}}{h^{gt}} - \arctan \frac w h)^2</script><h1 id="2-Bag-of-specials"><a href="#2-Bag-of-specials" class="headerlink" title="2. Bag of specials"></a>2. Bag of specials</h1><p>部分模块和 post-processing 方法仅增加推断成本，但是可以显著提高准确性，称其为 “Bag of specials”。通常增加的这些模块是为了增强某个模型的某些属性，例如：增大感受野，增强特征整合能力等。post-processing 方法则是用于筛查模型的预测结果。</p><h2 id="2-1-感受野"><a href="#2-1-感受野" class="headerlink" title="2.1 感受野"></a>2.1 感受野</h2><p>常用的用于增大感受野的模块有 SPP, ASPP, RFB 等。</p><p>SPP 在 backbone 之后增加一个 Spatial Pyramid Matching，将 backbone 的输出特征 features 分别 pooling 为 <code>1x1</code>, <code>2x2</code>, <code>4x4</code> 三种空间大小的特征，然后再 flatten 并 concatenate 送入全连接层。</p><h2 id="2-2-attention"><a href="#2-2-attention" class="headerlink" title="2.2 attention"></a>2.2 attention</h2><p>注意力模块也常用在目标检测种，分为 channel-wise 注意力和 point-wise 注意力，例如 Squeeze-and-Excitation, Spatial Attention Module。</p><h2 id="2-3-特征整合"><a href="#2-3-特征整合" class="headerlink" title="2.3 特征整合"></a>2.3 特征整合</h2><p>关于特征整合，早期的实现是 skip connection, 或者 hyper-column，融合高低层特征。另外 FPN 系列的多尺度特征上采用轻量检测 heads，例如 SFAM, ASFF, BiFPN 等。</p><h2 id="2-4-激活函数"><a href="#2-4-激活函数" class="headerlink" title="2.4 激活函数"></a>2.4 激活函数</h2><p>部分研究人员注意力集中在激活函数上，例如 ReLU，LReLU，PReLU，ReLU6， SELU, Swish, hard-Swish 以及 Mish 等。</p><h2 id="2-5-post-processing"><a href="#2-5-post-processing" class="headerlink" title="2.5 post-processing"></a>2.5 post-processing</h2><p>非极大抑制 NMS</p><p>soft NMS（参考这篇博文中的 <a href="https://jianjiansha.github.io/2019/06/24/cv/cv-mtds/">Soft-NMS</a>一节 ）核心思想是对于两个预测 box，其 IoU 超过阈值时较小得分的那个预测 box，其得分并不直接置 0，而是改为一个更小的值。</p><p>DIoU NMS，在 soft NMS 的基础上考虑中心点的距离信息。</p><h1 id="3-方法论"><a href="#3-方法论" class="headerlink" title="3. 方法论"></a>3. 方法论</h1><h2 id="3-1-框架选择"><a href="#3-1-框架选择" class="headerlink" title="3.1 框架选择"></a>3.1 框架选择</h2><p>在 network 输入大小，卷积层数量，参数量（<code>filter_size * filter_size * filters * channel / groups</code>）和 layer 输出数量（<code>filters</code>） 之间寻找一个最佳平衡。</p><p>在 ImageNet 数据集上（图像分类任务） CSPResNext50 比 CSPDarknet53 效果好，但是在 MSCOCO 数据集上（目标检测任务）后者要好些。</p><p>分类任务的最佳模型在检测任务上不一定是最佳。与分类不同，检测需要：</p><ol><li>更大的网络输入 size，用于检测小尺寸目标</li><li>更多 layers。由于网络输入 size 的增大，这就要求更大的感受野以足够覆盖网络输入 size。</li><li>更多的参数，使得拥有检测单个 image 中的多个不同 size 目标的能力。</li></ol><p>不同 size 的感受野 RF：</p><ol><li>RF 达到目标 size - 可以看到整个目标</li><li>RF 达到网络输入 size - 可以看到目标周围的上下文</li></ol><p>YOLOv4 整个网络概述：</p><ol><li>在 CSPDarknet53 上增加 SPP 模块，以增大感受野</li><li>PANet 路径聚合</li><li>YOLOv3（基于 anchor）的检测 head</li></ol><h2 id="3-2-BoF-和-BoS"><a href="#3-2-BoF-和-BoS" class="headerlink" title="3.2 BoF 和 BoS"></a>3.2 BoF 和 BoS</h2><h3 id="3-2-1-激活函数"><a href="#3-2-1-激活函数" class="headerlink" title="3.2.1 激活函数"></a>3.2.1 激活函数</h3><p>ReLU，Leaky-ReLU，parametric-ReLU，Swish，Mish</p><p>PReLU 和 SELU 难以训练，故不使用。ReLU6 用于量化网络也不使用。</p><h3 id="3-2-2-回归损失"><a href="#3-2-2-回归损失" class="headerlink" title="3.2.2 回归损失"></a>3.2.2 回归损失</h3><p>MSE，IoU，GIoU，CIoU，DIoU</p><h3 id="3-2-3-数据增强"><a href="#3-2-3-数据增强" class="headerlink" title="3.2.3 数据增强"></a>3.2.3 数据增强</h3><p>CutOut，MixUp，CutMix</p><h3 id="3-2-4-正则"><a href="#3-2-4-正则" class="headerlink" title="3.2.4 正则"></a>3.2.4 正则</h3><p>DropOut，DropPath，Spatial DropOut，DropBlock</p><p>由于先前论文研究认为 DropBlock 效果最好，故作者也使用了 DropBlock。</p><h3 id="3-2-5-归一化"><a href="#3-2-5-归一化" class="headerlink" title="3.2.5 归一化"></a>3.2.5 归一化</h3><p>BN，Filter Response Norm，Cross-Iteration BN</p><p>不使用 syncBN ，因为为了简化训练，仅使用单 GPU 训练。</p><h3 id="3-2-6-Skip-连接"><a href="#3-2-6-Skip-连接" class="headerlink" title="3.2.6 Skip 连接"></a>3.2.6 Skip 连接</h3><p>Residual 连接，加权 residual 连接，多输入加权 residual 连接，Cross stage partial（CSP）连接</p><h2 id="3-3-其他改进"><a href="#3-3-其他改进" class="headerlink" title="3.3 其他改进"></a>3.3 其他改进</h2><ol><li>介绍了新数据增强方法 Mosaic，以及 self-adversarial training（SAT）</li><li>使用遗传算法时，使用最优超参数</li><li><p>对现有方法的改进，使得检测更加高效，修改了 SAM，PAN，CmBN（Cross mini-batch BN）</p><p> 修改 SAM 从 spatial-wise 注意力到 point-wise 注意力，如图 4，</p><p> <img src="/images/obj_det/yolov4_4.png" alt=""></p><p> 将 PAN shortcut 连接替换为 concatenation，如图 5，</p><p> <img src="/images/obj_det/yolov4_5.png" alt=""></p></li></ol><h2 id="3-4-YOLOv4"><a href="#3-4-YOLOv4" class="headerlink" title="3.4 YOLOv4"></a>3.4 YOLOv4</h2><ul><li>Backbone: CSPDarknet53</li><li>Neck: SPP, PAN</li><li>Head: YOLOv3</li></ul><p>总结 YOLOv4 的 BoF 和 BoS</p><ul><li>backbone BoF：CutMix , Mosaic 数据增强，DropBlock 正则，分类标签平滑</li><li>backbone BoS：Mish 激活，CSP 连接，多输入加权 residual 连接</li><li>detector BoF：CIoU 损失，CmBN 归一化，DropBlock 正则，Mosaic 数据增强，SAT，grid 敏感度消除，单 GT 多 anchor，余弦退火调度，最优超参数，随机训练 shapes。（好多不懂是啥）</li><li>detector BoS：Mish 激活，SPP 模块，空间注意力模块（SAM），PAN 路径聚合模块，DIoU-NMS</li></ul><h1 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h1>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>边缘检测</title>
      <link href="/2022/04/08/dip/edge_det/"/>
      <url>/2022/04/08/dip/edge_det/</url>
      
        <content type="html"><![CDATA[<p>对灰度值求导，导数不为 0 的点即边界点。图像的像素点是离散点，故求导数实际上就是求相邻像素点的差值。</p><h1 id="1-边缘检测算子"><a href="#1-边缘检测算子" class="headerlink" title="1. 边缘检测算子"></a>1. 边缘检测算子</h1><h2 id="1-1-卷积核"><a href="#1-1-卷积核" class="headerlink" title="1.1 卷积核"></a>1.1 卷积核</h2><h3 id="1-1-1-简单的差分滤波"><a href="#1-1-1-简单的差分滤波" class="headerlink" title="1.1.1 简单的差分滤波"></a>1.1.1 简单的差分滤波</h3><ol><li>x 方向偏导</li></ol><script type="math/tex; mode=display">\begin{array}{|c|c|}\hline-1 & 1\\\hline\end{array}</script><ol><li>y 方向偏导</li></ol><script type="math/tex; mode=display">\begin{array}{|c|}\hline-1\\\hline1\\\hline\end{array}</script><p>对于卷积后的像素值，如果超过 <code>0-255</code> 范围，直接取绝对值就行。</p><h3 id="1-1-2-Roberts-算子"><a href="#1-1-2-Roberts-算子" class="headerlink" title="1.1.2 Roberts 算子"></a>1.1.2 Roberts 算子</h3><p>Roberts 算子考虑对角方向相邻像素差。</p><script type="math/tex; mode=display">dx = \begin{bmatrix} -1 & 0 \\ 0 & 1 \end{bmatrix}</script><script type="math/tex; mode=display">dy = \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix}</script><h3 id="1-1-3-Prewitt-算子"><a href="#1-1-3-Prewitt-算子" class="headerlink" title="1.1.3 Prewitt 算子"></a>1.1.3 Prewitt 算子</h3><p>间隔一个像素点的两个相近点的像素差，可以去掉部分伪边缘。</p><script type="math/tex; mode=display">dx = \begin{bmatrix} 1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1 \end{bmatrix}</script><script type="math/tex; mode=display">dy = \begin{bmatrix} -1 & -1 & -1 \\ 0 & 0 & 0 \\ 1 & 1 & 1 \end{bmatrix}</script><h3 id="1-1-4-Sobel-算子"><a href="#1-1-4-Sobel-算子" class="headerlink" title="1.1.4 Sobel 算子"></a>1.1.4 Sobel 算子</h3><p>在 Prewitt 算子的基础上考虑权重：越靠近中心的权重越大。</p><script type="math/tex; mode=display">dx = \begin{bmatrix} 1 & 0 & -1 \\ 2 & 0 & -2 \\ 1 & 0 & -1 \end{bmatrix}</script><script type="math/tex; mode=display">dy = \begin{bmatrix} -1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}</script><h2 id="1-2-图像梯度"><a href="#1-2-图像梯度" class="headerlink" title="1.2 图像梯度"></a>1.2 图像梯度</h2><h3 id="1-2-1-梯度定义"><a href="#1-2-1-梯度定义" class="headerlink" title="1.2.1 梯度定义"></a>1.2.1 梯度定义</h3><script type="math/tex; mode=display">\nabla f = \begin{bmatrix} \frac {\partial f} {\partial x}, & \frac {\partial f} {\partial y} \end{bmatrix}</script><h3 id="1-2-2-梯度角度"><a href="#1-2-2-梯度角度" class="headerlink" title="1.2.2 梯度角度"></a>1.2.2 梯度角度</h3><script type="math/tex; mode=display">\theta = \tan^{-1} \left(\frac {\partial f} {\partial x} / \frac {\partial f} {\partial y} \right)</script><h3 id="1-2-3-梯度幅值"><a href="#1-2-3-梯度幅值" class="headerlink" title="1.2.3 梯度幅值"></a>1.2.3 梯度幅值</h3><script type="math/tex; mode=display">\|\nabla f\| = \sqrt{\left(\frac {\partial f} {\partial x} \right)^2+\left( \frac {\partial f} {\partial y}\right)^2}</script><p>计算出 x，y 两个方向的梯度值之后，再计算梯度的幅值从而融合成一幅图像，最后二值化处理，可以得到边缘图。但是这种方法得到的边缘图存在很多问题，例如噪声污染未排除，边缘线过于粗宽等。</p><p>解决思想：</p><ol><li>平滑处理：使用高斯滤波器降噪，</li><li>对图像信号求导</li></ol><h2 id="1-2-4-高斯滤波器"><a href="#1-2-4-高斯滤波器" class="headerlink" title="1.2.4 高斯滤波器"></a>1.2.4 高斯滤波器</h2><p>使用高斯平滑降噪。二维高斯公式，</p><script type="math/tex; mode=display">G(x,y)=\frac 1 {2 \pi \sigma^2} e^{-\frac {x^2+y^2} {2\sigma^2}}</script><p>例如：</p><script type="math/tex; mode=display">\frac 1 {16} \times \begin{bmatrix} 1 & 2 & 1 \\ 2 & 4 &2 \\ 1 & 2 & 1\end{bmatrix}</script><script type="math/tex; mode=display">\frac 1 {273} \times \begin{bmatrix} 1 & 4 & 7 & 4& 1 \\ 4 & 16 & 26 & 16 & 4 \\ 7 & 26 & 41 & 26 & 7 \\ 4 & 16 & 26 & 16 & 4 \\ 1 & 4 & 7 & 4& 1 \end{bmatrix}</script><h3 id="1-2-5-Candy-算子"><a href="#1-2-5-Candy-算子" class="headerlink" title="1.2.5 Candy 算子"></a>1.2.5 Candy 算子</h3><p>根据卷积性质，$(f \star g)’=f \star g’$，故可以 <strong>先对平滑核求导，然后再卷积</strong>。</p><blockquote><p>计算 x, y 方向的梯度后，可以进行归一化， $\nabla f / \max \nabla f$</p></blockquote><h3 id="1-2-6-非极大抑制"><a href="#1-2-6-非极大抑制" class="headerlink" title="1.2.6 非极大抑制"></a>1.2.6 非极大抑制</h3><p>根据梯度幅值得到的图像仍然存在边缘粗宽，弱边缘干扰等问题，可以采样非极大抑制。</p><p>对于某一点 $C$，其灰度值在 8连通邻域内是否最大，如果是则继续检查其梯度方向（即上面的梯度角度）与 8 连通邻域连线的交点 $c1, c2$，如 $C$ 点值大于 $c_1, c_2$ 的值，那么 $C$ 处值不变，否则为 0。这里 $c_1, c_2$ 如果不在 8 连通邻域集合内，那么就是8 连通邻域集合里最近的两个点的线性插值得到。</p><h3 id="1-2-7-双阈值边缘连接"><a href="#1-2-7-双阈值边缘连接" class="headerlink" title="1.2.7 双阈值边缘连接"></a>1.2.7 双阈值边缘连接</h3><p>经过非极大抑制后，仍然存在部分伪边缘，Candy 算法中采取双阈值 $t_1, t_2, \ t_1 &lt; t_2$，将小于 $t_1$ 的点置为 0（伪边缘），大于 $t_2$ 的置 1。在 $t_1, t_2$ 之间的则等待进一步处理。</p><p>将像素值为 1 的点连接（8连通邻域）起来，形成轮廓，当到达轮廓端点时，在端点的 8 邻域内寻找满足介于 $t_1, t_2$ 之间的点，再根据此点收集新的端点，知道轮廓闭合。 </p><p>这里需要使用递归，即当一个点找不到下一个合适的 8 邻域内的点做新的端点时，那么回溯到这个点的上一个点，并重新找 8 邻域内的新端点。</p>]]></content>
      
      
      <categories>
          
          <category> 数字图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DIP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BERT</title>
      <link href="/2022/03/31/transformer/bert/"/>
      <url>/2022/03/31/transformer/bert/</url>
      
        <content type="html"><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><h2 id="1-1-参数量"><a href="#1-1-参数量" class="headerlink" title="1.1 参数量"></a>1.1 参数量</h2><p>$BERT_{BASE}$ $L=12, H=768, A=12$<br>$BERT_{LARGE}$ $L=24, H=1024, A=16$</p><p>参考 Transformer 结构，L 是 Encoder 中 block 的数量，即 《Attention is all you need》 中的 $N \times$，$A$ 是 multi-head attention 中的 head 数量，$H$ 是隐藏层的单元数，即模型宽度，也就是 《Attention is all you need》 中的 $d$。</p><p>于是，multi-head attention 中 单个 head 的模型宽带为 $H/A=64$。</p><ol><li><p>embedding， 一个矩阵 $\mathbb R^{V\times H}$，其中 $V$ 表示词汇集大小，$H$ 为 embedding 维度，由于 Transformer 中有 identity shortcut 连接，所以 embedding 维度必须与 attention 输出维度相同，故 embedding 维度也是 $H$ 。</p></li><li><p>Attention 中 $Q,K,V$ 的映射矩阵均为 $W \in \mathbb R^{H \times H}$，single/multi-head attention 均为这个大小。</p></li><li><p>Attention 中输出 $O$ 的映射矩阵也是 $W \in \mathbb R^{H \times H}$</p></li><li><p>attention 上方是 feed-forward layer，这是一个由两个 全连接 组成的 layer，Bert 论文指出，feed-forward/filter size 为 $4H$，所以这两个 全连接 的维度转换应该是 $H \rightarrow 4 H, \ 4H \rightarrow H$，参数量为 $2 \times 4\times H \times H=8H^2$</p></li></ol><p>于是一个 Transformer block 的（可学习）参数量为 $4H^2+8H^2=12H^2$</p><p>$L$ 个 Transformer block 的参数量为 $12LH^2$，总参数量为 $VH+12LH^2$，</p><p>论文中指出所用词汇集大小为 $V=30000$，然后根据 Bert base 的超参数 $L=12,H=786$，计算出总参数量为 $112542624$ （Bert large 模型的参数可类似地计算出来）。</p><h2 id="1-2-词嵌入"><a href="#1-2-词嵌入" class="headerlink" title="1.2 词嵌入"></a>1.2 词嵌入</h2><p>例如以空格进行分词，那么对于大数据集，token 数量会特别大，导致模型参数集中在嵌入层，为了解决这个问题，使用 WordPiece embedding。具体而言：使用一个 word 的子序列（字符串的前 n 个字符构成的子串），这个子序列有可能就是这个 word 的词根。参考 <a href="https://arxiv.org/abs/1609.08144">Google’s neural machine translation system: Bridging the gap between human and machine translation</a></p><h2 id="1-3-特殊-token"><a href="#1-3-特殊-token" class="headerlink" title="1.3 特殊 token"></a>1.3 特殊 token</h2><p>[CLS] 表示句子的整体信息，这个 token 的最终表示，即最后一个 Transformer block 的输出 （是一个 $H$ 长度的向量）就是这个句子信息的 BERT 表征。</p><p>每个句子末尾添加 [SEP] token 表示句子结束。</p><p>BERT 的输入序列可以是单个句子，也可以是句子对（两个句子）。输入是单个句子是，输入序列是 “[cls]”、文本序列的标记、以及特殊分隔词元 “[sep]”的连结。当输入为文本对时，BERT输入序列是“[cls]”、第一个文本序列的标记、“[sep]”、第二个文本序列标记、以及“[sep]”的连结</p><h2 id="1-4-输入表示"><a href="#1-4-输入表示" class="headerlink" title="1.4 输入表示"></a>1.4 输入表示</h2><p>每个 token 由三个 embedding 构成：</p><ol><li>word embedding。这就是 word 自身的词嵌入表示</li><li>segment embedding。由于 BERT 使用两个句子作为输入，那么每个句子的 token 均需要一个额外 embedding 表示是第一个句子还是第二个句子。</li><li>position embedding。与原生 Transformer 相同，由于 attention 中各输入是未知无关的，所以需要额外增加一个位置信息的 embedding。</li></ol><p>三种 embedding 的维度均为 $H$，相加得到最终的 embedding 表示（维度仍为 $H$）。</p><h1 id="2-预训练-BERT"><a href="#2-预训练-BERT" class="headerlink" title="2. 预训练 BERT"></a>2. 预训练 BERT</h1><h2 id="2-1-Masked-LM"><a href="#2-1-Masked-LM" class="headerlink" title="2.1 Masked LM"></a>2.1 Masked LM</h2><p>标准的条件语言模型只能进行从左到右或者从右到左地训练，数学模型为</p><script type="math/tex; mode=display">p(x_i|x_1,...,x_{i-1}) \\p(x_i|x_{i+1},...,x_T)</script><p>双向条件的训练的数学模型为</p><script type="math/tex; mode=display">p(x_i|x_1,...,x_T)</script><p>这使得每个 word 可以看见自己，导致模型可以平凡地预测目标值。</p><p>为了训练出一个深度双向的表征，作者随机对 token 进行掩码处理，然后预测这些被掩盖的 token，这称为 <code>masked LM</code>，这些 masked token 的最后一个 Transformer block 的输出特征，输入到一个 fc 层，输出向量表示词汇表各 word 的得分，然后使用 softmax 进行预测。</p><p>每个输入序列的 15% 的 wordpiece 被 mask，即使用 <code>[MASK]</code> 替换原来的 token。对于 <code>[CLS], [SEP]</code> 则不参与 mask。</p><p>但是这种 mask 处理也会带来不匹配问题，在 fine-tuning 阶段，<code>[MASK]</code> 可不会出现。因为 fine-tuning 阶段的目标不同，并非用于预测被 mask 的 token，所以不会有 <code>[MASK]</code>。</p><p>为了解决这个不匹配问题，对于每个被选中的待 mask 的 token：</p><ol><li>80% 训练时间使用 <code>[MASK]</code> 替换</li><li>10% 训练时间使用一个有效的随机 token 替换</li><li>10% 训练时间保持不变，就是原来的 token</li></ol><h2 id="2-2-NSP"><a href="#2-2-NSP" class="headerlink" title="2.2 NSP"></a>2.2 NSP</h2><p>Next Sentence Prediction(NSP)</p><p>许多下游任务例如 问答（QA）以及 自然语言推断（NLI）均基于两个句子间关系的理解。为了训练出一个能理解两个句子间关系的模型，作者设计了一个二分类的下一句预测任务，即给两个句子作为输入，预测第二个句子是否是第一个句子的下一句。</p><p>训练时，每个训练样本中的句子 A 和 B，50% 的概率下 B 是 A 的下一句，即 label 为正，另外 50% 的概率下 label 为负。将 <code>[CLS]</code> 的最终向量用于预测是否是下一句。</p><p><strong>预训练数据：</strong></p><p>使用 BooksCorpus 和 English Wikipedia 数据集。作者使用 document-level 的语料而非 sentence-level 语料。Document 中，可以获得连续的两个句子（在 document 中自然连续，不一定要有语义上的某种关联）。</p><h1 id="3-实验"><a href="#3-实验" class="headerlink" title="3. 实验"></a>3. 实验</h1><h2 id="3-1-GLUE"><a href="#3-1-GLUE" class="headerlink" title="3.1 GLUE"></a>3.1 GLUE</h2><p>输入序列（单个句子或者句子对），使用 <code>[CLS]</code> 的最终特征向量 $C \in \mathbb R^H$，作为输入序列的聚合表征。额外增加的分类层是一个 fc 层和 Softmax，fc 层参数 $W \in \mathbb R^{K \times H}$，其中 $K$ 表示分类数量。</p><p><code>batch_size=32</code></p><p>对所有 GLUE 任务 fine-tune <code>epoch=3</code> 轮。</p><p>使用 $5e^{-5}, 5e^{-5}, 4e^{-5}, 3e^{-5}, 2e^{-5}$ 不同的学习率，最终选择在 Dev set 验证数据集上最好的那个。</p><p>BERT 与其他模型在 GLUE 上的性能比较看原论文 Table ，这里不列出来了。</p><h2 id="3-2-SQuAD-v1-1"><a href="#3-2-SQuAD-v1-1" class="headerlink" title="3.2 SQuAD v1.1"></a>3.2 SQuAD v1.1</h2><p>这是 Standford 的一个 QA 问答数据集。给定一个问题和一个段落（来自 Wikipedia，且包含了问题的答案），这个任务目标是预测答案在段落中的起始截止位置。</p><p>如图 1，</p><p><img src="/images/transformer/BERT1.png" alt=""></p><center>图 1 </center><p>将问题和段落分别作为输入序列中的 A 和 B。</p><p>引入一个 start 向量 $S \in \mathbb R^H$ 和一个 end 向量 $E \in \mathbb R^H$。这两个向量相当于两个 fc 层的权重参数，将每个 word 的最后的 hidden 向量映射到一个非归一化得分，这两个 fc 层的权重参数均在各个 word 中共享。</p><p>例如向量 $S$，将 word <code>i</code> 的最后一个 Transformer block 的输出向量 $T_i$ 映射为得分 $S \cdot T_i$，那么经 softmax 后可得 word <code>i</code> 为答案的 start 的概率为</p><script type="math/tex; mode=display">P_i=\frac {e^{S \cdot T_i}}{\sum_j e^{S \cdot T_j}} \tag{1}</script><p>其中 $j$ 的范围是输入序列中 $B$ 的下标范围（or 整个输入序列范围？）。</p><p>对于 $E$ 同样处理，即 word <code>j</code> 作为答案 end 的得分为 $E\cdot T_j$。于是，word <code>i</code> 和 word <code>j</code> 构成一个答案 span 的得分为 $S \cdot T_i+E\cdot T_j$，具有最大得分的 word pair，且 $j \ge i$ 就是最终预测的答案 span。</p><p>训练的目标函数是正确的 start 和 end 的对数似然之和，即最大化下式的值（梯度上升）</p><script type="math/tex; mode=display">\log (P_s \cdot P_e)=\log P_s + \log P_e \tag{2}</script><p>其中 $s, \ e$ 分别是 gt start 和 gt end 的下标。</p><p>fine-tune <code>3</code> 个 epoch，<code>batch_size=32</code>，学习率为 $5e-5$。</p><h2 id="3-3-SQuAD-v2-0"><a href="#3-3-SQuAD-v2-0" class="headerlink" title="3.3 SQuAD v2.0"></a>3.3 SQuAD v2.0</h2><p>SQuAD v2.0 任务是对 SQuAD v1.0 的扩展，使得对应的段落中有可能不存在答案，这更加接近现实。</p><p>若段落中没有问题的答案，那么答案的 start 和 end 均在 <code>[CLS]</code> 这一位置，于是答案 start 和 end 的概率空间需要包含 <code>[CLS]</code> 的位置。</p><p>预测时，gt 对应的得分为 $s_{null}=S\cdot C+E\cdot C$，其中 $C$ 是 <code>[CLS]</code> 对应的最后一个 Transformer block 的输出特征向量，同时计算出最佳 non-null 的得分 $\hat s_{ij}=\max_{j \ge i} S\cdot T_i+E\cdot T_j$，那么当 </p><script type="math/tex; mode=display">\hat s_{ij} > s_{null}+\tau</script><p>时，预测为这个最佳 non-null 的答案 span，否则，预测为 null 答案（即不存在答案）。这里 $\tau$ 给出几个值，选择其中某个值使得 F1 最大。增加 $\tau$ 这个阈值是为了使预测更加准确。</p><p>训练阶段，依然使用 (2) 式进行训练，其中没有答案的情况下， gt label $s, \ e$ 均为 <code>[CLS]</code> 的位置。（1）式中分母的求和项，也需要包含 <code>[CLS]</code> 的得分。</p><h2 id="3-4-SWAG"><a href="#3-4-SWAG" class="headerlink" title="3.4 SWAG"></a>3.4 SWAG</h2><p>SWAG 数据集介绍：</p><p>给定一个部分描述，例如 “她打开汽车引擎盖”，那我们可以想到下一个场景可能是 “然后她检查了引擎”。SWAG 就是用于常识性推断这样一类任务的数据集，包含 113k 的问题描述，每个问题有四个选项，任务就是从中选择一个可能下个场景出现的。</p><p>在 SWAG 上 fine-tune  BERT 时，构造一个四输入序列，每个序列包含问题（序列A）和选项（序列B），对应的 Transformer 输入 Tensor 的 shape 为 <code>(batch_size, 4, max_length, embedding_dim)</code>，输出 Tensor 的 shape 为 <code>(batch_size, 4, max_length, H)</code>，其中 $H$ 就是上文所提的模型宽度，四个序列的 <code>[CLS]</code> token 对应的输出向量分别乘以一个权重向量（这就是任务相关的额外添加的 fc 层），得到这四个序列的得分，然后使用 softmax 进行分类。</p><p>训练 <code>3</code> 个 epoch，学习率为 $2e-5$，<code>batch_size=16</code>。</p><p>每个数据集上 BERT 与其他 models 的性能，详见论文，这里不再说明。</p>]]></content>
      
      
      
        <tags>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EfficientDet 论文总结</title>
      <link href="/2022/03/04/obj_det/efficient_det/"/>
      <url>/2022/03/04/obj_det/efficient_det/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a></p><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>之前的目标检测模型要么高效（例如 one-stage 和 anchor-free），要么高准确率，但是二者无法兼得。EfficientDet 旨在寻求一种可 scalable 目标检测框架，使得能同时兼顾高效和高准确率。</p><p>论文从 backbone，特征融合以及 分类/box network 等角度重新审视，并总结两点结论：</p><ol><li><p>高效的多尺度特征融合</p><p> 本文指出，FPN 自从问世被广泛应用，然而只是简单地将不同尺度的特征相加进行融合，这种融合不太妥。为了更好地的融合不同尺度的特征，本文提出一种高效的带权重双向 FPN，简称 BiFPN，这里的权重参数是可学习的。</p></li><li><p>模型缩放</p><p> 对网络（包括 backbone，feature networ，以及 box/class network）的 <code>resolution/depth/width</code> 进行缩放。 （模型缩放的思想在之前已经被提出）</p></li></ol><p>backbone 采用图像分类网络 EfficentNets，然后结合 BiFPN 以及 model scaling，这就是 EfficientDet 的主要思路。</p><blockquote><p>EfficientDet 是 one-stage detector。</p></blockquote><h1 id="2-BiFPN"><a href="#2-BiFPN" class="headerlink" title="2. BiFPN"></a>2. BiFPN</h1><h2 id="2-1-跨尺度融合"><a href="#2-1-跨尺度融合" class="headerlink" title="2.1 跨尺度融合"></a>2.1 跨尺度融合</h2><p>如何融合不同尺度的特征？</p><p>如图 1，不同的模型其融合方式也不同。</p><p><img src="/images/obj_det/efficientdet_1.png" alt=""></p><center>图 1. 几种网络的特征融合方式</center><p>记 $P_i^{in}, \ P_i^{out}$ 分别为第 <code>i</code> 层融合前后的特征，那么对于 FPN，有</p><script type="math/tex; mode=display">\begin{aligned}P_7^{out}&=Cov(P_7^{in})\\ P_6^{out}&=Cov(P_6^{in}+Resize(P_7^{in}))\\ \ldots\\ P_3^{out}&=Cov(P_3^{in}+Resize(P_4^{in}))\end{aligned}</script><p>FPN 的融合信息流是单向的，即从上到下，PANET 则实现了融合信息的双向流动。NAS-FPN 则进一步地使用 neural architecture search（NAS）搜索出较好的跨尺度信息融合方式，不过 NAS 对硬件要求（GPU）较高，而且搜索出来的网络结果不规则，难以对其进行解释或者调整。</p><p>作者比较发现：PANET 有更高的准确率，然而其参数量和计算量也更高，于是提出几点优化：</p><ol><li><p>去掉只有一个输入的节点。</p><p> PANET 中，去掉 <code>P7</code> 这一层的中间节点，以及 <code>P3</code> 层的最右端节点。这么做的原因很简单：这里是进行特征融合的网络，如果一个节点的输入没有进行特征融合，那么没有存在的必要。</p></li><li><p>增加一条 edge，从原始节点到特征融合的输出节点，目的是为了融合更多特征。</p></li><li><p>多次进行这种融合 （top-down &amp; bottom-up），即多次堆叠这种融合，以实现更高水平的特征融合。</p></li></ol><h2 id="2-2-带权特征融合"><a href="#2-2-带权特征融合" class="headerlink" title="2.2 带权特征融合"></a>2.2 带权特征融合</h2><p>用于融合的特征具有不同的尺度，其对融合的贡献不应该相同，于是作者提出带权重的特征融合，权重是可学习的参数。</p><p>考虑一下三种带权融合：</p><p><strong>Unbounded fusion</strong></p><script type="math/tex; mode=display">O=\sum_i w_i \cdot I_i</script><p>其中 $w_i$ 可以是一个 scalar，表示一个特征一个权重，也可以是一个 vector，表示特征的各通道的权重，也可以是一个 tensor，表示特征的每个 pixel 对应一个权重。</p><p><strong>Softmax-based fusion</strong></p><script type="math/tex; mode=display">O=\sum_i \frac {e^{w_i}}{\sum_j e^{w_j}} \cdot I_i</script><p>每个特征 $I_i$ 对应一个参数 $w_i$，使用 softmax 得到归一化权重，从而避免了 Unbounded fusion 会造成训练不稳定的缺点，但是 Softmax-based fusion 也有缺点，即降低 GPU 的计算速度。</p><p><strong>Fast normalized fusion</strong></p>]]></content>
      
      
      <categories>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow 中数据集构建</title>
      <link href="/2022/02/25/tensorflow/dataset/"/>
      <url>/2022/02/25/tensorflow/dataset/</url>
      
        <content type="html"><![CDATA[<h1 id="1-建立数据集"><a href="#1-建立数据集" class="headerlink" title="1. 建立数据集"></a>1. 建立数据集</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>返回 <code>tf.data.Dataset</code> 类对象。</p><p>适用于数据量较小的情况。例如装载 MNIST，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> train_label<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>mnist_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> train_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> img<span class="token punctuation">,</span> lbl <span class="token keyword">in</span> mnist_dataset<span class="token punctuation">:</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意，<code>train_data</code> 和 <code>train_label</code> 的第 <code>0</code> 维大小必须相同。</p><h2 id="1-1-TFRecord"><a href="#1-1-TFRecord" class="headerlink" title="1.1 TFRecord"></a>1.1 TFRecord</h2><p>对于较大的数据集，则不能通过 <code>tf.data.Dataset.from_tensor_slices()</code> 来构建数据集，而是借助 <code>TFRecord</code> 来处理。</p><p><code>TFRecord</code> 为 TensorFlow 中数据集存储格式，如下<br><pre class="line-numbers language-py" data-language="py"><code class="language-py"><span class="token punctuation">[</span>    <span class="token punctuation">&#123;</span>   <span class="token comment"># example 1 (tf.train.Example)</span>        <span class="token string">'feature_1'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Feature<span class="token punctuation">,</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token string">'feature_k'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Feature    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">&#123;</span>   <span class="token comment"># example N (tf.train.Example)</span>        <span class="token string">'feature_1'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Feature<span class="token punctuation">,</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token string">'feature_k'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Feature    <span class="token punctuation">&#125;</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><code>TFRecord</code> 是一个 <code>tf.train.Example</code> 组成的 list，每个 <code>tf.train.Example</code> 对象包含若干个 feature。</p><p><strong>将数据集存储为 TFRecord</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 猫狗分类</span>data_dir <span class="token operator">=</span> <span class="token string">'C:/datasets/cats_vs_dogs'</span>train_cats_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/train/cats'</span>   <span class="token comment"># 猫图片目录</span>train_dogs_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/train/dogs'</span>   <span class="token comment"># 狗图片目录</span>tfrecord_file <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'train/train.tfrecords'</span>train_cat_filenames <span class="token operator">=</span> <span class="token punctuation">[</span>train_cats_dir <span class="token operator">+</span> filename <span class="token keyword">for</span> filename <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>train_cats_dir<span class="token punctuation">)</span><span class="token punctuation">]</span>train_dog_filenames <span class="token operator">=</span> <span class="token punctuation">[</span>train_dogs_dir <span class="token operator">+</span> filename <span class="token keyword">for</span> filename <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>train_dogs_dir<span class="token punctuation">)</span><span class="token punctuation">]</span>train_filenames <span class="token operator">=</span> train_cat_filenames <span class="token operator">+</span> train_dog_filenamestrain_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_cat_filenames<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dog_filenames<span class="token punctuation">)</span><span class="token keyword">with</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>TFRecordWriter<span class="token punctuation">(</span>tfrecord_file<span class="token punctuation">)</span> <span class="token keyword">as</span> writer<span class="token punctuation">:</span>    <span class="token keyword">for</span> filename<span class="token punctuation">,</span> label <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>train_filenames<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>        image <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>        feature <span class="token operator">=</span> <span class="token punctuation">&#123;</span>            <span class="token string">'image'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Feature<span class="token punctuation">(</span>bytes_list<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>BytesList<span class="token punctuation">(</span>value<span class="token operator">=</span><span class="token punctuation">[</span>image<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'label'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Feature<span class="token punctuation">(</span>int64_list<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>BytesList<span class="token punctuation">(</span>value<span class="token operator">=</span><span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">&#125;</span>        example <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Example<span class="token punctuation">(</span>features<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Features<span class="token punctuation">(</span>feature<span class="token operator">=</span>feature<span class="token punctuation">)</span><span class="token punctuation">)</span>        writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>example<span class="token punctuation">.</span>SerializeToString<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>读取 TFRecord</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">raw_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TFRecordDataset<span class="token punctuation">(</span>tfrecord_file<span class="token punctuation">)</span>feature_description <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'image'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FixedLenFeature<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>string<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token string">'label'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FixedLenFeature<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span class="token keyword">def</span> <span class="token function">_parse_example</span><span class="token punctuation">(</span>example_string<span class="token punctuation">)</span><span class="token punctuation">:</span>    feature_dict <span class="token operator">=</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>parse_single_example<span class="token punctuation">(</span>example_string<span class="token punctuation">,</span> feature_description<span class="token punctuation">)</span>    feature_dict<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span> <span class="token operator">=</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>decode_jpeg<span class="token punctuation">(</span>feature_dict<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> feature_dict<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> feature_dict<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>dataset <span class="token operator">=</span> raw_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>_parse_example<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>返回的 <code>dataset</code> 是 <code>tf.data.Dataset</code> 实例。</p><h2 id="1-2-预处理"><a href="#1-2-预处理" class="headerlink" title="1.2 预处理"></a>1.2 预处理</h2><p><strong>shuffle</strong></p><p>打乱数据集，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">shuffle</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> buffer_size<span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reshuffle_each_iteration<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>其中 <code>buffer_size</code> 指定缓冲区大小。</p><p>洗牌原理：</p><ol><li>取前 <code>buffer_size</code> 大小的数据样本，添加到缓冲区</li><li>随机选取其中一个样本，作为第 <code>t=1</code> 个样本，并从缓冲区中移除这个样本</li><li>从缓冲区以外的数据中取一个样本填充到缓冲区中被移除样本的位置。</li><li>重复这样的操作，直到没有新样本填充到缓冲区，此时依次输出缓冲区样本</li></ol><p>使用示例：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span>dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>as_numpy_iterator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>batch</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">batch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> drop_reminder<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_parallel_calls<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>          deterministic<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>将数据集分批迭代（而非单个样本迭代）。</p><p>参数说明：</p><ol><li><p><code>batch_size</code>: 批大小。样本数据在第 <code>0</code> 维度上进行 stack（非 concatenate，注意区别），如果样本数据是 <code>(x,y)</code> 的元组形式，那么分别对 <code>x</code> 和 <code>y</code> 进行 stack，得到的依然是形如 <code>(x,y)</code> 的元组。</p></li><li><p><code>drop_remainder</code>：是否丢弃最后不足 <code>batch_size</code> 的样本。</p></li><li><p><code>num_parallel_calls</code>：指定需要并行计算的 batch 数量。</p></li><li><p><code>deterministic</code>：并行计算时产生 batch 的顺序是否确定？</p></li></ol><p><strong>prefetch</strong></p><p>此方法在 GPU 计算的时候预加载下一 batch 的数据，从而充分利用计算资源。使用示例，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">mnist_dataset <span class="token operator">=</span> mnist_dataset<span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>AUTOTUNE<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>完整示例：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">import</span> osnum_epochs <span class="token operator">=</span> <span class="token number">10</span>batch_size <span class="token operator">=</span> <span class="token number">32</span>learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>data_dir <span class="token operator">=</span> <span class="token string">'C:/datasets/cats_vs_dogs'</span>train_cats_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/train/cats/'</span>train_dogs_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/train/dogs/'</span>test_cats_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/valid/cats/'</span>test_dogs_dir <span class="token operator">=</span> data_dir <span class="token operator">+</span> <span class="token string">'/valid/dogs/'</span><span class="token keyword">def</span> <span class="token function">_decode_and_resize</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>    image_string <span class="token operator">=</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_file<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>            <span class="token comment"># 读取原始文件</span>    image_decoded <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>decode_jpeg<span class="token punctuation">(</span>image_string<span class="token punctuation">)</span>  <span class="token comment"># 解码JPEG图片</span>    image_resized <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>image_decoded<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span>    <span class="token keyword">return</span> image_resized<span class="token punctuation">,</span> label<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token comment"># 构建训练数据集</span>    train_cat_filenames <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span>train_cats_dir <span class="token operator">+</span> filename <span class="token keyword">for</span> filename <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>train_cats_dir<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    train_dog_filenames <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span>train_dogs_dir <span class="token operator">+</span> filename <span class="token keyword">for</span> filename <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>train_dogs_dir<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    train_filenames <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>train_cat_filenames<span class="token punctuation">,</span> train_dog_filenames<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    train_labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>        tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>train_cat_filenames<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">,</span>         tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>train_dog_filenames<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    train_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>train_filenames<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>    train_dataset <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>        map_func<span class="token operator">=</span>_decode_and_resize<span class="token punctuation">,</span>         num_parallel_calls<span class="token operator">=</span>tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>AUTOTUNE<span class="token punctuation">)</span>    <span class="token comment"># 取出前buffer_size个数据放入buffer，并从其中随机采样，采样后的数据用后续数据替换</span>    train_dataset <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span><span class="token number">23000</span><span class="token punctuation">)</span>        train_dataset <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>    train_dataset <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>AUTOTUNE<span class="token punctuation">)</span>    model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>        optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">,</span>        loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>sparse_categorical_crossentropy<span class="token punctuation">,</span>        metrics<span class="token operator">=</span><span class="token punctuation">[</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>sparse_categorical_accuracy<span class="token punctuation">]</span>    <span class="token punctuation">)</span>    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>ref</li></ol><p>本文示例代码来源 <a href="https://tf.wiki/zh_hans/basic/tools.html">tf.wiki/zh_hans</a></p>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于卷积网络的中文分词</title>
      <link href="/2022/02/22/nlp/conv_cws/"/>
      <url>/2022/02/22/nlp/conv_cws/</url>
      
        <content type="html"><![CDATA[<h1 id="1-ConvCWS"><a href="#1-ConvCWS" class="headerlink" title="1. ConvCWS"></a>1. ConvCWS</h1><p>论文：<a href="https://arxiv.org/abs/1711.04411">Convolutional Neural Network with Word Embeddings for Chinese Word Segmentation</a></p><p>将中文分词看作 sequence labaling 任务，例如</p><pre class="line-numbers language-none"><code class="language-none">S   S   B   E  B   M   E   S我  有  一  台  计  算  机  。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="1-1-网络框架"><a href="#1-1-网络框架" class="headerlink" title="1.1 网络框架"></a>1.1 网络框架</h2><h3 id="1-1-1-卷积网络"><a href="#1-1-1-卷积网络" class="headerlink" title="1.1.1 卷积网络"></a>1.1.1 卷积网络</h3><ol><li><p>embedding</p><p> 一个句子中各字符通过 embedding，即需要一个映射表 $M_c \in \mathbb R^{V \times d}$，其中 $V$ 为字符集大小，$d$ 为 embedding 维度，假设一个句子长度为 $L$，那么 embedding 后得到 $X \in \mathbb R^{L \times d}$。</p></li><li><p>堆叠 conv layer</p><p> 如图 1 所示，</p><p> <img src="/images/nlp/convcws_1.png" alt=""></p><p> 图 1.</p><p> conv layer 的输入 channel 为 $N$，输出 channel 为 $M$，输入序列长度为 $L$，kernel size 为 $k$（一维，与图像处理中的二维 kernel 不同），图 1 所示 conv layer 的变换如下，</p><script type="math/tex; mode=display">F(X)=(X\star W+b) \otimes \sigma(X\star V+c) \tag{1}</script><p> 两组 filters，第一组 $W \in \mathbb R^{k \times N \times M}, \ b \in \mathbb R^M$，第二组 $V \in \mathbb R^{k \times N \times M}, \ c \in \mathbb R^M$，输入 $X \in \mathbb R^{L \times N}$，$\sigma$ 为 sigmoid 函数，$\otimes$ 表示按位乘。输出 $F(X) \in \mathbb R^{L \times M}$，即需要对 $X$ 进行 padding（图 1 中未进行 padding）。</p><p> 没有 pooling 层，持续堆叠 conv layer 以获得长距信息。</p></li><li><p>线性变换</p><p> 在 conv layers 最上层，增加一个 linear layer，将 conv  block 的最终输出（$\in \mathbb R^{L \times M}$）转变为非归一化分类得分 $E \in \mathbb R^{L \times C}$ ，其中 $C$ 为分类数量。</p></li></ol><h3 id="1-1-2-CRF"><a href="#1-1-2-CRF" class="headerlink" title="1.1.2 CRF"></a>1.1.2 CRF</h3><p>考虑使用 CRF 来预测 label 序列。</p><p>定义 label 序列 $y =(y_1,\ldots, y_L)$ 的得分为</p><script type="math/tex; mode=display">s(S, y)=\sum_{i=1}^L E_{i,y_i}+\sum_{i=1}^{L-1} T_{y_i, y_{i+1}} \tag{2}</script><p>其中 $S=(c_1,\ldots, c_L)$ 表示字符序列（一个句子），$E$ 是前面卷积网络的输出得分，$T\in \mathbb R^{C\times C}$ 是状态转移矩阵（非归一化概率）。</p><p>label 序列的后验概率为</p><script type="math/tex; mode=display">p(y|S)=\frac {\exp s(S,y)} {\sum_{y'} \exp s(S,y')} \tag{3}</script><blockquote><p>增加一个 layer，输入为上一节 convnet 的输出得分 $E$，输出为后验概率</p></blockquote><p><strong>损失</strong>：负对数似然</p><script type="math/tex; mode=display">\mathcal L(S,y)=-\log p(y|S) \tag{4}</script><p><strong>训练</strong>阶段，采用反向传播，更新得到所有 layer 的参数，包括卷积参数和 CRF 状态转移矩阵。</p><p><strong>测试</strong>阶段，求</p><script type="math/tex; mode=display">\max_y p(y|S)=\max_y p(S,y)</script><p>卷积网络依然是执行一次，得到输出得分 $E$ 后，采用 Viterbi 算法：</p><p>迭代公式为 </p><script type="math/tex; mode=display">\begin{aligned}\delta_t(j)&=\max_{i \in 1, \ldots, C} \Psi(j,i,x_t) \delta_{t-1} (i)\\&=\max_{i \in 1, \ldots, C} p(j|i)p(x_t|j) \delta_{t-1}(i)\\&=\max_{i \in 1, \ldots, C} \exp (T_{i,j}+E_{t,j})\end{aligned}</script><p>同时还得到</p><script type="math/tex; mode=display">y_{t-1}^{\star}(j)=\arg \max_{y_{t-1}} \delta_t(j)</script><p>初始条件为 $\delta_1(j)=\Psi(j,y_0,x_1)=p(x_t|j)=E_{1,j}$ （一共 $C$ 个初始条件）。</p><blockquote><p>注：上面 (2) 与标准 CRF 不同，没有考虑 $y_0\rightarrow y_1$ 的状态转移概率，故初始条件中省去了因子 $T_{0,j}$</p></blockquote><h1 id="1-2-词嵌入"><a href="#1-2-词嵌入" class="headerlink" title="1.2 词嵌入"></a>1.2 词嵌入</h1><p>利用词嵌入 word embeddings，即设计一个基于词而非字符的模型。</p><p>基于词的模型可以利用 char-level 和 word-level 的信息。</p><p>设计如下词特征：</p><script type="math/tex; mode=display">\begin{array}{c|l}\hlineLength       &     Features\\\hline1    &   c_i\\\hline2     &     c_{i-1}c_i & c_ic_{i+1}\\\hline3       &  c_{i-2}c_{i-1}c_i & c_{i-1}c_ic_{i+1} & c_ic_{i+1}c_{i+2}\\\hline4 & c_{i-3}c_{i-2}c_{i-1}c_i & c_{i-2}c_{i-1}c_ic_{i+1} \\& c_{i-1}c_ic_{i+1}c_{i+2} & c_ic_{i+1}c_{i+2}c_{i+3}\\\hline\end{array}</script><center>表 1.</center> <p>字符 $c_i$ 的最终 embedding 为 <code>11</code> 个 embedding 的 concatenation（<code>1</code> 个字符 embedding 和 <code>10</code> 个词 embedding）：</p><script type="math/tex; mode=display">\begin{aligned}R(c_i)=&M_c[c_i] \oplus \\&M_w[c_i] \oplus M_w[c_{i-1}c_i] \oplus \cdots \oplus \\&M_w[c_ic_{i+1}c_{c+2}c_{i+3}]\end{aligned} \tag{5}</script><p>由于中文词长度通常不超过 <code>4</code>，故上表中我们最大考虑 <code>4</code> 个字符的词特征。记字符集 size 为 $V$，那么特征空间 size 为 $O(V^4)$，显然这是非常耗费内存和计算资源的，一种缓解办法是：</p><p>整个过程如下：</p><ol><li>训练出一个 teacher 模型（例如前面基于字符的 CWS）</li><li>使用 teacher CWS 对 unlabel 数据集 $\mathcal D_{un}$ 进行分词</li><li>根据第 <code>2</code> 步的结果建立词集 $V_{word}$，其中低频(&lt;5)词均用 UNK 进行替代</li><li>使用 <code>word2vec</code> 工具训练词 embedding</li><li>训练 student 分词模型</li></ol><h1 id="1-3-实验"><a href="#1-3-实验" class="headerlink" title="1.3 实验"></a>1.3 实验</h1><p>bench-mark 数据集选用 PKU 和 MSR。unlabel 数据来自 Sogou 新闻。</p><p><strong>Dropout</strong></p><p>所有的 conv layer 和 embedding layer 均用上 dropout，dropout rate 固定为 <code>0.2</code>。（embedding layer 的输出就是 char embedding，对这个 embedding vector 进行 dropout，即向量中每个 element 按 <code>0.2</code> 的概率置 0）</p><p><strong>超参数</strong></p><p>两个数据集的实验中使用相同的超参数，如表 2 所示，</p><div class="table-container"><table><thead><tr><th>超参数</th><th>value</th></tr></thead><tbody><tr><td>char embedding 维度</td><td>200</td></tr><tr><td>word embedding 维度</td><td>50</td></tr><tr><td>conv layer 数量</td><td>5</td></tr><tr><td>conv layer 输出 channel</td><td>200</td></tr><tr><td>kernel size</td><td>3</td></tr><tr><td>dropout rate</td><td>0.2</td></tr></tbody></table></div><p>表 2</p><p><strong>预训练</strong></p><p>使用 word2vec 在 unlabel 数据上预训练得到 char embedding 和 word embedding，然后这些 embedding 在监督学习中被反向传播微调。具体地：</p><ol><li><p>基于字符的 CWS 模型</p><p> 将预训练 char embedding 作为 embedding layer 的 weight 初始值，对于新字符，使用一种合适的方法来初始化 embedding（例如高斯分布？）</p></li><li><p>基于词的 CWS 模型</p><p> 将 char embedding 和 word embedding 根据 (5) 式组合，然后作为 embedding layer 的 weight 初始值，新字符的 embedding 使用一种合适的方法来初始化 embedding（例如高斯分布？）</p></li></ol><p><strong>优化：</strong> 使用 Adam 优化方法，batch size 为 100，训练不超过 100 个 epoch。对所有 conv layer 使用 <a href="https://arxiv.org/abs/1602.07868">Weight 归一化</a> 以加速训练过程，Weight norm 也可以参考<a href="/2021/03/08/dl/norm">这篇文章</a> 。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CRF 算法</title>
      <link href="/2022/02/21/ml/CRF_algo/"/>
      <url>/2022/02/21/ml/CRF_algo/</url>
      
        <content type="html"><![CDATA[<p>本文讲述 CRF 算法实现部分。<br><span id="more"></span></p><h1 id="1-线性-CRF"><a href="#1-线性-CRF" class="headerlink" title="1 线性 CRF"></a>1 线性 CRF</h1><p>为简单起见，从线性 CRF （即输出变量 $y_t$ 之间是一阶连接 $y_{t-1} \rightarrow y_t$）开始讨论。</p><p>本文约定 $\mathbf x_{1:t}$ 表示子序列 $(x_1,\ldots, x_t)$ ，其余同。</p><p>既然 HMM 可能转化为线性 CRF，就从 HMM 的前后向算法和 Viterbi 算法开始讨论。</p><p>HMM 的联合概率分布可写为</p><script type="math/tex; mode=display">p(\mathbf x, \mathbf y)=\prod_t \Psi_t(y_t, y_{t-1}, x_t) \tag{1}</script><p>其中 $Z=1$，且 $\Psi_t(j,i,x):=p(y_t=j|y_{t-1}=i)p(x_t=x|y_t=j), \ t=1, 2, \ldots, T$。</p><p>以下讨论三个问题。</p><h3 id="1-1-推断"><a href="#1-1-推断" class="headerlink" title="1.1 推断"></a>1.1 推断</h3><p>推断是指计算 <strong>观察序列的概率 $p(\mathbf x)$</strong> 。</p><p>根据 (1) 式可得观察序列 $\mathbf x$ 的边缘概率为，</p><script type="math/tex; mode=display">\begin{aligned} p(\mathbf x)&=\sum_{\mathbf y} \prod_{t=1}^T \Psi_t(y_t, y_{t-1},x_t)\\ &=\sum_{y_T}\sum_{y_{T-1}} \Psi_T(y_T,y_{T-1},x_T) \sum_{y_{T-2}} \Psi_{T-1}(y_{T-1},y_{T-2},x_{T-1})\sum_{y_{T-3}}\cdots\end{aligned}</script><p><strong>前向算法</strong></p><script type="math/tex; mode=display">\alpha_t(j):=p(\mathbf x_{1:t}, y_t=j), \quad t=1,\ldots, T, j=1,\ldots, S \tag{2}</script><p>其中 $S$ 为隐变量 $y_t$ 的所有状态数量。</p><p>根据 (2) 式定义易知迭代公式为</p><script type="math/tex; mode=display">\alpha_t(j)=\sum_{i=1}^S \Psi_t(j,i,x_t) \alpha_{t-1}(i) \tag{3}</script><p>初始条件为</p><script type="math/tex; mode=display">\alpha_1(j)=\Psi_1(j,y_0,x_1)=p(j)\cdot p(x_t|j)</script><p>观测序列 $\mathbf x$ 的边缘概率为 </p><script type="math/tex; mode=display">p(\mathbf x)=\sum_{j=1}^S \alpha_T(j) \tag{4}</script><p><strong>后向算法</strong></p><script type="math/tex; mode=display">\beta_t(i):=p(\mathbf x_{t+1:T}, y_t=i) \tag{5}</script><p>迭代公式为</p><script type="math/tex; mode=display">\beta_t(i)=\sum_{j=1}^S \Psi_{t+1}(j, i, x_{t+1}) \beta_{t+1}(j) \tag{6}</script><p>初始条件为 $\beta_T(i)=1$ 。</p><p>观测序列 $\mathbf x$ 的边缘概率为 </p><script type="math/tex; mode=display">p(\mathbf x)=\beta_0(y_0):=\sum_{j=1}^S \Psi_1(j,y_0,x_1)\beta_1(j) \tag{7}</script><p>计算 $p(y_{t-1},y_t|\mathbf x)$，这在后面参数估计中会用到。</p><script type="math/tex; mode=display">\begin{aligned}p(y_{t-1},y_t|\mathbf x)&=\frac {p(\mathbf x,y_{t-1},y_t)}{p(\mathbf x)}\\&=\frac {p(\mathbf x_{1:t-1},y_{t-1})p(y_t|y_{t-1})p(x_t|y_t)p(\mathbf x_{t+1,T}, y_t)}{p(\mathbf x)}\\&=\frac 1 {p(\mathbf x)} \alpha_{t-1}(y_{t-1}) \Psi_t(y_t, y_{t-1},x_t) \beta_t(y_t)\end{aligned} \tag{7-1}</script><h2 id="1-2-解码"><a href="#1-2-解码" class="headerlink" title="1.2 解码"></a>1.2 解码</h2><p>给定一个新的观测序列 $\mathbf x$，求其最有可能的状态序列 $\mathbf y$ ，即</p><script type="math/tex; mode=display">\hat {\mathbf y}=\arg \max_{\mathbf y} \ p(\mathbf y|\mathbf x) = \arg \max_{\mathbf y} p(\mathbf x, \mathbf y)</script><p><strong>Viterbi 算法</strong></p><script type="math/tex; mode=display">\delta_t(j):=\max_{\mathbf y_{1:t-1}} \ p(\mathbf y_{1:t-1}, \mathbf x_{1:t}, y_t=j)</script><p>表示： 当前已经观察到序列 $\mathbf x_{1:t}$，且时刻 $t$ 的 label 为 $y_t=j$ 的概率，时刻 $t=1, \ldots, t-1$ 的 label 未知，求 $t=1,\ldots, t-1$ 的 label，使得这个部分观察序列的联合概率最大。</p><p>迭代公式为 </p><script type="math/tex; mode=display">\begin{aligned}\color{fuchsia} {\delta_t(j)}&=\max_{\mathbf y_{1:t-1}} p(\mathbf y_{1:t-1}, \mathbf x_{1:t}, y_t=j)\\&=\max_{i \in 1,\ldots, S} \Psi_t(j,i, x_t) \cdot \max_{\mathbf y_{1:t-2}} p(y_{1:t-2}, \mathbf x_{1:t-1}, y_{t-1}=i)\\&= \color{fuchsia} {\max_{i \in 1, \ldots, S} \Psi(j,i,x_t) \delta_{t-1} (i)}\end{aligned} \tag{8}</script><p>注意：这里使用的是类似于 HMM  的线性 CRF 结构。</p><p>同时还得到</p><script type="math/tex; mode=display">y_{t-1}^{\star}=\arg \max_{y_{t-1}} \delta_t(j) \tag{9}</script><p>初始条件为 $\delta_1(j)=\Psi(j,y_0,x_1)=p(y_1=j)p(x_t|j)$ （一共 $S$ 个初始条件）。</p><p>根据 (9) 式，每个时刻 $t, t&gt;1$，均可计算出上一时刻的最优状态 $y_{t-1}$。</p><p>最后迭代计算出 </p><script type="math/tex; mode=display">y_T = \arg \max_j = \delta_T(j)</script><p>然后将 $y_T$ 的值代入 (9) 式进行状态回溯，得到最优的状态序列 $\mathbf y$。</p><p><strong>扩展到线性 CRF</strong></p><p>将 HMM 扩展到线性 CRF 的一般形式，前后向算法和 Viterbi 算法形式与上面各式相同，只是 $\Psi_t(y_t, y_{t-1},x_t)$ 不一定是 HMM 中条件概率，而是更一般的势函数，</p><script type="math/tex; mode=display">\Psi_t(y_t, y_{t-1}, \mathbf x)=\exp \left(\sum_k \theta_k f_k(y_t, y_{t-1}, \mathbf x)\right)</script><p>联合概率为</p><script type="math/tex; mode=display">p(\mathbf x, \mathbf y)=\frac 1 Z \prod_{t=1}^T \Psi_t(y_t, y_{t-1},\mathbf x)</script><p>后验概率为 </p><script type="math/tex; mode=display">p(\mathbf y|\mathbf x)=\frac 1 {Z(\mathbf x)}\prod_{t=1}^T \Psi_t(y_t, y_{t-1},\mathbf x) \tag{10}</script><p>注意线性 CRF 中 $\alpha_t(j), \ \beta_t(i)$ 不再表示概率，且 $\sum_{j=1}^S \alpha_T(j)$ 也不表示 $p(\mathbf x)$ 而是 $Z(\mathbf x)$，即</p><script type="math/tex; mode=display">Z(\mathbf x)=\sum_{\mathbf y} \prod_{t=1}^T \Psi_t(y_t, y_{t-1}, \mathbf x)= \sum_{j=1}^S \alpha_T(j)=\beta_0(y_0)</script><script type="math/tex; mode=display">p(\mathbf x)=\sum_{\mathbf y} p(\mathbf x, \mathbf y)=\frac {Z(\mathbf x)}{Z}</script><p>特殊地，线性 CRF 为 HMM 时，有 $Z=1$，此时 $p(\mathbf x)=Z(\mathbf x)$ 。</p><h2 id="1-3-参数估计"><a href="#1-3-参数估计" class="headerlink" title="1.3 参数估计"></a>1.3 参数估计</h2><p>采用最大似然估计。</p><p>数据集 $\mathcal D=\{\mathbf x^{(i)}, \mathbf y^{(i)}\}_{i=1}^N$，其中 $\mathbf x^{(i)}=(\mathbf x_1^{(i)}, \ldots, \mathbf x_T^{(i)})$ 是输入序列，输出序列为 $\mathbf y^{(i)}=(y_1^{(i)}, \ldots, y_T^{(i)})$，序列长度 $T$ 不固定，即 $T_i$ 可变，但是下文为了表达简单，统一写成 $T$，不影响算法的理解和实现。</p><p>模型参数记为 $\theta=(\theta_1,\ldots, \theta_K)$，K 为特征函数数量。记对数条件似然为</p><script type="math/tex; mode=display">l(\theta)=\sum_{i=1}^N \log p(\mathbf y^{(i)}|\mathbf x^{(i)}; \theta) \tag{11}</script><p>我们要求参数的最大似然估计 $\theta_{ML} = \arg \max_{\theta} l(\theta)$ 。现在已知线性 CRF 的条件概率为 (10) 式，代入 (11) 式得，</p><script type="math/tex; mode=display">l(\theta)=\sum_{i=1}^N \sum_{t=1}^T \sum_{k=1}^K \theta_k f_k(y_t^{(i)}, y_{t-1}^{(i)}, \mathbf x_t^{(i)}) - \sum_{i=1}^N \log Z(\mathbf x^{(i)})</script><p>参数量 $K \ge S\times V+S^2$ （S 为状态数，V 为观测值的集合大小）非常大，可能达几十万，为了避免过拟合，使用 <strong>正则项</strong>，于是</p><script type="math/tex; mode=display">l(\theta)=\sum_{i=1}^N \sum_{t=1}^T \sum_{k=1}^K \theta_k f_k(y_t^{(i)}, y_{t-1}^{(i)}, \mathbf x_t^{(i)}) - \sum_{i=1}^N \log Z(\mathbf x^{(i)}) -\sum_{k=1}^K \frac {\theta_k^2}{2\sigma^2}\tag{12}</script><p>其中 $\sigma^2$ 是平衡因子，引入正则项等效于参数的 MAP （最大后验 ）估计。</p><p>由于</p><script type="math/tex; mode=display">\begin{aligned}Z(\mathbf x)&=\sum_{\mathbf y} \prod_t \Psi_t(y_t,y_{t-1}, \mathbf x_t)\\&=\sum_{\mathbf y}\prod_t \exp\left(\sum_k \theta_k f_k(y_t,y_{t-1}, \mathbf x_t)\right)\\&=\sum_{\mathbf y} \exp\left(\sum_t \sum_k \theta_k f_k(y_t,y_{t-1}, \mathbf x_t) \right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\frac 1 {Z(\mathbf x)}\frac {\partial Z(\mathbf x)}{\partial \theta_k}&=\frac 1 {Z(\mathbf x)}\sum_{\mathbf y}  \exp(\cdots) \left(\sum_t f_k(y_t,y_{t-1}, \mathbf x_t)\right)\\&=\sum_{\mathbf y} \frac 1 {Z(\mathbf x)} \prod_s \Psi_{s=1}^T (y_s,y_{s-1}, \mathbf x_s)  \left(\sum_t f_k(y_t,y_{t-1}, \mathbf x_t)\right)\\&=\sum_{\mathbf y} p(\mathbf y|\mathbf x) \left(\sum_t f_k(y_t,y_{t-1}, \mathbf x_t)\right)\\&=\sum_{y_t, y_{t-1}} p(y_t, y_{t-1}|\mathbf x)\left(\sum_t f_k(y_t,y_{t-1}, \mathbf x_t)\right)\\&=\sum_{i,j}\sum_t p(j, i|\mathbf x)f_k(j,i, \mathbf x_t)\end{aligned}</script><p>似然函数对参数求偏导，</p><script type="math/tex; mode=display">\begin{aligned} \frac {\partial l}{\partial \theta_k}=&\sum_{i=1}^N \sum_{t=1}^T f_k(y_t^{(i)},y_{t-1}^{(i)}, \mathbf x_t^{(i)})\\ &-\sum_{i=1}^N\sum_{t=1}^T \sum_{i,j} p(j, i|\mathbf x^{(i)})f_k(j,i, \mathbf x_t^{(i)})-\frac {\theta_k}{\sigma^2}\end{aligned} \tag{13}</script><p>(13) 式中第一项可看作 $f_k$ 在经验分布 $\tilde p(\mathbf x,\mathbf y)$ 下的期望，第二项为 $f_k$ 在分布 $p(\mathbf y|\mathbf x;\theta)\tilde p(\mathbf x)$ 下的期望。</p><p>(13) 式中含有 $p(j,i|\mathbf x)$，根据 (7) 和 (7-1) 式进行计算，令 (13) 式表示的梯度为 $\mathbf 0$，难以求得参数解析解，故考虑数值解即梯度上升法：</p><ol><li>初始化参数 $\theta^{(1)}$</li><li>根据 (13) 式计算的似然函数对参数的梯度，$\nabla_{\theta} l$</li><li>更新参数 $\theta^{(t+1)}=\theta^{(t)}+\alpha \nabla_{\theta}l$</li></ol><h1 id="2-通用-CRF"><a href="#2-通用-CRF" class="headerlink" title="2. 通用 CRF"></a>2. 通用 CRF</h1><p>$\mathbf y$ 内部连接不再是线性连接。最大团 index 集合记为 $F$，那么概率可写为</p><script type="math/tex; mode=display">p(\mathbf y)=Z^{-1} \prod_{a \in F} \Psi_a(\mathbf y_a) \tag{10}</script><p>近似计算方法包括 MCMC (Markov Chain Monte Carlo) 和 variational algorithms (Belief Propagation) 等。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>条件随机场</title>
      <link href="/2022/02/19/ml/CRF/"/>
      <url>/2022/02/19/ml/CRF/</url>
      
        <content type="html"><![CDATA[<p>本文整理条件随机场的相关知识。</p><span id="more"></span><p>前面 <a href="2022/02/14/ml/prob_model">概率模型</a> 一文中讲了概率图模型，包括有向图（贝叶斯网络）和无向图（Markov 随机场）。本文主要讲无向图模型中的条件随机场（CRF）。</p><h1 id="1-概率模型"><a href="#1-概率模型" class="headerlink" title="1. 概率模型"></a>1. 概率模型</h1><p><strong>无向图</strong></p><p>考虑一组随机变量 $\mathbf y=[y_1,\ldots, y_D]$，每个变量取值范围 $y_i \in \mathcal Y$，可以是连续型或离散型，但本文主要考虑离散型。无向图的联合概率可以根据最大团进行因子化分解，即</p><script type="math/tex; mode=display">p(\mathbf y)=\frac 1 Z \prod_{a=1}^A \Psi_a(\mathbf y_a) \tag{1}</script><p>其中，$a$ 是最大团的 index， $\Psi$ 是势函数，任意非负的函数均可，即 $\Psi_a(\mathbf y_a) \ge 0$。$A$ 表示最大团的数量 $A\le D$。$Z$ 用于归一化，且 <strong><font color="magenta">与 $\mathbf y$ 的取值无关</font></strong>，</p><script type="math/tex; mode=display">Z=\sum_{\mathbf y'} \prod_{a=1}^A \Psi_a(\mathbf y_a')</script><p>（如果 $\Psi_a(\mathbf y_a)$ 就取对应最大团的条件概率，那么 $Z=1$）</p><p><strong>有向图</strong></p><script type="math/tex; mode=display">p(\mathbf y)=\prod_{i=1}^D p(y_i|\mathbf y_{\pi(i)}) \tag{2}</script><p>其中 $\pi(i)$ 表示节点 $i$ 的父节点集合。上式表示联合概率可因式分解为每个节点的条件概率（以其所有父节点为条件）的乘积。</p><p><strong>输入输出</strong></p><p>输入变量 $\mathbf x$ 是可观察变量，输出变量 $\mathbf y$ 是隐变量，例如中文分词，中文句子就是 $\mathbf x$，每个字符的分类（例如 <code>B,M,E,S</code>）就是 $\mathbf y$。那么联合概率分布为</p><script type="math/tex; mode=display">p(\mathbf x,\mathbf y)=\frac 1 Z \prod_{a=1}^A \Psi_a(\mathbf x_a, \mathbf y_a) \tag{3}</script><p>其中归一化因子 </p><script type="math/tex; mode=display">Z=\sum_{\mathbf x, \mathbf y} \prod_a^A \Psi_a(\mathbf x_a, \mathbf y_a)</script><h1 id="2-生成模型-vs-判别模型"><a href="#2-生成模型-vs-判别模型" class="headerlink" title="2. 生成模型 vs 判别模型"></a>2. 生成模型 vs 判别模型</h1><p>生成模型描述了标签 $\mathbf y$ 如何概率地生成可观察变量 $\mathbf x$，判别模型则相反地，描述了如何将 $\mathbf x$ 关联到其标签 $\mathbf y$。通常来说，生成模型需要计算 $p(\mathbf x, \mathbf y)$，而判别模型计算 $p(\mathbf y|\mathbf x)$。</p><p>例如中文分词，给定句子 $\mathbf x^{\star}$ ，要得到每个字符的标签（<code>B,M,E,S</code> 中的一个）：</p><ol><li><p>生成模型</p><script type="math/tex; mode=display">\mathbf y^{\star}=\arg \max_{\mathbf y} p(\mathbf x^{\star}, \mathbf y) \tag{4}</script></li><li><p>判别模型</p><script type="math/tex; mode=display">\mathbf y^{\star}=\arg \max_{\mathbf y} p(\mathbf y|\mathbf x^{\star}) \tag{5}</script></li></ol><p>虽然通过贝叶斯定理，这两种计算方法可以相互转化，但是实际中我们还是对这两种方法进行区分。</p><p>下文生成模型记为 <code>G</code>，判别模型记为 <code>D</code>。</p><h2 id="2-1-分类"><a href="#2-1-分类" class="headerlink" title="2.1 分类"></a>2.1 分类</h2><p>给定特征向量 $\mathbf x=(x_1,\ldots,x_D)$，预测一个对应分类 $y$，</p><h3 id="2-1-1-生成模型"><a href="#2-1-1-生成模型" class="headerlink" title="2.1.1 生成模型"></a>2.1.1 生成模型</h3><blockquote><p>朴素贝叶斯假设：给定分类标签，各特征之间独立。</p></blockquote><p>联合概率分布</p><script type="math/tex; mode=display">p(y,\mathbf x)=p(y)\prod_{i=1}^D p(x_i|y) \tag{6}</script><p>概率图如下所示</p><pre class="mermaid">graph TBy((y))y --> x1((x1))y --> x2((...))y --> x4((xD))</pre><p><strong>应用例子：句子主题分类</strong></p><p>将句子分词，词对应 $x_i$，句子主题分类对应 $y$，$y \in \mathcal Y$，$|\mathcal Y|=C$，即一共 $C$ 个分类。给定一个数据集 $\{(\mathbf x_n, y_n)|n=1,\ldots, N\}$，</p><script type="math/tex; mode=display">p(y)=\frac {\sum_{n=1}^N \mathbf 1_{y_n=y}} {N} \tag{7-1}</script><script type="math/tex; mode=display">p(x_i|y)=\sum_{x_{nm}, y_n} \mathbf 1_{x_{nm}=x_i, y_n=y} /\sum_{x_{nm, y_n}} \mathbf 1_{y_n=y} \tag{8-1}</script><p>上式中，$\sum_{x_{nm},y_n}$ 表示将每个句子展开 $(\mathbf x_n,y_n) \rightarrow ((x_{n1}, y_n),\ldots, (x_{nD_n},y_n))$，得到所有的 $(x_{nm},y_n)$ pair。</p><p><strong>拉普拉斯平滑：</strong></p><p>有时候数据没有全面覆盖，导致 (7) 或 (8) 式计算为 <code>0</code>，此时需要进行拉普拉斯平滑处理：</p><script type="math/tex; mode=display">p(y)=\frac {1+\mathbf 1_{y_n=y}} {C+N} \tag{7-2}</script><p>当 $N \gg C$ 时，(7-2) 与 (7-1) 差别甚微。</p><p>当然通常情况下，数据集大小不会特别小，所有标签分类都能覆盖到的情况下，还是使用 (7-1) 进行计算标签分类的先验概率。</p><p>对于 (8-1) 式，我们需要事先知道词汇集 $V$，然后才能判断 pair $(x_i，y)$ 出现的频次，如果存在频次为 <code>0</code> 的 pair，那么则需要对 (8-1) 进行拉普拉斯平滑处理，</p><script type="math/tex; mode=display">p(x_i|y)=\left(1+\sum_{x_{nm}, y_n} \mathbf 1_{x_{nm}=x_i, y_n=y} \right)/\left(V+\sum_{x_{nm, y_n}} \mathbf 1_{y_n=y}\right) \tag{8-2}</script><p>其中 $V$ 表示词汇集大小（根据上下文很容易判别 $V$ 表示词汇集，还是词汇集大小）。</p><h3 id="2-1-2-判别模型"><a href="#2-1-2-判别模型" class="headerlink" title="2.1.2 判别模型"></a>2.1.2 判别模型</h3><blockquote><p>logistic 回归，又称 最大熵分类器 ME</p></blockquote><p>条件概率</p><script type="math/tex; mode=display">p(y|\mathbf x)=\frac 1 {Z(\mathbf x)} \exp \left(\theta_y+\sum_{i=1}^D \theta_{yi}x_i \right) \tag{9}</script><p>其中 $Z(\mathbf x)=\sum_y \exp(\theta_y+\sum_{i=1}^D \theta_{yi}x_i)$</p><p>将 (9) 式进行改写，</p><script type="math/tex; mode=display">p(y|\mathbf x)=\frac 1 {Z(\mathbf x)} \exp \left(\sum_{i=1}^D \theta_i f_i(y, \mathbf x)\right) \tag{10}</script><h2 id="2-2-序列模型"><a href="#2-2-序列模型" class="headerlink" title="2.2 序列模型"></a>2.2 序列模型</h2><p>输出是一个序列 $\mathbf y$ 而非单个值 $y$。</p><p>例如命名实体识别（NER）中，将一个句子先分词，每个词都是一个实体的一部分，例如 “李白” 是 <code>PERSON</code>，”纽约” 是 <code>LOCATION</code>，”清华大学” 是 <code>ORGANIZATION</code>，或者 “早上” 是 <code>OTHER</code>（表示这不属于实体的一部分）。</p><h3 id="2-2-1-HMM"><a href="#2-2-1-HMM" class="headerlink" title="2.2.1 HMM"></a>2.2.1 HMM</h3><p>HMM 属于生成模型，$\mathbf x$ 为可观测量（例如句子中的单词），$\mathbf y$ 为隐变量（例如单词的 label），联合概率为</p><script type="math/tex; mode=display">p(\mathbf x, \mathbf y)=p(\mathbf y)p(\mathbf x|\mathbf y)=\prod_{t=1}^T p(y_t|y_{t-1})p(x_t|y_t) \tag{11}</script><p>其中 $p(y_0)=1$，$p(y_1|y_0)=p(y_1)$。序列模型中 $\mathbf x$ 可看作是时序变量，下标通常用 $t$ 表示。HMM 概率图模型如下图所示，</p><pre class="mermaid">graph LRy1((y1)) --> y3((...)) --> yT((yT))x1((x1))y1 --> x1y3 --> x3((...))yT --> xT((xT))</pre><p>常见的生成模型与判别模型的关系如下图，</p><p><img src="/images/ml/CRF1.png" alt=""></p><h3 id="2-2-2-线性-CRF"><a href="#2-2-2-线性-CRF" class="headerlink" title="2.2.2 线性 CRF"></a>2.2.2 线性 CRF</h3><p>考虑 HMM 中联合概率 $p(\mathbf x, \mathbf y)$ 对应的条件概率 $p(\mathbf y|\mathbf x)$，此时将图中边的箭头去掉，从有向图变成对应的无向图。</p><p>将 (11) 式改写如下</p><script type="math/tex; mode=display">p(\mathbf x,\mathbf y)=\frac 1 Z \prod_{t=1}^T \exp \left(\sum_{i,j \in S} \theta_{ij} \mathbf 1_{y_t=j}\mathbf 1_{y_{t-1}=i}+ \sum_{j \in S, o \in O} \mu_{jo} \mathbf 1_{y_t=j} \mathbf 1_{x_t=o} \right) \tag{12}</script><p>其中 $\exp(\cdot)$ 的第一项对应 $p(y_t|y_{t-1})$，第二项对应 $p(x_t|y_t)$。</p><p>特殊地，如果 $\theta_{ij}=\log p(y_t|y_{t-1})$，$\mu_{jo}=\log p(x_t|y_t)$，那么 $Z=1$。</p><p>引入特征方程，进一步简化 (11) 式，每个特征方程具有形式 $f_k(y_t,y_{t-1}, x_t)$，</p><script type="math/tex; mode=display">p(\mathbf x, \mathbf y)=\frac 1 Z \prod_{t=1}^T \exp \left(\sum_{k=1}^K \theta_k f_k(y_t, y_{t-1},x_t)\right) \tag{13}</script><p>于是得到 HMM 对应的线性 CRF 的条件概率为</p><script type="math/tex; mode=display">p(\mathbf y|\mathbf x)=\frac {p(\mathbf x, \mathbf y)}{\sum_{\mathbf y'}p(\mathbf x, \mathbf y')}=\frac {\prod_{t=1}^T \exp \left(\sum_{k=1}^K \theta_k f_k(y_t, y_{t-1},x_t)\right)}{\sum_{\mathbf y'}\prod_{t=1}^T \exp \left(\sum_{k=1}^K \theta_k f_k(y_t', y_{t-1}',x_t)\right)} \tag{14}</script><p>如果每个时刻的输入是多维变量 $\mathbf x_t \in \mathbb R^D$（D-维输入特征），那么线性 CRF 为</p><script type="math/tex; mode=display">p(\mathbf y|\mathbf x) =\frac 1 {Z(\mathbf x)} \prod_{t=1}^T \Psi_t(y_t,y_{t-1},\mathbf x_t) \tag{15}</script><p>其中 $\mathbf x \in \mathbb R^{T \times D}$，归一化因子 $Z(\mathbf x)=\sum_{\mathbf y’} \prod_{t=1}^T \Psi_t(y_t,y_{t-1},\mathbf x_t)$，且</p><script type="math/tex; mode=display">\Psi_t(y_t,y_{t-1},\mathbf x_t)=\exp \left(\sum_{k=1}^K \theta_k f_k(y_t, y_{t-1},x_t)\right)</script><p>称为 local function（最大团势函数）。</p><p>线性 CRF 概率图如下图所示，</p><p><img src="/images/ml/CRF2.png" alt=""></p><p>HMM 中下一时刻的状态仅与当前时刻的状态相关，在 CRF 中我们还可以增加特征：下一时刻状态与当前输入 $\mathbf x_{t-1}$ 也相关，即特征方程</p><script type="math/tex; mode=display">f_k(y_t, y_{t-1}, x_{t-1})=\mathbf 1_{y_t=j}\mathbf 1_{y_{t-1}=i} \mathbf 1_{x_{t-1}=o}</script><p>相关概率图如下所示</p><p><img src="/images/ml/CRF3.png" alt=""></p><p>还可以进一步泛化为状态依赖全局输入，如下图</p><p><img src="/images/ml/CRF4.png" alt=""></p><h2 id="2-2-3-泛化-CRF"><a href="#2-2-3-泛化-CRF" class="headerlink" title="2.2.3 泛化 CRF"></a>2.2.3 泛化 CRF</h2><p>根据最大团进行因式分解联合概率，</p><script type="math/tex; mode=display">p(\mathbf y|\mathbf x)=\frac 1 {Z(\mathbf x)} \prod_{a=1}^A \Psi_a(\mathbf y_a, \mathbf x_a) \tag{16}</script><p>其中 $a$ 是最大团的 index，最大团数量为 $A$，$\Psi_a \ge 0$ 是势函数，$\mathbf x_a, \mathbf y_a$ 是最大团 $a$ 中的节点集合。</p><p>特殊地，线性 CRF 指 $\mathbf y$ 各节点线性连接，即一阶 pair $(y_{t-1}, y_t)$，此时最大团 $\Psi(\mathbf y_a, \mathbf x_a)$ 为 $\Psi_t (y_t, y_{t-1},\mathbf x)$，有 $T$ 个最大团。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PCA的概率模型</title>
      <link href="/2022/02/16/ml/PPCA/"/>
      <url>/2022/02/16/ml/PPCA/</url>
      
        <content type="html"><![CDATA[<p>本文从概率角度理解 PCA。<br><span id="more"></span></p><h1 id="1-生成过程和概率模型"><a href="#1-生成过程和概率模型" class="headerlink" title="1. 生成过程和概率模型"></a>1. 生成过程和概率模型</h1><p>假设有隐变量 $\mathbf z \in \mathbb R^M$，其先验分布为标准正态分布 $p(\mathbf z)=\mathcal N(\mathbf 0, I)$。可观察变量 $\mathbf x$ 与隐变量 $\mathbf z$ 满足一个线性关系</p><script type="math/tex; mode=display">\mathbf x=B\mathbf z+\boldsymbol \mu + \boldsymbol \epsilon \in \mathbb R^D \tag{1}</script><p>其中 $\boldsymbol \epsilon \sim \mathcal N(\mathbf 0, \sigma^2I)$ 是一个高斯噪声。转换矩阵 $B \in \mathbb R^{D \times M}$，$\boldsymbol \mu \in \mathbb R^D$ 是一个偏移（实现仿射变换），$\mathbf x$ 的概率分布为</p><script type="math/tex; mode=display">p(\mathbf x|\mathbf z, B, \boldsymbol \mu, \sigma^2)=\mathcal N(\mathbf x|B\mathbf z+\boldsymbol \mu, \sigma^2I) \tag{2}</script><p>数据生成过程/步骤：</p><ol><li>随机生成 $\mathbf z_n$</li><li>根据 $\mathbf z_n$ 随机生成数据 $\mathbf x_n \sim p(\mathbf x|\mathbf z_n, B, \boldsymbol \mu, \sigma^2)$</li></ol><p>于是有</p><script type="math/tex; mode=display">p(\mathbf x,\mathbf z|B, \boldsymbol \mu, \sigma^2)=p(\mathbf x|\mathbf z, B, \boldsymbol \mu, \sigma^2) p(\mathbf z) \tag{3}</script><p>$\mathbf z$ 就是数据 $\mathbf x$ 在低维空间的表示，根据数据集我们可以学习得到 $\mathbf z$ 的分布，每次随机生成 $\mathbf z$ 后，使用 (1) 式将 $\mathbf z$ 恢复到原空间中。</p><h2 id="1-1-似然和联合分布"><a href="#1-1-似然和联合分布" class="headerlink" title="1.1 似然和联合分布"></a>1.1 似然和联合分布</h2><p>数据的似然概率为 </p><script type="math/tex; mode=display">p(\mathbf x|B,\boldsymbol \mu, \sigma^2)=\int p(\mathbf x|\mathbf z, B, \boldsymbol \mu, \sigma^2) p(\mathbf z) d \mathbf z\\=\int \mathcal N(\mathbf x|B\mathbf z+\boldsymbol \mu, \sigma^2I)\mathcal N(\mathbf z|\mathbf 0,I)d\mathbf z \tag{4}</script><p>根据期望的线性性质得数据的期望</p><script type="math/tex; mode=display">\mathbb E_{\mathbf x}[\mathbf x]=\mathbb E_{\mathbf z}[B\mathbf z+\boldsymbol \mu] + \mathbb E_{\boldsymbol \epsilon}[\boldsymbol \epsilon]=\boldsymbol \mu</script><p>协方差矩阵为</p><script type="math/tex; mode=display">\mathbb V[\mathbf x]=\mathbb V_{\mathbf z}[B\mathbf z+\boldsymbol \mu] + \mathbb V_{\boldsymbol \epsilon}[\boldsymbol \epsilon]=\mathbb V_{\mathbf z}[B\mathbf z] + \sigma^2I\\=B \mathbb V_{\mathbf z}[\mathbf z] B^{\top} + \sigma^2I=BB^{\top}+\sigma^2I</script><p>上式推导中，第一个等式成立是因为 $\mathbf z$ 与 $\boldsymbol \epsilon$ 独立，第二个等式成立是因为 $\boldsymbol \mu$ 是常量。</p><p>根据概率论相关知识，高斯随机变量 $\mathbf z$ 的线性变换仍然是高斯分布，而 $\mathbf x$ 的期望和方差由上面两式给出，故 $\mathbf x$ 的分布为</p><script type="math/tex; mode=display">p(\mathbf x|B,\boldsymbol \mu, \sigma^2)=\mathcal N(\mathbf x|\boldsymbol \mu, BB^{\top}+\sigma^2I) \tag{5}</script><p>而 $\mathbf x$ 与 $\mathbf z$ 之间的交叉协方差为</p><script type="math/tex; mode=display">\begin{aligned}\text{Cov}[\mathbf x,\mathbf z]&=\text{Cov}[B\mathbf z+\boldsymbol \mu + \boldsymbol \epsilon, \mathbf z]\\&=\text{Cov}[B\mathbf z, \mathbf z] + \text{Cov}[\boldsymbol \mu, \mathbf z]+ \text{Cov}[\boldsymbol \epsilon, \mathbf z]\\&=B \text{Cov}[\mathbf z,\mathbf z]\\&=B\end{aligned}</script><p>$\mathbf x$ 和 $\mathbf z$ 的联合概率也是高斯型，故联合概率为</p><script type="math/tex; mode=display">p(\mathbf x,\mathbf z|B,\boldsymbol \mu, \sigma^2)=\mathcal N \left(\begin{bmatrix}\mathbf x \\ \mathbf z\end{bmatrix}| \begin{bmatrix}\boldsymbol \mu \\ \mathbf 0\end{bmatrix}, \begin{bmatrix}BB^{\top}+\sigma^2I & B \\ B^{\top} & I\end{bmatrix}\right) \tag{6}</script><p>利用 (6) 式的联合概率分布，可以计算 $\mathbf z$ 后验分布，显然这也是一个高斯型分布，</p><script type="math/tex; mode=display">p(\mathbf z|\mathbf x)=\mathcal N(\mathbf z|\mathbf m, C)</script><p>根据高斯型联合概率分布的条件分布（参考这里关于 <a href="">高斯分布</a> 的介绍），可知</p><script type="math/tex; mode=display">\mathbf m=B^{\top}(BB^{\top}+\sigma^2I)^{-1}(\mathbf x-\boldsymbol \mu) \tag{7}</script><script type="math/tex; mode=display">C=I-B^{\top}(BB^{\top}+\sigma^2I)^{-1}B \tag{8}</script><p>得到隐变量 $\mathbf z$ 的后验概率分布之后：</p><ol><li>对于一个新的数据 $\mathbf x^{\star}$，计算 $p(\mathbf z^{\star}|\mathbf x^{\star})$ 的概率分布</li><li>根据这个后验分布随机生成 $\mathbf z^{\star}$</li><li>重建数据 $\tilde {\mathbf x}^{\star}~p(\mathbf x|\mathbf z^{\star},B,\boldsymbol \mu, \sigma^2)$，其中 $B,\boldsymbol \mu,\sigma^2$ 为模型参数，在对数据集做 MLE 或 MAP 时学习得到</li></ol><h2 id="1-2-MLE"><a href="#1-2-MLE" class="headerlink" title="1.2 MLE"></a>1.2 MLE</h2><p>使用 MLE 或 MAP 进行参数估计，似然函数使用 (5) 式。负对数似然为</p><script type="math/tex; mode=display">\mathcal L=-\log P(X)=-\sum_{n=1}^N \log p(\mathbf x_n)\propto \sum_{n=1}^N (\mathbf x_n-\mathbb E[\mathbf x])^{\top}\Sigma^{-1}(\mathbf x_n-\mathbb E[\mathbf x])</script><p>其中 $X$ 表示整个数据集。$\mathbb E[\mathbf x]$ 表示随机变量 $\mathbf x$ 的真实期望，$\Sigma$ 是其真实协方差矩阵，根据 (5) 式得</p><script type="math/tex; mode=display">\mathbb E[\mathbf x]=\boldsymbol \mu\\ \Sigma=BB^{\top}+\sigma^2I</script><p>$\mathcal L$ 对 $\boldsymbol \mu$ 求梯度，</p><script type="math/tex; mode=display">\nabla {\mathcal L}_{\boldsymbol \mu}=\sum_{n=1}^N (\mathbf x_n-\boldsymbol \mu)\Sigma^{-1}=\mathbf 0</script><p>解得，</p><script type="math/tex; mode=display">\boldsymbol \mu_{ML}=\frac 1 N \sum_{n=1}\mathbf x_n \tag{9}</script><p>同理对 $B$ 和 $\sigma^2$ 求梯度并等于零，解得</p><script type="math/tex; mode=display">B_{ML}=T(\Lambda-\sigma^2I)^{1/2}R \tag{10}</script><script type="math/tex; mode=display">\sigma^2=\frac 1 {D-M} \sum_{j=M+1}^D \lambda_j \tag{11}</script><p>其中 $T \in \mathbb R^{D\times M}$ 包含了数据协方差矩阵的前 $M$ 个特征向量（特征向量是 $D$ 维），$\Lambda=\text{diag}(\lambda_1,\ldots, \lambda_M)$ 是数据协方差矩阵的前 $M$ 个特征值（如果几何重数 $&gt;1$ 则可重复），$R \in \mathbb R^{M\times M}$ 是任意正交矩阵。</p><h2 id="1-3-MLE-结果分析"><a href="#1-3-MLE-结果分析" class="headerlink" title="1.3 MLE 结果分析"></a>1.3 MLE 结果分析</h2><h3 id="1-3-1-期望"><a href="#1-3-1-期望" class="headerlink" title="1.3.1 期望"></a>1.3.1 期望</h3><p>随机变量 $\mathbf x$ 的概率分布的期望 $\boldsymbol \mu$ 就是样本均值</p><h3 id="1-3-2-协方差"><a href="#1-3-2-协方差" class="headerlink" title="1.3.2 协方差"></a>1.3.2 协方差</h3><p>根据 (9) 式，噪声方差 $\sigma^2$ 为数据映射到 “ $M$ 阶主子空间的正交补空间 ” 后方差的平均，即数据协方差矩阵对应到补空间的特征值之和。</p><p>对 $\sigma^2=0$ 的情况进行验证。</p><p>根据 (7) 式进行数据降维</p><script type="math/tex; mode=display">\mathbf z \approx B^{\top}(BB^{\top}+\sigma^2I)^{-1}(\mathbf x-\boldsymbol \mu)=B^{\top}(BB^{\top})^{-1}(\mathbf x-\boldsymbol \mu)</script><p>根据 上式以及 (2) 式，数据恢复为</p><script type="math/tex; mode=display">\tilde {\mathbf x} \approx B\mathbf z+ \boldsymbol \mu \approx \mathbf x</script><p>也就是说，对于原始数据 $\mathbf x$:</p><ol><li>使用 PCA （数据协方差矩阵特征分解）恢复的数据记为 $\tilde {\mathbf x}’$</li><li>如果不引入噪声，通过两步随机生成（先生成 $\mathbf z^{\star}$，然后生成 $\tilde {\mathbf x}$）， 那么 $p(\tilde {\mathbf x}=\tilde {\mathbf x}’)$ 的概率密度最大。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据集说明</title>
      <link href="/2022/02/15/dl/datasets/"/>
      <url>/2022/02/15/dl/datasets/</url>
      
        <content type="html"><![CDATA[<p>对各种常用数据集格式进行说明</p><span id="more"></span><h1 id="1-MNIST"><a href="#1-MNIST" class="headerlink" title="1. MNIST"></a>1. MNIST</h1><h2 id="1-1-存储说明"><a href="#1-1-存储说明" class="headerlink" title="1.1 存储说明"></a>1.1 存储说明</h2><p><a href="http://yann.lecun.com/exdb/mnist/">官方网站</a></p><p>有以下四个文件<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">train-images-idx3-ubyte: training set imagestrain-labels-idx1-ubyte: training set labelst10k-images-idx3-ubyte:  test set imagest10k-labels-idx1-ubyte:  test set labels<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>如果下载的是 <code>.gz</code> 压缩文件，使用下面命令进行解压<br><pre class="line-numbers language-none"><code class="language-none">gzip -d &lt;file name&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>数据说明：</p><ol><li><p>训练集 label 文件 <code>train-labels-idx1-ubyte</code></p> <pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">[offset] [type]          [value]          [description]0000     32 bit integer  0x00000801(2049) magic number (MSB first)0004     32 bit integer  60000            number of items0008     unsigned byte   ??               label0009     unsigned byte   ??               label........xxxx     unsigned byte   ??               label<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> labels 值为 <code>[0,9]</code>。</p></li><li><p>训练集 image 文件 <code>train-images-idx3-ubyte</code></p> <pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">[offset] [type]          [value]          [description]0000     32 bit integer  0x00000803(2051) magic number0004     32 bit integer  60000            number of images0008     32 bit integer  28               number of rows0012     32 bit integer  28               number of columns0016     unsigned byte   ??               pixel0017     unsigned byte   ??               pixel........xxxx     unsigned byte   ??               pixel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 行顺序存储，像素值范围 <code>[0,255]</code>，其中 <code>0</code> 表示背景，<code>255</code>表示前景。</p></li></ol><p>测试集文件类似，只是 images 数量不同。</p><h2 id="1-2-numpy-加载"><a href="#1-2-numpy-加载" class="headerlink" title="1.2 numpy 加载"></a>1.2 numpy 加载</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> struct<span class="token keyword">def</span> <span class="token function">load_mnist</span><span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    prefix <span class="token operator">=</span> <span class="token string">'train'</span> <span class="token keyword">if</span> train <span class="token keyword">else</span> <span class="token string">'t10k'</span>    home <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>expanduser<span class="token punctuation">(</span><span class="token string">'~'</span><span class="token punctuation">)</span>    root <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>home<span class="token punctuation">,</span> <span class="token string">'data/cv/mnist'</span><span class="token punctuation">)</span>    label_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">'%s-labels-idx1-ubyte'</span><span class="token operator">%</span>prefix<span class="token punctuation">)</span>    image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span> <span class="token string">'%s-images-idx3-ubyte'</span><span class="token operator">%</span>prefix<span class="token punctuation">)</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>label_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span>        buf <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        labels <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>buf<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span>        buf <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        images <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>buf<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> images<span class="token punctuation">,</span> labels<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主成分分析</title>
      <link href="/2022/02/14/ml/PCA/"/>
      <url>/2022/02/14/ml/PCA/</url>
      
        <content type="html"><![CDATA[<p>主成分分析用于数据降维</p><span id="more"></span><p>（本文有的大小符号表示矩阵，有的大写符号表示 scalar，可根据上下文辨别。）</p><h1 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h1><p>考虑 i.i.d 数据集 $\mathcal X=\{\mathbf x_1,\ldots, \mathbf x_N\}$，$\mathbf x_n \in \mathbb R^D$，且经验期望为 $\hat {\mathbb E}[\mathbf x]=\mathbf 0$，那么经验方差（协方差矩阵）为</p><script type="math/tex; mode=display">S=\frac 1 N \sum_{n=1}^N \mathbf x_n \mathbf x_n^{\top} \tag{1}</script><p>为了降维，将数据映射到低维 </p><script type="math/tex; mode=display">\mathbf z = B^{\top} \mathbf x \in \mathbb R^M \tag{2}</script><p>其中 </p><script type="math/tex; mode=display">B:=[\mathbf b_1,\ldots, \mathbf b_M] \in \mathbb R^{D \times M}</script><p>且 $B$ 的列相互正交且归一，$M &lt; D$</p><p>从 $\mathbf z$ 再恢复到原空间的数据 $\tilde {\mathbf x}$，</p><script type="math/tex; mode=display">\begin{aligned}\tilde {\mathbf x}=B^{-\top}\mathbf z =B \mathbf z&=BB^{\top}\mathbf x\\&=[\mathbf b_1,\ldots, \mathbf b_M]\begin{bmatrix}\mathbf b_1^{\top} \\ \vdots \\ \mathbf b_M^{\top}\end{bmatrix}\mathbf x\\&=\sum_{i=1}^M \mathbf b_i \mathbf b_i^{\top} \mathbf x \end{aligned}\tag{3}</script><p>其中 $B$ 是正交矩阵 $\Rightarrow B^{\top}B=I$。</p><p>那么如何求这样的转换矩阵 $B$？显然需要根据某种指标优化来求解，因为满足降维的正交矩阵有无数个。</p><h1 id="2-最大化方差"><a href="#2-最大化方差" class="headerlink" title="2. 最大化方差"></a>2. 最大化方差</h1><p>最大化方差来求解 $B$。</p><p>上面我们假设数据集是 centered data，即均值为 $\mathbf 0$，这种假设是合理的。因为如果数据均值为 $\boldsymbol \mu$，那么变换为</p><script type="math/tex; mode=display">\mathbf z =B^{\top}(\mathbf x - \boldsymbol \mu)</script><p>于是方差为</p><script type="math/tex; mode=display">\mathbb V_{\mathbf z}[\mathbf z]=\mathbb V_{\mathbf x}[B^{\top}(\mathbf x-\boldsymbol \mu)]=\mathbb V_{\mathbf x}[B^{\top}\mathbf x]</script><p>即，映射到低维空间的数据分布的方差与原数据是否 centered 无关。于是可以假设 $\mathbb E_{\mathbf x}[\mathbf x]=\mathbf 0$，此时</p><script type="math/tex; mode=display">\mathbb E_{\mathbf z}[\mathbf z]=B^{\top} \mathbb E_{\mathbf x}[\mathbf x]=\mathbf 0</script><p>根据 (2) 式有</p><script type="math/tex; mode=display">z_1=\mathbf b_1^{\top} \mathbf x</script><p>考虑 $z_1$ 方向（或者称，变换后这个 axis）上的方差，</p><script type="math/tex; mode=display">\begin{aligned}V_1:=\mathbb V[z_1]&=\frac 1 N \sum_{n=1}^N z_{1n}^2\\&=\frac 1 N \sum_{n=1}^N (\mathbf b_1^{\top} \mathbf x_n)^2\\&=\frac 1 N \sum_{n=1}^N \mathbf b_1^{\top} \mathbf x_n\mathbf x_n^{\top}\mathbf b_1\\&=\mathbf b_1^{\top} \left(\frac 1 N \sum_{n=1}^N \mathbf x_n \mathbf x_n^{\top} \right)\mathbf b_1\\&=\mathbf b_1^{\top} S \mathbf b_1\end{aligned}</script><p>在求 $\max V_1$ 之前，还需要增加限制条件 $||\mathbf b_1||^2=1$，否则，将 $\mathbf b_1$ 进行 scale，方差 $V$ 则会二次幂 scale，故得到优化问题</p><script type="math/tex; mode=display">\max_{\mathbf b_1} \mathbf b_1^{\top} S \mathbf b_1\\ s.t. \ ||\mathbf b_1||^2=1</script><p>对于受限优化问题，可以使用拉格朗日乘子法，</p><script type="math/tex; mode=display">\mathcal L(\mathbf b_1, \lambda_1)=\mathbf b_1^{\top} S \mathbf b_1 + \lambda_1(1-\mathbf b_1^{\top} \mathbf b_1)</script><p>求偏导</p><script type="math/tex; mode=display">\frac {\partial \mathcal L}{\partial \mathbf b_1}=2\mathbf b_1^{\top} S-2\lambda_1 \mathbf b_1^{\top}, \quad \frac {\partial \mathcal L}{\partial \lambda_1}=1-\mathbf b_1^{\top}\mathbf b_1</script><p>令偏导为 $\mathbf 0$，解得</p><script type="math/tex; mode=display">S\mathbf b_1=\lambda_1 \mathbf b_1, \quad \mathbf b_1^{\top}\mathbf b_1=1</script><p>即 $\lambda_1, \mathbf b_1$ 分别是矩阵 $S$ 的特征根和（归一化）特征向量。于是</p><script type="math/tex; mode=display">V_1=\mathbf b_1^{\top} S \mathbf b_1=\lambda_1 \mathbf b_1^{\top} \mathbf b_1=\lambda_1 \ge 0</script><font color="magenta">$S$ 是对称矩阵，故是半正定的，其特征值非负。</font><p><strong>故当 $\lambda_1$ 是 $S$ 的最大特征值时，方差 $V_1$ 最大，此时 $\mathbf b_1$ 为最大特征值对应的归一化特征向量。</strong></p><p>映射到低维空间的 $z_1$ 分量为</p><script type="math/tex; mode=display">z_1=\mathbf b_1^{\top} \mathbf x</script><p>根据 $z_1$ 恢复到原空间数据</p><script type="math/tex; mode=display">\tilde {\mathbf x}^{(1)}=\mathbf b_1 z_1=\mathbf b_1 \mathbf b_1^{\top} \mathbf x</script><h2 id="2-1-最大方差的-M-维子空间"><a href="#2-1-最大方差的-M-维子空间" class="headerlink" title="2.1 最大方差的 M 维子空间"></a>2.1 最大方差的 M 维子空间</h2><p>我们考虑一般情况，假设已经找到 $m-1$ 个主成分对应的特征向量，由于协方差矩阵是对称矩阵，根据矩阵光谱定理，其特征向量可以组成 $m-1$ 维子空间的一组正交归一基，即 </p><script type="math/tex; mode=display">\mathbf b_i^{\top} \mathbf b_j=\begin{cases} 1 & i=j \\ 0 & i \ne j \end{cases}, \quad 1 \le i,j \le m-1</script><p>对数据做如下处理</p><script type="math/tex; mode=display">\hat X:=X-\sum_{i=1}^{m-1} \mathbf b_i \mathbf b_i^{\top} X=X-B_{m-1}X</script><p>其中 $B_{m-1}=\sum_{i=1}^{m-1} \mathbf b_i \mathbf b_i^{\top}$，$X =[\mathbf x_1, \ldots,\mathbf x_N]$ 表示数据集，$\mathbf b_i \mathbf b_i^{\top} X$ 表示根据主成分分量恢复到原空间的数据集，故 $\hat X$ 表示去掉原数据中已确定的 $m-1$ 个主成分，这样 $\hat X$ 在这 $m-1$ 子空间的方差为 $\mathbf 0_{m-1}$，于是对 $\hat X$ 求第一个主成分就是对 $X$ 求第 $m$ 个主成分，</p><script type="math/tex; mode=display">V_m =\mathbb V[z_m]=\frac 1 N \sum_{n=1}^N z_{mn}^2=\frac 1 N \sum_{n=1}^N (\mathbf b_m^{\top} \hat {\mathbf x}_n)^2=\mathbf b_m^{\top}\hat S \mathbf b_m</script><p>满足 $||\mathbf b_m||^2=1$。</p><p>即 <strong>$\hat S$ 的第一个特征值和对应特征向量就是 $S$ 的第 $m$ 个特征值和特征向量（特征值降序排列）</strong>。</p><p>于是，</p><script type="math/tex; mode=display">V_m=\mathbf b_m^{\top}S \mathbf b_m=\lambda_m</script><p>事实上有：</p><ol><li>$\hat S$ 的特征向量与 $S$ 的特征向量相同</li><li>$\hat S$ 的后 $m-1$ 特征值均为 0，其特征向量对应 $S$ 前 $m-1$ 个特征向量</li><li>$\hat S$ 的前 $D-(m-1)$ 特征值和特征向量对应 $S$ 后 $D-(m-1)$ 个特征值和特征向量。</li></ol><p><strong><font color="magenta">结论</font></strong><br>转换矩阵 $B \in \mathbb R^{D \times M}$ 由数据协方差矩阵 $S$ 的前 $m$ 个特征向量（列向量）组成。</p><p><strong>数据恢复</strong></p><p>使用前 $m$ 个主成分进行数据恢复，根据 (3) 式，</p><script type="math/tex; mode=display">\tilde {\mathbf x}=\sum_{i=1}^m \mathbf b_i \mathbf b_i^{\top}\mathbf x=[\mathbf b_1,\ldots,\mathbf b_m]\begin{bmatrix}\mathbf b_1^{\top} \\ \vdots \\ \mathbf b_m^{\top}\end{bmatrix}\mathbf x=B_{:,1:m}B_{:,1:m}^{\top}\mathbf x</script><h2 id="2-2-映射"><a href="#2-2-映射" class="headerlink" title="2.2 映射"></a>2.2 映射</h2><p>最大化方差是尽可能的保证数据分布的信息，而映射则是根据最小化原数据与恢复数据之间的误差进行求解。</p><p>选取空间 $\mathbb R^D$ 的一组正交归一基 （ONB）$B=(\mathbf b_1, \ldots, \mathbf b_D)$，那么任意数据点</p><script type="math/tex; mode=display">\mathbf x=\sum_{d=1}^D \zeta_d \mathbf b_d=\sum_{m=1}^M \zeta_m \mathbf b_m+\sum_{j=M+1}^D \zeta_j \mathbf b_j</script><p>注意 $\zeta_j, \ j=1,\ldots, D$ 表示数据相对于 $B$ 的坐标，而 $x_j, \ j=1,\ldots, D$ 是数据在标准基 $E=[\mathbf e_1, \ldots, \mathbf e_D]$（one-hot 向量组）下的坐标。</p><p>我们目的是想将数据维度从 $D$ 降到 $M$，这里 $M$ 是超参数，事先设定好的一个固定值。使用前 $M$ 个坐标来表示数据（的一个近似）：</p><script type="math/tex; mode=display">\tilde {\mathbf x}=\sum_{m=1}^M z_m \mathbf b_m \tag{4}</script><p>事实上，由于 $\{\mathbf b_m| m=1,\ldots, D|$ 是正交归一基，故 $z_m=\zeta_m, \ m=1,\ldots, M$，注意 $m$ 的取值范围。下文统一使用 $z_m$ 表示 $\mathbf x$ 在 $B$ 下的坐标。</p><p>求解的依据是对整个数据集而言，恢复的数据近似 $\tilde {\mathbf x}$ 与原数据 $\mathbf x$ 误差最小，误差（loss）使用欧氏距离，于是总误差为</p><script type="math/tex; mode=display">L=\frac 1 N \sum_{n=1}^N ||\tilde {\mathbf x}_n-\mathbf x_n||^2 \tag{5}</script><p>其中 $N$ 是数据集大小。</p><p><strong>总结</strong></p><p>要求解两个部分：</p><ol><li>正交归一基组 $\{\mathbf b_m, \ m=1,\ldots, M\}$</li><li>$\mathbf x$ 在基组 $\{\mathbf b_m, \ m=1,\ldots, M\}$ 下的坐标</li></ol><p>以使得 $L=\frac 1 N \sum_{n=1}^N ||\tilde {\mathbf x}_n-\mathbf x_n||^2$ 最小。</p><h3 id="2-2-1-求解坐标"><a href="#2-2-1-求解坐标" class="headerlink" title="2.2.1 求解坐标"></a>2.2.1 求解坐标</h3><p>根据 (4),(5) 式，误差对坐标求偏导，</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial L}{\partial z_{mn}}&=\frac {\partial L}{\partial \tilde {\mathbf x}_n} \frac {\partial \tilde {\mathbf x}_n}{\partial z_{mn}} \\&=\frac 2 N(\tilde {\mathbf x}_n-\mathbf x_n)^{\top} \mathbf b_m\\&=\frac 2 N \left(\sum_{i=1}^M z_{in} \mathbf b_i-\mathbf x_n\right)^{\top} \mathbf b_m\\& \stackrel{ONB}= \frac 2 N (z_{mn} \mathbf b_m^{\top} \mathbf b_m - \mathbf x_n^{\top} \mathbf b_m)\\&=\frac 2 N (z_{mn} - \mathbf x_n^{\top} \mathbf b_m)\\&= 0\end{aligned}</script><p>于是 </p><script type="math/tex; mode=display">z_{mn}=\mathbf x_n^{\top} \mathbf b_m=\mathbf b_m^{\top}\mathbf x_n \tag{6}</script><p>其中 $m=1,\ldots, M; \ n=1,\ldots,N$</p><p>这表明 $\mathbf x$ 在 $\mathbf b_m$ 上的投影值就是对应的坐标 $z_m$，于是数据恢复为</p><script type="math/tex; mode=display">\tilde {\mathbf x}=\sum_{m=1}^M  \mathbf b_m z_m=\sum_{m=1}^M \mathbf b_m \mathbf b_m^{\top} \mathbf x=B_m B_m^{\top} \mathbf x \tag{7}</script><p>其中 $B_m:=[\mathbf b_1, \ldots, \mathbf b_M] \in \mathbb R^{D \times M}$，表示主子空间的变换矩阵。(7) 式表示将数据 $\mathbf x$ 投影到主子空间，所得的投影 $\tilde {\mathbf x}$ 与原数据 $\mathbf x$ 的距离需要尽可能小。</p><h3 id="2-2-2-求解基向量"><a href="#2-2-2-求解基向量" class="headerlink" title="2.2.2 求解基向量"></a>2.2.2 求解基向量</h3><p>根据 (6)(7) 式， </p><script type="math/tex; mode=display">\tilde {\mathbf x}=\sum_{m=1}^M z_m \mathbf b_m =\sum_{m=1}^M (\mathbf x^{\top} \mathbf b_m)\mathbf b_m</script><p>注意右侧小括号不能省略，表示一个 scalar 与矩阵相乘。</p><p>当 $M=D$ 时，$\tilde {\mathbf x}=\mathbf x$，所以，$\mathbf x=\sum_{m=1}^D (\mathbf x^{\top} \mathbf b_m)\mathbf b_m$，于是向量差</p><script type="math/tex; mode=display">\mathbf x - \tilde {\mathbf x}=\sum_{j=M+1}^D (\mathbf x^{\top} \mathbf b_j)\mathbf b_j</script><p>代入 (5) 式得损失为</p><script type="math/tex; mode=display">\begin{aligned}L &=\frac 1 N \sum_{n=1}^N \begin{Vmatrix}\sum_{j=M+1}^D (\mathbf x_n^{\top} \mathbf b_j)\mathbf b_j \end{Vmatrix}^2\\&=\frac 1 N \sum_{n=1}^N \left(\sum_{j=M+1}^D (\mathbf x_n^{\top} \mathbf b_j)\mathbf b_j\right)^{\top} \left(\sum_{j=M+1}^D (\mathbf x_n^{\top} \mathbf b_j)\mathbf b_j\right)\\&\stackrel{ONB}=\frac 1 N \sum_{n=1}^N \sum_{j=M+1}^D (\mathbf x_n^{\top} \mathbf b_j)^2\mathbf b_j^{\top} \mathbf b_j\\&=\frac 1 N \sum_{n=1}^N \sum_{j=M+1}^D (\mathbf x_n^{\top} \mathbf b_j)^{\top}(\mathbf x_n^{\top} \mathbf b_j)\\&=\frac 1 N \sum_{n=1}^N \sum_{j=M+1}^D \mathbf b_j^{\top}\mathbf x_n\mathbf x_n^{\top} \mathbf b_j\\&=\sum_{j=M+1}^D \mathbf b_j^{\top} \underbrace{\left(\frac 1 N \sum_{n=1}^N \mathbf x_n\mathbf x_n^{\top} \right)}_{:=S}\mathbf b_j\\&= \sum_{j=M+1}^D \mathbf b_j^{\top} S \mathbf b_j\end{aligned}</script><p>由于 $S$ 是对阵半正定，故 $\mathbf b_j^{\top} S \mathbf b_j\ge 0$，且<br>$\mathbf b_j^{\top} S \mathbf b_j$ 最小为 $S$ 的最小特征根，此时 $\mathbf b_j$ 就是对应的特征向量。下面简单证明。</p><p><strong>证明：</strong></p><p>做特征分解 $S=P^{\top} \Lambda P$，其中 $P$ 是正交矩阵，$P^{\top}$ 的列为 $S$ 的特征向量。要求下式的最小值</p><script type="math/tex; mode=display">\mathbf b^{\top} S \mathbf b=\mathbf b^{\top} P^{\top} \Lambda P\mathbf b \stackrel{\mathbf c:=P\mathbf b}=\mathbf c^{\top} \Lambda \mathbf c=\sum_{i=1}^D \lambda_i c_i^2</script><p>由于 $\mathbf c^{\top}\mathbf c=\mathbf b^{\top}P^{\top}P\mathbf b=1$，特征值 $\lambda_i \ge 0 , \ i=1,\ldots, D$ 且降序排列，那么最值问题</p><script type="math/tex; mode=display">\min_{\mathbf c} \ \sum_{i=1}^D \lambda_i c_i^2</script><p>的解为 $\mathbf c=[0, \ldots, 0, 1]^{\top}$，最小值为 </p><script type="math/tex; mode=display">\min \mathbf b^{\top} S \mathbf b=\lambda_D</script><p>此时 $\mathbf b=P^{\top} \mathbf c=P_{:,D}^{\top}$，此即 $S$ 对应于 $\lambda_D$ 的一个特征向量（$P^{\top}$ 的最后一列）。<p align="right">$\square$</p></p><p>故损失 $L$ 最小为</p><script type="math/tex; mode=display">L=\sum_{j=M+1}^D \lambda_j</script><p>其中 $\lambda_j$ 可重复（可重复是指特征值几何重数 $n&gt;1$）。</p><font color="magenta">结论：</font><p>矩阵 $B$ 由协方差矩阵 $S$ 的特征向量（列向量）组成，<strong>变换矩阵 $B_M$ 由其 top <code>M</code> 特征值（可重复）对应的特征向量组成</strong>。</p><p>可见，这与最大化方差的结果是相同的。</p><h2 id="2-3-why-centered-data"><a href="#2-3-why-centered-data" class="headerlink" title="2.3 why centered data"></a>2.3 why centered data</h2><p>我们假设数据集经验期望为 $\boldsymbol \mu=\mathbf 0$，这样方便下文的讨论，如果不为 $\mathbf 0$，那么最终的求解结果（指转换矩阵）仍然不变，只是求解过程的展示更繁冗些。事实上，当经验期望为 $\boldsymbol \mu$ 时，做变换</p><script type="math/tex; mode=display">\mathbf z=B_m^{\top} (\mathbf x-\boldsymbol \mu) \in \mathbb R^M</script><p>那么 $\tilde {\mathbf x}=B_m \mathbf z + \boldsymbol \mu$，损失对坐标 $z_{mn}$ 的偏导为</p><script type="math/tex; mode=display">\begin{aligned} \frac {\partial L}{\partial z_{mn}}&=\frac 2 N(\tilde {\mathbf x}_n-\mathbf x_n)^{\top} \mathbf b_m\\&=\frac 2 N (z_{mn} + \boldsymbol \mu^{\top} \mathbf b_m- \mathbf x_n^{\top} \mathbf b_m)=0\end{aligned}\Rightarrow z_{mn}=(\mathbf x_n-\boldsymbol \mu)^{\top} \mathbf b_m</script><p>可见基向量 $\mathbf b_m$ 是不变的，于是对数据 $\mathbf x$ 转换的矩阵 $B_m$ 也是不变的，改变的只是相对于这些基向量的坐标值（平移 $-\boldsymbol \mu^{\top} \mathbf b_m$）。</p><p><strong>non-centered data</strong> 处理步骤：</p><ol><li>将数据进行 centering 处理 $\mathbf x:=\mathbf x - \boldsymbol \mu$，其中 $\boldsymbol \mu= \frac 1 N \sum_n \mathbf x_n$</li><li>将数据按 centered data 处理：求协方差矩阵的 top <code>m</code> 对应的特征向量，得到转换矩阵 $B_m$</li><li>恢复数据 $\tilde {\mathbf x}=B_m \mathbf z + \boldsymbol \mu=B_mB_m^{\top} \mathbf x + \boldsymbol \mu$</li></ol><h1 id="3-低-rank-近似"><a href="#3-低-rank-近似" class="headerlink" title="3. 低 rank 近似"></a>3. 低 rank 近似</h1><h2 id="3-1-特征向量求解"><a href="#3-1-特征向量求解" class="headerlink" title="3.1 特征向量求解"></a>3.1 特征向量求解</h2><p>数据集的协方差矩阵</p><script type="math/tex; mode=display">S=\frac 1 N \sum_{n=1}^N \mathbf x_n \mathbf x_n^{\top}=\frac XX^{\top}</script><p>其中 $X=[\mathbf x_1, \ldots, \mathbf x_N] \in \mathbb R^{D \times N}$ 表示整个数据集。</p><p>获取协方差矩阵的特征向量的方法：</p><ol><li>直接对 $S$ 进行特征分解</li><li><p>对 $X$ 进行 SVD，</p><script type="math/tex; mode=display">X=U \Sigma V^{\top}</script><script type="math/tex; mode=display">S=\frac 1 N XX^{\top}=U (\frac 1 N \Sigma \Sigma^{\top}) U^{\top}</script><p> $U$ 的列就是特征向量。</p></li></ol><h2 id="3-2-数据集低-rank-近似"><a href="#3-2-数据集低-rank-近似" class="headerlink" title="3.2 数据集低 rank 近似"></a>3.2 数据集低 rank 近似</h2><p>数据集 $X \in \mathbb R^{D \times N}$ 的近似 </p><script type="math/tex; mode=display">\tilde X_M=\underbrace{U_M}_{D \times M} \underbrace{\Sigma_M}_{M\times M} \underbrace{V_M^{\top}}_{M \times N} \in \mathbb R^{D \times N} \tag{8}</script><p>其中：</p><ol><li>$U_M=[\mathbf u_1,\ldots, \mathbf u_M]$ 为前 $M$ 个左特征向量</li><li>$\Sigma_M$ 为前 $M$ 个特征值所构成的对角矩阵</li><li><p>$V_M=[\mathbf v_1,\ldots, \mathbf v_M]$ 为前 $M$ 个右特征向量</p><p> 注意，代入 (8) 式中时，$V_M$ 需要转置为 $V_M^{\top}$，而 <code>numpy.linalg.svd</code> 返回的三元组 <code>u,d,v</code> 中 <code>v</code> 已经是转置过的，所以直接取 <code>v[:M,:]</code>，根据 (8) 式恢复的数据集近似则为 </p> <pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>u<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span>M<span class="token punctuation">]</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>d<span class="token punctuation">[</span><span class="token punctuation">:</span>M<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v<span class="token punctuation">[</span><span class="token punctuation">:</span>M<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p>这跟这里的<a href="/2022/02/10/math/linear_algebra_concepts">图像压缩存储（图像近似）</a>本质是一样的,只要存储 $DM+M+MN$ 个数，而原数据集需要存储 $DN$ 个数，从而达到压缩目的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率模型</title>
      <link href="/2022/02/14/ml/prob_model/"/>
      <url>/2022/02/14/ml/prob_model/</url>
      
        <content type="html"><![CDATA[<p>总结概率和概率图模型。<br><span id="more"></span></p><h1 id="1-参数估计"><a href="#1-参数估计" class="headerlink" title="1. 参数估计"></a>1. 参数估计</h1><p><strong>MLE</strong></p><p>最大似然估计</p><script type="math/tex; mode=display">\mathcal L(\boldsymbol \theta)=-\log p(\mathbf x|\boldsymbol \theta)</script><p>监督学习中，每个数据 $\mathbf x_i$ 均有对应的 label 为 $y_i$，那么对于 size 为 $N$ 的数据集，负对数似然为</p><script type="math/tex; mode=display">\mathcal L(\boldsymbol \theta)=-\sum_{i=1}^N \log p(y_n|\mathbf x_i, \boldsymbol \theta)</script><p>MLE 的一个缺点：容易过拟合。</p><p><strong>MAE</strong></p><p>最大后验估计</p><p>MLE 中将参数 $\boldsymbol \theta$ 看作一个未知但是确定不变的量，MAE 中将 $\boldsymbol \theta$ 看作一个随机变量，其有一个先验分布 $p(\boldsymbol \theta)$，那么后验概率为</p><script type="math/tex; mode=display">p(\boldsymbol \theta|\mathbf x)=\frac {p(\mathbf x|\boldsymbol \theta)p(\boldsymbol \theta)} {p(\mathbf x)}</script><p>最大化后验概率求参数估计，</p><script type="math/tex; mode=display">\max_{\boldsymbol \theta} \ p(\boldsymbol \theta|\mathbf x)=\max_{\boldsymbol \theta} p(\mathbf x|\boldsymbol \theta) \ p(\boldsymbol \theta)</script><p>其中，$\mathbf x$ 是给定的已知观察量，在 MAE 过程中，$p(\mathbf x)$ 为一个确定不变的量。</p><h1 id="2-概率模型"><a href="#2-概率模型" class="headerlink" title="2. 概率模型"></a>2. 概率模型</h1><p>上一节内容为参数估计的两种常用方法，其中要求似然概率，就需要确定模型。</p><h2 id="2-1-贝叶斯推断"><a href="#2-1-贝叶斯推断" class="headerlink" title="2.1 贝叶斯推断"></a>2.1 贝叶斯推断</h2><p>数据集 $\mathcal X$，参数先验 $p(\boldsymbol \theta)$，后验为</p><script type="math/tex; mode=display">p(\boldsymbol \theta|\mathcal X)=\frac {p(\mathcal X|\boldsymbol \theta)p(\boldsymbol \theta)}{p(\mathcal X)} \tag{1}</script><p>数据集似然为</p><script type="math/tex; mode=display">p(\mathcal X)=\int p(\mathcal X|\boldsymbol \theta)p(\boldsymbol \theta)d \boldsymbol \theta \tag{2}</script><p>单个数据样本的概率</p><script type="math/tex; mode=display">p(\mathbf x)=\int p(\mathbf x|\boldsymbol \theta)p(\boldsymbol \theta) d \boldsymbol \theta =\mathbb E_{\boldsymbol \theta}[p(\mathbf x|\boldsymbol \theta)] \tag{3}</script><p>贝叶斯推断与 MLE 和 MAP 的区别：</p><ol><li>MLE 和 MAP 是点估计，求 $\boldsymbol \theta$ 的最可能的值 $\boldsymbol \theta^{\star}$，推断阶段计算 $p(\mathbf x^{new}|\boldsymbol \theta^{\star})$ 。</li><li>贝叶斯推断，根据 (1) 和 (2) 式（这两个等式中 $p(\boldsymbol \theta)$ 为先验）求后验概率分布 $p(\boldsymbol \theta|\mathcal X)$，然后将后验概率代入 (3) 式进行推断</li></ol><p>贝叶斯推断的难点：</p><ol><li>(2) 式的积分比较难处理。如果先验不是共轭于似然函数，那么后验分布类型与先验分布类型不同，那么 (2) 式的积分难以得到解析解，只能使用数值近似，例如 Markov chain Monte Carlo 等。</li><li>$p(\mathbf x|\boldsymbol \theta)p(\boldsymbol \theta)$ 与后验分布 $p(\boldsymbol \theta|\mathbf x)$ 类型相同，前者未归一化，后者归一化（相差了一个常数归一化因子）。</li></ol><h2 id="2-2-隐变量模型"><a href="#2-2-隐变量模型" class="headerlink" title="2.2 隐变量模型"></a>2.2 隐变量模型</h2><p>有隐变量的生成过程</p><script type="math/tex; mode=display">p(\mathbf x|\mathbf z, \boldsymbol \theta)</script><p>其中 $\mathbf x$ 是可观测变量，$\mathbf z$ 是隐变量。对隐变量我们有先验概率 $p(\mathbf z)$。</p><p>数据的不带隐变量的似然概率</p><script type="math/tex; mode=display">p(\mathbf x|\boldsymbol \theta)=\int p(\mathbf x|\mathbf z, \boldsymbol \theta) p(\mathbf z) d \mathbf z</script><p>根据上式似然函数，可以进行参数 $\boldsymbol \theta$ 的估计，但是上式中，如果先验 $p(\mathbf z)$ 共轭与似然 $p(\mathbf x|\mathbf z, \boldsymbol \theta)$，那么上式有解析解，否则难分析其解析解。</p><p>我们也可以计算隐变量的后验分布</p><script type="math/tex; mode=display">p(\mathbf z|\mathcal X)=\frac {p(\mathcal X|\mathbf z)p(\mathbf z)}{p(\mathcal X)}</script><p>其中数据集的似然为 $p(\mathcal X|\mathbf z)=\int p(\mathcal X|\mathbf z, \boldsymbol \theta)p(\boldsymbol \theta)d\boldsymbol \theta$，这里需要知道模型以及模型参数 $\boldsymbol \theta$ 的先验分布。</p><h2 id="2-3-有向图模型"><a href="#2-3-有向图模型" class="headerlink" title="2.3 有向图模型"></a>2.3 有向图模型</h2><p>有向图也称贝叶斯网络，用于表示有依赖条件的概率模型。</p><pre class="mermaid">graph LRA(a) -->B(b)B --> C(c)A --> C(c)</pre><p>上面图示表示的概率满足 $p(a,b,c)=p(c|a,b)p(b|a)p(a)$</p><p>有向图的联合概率分布为</p><script type="math/tex; mode=display">p(\mathbf x)=p(x_1,\ldots,x_K)=\prod_{k=1}^K p(x_k|\text{Pa}_k)</script><p>其中 $\text{Pa}_k$ 表示 $x_k$ 节点的所有父节点。</p><h3 id="2-3-1-条件独立"><a href="#2-3-1-条件独立" class="headerlink" title="2.3.1 条件独立"></a>2.3.1 条件独立</h3><p>给定 $\mathcal C$，$\mathcal A$ 条件独立于 $\mathcal B$，记作 $\mathcal A \perp !!! \perp \mathcal B|\mathcal C$。</p><p>考虑所有可能的路径（忽略箭头方向）：从 $\mathcal A$ 中节点出发到达 $\mathcal B$ 中节点。如果路径上某节点满足以下任何一点，那么称这个路径被阻塞：</p><ol><li>箭头到箭尾或者箭尾到箭尾汇合于 $\mathcal C$ 中的某节点</li><li>箭头到箭头交汇于某节点，而此节点和其所有后代节点均不在 $\mathcal C$ 中</li></ol><p>如果 $\mathcal A$ 到 $\mathcal B$ 的所有路径均被阻塞，那么 $\mathcal A \bot \mathcal B|\mathcal C$</p><p>例：</p><pre class="mermaid">graph LRA(a) -->B(b) --> C(c)C --> D(d)A --> D(d)D --> E(e)</pre><p>本例中，</p><ol><li><script type="math/tex; mode=display">b \perp \!\!\! \perp d|a,c</script><p> $b$ 到 $d$ 的两条路径分别经过 $a, c$，这两条路径均满足条件 <code>1</code>，故被阻塞，条件独立成立</p></li><li><script type="math/tex; mode=display">a \perp \!\!\! \perp c|b</script><p> $a$ 到 $c$ 的两条路径分别经过 $b, d$，前者满足条件 <code>1</code>，被阻塞，后者满足条件 <code>2</code>，故均被阻塞，条件独立成立</p></li><li><p>$b \not ! \perp !!! \perp d | c$</p><p> $b$ 到 $d$ 的两条路径分别经过 $a, c$，后者满足条件 <code>1</code>，前者不满足 <code>1,2</code> 任何一条，故未被阻塞，条件独立不成立</p></li><li><p>$a \not ! \perp !!! \perp c|b,e$</p><p> $a$ 到 $c$ 的两条路径分别经过 $b, d$，前者满足条件 <code>1</code>，后者 $d$ 虽然有箭头到箭头的交汇，但是 $d$ 有子节点 $e$，不满足条件 <code>2</code>，条件独立不成立</p></li></ol><p><strong>三节点图</strong></p><p>下面使用三节点图帮助分析条件独立。下列三种情况涵盖了所有的是否条件独立的情况。</p><p><strong>1. case1</strong></p><pre class="mermaid">graph TDC(c) --> A(a)C(c) --> B(b)</pre><p>易知联合概率分布为 $p(a,b,c)=p(a|c)p(b|c)p(c)$</p><p><code>(a,b)</code> 的边缘分布为 $p(a,b)=\sum_c p(a|c)p(b|c)p(c)$<br><code>a</code> 的边缘分布 $p(a)=\sum_c p(a|c)p(c)$<br><code>b</code> 的边缘分布 $p(b)=\sum_c p(b|c)p(c)$</p><p>显然 $p(a,b) \not \equiv p(a)p(b)$，故一般而言 </p><script type="math/tex; mode=display">a \not \! \perp \!\!\! \perp b |\emptyset</script><p>除非巧妙的设计各条件概率，使得 $p(a,b) = p(a)p(b)$，但是这里的有向图考虑的是一般情况，而非特殊情况。</p><p>考虑给定条件 <code>c</code> ，那么</p><script type="math/tex; mode=display">p(a,b|c)=\frac {p(a,b,c)}{p(c)}=p(a|c)p(b|c)</script><p>于是下面结论成立：</p><script type="math/tex; mode=display">a \perp \!\!\! \perp b|c</script><p><strong>2. case2</strong></p><pre class="mermaid">graph LRA(a) --> C(c) --> B(b)</pre><p>写出联合概率分布 $p(a,b,c)=p(a)p(c|a)p(b|c)$，</p><p>没有前提条件时，</p><p>$p(a,b)=\sum_c p(a)p(c|a)p(b|c)=p(a)\sum_c p(c|a)p(b|c)=p(a)p(b|a)$</p><p>$p(b)=\sum_a p(a) p(b|a)$</p><p>显然 $p(a,b) \not \equiv p(a)p(b)$，故 </p><script type="math/tex; mode=display">a \not \! \perp \!\!\! \perp b|\emptyset</script><p>给定条件 <code>c</code> 时，</p><script type="math/tex; mode=display">\begin{aligned}p(a,b|c)&=\frac {p(a,b,c)}{p(c)}\\&=\frac {p(a)p(c|a)p(b|c)}{p(c)}\\&=\frac {p(a,c)p(b|c)}{p(c)}\\&=p(a|c)p(b|c) \end{aligned}</script><p>于是有</p><script type="math/tex; mode=display">a \perp \!\!\! \perp b|c</script><p><strong>3. case3</strong></p><pre class="mermaid">graph TDA((a)) --> C((c))B((b)) --> C((c))</pre><p>写出联合概率分布 $p(a,b,c)=p(a)p(b)p(c|a,b)$，</p><p>没有前提条件 <code>c</code> 时，</p><p>$p(a,b)=\sum_c p(a)p(b)p(c|a,b)=p(a)p(b)$</p><p>显然</p><script type="math/tex; mode=display">a \perp \!\!\! \perp b|\emptyset</script><p>给定条件 <code>c</code> 时，</p><script type="math/tex; mode=display">\begin{aligned}p(a,b|c)&=\frac {p(a,b,c)}{p(c)}\\&=\frac {p(a)p(b)p(c|a,b)}{p(c)}\\&=\frac {p(a|c)p(b|c)p(c|a,b)}{\sum_{a',b'}p(c|a',b')}\\&\not \equiv p(a|c)p(b|c) \end{aligned}</script><p>于是有</p><script type="math/tex; mode=display">a \not \perp \!\!\! \perp b|c</script><h2 id="2-4-Markov-随机场"><a href="#2-4-Markov-随机场" class="headerlink" title="2.4 Markov 随机场"></a>2.4 Markov 随机场</h2><p>也称 Markov 网络或无向图模型。</p><p>假设无向图中的三个节点集 $A,B,C$，考虑以下条件独立性：</p><script type="math/tex; mode=display">A \perp \!\!\! \perp B|C</script><p>上述条件独立成立的条件是：</p><ol><li>从 $A$ 中节点到 $B$ 中节点的所有路径，均通过 $C$ 中节点，那么所有路径均被阻塞，上述条件独立性成立。</li></ol><p>从另一个角度来理解这个条件独立：将 $C$ 中所有节点（以及关联的边）均移除，那么 $A$ 中节点到 $B$ 中节点不存在任何一条路径。</p><p>无向图中引入“团”的概念：由一组节点构成，这组节点中任意两个节点之间均有连接，那么这组节点构成一个团。</p><p>最大团：向一个团中增加任何节点，都不再构成一个新的团，那么原来的团就是最大团。</p><p>例如下图中，有两个最大团 <code>(x1,x2,x3)</code> 和 <code>(x2,x3,4)</code>。</p><pre class="mermaid">graph LRLT((x1)) --- RT((x2))LT --- LB((x3))RT --- RB((x4))LB --- RBRT --- LB</pre><p>假设我们有一个团，记为 $C$，团中所有节点（随机变量）记为 $\mathbf x_C$，团的势函数为 $\psi_C(\mathbf x_C)$，那么无向图的联合概率分布为其中所有最大团的势函数连乘，</p><script type="math/tex; mode=display">p(\mathbf x)=\frac 1 Z \prod_C \psi_C(\mathbf x_C)</script><p>其中 $Z$ 用于归一化，即 $Z=\sum_{\mathbf x} \prod_C \psi_C(\mathbf x_C)$。</p><p>势函数必须满足 $\psi_C(\mathbf x_C) \ge 0$。一个很自然的选择是</p><script type="math/tex; mode=display">\psi_C(\mathbf x_C)=\exp\{-E(\mathbf x_C)\}</script><p>其中 $E(\mathbf x_C)$ 称作能量函数。能量函数越大，对于的势越小，概率也越小。势函数的指数形式，使得上式中势函数的相乘变成能量函数的相加。</p><h3 id="2-4-1-例子：图像降噪"><a href="#2-4-1-例子：图像降噪" class="headerlink" title="2.4.1 例子：图像降噪"></a>2.4.1 例子：图像降噪</h3><p>如图 1，</p><p><img src="/images/ml/prob_model_1.png" alt=""></p><p>图 1. 左侧是原图，右侧是加噪后图片</p><p>原图是二值图像（图 1 中采样 蓝色和黄色两种颜色表示），像素值 $\{-1,1\}$，以 <code>10%</code> 的概率反转像素值的符号，原图像素值记为 $x_i$，加噪后像素值为 $y_i$，由于噪声等级较低（10% 的概率）， $x_i, \ y_i$ 之间的关联性较强，且 $x_i, \ x_j$ 的关联性也较强，于是可用下图表示，</p><p><img src="/images/ml/prob_model_2.png" alt=""></p><p>图 2. 图像降噪的无向图</p><p>无向图中有两类团：</p><ol><li><p>$\{x_i,y_i\}$</p><p> 这类团的能量函数使用 $E=-\eta x_i y_i, \ \eta &gt; 0$。当 $y_i=x_i$ 时（表示未被噪声污染），$E$ 较小，对应的概率较大。由于噪声等级较低，这种假设是合理的。</p></li><li><p>$\{x_i, x_j\}$，其中 $i,j$ 表示相邻的像素的位置。</p><p> 如果 $x_i=x_j$，我们希望这个团具有较低的能量，从而具有较高的概率，观察图 1，这样的期望是合理的，因为大多数时候相邻的像素值相等。故能量函数设为 $E=-\beta x_i x_j$</p></li></ol><p>此外还需要增加一项 $hx_i$，表示像素自身对符号（或对 <code>1,-1</code>中哪个值）的偏好，prior，即 $x_i$ 的先验，即更偏向于 $-1$ 还是 $1$，令背景像素值为 <code>-1</code>，那么显然背景像素的这一项能量较低，其概率较大。</p><p><strong>再来理清上面所说的能量与概率的具体含义：</strong></p><ol><li><p>$hx_i$。我们希望背景像素值 $-1$ 的概率较大，即 $p(x=-1)&gt;p(x=1)$，那么能量值则有 $h \cdot -1 &lt; h \cdot 1 \Rightarrow h&gt;0$。</p><p> 假设使用 $p(x_i)$ 来生成随机像素值，显然 $x=-1$ 出现的次数通常要比 $x=1$ 出现的次数多，即背景像素比前景像素多。$hx_i, h &gt;0$ 的假设是合理的</p></li><li><p>$-\eta x_iy_i$ 。由于噪声概率较小，所以符号相反的概率较小，对应的能量值较大。<br> 令 $f(x,y)=-\eta xy, \ \eta&gt;0$ 表示此类型能量函数，于是 $f(1,-1)&gt;f(1,1)$，且 $f(-1,1)&gt;f(-1,-1)$，故满足符号相反的能量值较大。假设合理。</p></li><li><p>$-\beta x_i x_j$。与 <code>2</code> 类似。</p></li></ol><p>于是整个能量函数为</p><script type="math/tex; mode=display">E(\mathbf x, \mathbf y)=h\sum_i x_i -\beta \sum_{i,j}x_i x_j -\eta \sum_i x_i y_i</script><p>联合概率分布为</p><script type="math/tex; mode=display">p(\mathbf x, \mathbf y)=\frac 1 Z \exp \{-E(\mathbf x,\mathbf y))\}</script><p>降噪时，来自带噪图像的像素值 $y_i$ 是以观察值，$x_i$ 是隐变量（不可观察），求条件分布 $p(\mathbf x|\mathbf y)$。这是一个 Ising model，在统计物理中已经被广泛研究。对于这个图像恢复问题，我们要求的是具有最大概率的 $\mathbf x$ 值，下面采样 ICM（iterated condition models）法求解。</p><p><strong>方法1：ICM</strong></p><div id="flowchart-0" class="flow-chart"></div><p>迭代图像 $\mathbf x$，既可以按光栅扫描，也可以随机取点。退出标准可以是人为设定总迭代次数，或者设定一个概率目标值，或者说在每个点都参与计算的前提下，$\mathbf x$ 连续两次迭代不发生概率（局部最大）。</p><p>这种迭代方法不一定得到全局最优解，很有可能是局部最优解。</p><p>本例中，$\beta=1.0, \eta=2.1, h=0$，其中 $h=0$ 表示不考虑先验。另外，如果 $\beta=0$，那么表示不考虑相邻像素的关系，那么很有可能迭代的最终结果与带噪图像相同。</p><p><strong>方法2：graph cuts</strong></p><p>基于图割的方法（Greig et al., 1989; Boykov et al., 2001; Kolmogorov and  Zabih, 2004），求后验 $p(\mathbf x|\mathbf z)$ 全局最优解。</p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Init X=Yiter=>condition: X->Xidispatch=>condition: Xi=1,-1energy=>operation: E{-1}(X,Y)reenergy=>operation: E{1}(X,Y)reverse=>operation: Xi:=-Ximax=>operation: Xi=E{1,-1}(X,Y)argmax=>subroutine: xxcond=>condition: end iter?e=>end: 输出 Xst(right)->iteriter(yes)->dispatchiter(no)->iterdispatch(yes,right)->reenergyreenergy->maxcond(no)->itercond(yes)->edispatch(no)->energy->max(right)->cond</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率统计基本概念</title>
      <link href="/2022/02/12/math/statistic_concepts/"/>
      <url>/2022/02/12/math/statistic_concepts/</url>
      
        <content type="html"><![CDATA[<p>总结概率统计的一些知识点。<br><span id="more"></span></p><h1 id="1-统计"><a href="#1-统计" class="headerlink" title="1. 统计"></a>1. 统计</h1><h2 id="1-1-协方差"><a href="#1-1-协方差" class="headerlink" title="1.1 协方差"></a>1.1 协方差</h2><p>两个随机变量 $X,Y \in \mathbb R$ 的协方差定义为</p><script type="math/tex; mode=display">\begin{aligned}\text {Cov}[X,Y]&:=\mathbb E[(X-\mathbb E[X])(Y-\mathbb E[Y])]\\&=\mathbb E[XY-X\mathbb E[Y]-\mathbb E[X]Y-\mathbb E[X]\mathbb E[Y]]\\&=\mathbb E[XY]-\mathbb E[X]\mathbb E[Y]\end{aligned}</script><p>给定联合概率分布 $P(X,Y)$，协方差 $\text {Cov}[X,Y]$ 可以计算出来，是一个标量。特别地，$\mathbb V[X]:=\text {Cov}[X,X]=\mathbb E[X^2]-\mathbb E^2[X]$ 称作 $X$ 的方差。</p><p><strong>多维随机变量的协方差</strong></p><p>对于随机向量 $X \in \mathbb R^D$ 和 $Y \in \mathbb R^E$，协方差矩阵为</p><script type="math/tex; mode=display">\text {Cov}[X,Y]=\mathbb E[XY^{\top}]-\mathbb E[X] \mathbb E[Y]^{\top} = \text {Cov}[Y, X]^{\top} \in \mathbb R^{D \times E}</script><p><strong>协方差矩阵</strong></p><p>注意，协方差矩阵指的是多维随机变量 $X \in \mathbb R^D$ 的方差，</p><script type="math/tex; mode=display">\mathbb V[X]=\mathbb E[XX^{\top}]-\mathbb E[X] \mathbb E[X]^{\top}</script><p>协方差矩阵是对阵半正定矩阵。</p><p><strong>一般机器学习应用中，我们会假设协方差矩阵就是对称正定的，这样会更方便我们处理问题。事实上，协方差矩阵是对称的，且对角线元素值为正（一维随机变量的方差为正），而实际问题中的协方差矩阵也是满秩的（没有哪个列是其他列的线性组合），所以这种假设是合理的。</strong></p><p>性质：（$X,Y \in \mathbb R^D$）</p><ol><li>$\mathbb E[X \pm Y]=\mathbb E[X] \pm \mathbb E[Y]$</li><li>$\mathbb V[X\pm Y]=\mathbb V[X]+\mathbb V[Y] \pm \text{Cov}[X,Y]\pm \text{Cov}[Y,X]$</li><li>$X,Y$ 不相关 $\Leftrightarrow \text{Cov}[X,Y]=\mathbf 0$</li><li>$X,Y$ 独立 $\Rightarrow \text{Cov}[X,Y]=\mathbf 0$，反之不一定</li><li><script type="math/tex; mode=display">\text{Cov}[X+Y,Z]=E[(X+Y)Z^{\top}]-E[X+Y]E[Z]^{\top}\\=E[XZ^{\top}]+E[YZ^{\top}]-E[X]E[Z]^{\top}-E[Y]E[Z]^{\top}\\=\text{Cov}[X,Z]+\text{Cov}[Y,Z]</script></li><li><p>$\text{Cov}[A, X]=E[AX^{\top}]-E[A]E[X]^{\top}=AE[X]^{\top}-AE[X]^{\top}=\mathbf 0_{D\times E}$</p><p> 其中 $A \in \mathbb R^D$，为常向量，$X \in \mathbb R^E$ 为随机向量。</p></li></ol><p><strong>相关系数</strong></p><p>两个一维随机变量的相关稀疏 (Correlation) 为</p><script type="math/tex; mode=display">\text {corr}[X,Y]=\frac {\text {Cov}[X,Y]} {\sqrt {\mathbb V[X] \mathbb V[Y]}} \in [-1, 1]</script><p>相关系数矩阵：标准化随机变量（多维）$X/\mathbb V^{1/2}[X]$ 的协方差矩阵。这里 $\mathbb V^{1/2}[X]$ 是 $X$ 的标准差向量，$X/\mathbb V^{1/2}[X]$ 是 element-wise 相除。</p><h2 id="1-2-经验期望和协方差"><a href="#1-2-经验期望和协方差" class="headerlink" title="1.2 经验期望和协方差"></a>1.2 经验期望和协方差</h2><p>前面的期望和协方差均是针对真实分布的统计量，然而机器学习中，我们的数据集大小有限，所以无法得到真实的统计量，而是经验统计量。</p><p>经验期望：</p><script type="math/tex; mode=display">\overline {\mathbf x}:=\frac 1 N \sum_{n=1}^N \mathbf x_n</script><p>其中，$N$ 表示数据集大小，$\mathbf x_n \in \mathbb R^D$。</p><p>经验协方差矩阵：</p><script type="math/tex; mode=display">\Sigma:=\frac 1 N \sum_{n=1}^N (\mathbf x_n - \overline {\mathbf x})(\mathbf x_n - \overline {\mathbf x})^{\top}</script><h2 id="1-3-高斯分布"><a href="#1-3-高斯分布" class="headerlink" title="1.3 高斯分布"></a>1.3 高斯分布</h2><p><strong>高斯混合</strong></p><p>两个一维高斯分布的混合，</p><script type="math/tex; mode=display">p(x)=\alpha p_1(x) + (1-\alpha) p_2(x), \quad \alpha \in [0, 1]</script><p>其中，$X_i \sim (\mu_i, \sigma_i^2),\ i =1,2$， 那么，根据期望的线性映射的性质有</p><script type="math/tex; mode=display">\mathbb E[X]=\alpha \mu_1 + (1-\alpha)\mu_2</script><p>另外，</p><script type="math/tex; mode=display">\begin{aligned} \mathbb E[X^2]&=\int x^2 p(x)dx\\&=\int \alpha x^2 p_1(x)+(1-\alpha)x^2 p_2(x) dx\\&=\alpha \mathbb E_1[X^2] + (1-\alpha) \mathbb E_2[X^2]\\&=\alpha(\mu_1^2+\sigma_1^2) + (1-\alpha)(\mu_2^2+\sigma_2^2)\end{aligned}</script><p>于是方差为</p><script type="math/tex; mode=display">\mathbb V[X]=\mathbb E[X^2]-\mathbb E^2[X]=\alpha(\mu_1^2+\sigma_1^2) + (1-\alpha)(\mu_2^2+\sigma_2^2)-[\alpha \mu_1 + (1-\alpha)\mu_2]^2</script><p><strong>多维高斯分布</strong></p><p>服从标准高斯分布的多维随机变量，经过线性映射，可以得到非标准高斯分布。例如 $X \in \mathbb R^D$ 满足 $X \sim \mathcal N(\mathbf 0, I)$，那么 $\mathbf y=A\mathbf x + \boldsymbol \mu \in \mathbb R^D$ 服从 $\mathcal N(\boldsymbol \mu, \Sigma)$ 分布，其中 $\Sigma=AA^{\top}$。故要得到一个 $\mathcal N(\boldsymbol \mu, \Sigma)$ 分布，将协方差矩阵 $\Sigma$ 做 CholesKy 分解，得到矩阵 $A$，然后做线性变换 $\mathbf y=A\mathbf x + \boldsymbol \mu$ 即可。</p><p><strong>边际和条件型高斯分布</strong></p><p>考虑两个多维随机变量 $\mathbf x$ 和 $\mathbf y$，其维度可能不等，联合概率分布为</p><script type="math/tex; mode=display">p(\mathbf x, \mathbf y)=\mathcal N(\begin{bmatrix} \boldsymbol \mu_x \\ \boldsymbol \mu_y\end{bmatrix}, \begin{bmatrix} \Sigma_{xx} & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_{yy}\end{bmatrix})</script><p>那么条件概率分布也是高斯型，</p><script type="math/tex; mode=display">p(\mathbf x| \mathbf y)=\mathcal N(\boldsymbol \mu_{x|y}, \Sigma_{x|y})</script><p>其中</p><script type="math/tex; mode=display">\boldsymbol \mu_{x|y}=\boldsymbol \mu_x+\Sigma_{xy}\Sigma_{yy}^{-1}(\mathbf y-\boldsymbol \mu_y)</script><script type="math/tex; mode=display">\Sigma_{x|y}=\Sigma_{xx}-\Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx}</script><p>边际分布也是高斯型，</p><script type="math/tex; mode=display">p(\mathbf x)=\int p(\mathbf x,\mathbf y) d\mathbf y=\mathcal N(\mathbf x|\boldsymbol \mu_x, \Sigma_{xx})</script><h1 id="2-指数分布"><a href="#2-指数分布" class="headerlink" title="2. 指数分布"></a>2. 指数分布</h1><p><strong>Bernoulli 分布</strong></p><script type="math/tex; mode=display">p(x|\mu)=\mu^x(1-\mu)^{1-x}</script><script type="math/tex; mode=display">\mathbb E[X]=\mu</script><script type="math/tex; mode=display">\mathbb V[X]=\mu(1-\mu)</script><p><strong>二项分布</strong></p><script type="math/tex; mode=display">p(X=m|N,\mu)=\begin{pmatrix}N \\ m\end{pmatrix}\mu^m (1-\mu)^{N-m}</script><script type="math/tex; mode=display">\mathbb E[X]=N \mu</script><script type="math/tex; mode=display">\mathbb V[X]=N\mu(1-\mu)</script><p>二项分布可看作 $N$ 个独立的 Bernoulli 分布。</p><p><strong>Beta 分布</strong></p><p>Beta 分布中的随机变量范围为 $\mu \in [0, 1]$，</p><script type="math/tex; mode=display">\text{Beta}(\alpha, \beta) = p(\mu|\alpha, \beta)=\frac {\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \mu^{\alpha-1} (1-\mu)^{\beta-1}</script><script type="math/tex; mode=display">\mathbb E[\mu]=\frac {\alpha}{\alpha+\beta}</script><script type="math/tex; mode=display">\mathbb V[\mu]=\frac {\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}</script><p>其中，$\alpha, \beta &gt; 0$ 。Gamma 函数（连续情况的阶乘）满足</p><script type="math/tex; mode=display">\Gamma(t)=\int_0^{\infty} x^{t-1} \exp (-x) dx, \ t > 0</script><script type="math/tex; mode=display">\Gamma(t+1)=t\Gamma(t)</script><p>由于 $\mu \in [0, 1]$，我们可以将 $\mu$ 看作是某个 Bernoulli/Binomial 分布的参数，即 Bernoulli 分布的参数 $\mu$ 不再是一个确定不变的量，而是一个随机变量。</p><h2 id="2-1-共轭"><a href="#2-1-共轭" class="headerlink" title="2.1 共轭"></a>2.1 共轭</h2><p>贝叶斯定理：</p><script type="math/tex; mode=display">p(x|y)=\frac {p(x)p(y|x)} {p(y)}</script><p>其中 $x$ 可以是某隐变量（不可观察，例如 HMM 中的状态），而 $y$ 是可以直接观察的量。那么在给定观察 $y$ 的条件下，隐变量的后验分布 $p(x|y) \propto p(x) p(y|x)$，即正比于先验与似然的乘积。</p><p>如果后验分布与先验分布类型相同，那么称先验共轭于似然函数，即<strong>如果 $p(x)$ 与 $p(y|x)$ 共轭</strong> ，<br>那么 $p(x|y)$ 与 $p(x)$ 分布类型相同。</p><p><strong>Beta-Binomial共轭</strong></p><p>考虑一个二项分布，其参数 $\mu$ 未知，看作一个随机变量，对于 $\mu$，我们已知其先验，遵从 Beta 分布，</p><script type="math/tex; mode=display">p(\mu|\alpha, \beta)=\frac {\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \mu^{\alpha-1} (1-\mu)^{\beta-1}</script><p>现在执行 $N$ 次抛硬币试验，正面向上的次数为可观测量 $y$，且观测到 $y=h$，那么 $\mu$ 的后验概率为，</p><script type="math/tex; mode=display">\begin{aligned}p(\mu|y=h,N,\alpha,\beta) & \propto p(\mu|\alpha,\beta) p(y=h|\mu)\\& \propto \mu^h(1-\mu)^{N-h}\mu^{\alpha-1} (1-\mu)^{\beta-1}\\ &= \mu^{h+\alpha-1} (1-\mu)^{N-h+\beta-1}\\& \propto \text{Beta}(h+\alpha, N-h+\beta)\end{aligned}</script><p>即，后验与先验分布类型相同，均为 Beta 分布。</p><div class="table-container"><table><thead><tr><th>似然</th><th>共轭先验</th><th>后验</th></tr></thead><tbody><tr><td>Bernoulli</td><td>Beta</td><td>Beta</td></tr><tr><td>Binomial</td><td>Beta</td><td>Beta</td></tr><tr><td>Gaussian</td><td>Gaussian/inverse Gamma</td><td>Gaussian/inverse Gamma</td></tr><tr><td>Gaussian</td><td>Gaussian/inverse Wishart</td><td>Gaussian/inverse Wishart</td></tr><tr><td>Multinomial</td><td>Dirichlet</td><td>Dirichlet</td></tr></tbody></table></div><h2 id="2-2-充分统计量"><a href="#2-2-充分统计量" class="headerlink" title="2.2 充分统计量"></a>2.2 充分统计量</h2><p>包含了足够的可以表达分布信息的统计量。</p><h2 id="2-3-指数家族"><a href="#2-3-指数家族" class="headerlink" title="2.3 指数家族"></a>2.3 指数家族</h2><p>满足如下形式的分布</p><script type="math/tex; mode=display">p(\mathbf x|\boldsymbol \theta)=h(\mathbf x) \exp(\boldsymbol \theta^{\top} \boldsymbol \phi(\mathbf x)-A(\boldsymbol \theta))</script>]]></content>
      
      
      
        <tags>
            
            <tag> math </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性代数基本概念总结</title>
      <link href="/2022/02/10/math/linear_algebra_concepts/"/>
      <url>/2022/02/10/math/linear_algebra_concepts/</url>
      
        <content type="html"><![CDATA[<p>总结线性代数的常用知识点。<br><span id="more"></span></p><h1 id="1-解线性方程组"><a href="#1-解线性方程组" class="headerlink" title="1. 解线性方程组"></a>1. 解线性方程组</h1><p>形式如</p><script type="math/tex; mode=display">A\mathbf x = \mathbf b, \quad A \in \mathbb R^{m \times n}</script><p>解线性方程组之前先来了解几个概念。</p><p><strong>基本变换</strong></p><ol><li>交换两个等式位置（即，矩阵或增广矩阵的行）</li><li>对某个等式两边乘以一个非 0 常数</li><li>两个等式相加</li></ol><blockquote><p>基本变换不会改变线性方程组的解。</p></blockquote><p><strong>行阶梯矩阵</strong></p><p>满足：</p><ol><li>全零行在矩阵下方，非全零行（row 中存在 nonzero 元素）在矩阵上方</li><li>对非全零行而言，左侧起第一个 nonzero 元素称为 <code>pivot</code>，下方行 pivot 严格在上方行 pivot 的右侧。这里的“严格”表明不能在同一列。</li></ol><p><strong>基本/自由 变量</strong></p><p>行阶梯型矩阵中，pivot 对应的变量称为基本变量，其他变量称为自由变量。</p><p><strong>规约行阶梯矩阵</strong></p><p>满足：</p><ol><li>是行阶梯型矩阵</li><li>每个 pivot 值为 <code>1</code></li><li>pivot 是所在列唯一的 nonzero 元素</li></ol><p>举例说明，下方是一个规约行阶梯矩阵，粗体的 <code>1</code> 均为 pivot，没有其他 pivot 了，pivot 所在列的其他元素均为 <code>0</code>。</p><script type="math/tex; mode=display">A=\begin{bmatrix}\mathbf 1 & 3 & 0 & 0 & 3\\ 0 & 0 & \mathbf1 & 0 & 9\\ 0 & 0 & 0 & \mathbf 1 & -4\end{bmatrix}</script><p>规约行阶梯矩阵有利于解方程组。</p><p><strong>一个简单例子：</strong></p><p>例如齐次方程组 $A\mathbf x = \mathbf 0$，其中 $A$ 就是上面这个，那么展开得</p><script type="math/tex; mode=display">A_{:,1} x_1 +A_{:,2}x_2 + A_{:,3}x_3 +A_{:,4}x_4 + A_{:,5}x_5 = \mathbf 0 \tag{1}</script><p>由于 pivot 所在列已经是基本向量了，所以可用 pivot 列来表示非 pivot 列，</p><script type="math/tex; mode=display">\begin{aligned} A_{:,2}&=3A_{:,1}\\A_{:,5}&=3A_{:,1}+9A_{:,3}-4A_{:,4}\end{aligned}</script><p>移项得，</p><script type="math/tex; mode=display">\begin{aligned} 3A_{:,1}- A_{:,2}&=\mathbf 0\\3A_{:,1}+9A_{:,3}-4A_{:,4} -A_{:,5}&=\mathbf 0 \end{aligned} \tag{2}</script><p>上面方程组（2）的第一个等式的一个特殊解为 $\mathbf x=[3,-1,0,0,0]^{\top}$，一般解为 $\mathbf x=\lambda_1 [3,-1,0,0,0]^{\top}, \quad \lambda_1 \in \mathbb R$ 。</p><p>第二个等式的一个特殊解为 $\mathbf x=[3, 0, 9,-4,-1]^{\top}$，一般解为 $\mathbf x=\lambda_2 [3, 0, 9,-4,-1]^{\top}, \quad \lambda_2 \in \mathbb R$ 。</p><p>由于方程组 (2) 的两个等式均满足 (1) 式，故两个一般解均是 (1) 的解，于是最终的一般解为 </p><script type="math/tex; mode=display">\mathbf x = \lambda_1 \begin{bmatrix} 3 \\ 1 \\ 0 \\ 0 \\ 0 \end{bmatrix} + \lambda_2 \begin{bmatrix} 3 \\ 0 \\ 9 \\ -4 \\ -1 \end{bmatrix}, \quad \lambda_1, \lambda_2 \in \mathbb R</script><p><strong>高斯消除：</strong><br>使用 <strong>基本变换</strong> 将线性方程组转变为规约行阶梯型。</p><h1 id="2-几种算法"><a href="#2-几种算法" class="headerlink" title="2. 几种算法"></a>2. 几种算法</h1><ol><li>高斯消除法</li><li><p>求逆法</p><script type="math/tex; mode=display">A \mathbf x = \mathbf b \Rightarrow \mathbf x=A^{-1} \mathbf b</script><p> 这种方法要求 $A$ 可逆，否则，可以求 Moore-Penrose 逆，</p><script type="math/tex; mode=display">A \mathbf x = \mathbf b \Leftrightarrow A^{\top}A \mathbf x = A^{\top} \mathbf b \Leftrightarrow \mathbf x=(A^{\top}A)^{-1}A^{\top}\mathbf b</script></li><li><p>数值计算法</p><p> 实际应用中（例如未知数量达百万级别），上面 <code>1,2</code> 方法计算量都会特别大，此时可以采用数值计算法，通常是迭代计算，例如 Richardson 法，Jacobi 法，$Gau\beta-Seidel$ 法等。参见 《Stoer, Josef, and Burlirsch, Roland. 2002. Introduction to Numerical Analysis. Springer.》，《Strang, Gilbert. 2003. Introduction to Linear Algebra. Wellesley-Cambridge Press》。</p></li></ol><h1 id="3-向量空间"><a href="#3-向量空间" class="headerlink" title="3. 向量空间"></a>3. 向量空间</h1><p>向量空间 $V$ 的相关概念这里不再列出。</p><h2 id="3-1-rank"><a href="#3-1-rank" class="headerlink" title="3.1 rank"></a>3.1 rank</h2><p>矩阵的秩的一些重要性质</p><p>假设 $A \in \mathbb R^{m \times n}, \ \mathbf b \in \mathbb R^m$，</p><ol><li><p>$A \mathbf x=\mathbf b$ 有解 $\Leftrightarrow rk(A)=rk(A|\mathbf b)$</p><p>$A$ 的行阶梯型与 $A|\mathbf b$ 的行阶梯型，下方具有相同数量的全零行（ <code>0</code> 个全零行或更多），才能有解。这很好理解，否则会出现 $0 \neq 0$，矛盾</p></li><li><p>满足 $A\mathbf x=\mathbf 0$ 的解构成 $A$ 的 kernel，记为 $K$ ；所有满足 $\mathbf b=A\mathbf x, \ \forall \mathbf x \in \mathbb R^n$ 的 $\mathbf b$ 向量 构成 $A$ 的 image，记为 $U$。有以下关系，</p><script type="math/tex; mode=display">dim(U) = rk(A), \ dim(K) + rk(A)= n</script></li></ol><h2 id="3-2-线性映射的矩阵表示"><a href="#3-2-线性映射的矩阵表示" class="headerlink" title="3.2 线性映射的矩阵表示"></a>3.2 线性映射的矩阵表示</h2><p>两个向量空间 $V,W$，基向量分别为 $B=(\mathbf b_1,\ldots, \mathbf b_n), C=(\mathbf c_1, \ldots, \mathbf c_m)$，考虑一个线性变换 $\Phi:V\rightarrow W$，那么对 $j \in \{1,\ldots, n\}$，</p><script type="math/tex; mode=display">\Phi(\mathbf b_j)=\sum_{i=1}^m a_{ij} \mathbf c_i</script><p>那么 $\Phi$ 对应的转换矩阵为 $A_{\Phi}$，满足 $A_{\Phi}(i,j)=a_{ij}$。</p><p>$\Phi(\mathbf b_j)$ 在 $W$ 空间中，其关于向量基 $C$ 的坐标为 $A_{\Phi}$ 的第 $j$ 列，也就是说，线性变换 $\Phi$ 将 $\mathbf b_j$ 变换到 $A_{\Phi}$ 第 <code>j</code> 列坐标（所表示的向量）。</p><p>对于 $\mathbf x \in V$ ，其坐标记作 $\mathbf {\hat x}$（除特别说明，$V$ 中向量坐标均基于 $B$，$W$ 中向量坐标均基于 $C$），其线性变换结果为 $\mathbf y=\Phi(\mathbf x)$，位于 $W$ 中，坐标记为 $\mathbf {\hat y}$，那么根据定义，</p><script type="math/tex; mode=display">\begin{aligned}\mathbf y=\Phi(\mathbf x)&=\Phi(B\mathbf {\hat x})\\&=\Phi\left(\sum_{j=1}^n \mathbf b_j \hat x_j\right)\\&=\sum_{j=1}^n \Phi(\mathbf b_j \hat x_j)\\&=\sum_{j=1}^n \Phi(\mathbf b_j) \hat x_j\\&=\sum_{j=1}^n \sum_{i=1}^m a_{ij} \mathbf c_i \hat x_j\\&=\sum_{i=1}^m [A_{\Phi}(i,:) \mathbf {\hat x}] \mathbf c_i\end{aligned}</script><p>其中 $A_{\Phi}(i,:)$ 表示矩阵 $A_{\Phi}$ 的第 <code>i</code> 行。用坐标表示则为，</p><script type="math/tex; mode=display">\mathbf {\hat y}=A_{\Phi} \mathbf {\hat x}</script><p><strong>Rank-Nullity 定理</strong></p><script type="math/tex; mode=display">dim(ker(\Phi))+dim(Im(\Phi))=dim(V)</script><h2 id="3-3-解析几何"><a href="#3-3-解析几何" class="headerlink" title="3.3 解析几何"></a>3.3 解析几何</h2><p><strong>对称/正定 矩阵</strong></p><p><strong>对称：</strong> $A=A^{\top}$</p><p><strong>正定：</strong> $\mathbf x^{\top} A \mathbf x &gt; 0, \ \forall \mathbf x \in V \setminus {\mathbf 0}$</p><p>对称正定矩阵 $A$ 的性质：</p><ol><li>$A$ 的 kernel 为 $\{\mathbf 0\}$</li><li>$A$ 的主对角线元素 $a_{ii} &gt; 0$，因为 $a_{ii}=\mathbf e_i^{\top} A \mathbf e_i &gt; 0$</li></ol><p><strong>正交矩阵</strong></p><p>$A \in \mathbf R^{n \times n}$ 是正交矩阵，当且仅当其列向量是正交归一向量。</p><p>正交矩阵性质：</p><ol><li>$AA^{\top}=I=A^{\top}A$</li><li><p>$A^{-1}=A^{\top}$</p></li><li><p>正交矩阵所表示的映射 $\Phi$ 不会改变 $\mathbf x$ 的长度</p></li><li>$\mathbf x, \mathbf y$ 的夹角等于 $\Phi(\mathbf x), \Phi(\mathbf y)$ 的夹角</li></ol><p><strong>投影</strong></p><p>$U \subseteq V$ 是两个空间，映射 $\pi: V \rightarrow U$ 称为投影，如果 $\pi^2 = \pi \circ \pi = \pi$</p><p>令矩阵 $P_{\pi}$ 表示投影 $\pi$，那么 $P_{\pi}^2=P_{\pi}$</p><h2 id="3-4-矩阵"><a href="#3-4-矩阵" class="headerlink" title="3.4 矩阵"></a>3.4 矩阵</h2><p><strong>行列式</strong></p><p>性质：</p><ol><li>$det(AB)=det(A) \cdot det(B)$</li><li>$det(A)=det(A^{\top})$</li><li>$A$ 可逆，那么 $det(A^{-1})=1/ det(A)$</li><li>将某行（列）乘上一个常数，再加到零一行（列）上，不改变行列式值</li><li>某行（列）乘上一个常数 $\lambda$，行列式值也变成原来的 $\lambda$ 倍</li><li>交行两行（列）改变行列式符号（正负性）</li></ol><p>根据最后三条性质，可以将 $A$ 通过高斯消除变成行阶梯型，从而求 $det(A)$</p><p><strong>迹（trace）</strong></p><p>矩阵 $A \in \mathbb R^{n \times n}$ 的 trace 定义为</p><script type="math/tex; mode=display">tr(A):=\sum_{i=1}^n a_{ii}</script><p>性质：</p><ol><li>$tr(A+B)=tr(A)+tr(B)$，其中 $A, B \in \mathbb R^{n \times n}$</li><li>$tr(\alpha A)=\alpha \cdot tr(A)$，其中 $\alpha \in \mathbb R$</li><li><p>$tr(AB)=tr(BA)$，其中 $A \in \mathbb R^{n \times k}, \ B \in \mathbb R^{k \times n}$</p><p> 根据第 <code>3</code> 条性质，可知 $tr(ABC)=tr(CAB)=tr(BCA)$，推广到更一般的情况，有性质 <code>4</code>。</p></li><li><p>m 个矩阵相乘，循环轮转矩阵位置，其乘积矩阵的 trace 保持不变</p></li><li><p>线性映射 $\Phi$ 对于不同的 $V$ 空间的基向量组，其有不同的矩阵表示，但是这些矩阵的 trace 均相同</p><p> 例如 $\Phi$ 在 $V$ 的某一个基向量组下的矩阵表示记为 $A$，在 $V$ 的另一个基向量组下的矩阵表示记为 $B$，那么一定可以找到 $S$，使得 $B=S^{-1}A S$（<font color='magenta'>这样的 $A,B$ 称为相似矩阵</font>），于是</p><pre><code> $$tr(B)=tr(S^&#123;-1&#125;AS)=tr(ASS^&#123;-1&#125;)=tr(A)$$</code></pre></li></ol><p><strong>特征多项式</strong></p><script type="math/tex; mode=display">\begin{aligned}p_{A}(\lambda) &:= det(A-\lambda I)\\ &=c_0+c_1 \lambda + \cdots + c_{n-1} \lambda ^{n-1}+(-1)^n \lambda ^n\end{aligned}</script><p>第二个等式是使用 Laplace 展开，其中</p><script type="math/tex; mode=display">c_0=det(A)\\c_{n-1}=(-1)^{n-1} tr(A)</script><p><strong>特征值与特征向量</strong></p><script type="math/tex; mode=display">A\mathbf x = \lambda \mathbf x</script><p>其中 $\lambda \in \mathbb R$，且 $\mathbf x \neq \mathbf 0$。</p><p>性质：</p><ol><li><p>$rk(A-\lambda I_n) &lt; n$</p><script type="math/tex; mode=display">A\mathbf x = \lambda \mathbf x \Leftrightarrow (A-\lambda I_n) \mathbf x=\mathbf 0 \Leftrightarrow ker(A-\lambda I_n) \neq \{\mathbf 0\}</script></li><li>$det(A-\lambda I_n)=0$</li><li>$A$ 的特征值 $\lambda$ 也是其特征多项式 $p_{A}(\lambda)$ 的根（root）</li><li><p>$p_{A}(\lambda)$ 的 root 出现的次数就是对应特征值的<strong>代数重数</strong></p><p> 例如多项式有一个 二重根 $\lambda_i$，那么特征值 $\lambda_i$ 的代数重数就是 <code>2</code>。</p></li><li><p>$A$ 与 $A^{\top}$ 的特征值均相同，但是对应的特征向量不一定相同</p></li><li>特征空间 $E_{\lambda}$ 是 $A-\lambda I$ 的 kernel 空间</li><li>相似矩阵有相同的特征值</li><li><font color="red">对阵正定矩阵的特征值是正实数</font><script type="math/tex; mode=display">\mathbf x^{\top}A\mathbf x>0 \Leftrightarrow \mathbf x^{\top} \lambda \mathbf x>0 \Leftrightarrow \lambda > 0</script></li><li><p>$A$ 的一个特征值 $\lambda_i$ 所关联的特征空间的维度就是其<strong>几何重数</strong></p><p> 几何重数不能大于代数重数，但是可能会小于代数重数。例如，</p><script type="math/tex; mode=display">A=\begin{bmatrix}2 & 1 \\ 0 & 2 \end{bmatrix}</script><p> 特征值 $\lambda_1=\lambda_2=2$，代数重数为 <code>2</code>，但是只有一个特征向量（线性相关的其他向量不算）$\mathbf x_1=[1, 0]^{\top}$，故几何重数为 <code>1</code>。</p></li><li>$det(A)=\prod_{i=1}^n \lambda_i$，其中 $\lambda_i \in \mathbb C$ 是 $A$ 特征值（可能有重复）。</li><li>$tr(A)=\sum_{i=1}^n \lambda_i$，其中 $\lambda_i \in \mathbb C$ 是 $A$ 特征值（可能有重复）。</li></ol><font color="red">**重要定理：**</font><p>给定 $A \in \mathbf R^{m \times n}$，那么 $S:=A^{\top}A$ 是对称半正定矩阵。如果 $rk(A)=n$，那么 $S$ 是对称正定矩阵，即 <font color="red">满秩的且对角线元素值为正的对称矩阵是正定的</font>。</p><p>对称是显而易见的。</p><ol><li><p>证明半正定性，</p><script type="math/tex; mode=display">\mathbf x^{\top}S\mathbf x=\mathbf x^{\top}A^{\top}A\mathbf x\Leftrightarrow \mathbf y^{\top}\mathbf y \ge 0</script><p> 其中，$\mathbf y= A \mathbf x \in \mathbb R^{m\times 1}$</p></li><li><p>证明正定性，</p><p> $rk(A)=n \Rightarrow m\ge n$，$A$ 所有 $n$ 个列均线性无关，那么对 $\forall \mathbf x \in \mathbb R^n \setminus \mathbf 0$，均有 $\mathbf y = [A_1,\ldots, A_n]\mathbf x \neq \mathbf 0$，其中 $A_j$ 表示第 <code>j</code> 列，故 $\mathbf y^{\top}\mathbf y&gt; 0$，证毕。</p><p> 另外，如果 $rk(A)&lt;n$，即 $A$ 的所有列线性相关，那么存在 $j \in [0,n]$，使得 $A_j=\sum_{k\neq j} \lambda_k A_k$，故存在 $\mathbf x=[\lambda_1,\ldots, \lambda_{j-1}, -1, \lambda_{j+1}, \ldots, \lambda_n]^{\top} \neq \mathbf 0$，使得 $\mathbf y=[A_1,\ldots, A_n]\mathbf x=\mathbf 0$，故 $S$ 非正定。</p></li></ol><font color="red">**Spectral Theorem：**</font><p>若 $A \in \mathbb R^{n \times n}$ 对称，则 $A$ 的特征值均为实数，且 $A$ 的特征向量为空间 $V$ 的正交归一基（ONB）。</p><p>这表明对称方阵 $A$ 可以做特征分解。</p><h2 id="3-5-矩阵分解"><a href="#3-5-矩阵分解" class="headerlink" title="3.5 矩阵分解"></a>3.5 矩阵分解</h2><p><strong>Cholesky 分解</strong></p><p>对称正定矩阵 $A$ 可以被唯一地分解为 $A=LL^{\top}$，其中 $L$ 是下三角矩阵，且对角线元素值均为正。</p><p>Cholesky 分解可以类比正实数的求平方根。</p><p><strong>可对角化：</strong> 若方阵 $A$ 可写成 $D=P^{-1}AP$，那么 $A$ 是可对角化的。对称方阵 $S$ 总是可对角化（结合 Spectral theorem 和特征分解的定义可证）。</p><p><strong>特征分解</strong></p><p>方阵 $A$ 可被写成 $A=PDP^{-1}$，其中，$D$ 是 $A$ 的特征值组成的对角阵，这个过程称为特征分解。</p><p>$A$ 可被特征分解的充要条件：$A$ 的特征向量可构成 $V$ 空间的一组基（注意不能得出 $det(A) \neq 0$ 的结论），这表明，<strong>对称方阵可以特征分解</strong>。</p><p><strong>SVD</strong></p><p>任意矩阵 $A^{m \times n}$ 均可被奇异值分解为</p><script type="math/tex; mode=display">A=U \Sigma V^{\top}</script><p>其中，$U \in \mathbb R^{m \times m}$ 和 $V \in \mathbb R^{n \times n}$ 是正交矩阵（正交归一列向量），$\Sigma$ 是 $m \times n$ 的矩阵，且 $\Sigma_{ii} = \sigma_i \ge 0$，$\Sigma_{ij}=0, \ i\neq j$。</p><p>注：正交矩阵 $M$ 满足 $M^{\top}=M^{-1}$</p><p><strong>矩阵近似</strong></p><p>对于矩阵 $A \in \mathbb R^{m \times n}$，构建 rank=1 的 $A_i \in \mathbb R^{m\times n}$ 如下：</p><script type="math/tex; mode=display">A_i := \mathbf u_i \mathbf v_i^{\top}</script><p>其中 $\mathbf u_i, \mathbf v_i$ 分别来自 $U, V$ 中的列向量。根据 SVD 为 $A=U\Sigma V^{\top}$，可知</p><script type="math/tex; mode=display">A=\sum_{i=1}^r \sigma_i \mathbf u_i \mathbf v_i^{\top}=\sum_{i=1}^r \sigma_i A_i</script><p>其中，$rk(A)=r$，$\sigma_i$ 为第 <code>i</code> 个奇异值。</p><p>如果我们将奇异值排序，并取 top <code>k</code> （$k &lt; r$）的这样的 rank=1 的 $A_1,\ldots, A_k$，那么有 $A$ 的近似，</p><script type="math/tex; mode=display">\hat A(k)=\sum_{i=1}^k \sigma_i A_i</script><p>且 $rk(\hat A(k))=k$ 。</p><p><strong>应用</strong></p><p>一幅（灰度）图片（彩色图片可以看作是 r b g 三个灰度图片），height width 为 <code>1432, 1910</code>，那么需要存储 $1432 \times 1910=2735120$ 个数，如果使用上述 SVD 的近似，例如取 <code>k=5</code>，那么仅需存储 $5$ 个特征值，以及 5 个左奇异向量和 5 个右奇异向量，共 $5(1432+1910+1)=16715$ 个数，存储量大大降低。<a href="https://gist.github.com/JianjianSha/9e76411bd4a5570c1363c7c3bcc3900c">参见代码</a></p><p>为什么使用 top <code>k</code> 最大绝对值的奇异值呢？</p><p><strong>光谱范数</strong></p><p>Spectral Norm</p><p>对于 $\mathbf x \neq \mathbf 0$，矩阵 $A \in \mathbb R^{m \times n}$ 的光谱范数定义为：</p><script type="math/tex; mode=display">||A||_2:=\max_{\mathbf x} \frac {||A\mathbf x||_2}{||\mathbf x||_2}</script><p>即，向量经过 $A$ 变换后，长度 scale 比例最大值，这个最大值是 $A$ 的最大奇异值 $\sigma_1$ 。</p>]]></content>
      
      
      
        <tags>
            
            <tag> math </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速风格迁移</title>
      <link href="/2022/02/07/style_transfer/Fast_Neural_Style/"/>
      <url>/2022/02/07/style_transfer/Fast_Neural_Style/</url>
      
        <content type="html"><![CDATA[<p>快速风格迁移(fast stype transfer)论文总结。<br><span id="more"></span><br>论文：<a href="https://arxiv.org/abs/1603.08155">Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a></p><p>补充材料：<a href="https://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf">fast-style-supp</a></p><h1 id="1-网络"><a href="#1-网络" class="headerlink" title="1. 网络"></a>1. 网络</h1><p>风格迁移中，有两类图片，一类是风格图片，例如艺术家的作品，另一类是内容图片，例如照片，利用风格迁移将内容图像转换为具有艺术家风格的图片。</p><p>如图 1，<br><img src="/images/style_transfer/Fast_Neural_Style_1.png" alt=""></p><p>图 1</p><p>网络由两部分组成：</p><ol><li><p>一个图像转换网络</p><p> 这是一个 deep residual CNN，其网络参数记为 $W$，将输入图像 $x$ 转换为输出图像 $\hat y$，记 $\hat y = f_W(x)$</p></li><li><p>一个用于计算损失的网络</p><p> 这个网络是一个已经用图像分类数据集预训练好的 CNN 网络，在风格迁移的训练中，固定这个网络（其参数保持不变）。将此网络记为 $\phi$。$\phi$ 计算图像转换网络的输出 $\hat y$ 与目标图像 $y_i$ 之间的损失 $l_i(\hat y, y_i)$，$y_i$ 包括内容图像和风格图像，分别记为 $y_c$ 和 $y_s$。利用损失最小化来训练图像转换网络 $f_W$，</p><script type="math/tex; mode=display">W^{\star}=\arg \min_W \mathbf E_x,\{y_i\} \left[\sum_{i=1} \lambda_i l_i(f_W(x), y_i)\right]</script><p> 风格迁移任务中，输入图像 $x$ 就是内容图像 $x=y_c$。</p></li></ol><h2 id="1-1-图像转换网络"><a href="#1-1-图像转换网络" class="headerlink" title="1.1 图像转换网络"></a>1.1 图像转换网络</h2><p><img src="/images/style_transfer/Fast_Neural_Style_2.png" alt=""></p><p>图 2. 风格迁移中的图像转换网络结构</p><ol><li>输入图像大小为 $3 \times 256 \times 256$，size 默认形式为 <code>channels, height, width</code>。</li><li>包含 <code>5</code> 个 residual blocks。</li><li><p>对于 non-residual 中的 conv，除最后一个 output 层的 conv 之外，conv 的具体形式为 <code>Conv-InstNorm-ReLU</code>，最后一个 conv 的展开为 <code>Conv-InstNorm-ScaledTanh</code>，即，先激活到 <code>[-1,1]</code>之间，然后 scale 到 <code>[0,255]</code> 之间。</p><p> （然而很多代码中直接使用 <code>Conv</code> 作为 output 层的 conv，可能是认为，前面每个 layer 均有 normalization 操作，所以特征均在一个区间范围内，最后一个 <code>Conv</code> 通过训练其参数，能使得最终输出位于（或几乎位于） [0,255] 内。）</p></li><li>第一个和最后一个 <code>conv</code> 使用 <code>9x9</code> 卷积核，其他 <code>conv</code> 使用 <code>3x3</code> 卷积核。</li><li>使用 strided conv 和 fractionally strided conv 作为下采样和上采样。实际实现中，不使用 ConvTransposed2d，这样会出现 Checkerboard Artifacts 现象，而是先 upsample（双线性插值），然后在使用 Conv。</li></ol><h2 id="1-2-Perceptual-Loss-Functions"><a href="#1-2-Perceptual-Loss-Functions" class="headerlink" title="1.2 Perceptual Loss Functions"></a>1.2 Perceptual Loss Functions</h2><ol><li>$\phi$ 网络的初始输入图像需要经过处理：<script type="math/tex; mode=display">y:= (y-mean)/std</script> 其中 $y$ 为输出图像或 target 图像，位于 [0,255]，mean 为三通道的像素均值（对彩色图像而言），std 为三通道的像素方差。有的 implementation 中，没有使用 std，即 $y:=y-mean$ 。</li></ol><p>Perceptual Loss 用于测量两个图像的高层感知和语义上的差异（与此相对的是图像的 per-pixel 差异）。</p><p>本文采用 VGG-16 作为 $\phi$ 网络，在 ImageNet 上进行预训练，然后固定 $\phi$。</p><p><strong>特征重建损失</strong></p><p>图像转换网络的输出 $\hat y$ 与内容图像 $y_c$ 之间的损失。</p><p>如图 1，记 $\phi_j(x)$ 为网络 $\phi$ 的第 <code>j</code> 个 layer 的输出值（激活值），记其 size 为 $C_j \times H_j \times W_j$，那么特征重建损失为两个图像在这一层的输出特征的欧氏距离，</p><script type="math/tex; mode=display">l_{feat}^{\phi,j} (\hat y, y)=\frac 1 {C_j H_j W_j} ||\phi_j(\hat y)-\phi_j(y)||_2^2</script><p>作者实验表明：</p><ol><li>最小化 $\phi$ 低层特征重建损失，利于生成图像 $\hat y$ ，使得与原内容图像 $y$ 视觉差异较小。</li><li>最小化 $\phi$ 高层特征重建损失，图像内容以及整个空间结构得以保持，但是颜色纹理以及精确形状均有所改变。这正是风格迁移所需要的特性。</li></ol><p><strong>风格重建损失</strong></p><p>这个损失着重对生成图像 $\hat y$ 与风格图像在风格：颜色，纹理以及一些通用模式上的差异进行惩罚。</p><p>对于 $\phi$ 的第 <code>j</code> 层输出 $\phi_j(x)$，其 size 依然记为 $C_j \times H_j \times W_j$，定义 Gram matrix $G_j^{\phi}(x) \in \mathbb R^{C_j \times C_j}$，定义 Gram matrix 的元素，</p><script type="math/tex; mode=display">G_j^{\phi}(x)_{c, c'}=\frac 1 {C_jH_jW_j}\sum_{h=1}^{H_j}\sum_{w=1}^{W_j} \phi_j(x)_{h,w,c} \phi_j(x)_{h,w,c'}</script><p>如果将 $\phi_j(x)$ 看作是 $H_j \times W_j$ 大小的 grid 上所有点的 $C_j$ 维特征，那么 $G_j^{\phi}(x)$ 正比于 $C_j$ 维特征的非中心协方差（类比，两个 $C_j$ 维随机向量 $X, Y$，这里 grid 上所有点的取值构成随机向量的分布，非中心协方差为 $\mathbb E[XY]$） 。</p><p>计算 Gram matrix：将特征 $\phi_j(x)$ reshape 为 $\psi \in \mathbb R^{C_j \times H_jW_j}$，于是</p><script type="math/tex; mode=display">G_j^{\phi}(x) = \psi \psi^{\top} / C_jH_jW_j</script><p>风格重建损失为两个图像特征的 Gram matrix 之差的 F 范数，</p><script type="math/tex; mode=display">l_{style}^{\phi,j}(\hat y, y)= ||G_j^{\phi}(\hat y) - G_j^{\phi}(y)||_F^2</script><p><strong>即使 $\hat y$ 和 $y$ 的 size 不同，风格重建损失也是可以计算的。因为两者的特征 $\phi_j(\hat y)$ 和 $\phi_j(y)$ 具有相同的 channel $C_j$，故两者的 Gram matrices 具有相同的 size。</strong></p><p>最小化风格重建损失有助于保留风格特征，但是不保留空间形状。</p><p>从一组 layers $J$ 而非单个 layer $j$ 中重建风格，定义 $l_{style}^{\phi, J}(\hat y, y)$ 为这组 layers 中单个 layer  $j \in J$ 的风格重建损失之和。</p><h2 id="1-3-Simple-Loss"><a href="#1-3-Simple-Loss" class="headerlink" title="1.3 Simple Loss"></a>1.3 Simple Loss</h2><p><strong>Pixel Loss</strong></p><script type="math/tex; mode=display">l_{pixel}(\hat y, y)= ||\hat y - y||_2^2 / CHW</script><p>Pixel loss 为图像像素（展开为长向量）的归一化欧式距离，其中 $C,H,W$ 表示 <code>channel, height, width</code>。</p><p><strong>Total Variation Regularization</strong></p><p>这个损失是为了图像空间更加平滑，</p><p>total variation（TV）function 离散形式如下：</p><script type="math/tex; mode=display">l_{TV}(\mathbf x)=\frac 1 {CHW}\sum_{i,j} [(x_{i,j+1}-x_{i,j})^2+(x_{i+1,j-x_{i,j}})^2]^{\beta/2}</script><p>当 $\beta=1$ 时为 TV regularizer。</p><h1 id="2-风格迁移"><a href="#2-风格迁移" class="headerlink" title="2. 风格迁移"></a>2. 风格迁移</h1><p>风格迁移是使得图像转换网络的输出满足</p><script type="math/tex; mode=display">\hat y = \arg \min_y \lambda_c l_{feat}^{\phi, j}(y, y_c)+\lambda_s l_{style}^{\phi,J}(y, y_s) + \lambda_{TV}l_{TV}(y)</script><p>图像转换网络训练细节：</p><ol><li>使用 COCO 数据集，将 80k 训练图片 resize 到 $256\times 256$ 大小</li><li>batch size 取 <code>4</code></li><li>优化方法为 <code>Adam</code>，学习率为 $1\times 10^{-3}$</li><li>$\phi$ 使用 <code>VGG-16</code></li><li>特征重建使用 <code>relu2_2</code> 的输出</li><li>风格重建使用 <code>relu1_2</code>，<code>relu2_2</code>，<code>relu3_3</code> 以及 <code>relu4_3</code> 的输出。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 风格迁移 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> style transfer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention</title>
      <link href="/2022/01/25/pytorch/attention/"/>
      <url>/2022/01/25/pytorch/attention/</url>
      
        <content type="html"><![CDATA[<p>相关论文：<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p><p><a href="/transformer/2022/01/17/transformer/self_attention">论文解读</a></p><h1 id="1-流程简介"><a href="#1-流程简介" class="headerlink" title="1. 流程简介"></a>1. 流程简介</h1><p>为了方便理解，这里我简洁地进行总结。以机器翻译任务为例说明。</p><p>将 multi-head self-attention 简记为 mh self-attn</p><h2 id="1-1-Encoder"><a href="#1-1-Encoder" class="headerlink" title="1.1 Encoder"></a>1.1 Encoder</h2><p>输入预处理：</p><ol><li>输入 shape 按 <code>(batch_size, seq_len)</code> 的顺序，记为 <code>(B, L)</code>，input 中各元素表示 word 的 index，index 范围为 <code>[0, V]</code>，其中 <code>0</code> 表示 <code>&lt;pad_tok&gt;</code>，<code>V</code> 表示词汇表大小。</li><li>heads 数量为 <code>n</code>，模型维度为 <code>d</code>，每个 head 的维度为 $d/n$ </li><li>输入 tensor 经 embedding 转化为 input embedding，其 shape 为 <code>(B, L, d)</code>，embedding 参数矩阵维度为 <code>(V+1, d)</code></li><li>叠加 position embedding，故叠加后 shape 相同，仍为 <code>(B, L, d)</code>。</li></ol><p>mh self-attn 过程：</p><ol><li>input embedding 使用参数矩阵 $W^Q \in \mathbb R^{d \times d}$，得到 <code>query</code> 数据，记为 $Q$，其 shape 为 $(B, L, d)$。</li><li><p>input embedding 分别使用参数矩阵 $W^K \in \mathbb R^{d \times d_k}$，$W^V \in \mathbb R^{d \times d_v}$，线性转换为 <code>key</code> 和 <code>value</code>，记为 $K, \ V$，其 shape 分别为 $(B, L, d_k), \ (B, L, d_v)$。</p></li><li><p>$Q, K ,V$ 的最后一维，实际上是 <code>n</code> 个 heads concatenate 的结果，可以 <code>Q1=Q.view(B, L, n, d/n)</code>，<code>K1=K.view(B, L, n, d_k/n)</code>， <code>V1=V.view(B, L, n, d_v/n)</code>。</p></li><li>执行 attention 操作，$A_i=Q_iK_i^{\top}, \ i=1,2,…,n$，注意这里是每个 head 内部进行 atention 操作，由于 attention 涉及到 <code>L</code> 和 最后一维，为了方便矩阵计算，进行以下维度调整， <code>Q1.permute(0,2,1,3)</code>，使得 shape 变为 <code>(B, n, L, d/n)</code>，$K$ 进行同样的维度调整，为 <code>(B,n,L,d_k/n)</code>，通常 $d_k=d$，然后计算 attention tensor，其 shape 为 $(B,n,L,L)$</li><li>对 attention 做 softmax 进行归一化，结果记为 $\hat A$</li><li>使用 attention 作为权重，加权求和输出，这个步骤依然是每个 heads 内部进行，<code>V1.permute(0, 2, 1, 3)</code>，调整维度顺序变为 <code>(B,n,L,d_v/n)</code>，然后就可以执行矩阵乘法 $\hat A_i V_i$，得到的 n 个 heads 的输出 tensor，记为 $O$，其 shape 为 $(B,n,L,d_v/n)$</li><li>然后再调整维度顺序，使得 shape 变为 $(B, L, d_v)$ <pre class="line-numbers language-python" data-language="python"><code class="language-python">O<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span>L<span class="token punctuation">,</span> d_v<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>最后使用一个线性变换，参数矩阵 $W^O \in \mathbb R{d_v \times d}$，将上一步结果映射为 $OW^O$，其 shape 为 $(B, L, d)$</p></li><li><p>FFN 就不详细介绍了。 将第 <code>8</code> 步中的输出作为 input embedding，循环执行 <code>1~8</code> 步 <code>N-1</code> 次，最终得到输出的 shape 依然是 $(B, L, d)$</p></li></ol><p>注：</p><ol><li>$d_k \equiv d$，这样才能执行向量内积 $\mathbf q_i \mathbf k_i$，或者矩阵相乘 $Q_iK_i^{\top}$，但是 <code>MultiheadAttention</code> 构造函数中用到了表示 $d_k$ 的参数 <code>kdim</code>，难道还能 $d_k \neq d$？不理解。</li></ol><p><strong>Image 相关任务如目标检测，分割等</strong></p><p>_Image 经过 backbone 得到特征 <code>features</code>，其 shape 为 $(B, C, H, W)$，通过一个 <code>1x1 Conv</code>，将维度 <code>C</code> 调整为模型维度 <code>d</code>，然后再 <code>features.view(B, d, HW).permute(0, 2, 1)</code>，使得顺序为 <code>(batch_size, seq_len, feature_dim)</code>。但是图像任务中，Transformer 结构稍有不同，具体参考论文 <a href="">DETR</a>，以及我的文章 <a href="">detr 解读</a>_</p><h2 id="2-2-Decoder"><a href="#2-2-Decoder" class="headerlink" title="2.2 Decoder"></a>2.2 Decoder</h2><p>Encoder 中的 <code>N</code> 个循环的 Block 中，每个 Block 均由一个 mh self-attn 和一个 FFN 构成，而 Decoder 中对应的 Block 则是两个 mh self-attn 和一个 FFN 构成。</p><p>Decoder 输入的预处理部分：</p><ol><li>输入 shape 为 <code>(B, L)</code>，这里 <code>seq_len</code> 为 $L$，与 Encoder 中的 <code>L</code> 可能不相等，输入 tensor 中各元素表示 word index，通过线性变换转为 embedding，其 shape 为 <code>(B, L, d)</code>。</li><li>叠加 position embedding，shape 不变。</li><li>将 input embedding 分别线性变换为 $Q, K, V$，shape 均为 $(B, L, d)$，作为第一个 mh self-attn 的 <code>query</code>，<code>key</code>，<code>value</code>。第一个 mh self-attn 的输出 shape 保持不变，为 $(B,L,d)$</li><li>第一个 mh self-attn 输出作为第二个 mh self-attn 的 <code>query</code>，而 Encoder 最终（<code>N</code> 次循环之后）的输出 <code>src_enc</code>，作为第二个 mh self-attn 的 <code>key</code> 和 <code>value</code>，这两个变量的 shape 均为 $(B, S, d)$，注意与 <code>query</code> 具有不同的 shape，且将 Encoder 输出 shape 中的 <code>seq_len</code> 记为 $S$ 。</li><li>根据 $A=QK^{\top}$ 可知，attention 矩阵维度为 $L \times S$，故第二个 mh self-attn 的输出 $\hat A V$ 的维度为 $(B, L, d)$。</li><li>FFN 结构略。Decoder 中 block（两个 mh self-attn 和一个 FFN）的输出 shape 为 $(B, L, d)$。</li><li>第 <code>6</code> 步的输出作为 input embedding，循环步骤 <code>3~6</code> 若干次，得到最终的输出。</li><li>使用线性变换将上一步的输出 $(B, L, d)$ 变为 $(B, L, V+1)$，然后执行 Softmax 分类。</li></ol><p>构造函数参数：</p><ol><li><code>embed_dim</code>： 模型维度，通常指 <code>query</code> 变量的最后一维的大小。</li><li><code>num_heads</code>：multi-head 中 heads 数量</li><li><code>dropout</code>：防止过拟合，丢弃率。</li><li><code>bias</code>：是否对线性变换 (nn.Linear) 增加偏置。</li><li><code>kdim</code>： <code>key</code> 的最后一维大小，默认为 <code>embed_dim</code></li><li><code>vdim</code>： <code>value</code> 的最后一维大小，默认为 <code>embed_dim</code></li><li><code>batch_first</code>：True，那么维度顺序为 <code>(batch_size, seq_len, feat_dim)</code>，否则为 <code>(seq_len, batch_size, feat_dim)</code>。</li></ol><p>前向传播参数：</p><ol><li><code>query</code>：$(B, L, d)$</li><li><code>key</code>：  $(B, S, d)$</li><li><p><code>value</code>：$(B, S, d)$</p></li><li><p><code>key_padding_mask</code>：$(B, S)$，对 <code>key</code> 做 mask。</p><p> attention 中，对 <code>query</code> 中的每个部分（mini-batch 中单个 instance，query 一共有 $L$ 个部分）对 $S$ 个 key 做 attention，但是有时候由于 sequence 长度不够而进行 padding，或者 autoregression 中预测是 one-by-one 的，所以无法对后面的 <code>key</code> 的部分做 attention，这两种情况下，都需要对 <code>key</code> 做 mask。</p></li><li><p><code>need_weights</code>：True，返回 attention 权重矩阵 $\hat A$，否则不返回。</p></li><li><p><code>attn_mask</code>：指定 对 attention 做 mask。shape 为 $(L, S)$ 或者 $(B \cdot n, L, S)$</p><p> 由于 $A_i =Q_i K_i^{\top} \in \mathbb R^{L \times S}$，所以 mask shape 为 $(L, S)$ ，表示 mini-batch 中 $B \cdot n$ 个 heads 均使用相同的 mask；如果为 $(B \cdot n, L, S)$，那么为  mini-batch 中 $B \cdot n$ 个 heads 分别指定 mask。</p></li></ol><p>前向传播输出参数：</p><ol><li><code>attn_output</code>：attention 的输出，shape 为 $(B, L, d)$，其中 $d$ 为模型维度。</li><li><code>attn_output_weights</code>：attention 权重参数 $\hat A$，shape 为 $(B,L, S)$。<br> 由于 multi-head，本来 weights shape 应该为 $(B, n,L, S)$，沿着 <code>dim=1</code> 求均值。</li></ol><h1 id="2-代码"><a href="#2-代码" class="headerlink" title="2. 代码"></a>2. 代码</h1><p>Attention 模块 PyTorch 源码解读。<br><span id="more"></span><br><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MultiheadAttention<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>add_bias_kv<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> add_zero_attn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> kdim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> vdim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><p>参数说明：</p><ol><li><code>embed_dim</code>： model dimension，即上面的 $d$。</li><li><code>num_heads</code>：多头 attention 中的 head 的数量</li><li><p><code>drop_out</code>：<code>attn_output_weights</code> 上的丢弃率。</p><p> <code>attn_output_weights</code> shape 为 <code>(tgt_seq_len, src_seq_len)</code> 表示各 element 之间的 weight。通常情况，<code>tgt_seq_len=src_seq_len=seq_len</code>，参考 <a href="https://jianjiansha.github.io/2022/01/17/transformer/self_attention/">attention</a> 一文中的矩阵 $A$。 </p></li><li><p><code>bias</code>： 默认为 <code>True</code>，表示在输入输出的 <code>linear</code> layer（全连接层）上使用 bias。参考 <a href="https://jianjiansha.github.io/2022/01/17/transformer/self_attention/">attention</a> 一文中的图 2 中右图。</p></li><li><code>batch_first</code>：默认 <code>False</code>，表示 <code>(seq_len, batch_size, embed_dim)</code>，否则输入 shape 应为 <code>(batch_size, seq_len, embed_dim)</code>。</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">forward<span class="token punctuation">(</span>query<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> key_padding_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> need_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> attn_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> average_attn_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明（以默认 <code>batch_first=False</code> 为例说明）：</p><ol><li><code>query</code>：<code>(L,N,E)</code>，其中 <code>L=seq_len, N=batch_size, E=embed_dim</code>。<code>L</code> 是 target sequence length。</li><li><code>key</code>: <code>(S,N,E)</code>，<code>S</code> 表示 source sequence length。</li><li><p><code>value</code>：<code>(S,N,E)</code>。考虑单个样本，query 和 key 做 attention，得到 attention weights，这是一个矩阵 <code>(L, S)</code>，然后与 value（数据矩阵为 <code>(S, E)</code>）相乘得到结果 <code>(L, E)</code>。</p></li><li><p><code>key_padding_mask</code>：<code>(N, S)</code>，指示 key 中哪些元素是需要忽略的，即被看作是 padding。<code>key_padding_mask</code> 中 <code>True</code> 值指示相应的 key 元素值将被忽略。</p><p> 例如，某个 sequence 中，序列长度为 <code>S</code>，第 $i$ 个 <code>key_padding_mask</code> 元素值为 <code>1</code>，$i &lt; S$，那么得到的 attention 矩阵中第 $i$ 列全为 <code>0</code>。</p></li><li><p><code>attn_mask</code>：阻止某些位置上的 attention。shape 为 <code>(L,S)</code> 或者 <code>(N*num_heads, L, S)</code>。2D mask 会广播到 3D。这个 mask 直接对 query 和 key 的 attention weight 矩阵进行 mask。</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DETR</title>
      <link href="/2022/01/21/transformer/detr/"/>
      <url>/2022/01/21/transformer/detr/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2005.12872">End-to-End Object Detection with Transformers</a></p><p>代码：<a href="https://github.com/facebookresearch/detr">facebookresearch/detr</a></p><p>首次将 transformer 应用于目标检测任务中。模型简称 <code>DETR</code>。</p><span id="more"></span><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>特点：</p><ol><li>端到端训练</li><li>可以基于任意的 CNN baseline</li><li><p>采用非自回归并行解码（non-autoregressive parallel decoding）</p><p> 自回归模型例如机器翻译任务，每一 step，Decoder 的输出依赖之前的输出，即，每次 Decoder 输出一个新的 token 后，都附加到输入 sequence 之后，作为下一次 Decoder 的输入。</p><p> 非自回归模型，则是并行生成所有的 tokens，这样解码速度更快。</p><p> 在 DETR 中，对于一个 gt box，仅将一个预测 box 与它对应起来，得到一个 pair，并计算匹配 loss，这样预测 boxes 的顺序可以是任意，即 预测 boxes 之间是独立的，从而使得可以并行计算得到所有预测 boxes。</p></li><li><p>对大目标的检测上，DETR 比之前的目标检测模型效果更好，这是因为 transformer 的 attention 是 global 的，而 CNN 则是 local 的。相对的，在小目标检测上，则效果差些。</p></li><li><p>set prediction</p><p> DETR 一次性预测所有的 box 集合，需要一个 matching loss 函数，用于 预测 box 与 gt box 之间的匹配，采用基于匈牙利算法（Hungarian algorithm）的 loss 计算方式，一个 gt box 最多只有一个预测 box 与之匹配，从而省去了 NMS 等 postprocessing。</p><p> 匈牙利算法可以参考这个 <a href="https://gist.github.com/JianjianSha/ed5ea9022a8aa1217113dc7d30b52044">代码实现</a></p></li></ol><h1 id="2-DETR"><a href="#2-DETR" class="headerlink" title="2. DETR"></a>2. DETR</h1><p>DETR 的结构示意图如下，</p><p><img src="/images/transformer/DETR1.png" alt=""></p><center>图 1. DETR 直接一次性（并行）预测所有的 box 集合。</center><ol><li>输入 image ，shape <code>(batch_size, 3, H, W)</code> </li><li><p>经过一个 CNN 网络输出 features 。shape <code>(batch_size, c, h, w)</code></p><p> 例如 ResNet-50，下采样率为 32，输出 channel 为 2048，即 <code>c=2048, h=H/32, w=W/32</code></p></li><li><p>backbone 的输出 features 作为 transformer 的输入，另外还使用了位置嵌入向量 <code>PE</code> 作为 transformer 的输入，具体参见下文分析</p></li><li><p>transformer decoder 输出经前馈网络 FFN 输出（feature map）上各 location 的预测分类得分和预测 box。（注：整个过程是并行的）</p></li></ol><h2 id="2-1-DETR-结构"><a href="#2-1-DETR-结构" class="headerlink" title="2.1 DETR 结构"></a>2.1 DETR 结构</h2><p><img src="/images/transformer/DETR2.png" alt=""></p><center>图 2. DETR 包含：1. CNN backbone，输出 feature maps；2. encoder-decoder transformer；3. 前馈网络 FFN。</center><p><strong>Backbone</strong></p><p>CNN backbone 的输入 image $x \in \mathbb R^{3 \times H_0 \times W_0}$，输出 features 为 $f \in \mathbb R^{C \times H \times W}$。通常取，$C=2048$，$H,W=H_0/32, W_0/32$。</p><p>代码中 backbone 默认使用 <code>ResNet50</code>，（代码 1）<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--backbone'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'resnet50'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">)</span>backbone <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>models<span class="token punctuation">,</span> <span class="token string">'resnet50'</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment"># create resnet50</span><span class="token comment"># 标记 layer4 为 backbone 的输出层，其编号为 0</span><span class="token comment"># 对于 segmentation task，则有多个输出层</span>return_layers <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'layer4'</span><span class="token punctuation">:</span> <span class="token string">'0'</span><span class="token punctuation">&#125;</span><span class="token comment"># self.body 输出 layer4 的 output features</span>self<span class="token punctuation">.</span>body <span class="token operator">=</span> IntermediateLayerGetter<span class="token punctuation">(</span>backbone<span class="token punctuation">,</span> return_layers<span class="token operator">=</span>return_layers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>机器翻译任务中，对短句子的末尾进行填充 <code>&lt;pad_tok&gt;</code>，然后再创建 <code>src_mask</code>，其中 <code>&lt;pad_tok&gt;</code> 对应 <code>mask=1</code>，这里对 image 采取类似的预处理，（代码 2）<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">nested_tensor_from_tensor_list</span><span class="token punctuation">(</span>tensor_list<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># tensor_list: a list of tensors. each tensor represents an image data</span>    <span class="token comment"># each tensor has a shape of (C, H, W)</span>    max_size <span class="token operator">=</span> _max_by_axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token keyword">for</span> img <span class="token keyword">in</span> tensor_list<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 得到一个最大的 size，可以容纳 mini-batch 中所有的 images</span>    batch_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>tensor_list<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> max_size    b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> batch_shape    dtype <span class="token operator">=</span> tensor_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dtype    device <span class="token operator">=</span> tensor_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>device    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    <span class="token comment"># 创建 mask，指示哪些 spatial pixeles 是填充数据</span>    mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    <span class="token keyword">for</span> img<span class="token punctuation">,</span> pad_img<span class="token punctuation">,</span> m <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>tensor_list<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token punctuation">:</span>        pad_img<span class="token punctuation">[</span><span class="token punctuation">:</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy_<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        m<span class="token punctuation">[</span><span class="token punctuation">:</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">return</span> NestedTensor<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>   <span class="token comment"># 打包 image 数据和 mask</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>（_为什么不将 image  resize 到相同 size 并保存各 image 的 scale 比例，而是使用 padding 和 mask？这是因为后者处理方法应该效果更好_）</p><p>经过 backbone 之后，image 转变成 features，其 spatial size 缩小了 $32$ 倍，故 mask 也需要等比例缩小 $32$ 倍，（代码 3）<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># class BackboneBase(nn.Module)</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tensor_list<span class="token punctuation">:</span> NestedTensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    xs <span class="token operator">=</span> self<span class="token punctuation">.</span>body<span class="token punctuation">(</span>tensor_list<span class="token punctuation">.</span>tensors<span class="token punctuation">)</span> <span class="token comment"># (batch_size, C=2048, H, W)</span>    <span class="token comment"># xs: backbone 的输出 features</span>    out <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token comment"># 检测任务 xs -> &#123;'0':res0&#125;</span>    <span class="token comment"># 分割任务 xs -> &#123;'0':res0, '1':res1, '2':res2, '3':res3&#125;</span>    <span class="token keyword">for</span> name<span class="token punctuation">,</span> x <span class="token keyword">in</span> xs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 对应上面 return_layers 的输出，name 为 编号</span>        m <span class="token operator">=</span> tensor_list<span class="token punctuation">.</span>mask        <span class="token comment"># mask 先从 3-D，转为 4-D，然后对最低的两个维度（spatial dimension）进行</span>        <span class="token comment"># 插值，rescale 之后，再转为 3-D</span>        <span class="token comment"># 这里使用最近邻插值，将 mask resize 到原来的 1/32</span>        mask <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>m<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token operator">=</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        out<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> NestedTensor<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>    <span class="token comment"># 根据 return_layers 的输出，继续打包 features 与 masks</span>    <span class="token keyword">return</span> out<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>Transformer encoder</strong></p><ol><li>使用一个 <code>1x1 conv</code> 对 CNN backbone 的输出 features 进行降维，从维度 $C$ 降到 $d=256$，得到 features 为 $z_0 \in \mathbb R^{d \times H \times W}$</li><li>将 spatial 特征压缩至一维，即 $(d,H,W)\rightarrow (d,HW)$，这里 $d$ 就是(transformer)特征维度，$HW$ 则作为输入 sequence 的 <code>seq_len</code>。</li><li>Encoder 为标准结构，包含一个 multi-head self-attention 和 一个 FFN</li><li>对特征  $z_0 \in \mathbb R^{d \times H \times W}$ 进行 positional encoding，然后加到 $z_0$ 上</li></ol><p><strong>position encoding</strong></p><script type="math/tex; mode=display">PE(pos_x, 2i)=\sin(pos_x / 10000^{2i/128})\\PE(pos_x, 2i+1)=\cos(pos_x/10000^{2i/128})\\PE(pos_y, 2i)=\sin(pos_y/10000^{2i/128})\\PE(pos_y, 2i+1)=\cos(pos_y/10000^{2i/128})</script><p>考虑了二维 spatial 位置上 x 轴 与 y 轴的位置编码，$i \in [0, d//4)$，每个空间位置 <code>pos</code> 处，位置 encoding 向量维度为 $d=256$，前 <code>128</code> 维表示 <code>pos_y</code> 位置编码，后 <code>128</code> 维表示 <code>pos_x</code> 位置编码，记 <code>pos</code> 坐标为 $(x, y)$，那么此处位置 encoding 为<br><pre class="line-numbers language-none"><code class="language-none">[PE(x, 0), PE(x,1), PE(x,2),PE(x,3), ..., PE(x,126),PE(x,127),PE(y,0),PE(y,1), ... ,PE(y,126),PE(y,127)]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>（代码 4）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># class PositionEmbeddingSine(nn.Module):</span><span class="token comment"># 获取 position embedding</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tensor_list<span class="token punctuation">:</span> NestedTensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># tensor_list: the data pack of one return_layer(refer to return_layers)</span>    x <span class="token operator">=</span> tensor_list<span class="token punctuation">.</span>tensors     <span class="token comment"># feartures of batch-images</span>    mask <span class="token operator">=</span> tensor_list<span class="token punctuation">.</span>mask     <span class="token comment"># corresponding masks of features</span>    <span class="token comment"># x: (B, C, H, W)</span>    <span class="token comment"># mask: (B, H, W), where `1` elements represent padding pixels</span>    not_mask <span class="token operator">=</span> <span class="token operator">~</span>mask    <span class="token comment"># position of y-axis, (B, H, W)</span>    <span class="token comment"># for one image features: [[1,1,...], </span>    <span class="token comment">#                          [2,2,...],...]</span>    <span class="token comment"># 对于i-th图像特征而言，y_embed[i] 沿y轴增 1</span>    y_embed <span class="token operator">=</span> not_mask<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>    <span class="token comment"># position of x_axis</span>    <span class="token comment"># for one image feature: [[1,2,3,...],</span>    <span class="token comment">#                         [1,2,3,...],...]</span>    x_embed <span class="token operator">=</span> not_mask<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>normalize<span class="token punctuation">:</span>   <span class="token comment"># True, normalize position to [0, 1]</span>        eps <span class="token operator">=</span> <span class="token number">1e-6</span>        <span class="token comment"># normalize the y-position</span>        y_embed <span class="token operator">=</span> y_embed <span class="token operator">/</span> <span class="token punctuation">(</span>y_embed<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>scale   <span class="token comment"># scale: 2*math.pi</span>        x_embed <span class="token operator">=</span> x_embed <span class="token operator">/</span> <span class="token punctuation">(</span>x_embed<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>scale    <span class="token comment"># self.temperature: 10000</span>    <span class="token comment"># self.num_pos_feats = d//2 = 256/2=128</span>    dim_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_pos_feats<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token comment"># dim_t // 2: 0, 0, 1, 1, 2, 2, ... , 63, 63</span>    <span class="token comment"># 2 * (dim_t // 2): 0, 0, 2, 2, 4, 4, ... , 126, 126</span>    <span class="token comment"># dim_t:= ...,  10000^&#123;2i/128&#125;</span>    dim_t <span class="token operator">=</span> self<span class="token punctuation">.</span>temperature <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>dim_t <span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>num_pos_features<span class="token punctuation">)</span>    <span class="token comment"># dim_t: (128,)</span>    <span class="token comment"># pos_x / 10000^&#123;2i/128&#125;</span>    <span class="token comment"># PE(pos_x, (2i, 2i+1)), PE(pos_y, (2i, 2i+1))</span>    pos_x <span class="token operator">=</span> x_embed<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">/</span> dim_t     <span class="token comment"># (B, H, W, 128)</span>    pos_y <span class="token operator">=</span> y_embed<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">/</span> dim_t     <span class="token comment"># (B, H, W, 128)</span>    <span class="token comment"># cross: [(B,H,W,64),(B,H,W,64)] => (B,H,W,64,2) => (B,H,W,128)</span>    <span class="token comment">#   [sin, cos, sin, cos, sin, ...]</span>    pos_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>pos_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pos_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    pos_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>pos_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pos_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    dim<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment"># (B, H, W, 256) => (B, 256, H, W)</span>    pos <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>pos_y<span class="token punctuation">,</span> pos_x<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> pos <span class="token comment"># (B, 256, H, W)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>backbone 输出包含两部分，</p><ol><li>image 数据经过 backbone 输出的 features</li><li>position embedding，与第 <code>1</code> 步中的 features 具有相同的 spatial size</li></ol><p>代码如下：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Joiner</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> backbone<span class="token punctuation">,</span> position_embedding<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>backbone<span class="token punctuation">,</span> position_embedding<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">orward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tensor_list<span class="token punctuation">:</span> NestedTensor<span class="token punctuation">)</span><span class="token punctuation">:</span>        xs <span class="token operator">=</span> self<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">(</span>tensor_list<span class="token punctuation">)</span>   <span class="token comment"># &#123;'0': NestTensor0&#125;</span>        out<span class="token punctuation">:</span> List<span class="token punctuation">[</span>NestedTensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        pos <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> x <span class="token keyword">in</span> xs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            out<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            pos<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>x<span class="token punctuation">.</span>tensors<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 对应的 PE</span>    <span class="token keyword">return</span> out<span class="token punctuation">,</span> pos<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>整个 features 的位置编码 shape 为 $(d, H, W)$ （未考虑 batch_size 这一维度），而 features 的 shape 为 <code>(512,H,W)</code> 或者 <code>(2048,H,W)</code> (参考各ResNet的输出 channel)，故Backbone 的输出 features 经过 <code>1x1 Conv</code> 降维后特征 shape 为 $(d, H, W)$，两者执行 element-wise 相加，然后 flatten spatial，得到 $d \times HW$ 的特征，作为 encoder 的输入。（代码 5）<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># class DETR(nn.Module):</span><span class="token comment"># decrease channels from 2048 to 256</span>input_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>backbone<span class="token punctuation">.</span>num_channels<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># def forwrad(sef, samples: NestedTensor):</span><span class="token comment"># features, pos is just `out, pos` in last code snippet.</span>features<span class="token punctuation">,</span> pos <span class="token operator">=</span> self<span class="token punctuation">.</span>backbone<span class="token punctuation">(</span>samples<span class="token punctuation">)</span>src<span class="token punctuation">,</span> mask <span class="token operator">=</span> features<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>decompose<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># param: src is the output of backbone, its shape (B, 2048, H, W)</span>src <span class="token operator">=</span> input_proj<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><img src="/images/transformer/DETR3.png" alt=""></p><center>图 3. DETR 中 Transformer 的具体结构</center><p>从图 3 中可见，backbone 输出特征经过 <code>1x1 conv</code> 降维后，直接作为 Encoder 的一个 input，记为 <code>f</code>，position encoding 作为另一个 input，记为 <code>PE</code>，这两个 tensor 的 shape 均为 $(d, HW)$（实际实现中，习惯按 <code>(seq_len, batch_size, feature_dim)</code> 的顺序 reshape，于是一个 mini-batch 中这两个 tensor 的 shape 为 $(HW,B,d)$ ），然后：</p><ol><li><code>f+PE</code> 作为 query, key；<code>f</code> 作为 value。value 中不需要 position encoding，可能是因为最终是一次性解码得到所有 object 列表，这个列表是无序的，例如原 image 上编号 <code>1</code> 的 object，其可以解码输出的列表中任意位置（index，下标），但是计算 attention 需要位置信息，故 <code>query</code> 和 <code>key</code> 上叠加了 <code>PE</code>。</li><li>multi-head self-attention 的输出与输入 <code>f</code> 做 Add&amp;Norm 操作，得到输出记为 <code>f1</code>，然后 <code>f1</code> 经过一个 FFN 得到的输出特征记为 <code>f2</code>，<code>f1</code> 与 <code>f2</code> 再次做 Add&amp;Norm 操作，得到单个 block 的输出。</li><li>Encoder 除了 <code>PE</code> 接入的位置不同，其他均与原生 transfromer 相同。</li></ol><p><strong>Encoder 总结：</strong></p><p><code>batch_size</code> 记为 $B$，考虑维度顺序 <code>(seq_len, batch_size, feature_dim)</code>。 $d=256$。</p><ol><li>输入 image backbone 的特征经过一个 <code>1x1 Conv</code> 降维，输出为 $z_0 \in \mathbb R^{HW \times B \times d}$，位置编码 $PE \in \mathbb R^{HW \times B \times d}$</li><li>PE 叠加到 <code>Q, K</code> 上</li><li>Block 输出 tensor 的 shape 为 $(HW, B, d)$ ，保持不变</li><li>第 <code>3</code> 步的输出继续作为下一个 block 的输入（仍使用一开始的那个 PE），重复步骤 <code>2~3</code> $N=6$ 次，最后得到整个 Encoder 的输出 shape 依然是 $(HW, B, d)$。</li></ol><p>Encoder 的代码：（代码 6）<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># class TransformerEncoder(nn.Module):</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> src_key_padding_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> pos<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># src: `1x1 Conv` 输出特征 （reshape 之后） （HW, B, d)</span>    <span class="token comment"># src_key_padding_mask: (HW, B, d)，backbone 输出的 mask，由于batch 内各 </span>    <span class="token comment">#      image size 大小不一，使用了 zero-padding，故需要使用 mask</span>    <span class="token comment"># pos: position embedding (HW, B, d)</span>    <span class="token comment"># mask: 对 attention 是否需要做 mask。在 Encoder 对 attention 不需要做</span>    <span class="token comment">#       mask，故这里 mask=None</span>    output <span class="token operator">=</span> src    <span class="token comment"># `1x1 Conv` 输出特征 （reshape 之后）</span>    <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>        output <span class="token operator">=</span> layer<span class="token punctuation">(</span>output<span class="token punctuation">,</span> src_mask<span class="token operator">=</span>mask<span class="token punctuation">,</span> \            src_key_padding_mask<span class="token operator">=</span>src_key_padding_mask<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>norm <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>   <span class="token comment"># normalize_before is false, so self.norm is None</span>        <span class="token comment"># normalize_after, so do not need norm here.</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>output<span class="token punctuation">)</span>    <span class="token keyword">return</span> output<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>Encoder layer (block) 小结：</strong></p><ol><li>features 与 position embedding 相加，作为 <code>query</code> 和 <code>key</code>，features 作为 <code>value</code></li><li>计算 mh self-attn 的输出，然后与输入相加，然后计算 layer_norm</li><li>FFN 的输出再与 FFN 的输入相加，然后计算 layer_norm。</li><li>Encoder layer 的输入输出 shape 均为 $(HW, B, d)$。</li></ol><p>Encoder layer 代码：（代码 7）<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward_post</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> src_mask<span class="token punctuation">,</span> src_key_padding_mask<span class="token punctuation">,</span> pos<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># src: input embedding      (HW, B, d)</span>    <span class="token comment"># pos: position embedding   (HW, B, d)</span>    <span class="token comment"># src_mask：对 attention 参数矩阵做 mask</span>    <span class="token comment"># src_key_padding_mask: 对 `key` 做 mask</span>    q <span class="token operator">=</span> k <span class="token operator">=</span> self<span class="token punctuation">.</span>with_pos_embed<span class="token punctuation">(</span>src<span class="token punctuation">,</span> pos<span class="token punctuation">)</span>   <span class="token comment"># 叠加 position embedding</span>    src2 <span class="token operator">=</span> self<span class="token punctuation">.</span>self_attn<span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> value<span class="token operator">=</span>src<span class="token punctuation">,</span> attn_mask<span class="token operator">=</span>src_mask<span class="token punctuation">,</span>                          key_padding_mask<span class="token operator">=</span>src_key_padding_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    src <span class="token operator">=</span> src <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>src2<span class="token punctuation">)</span>      <span class="token comment"># residual 结构</span>    src <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>src<span class="token punctuation">)</span>    <span class="token comment"># linear -> act -> dropout -> linear</span>    src2 <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    src <span class="token operator">=</span> src <span class="token operator">+</span> src2    src <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>src<span class="token punctuation">)</span>    <span class="token keyword">return</span> src<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>Transformer decoder</strong></p><ol><li><p>decoder 采用标准结构，但是是并行解码得到 $N$ 个预测 objects，非自回归。</p><p> $N$ 是手动给出的，且需要大于单个 image 中的 object 数量，通常 $N \neq HW$。注意需要与图 3 Encoder 中的 block 数量 N 区分开来，这是两个不同的变量。</p></li><li><p>decoder 结构如图 3 所示，输入称为 object queries，这是 N 个 positional embedding（向量，维度为 $d$），是可学习的 positional embedding。</p><p> （代码 8）</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python">N  <span class="token operator">=</span>  <span class="token number">100</span>       <span class="token comment"># 默认为 100，大于单个 image 中可能的 object 数量</span><span class="token comment"># hidden_dim = 256，就是前面 Encoder 中的参数 `d` </span><span class="token comment"># Embedding.weight 根据标准正态分布进行初始化</span>query_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>N<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span><span class="token comment"># src: output of `backbone + 1x1 Conv`</span><span class="token comment"># mask: set mask=1 for all padding pixels in mini-batch</span><span class="token comment"># query_emb: N x d, object queries</span><span class="token comment"># pos: position embeddings of all return_layers</span><span class="token comment">#   pos[-1] -> PE of the last return_layer, (B, d, H, W)</span>transformer<span class="token punctuation">(</span>src<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> query_emb<span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 图 3 关于 Decoder 的输入标注会有些误导，其实 Decoder 还有一个输入，是与 object queries 相同 shape 的全 0 tensor，如下代码中的 <code>tgt</code>。</p><p> Transformer （Encoder+Decoder）代码实现：（代码 9）</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># class Transformer(nn.Module):</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> query_embed<span class="token punctuation">,</span> pos_embed<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># src: output of input_proj(...), the input of encoder, (B, 256, H, W)</span>    <span class="token comment"># mask: mask of backbone output, (B, H, W)</span>    <span class="token comment"># query_embed: object query embedding of decoder, (N, 256)</span>    <span class="token comment"># pos_embed: positional embedding, (B, 256, H, W)</span>    b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> src    <span class="token comment"># (B, 256, H, W) -> (B, 256, HW) -> (HW, B, 256)</span>    src <span class="token operator">=</span> src<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    pos_embed <span class="token operator">=</span> pos_embed<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># (N, 256) -> (N, B, 256)</span>    <span class="token comment"># query_embed 是手动设置的 N 个目标的 object_queries</span>    query_embed <span class="token operator">=</span> query_embed<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> b<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># (B, H, W) -> (B, HW)</span>    mask <span class="token operator">=</span> mask<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    tgt <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>query_embed<span class="token punctuation">)</span>     <span class="token comment"># (N, B, 256)</span>    <span class="token comment"># memory: output of encoder, (HW, B, 256)</span>    memory <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>src<span class="token punctuation">,</span> src_key_padding_mask<span class="token operator">=</span>mask<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos_embed<span class="token punctuation">)</span>    <span class="token comment"># hs：(M, N, B, d)，其中 M 为 decoder layer iteration number。参见代码 11 的返回结果</span>    hs <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> memory_key_padding_mask<span class="token operator">=</span>mask<span class="token punctuation">,</span>                    pos<span class="token operator">=</span>pos_embed<span class="token punctuation">,</span> query_pos<span class="token operator">=</span>query_embed<span class="token punctuation">)</span>    <span class="token comment"># hs: (M, N, B, 256) -> (M, B, N, 256)</span>    <span class="token comment"># memory: (HW, B, 256) -> (B, 256, HW) -> (B, C, H, W)</span>    <span class="token keyword">return</span> hs<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> memory<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Decoder 的第一个 mh self-attn 的 <code>query</code> 和 <code>key</code> 均为 <code>tgt</code> 与 object queries 相加，</p><p> Decoder layer 的代码：（代码 10）</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward_post</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tgt<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> tgt_mask<span class="token punctuation">,</span> memory_mask<span class="token punctuation">,</span> tgt_key_padding_mask<span class="token punctuation">,</span>     memory_key_padding_mask<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> query_pos<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># query_pos: 就是前面说的 object queries `query_emb`， shape 为 (N, B, d)</span>    <span class="token comment"># tgt: 初始时为全零 tensor，shape 为 (N, B, d)</span>    <span class="token comment"># tgt_mask: 对 tgt 做 mask，这里不需要，为 None</span>    <span class="token comment"># memory: encoder 的最终输出 (HW, B, d), </span>    <span class="token comment"># memory_mask： 第二个 mh self-attn 中与 memory 计算 attention 之后的的 mask，这里为 None</span>    <span class="token comment"># tgt_key_padding_mask: 第一个 mh self-attn 中 `key` 的 mask， 为 None</span>    <span class="token comment"># memory_key_padding_mask: 第二个 mh self-attn 中 `key` 的 mask</span>    <span class="token comment">#   由于 batch 中 image 大小各不相同，左上角对齐，右下防 padding，padding pixels 的 mask=1</span>    <span class="token comment">#   memory_mask 缩放到 (H, W) 空间大小，(B,H,W) -> (B, HW)，参见代码 3 中的 mask</span>    <span class="token comment"># pos: encoder 中的 position embedding，(HW, B, d)</span>    q <span class="token operator">=</span> k <span class="token operator">=</span> self<span class="token punctuation">.</span>with_pos_embed<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> query_pos<span class="token punctuation">)</span>     <span class="token comment"># target 输入，Q, K 需要叠加 query embedding</span>    <span class="token comment"># 调用第一个 mh self-attn，参数 tgt_mask, tgt_key_padding_mask 均为 None，即不做 mask</span>    tgt2 <span class="token operator">=</span> self<span class="token punctuation">.</span>self_attn<span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> value<span class="token operator">=</span>tgt<span class="token punctuation">,</span> attn_mask<span class="token operator">=</span>tgt_mask<span class="token punctuation">,</span> key_padding_mask<span class="token operator">=</span>tgt_key_padding_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    tgt <span class="token operator">=</span> tgt <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout1<span class="token punctuation">(</span>tgt2<span class="token punctuation">)</span>     <span class="token comment"># redisual 结构</span>    tgt <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>tgt<span class="token punctuation">)</span>    <span class="token comment"># 调用第二个 mh self-attn，first mh self-attn 的输出作为 query，encoder 的最终输出作为 key 和 value，</span>    <span class="token comment"># query 和 key 分别使用 query_embedding 和 position embedding 叠加，value 保持不变</span>    <span class="token comment"># memory_mask：为 None，计算出 attention 之后不需要做 mask；</span>    <span class="token comment"># memory_key_padding_mask：与 encoder 中 src mask 相同，(B, HW)，由于 images 大小各不相同，存在 padding，故需要 mask</span>    tgt2 <span class="token operator">=</span> self<span class="token punctuation">.</span>multihead_attn<span class="token punctuation">(</span>query<span class="token operator">=</span>self<span class="token punctuation">.</span>with_pos_embed<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> query_pos<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span>self<span class="token punctuation">.</span>with_pos_embed<span class="token punctuation">(</span>memory<span class="token punctuation">,</span> pos<span class="token punctuation">)</span><span class="token punctuation">,</span>                               value<span class="token operator">=</span>memory<span class="token punctuation">,</span> attn_mask<span class="token operator">=</span>memory_mask<span class="token punctuation">,</span> key_padding_mask<span class="token operator">=</span>memory_key_padding_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    tgt <span class="token operator">=</span> tgt <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout2<span class="token punctuation">(</span>tgt2<span class="token punctuation">)</span>    tgt <span class="token operator">=</span> self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>tgt<span class="token punctuation">)</span>    tgt2 <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>tgt<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    tgt <span class="token operator">=</span> tgt <span class="token operator">+</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>tgt2<span class="token punctuation">)</span>    tgt <span class="token operator">=</span> self<span class="token punctuation">.</span>norm3<span class="token punctuation">(</span>tgt<span class="token punctuation">)</span>       <span class="token comment"># (N, B, d)</span>    <span class="token keyword">return</span> tgt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>整个 Decoder 的前向过程：（代码 11）</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tgt<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> tgt_mask<span class="token punctuation">,</span> memory_mask<span class="token punctuation">,</span> tgt_key_padding_mask<span class="token punctuation">,</span> memory_key_padding_mask<span class="token punctuation">,</span>            pos<span class="token punctuation">,</span> query_pos<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 参数与 Decoder layer 的前向传播方法参数相同，略过解释</span>    output <span class="token operator">=</span> tgt        <span class="token comment"># 全零 tensor，(N, B, d)，N=100</span>    intermediate <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>   <span class="token comment"># 循环执行 Decoder layer 若干次</span>        output <span class="token operator">=</span> layer<span class="token punctuation">(</span>output<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> tgt_mask<span class="token operator">=</span>tgt_mask<span class="token punctuation">,</span> memory_mask<span class="token operator">=</span>memory_mask<span class="token punctuation">,</span>                       tgt_key_padding_mask<span class="token operator">=</span>tgt_key_padding_mask<span class="token punctuation">,</span>                       memory_key_padding_mask<span class="token operator">=</span>memory_key_padding_mask<span class="token punctuation">,</span>                       pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> query_pos<span class="token operator">=</span>query_pos<span class="token punctuation">)</span>        <span class="token comment"># refer to the paper's section "Auxiliary decoding losses":</span>        <span class="token comment">#   add prediction FFNs and Hungarian loss after each decoder layer...</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>return_intermediate<span class="token punctuation">:</span>            intermediate<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>norm <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>   <span class="token comment"># True</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>output<span class="token punctuation">)</span>  <span class="token comment"># the last (final) decoder layer's output</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>return_intermediate<span class="token punctuation">:</span>    <span class="token comment"># 默认为 True，即，使用辅助 decoding loss</span>        <span class="token comment"># (M, N, B, d)，M is the total iteration number for decoder layer</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>intermediate<span class="token punctuation">)</span>    <span class="token keyword">return</span> output<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>      <span class="token comment"># (1, N, B, d)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 将 Decoder 中每个 block（总共 $M=6$ 个 block）的输出均存储起来 <code>intermediate</code>，并 stack 后返回，每个 block 的输出 <code>(N, B, d)</code>，那么 stack 后 Decoder 的输出为 <code>(M, N, B, d)</code>，其中 $M=6, \ N=100$。</p></li><li><p>Transformer 的输出包含两部分</p><ul><li>Decoder 的输出 <code>(M, B, N, d)</code> （经过了 shape 转置）</li><li>Encoder 的输出 <code>(B, d, H, W)</code> （shape permute+view）</li></ul></li></ol><p><strong>prediction heads</strong></p><p>decoder 的输出 shape 为 $(M, B, N, d)$，其中 $M$ 为 decoder layer 循环次数，$B$ 为 <code>batch_size</code>，<code>d=256</code> 表示模型维度，$N$ 表示单个 image 中预测的 object 数量。</p><ol><li>decoder 的输出经一个线性变换，使得维度从 <code>d</code> 变为 <code>C+1</code>，这里 <code>C</code> 表示 fg 分类数量，<code>1</code> 表示 bg 。（代码 12） <pre class="line-numbers language-python" data-language="python"><code class="language-python">class_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> num_classes<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>outputs_class <span class="token operator">=</span> class_embed<span class="token punctuation">(</span>hs<span class="token punctuation">)</span>         <span class="token comment"># hs 为 decoder layers 的输出，shape 为 (M, B, N, d)</span><span class="token comment"># 得到分类（非归一化）得分，(M, B, N, C+1)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>decoder 的输出经另一路分支即，由三层全连接层组成的分支，中间层的输出单元保持不变，输出层的输出单元数量为 4，表示坐标，坐标数据 shape 为 <code>(M, B, N, 4)</code>，（代码 13） <pre class="line-numbers language-python" data-language="python"><code class="language-python">bbox_embed <span class="token operator">=</span> MLP<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>outputs_coord <span class="token operator">=</span> bbox_embed<span class="token punctuation">(</span>hs<span class="token punctuation">)</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 归一化坐标</span><span class="token comment"># tensor 经 MLP，shape 变化为</span><span class="token comment"># MLP 输入 (M, B, N, d) -> (M, B, N, d) -> (M, B, N, d) -> (M, B, N, 4)</span><span class="token comment"># 每一个 "->" 表示一个全连接层</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>DETR 的输出</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 使用 Decoder 最后一个 block 进行预测</span><span class="token comment"># pred_logits: (B, N, C+1)</span><span class="token comment"># pred_boxes: (B, N, 4)</span>out <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'pred_logits'</span><span class="token punctuation">:</span> outputs_class<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'pred_boxes'</span><span class="token punctuation">:</span> outputs_coord<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token keyword">if</span> self<span class="token punctuation">.</span>aux_loss<span class="token punctuation">:</span>   <span class="token comment"># 为 True，其他 Decoder block 输出用于辅助 loss 计算</span>    out<span class="token punctuation">[</span><span class="token string">'aux_outputs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_set_aux_loss<span class="token punctuation">(</span>outputs_class<span class="token punctuation">,</span> outputs_coord<span class="token punctuation">)</span><span class="token comment"># aux_outputs: [&#123;&#125;]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="2-2-Loss"><a href="#2-2-Loss" class="headerlink" title="2.2 Loss"></a>2.2 Loss</h2><blockquote><p>预测集损失用于反向传播，优化网络。Hungarian 匹配损失用于寻找匹配的预测 box，不用于反向传播。</p></blockquote><p>记 $y$ 为 gt box 集合，$\hat y = \{\hat y_i \}_{i=1}^N$ 为预测 box 集合，                      </p><ol><li>$N$ 为某固定不变的值，表示对单个 image，预测 box 的数量。设置 $N$ 的值使得较大于一般意义上单个 image 中 object 数量。论文中设置 $N=100$</li><li>如果 gt box 数量不足 $N$，用 no-object进行填充，使得数量为 $N$。</li><li>填充的表示 no-object 的 gt boxes，其分类 index 为 <code>0</code>，表示背景 bg，坐标无所谓，因为坐标回归 loss 中只对正例预测 box 的坐标计算损失</li><li><strong><code>2~3</code> 是论文中原话，代码中并没有使用 no-object 进行填充使得 gt box 数量为 $N=100$</strong>。参考 下方关于 <code>HungarianMatcher</code> 的代码</li></ol><h3 id="2-2-1-Hungarian-损失"><a href="#2-2-1-Hungarian-损失" class="headerlink" title="2.2.1 Hungarian 损失"></a>2.2.1 Hungarian 损失</h3><p>在预测 box 集合和 gt box 集合上的二分匹配（bipartite matching）loss 为，</p><script type="math/tex; mode=display">\hat {\sigma} = \arg \min_{\sigma \in \mathcal G_N} \Sigma_i^N \mathcal L_{match}(y_i, \hat y_{\sigma(i)})</script><p>其中 $\sigma$ 表示 <code>1~N</code> 个自然数集合 $[N]$ 的一个 permutation（排列），$\sigma(i)$ 表示这个排列中第 $i$ 个数。$\mathcal G_N$ 表示 $[N]$ 的所有排列的集合。$\mathcal L_{match}(y_i, \hat y_{\sigma(i)})$ 表示 $y_i$ 和 $\hat y_{\sigma(i)}$ 的匹配 loss，这个 loss 包含了分类预测 loss 和 box 位置大小预测</p><p>记 gt box 为 $y_i=(c_i, b_i)$，其中 $c_i$ 表示分类 label index（约定 <code>0</code> 为 bg index），$b_i \in [0,1]^4$ 表示 box 的 center 坐标和 height，width（相对于 image size 进行了归一化）。单个 matching pair 的损失包含两部分：分类损失和坐标损失</p><script type="math/tex; mode=display">\mathcal L_{match}(y_i, \hat y_{\sigma(i)})=-\hat p_{\sigma(i)}(c_i)+ \mathbb I_{c_i \neq 0} \cdot \mathcal L_{box}(b_i, \hat b_{\sigma(i)})</script><p><strong>注：这里没有使用 NLL 损失，而是直接使用概率的负数作为损失</strong></p><p>对于单个 image，输出的预测分类概率应该类似于一个矩阵 $P \in [0, 1]^{N \times (C+1)}$，其中 $N=100$ 为单个 image 中预测 box 的数量，$C$ 为分类数量，$C+1$ 则包含了 bg。</p><p>第 <code>i</code> 个 gt box $y_i=(c_i, b_i)$ 与之匹配的预测 box 下标为 $\sigma(i)$，那么其对应到 $c_i$ 这个分类的预测概率为 $\hat p_{\sigma(i)}(c_i)=P_{\sigma(i),c_i}$</p><p>定义 Hungarian loss 表示单个 image 中所有 matching pairs 的损失，</p><script type="math/tex; mode=display">\mathcal L_{Hungarian}(y, \hat y)=\sum_{i=1}^N \left[-\log \hat p_{\hat \sigma(i)}(c_i) + \mathbb I_{c_i \neq 0} \cdot \mathcal L_{box}(b_i, \hat b_{\hat \sigma(i)})\right] \tag{1}</script><p>说明：</p><ol><li><font color="magenta">使用概率而非对数概率，即，去掉 （1）式中的 log，这样分类损失与坐标损失就比较相称。</font>（在下方的 Hungarian 代码中，没有对概率取对数操作）</li></ol><p><strong>Bound box loss</strong></p><p>DETR 直接预测 box，而非 box 相对于 anchor 的坐标偏差，故直接使用 $L_1$ 损失不合适，没有考虑到 scale 带来的影响，故 <strong>结合 $L_1$ 和 GIOU 作为坐标损失</strong>。</p><script type="math/tex; mode=display">L_1(b, \hat b) = |b-\hat b|</script><p>GIOU 损失参考 <a href="/2019/06/13/GIoU">这篇文章</a>。</p><p>于是 </p><script type="math/tex; mode=display">\mathcal L_{box}(b_i, \hat b_i)=\lambda_{iou} \mathcal L_{iou}(b_i, \hat b_{\sigma(i)})+\lambda_{L_1}||b_i - \hat b_{\sigma(i)}||_1</script><p>上式中使用了两个平衡因子 $\lambda_{iou}, \ \lambda_{L_i}$，代码中 $\lambda_{iou}=2, \ \lambda_{L_1}=5$，实际上分类损失也有平衡因子，只不过 $\lambda_{cls}=1$。</p><h3 id="2-2-2-Hungarian-代码"><a href="#2-2-2-Hungarian-代码" class="headerlink" title="2.2.2 Hungarian 代码"></a>2.2.2 Hungarian 代码</h3><p><strong>HungarianMatcher</strong></p><p>预测集与 target 集 的匹配采用匈牙利算法匹配，Hungarian 匹配算法仅仅是用于获取与 gt boxes 匹配的预测 boxes，这个匹配过程，也用到了一些损失计算，目标是求使得损失最小的二分图匹配，这个损失与上面求网络的优化目标损失不同，后者用于反向传播更新梯度，而前者（即 Hungarian 匹配损失）不是。（代码 17）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># class HungarianMatcher(nn.Module):</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># outputs 是 DETR 的输出，这是一个 dict 类型，key 可以是：</span>    <span class="token comment">#   pred_logits: 最后一个 decoder layer 的输出分类未归一化得分  (B, N, C+1)</span>    <span class="token comment">#   pred_boxes: 最后一个 decoder layer 的输出坐标       (B, N, 4)</span>    <span class="token comment"># targets: dict list，每个 dict 表示一个 image 的 target，包含 key：</span>    <span class="token comment">#   boxes: 某个 image 中 objects 的 (x, y, w, h)， shape 为 (M, 4)，</span>    <span class="token comment">#           M 表示 object 数量，每个 image 的 M 均不同</span>    <span class="token comment">#   labels：某个 image 中 objects 的分类 index（0 表示 bg），shape 为 (M, )</span>    <span class="token comment">#   image_id：image 的 id（coco 数据集中每个 image 有一个数值编号）</span>    <span class="token comment">#   ...：其他 keys 省略</span>    bs<span class="token punctuation">,</span> num_queries <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">'pred_logits'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># B, N</span>    out_prob <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">'pred_logits'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># (B*N, C+1)</span>    out_bbox <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">'pred_boxes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (B*N, 4)</span>    tgt_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>v<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> targets<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># (BM,), BM = M_1+M_2+...+M_B</span>    tgt_bbox <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>v<span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> targets<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># (BM, 4)</span>    <span class="token comment"># =================================================</span>    <span class="token comment"># 注意：以下三个损失计算理论上应分别在单个 image 内计算</span>    <span class="token comment"># 但是为了计算效率提升，故将 mini-batch 内所有预测和 </span>    <span class="token comment"># target 各自混合然后再计算这三种损失，最后取各 image</span>    <span class="token comment"># 内的预测与 target 之间的匹配损失，参见下方 c[i] 变量</span>    <span class="token comment"># =================================================</span>    <span class="token comment"># 计算预测分类与 gt 分类 两两之间的损失</span>    cost_class <span class="token operator">=</span> <span class="token operator">-</span>out_prob<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> tgt_ids<span class="token punctuation">]</span>      <span class="token comment"># (B*N, BM)</span>    <span class="token comment"># 计算预测 boxes 与 gt boxes，两两 之间的 p1 范数 => 差的绝对值</span>    cost_bbox <span class="token operator">=</span> torch<span class="token punctuation">.</span>cdist<span class="token punctuation">(</span>out_bbox<span class="token punctuation">,</span> tgt_bbox<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment"># (B*N, BM)</span>    <span class="token comment">#（B*N, BM)</span>    cost_giou <span class="token operator">=</span> <span class="token operator">-</span>generalized_box_iou<span class="token punctuation">(</span>box_cxcywh_to_xyxy<span class="token punctuation">(</span>out_bbox<span class="token punctuation">)</span><span class="token punctuation">,</span> box_cxcywh_to_xyxy<span class="token punctuation">(</span>tgt_bbox<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 计算总的损失，加权求和，损失 tensor shape: (B*N, BM)</span>    <span class="token comment"># cost_bbox=5, cost_class=1, cost_giou=2</span>    C <span class="token operator">=</span> self<span class="token punctuation">.</span>cost_bbox <span class="token operator">*</span> cost_bbox <span class="token operator">+</span> self<span class="token punctuation">.</span>cost_class <span class="token operator">*</span> cost_class <span class="token operator">+</span> self<span class="token punctuation">.</span>cost_giou <span class="token operator">*</span> cost_giou    C <span class="token operator">=</span> C<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_queries<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># (B, N, BM)</span>    sizes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>v<span class="token punctuation">[</span><span class="token string">"boxes"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> targets<span class="token punctuation">]</span>  <span class="token comment"># (B,)  gt number of all images in batch</span>    <span class="token comment"># C.split(sizes, -1) -> ((B, N, M_1), (B, N, M_2), ... , (B, N, M_B))</span>    <span class="token comment"># c[i] -> (N, M_i)  assignment the i-th image</span>    <span class="token comment"># 注意：这里预测数量 N，target 数量 M_i，所以并没有将 target 数量通过</span>    <span class="token comment">#   no-object 填充到 N</span>    <span class="token comment"># linear_sum_assignment: 计算二分图匹配中最小损失的匹配对，返回结果：(row_ind, col_ind)</span>    <span class="token comment"># row_ind 和 col_ind 均为长度为 M_i 的数量（这里假设了 N >= M_i）</span>    <span class="token comment"># row_ind 表示匹配的 pairs 中预测 box 的索引</span>    <span class="token comment"># col_ind 表示对应的 target 的索引</span>    indices <span class="token operator">=</span> <span class="token punctuation">[</span>linear_sum_assignment<span class="token punctuation">(</span>c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>C<span class="token punctuation">.</span>split<span class="token punctuation">(</span>sizes<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment"># tuple list，每个 tuple 表示对应 image 中，最佳匹配（loss 最小）的 预测 box ind 和 gt box ind</span>    <span class="token comment">#       每个 tuple 的 shape ((M_i,), (M_i,))</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>i<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>j<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span>j <span class="token keyword">in</span> indices<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-3-目标函数"><a href="#2-2-3-目标函数" class="headerlink" title="2.2.3 目标函数"></a>2.2.3 目标函数</h3><p>几种种损失（检测任务只有前三种，分割任务包含以下所有损失）：</p><ol><li>分类损失，平衡系数 $\lambda_{cls}=1$</li><li>坐标损失 $L_1$，平衡系数 $\lambda_{L_1}=5$</li><li>GIOU 损失，平衡系数 $\lambda_{iou}=2$</li><li>mask 损失，平衡系数 $1$ （分割任务中使用）</li><li>dice 损失，平衡系数 $1$ （分割任务中使用）</li><li>实际应用中，对于 bg 的分类损失，相较于 fg 的分类损失，我们使用一个权重因子 $\lambda_{no-object}=0.1$，以便缓和分类不平衡的问题。</li></ol><p><strong>分类损失：</strong></p><p>单个 image 的分类预测损失：</p><script type="math/tex; mode=display">L_{cls}=-\frac 1 N \sum_{i=1}^N w_i \log \hat p_{\hat \sigma(i)}(c_i)</script><p>其中权重</p><script type="math/tex; mode=display">w_i=\begin{cases} 1 & 0\le c_i <C(\text{fg}) \\ 0.1 & c_i=C(\text{bg})\end{cases}</script><p><strong>L1 坐标损失：</strong></p><p>mini-batch 的 L1 坐标损失，</p><script type="math/tex; mode=display">L_{L_1}=\frac 1 {\sum_i M_i}\sum_i \sum_{j=1}^{M_i} \sum_{c \in \{x,y,w,h\}} ||\hat b_{j,c}-b_{j,c}||</script><p>其中 $i$ 表示 mini-batch 中第 <code>i</code> 个 image， $M_i$ 是 <code>i-th</code> image 中 targets 数量。$b_{j,c}$ 表示第 <code>j</code> 个 target 的某个坐标 (<code>cx,cy,w,h</code>)，$\hat b_{j,c}$ 表示与第 <code>j</code> 个 target 匹配的预测 box 的某个坐标。</p><p><strong>GIoU:</strong></p><script type="math/tex; mode=display">L_{iou}=\frac 1 {\sum_i M_i} \sum_{j=1}^{M_i} GIoU(\hat b_j, b_j)</script><p>目标损失：</p><script type="math/tex; mode=display">L=\lambda_{cls}L_{cls}+\lambda_{L_1}L_{L_1}+\lambda_{iou}L_{iou}</script><h3 id="2-2-4-目标函数的代码"><a href="#2-2-4-目标函数的代码" class="headerlink" title="2.2.4 目标函数的代码"></a>2.2.4 目标函数的代码</h3><p><strong>SetCriterion</strong></p><p>集合匹配损失，用于反向传播优化网络（下面的 Hungarian 匹配损失则不参加反向传播，仅用于寻找匹配的 预测 box，注意区别）</p><p>（代码 14）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 只保留最后一个 decoder layer 的输出，辅助输出（非最后 decoder layer 的输出）的损失后面再计算</span>    outputs_without_aux <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> outputs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token operator">!=</span> <span class="token string">'aux_outputs'</span><span class="token punctuation">&#125;</span>      indices <span class="token operator">=</span> self<span class="token punctuation">.</span>matcher<span class="token punctuation">(</span>output_without_aux<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>     <span class="token comment"># 计算 Hungarian Loss，见下文代码 17</span>    num_boxes <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> targets<span class="token punctuation">)</span>      <span class="token comment"># 统计 minibatch 中所有 gt box 数量</span>    <span class="token comment"># </span>    num_boxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>num_boxes<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span>    num_boxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>num_boxes <span class="token operator">/</span> get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 不考虑分布式训练，get_world_size()=1</span>    losses <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> loss <span class="token keyword">in</span> self<span class="token punctuation">.</span>losses<span class="token punctuation">:</span>    <span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">,</span> <span class="token string">'boxes'</span><span class="token punctuation">,</span> <span class="token string">'cardinality'</span><span class="token punctuation">]</span>        <span class="token comment"># get_loss: 根据指定的 loss 类型，获取相应的 loss 值；</span>        <span class="token comment"># labels -> loss_labels(); boxes -> loss_boxes; cardinality -> loss_cardinality</span>        losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>self<span class="token punctuation">.</span>get_loss<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> num_boxes<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token string">'aux_outputs'</span> <span class="token keyword">in</span> outputs<span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> aux_outputs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>outputs<span class="token punctuation">[</span><span class="token string">'aux_outputs'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 计算辅助 loss</span>            indices <span class="token operator">=</span> self<span class="token punctuation">.</span>matcher<span class="token punctuation">(</span>aux_outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>            <span class="token comment"># 获取 匹配 indices</span>            <span class="token keyword">for</span> loss <span class="token keyword">in</span> self<span class="token punctuation">.</span>losses<span class="token punctuation">:</span>                <span class="token keyword">if</span> loss <span class="token operator">==</span> <span class="token string">'masks'</span><span class="token punctuation">:</span> <span class="token keyword">continue</span>    <span class="token comment"># 分割任务，不计算辅助 mask loss</span>                l_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>get_loss<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> aux_outputs<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> log<span class="token operator">=</span>loss<span class="token operator">!=</span><span class="token string">'labels'</span><span class="token punctuation">)</span>                l_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token operator">+</span><span class="token string-interpolation"><span class="token string">f'_</span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> l_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>                losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>l_dict<span class="token punctuation">)</span>    <span class="token keyword">return</span> losses<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最终返回一个 loss dict，以 <code>loss_ce</code> 开头的 key 表示交叉熵分类损失，<code>loss_bbox</code> 开头的 key 表示 l1 坐标（xywh）损失，以 <code>loss_giou</code> 开头的 key 表示 giou 损失。对于非最后一个 decoder layer 的损失，使用 <code>_&lt;i&gt;</code> 结尾，其中 <code>i</code> 为从 0 开始的编号。</p><ol><li><p>分类损失。注意，这里使用 NLL，用于反向传播更新梯度。（代码 15）</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_labels</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> log<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># outputs: &#123;'pred_logits': (B, N, C+1), 'pred_boxes': (B, N, 4)&#125;</span>    <span class="token comment"># targets: dict list, 每个 dict 表示一个 image 的 target</span>    <span class="token comment"># indices: tuple list，每个 tuple 表示一个 image 的预测 box ind 和 gt box ind</span>    <span class="token comment"># num_boxes: minibatch 中所有 gt box 的数量</span>    src_logits <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">'pred_logits'</span><span class="token punctuation">]</span>     <span class="token comment"># (B, N, C+1)</span>    <span class="token comment"># batch_idx: (BM,)  where BM=M_1+M_2+...+M_B, first M_1 is `0`, and</span>    <span class="token comment">#   then are M_2 `1`, and so on...</span>    <span class="token comment"># src_idx: (BM,)   first M_1 are row ind(pred box ind) of first image, and so on...</span>    <span class="token comment"># idx: (batch_idx, src_idx)</span>    idx <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_src_permutation_idx<span class="token punctuation">(</span>indices<span class="token punctuation">)</span>    <span class="token comment"># t: i-th target, this is a dict. t['labels'] has a shape of (M_i,)</span>    <span class="token comment"># J: gt box ind of matched pairs in i-th img, its shape is (M_i,)</span>    <span class="token comment"># target_boxes_o: (BM,) ，minibatch 中所有匹配的 gt boxes 的 分类 id</span>    target_classes_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>J<span class="token punctuation">]</span> <span class="token keyword">for</span> t<span class="token punctuation">,</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> J<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>targets<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># target_classes: (B, N), 预测 box 对应的 gt 分类 id，</span>    <span class="token comment">#       默认为 bg id，即 `num_classes`，不是 `0`，`0` 是第一个 fg 分类id</span>    <span class="token comment">#       表示 预测 box 是 no-object（负例）</span>    target_classes <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>src_logits<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_classes<span class="token punctuation">,</span>                                 dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">,</span> device<span class="token operator">=</span>src_logits<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token comment"># idx: mini-batch 中匹配对中的预测 box ind（范围 0~N-1）</span>    <span class="token comment"># target_classes_o: mini-batch 中匹配对中的 target 分类 id</span>    <span class="token comment"># 设置 target_classes 中被匹配中的预测 box 的分类，其分类为对应的 target 分类 id</span>    target_classes<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> target_classes_o    <span class="token comment"># 计算交叉熵，即 NLL 损失</span>    <span class="token comment"># empty_weight: torch.ones(num_classes+1), 且 empty_weight[-1] = 0.1</span>    <span class="token comment">#       正例损失系数 1.0， 负例损失系数为 0.1</span>    <span class="token comment"># 交叉熵的 input shape：(B, C+1, N), target shape：(B, N)</span>    <span class="token comment"># 交叉熵的各分类权重 shape：(C+1)</span>    <span class="token comment"># loss_ce: (B, N) -> (reduction: mean) -> scalar</span>    loss_ce <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>src_logits<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target_classes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>empty_weight<span class="token punctuation">)</span>    losses <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'loss_ce'</span><span class="token punctuation">:</span>loss_ce<span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> losses<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>坐标损失，包括 l1 损失和 GIOU 损失，（代码 16）</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loss_boxes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> num_boxes<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># idx: 获取 batch 中所有匹配对中的预测 box ind</span>    idx <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_src_permutation_idx<span class="token punctuation">(</span>indices<span class="token punctuation">)</span>    <span class="token comment"># predicted boxes，获取 batch 匹配对中的预测 box（归一化坐标，cx,cy,w,h）</span>    src_boxes <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">'pred_boxes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span>  <span class="token comment"># (BM, 4)</span>    <span class="token comment"># t: j-th target, this is a dict. t['boxes'] has a shape of (M_j, 4)</span>    <span class="token comment"># i: j-th gt box ind, its shape is (M_j,)</span>    <span class="token comment"># target_boxes: (BM, 4)，batch 中所有 target box 坐标（归一化，cx,cy,w,h)</span>    target_boxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> t<span class="token punctuation">,</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>targets<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment"># 计算 L1 损失</span>    loss_bbox <span class="token operator">=</span> F<span class="token punctuation">.</span>l1_loss<span class="token punctuation">(</span>src_boxes<span class="token punctuation">,</span> target_boxes<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>    <span class="token comment"># (BM, 4)</span>    losses <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    losses<span class="token punctuation">[</span><span class="token string">'loss_bbox'</span><span class="token punctuation">]</span> <span class="token operator">=</span> loss_bbox<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_boxes   <span class="token comment"># num_boxes 应该等于 src_boxes.shape[0]?</span>    <span class="token comment"># GIOU loss = 1 - GIOU</span>    loss_giou <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">-</span>torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>box_ops<span class="token punctuation">.</span>generalized_box_iou<span class="token punctuation">(</span>        box_ops<span class="token punctuation">.</span>box_cxcywh_to_xyxy<span class="token punctuation">(</span>src_boxes<span class="token punctuation">)</span><span class="token punctuation">,</span>        box_ops<span class="token punctuation">.</span>box_cxcywh_to_xyxy<span class="token punctuation">(</span>target_boxes<span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token punctuation">)</span>    losses<span class="token punctuation">[</span><span class="token string">'loss_giou'</span><span class="token punctuation">]</span> <span class="token operator">=</span> loss_giou<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_boxes    <span class="token keyword">return</span> losses<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>cardinality loss：预测 fg box 数量与 gt box 数量（在一个 mini-batch 内）的平均差。</p><p> 预测 box 为非 bg 的数量 <code>card_pred</code>，其 shape 为 $(B,)$，gt box 的数量 <code>tgt_lengths</code>，其 shape 为 $(B,)$，表示 mini-batch 中各个 image 中的预测为 fg 的数量和 gt box 数量，计算这两个 tensor 的 L1 损失，并求均值，这个损失 <strong>不用于反向传播</strong>。</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python">card_err <span class="token operator">=</span> F<span class="token punctuation">.</span>l1_loss<span class="token punctuation">(</span>card_pred<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tgt_lengths<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p><strong>反向传播</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_dict <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>     <span class="token comment"># 分类损失，l1 损失，giou 损失</span>weight_dict <span class="token operator">=</span> criterion<span class="token punctuation">.</span>weight_dict     <span class="token comment"># 各损失的权重，分类损失为基准（其权值为 1），l1 权值为 5，giou 权值为 2</span><span class="token comment"># 计算所有损失的加权和，包括所有 decoder layer 的各项损失</span>losses <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>loss_dict<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">*</span> weight_dict<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> loss_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">in</span> weight_dict<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>losses<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> max_norm <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>    <span class="token comment"># 默认 0.1</span>    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_norm<span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-3-测试"><a href="#2-3-测试" class="headerlink" title="2.3 测试"></a>2.3 测试</h2><p>对一个新的 input image 进行预测时，根据前面分析，知道两个预测分支的输出为：1.分类得分$(1, N, C+1)$，2.预测坐标（xywh） $(1, N, 4)$。</p><p>首先根据分类得分得到 fg boxes 以及对应的分类 id<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pred_logits, pred_boxes</span><span class="token comment"># batch_size  B=1</span>pred_ind <span class="token operator">=</span> pred_logits<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># (B, N)</span><span class="token comment"># (B, N, C+1)，the last class id `C` represents bg</span>fg_ind <span class="token operator">=</span> pred_ind <span class="token operator">!=</span> pred_logits<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>  <span class="token comment"># shape: (B, N)</span><span class="token comment"># (B,)  each element is the number of pred_fg boxes for some one image</span>fg_num <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>fg_ind<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># (n, 4)  n 为 mini-batch 中所有预测为 fg 的数量</span>fg_boxes <span class="token operator">=</span> pred_boxes<span class="token punctuation">[</span>fg_ind<span class="token punctuation">]</span>       x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h <span class="token operator">=</span> fg_boxes<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 4 个变量 shape 均为 (n,)</span><span class="token comment"># (cx, cy, w, h) -> (x1, y1, x2, y2)</span>xyxy <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token operator">-</span><span class="token number">0.5</span><span class="token operator">*</span>w<span class="token punctuation">,</span> y<span class="token operator">-</span><span class="token number">0.5</span><span class="token operator">*</span>h<span class="token punctuation">,</span> x<span class="token operator">+</span><span class="token number">0.5</span><span class="token operator">*</span>w<span class="token punctuation">,</span> y<span class="token operator">+</span><span class="token number">0.5</span><span class="token operator">*</span>h<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># (n, 4)</span>cls_id <span class="token operator">=</span> pred_ind<span class="token punctuation">[</span>fg_ind<span class="token punctuation">]</span>           <span class="token comment"># (n,)   class id of predicted box</span><span class="token comment"># normalized (x1, y1, x2, y2)</span><span class="token comment"># split x1y1x2y2 into a tuple, each element represents predicted coords of one image in mini-batch</span>xyxy_tuple <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>xyxy<span class="token punctuation">,</span> fg_num<span class="token punctuation">)</span>  <span class="token comment"># (tensor_1,...,tensor_B), each tensor has a shape (n_i, 4), s.t. sum_i n_i = n</span><span class="token comment"># fg predicted class id</span>cls_id_tuple <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>cls_id<span class="token punctuation">,</span> fg_num<span class="token punctuation">)</span>  <span class="token comment"># (tensor1,...,tensor_B), each tensor's shape (n_i,), s.t. sum_i n_i = n</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>DETR 没有 post processing，故获取预测结果非常简单。</p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><p>DETR 首次（不是？）将 Transformer 用于目标检测，后面有很多研究均基于 DETR 进行改进，故对 DETR 研究透彻非常有必要，为了以后能快速恢复对 DETR 的了解，对 DETR 各关键点进行总结。</p><h2 id="3-1-结构"><a href="#3-1-结构" class="headerlink" title="3.1 结构"></a>3.1 结构</h2><p>DETR 结构图如图 1 和图 2。</p><h3 id="3-1-1-Network-Input"><a href="#3-1-1-Network-Input" class="headerlink" title="3.1.1 Network Input"></a>3.1.1 Network Input</h3><p>对于一个 mini batch 中图像数据，左上对齐，右下 zero-padding，得到一个 batch 数据，以及一个相同 spatial size 的 mask。</p><p>对于 target bbox 坐标，从 COCO anno 文件加载的是 <code>(x1, y1, w, h)</code>，经过 <code>ConvertCocoPolysToMask</code> 转换后为 <code>(x1, y1, x2, y2)</code>，然后再经 <code>transforms.Normalize</code> 转换为 <strong>归一化后的</strong> <code>(cx, cy, w, h)</code>。（归一化指 将 <code>x, y</code> 除以 <code>w, h</code>）。</p><h3 id="3-1-2-Backbone"><a href="#3-1-2-Backbone" class="headerlink" title="3.1.2 Backbone"></a>3.1.2 Backbone</h3><p>ResNet50/ResNet101（这两个常用），下采样率 <code>32</code>。</p><p>预处理的数据经过 backbone，输出 feature，然后将 Network Input 中的 mask 数据 rescale 到原来的 <code>1/32</code>。两个输出：</p><ol><li>features</li><li>PE</li></ol><h3 id="3-1-3-Encoder"><a href="#3-1-3-Encoder" class="headerlink" title="3.1.3 Encoder"></a>3.1.3 Encoder</h3><p>上一步的 features 和 PE 的 channel 数不同，对 features 采用 <code>1x1 conv</code> 降维。</p><p>Encoder 输入：</p><ol><li>降维后的 features</li><li>PE</li><li>src_key_padding_mask，这是由于 batch 内各 image size 不同而进行 zero padding，由此需要引入 mask，对部分位置上的 attention 进行 mask。</li></ol><p>Encoder 结构如图 3 所示，为了方便查看，这里在下方再贴出来。features 为 query, key, value，其中 query 和 key 还需要另外 element-wise 加上 PE，value 不需要叠加 PE。</p><p>单个 block 的输出 <code>output</code> shape 为 <code>(HW, B, d)</code>，保持不变，这个 <code>output</code> 继续作为下一个 block 的 query, key, value，且同时 query 和 key 需要叠加 PE（与最开始的 PE 相同，value 不需要叠加 PE。</p><p>重复 $N=6$ 次 Encoder block 后输出 <code>output</code>，其 shape 为 <code>(HW, B, d)</code> 。</p><p><img src="/images/transformer/DETR3.png" alt=""></p><center>图 3. Encoder 和 Decoder 结构图</center><h3 id="3-1-4-Decoder"><a href="#3-1-4-Decoder" class="headerlink" title="3.1.4 Decoder"></a>3.1.4 Decoder</h3><p>Decoder 结构如图 3 所示，输入包含：</p><ol><li>object_query：用于表征 $N=100$ 个预测目标，这是一个可学习的 Embedding（weight使用 $\mathcal N(0,1)$ 进行初始化）。shape 为 <code>(N=100, d)</code>，其中 $d$ 为模型维度，维度调整后 shape 为 <code>(N, B, d)</code>。</li><li>tgt：与 object_query 相同 shape，初始化为全零 tensor。</li><li>Encoder 的最后一个 block 的输出，记为 <code>memory</code>，shape 为 <code>(HW, B, d)</code>。</li><li>memory_key_padding_mask：这是对 <code>memory</code> 进行 mask。仍然是因为 network input image 大小不一，导致 zero-padding，从而需要对 padded position 进行 mask。</li><li>PE：position embedding，与 Encoder 中所用 PE 相同。</li></ol><p>注意 Encoder block 中只有一个 attn layer，而 Decoder 中有两个 attn layer，这两个 attn layer 的输入 <strong>不同</strong>。</p><p><strong>第一个 attn layer：</strong></p><p>query 和 key 均为 <code>tgt</code> 与 <code>object_query</code> 的叠加。value 为 <code>tgt</code>，attn layer 的输出，记为 <code>tgt2</code>，其 shape 仍然是 <code>(N, B, d)</code>。</p><p>这个输出 <code>tgt2</code> 依次经过 dropout，residual connect 和 norm 处理之后，记为 <code>tgt</code>，准备进入 第二个 attn layer。</p><p><strong>第二个 attn layer：</strong></p><p>注意看图 3， q, k, v 均与第一个 attn layer 不同。</p><ol><li>将 <code>tgt</code>（上一个步的输出） 和 <code>object_query</code> （与上一步的相同）叠加，作为 query，shape 为 <code>(N, B, d)</code></li><li>将 Encoder 的最终输出 <code>memory</code> 与 PE 叠加，作为 key，shape 为 <code>(HW,B,d)</code>。</li><li>将 Encoder 的最终输出 <code>memory</code> 作为 value，shape 为 <code>(HW, B, d)</code>。</li></ol><p>Q 与 K 的 attention weight，<code>(B, N, HW)</code>，与  value 作用后结果 shape 为 <code>(N, B, d)</code>，然后再依次经过 dropout，residual connect 和 norm 操作，记这一步结果为 <code>tgt</code>。</p><p><strong>FFN：</strong></p><p>上一步结果 <code>tgt</code> 经一个双 fc layer 组成的前馈网络，输出的 shape 保持不变为 <code>(N, B, d)</code>，然后再依次经过 dropout，residual connect 和 norm 操作，得到 Decoder 中单个 block 的输出，记结果为 <code>tgt</code>。</p><p>将第一个 block 的输出 <code>tgt</code> 代替原始的全零 tensor 的 <code>tgt</code>，其他参数保持不变，送入第二个 block。重复 $M=6$ 次 block。</p><p>每个 block 的输出仅保存起来，最后再 stack，得到 Decoder 的输出 <code>(M, N, B, d)</code>。</p><h3 id="3-1-6-检测-heads"><a href="#3-1-6-检测-heads" class="headerlink" title="3.1.6 检测 heads"></a>3.1.6 检测 heads</h3><p>分类和位置两个 heads。</p><ol><li>分类 head：一个 fc 层，输出 channel 为 <code>num_classes+1</code>，因为 $N=100$ 的预测目标通常有 bg。输出 shape 为 <code>(M, B, N, num_classes+1)</code></li><li><p>坐标 head：三个 fc 层组成的 MLP。输出 shape <code>(M, B, N, 4)</code></p><p> MLP 输入 channel 和 hidden channel 均为 d，输出 channel 为 4 （bbox 坐标）<br> MLP 中前两个 fc 有 relu，最后一个 fc 没有 relu</p></li></ol><h2 id="3-2-LOSS"><a href="#3-2-LOSS" class="headerlink" title="3.2 LOSS"></a>3.2 LOSS</h2><p>见上面 <code>2.2</code> 节。</p><h2 id="3-3-Prediction"><a href="#3-3-Prediction" class="headerlink" title="3.3 Prediction"></a>3.3 Prediction</h2><p>见上面 <code>2.3</code> 节。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>词嵌入向量</title>
      <link href="/2022/01/19/pytorch/embedding/"/>
      <url>/2022/01/19/pytorch/embedding/</url>
      
        <content type="html"><![CDATA[<p>embedding 就是将一个 word 转换为 一个 vector，最简单的方法就是使用 <code>one-hot vector</code>，其长度为词汇表大小，但是 <code>one-hot vector</code> 无法表示词的语义，比如两个词是相近还是相反含义，或者无关，embedding vector 则可以很好的表征词的语义。</p><span id="more"></span><h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1. 原理"></a>1. 原理</h1><p>给词汇表中每个 word 分配一个唯一的编号 index，例如词汇表大小为 $V$，那么 index 为 $1,\ldots, V$，记 embedding vector 维度为 $d$，那么可以使用一个矩阵 $E \in \mathbb R^{V \times d}$，矩阵每一行表示一个 word 对应的 embedding。</p><p>这个 embedding 过程其实就是一层全连接层（fc），fc 的参数就是上面说的矩阵 $E$，fc 的输入是 <code>one-hot vector</code>，记为 $\mathbf x_i \in \mathbb R^{1 \times V}$，第 <code>i</code> 个元素值为 <code>1</code>，那么 fc 的输出 $\mathbf e_i = \mathbf x E \in \mathbb R^{1 \times d}$。</p><p>将 word 转换为 embedding vector 后，可以作为网络的输入，既然如此，可以直接像训练网络那样训练这个 fc。</p><h1 id="2-Embedding-类型"><a href="#2-Embedding-类型" class="headerlink" title="2. Embedding 类型"></a>2. Embedding 类型</h1><p>在 PyTorch 中，使用 <code>Embedding</code> 类来实现 embedding 相关操作，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    max_norm<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> scale_grad_by_freq<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    _weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>参数说明：</p><ol><li><code>num_embeddings</code> ： embeddings 数量，即词汇表大小。</li><li><code>embedding_dim</code>： embedding vector 维度</li><li><p><code>padding_idx</code>：可选，指定填充 index 值。通常选取 <code>batch_size</code> 数量的句子（word sequence）作为一个 batch，但是各个句子长度（word 数量，即 sequence length）可能不同，所以固定一个值作为 sequence length，然后对于那些较短的句子，使用 <code>padding_idx</code> 进行填充。一种经典的做法是：</p><ul><li>取 <code>batch_size</code> 的 sentences，使用分词器分词，得到 <code>batch_size</code> 个 sequences</li><li>取 sequences 中长度最大值，记为 <code>L</code></li><li><p>对每个 sequence， prepend <code>&lt;init_token&gt;</code>，然后再 append <code>&lt;end_token&gt;</code>，最后，对长度不足 <code>L</code> 的 sequence，填充 <code>&lt;pad_token&gt;</code>，使得长度为 <code>L</code>。这里的长度 <code>L</code> 不包括 <code>&lt;init_token&gt;</code> 和 <code>&lt;end_token&gt;</code>。</p><p><strong><code>padding_idx</code> 如果指定，那么对应的 embedding vector 在训练过程中将保持不变，这个 embedding vector 初始为全 0 向量，但是可以手动更改。</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 默认 padding embedding 为 0-vector</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># (B, seq_len) = (1, 4)</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token comment"># 手动修改 padding embedding</span>padding_idx <span class="token operator">=</span> <span class="token number">0</span>embedding<span class="token punctuation">.</span>weight    <span class="token comment"># print embeddings before updating</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    embedding<span class="token punctuation">.</span>weight<span class="token punctuation">[</span>padding_idx<span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>embedding<span class="token punctuation">.</span>weight    <span class="token comment"># print embeddings after updating</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>padding_idx</code> 如果指定，那么 <code>num_embeddings</code> 为 <code>V+1</code> 。</p></li></ul></li><li><p><code>max_norm</code> ： 可选。如果指定，那么任何 embedding vector，如果其 norm 超过这个值，会被收缩使得 norm 等于 <code>max_norm</code>。</p></li><li><code>norm_type</code>：norm 类型，与 <code>max_norm</code> 配合使用。</li><li><code>scale_grad_by_freq</code>：如果为 True，将根据 word 在 mini-batch 中的频率倒数，rescale （weight 关联的）gradient，类似于样本均衡，否则如果某个 word 出现太多，导致其对应的 gradient 太大，网络注意力全在这些高频 word 上了。</li><li><code>sparse</code>：如果为 True，那么 <code>gradient</code> w.r.t. <code>Embedding.weight</code> 矩阵为稀疏矩阵，由于这个矩阵维度较大，采用稀疏矩阵可以节约内存，但是只有几个优化器支持稀疏矩阵：<code>optim.SGD(CUDA 和 CPU)</code>，<code>optim.SparseAdam(CUDA 和 CPU)</code>，以及 <code>optim.Adagrad(CPU)</code>。</li></ol><p>注意：<code>max_norm</code> 不为 none 时，Embedding 类的 <code>forward</code> 方法会 in-place 修改其 <code>weight</code> tensor，然而在梯度计算时，不能 in-place 修改 tensor，否则梯度计算不准确，所以如果在损失计算式中包含了 <code>weight</code>，那么必须要使用 <code>weight</code> 的 clone，示例代码：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">n<span class="token punctuation">,</span> d<span class="token punctuation">,</span> m <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>n<span class="token punctuation">,</span> d<span class="token punctuation">,</span> max_norm<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>W <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 这里，a 必须要使用 weight 的 clone，如果不使用 clone，那么 a 的计算</span><span class="token comment">#   必须要放在 b 的计算之后，此时表示另一种含义的 out</span>a <span class="token operator">=</span> embedding<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span> @ W<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>b <span class="token operator">=</span> embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> @ W<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 这一步，修改了 weight</span>out <span class="token operator">=</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> out<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prod<span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><code>forward</code> 参数：</p><ol><li><p><code>input</code>：为 IntTensor 或 LongTensor 类型，为任意 shape，记为 $(\star)$，元素值为 index，注意不是 <code>one-hot</code> vector，第 <code>1</code> 节中使用 <code>one-hot</code> vector 仅仅是为了说明，PyTorch 中使用 <code>index</code> （例如 $idx \in [0, V]$，其中 <code>0</code> 表示 <code>padding_idx</code> ）。</p></li><li><p><code>forward</code> 方法的输出：shape 为 $(\star, d)$， 其中 embedding 维度为 <code>d</code>，相当于为最后增加一个维度，维度大小为 <code>d</code>。</p></li></ol><h1 id="3-from-pretrained-方法"><a href="#3-from-pretrained-方法" class="headerlink" title="3. from_pretrained 方法"></a>3. from_pretrained 方法</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python">CLASSMETHOD from_pretrained<span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> freeze<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>    max_norm<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> norm_type<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> scale_grad_by_freq<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>根据给定的一个 embeddings 矩阵，创建一个 <code>Embedding</code> 实例<br>参数说明</p><ol><li><code>embeddings</code>：指定 embeddings 矩阵，shape 为 <code>(num_embeddings, embedding_dim)</code>。</li><li>其他参数含义与 <code>Embedding</code> 构造函数的参数意义相同。</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># (2, 3)</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># input shape: (1,)</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>                <span class="token comment"># output shape: (1, 3)</span><span class="token comment"># tensor([[4.0000, 5.0000, 6.0000]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>attention is all you need</title>
      <link href="/2022/01/17/transformer/self_attention/"/>
      <url>/2022/01/17/transformer/self_attention/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a><br><span id="more"></span></p><h1 id="1-Sequence"><a href="#1-Sequence" class="headerlink" title="1. Sequence"></a>1. Sequence</h1><p>处理 Sequence ，自然想到 RNN，如图 1，<br><img src="/images/ml/lstm2.png" alt=""><br>图 1. RNN</p><p>输入 Sequence 长度为 <code>T</code>，即 $\mathbf x_1, \ldots, \mathbf x_T$，输入为一个 $T \times l$ 的 tensor，其中 $l$ 为向量 $\mathbf x_i$ 的特征长度。</p><p>RNN 的缺点是无法并行化计算，因为 <code>t</code> 时刻输出依赖 <code>t-1</code> 时刻输出，即对于网络 $\mathcal L$，<code>t+1</code> 时刻的输出 </p><script type="math/tex; mode=display">\begin{aligned}\mathbf h_{t+1}&= \mathcal L(\mathbf x_{t+1}, \mathbf h_t)\\&=\mathcal L[\mathbf x_{t+1}, \mathcal L(\mathbf x_t, \mathbf h_{t-1})]\\&=\mathcal L\{\mathbf x_{t+1}, \mathcal L[\mathbf x_t, \mathcal L(\cdots \mathcal L(\mathbf x_1, \mathbf h_0))]\}\end{aligned}</script><p>很明显，网络 $\mathcal L$ 是串行计算的。</p><p>而 attention 可以解决这个问题，主要思想是：抛弃 RNN 中前一时刻 <code>t</code> 整个网络的输出 $\mathbf h_t$ 与下一时刻 <code>t+1</code> 的输入 $\mathbf x_{t+1}$ 对齐后作为网络的新的输入（用于计算 $\mathbf h_{t+1}$），而是将所有时刻的输入 $\mathbf x_1, \ldots, \mathbf x_T$ 作为一个 size 为 T 的 batch，送入网络，并行计算，并在网络内部，进行交叉计算（类似于 batch norm），实现依赖性。具体参见下文。</p><h1 id="2-Self-attention"><a href="#2-Self-attention" class="headerlink" title="2. Self-attention"></a>2. Self-attention</h1><h2 id="2-1-scaled-dot-product-attention"><a href="#2-1-scaled-dot-product-attention" class="headerlink" title="2.1 scaled dot-product attention"></a>2.1 scaled dot-product attention</h2><p>记输入序列为 $\mathbf x_1, \ldots, \mathbf x_T$，</p><ol><li>每个时刻的 input 乘以一个矩阵 $W \in \mathbb R^{n \times l}$，得到对应的 embedding 向量，$\mathbf a_i=W \mathbf x_i, \ i = 1,2,\ldots, T$。$n$ 为 embedding dimension。（这一步不属于 attention 模块，但是为了完整，这里也写出来了）</li><li>使用三个矩阵分别与 embedding 向量相乘，得到 query，key，value 三个向量，这三个向量长度相同，记为 $d$，<strong><font color='red'>称 $d$ 为 model dimension</font></strong>，论文中取 $d=512$。<script type="math/tex; mode=display">\mathbf q_i=W_q^{\top} \mathbf a_i, \ \mathbf k_i=W_i^{\top} \mathbf a_i, \ \mathbf v_i =W_v^{\top} \mathbf a_i, \quad \mathbf q_i, \mathbf k_i, \mathbf v_i \in \mathbb R^d</script></li><li>$\mathbf q_i$ 与 $\mathbf k_i$ 做 attention，attention 操作可以实现 time step 之间的依赖性。$\mathbf q_i$ 与 $\mathbf k_i$ 是齐头并进地计算出来的，即，可以并行计算。<strong>scaled dot-product attention：</strong><script type="math/tex; mode=display">\alpha_{ij}=\mathbf q_i \cdot \mathbf k_i / \sqrt d, \quad i,j=1,\ldots, T</script> 向量内积需要乘以因子 $1/\sqrt d$，因为如果 <code>d</code> 太大，内积分布的方差就很大，那么执行第 <code>4</code> 步的 softmax 之后，会位于 softmax 的梯度较小的区域，影响反向传播。</li><li>对 $\alpha_{i1}, \ldots, \alpha_{iT}$ 做 softmax 进行归一化，<script type="math/tex; mode=display">\hat {\alpha}_{ij} = \exp(\alpha_{ij})/\sum_l \exp(\alpha_{il})</script> 记矩阵 $A \in \mathbb R^{T \times T}$，表示上述的 attention 矩阵，对每一行做 softmax， <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># A is the attention matrix, A_&#123;ij&#125; means attention between</span><span class="token comment"># query_i and key_j. Both i and j are some time steps.</span>torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>A<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>归一化后的 attention 作为 weight，将表征信息的 $\mathbf v_i$ 向量加权求和，得到这一阶段的计算结果（$\mathbf b$ 类似于上文 RNN 中的 $\mathbf h$ ），<script type="math/tex; mode=display">\mathbf o_i=\sum_j \hat {\alpha}_{ij} \mathbf v_j, \quad i=1,\ldots, T</script></li></ol><p><strong>上面在每一步中的计算中，所有 time step 都可以同时计算，于是可以实现并行计算。</strong></p><font color='magenta'>$\mathbf o_i \in \mathbb R^d \ , \ i=1,\ldots, T$</font><h2 id="2-2-矩阵表示"><a href="#2-2-矩阵表示" class="headerlink" title="2.2 矩阵表示"></a>2.2 矩阵表示</h2><ol><li>输入矩阵 $X \in \mathbb R^{T \times l}$，每一行表示一个 time step 的输入向量</li><li>embedding vector 维度为 $n$，参数矩阵 $W \in \mathbb R^{n \times l}$，得到所有 embedding 序列 $I \in \mathbb R^{T \times n}$：$I=X\cdot W^{\top}$</li><li>三个参数矩阵 $W_q,W_k,W_v \in \mathbb R^{d\times n}$， 得到 query，key，value 序列 $Q, K, V \in \mathbb R^{T \times d}$，<script type="math/tex; mode=display">Q=I W_q^{\top}, \quad K=I W_k^{\top}, \quad V=IW_v^{\top}</script></li><li>attention op，得到 attention 矩阵 $A \in \mathbb R^{T \times T}$：$A=Q K^{\top}/\sqrt d$</li><li>归一化 attention：$\hat A_{ij} =\exp( A_{ij})/ \sum_l \exp(A_{il})$。第 <code>i</code> 行 $\hat A_{i,:}$ 作为 time step <code>i</code> 的 weights。</li><li>输出矩阵 <font color='magenta'>$O \in \mathbb R^{T \times d}$</font>，$O=\hat A V$</li></ol><h2 id="2-3-Multi-head-Self-attention"><a href="#2-3-Multi-head-Self-attention" class="headerlink" title="2.3 Multi-head Self-attention"></a>2.3 Multi-head Self-attention</h2><p><code>2.1</code> 节的内容可以看作是 single-head self-attention，重复横向堆叠多个相同的 <strong>scaled dot-product attention</strong> 可以得到 multi-head self-attention，具体过程如下：</p><ol><li>按 <code>2.1</code> 节中得到 $Q, K, V$ 三个矩阵（即输入的 embedding 经三个权重参数线性变换得到 $Q,K,V$ 三个矩阵，这三个权重参数分别为 $W_q,W_k,W_v \in \mathbb R^{d\times n}$）。</li><li><p>记 heads 的数量为 <font color='red'> $h$ </font>，对于第 $i \in [h]$ 个 head，使用三个参数矩阵 $W_i^Q \in \mathbb R^{d \times d_k}, \quad W_i^K \in \mathbb R^{d \times d_k}, \quad W_i^V \in \mathbb R^{d \times d_v}$，分别将 $Q,K,V$ 映射为新的矩阵 <font color='magenta'>$Q_i \in \mathbb R^{T \times d_k}, \quad K_i \in \mathbb R^{T \times d_k}, \quad V_i \in \mathbb R^{T \times d_v}$</font>，注意这里 $\mathbf q_i, \ \mathbf k_i$ 维度相同均为 $d_k$，因为这两个向量需要做内积，</p><script type="math/tex; mode=display">Q_i = Q W_i^Q, \quad K_i = K W_i^K, \quad V_i=V W_i^V, \quad i=1,\cdots, h</script><p> 由于 $Q_i=QW_i^Q=IW_q^TW_i^Q \Rightarrow Q_i=IW_i^{Q’}$，其中 $I$ 为输入的 embedding。所以也可以认为直接从 输入 embedding（word embedding）直接线性转换为 <code>query</code>；对于 <code>key</code> 和 <code>value</code> 类似处理。</p></li><li>每个 head 单独执行 scaled dot-product attention 即，对每个 head $i=1,\cdots,h$<script type="math/tex; mode=display">A_i=Q_i K_i^{\top} / \sqrt {d_k} \in \mathbb R^{T \times T} \\ \hat A_i=\text{softmax} (A_i) \\ O_i =\hat A_i V_i \in \mathbb R^{T \times d_v}</script></li><li>将每个 head 的输出沿着 <code>axis=1</code> 方向 concatenate（类似于<code>torch.hstack</code>），再乘以个输出参数矩阵 $\color{magenta} W^O \in \mathbb R^{hd_v \times d}$，<script type="math/tex; mode=display">O=\text {Concat}(O_1,\cdots, O_h) \in \mathbb R^{T \times hd_v} \\ O:= O W^O \in \color{magenta} \mathbb R^{T \times d}</script></li></ol><p><img src="/images/transformer/self_attention_1.png" alt=""><br>图 2. 左：scaled dot-product attention; 右：multi-head self-attention</p><p>通常取 $d=512, \ h=8, \ d_k=d_v=d/h=64$。</p><p><strong>总结：</strong></p><p>$\text{Transformer}:\mathbb R^{T \times n} \rightarrow \mathbb R^{T \times d}$，其中 $n$ 是 embedding 维度，$d$ 是隐层维度。</p><p><strong>示例代码</strong></p><p>实际操作中，可以将这 <code>h</code> 个 head 中的参数 concatenate 起来，然后一起执行矩阵操作，</p><script type="math/tex; mode=display">W^Q=\begin{bmatrix} W_1^Q & \cdots & W_h^Q \end{bmatrix} \ \in \mathbb R^{d \times d}</script><script type="math/tex; mode=display">Q' = QW^Q=\begin{bmatrix}QW_1^Q & \cdots & QW_h^h \end{bmatrix} \ \in \mathbb R^{T \times d}</script><p>注：embedding dimension 与 model dimension 相同，即 $n=d$。<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># hidden_dim is `d`, fc_q is W^Q</span>fc_q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>fc_k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>fc_v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>fc_o <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span><span class="token comment"># given `query` , `key`, `value`, which are 3 linear transformed results for embedding, respectively</span><span class="token comment"># query, key, value: (batch_size, seq_len, d)</span>Q <span class="token operator">=</span> fc_q<span class="token punctuation">(</span>query<span class="token punctuation">)</span>         <span class="token comment"># Q': (batch_size, seq_len, d)</span>K <span class="token operator">=</span> fc_k<span class="token punctuation">(</span>key<span class="token punctuation">)</span>           <span class="token comment"># K'</span>V <span class="token operator">=</span> fc_v<span class="token punctuation">(</span>value<span class="token punctuation">)</span>         <span class="token comment"># V'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>然后是每个 head 单独执行 scaled dot-product attention，这里必须各个 head 分开执行，因为每个 head 的 attention 维度为 $d_k$ 而不是 $d$，如果是 single head，那么就不需要分开，但是 multi head，必须要分开，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>num_heads<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># hidden_dim = num_heads * head_dim</span><span class="token comment"># after permuting dimensions, shape is (batch_size, num_heads, seq_len, head_dim)</span>Q <span class="token operator">=</span> Q<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> head_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>K <span class="token operator">=</span> K<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> head_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>V <span class="token operator">=</span> V<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> head_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment"># to do attention, we must make the lowest two dimensions be (seq_len, attention_dim)</span><span class="token comment"># A_i = Q_i K_i^&#123;\top&#125;</span><span class="token comment"># transpose the lowest two dimensions of K</span><span class="token comment"># A's shape: (batch_size, num_heads, seq_len, seq_len)</span>A <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>scale      <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>对 attention tensor 归一化，然后执行 dropout 以增强泛化能力，接着与 value 相乘，所有 heads 的结果 concatenate，最后经过一个输出层的线性变换，得到 multi-head self-attention layer 的输出，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>A<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>O <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">,</span> V<span class="token punctuation">)</span>    <span class="token comment"># (batch_size, num_heads, seq_len, head_dim)</span>O <span class="token operator">=</span> O<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># (batch_size, seq_len, num_heads, head_dim)</span>O <span class="token operator">=</span> O<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>  <span class="token comment"># concatenate all heads</span><span class="token comment"># O: (batch_size, seq_len, hidden_dim)</span>O <span class="token operator">=</span> fc_o<span class="token punctuation">(</span>O<span class="token punctuation">)</span>                             <span class="token comment"># refer to fig 2.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>注：</p><ol><li>代码注释中使用 <code>seq_len</code>，表示一个 mini-batch 中最长 sentence 中 word 数量。上文 $T$ 表示单个 sentence 中 word 数量。代码实现中，不使用单个 sentence，而是一个 mini-batch，故对于 short sentence，需要在最后进行 padding，使得长度一致，记为 <code>seq_len</code>。</li><li>输出 $O$ 与 <code>query</code> ,<code>key</code>,<code>value</code> 等具有相同的 shape。</li></ol><h1 id="3-Transformer"><a href="#3-Transformer" class="headerlink" title="3. Transformer"></a>3. Transformer</h1><p><img src="/images/transformer/self_attention_2.png" alt=""><br>图 3. Transformer 模型结构</p><h2 id="3-1-Encoder"><a href="#3-1-Encoder" class="headerlink" title="3.1 Encoder"></a>3.1 Encoder</h2><p>如图 3，左边是 Encoder，$N=6$，即串联 $N$ 个相同结构的 block，</p><ol><li>每个 block 包含两个 layer：multi-head attention 和全连接前馈网络，这两个 layer 有 residual 连接，后跟一个 layer normalization（Layer Norm 对每个样本进行归一化，即在 <code>(C,H,W)</code> 上做归一化，每个样本独立进行）。</li><li>全连接前馈网络由两个全连接层组成</li><li>由于存在 residual 连接，channel dimension 全部取 $d=512$，即，input embedding vector 的维度，multi-head attention 的输出 vector 维度，全连接层的输出维度，全部为 $d=512$。</li><li>Encoder 的输出可用矩阵 $O_e \in \mathbb R^{T \times d}$ 表示。</li></ol><h2 id="3-2-Decoder"><a href="#3-2-Decoder" class="headerlink" title="3.2 Decoder"></a>3.2 Decoder</h2><p>解码器的主体结构是 $N=6$ 的相同 block 的串联，</p><ol><li>Decoder 无法并行计算，因为其 <code>t+1</code> 时刻的输入是其 <code>t</code> 时刻的输出</li><li>每个 block 包含两个 multi-head attention，以及一个全连接前馈网络，这三个 layer 均有 residual 连接。</li><li><p>第二个 multi-head attention 的 <code>key</code> 和 <code>value</code> 为 encoder 的输出，均位于向量空间 $\mathbb R^{T_1 \times d}$，且相同，而 <code>query</code> 为第一个 multi-head attention 的输出，位于向量空间 $\mathbb R^{T_2 \times d}$，此时 <code>query</code> 与 <code>key</code> 的 attention 矩阵为 $A = QK^{\top} \in \mathbb R^{T_2 \times T_1}$，这可能不是一个方阵，但是没关系，不影响对 <code>value</code> 的加权求和，$\hat AV \in \mathbb R^{T_2 \times d}$。</p></li><li><p>虽然 Encoder 和 Decoder 中的 block 数量均为 $N=6$，但是，<strong><font color='red'>使用 Encoder 的最终输出（即最后一个 block 的输出）作为 Decoder 中每个 block 中第二个 multi-head attention 的 <code>key</code> 和 <code>value</code>，而不是 Encoder 中的各个 block 的输出分别作为 Decoder 中各 block 的 <code>key</code> 和 <code>value</code>。</font></strong></p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># trg: (batch_size, trg_len)</span><span class="token comment"># enc_src: output of encoder. has a shape of (batch_size, src_len, hidden_dim)</span>N <span class="token operator">=</span> <span class="token number">6</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>DecoderLayer<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>    <span class="token comment"># all block use the same output of encoder</span>    trg <span class="token operator">=</span> layer<span class="token punctuation">(</span>trg<span class="token punctuation">,</span> enc_src<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>Decoder 在训练和测试阶段，稍有不同。</p><h3 id="3-2-1-Decoder-训练"><a href="#3-2-1-Decoder-训练" class="headerlink" title="3.2.1 Decoder 训练"></a>3.2.1 Decoder 训练</h3><p><strong><font color=#FF88>使用 Teacher Forcing 且是并行化训练</font></strong> 。</p><p>例如将“我有一只猫”翻译为 “I have a cat”，对于 src sentence 和 trg sentence，都要 prepend  <code>&lt;sos_tok&gt;</code> 和 append <code>&lt;eos_tok&gt;</code>，那么 trg sentence 变为 “<code>&lt;sos_tok&gt;</code> I have a cat <code>&lt;eos_tok&gt;</code>”，于是 Decoder 输入应为 (<code>&lt;sos_tok&gt;</code> I have a cat)，输出应为 （I have a cat <code>&lt;eos_tok&gt;</code>），这里输入 sequence 应该去掉最后一个 token，因为我们设计的 Decoder 是根据输入一个词，输出下一个词，而输出 sequence 应该去掉第一个 token。</p><p>使用 sequence 输入输出，实现 Decoder 并行化计算，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh"># target sequence: &lt;sos&gt; I have a cat &lt;eos&gt; &lt;pad&gt; &lt;pad&gt;# （填充了两个 &lt;pad&gt; token）        &lt;sos&gt;  I  have  a  cat    &lt;eos&gt;  &lt;pad&gt;          |    |   |    |   |       |      |    +-------------------------------------------+    |                   Decoder                 |    +-------------------------------------------+          |    |   |    |   |       |      |          I  have  a   cat &lt;eos&gt;   &lt;pad&gt; &lt;pad&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>但是输出是一个一个出来的，而 attention 是对整个 sequence 全局进行的。实际的顺序应该是下面 <code>3.2.2</code> 节中说明的那样，这里一次性给出 sequence 整体仅仅是为了并行化训练，所以对于第 <code>i</code> 个 token，它不能看到之后的 token，也没法跟之后的 token 做 attention，无法进行 $\mathbf q_i \mathbf k_j / \sqrt {d_k}, \ j &gt; i$ 这样的 attention，故需要对 attention 得到的矩阵（上面的矩阵 $A$ ）进行 mask 操作，如图 2 左边部分中的 <code>Mask (opt.)</code>，在 softmax 之前执行 Mask 操作。</p><p>回顾前面内容，attention 矩阵表示一个 sentence 内各 token 之间的 attention，矩阵中第 <code>i</code> 行表示第 <code>i</code> 个 token 与所有 token 之间的 attention，那么第 <code>1</code> 个 token 仅与自身有 attention，第 <code>2</code> 个 token 与前 <code>2</code> 个 token 有 attention，即这个矩阵应该是下三角矩阵（左下方有非 0 值），即，<strong>使用左下方全 1 的下三角矩阵实现 mask 操作</strong>。</p><p>顺便一提，mini-batch 内部分 sentences 在末尾进行了 padding，显然前面的 token 也不应该与这些 padding token 做 attention，应该这些 padding token 本不存在，仅仅是因为 tensor 需要才进行补全。</p><p>由于 attention 是作为 $\mathbf v_i$ 的权重，不存在的 attention 其权重应该为 $0$，使得相应的 $\mathbf v_i$ 贡献为 $0$。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">src_pad_idx <span class="token operator">=</span> <span class="token number">0</span>trg_pad_idx <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">make_src_mask</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># src: (batch_size, seq_len), src contains all indices of tokens</span>    src_mask <span class="token operator">=</span> <span class="token punctuation">(</span>src <span class="token operator">!=</span> src_pad_idx<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment"># src_mask: (batch_size, 1, 1, seq_len)</span>    <span class="token comment"># after dimension broadcasting, the right-bottom sub-matrix of src_mask is 0</span>    <span class="token keyword">return</span> src_mask<span class="token keyword">def</span> <span class="token function">make_trg_mask</span><span class="token punctuation">(</span>trg<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># trg: (batch_size, seq_len), where `seq_len` may not be equal to that in src</span>    trg_pad_mask <span class="token operator">=</span> <span class="token punctuation">(</span>trg <span class="token operator">!=</span> trg_pad_idx<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment"># trg_pad_mask: (batch_size, 1, 1, seq_len)</span>    seq_len <span class="token operator">=</span> trg<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    trg_sub_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tril<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> diagonal<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    trg_mask <span class="token operator">=</span> trg_pad_mask <span class="token operator">&amp;</span> trg_sub_mask    <span class="token comment"># trg_mask: (batch_size, 1, seq_len, seq_len)</span>    <span class="token keyword">return</span> trg_mask<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如图 2 左侧，对 scale 之后的结果（ $Q_i K_i^{\top} / \sqrt {d_k}$）进行 mask，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># A = torch.matmul(Q, K.permute(0, 1, 3, 2))/scale   # refer to the related code above in section 2.3</span><span class="token comment"># A's shape: (batch_size, num_heads, seq_len, seq_len)</span>A <span class="token operator">=</span> A<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>mask<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1e10</span><span class="token punctuation">)</span>   <span class="token comment"># after softmax, -1e10 is enough to approach 0</span><span class="token comment"># A = torch.softmax(A, dim=-1)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>从 Decoder 的输入输出 tensor shape 来分析一波：</p><p>从 target dataset 获得的 mini-batch，记为变量 <code>trg</code>， 具有 shape： <code>(batch_size, trg_len+1)</code>，Decoder 的输入为 <code>trg[:,:-1]</code>，Decoder 网络的 gt sequence 为 <code>trg[:,1:]</code>，这两个变量的 shape 均为 <code>(batch_size, trg_len)</code>，</p><p>其中输入经过 embedding，shape 变为 <code>(batch_size, trg_len, hidden_dim)</code>，注意 <code>embedding_dim=hidden_dim</code>，然后经过 Decoder 的 <code>Nx</code> 个 block 后，shape 保持不变，最后经过一个全连接层（fc）和 Softmax 层，其中 fc 线性变换后 tensor shape 变为<br><code>(batch_size, trg_len, out_dim)</code>，这里 <code>out_dim</code> 为 target 词汇表大小（包括了 pad_tok，sos_tok, eos_tok），fc 的输出就是 tokens 的非归一化得分，而 Decoder 的 gt shape 为 <code>(batch_size, trg_len)</code>，很显然，使用 PyTorch 中的 <code>CrossEntropyLoss</code> 可计算损失（这个类内部包含了 softmax，所以预测为非归一化得分）。</p><p><strong>目标函数（loss）</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># suppose trg is the torch.tensor that stores indices of all tokens in a mini-batch</span><span class="token comment">#   after padding and aligning</span><span class="token comment"># trg: (batch_size, trg_len+1). trg_len is just seq_len, but in order to distinguish </span><span class="token comment">#   with that for src, use trg_len instead and use src_len to represent </span><span class="token comment">#   seq_len of src</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_idx<span class="token operator">=</span>TRG_PAD_IDX<span class="token punctuation">)</span>model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>output <span class="token operator">=</span> model<span class="token punctuation">(</span>src<span class="token punctuation">,</span> trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token comment"># （batch_size, trg_len, out_dim)</span>output <span class="token operator">=</span> output<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span>trg <span class="token operator">=</span> trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> trg<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意上面代码片段中，指明 <code>ignore_idx=TRG_PAD_IDX</code>。以前面举的例子来说明，<br><pre class="line-numbers language-none"><code class="language-none">target sequence: &lt;sos&gt; I have a cat &lt;eos&gt; &lt;pad&gt; &lt;pad&gt;填充了两个 &lt;pad&gt; token）gt: I have a cat &lt;eos&gt; &lt;pad&gt; &lt;pad&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>显然，计算交叉熵损失时，应该计算 <code>I have a cat &lt;eos&gt;</code> 这些 token 的损失，而后面填补的两个 <code>&lt;pad&gt;</code> token 则不应该包含在损失计算中。因为这两个 <code>&lt;pad&gt;</code> token 仅仅是为了填充使得数据对齐从而可以存储在 tensor 中，实际上它们本不应该存在，损失则无从说起，毕竟前面已经有 <code>&lt;eos&gt;</code> 了，后面的 token 可以随便预测，都算对，因为从 <code>&lt;eos&gt;</code> 往后都被截断了，对与不对都不重要，故不应该作为惩罚性添加到 loss 中。这类似于目标检测中，只对正例 region 计算坐标回归损失，而负例 region 则不需要计算坐标回归损失。</p><h3 id="3-2-2-Decoder-测试"><a href="#3-2-2-Decoder-测试" class="headerlink" title="3.2.2 Decoder 测试"></a>3.2.2 Decoder 测试</h3><p> 根据上一小节的分析，Decoder 输入和输出（这里的输出指经过了 argmax 之后的值）具有相同的 shape：<code>(batch_size, trg_len)</code>，简单起见，令 <code>batch_size=1</code>，于是<br> Decoder 实际的顺序应该是：</p><ol><li>输入 <code>[[&lt;sos&gt;]]</code>，输出 <code>[[I]]</code></li><li>输入 <code>[[&lt;sos&gt;, I]]</code>，输出 <code>[[I, have]]</code></li><li>输入 <code>[[&lt;sos&gt;, I, have]]</code>，输出 <code>[[I, have, a]]</code></li><li>输入 <code>[[&lt;sos&gt;, I, have, a]]</code>，输出 <code>[[I, have, a, cat]]</code></li><li>输入 <code>[[&lt;sos&gt;, I, have, a, cat]]</code>，输出 <code>[[I, have, a, cat, &lt;eos&gt;]]</code>，结束。<pre class="line-numbers language-python" data-language="python"><code class="language-python"> max_len <span class="token operator">=</span> <span class="token number">50</span> <span class="token comment"># 根据经验手动设置一个值，使得 sentence 长度不超过 `max_len-2`</span> model <span class="token operator">=</span> Seq2seq<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># enc_src: output of encoder</span>trg_idxs <span class="token operator">=</span> <span class="token punctuation">[</span>TRG<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>stoi<span class="token punctuation">[</span>TRG<span class="token punctuation">.</span>init_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_len<span class="token punctuation">)</span><span class="token punctuation">:</span>    trg <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>trg_idxs<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    trg_mask <span class="token operator">=</span> make_trg_mask<span class="token punctuation">(</span>trg<span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> model<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>trg<span class="token punctuation">,</span> enc_src<span class="token punctuation">,</span> trg_mask<span class="token punctuation">,</span> src_mask<span class="token punctuation">)</span>    pred_idx <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    trg_idxs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred_idx<span class="token punctuation">)</span>    <span class="token keyword">if</span> pred_token <span class="token operator">==</span> TRG<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>stoi<span class="token punctuation">[</span>TRG<span class="token punctuation">.</span>eos_token<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">break</span><span class="token comment"># pred_tokens contains &lt;sos_tok> and &lt;eos_tok ></span>pred_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>TRG<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>itos<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> trg_idxs<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="3-3-前馈网络"><a href="#3-3-前馈网络" class="headerlink" title="3.3 前馈网络"></a>3.3 前馈网络</h2><p>Encoder 和 Decoder 的 block 中除了 attention 模块，还有前馈网络（FFN），这个 FFN 由两个全连接层组成，两个全连接层中间有一个 ReLU，</p><script type="math/tex; mode=display">FFN(x)=\max(0, xW_1+b_1)W_2 + b_2</script><h2 id="3-4-Position-Encoding"><a href="#3-4-Position-Encoding" class="headerlink" title="3.4 Position Encoding"></a>3.4 Position Encoding</h2><p>通过前面对 attention 的介绍可知，各 time step 的输入其实是位置无关的，因为每个 time step 输入的 attention 操作都是全局进行的，即 <code>i</code> 位置的输入 $\mathbf x_i$，其 attention 记为 $\mathbf o_i$，如果换到 <code>j</code> 位置，其 attention 结果记为 $\mathbf o_j$，显然有 $\mathbf o_i = \mathbf o_j$。例如 “A打B” 和 “B打A”，前者 A 是打人，后者 A 是被打，但是 attention 输出却一样，所以不合理。考虑位置信息后，就可以解决这个问题。</p><p>使用 one-hot vector 来表示位置信息，例如第 <code>i</code> time step 输入 $\mathbf x_i$，其位置信息的 one-hot vector 为 $\mathbf p_i = [\underbrace{0,\cdots, 0}_{i-1}, 1, \underbrace {0, \cdots, 0}_{L-i}]$，其中 $L$ 是 max sequence length，即数据集（或一个 minibatch 中）所有 sentences 中最长的 sentence 长度（words 数量），或者根据具体任务和经验手动设置一个较大的数，数据集中长度大于 $L$ 的 sentence 都会被截断使得长度为 $L$，例如 $L=100$。于是叠加位置信息后的最终的 embedding 为</p><script type="math/tex; mode=display">\begin{bmatrix}W^I & W^P\end{bmatrix}\begin{bmatrix}\mathbf x_i \\ \mathbf p_i\end{bmatrix}=\mathbf o_i + \mathbf e_i</script><p>即，输入的 embedding 与位置信息的 embedding 相加。论文中提到，对于 $\mathbf o_i$ 需要进行 scale，相当于对这两种 embedding 赋予不同的权重，$\lambda \cdot\mathbf o_i + \mathbf e_i$，通常取 $\lambda = \sqrt d$。</p><p>$W^I$ 就是上面所说的 embedding 矩阵，可以训练得到（参见 <a href="/2022/01/19/pytorch/embedding">embedding</a> ）。 $W^P \in \mathbb R^{n \times L}$ 则表示位置信息的 embedding 矩阵，$n$ 为 embedding dimension。$W^P$ 可以与 $W^I$ 一样训练得到，也可以使用公式计算得到。</p><p>训练得到 embedding 矩阵<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">hidden_dim <span class="token operator">=</span> <span class="token number">512</span>L <span class="token operator">=</span> <span class="token number">100</span><span class="token comment"># hidden_dim is usually equal to model dimension `d`</span>tok_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>   <span class="token comment"># (l, d)</span>pos_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>L<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span><span class="token comment"># scale the token embedding, i.e., a balance factor between</span><span class="token comment">#   token embedding and position embedding</span>scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>hidden_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># src: (batch_size, seq_len)</span><span class="token comment">#   where seq_len is the max sequence length of sentences in this batch</span>batch_size <span class="token operator">=</span> <span class="token number">8</span>seq_len <span class="token operator">=</span> <span class="token number">10</span>V <span class="token operator">=</span> <span class="token number">100</span>     <span class="token comment"># 1-99 is indices of words, 0 is the index of padding</span>src <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    l <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span>    s <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    c <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>seq_len<span class="token operator">-</span>l<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span>    src<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># pos: (batch_size, seq_len)</span>pos <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tok_embedding<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token operator">*</span>scale <span class="token operator">+</span> pos_embedding<span class="token punctuation">(</span>pos<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>公式计算 position embedding</p><script type="math/tex; mode=display">PE(pos, 2i)=\sin (pos/10000^{2i/d})\\PE(pos, 2i+1)=\cos(pos/10000^{2i/d})</script><p>其中 $pos$ 表示 sequence 中 word 的位置，范围为 <code>[0,seq_len-1]</code>，$2i$ 和 $2i+1$ 表示 position embedding vector 中的 index，由于 position embedding 维度为 $d$，故<br>$i \le \lfloor d/2 \rfloor$<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">d <span class="token operator">=</span> <span class="token number">512</span>                             <span class="token comment"># model dimension</span>L <span class="token operator">=</span> <span class="token number">100</span>                             <span class="token comment"># seq_len &lt;= L</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span>              <span class="token comment"># [1~L]</span>a <span class="token operator">=</span> a <span class="token operator">/</span> <span class="token number">10000</span>                       <span class="token comment"># [1/10000 ~ L/10000]</span>a <span class="token operator">=</span> a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> d<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># (L, d//2)</span>e <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> d<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">/</span> d   <span class="token comment"># (d//2,)  [0/d,2/d,...]</span>e <span class="token operator">=</span> e<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>L<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># (L, d//2)</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> e<span class="token punctuation">)</span>s <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>a<span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>a<span class="token punctuation">)</span>PE <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>L<span class="token punctuation">,</span> d<span class="token punctuation">)</span>PE<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> sPE<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span>d<span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> c<span class="token comment"># get the position embedding for current mini-batch</span>pos <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span>pe <span class="token operator">=</span> PE<span class="token punctuation">[</span>pos<span class="token punctuation">]</span>    <span class="token comment"># (seq_len, d)</span>pe <span class="token operator">=</span> pe<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tok_embedding<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token operator">*</span>scale <span class="token operator">+</span> pe<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/340149804">Vision Transformer 超详细解读</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPN 回顾</title>
      <link href="/2022/01/12/obj_det/fpn/"/>
      <url>/2022/01/12/obj_det/fpn/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1612.03144">Feature Pyramid Networks for Object Detection</a></p><p>本文是对 FPN 的回顾，适用于复习 FPN，或者快速查看 FPN 实现的关键细节。<br><span id="more"></span></p><h1 id="1-网络"><a href="#1-网络" class="headerlink" title="1. 网络"></a>1. 网络</h1><p>目标检测是使用 backbone 得到 feature maps，然后在 feature 上进行检测。根据 feature scale 可分如下四种情况，<br><img src="/images/obj_det/fpn1.png" alt=""></p><p>图 1</p><p><strong>FPN 使用上图 (d) 的结构，这是因为，网络高层的输出 feature 的语义较强，但是感受野较大，scale 较小，导致小目标很难检测出来，而低层输出 feature 的 scale 够大，但是语义较弱，故自然而然想到将具有较强语义的高层 feature 融合进低层 feature 中。</strong></p><p>FPN 在 Faster R-CNN 的基础上进行修改，backbone（或称 baseline）使用 ResNet。</p><h2 id="1-1-Bottom-up"><a href="#1-1-Bottom-up" class="headerlink" title="1.1 Bottom-up"></a>1.1 Bottom-up</h2><p>Bottom-up 就是 backbone 的前向传播，使用 ResNet，使用 <code>stage2~5</code> 的输出特征，每个 stage 使用最后一个 layer 的激活输出（即 ReLU 后的数据），下采样率分别为 $[4, 8, 16, 32]$，每个 stage 的最后一个 block 记为 $[C_2, C_3, C_4, C_5]$。（不用 <code>conv1</code> 的输出特征是为了节约内存）</p><h2 id="1-2-Top-down-和-横向连接"><a href="#1-2-Top-down-和-横向连接" class="headerlink" title="1.2 Top-down 和 横向连接"></a>1.2 Top-down 和 横向连接</h2><p>自顶向下，上层特征需要上采样（<code>2x</code>）然后下层特征经过 <code>1x1 Conv</code> 进行调整（使得 channels 相匹配），然后两者可进行融合。如图 2，</p><p><img src="/images/obj_det/fpn2.png" alt=""><br>图 2. </p><p>说明：</p><ol><li>上采样采用最近邻法（或者插值法）</li><li>融合采用 element-wise 相加</li><li>所有层横向连接中的 <code>1x1 Conv</code> 均降低 bottom-up 的特征 channels 为 <code>d</code>。例如 ResNet-n($n \ge 50$)，<code>C2,C3,C4,C5</code> 的 channels 最小值为 <code>256</code>，故可取 <code>d=256</code>，即，所有横向连接以及 top-down 结构中均为 <code>d=256</code>。</li><li>每层融合后的特征分别经过一个 <code>3x3 Conv</code> 得到最终的 feature maps，这个 <code>3x3 Conv</code> 降低（调整）上采样的偏差影响。</li><li>横线连接和 top-down 结构中的卷积<strong>没有非线性激活</strong>，论文中指出，去掉非线性激活对结果影响较小。</li><li>横向连接的 <code>1x1 Conv</code> 不是所有 level 共享？</li></ol><p>注：与前面保持一致地，<code>Conv</code> 只表示卷积这个单一操作，而 <code>conv</code> 表示 <code>Conv+BN+ReLU</code> 这个组合（早期的工作中，还未诞生 <code>BN</code>，彼时  <code>conv</code> 表示 <code>Conv+ReLU</code>）。</p><h2 id="1-3-feature-maps"><a href="#1-3-feature-maps" class="headerlink" title="1.3 feature maps"></a>1.3 feature maps</h2><p>最终得到 feature maps，记为 $\{P_2, P_3,P_4,P_5\}$。此外，为了覆盖更大的目标 size，额外增加一个 $P_6$，是对 $P_5$ 进行 <code>2x</code> 的下采样得到。</p><h1 id="2-RPN-应用-FPN"><a href="#2-RPN-应用-FPN" class="headerlink" title="2. RPN 应用 FPN"></a>2. RPN 应用 FPN</h1><p>由于是在 Faster R-CNN 进行修改，故先看 RPN 部分。首先 feature maps 由单一 sacle 变成 FPN 的多 scales，每个 scale 的 feature maps 上，均采用 <code>3x3 conv</code> 以及两个并列的 <code>1x1 conv</code> （分别用于生成 object/non-object 的二分类得分和基于 anchor 的坐标偏差回归）。</p><ol><li>每个 scale 的 feature maps 上使用 单个 scale 的 anchor，对于 ${P_2,P_3,P_4,P_5,P_6}$，anchor area 分别为 $\{32^2, 64^2, 128^2, 256^2, 512^2\}$，aspect ratios 取 $\{1/2, 1, 2\}$ 三种，故每个 spatial point 有 <code>k=3</code> 个 anchors。</li><li>正例 anchors：与 gt boxes 的最大 IOU 大于 <code>0.7</code></li><li>负例 anchors：与 gt boxes 的最大 IOU 小于 <code>0.3</code></li><li>network head（即，两个 <code>1x1 conv</code>，输出 channels 不同，分别为 <code>2k</code> 和 <code>4k</code>），在<strong>所有 level 共享参数</strong></li></ol><h1 id="3-Fast-RCNN-应用-FPN"><a href="#3-Fast-RCNN-应用-FPN" class="headerlink" title="3. Fast RCNN 应用 FPN"></a>3. Fast RCNN 应用 FPN</h1><p>通过 RPN 得到 ROIs 之后，由于 backbone 生成多 scale 的 feature maps，所以需要确定某个 ROI 应该对应哪个 scale。记 ROI 的 size 为 <code>(h, w)</code>，那么 feature pyramid $P_k$ 根据下式确定：</p><script type="math/tex; mode=display">k=\lfloor k_0 + \log_2 (\sqrt {wh} / 224) \rfloor</script><p>其中 $k_0=4$ 。这是因为 ResNet based Faster R-CNN 中，输入 size 为 $224 \times 224$，使用 $C_4$ 作为单 scale 的 feature maps，作为类比，这里使用 $k_0=4$ 比较合适。</p><ol><li>在每个 level 上使用 predictor heads（一个分类器和一个 bbox 坐标偏差回归器），与 Faster R-CNN 一样，feature maps 首先经过 ROIPooling，得到 <code>7x7</code> 的特征 size，经过连续两个全连接层 <code>fc+relu+drop</code> （这两个 fc layer 输出 channels 均为 <code>124</code>），然后分别使用分类器（crossentropyloss）和回归器（MSE）。</li><li>每个 level 上的 predictor heads 共享参数。</li><li>Fast R-CNN 不使用 $P_6$。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类网络（二）</title>
      <link href="/2021/12/27/img_cls/baselines_2/"/>
      <url>/2021/12/27/img_cls/baselines_2/</url>
      
        <content type="html"><![CDATA[<p><strong>总结</strong> 图像分类网络的结构，包括 <code>ResNeXt</code>, <code>ShuffleNet</code>, <code>ShuffleNetV2</code>, <code>SENet</code>， 以及 <code>Res2Net</code> 。</p><span id="more"></span><h1 id="1-ResNeXt"><a href="#1-ResNeXt" class="headerlink" title="1. ResNeXt"></a>1. ResNeXt</h1><p>论文地址：<a href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a></p><p>主要思路：<strong>分组卷积</strong>，改造 ResNet 中的 Bottleneck block，如图 1，<br><img src="/images/img_cls/baselines2_1.png" alt=""><br>图 1. 左：ResNet 中的 block；右：ResNeXt 中的 block，称 path 的数量为 <code>cardinality</code>，图中 <code>cardinality=32</code>。（每一 layer 的标注顺序：<code>in_channels, filter size, out_channels</code>）</p><blockquote><p>图 1 中多路分支的 <code>3x3</code> 卷积实际上就是 <code>128, 3x3, 128</code> 的分组卷积。</p></blockquote><p>除了图 1 中的这种划分方法，还有其他两种方法，如图 2，<br><img src="/images/img_cls/baselines2_2.png" alt=""><br>图 2. ResNeXt 可用的三种 block 结构。</p><p>整个 ResNeXt 结构如图 3，从图中可见，大体框架相同，只是 block 不同。<br><img src="/images/img_cls/baselines2_3.png" alt=""><br>图 3. ResNet 与 ResNeXt 结构对比。<code>C</code> 表示 <code>cardinality</code> 。</p><p>说明：</p><ol><li>ResNeXt 就是在 ResNet 基础之上，对 block 加以改进，即 <code>3x3 conv</code> 变为分组卷积，其他则几乎保持不变，故：</li><li><code>stage 3/4/5</code> 的第一个 block（内的 <code>3x3 conv group</code>）有 <code>stride=2</code>。</li><li>整个网络的 down sampling rate 为 $2^5=32$。</li><li>在 <code>stride=2</code> 的 block 上的 shortcut 分支需要一个 <code>downsample</code> 映射函数，将 <code>x</code> 的 channel 增加一倍，feature size 缩小原来的到 $1/2 \times 1/ 2$。</li></ol><h1 id="2-ShuffleNet"><a href="#2-ShuffleNet" class="headerlink" title="2. ShuffleNet"></a>2. ShuffleNet</h1><p>论文地址：<a href="https://arxiv.org/abs/1707.01083">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a></p><h2 id="2-1-Channel-Shuffle"><a href="#2-1-Channel-Shuffle" class="headerlink" title="2.1 Channel Shuffle"></a>2.1 Channel Shuffle</h2><p>MobileNet 中采用了对 <code>3x3 conv</code> 采用了 depthwise seprable conv，导致在一个 block 中， <code>1x1 conv</code> 计算量占比非常高，ShuffleNet 对 <code>1x1 conv</code> 也采用分组卷积，但是连续的分组卷积，导致某个输出 channel 只能从一部分输入通道中获取信息，如图 4，于是 ShuffleNet 在 <code>1x1 conv</code> 分组卷积之前，将 channel 顺序重组，降低连续分组卷积导致的 side effect，<br><img src="/images/img_cls/baselines2_4.png" alt=""><br>图 4. 分组数量为 <code>3</code>。左：连续两次分组卷积；中：第一次分组卷积之后，将 channel 重组，使得重组后每个分组具有所有原来分组中的部分 channel；右：使用 channel shuffle 实现 channel 重组，与（中）等效。</p><blockquote><p>channel shuffle 操作：记 channel 数量为 <code>g x n</code>，<code>g</code> 为分组数量，<code>n</code> 为每个分组内的 channel 数量；reshape channel 为 <code>(g,n)</code>，然后转置为 <code>(n, g)</code>，然后再 flatten 为 <code>n x g</code>，即可。</p></blockquote><h2 id="2-2-ShuffleNet-网络结构"><a href="#2-2-ShuffleNet-网络结构" class="headerlink" title="2.2 ShuffleNet 网络结构"></a>2.2 ShuffleNet 网络结构</h2><p>ShuffleNet Unit 如图 5，<br><img src="/images/img_cls/baselines2_5.png" alt=""><br>图 5. 左：ResNet 中的 bottleneck block。中：第一个 <code>1x1 conv</code> 后使用了 channel shuffle，第二个 <code>1x1 conv</code> 后没有 channel shuffle（实验验证说明使用了也没有什么改善）；右：stride=2 的 block。</p><p>图 5 的说明：</p><ol><li><code>GConv</code> 表示分组卷积。<code>DWConv</code> 表示深度可分离卷积。</li><li><code>DWConv</code> 后没有 <code>ReLU</code>。</li><li><code>stride=2</code> 时，shortcut 采用 <code>(3x3 avg pool stride=2)</code> 进行降采样，然后使用 <code>concat</code> 进行 <strong>特征融合</strong>。</li></ol><p>ShuffleNet 总体结构如图 6 所示，<br><img src="/images/img_cls/baselines2_6.png" alt=""><br>图 6. ShuffleNet 网络。<code>Stage 2</code> 的第一个 <code>1x1 conv</code> 没有应用 <code>group conv</code>，这是因为其输入 channel 太小（为 <code>24</code>）。</p><p>图 6 的补充说明：</p><ol><li>三个 <code>stage</code>，每个 <code>stage</code> 的第一个 <code>block</code> 具有 <code>stride=2</code>，具有 <code>stride=2</code> 的 block 结构参见图 5 右。</li><li>ShuffleNet Unit 的各 layer 参数为 <code>c, 1x1, m, g</code> -&gt; <code>channel shuffle</code> -&gt; <code>m, 3x3, m, dwConv</code> -&gt; <code>m, 1x1, c,g</code>，其中 <code>c</code> 为 block 的输入 channel，<code>m</code> 为 bottleneck 的 channel。</li><li><code>block</code> 的内部 bottleneck 的 channel （参见图 5 中间 block 的第一个 <code>1x1 GConv</code> 的输出 channel）为 block 输出 channel 的 <code>1/4</code>，例如，<code>stage 2</code> 的每个 block 的输出 channel 为 <code>200</code>（对应 <code>g=2</code> 这个 case），那么 bottleneck channel 为 <code>50</code>。</li><li>整个网络的 down sampling rate 为 $2^5=32$。</li><li>为进一步控制网络的复杂度，对各 layer 的输出 channel，乘以一个因子， <code>s</code>，图 6 中则对应 <code>s=1</code> 的情况，记为 <code>ShuffleNet 1x</code>，那么 <code>ShuffleNet sx</code> 则大约是 <code>ShuffleNet 1x</code> 复杂度的 $s^2$ 倍。</li></ol><h1 id="3-ShuffleNetV2"><a href="#3-ShuffleNetV2" class="headerlink" title="3. ShuffleNetV2"></a>3. ShuffleNetV2</h1><p>论文：<a href="https://arxiv.org/abs/1807.11164">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a></p><p>本文所考虑的点：</p><ol><li>FLOP 是间接指标，network 运行速度才是直接指标，而影响速度的除了 FLOP，还有 memory access cost（<strong>MAC</strong>）等。此外，CUDNN 库中，<code>3x3</code> 卷积并不比 <code>1x1</code> 卷积慢 <code>9</code> 倍。</li><li>network 运行在不同的设备上，其速度也不同，例如 GPU 和 ARM，过去声称为了 移动设备 而设计的网络如 MobileNet 和 ShuffleNet 并没有真正在移动设备上测试。</li></ol><p>分析（以下结论的前提是 <code>FLOP</code> 保持不变）：</p><ol><li>输入输出 channel 相等时 MAC 最小。</li><li>分组卷积中，分组数量越大, MAC 也越大。</li><li>增加网络分支数量会降低计算的并行度。</li><li>Element-wise 计算不可忽略。</li></ol><h2 id="3-1-ShuffleNetV2-网络设计"><a href="#3-1-ShuffleNetV2-网络设计" class="headerlink" title="3.1 ShuffleNetV2 网络设计"></a>3.1 ShuffleNetV2 网络设计</h2><p>在 ShuffleNetV1 基础上进行修改，如图 7 所示，<br><img src="/images/img_cls/baselines2_7.png" alt=""></p><p>图 7. 左一： basic ShuffleNet block；左二：具有 down sampling(2x) 的 ShuffleNet block；左三：basic ShuffleNetV2 block；右一：具有 down sampling(2x) 的 ShuffleNetV2 block。</p><p>ShuffleNetV2 的说明：</p><ol><li>block 的输入沿 channel 方向 split 成两部分（通常是 <code>二等分</code>）：一部分作为 identity shortcut；另一部分经过<strong>三个卷积层</strong>，输入输出 channel 均相同。</li><li>block 中的两个 <code>1x1 conv</code> 不是 group Conv，而是普通 Conv（分组数量大会增加 MAC）。另外 channel split 可视作一种分组。</li><li>最后两个分支 concatenate，使得 block 的输入输出 channel 保持相等。</li><li>block 的最后使用 <code>channel shuffle</code>，这样是为了使得两个分组之间实现信息交流。</li><li>down sampling rate 为 <code>2</code> 时，去掉 <code>channel split</code> 这个操作，故 block 的输出 channel 变为 <code>2</code> 倍。</li></ol><p>整个网络的结构如图 8，</p><p><img src="/images/img_cls/baselines2_8.png" alt=""><br>图 8. ShuffleNetV2 的网络结构。分别取四种不同的 channel。</p><p>说明：</p><ol><li>Global Pool 之前增加了一个 <code>1x1 conv</code>，用于 mix up features。</li></ol><h1 id="4-SENet"><a href="#4-SENet" class="headerlink" title="4. SENet"></a>4. SENet</h1><p>论文：<a href="https://arxiv.org/abs/1709.01507">Squeeze-and-Excitation Networks</a></p><p>思路：上一 layer 的输出经过 channel 加权后再输入到下一 layer。如图 9 所示，<br><img src="/images/img_cls/baselines2_9.png" alt=""></p><h2 id="4-1-squeeze"><a href="#4-1-squeeze" class="headerlink" title="4.1 squeeze"></a>4.1 squeeze</h2><script type="math/tex; mode=display">z_c=\mathbf F_{sq}(\mathbf u_c)=\frac 1 {H \times W} \sum_{i=1}^H \sum_{j=1}^W u_c(i,j)</script><h2 id="4-2-Excitation"><a href="#4-2-Excitation" class="headerlink" title="4.2 Excitation"></a>4.2 Excitation</h2><script type="math/tex; mode=display">\mathbf s = \mathbf F_{ex}(\mathbf z, \mathbf W)=\sigma(g(\mathbf z, \mathbf W)) = \sigma(\mathbf W_2 \cdot \delta(\mathbf W_1 \cdot \mathbf z))</script><p>其中 $\mathbf W_1 \in \mathbb R^{\frac C r \times C}$，$\mathbf W_2 \in \mathbb R^{C \times \frac C r}$。$\delta$ 是 ReLU 函数， $\sigma$ 是 sigmoid 函数。</p><p>最终的输出则为</p><script type="math/tex; mode=display">\hat {\mathbf x_c} = \mathbf F_{scale} (\mathbf u_c, s_c) = s_c \mathbf u_c</script><p>$c$ 为 channel 编号。</p><p>整个过程如图 10 所示，</p><p><img src="/images/img_cls/baselines2_10.png" alt=""></p><p>图 10. 左：在 Inception 上使用 SE block；右：在 Residual 上使用 SE block</p><p><img src="/images/img_cls/baselines2_11.png" alt=""><br>图 11. 左：ResNet-50；中：SE-ResNet-50；右：SE-ResNeXt-50</p><h1 id="5-Res2Net"><a href="#5-Res2Net" class="headerlink" title="5. Res2Net"></a>5. Res2Net</h1><p>论文：Res2Net: <a href="https://arxiv.org/abs/1904.01169">A New Multi-scale Backbone Architecture</a></p><p>设计一个具有 multi-scale 特征的网络，以前的网络为了达到这一目的，均依赖于多个 layer，每个 layer 的输出 feature 的空间 size 不同，这是从 layer 层面实现，本文在 layer 内部实现 multi-scale 特征，具有更细粒度的级别，如图 12，</p><p><img src="/images/img_cls/baselines2_12.png" alt=""></p><p>图 12. 左：普通的 bottleneck block；右：Res2Net 模块，图中 scale dimension <code>s=4</code>。</p><p>说明：</p><ol><li>将 <code>3x3 conv</code> 输出 channel 为 <code>n</code> 的 filters 替换为若干组小的 filters，每组 filters 的输出 channel 为 <code>w</code> （即，每组 <code>w</code> 个 filter）。</li><li>将输入 feature maps 分成若干组。取第一组 filters，对一组 input feature maps 抽取特征，然后与另一组 input feature maps 一起（elementwise add?）送入第二组 filters，直到用完所有 filters。</li><li>每次引入一个 <code>3x3 conv</code>，感受野就增大，从而得到 multi-scale 的特征。</li></ol><h2 id="5-1-Res2Net-模块"><a href="#5-1-Res2Net-模块" class="headerlink" title="5.1 Res2Net 模块"></a>5.1 Res2Net 模块</h2><p>Res2Net 模块中，<code>1x1 conv</code> 之后，feature maps 被等分成 <code>s</code> 份，记 $\mathbf x_i, \ i \in \{1,2,\ldots , s\}$，每个 $\mathbf x_i$ 空间 size 相等，但是 channel 为原来的  $1/s$，除 $\mathbf x_1$ 之外，每个 $\mathbf x_i$ 对应一组 <code>3x3 conv</code> filters，记为 $\mathbf K_i$，显然有 $i &gt; 1$，这组 filters 的输出为 $\mathbf y_i$，$\mathbf x_i$ 与 $\mathbf K_{i-1}$ 的输出相加，然后作为 $\mathbf K_i$ 的输入，于是</p><script type="math/tex; mode=display">\mathbf y_i = \begin{cases}\mathbf x_i & i=1 \\ \mathbf K_i(\mathbf x_i) & i=2 \\ \mathbf K_i(\mathbf x_i + \mathbf y_{i-1}) & 2 < i \le s \end{cases}</script><p>所有的 $\mathbf y_i$ concatenate，然后通过 <code>1x1 conv</code> 进行特征融合。</p><p>如图 13，还可以结合 SE block（先 squeeze 得到 <code>1x1xC</code> 的特征，然后 excite 得到 <code>1x1xC</code> 的 channel 权重） 和 cardinality dimension（分组卷积），</p><p><img src="/images/img_cls/baselines2_13.png" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> image classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类网络（一）</title>
      <link href="/2021/12/23/img_cls/baselines_1/"/>
      <url>/2021/12/23/img_cls/baselines_1/</url>
      
        <content type="html"><![CDATA[<p><strong>总结</strong> 图像分类网络的结构，包括 <code>VGG</code>, <code>ResNet</code>, <code>DenseNet</code>, <code>MobileNet</code>， <code>MobileNetV2</code> 以及 <code>Inception</code> 。</p><span id="more"></span><h1 id="1-VGG"><a href="#1-VGG" class="headerlink" title="1. VGG"></a>1. VGG</h1><p><a href="https://arxiv.org/abs/1409.1556">论文地址</a></p><p>VGG 网络结构如图 1 所示，<br><img src="/images/img_cls/baselines_1.png" alt=""></p><p>图 1. VGG 网络结构。卷积层为 “conv<kernel size>-<output channels>“ 的表示形式。表格中粗体表示新增的 layer。ReLU 省略（实际上每个 Conv 后面都跟一个 ReLU 激活层，Conv-ReLU 表示一个 layer。）</p><p>说明：</p><ol><li><p><strong>LRN</strong> 表示 Local Response Normalisation。表示对某层的激活值做归一化，用到同一 output feature 空间位置 (x,y)，不同 channel 的激活值加权平均，具体可参考论文 <a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a> 。VGG 论文中指出 LRN 在 ILSVRC 数据集上并不能带来提升，故对于较深的 VGG13 ~ VGG19 均没有采用 LRN。</p></li><li><p>整个网络的 down sampling rate 为 $2^5=32$。如果网络 input size 为 <code>(224,224)</code>，那么输出特征 size 为 <code>(7,7)</code>。</p></li></ol><h1 id="2-ResNet"><a href="#2-ResNet" class="headerlink" title="2. ResNet"></a>2. ResNet</h1><p><a href="https://arxiv.org/abs/1512.03385">论文地址</a></p><p>ResNet 网络结构如图 2，<br><img src="/images/img_cls/resnet_1.png" alt=""></p><p>图 2. ResNet 结构。</p><p>说明：</p><ol><li><p><code>conv2_x</code> 中 <code>x</code> 表示第二组卷积中的第 <code>x</code> 个卷积块，conv-block。每个 conv block 由 方括号中所列的 conv layer 堆叠而成。每个 conv layer 均为 <code>Conv-bn-ReLU</code> 的形式。</p></li><li><p>当网络较深时（50-layers 以上），改变 conv block，如图 3，</p><p> <img src="/images/img_cls/resnet_2.png" alt=""><br> 图 3. 左：普通 conv block；右：bottle-neck conv block</p></li><li><p>每个 conv block 有一个并列的 shortcut 分支。例如 <code>conv2_1</code> 这个 conv block，其输入 记为 <code>x</code>，在 <code>conv2_1</code> 最后一个 conv layer 的 ReLU 之前，输出记为 <code>out</code>，那么 <code>out+x</code> 再由 <code>conv2_1</code> 最后一个 ReLU 激活，输出为 <code>ReLU(out+x)</code>。</p></li><li><p><code>conv3_1</code>，<code>conv4_1</code> 和 <code>conv5_1</code> 这三个 conv block 中的第一个 <code>3x3</code> 的 conv layer 具有 <strong>stride=2</strong>，故整个网络的 down sampling rate 为 $2^5=32$。</p></li><li><p><code>conv3_1</code>，<code>conv4_1</code> 和 <code>conv5_1</code> 这三个 conv block 存在下采样，故融合 <code>out+x</code> 存在一个问题：<code>x</code> 与 <code>out</code> shape 不同。以图 2 为例说明，对于 34-layer，<code>conv3_1</code> 的输入 <code>x</code> shape （h,w,c）为 <code>56*56*64</code>，而 <code>conv3_1</code> 的 <code>out</code> shape 为 <code>28*28*128</code>。有两种解决方案：</p><ul><li>将 <code>x</code> 通过 zero-pad 升维，升维后，x 通过 stride=2 采样，使得 feature size 与 <code>out</code> 的 feature size 相同。</li><li><p>对 <code>x</code> 使用 <code>1x1</code> conv 进行升维，同时 conv stride=2，降低 feature size，然后在接一个 <code>BN</code> 。（torchvision 实现中统一使用这种方法， projection shortcut）</p><p>如果 <code>x</code> 与 <code>out</code> 的 shape 相同，那么不对 <code>x</code> 进行处理，即 identity shortcut。</p></li></ul></li></ol><h1 id="3-DenseNet"><a href="#3-DenseNet" class="headerlink" title="3. DenseNet"></a>3. DenseNet</h1><p><a href="https://arxiv.org/abs/1608.06993">论文地址</a></p><p>引入了 DenseBlock 结构，如图 4 ，<br><img src="/images/img_cls/densenet_1.png" alt=""></p><p>图 4. 一个具有 5 层的 dense block（dense block 后面的那个 transition layer 也计算在内？否则，只有 4 层）。</p><p>简单而言，记 dense block 层数为 <code>L</code>，那么第 <code>l</code> 层的输出作为后续 <code>L-l</code> 个 layer 的输入。</p><p>dense block 说明：</p><ol><li>第 <code>l</code> 层输出记为 $x_l$，它有 <code>l</code> 个输入 $x_0, x_1, \cdots, x_{l-1}$，其中 $x_0$ 为本 dense block 的输入。这 <code>l</code> 个输入的融合 <strong>不是相加</strong>，而是 <strong>沿着 channel 方向 concatenate</strong>，这一点与 ResNet 不同。</li><li>dense block 中各层的输出 feature size 相同，这使得 concatenate 操作简单。</li><li>dense block 中各层的输出 channel 也相同，记为 <code>k</code>。（使用了 bottle neck 结构除外）</li></ol><p><img src="/images/img_cls/densenet_3.png" alt=""></p><p>图 5. DenseNet 网络结构（应用于 ImageNet 数据集上）。**图中每个 conv 均表示 <code>BN-ReLU-Conv</code>。</p><p>DenseNet 说明：</p><ol><li>每个 conv layer 由 <code>BN-ReLU-Conv</code> 构成（注意顺序，参考 <a href="https://arxiv.org/abs/1603.05027">Identity Mappings in Deep Residual Networks</a> ）</li><li>dense block 中每层输出 channel 数 <code>k</code> ，称为 <strong>growth rate</strong>。<code>k</code> 可以很小，例如 <code>12, 24, 32</code> 等。</li><li>dense block 中可以采用 bottleneck 结构，即，dense block 由 <code>L</code> 个 bottleneck 构成，bottleneck 机构 为 <code>BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)</code>，采用这种结构的网络称为 <code>DenseNet-B</code> 。论文中，bottleneck 中的 <code>Conv(1x1)</code> 的输出 channel 为 <code>4k</code> 。bottleneck layer 的输出仍为 <code>k</code> ，这与普通 dense block 中各层输出 channel 相同。</li><li>整个网络的 down sampling rate 为 $2^5=32$。</li><li>transition layer 中的 <code>1x1 conv</code> 的输入 channel 为 $m=k_0+k \times (L-1)$，输出 channel 为 $\lfloor \theta m\rfloor$，其中 $0 &lt; \theta \le 1$，$\theta$ 用于压缩模型。当 $\theta &lt; 1$ 时，称为 <code>DenseNet-C</code>，那么 <code>DenseNet-BC</code> 表示既采用了 bottleneck layer，又压缩了 transition layer 的输出 channel。</li></ol><p>对于 cifar 数据集，由于图片尺寸较小（32*32），故没有 图 5 中的 <code>7x7</code> 卷积和 <code>maxpool</code>。采用了两种网络：</p><ol><li><p>basic DenseNet</p><p> 图片输入首先通过一个 <code>3x3 conv</code> 的 layer，输出 channel 为 <code>16</code>。 然后通过三个 dense block，（每两个 dense block 依然有 transition layer，共 2 个 transition layer）。dense block 配置为 <code>&#123;L=40, k=12&#125;, &#123;L=100, k=12&#125;, &#123;L=100, k=24&#125;</code>。down sampling rate 为 $2^2=4$ 。</p></li><li><p>DenseNet-BC</p><p> 图片输入首先通过一个 <code>3x3 conv</code> 的 layer，输出 channel 为 <code>32</code>，后面的结构与 basic DenseNet 中总体相同，三个 dense block 的配置为 <code>&#123;L=100, k =12&#125;, &#123;L=250, k=24&#125;, &#123;L=190, k=40&#125;</code>。</p></li></ol><h1 id="4-MobileNet"><a href="#4-MobileNet" class="headerlink" title="4. MobileNet"></a>4. MobileNet</h1><h2 id="4-1-Depthwise-Separable-Convolution"><a href="#4-1-Depthwise-Separable-Convolution" class="headerlink" title="4.1 Depthwise Separable Convolution"></a>4.1 Depthwise Separable Convolution</h2><p>记为 <code>Conv dw</code>。记输入 channel 为 <code>M</code>，卷积核为 <code>k*k*1</code>，共 <code>M</code> 个这与的 kernel，输入特征的每个 channel 分别使用一个 kernel 进行卷积，故，输出 channel 依然是 <code>M</code> 。</p><h2 id="4-2-Pointwise-Convolution"><a href="#4-2-Pointwise-Convolution" class="headerlink" title="4.2 Pointwise Convolution"></a>4.2 Pointwise Convolution</h2><p>kernel shape 为 <code>N*M*1*1</code>，用于 <code>Conv dw</code> 之后，使得输出 channel 变成 <code>N</code> 。</p><p><img src="/images/img_cls/baselines_2.png" alt=""></p><p>图 6. MobileNet 网络结构。其中 Filter shape 为 <code>(h, w, in_channel, out_channel)</code> 的顺序。图中每个 Conv 都是 <code>Conv-BN-ReLU</code> 结构。（图中最后一个 s2 应该改为 s1）。</p><h2 id="4-3-Width-Multiplier"><a href="#4-3-Width-Multiplier" class="headerlink" title="4.3 Width Multiplier"></a>4.3 Width Multiplier</h2><p>引入参数 $\alpha \in (0,1)$， 原来的 conv layer 的输出 channel <code>M, N</code> 分别变为 $\alpha M$，$\alpha N$。常用的 $\alpha$ 可取 <code>1, 0.75, 0.5</code> 等。</p><h2 id="4-4-Resolution-Multiplier"><a href="#4-4-Resolution-Multiplier" class="headerlink" title="4.4 Resolution Multiplier"></a>4.4 Resolution Multiplier</h2><p>引入参数 $\rho$，使得每层的输入 feature 的空间 size $(D_F, D_F)$ 变为 $(\rho D_F, \rho D_F)$ 。</p><p>实际应用中，是将图 6 中每层的输出 channel 分别变为原来的 $\alpha$ 倍。将 input size 变为原来的 $\rho$ 倍即可实现 “每层的输入 feature size 变为 $\rho$ 倍” 这一目的。</p><h1 id="5-MobileNetV2"><a href="#5-MobileNetV2" class="headerlink" title="5. MobileNetV2"></a>5. MobileNetV2</h1><p>MobileNetV2 是在 MobileNet 基础上进行改进：</p><ol><li>高 channel 的 layer 后保留使用 ReLU，而低 channel 的 layer 后不使用 ReLU，这是因为如果 channel 较大，即使使用 ReLU，大部分信息仍然保持，而如果 channel 较小，那么 ReLU 会损失较多信息。</li><li>bottleneck 结构会压缩 channel ，所以根据第 <code>1</code> 点，bottleneck 的 <code>1x1 conv</code> （正是这个 layer 用于压缩 channel）后不应该使用 ReLU。</li><li><p>MobileNet 没有使用 ResNet 中的 shortcut，MobileNetV2 则使用了 shortcut ，但是与 ResNet 中的 residual block 不同，而是 Inverted residual block。如图 7，</p><p> <img src="/images/img_cls/baselines_3.png" alt=""><br> 图 7. 普通 residual block 和 inverted residual block。（都是 bottleneck block）</p><p> 图 7 的右边的这个 inverted sidual block，block 的输入 channel 经过 <code>1x1 conv</code> 使得 channel 膨胀到 <code>k</code> 倍，然后使用 <code>3x3 dw conv</code> ，由于是 depthwise 可分离卷积，参数量和计算量都降下来了，而 channel 经过膨胀，故可以先使用 ReLU，然后再做 <code>3x3 dw conv</code>，得到的 feature channel 保持不变，故继续使用 ReLU 进行非线性激活，然后再使用 <code>1x1 conv</code>，得到的输出将作为下一个 block 的输入。具体的 block 各层结构如图 8</p><p> <img src="/images/img_cls/baselines_4.png" alt=""><br> 图 8</p></li><li><p>shortcut 融合采用按位相加，即 bottleneck 的输入与输出按位相加。</p></li><li><p>ReLU6 就是限制 ReLU 的最大输出值为6（对输出值做clip）。</p></li></ol><p>整个网络结构</p><p><img src="/images/img_cls/baselines_5.png" alt=""><br>图 9. MobileNetV2：<code>t</code> 表示 channel 的膨胀率，<code>c</code> 表示 bottleneck block 的输出 channel。<code>n</code> 表示相同的 bottleneck 重复堆叠几次。<code>s</code> 表示这一组重复的 block 总的 stride。</p><p>对图 9 中的结构作补充说明：</p><ol><li><p>除 bottleneck block 中最后一个 <code>1x1 conv</code> 之外，所有的 <code>conv</code> 具体展开均为 <code>Conv-BN-ReLU6</code>。如果是 <code>dw conv</code>，那么对应的则为 <code>dw Conv-BN-ReLU6</code>。bottleneck block 中最后一个 <code>1x1 conv</code> 则展开为 <code>Conv-BN</code>，这是因为两个 block 之间的 feature channel 较小，不应该使用 ReLu，而 block 内部由于第一个 <code>1x1 conv</code> 使得 channel 经过膨胀，所以可以使用 ReLU。</p></li><li><p>一组相同的 block 中，如果 <code>s&gt;1</code>，那么由这组中的第一个 block 执行 <code>stride=s</code>，具体而言是由这个 block 中的 <code>3x3 dw conv</code> layer 执行。参见 图 8。</p></li><li><p>在 block 的 <code>stride=1</code> 且 block 的输入和输出 channel 相等时，才有 shortcut 连接。如图 8 所示，当 <code>stride=2</code> 时，没有 shortcut 。另外，从图 9 中可见，两个相邻的 block 如果跨组了，那么后一个 block 的输入输出 channel 肯定不同，即，每组中的第一个 block 不使用 shortcut，这样就保证了输入输出 feature 的 shape 完成相同，方便实现按位相加。</p></li><li><p>torchvision 中的 MobileNetV2 实现源码，如果 block 的膨胀系数 <code>t=1</code>，那么就省去了第一个 <code>1x1 conv</code>，直接是 <code>3x3 dw conv</code> ，可能是因为既然 <code>1x1 conv</code> 没有提高 channel，就没必要用了，在图 9 中，第一个 <code>conv</code> 的输出 channel 32，可能是因为觉得在网络的浅层阶段，这个 channel 已经足够大了，没必要再用 <code>1x1 conv</code> 进行膨胀，即，第一个 bottleneck 中省去了第一个 <code>1x1 conv</code>。</p></li></ol><h1 id="6-Inception"><a href="#6-Inception" class="headerlink" title="6. Inception"></a>6. Inception</h1><p>论文：<a href="https://arxiv.org/abs/1409.4842">Going deeper with convolutions</a></p><p>思路：提高性能的一个方法是增加网络的 <code>depth</code> 以及 <code>width</code>，但是随之而来的缺点是：</p><ol><li>大尺寸网络意味着大量的参数，在数据集不是足够大时，容易过拟合</li><li>大尺寸网络增加计算量。</li></ol><p>设计细节：</p><ol><li>低层网络负责一个小的 local region，到下一 layer 时，采用 <code>1x1 Conv</code>，其感受野不变，但是我们也希望有更大的感受野，可采用 <code>3x3 Conv</code> 和 <code>5x5 Conv</code>，如图 10 左边部分所示，但是这种设计存在问题：<code>5x5 Conv</code> 计算量太大，故采用图 10 右侧部分，使用 <code>1x1 Conv</code> 先降维，然后再卷积。<br><img src="/images/img_cls/baselines_6.png" alt=""><br>图 10. 左：朴素的 Inception 模块；右：具有降维的 Inception 模块。</li></ol><p>说明：</p><ol><li>Inception 中的 max pooling <code>stride=1</code>，feature 空间 size 不变。</li></ol><h2 id="6-1-GoogLeNet"><a href="#6-1-GoogLeNet" class="headerlink" title="6.1 GoogLeNet"></a>6.1 GoogLeNet</h2><p><img src="/images/img_cls/baselines_7.png" alt=""><br>图 11. GoogLeNet 网络。图中 <code>#3x3 reduce</code> 实际上是 <code>1x1 Conv</code> 对应的是图 10 中右图的 <code>3x3 Conv</code> 前的降维卷积。<code>depth</code> 表示这个 module 中堆叠了几个 <code>Conv</code>。</p><p>说明：</p><ol><li><p>表中第三行，参数量为 $64\times 1^2 \times 64+64\times 3^2 \times 192=112\times 1024=112K$</p></li><li><p>表中第五行，根据图 10 中右图，可知参数量为 $192\times 1^2 \times 64+192\times 1^2 \times 96 + 96\times 3^2 \times 128+ 192 \times 1^2 \times 16 +16 \times 5^2 \times 32 + 192\times 1^2 \times 32=159.5K$。这一 layer 的输出 channel 为 $64+128+32+32=256$。</p></li><li><p>所有的 <code>Conv</code> 后接 ReLU。</p></li><li><p>由于网络相对较深，梯度反向传播可能较为困难。网络的中间层已经具有辨别区分能力了，故在网络的中间层增加两个辅助分类分支，参见论文 <a href="https://arxiv.org/abs/1409.4842">Going deeper with convolutions</a> 中的 <code>Figure 3</code>，（图太大，不贴出来）这两个辅助分支说明：</p><ul><li>在 <code>(4a)</code> 和 <code>(4d)</code> 后使用一个 <code>5x5 avg pooling</code>，<code>stride=3</code> ，得到输出为 <code>4x4x512</code> 和 <code>4x4x528</code></li><li>一个 <code>1x1 Conv, 128</code> 的 filters 用于降维（后接 ReLU）</li><li>一个全连接层，输出 units 为 <code>1024</code>，后接 ReLU</li><li>drop ratio 为 <code>70%</code> 的 dropout layer</li><li>一个全连接层，输出 units 为 <code>1000</code>（ImageNet 数据集），这个 layer 后面没有 ReLU，而是 softmax loss 层。</li><li>这两个辅助分类分支在 inference 阶段被移除</li></ul></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> image classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN 回顾</title>
      <link href="/2021/12/23/obj_det/faster-rcnn/"/>
      <url>/2021/12/23/obj_det/faster-rcnn/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a><br><span id="more"></span><br>本文对 Faster R-CNN 进行梳理，主要用于复习 Faster R-CNN，重温一些实现细节。</p><p>整个网络的结构示意图如图 1，<br><img src="/images/obj_det/faster-rcnn_1.png" alt=""><br>图 1. Faster R-CNN 网络示意图</p><p>说明：</p><ol><li>任意 size 的 image 经过 一个 backbone （全卷积）得到 feature maps</li><li>一方面，feature maps 经过 RPN 网络 得到 proposals，以及每个 proposal 的 objectness score，这是一个<strong>二分类</strong>，表示 proposal 是否是正例。</li><li>另一方面，利用上一步得到的 proposal 在 feature maps 进行 crop，crop 之后的 部分 feature maps 经过 ROI pooling，得到固定 size 的 feature （例如 <code>7x7</code>)，作为 Fast R-CNN 的输入，Fast R-CNN 输出分类得分，以及坐标（$t_x, t_y, t_w, t_h$）。</li><li>两个子网络 RPN （用于生成 proposals）和 Fast R-CNN（目标检测网络）共享 baseline。</li></ol><p>下面分别对 backbone 和后续的两个子网络予以讨论。</p><h1 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h1><p>论文中采用 VGG-16，即 <code>5</code> 个 stage， stage 内的 <code>3x3 conv</code> 数量分别为 <code>2, 2, 3, 3, 3</code>，相邻 stage 之间使用 <code>mp</code> 进行降采样，故 baseline 输出的 feature maps 的 size 相较于 input size ，总的降采样率为 <code>16</code>。</p><h2 id="image-预处理"><a href="#image-预处理" class="headerlink" title="image 预处理"></a>image 预处理</h2><p><strong>image 读取</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">im <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>   <span class="token comment"># BGR order</span><span class="token comment"># use cv2.cvtColor(im, cv2.COLOR_BGR2RGB) ot convert the channel order</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>随机flip</strong><br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0.5</span><span class="token punctuation">:</span>    im <span class="token operator">=</span> im<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>       <span class="token comment"># left to right flipped</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><p>gt box 的坐标 $(x_1,y_1,x_2,y_2)$ 变成 $(W-x_2,y_1,W-x_1,y_2)$</p><p><strong>减去均值</strong><br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># pixel mean follows the order BGR</span>im <span class="token operator">-=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">102.9801</span><span class="token punctuation">,</span> <span class="token number">115.9465</span><span class="token punctuation">,</span> <span class="token number">122.7717</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><p><strong>resize</strong></p><p>resize image 使得短边为 <code>600</code>，同时 resize 后长边不超过 <code>1000</code>，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">target_size <span class="token operator">=</span> <span class="token number">600.0</span>max_size <span class="token operator">=</span> <span class="token number">1000.0</span>h<span class="token punctuation">,</span> w <span class="token operator">=</span> im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>    <span class="token comment"># im is an object returned from cv2.imread()</span>size_min<span class="token punctuation">,</span> size_max <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>im_scale <span class="token operator">=</span> target_size <span class="token operator">/</span> size_min<span class="token keyword">if</span> np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>im_scale <span class="token operator">*</span> size_max<span class="token punctuation">)</span> <span class="token operator">></span> max_size<span class="token punctuation">:</span>    <span class="token comment"># decrease the im_scale</span>    im_scale <span class="token operator">=</span> max_size <span class="token operator">/</span> size_maxim <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>im<span class="token punctuation">,</span> fx<span class="token operator">=</span>im_scale<span class="token punctuation">,</span> fy<span class="token operator">=</span>im_scale<span class="token punctuation">)</span><span class="token comment"># update the gt_box coordinates</span>gt_box <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y2<span class="token punctuation">]</span><span class="token punctuation">)</span>gt_box <span class="token operator">=</span> <span class="token punctuation">(</span>gt_box <span class="token operator">*</span> im_scale<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int16<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>组建 blob/tensor</strong><br>经过上面的 resize 后，各个 image size 相差不大了，取这组 images 中最大的 height，和最大的 width，创建一个可以容纳 batch 内所有 images 的 blob/tensor，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># im.shape -> (h, w) -> (batch_size, 2) -> (2,)</span>max_shape <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>im<span class="token punctuation">.</span>shape <span class="token keyword">for</span> im <span class="token keyword">in</span> ims<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>batch_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>blob <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_images<span class="token punctuation">,</span> max_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    im <span class="token operator">=</span> ims<span class="token punctuation">[</span>i<span class="token punctuation">]</span>    <span class="token comment"># the image is aligned with the top-left cornor</span>    blob<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> imblob <span class="token operator">=</span> blob<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># from (B,H,W,C) to (B,C,H,W)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>network 的 input size 以 <code>(600, 1000)</code> 为例，下采样率为 <code>16</code>，于是输出 feature size 大约是 <code>(38, 63)</code>。</p><h1 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h1><p>在 baseline 得到的 feature maps，使用 <code>3x3 conv</code>，得到 <code>512-d</code>（或者如图 2 的 <code>256-d</code>） 的中间 feature，然后分别经过两个 full-connected layer，得到 <code>2k</code> 的 objectness scores，和 <code>4k</code> 个坐标，即 feature maps 上每个 location 预测 <code>k</code> 个 proposals，如图 2，<br><img src="/images/obj_det/faster-rcnn_2.png" alt=""><br>图 2. RPN</p><p>说明：</p><ol><li><p>每个 location 的中间 feature 均为 <code>512-d</code>，对于 cls layer，全连接层参数 $W^{512\times 2k}$，reg layer 的全连接层参数 $W^{512 \times 4k}$，所有 location 处的这两个全连接层共享参数，即，分别使用 <code>1x1 Conv 2k</code> 和 <code>1x1 Conv 4k</code> 的两个卷积层，输出 shape 分别为 <code>(B, H, W, 2k)</code> 和 <code>(B, H, W, 4k)</code>， <code>(H, W)</code> 为 feature maps 上 size，<code>B</code> 为 <code>batch_size</code>。</p></li><li><p>训练 RPN 时，<code>batch_size=1</code>，即每个 mini-batch 内仅有 <code>1</code> 个 image。在训练 Fast RCNN 子网络时，保持 RPN 不变，此时取 <code>batch_size=2</code>。</p></li></ol><h2 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h2><p>RPN （在每个 location 处）使用 <code>k</code> 个 Anchors 辅助预测 proposals，<code>k</code> 个 Anchors 具有不同的 scale 和 aspect ratio。通常 <code>k=9</code>：3 个 scales 和 3 个 aspect ratios。对于 $H \times W$ 的 feature maps，一共有 $H \times W \times k$ 个 anchors。</p><p><strong>如何确定 anchor 的大小和位置</strong></p><p>anchor 的 scale 取 <code>8, 16, 32</code>（人为确定，可以根据实际任务进行调整。由于 backbone 的下采样率为 <code>16</code>，映射到原 input image 就是 <code>128,256,512</code>，而 input size 大概是 <code>600 x 1000</code>，故这个 scale 较为合理）。aspect ratio （记为 $r$）取 <code>0.5, 1, 2</code> 三个值，正好覆盖 矮胖，方正，高瘦 三种情况，anchor 的 size 记为 $(h, w)$，那么有</p><script type="math/tex; mode=display">r=\frac h w</script><p>对于标准 scale，即 $r=1, h \times w = 16 \times 16$。改变 $r$ 值，但是面积保持相同，故</p><script type="math/tex; mode=display">s = 16 \times 16 = h  w = r w^2=\frac {h^2} r</script><p>于是</p><script type="math/tex; mode=display">w= \sqrt {s/r} , \quad h = \sqrt{sr}</script><p>考虑到 scale 可取不同值，那么最终 anchor size 为</p><script type="math/tex; mode=display">w = a \sqrt{s/r}, \quad h = a \sqrt{sr}, \quad a = 0.5, 1, 2, \quad r=0.5, 1, 2, \quad s = 16^2=256</script><p>上式可以确定 <code>9</code> 个 anchors 的 size，其中心点坐标相同，均为 $x_c=0+0.5(16-1), \ y_c=0+0.5(16-1)$（考虑到 C/Python 语言习惯以 <code>0</code> 开始表示第一个位置），于是左上右下坐标为</p><script type="math/tex; mode=display">x_1=x_c-\frac 1 2(w-1), \quad y_1=y_c-\frac 1 2(h-1)</script><script type="math/tex; mode=display">x_2=x_c+\frac 1 2(w-1), \quad y_2=y_c+\frac 1 2(h-1)</script><pre class="line-numbers language-python" data-language="python"><code class="language-python">s <span class="token operator">=</span> <span class="token number">16</span><span class="token operator">**</span><span class="token number">2</span>r <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>           <span class="token comment"># (1, 3)</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># (3, 1)</span>w <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>s <span class="token operator">/</span> r<span class="token punctuation">)</span> <span class="token operator">*</span> a                   <span class="token comment"># (3, 3)</span>h <span class="token operator">=</span> r <span class="token operator">*</span> w                                   <span class="token comment"># (3, 3)</span>h <span class="token operator">=</span> h<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span>        <span class="token comment"># (1, 9)</span>w <span class="token operator">=</span> w<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span>        <span class="token comment"># (1, 9)</span>xc <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>yc <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>x1 <span class="token operator">=</span> xc <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>w<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>y1 <span class="token operator">=</span> yc <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>h<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>x2 <span class="token operator">=</span> xc <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>w<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>y2 <span class="token operator">=</span> yc <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>h<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># >>>>>> each location has its own 9 anchors &lt;&lt;&lt;&lt;&lt;&lt;</span>H <span class="token operator">=</span> <span class="token number">40</span>  <span class="token comment"># Here I simply assign 40 and 60 to H and W respectively,</span>W <span class="token operator">=</span> <span class="token number">60</span>  <span class="token comment"># but in practice, H and W may be other values.</span>grid_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>W<span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>H<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># (HW, 1)</span>grid_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># (HW, 1)</span><span class="token comment"># all anchors locations are</span>k <span class="token operator">=</span> <span class="token number">9</span>x1 <span class="token operator">=</span> <span class="token punctuation">(</span>x1 <span class="token operator">+</span> grid_x<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token operator">*</span>k<span class="token punctuation">)</span>y1 <span class="token operator">=</span> <span class="token punctuation">(</span>y1 <span class="token operator">+</span> grid_y<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token operator">*</span>k<span class="token punctuation">)</span>x2 <span class="token operator">=</span> <span class="token punctuation">(</span>x2 <span class="token operator">+</span> grid_x<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token operator">*</span>k<span class="token punctuation">)</span>y2 <span class="token operator">=</span> <span class="token punctuation">(</span>y2 <span class="token operator">+</span> grid_y<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token operator">*</span>k<span class="token punctuation">)</span>anchors <span class="token operator">=</span> torch<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># filter out those out-of-scope anchors</span><span class="token comment"># inside_indices = torch.where(x1 >= 0 &amp; y1 >= 0 &amp; x2 &lt; W &amp; y2 &lt; H)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>RPN 这个网络的 Loss，包含分类（proposal 是否含有 object，二分类）损失，以及坐标回归损失。</p><p><strong>如何确定正例</strong>： 记 image 中 gt boxes 数量为 $m$，计算 $m$ 个 gt boxes 与 $HW k$ 个 anchors 之间的 IOU ， IOU 矩阵记为 $M_{m \times HWk}$，</p><ol><li>与某个 gt box 具有最大 IOU 的 anchor 为正例，负责预测这个 gt box，这种正例 anchor 有 $m$ 个 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># gt: (m, 4)</span>M <span class="token operator">=</span> bbox_iou<span class="token punctuation">(</span>gt<span class="token operator">/</span><span class="token number">16</span><span class="token punctuation">,</span> anchors<span class="token punctuation">)</span>   <span class="token comment"># anchors: (H*W*k, 4)</span><span class="token comment"># positive anchors(have a max iou with some gt box)</span>max_ious<span class="token punctuation">,</span> positive_anchor_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>anchors<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int8<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># set the positive anchors with label `1`</span>labels<span class="token punctuation">[</span>positive_anchor_indices<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>与某个 gt box 的 IOU 大于一个阈值（论文中使用 <code>0.7</code>），则认为这样的 anchor 是正例，$m$ 个 gt box 中，与这个 anchor 有最大 IOU 的 gt box，将被这个 anchor 预测， <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># the max iou(with some one gt box) for each anchor</span><span class="token comment"># both the two tensor have the same shape of (HWk,)</span>max_ious<span class="token punctuation">,</span> gt_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>     <span class="token comment"># indices of positive anchors(with a iou > 0.7)</span><span class="token comment"># all indices are in [0, HWk)</span>positive_anchor_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>max_ious <span class="token operator">>=</span> <span class="token number">0.7</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment"># extract indices of gt boxes ( in [0, m) ) for positive anchors</span>positive_gt_indices <span class="token operator">=</span> gt_indices<span class="token punctuation">[</span>positive_anchor_indices<span class="token punctuation">]</span><span class="token comment"># set the positive anchors with label `1`</span>labels<span class="token punctuation">[</span>positive_anchor_indices<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>满足以上两个条件中的一个，认为是 positive。</li></ol><p><strong>如何确定负例</strong>：对于非正例的 anchor，没有全部作为负例，否则正负例样本严重不均衡。事实上，对于 IOU 在 0.5 附近的 anchor，属于 hard example，不予采用。与 gt box 的最大 IOU 小于阈值 （论文中取 <code>0.3</code>）的认为是负例：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">max_ious<span class="token punctuation">,</span> gt_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># indices( in [0, HWk) ） of negative anchors</span>negative_anchor_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>max_ious <span class="token operator">&lt;</span> <span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment"># extract indices of gt boxes ( in [0, m) ) for negative anchors</span>negative_gt_indices <span class="token operator">=</span> gt_indices<span class="token punctuation">[</span>negative_anchor_indices<span class="token punctuation">]</span><span class="token comment"># set the negative anchors with label `0`</span>labels<span class="token punctuation">[</span>negative_anchor_indices<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>单个 image 的损失如下，</p><script type="math/tex; mode=display">L=\frac 1 {N_cls} \sum_i L_{cls}(p_i, p_i^{\star})+\lambda \frac 1 {N_{reg}}\sum_i p_i^{\star} L_{reg}(t_i, t_i^{\star})</script><p>其中：</p><ol><li>$N_{cls}=256$ 表示一个 mini-batch 内，所选取的用于分类任务的正负 anchors 的数量。按照 <code>1:1</code> 比例分配正负 anchors，如果正例 anchors 不足 <code>128</code>，那么使用负例 anchors 进行补充。前面说到 <code>batch_size=1</code>，这表明，<strong>在每个 image 上随机选择 <code>128</code> 个 positive anchors，如果不够，使用 negative anchors 补充</strong>。</li><li>$N_{reg}=HWk \approx 10 N_{cls}$，$N_{reg}$ 为一个 image 上所有的 anchors 数量， 故取 $\lambda=10$ 。注意：<strong>回归损失使用全部 anchors，而非第 <code>1</code> 点中的取样 <code>256</code> 个</strong>。</li><li>第 <code>i</code> 个 anchor 如果是 positive，那么 $p_i^{\star}=1$，否则 $p_i^{\star}=0$</li><li>$p_i$ 表示第 <code>i</code> 个 anchor 被预测为正的得分。</li><li>$L_{cls}$ 可以使用负对数似然损失，也就是交叉熵损失 <pre class="line-numbers language-python" data-language="python"><code class="language-python">rpn_batch <span class="token operator">=</span> <span class="token number">256</span><span class="token comment"># imitate the sampling process</span>scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>rpn_batch<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># (256, 2)</span>gt_conf <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>rpn_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>random_<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>     <span class="token comment"># (256,)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># do not need to normalize the input</span>cls_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> gt_conf<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>$L_{reg}$ 为 smooth L1 函数</p><script type="math/tex; mode=display">L_{reg}(t_i, t_i^{\star})=smooth_{L_1}(t_i-t_i^{\star})</script><script type="math/tex; mode=display">smooth_{L_1}=\begin{cases}0.5 x^2 & |x|<1 \\ |x|-0.5 & |x|\ge 1\end{cases}</script><p> 这是为了防止梯度太大，导致训练不稳定</p><p> $t_i$ 是一个向量，表示第 <code>i</code> 个 anchor 的预测坐标偏差 $(t_x, t_y, t_w, t_h)$，$t_i$ 就是 reg layer （即 <code>1x1 conv 4k</code>，k=9）的输出。坐标偏差有如下关系：</p><script type="math/tex; mode=display">t_x=(x_p-x_a)/w_a, \quad t_y=(y_p-y_a)/h_a</script><script type="math/tex; mode=display">t_w=\log(w_p/w_a), \quad t_h=\log(h_p/h_a)</script><p> 根据上面 4 个等式，以及 anchor 的坐标 $(x_a, y_a, w_a, h_a)$ 可以很容易得到预测 proposal 的坐标 $(x_p, y_p, w_p, h_p)$。</p><p> $t_i^{\star}$ 为 gt box 对 anchor 的坐标偏差，可看作是 gt offset，其计算如下：</p><script type="math/tex; mode=display">t_x^{\star}=(x_{gt}-x_a)/w_a, \quad t_y^{\star}=(y_{gt}-y_a)/h_a \tag{1}</script><script type="math/tex; mode=display">t_w^{\star}=\log(w_{gt}/w_a), \quad t_h^{\star}=\log(h_{gt}/h_a) \tag{2}</script><p> 目标就是使得正例 anchor 的预测偏差 $t_i$ 尽量逼近真实偏差 $t_i^{\star}$。</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">assert</span> B <span class="token operator">==</span> <span class="token number">1</span>loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SmoothL1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># t_i: in practice, t_i is gotten from reg_layer(`1x1 conv 4k`)</span>t_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token number">4</span><span class="token operator">*</span>k<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token operator">*</span>H<span class="token operator">*</span>W<span class="token operator">*</span>k<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>t_i <span class="token operator">=</span> t_i<span class="token punctuation">[</span>labels<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># anchors: (HWk, 4)</span><span class="token comment"># gt_indices: index of gt(with max iou) for each anchor</span>t_i_gt <span class="token operator">=</span> bbox_target<span class="token punctuation">(</span>anchors<span class="token punctuation">,</span> gt<span class="token punctuation">[</span>gt_indices<span class="token punctuation">]</span><span class="token punctuation">)</span>t_i_gt <span class="token operator">=</span> t_i_gt<span class="token punctuation">[</span>labels<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span>reg_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>t_i<span class="token punctuation">,</span> t_i_gt<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>根据 backbone 和 RPN 以及 RPN 对应的 loss，就可以训练 RPN ，训练好 RPN 之后，利用 RPN 来生成 proposals，见下一节内容。</p><h1 id="ROI-Proposal"><a href="#ROI-Proposal" class="headerlink" title="ROI Proposal"></a>ROI Proposal</h1><p>RPN 中，我们说到有两个分支：cls 分支和 reg 分支，输出分别表示 anchor 的分类 objectness scores（未归一化）以及坐标偏差，shape 分别为 $(B, H, W, 2k), \ (B, H, W, 4k)$，按以下步骤得到 proposals：</p><ol><li>二分类预测得分（cls分支输出），取预测为正例的得分</li><li>根据 (1,2) 式和 anchors 坐标，得到 proposals 坐标，并 clip 使得在 input image 范围内</li><li>过滤掉太小的 proposals</li><li>得分降序排列，proposals 顺序保持与 scores 的一致，取 top 6000 的 proposals，此举是为了加快 nms 速度</li><li>执行 nms</li><li>对 nms 之后的 proposals 继续取 top 300</li></ol><p>（代码中，TRAIN 和 TEST 阶段，上面 nms 前后的两组 top n 中 <code>n</code> 值各不相同）</p><p><strong>注：<code>batch_size=1</code></strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">assert</span> B <span class="token operator">==</span> <span class="token number">1</span>scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">*</span>k<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">)</span>t_i    <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token number">4</span><span class="token operator">*</span>k<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># normalize scores, and extract the scores of objectness(positive)</span>scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>scores <span class="token operator">=</span> scores<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>t_i <span class="token operator">=</span> t_i<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token comment"># according to eq(1) and eq(2), recover the (x1y1x2y2) of proposals</span><span class="token comment"># multiply by 16 to recover the size relatived to image input</span>proposals <span class="token operator">=</span> bbox_transform<span class="token punctuation">(</span>anchors<span class="token punctuation">,</span> t_i<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">16</span><span class="token comment"># clip the x1, y1 to 0, and x2, y2 to max_shape[1] and max_shape[0], repectively</span>proposals <span class="token operator">=</span> clip<span class="token punctuation">(</span>proposals<span class="token punctuation">)</span><span class="token comment"># filter out those very little proposals</span>min_scale <span class="token operator">=</span> <span class="token number">16</span> <span class="token operator">*</span> im_scalepw <span class="token operator">=</span> proposals<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> proposals<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>ph <span class="token operator">=</span> proposals<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> proposals<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>keep <span class="token operator">=</span> pw <span class="token operator">>=</span> min_scale <span class="token operator">&amp;</span> ph <span class="token operator">>=</span> min_scaleproposals <span class="token operator">=</span> proposals<span class="token punctuation">[</span>keep<span class="token punctuation">]</span>scores <span class="token operator">=</span> scores<span class="token punctuation">[</span>keep<span class="token punctuation">]</span>order <span class="token operator">=</span> scores<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> descending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>pre_nms_topn <span class="token operator">=</span> <span class="token number">6000</span>order <span class="token operator">=</span> order<span class="token punctuation">[</span><span class="token punctuation">:</span>pre_nms_topn<span class="token punctuation">]</span>proposals <span class="token operator">=</span> proposals<span class="token punctuation">[</span>order<span class="token punctuation">]</span>scores <span class="token operator">=</span> scores<span class="token punctuation">[</span>order<span class="token punctuation">]</span>keep <span class="token operator">=</span> nms<span class="token punctuation">(</span>proposals<span class="token punctuation">,</span> scores<span class="token punctuation">,</span> nms_thre<span class="token punctuation">)</span>post_nms_topn <span class="token operator">=</span> <span class="token number">300</span>keep <span class="token operator">=</span> keep<span class="token punctuation">[</span><span class="token punctuation">:</span>post_nms_topn<span class="token punctuation">]</span>proposals <span class="token operator">=</span> proposals<span class="token punctuation">[</span>keep<span class="token punctuation">]</span>scores <span class="token operator">=</span> scores<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上便是使用 RPN 生成 proposals 的过程，当然因为 input image 是经过 resize 的，故，proposals 还需要除以 <code>im_scale</code>，以恢复原先的 size。</p><p>在 <code>alt_opt</code> 这种训练方式中，就是使用 <code>rpn_generate</code> 专门为数据集中每个 image 生成 proposals，得到 proposals 的列表（双重列表），然后 dump 到一个 <code>.pkl</code> 文件中。</p><hr><p>以下内容为 <code>end2end</code> 的近似联合训练方式，可以跳过</p><p>上面得到的 top 300 proposals 与这个 image 中的所有 gt boxes 一起，得到总的候选 proposals，然后：</p><ol><li>总的候选 proposals 与 gt boxes 计算 IOU 矩阵，并求出每个候选 proposal 对应最大 IOU 的那个 gt box，以及最大 IOU</li><li>最大 IOU 大于某阈值（<code>0.5</code>）的 proposal 被认为是 正例</li><li>单个 image 中取 <code>128</code> 个 proposals，作为 RCNN 检测网络的输入，其中正负 proposals 的比例为 <code>1:3</code>，故正例 proposals 数量为 <code>32</code>，如果第 <code>2</code> 步中筛选出的正例数量大于 <code>32</code>，那么随机取 <code>32</code> 个正例 proposals。</li><li>最大 IOU 位于 <code>[0.1, 0.5)</code> 之间的 proposals 为负例（难负例挖掘）。负例数量为 <code>96</code>，如果第 <code>3</code> 步中正例数量小于 <code>32</code>，那么缺少的使用负例补充。最后正负 proposals 总数量可能小于 <code>128</code>。</li><li>与 RPN 中类似，RCNN 中以 proposal 为 anchor，预测 proposal 的分类（PASCAL VOC 为例，为 20+1 种分类，包含 bg 分类），以及 proposal 的坐标偏差，故需要计算 gt box 相对 proposal 的坐标偏差（固定某个 proposal，取与其有最大 IOU 的那个 gt box）<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># gt_labels: class labels of all gt boxes, shape: (m,)</span>all_rois <span class="token operator">=</span> torch<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">(</span>proposals<span class="token punctuation">,</span> gt<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># (n, 4)</span>M <span class="token operator">=</span> bbox_iou<span class="token punctuation">(</span>all_rois<span class="token punctuation">,</span> gt<span class="token punctuation">)</span>      <span class="token comment">#(n, m), m is number of all gt boxes</span>max_ious<span class="token punctuation">,</span> gt_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># fix one proposal, the class label of the gt box (with the max iou) is used</span>labels <span class="token operator">=</span> gt_labels<span class="token punctuation">[</span>gt_indices<span class="token punctuation">]</span>  fg_thre <span class="token operator">=</span> <span class="token number">0.5</span>fg_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>max_ious <span class="token operator">>=</span> fg_thre<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>bg_thre_low <span class="token operator">=</span> <span class="token number">0.1</span>bg_thre_up <span class="token operator">=</span> <span class="token number">0.5</span>bg_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>max_ious <span class="token operator">>=</span> bg_thre_low <span class="token operator">&amp;</span> max_ious <span class="token operator">&lt;</span> bg_thre_up<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>rois_num <span class="token operator">=</span> <span class="token number">128</span>fg_ratio <span class="token operator">=</span> <span class="token number">0.25</span>fg_num <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>rois_num <span class="token operator">*</span> fg_ratio<span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">)</span> <span class="token operator">></span> fg_num<span class="token punctuation">:</span>    fg_indices <span class="token operator">=</span> fg_indices<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>fg_num<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>bg_num <span class="token operator">=</span> rois_num <span class="token operator">-</span> fg_num<span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>bg_indices<span class="token punctuation">)</span> <span class="token operator">></span> bg_num<span class="token punctuation">:</span>    bg_indices <span class="token operator">=</span> bg_indices<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>bg_indices<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>bg_num<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>keep <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">,</span> bg_indices<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> labels<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token comment"># class label for any bg proposal is 0</span>labels<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>rois <span class="token operator">=</span> all_rois<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token comment"># gt_indices: index of gt(with max iou) for each anchor</span>gt_indices_keep <span class="token operator">=</span> gt_indices<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token comment"># according to eq(1) and eq(2), get the gt coordinate offsets for all candidated proposals</span>bbox_target <span class="token operator">=</span> bbox_target<span class="token punctuation">(</span>rois<span class="token punctuation">,</span> gt<span class="token punctuation">[</span>gt_indices_keep<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 1. for regression task, only positive proposals are used in reg-loss calculation</span><span class="token comment"># 2. gt coordinate offsets are class related</span>t_i_gt <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>rois<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    cls_id <span class="token operator">=</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span>    start <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">*</span> cls_id    end   <span class="token operator">=</span> start <span class="token operator">+</span> <span class="token number">4</span>    t_i_gt<span class="token punctuation">[</span>i<span class="token punctuation">,</span> start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token operator">=</span> bbox_target<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>上面代码，最后的 <code>t_i_gt</code> 保存了正例 proposal 所对应的 gt box 的坐标偏差。</li></ol><p>以上内容为 <code>end2end</code> 的近似联合训练方式，可以跳过</p><hr><h1 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h1><p>训练 Fast R-CNN，需要加载数据集的 gt boxes，以及上一节所说的 proposals，既然这些 proposals 用于训练，就需要确定其分类，以及正负例（注：gt boxes 全部看作正例且已经有分类的 proposals），<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># gt_boxes of one image in the dataset</span><span class="token comment"># gt_classes of gt_boxes of that image</span><span class="token comment"># proposals of that image</span>M <span class="token operator">=</span> bbox_iou<span class="token punctuation">(</span>proposals<span class="token punctuation">,</span> gt_boxes<span class="token punctuation">)</span>max_ious<span class="token punctuation">,</span> gt_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>fg_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>max_ious <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment"># classes of proposals</span>classes <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>proposals<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>classes<span class="token punctuation">[</span>fg_indices<span class="token punctuation">]</span> <span class="token operator">=</span> gt_classes<span class="token punctuation">[</span>gt_indices<span class="token punctuation">[</span>fg_indices<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token comment"># combine gt boxes and proposals</span><span class="token comment"># rois: coordinates of all rois</span>rois <span class="token operator">=</span> torch<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>gt_boxes<span class="token punctuation">,</span> proposals<span class="token punctuation">)</span>        <span class="token comment"># concatenate two 2-d vectors</span>roi_classes <span class="token operator">=</span> torch<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span>gt_classes<span class="token punctuation">,</span> classes<span class="token punctuation">)</span> <span class="token comment"># concatenate two 1-d vectors</span>overlaps <span class="token operator">=</span> torch<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>gt_classes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> max_ious<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><code>batch_size=2</code></p><p>Fast R-CNN 的输入为 image，以及（包含 gt boxes）的 proposals。对 image 的预处理与训练 RPN 相同（各 channel 减去 mean value，resize，然后拷贝到一个 batch 中）。重点看 rois 的处理，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">fg_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>overlaps <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>rois_per_img <span class="token operator">=</span> <span class="token number">64</span>       <span class="token comment"># 128 // batch_size</span>fg_rois_per_img <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.25</span> <span class="token operator">*</span> roi_per_img<span class="token punctuation">)</span>   <span class="token comment"># 16</span><span class="token keyword">if</span> fg_indices<span class="token punctuation">.</span>size <span class="token operator">></span> fg_rois_per_img<span class="token punctuation">:</span>    fg_indices <span class="token operator">=</span> fg_indices<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>fg_rois_per_img<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>bg_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>overlaps <span class="token operator">&lt;</span> <span class="token number">0.5</span> <span class="token keyword">and</span> overlaps <span class="token operator">>=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>bg_rois_per_img <span class="token operator">=</span> rois_num <span class="token operator">-</span> fg_rois_per_img<span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>bg_indices<span class="token punctuation">)</span> <span class="token operator">></span> bg_num<span class="token punctuation">:</span>    bg_indices <span class="token operator">=</span> bg_indices<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>bg_indices<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>bg_rois_per_img<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>keep <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">,</span> bg_indices<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>roi_classes <span class="token operator">=</span> roi_classes<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token comment"># class label for any bg proposal is 0</span>roi_classes<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>fg_indices<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>rois <span class="token operator">=</span> rois<span class="token punctuation">[</span>keep<span class="token punctuation">]</span>overlaps <span class="token operator">=</span> overlaps<span class="token punctuation">[</span>keep<span class="token punctuation">]</span><span class="token comment"># calcucate the gt coordinate offsets (based on positive proposals)</span>gt_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>overlaps <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>fg_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>overlaps <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>M <span class="token operator">=</span> bbox_iou<span class="token punctuation">(</span>rois<span class="token punctuation">[</span>fg_indices<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rois<span class="token punctuation">[</span>gt_indices<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># find each positive proposal and its matched gt box</span>max_ious<span class="token punctuation">,</span> gt_assignments <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>fg_rois <span class="token operator">=</span> rois<span class="token punctuation">[</span>fg_indices<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>gt_rois <span class="token operator">=</span> rois<span class="token punctuation">[</span>gt_indices<span class="token punctuation">[</span>gt_assignments<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># according to eq(1) and eq(2), get the gt coordinate offsets for all candidated proposals</span>bbox_target <span class="token operator">=</span> bbox_target<span class="token punctuation">(</span>fg_rois<span class="token punctuation">,</span> gt_rois<span class="token punctuation">)</span><span class="token comment"># predicted bbox is class related, so provides the positive proposals' classes</span>bbox_classes <span class="token operator">=</span> roi_classes<span class="token punctuation">[</span>fg_indices<span class="token punctuation">]</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>当然，<code>rois</code> 还需要乘以 <code>im_scale</code> 以与 resized input image 匹配。然后<br>将每个 image 的 <code>rois</code> 数据进行打包，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">batched_rois <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> rois <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>rois_list<span class="token punctuation">)</span><span class="token punctuation">:</span>    batch_ind <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>rois<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> i    ind_rois <span class="token operator">=</span> torch<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_ind<span class="token punctuation">,</span> rois<span class="token punctuation">)</span><span class="token punctuation">)</span>    batched_rois <span class="token operator">=</span> torch<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">(</span>batched_rois<span class="token punctuation">,</span> ind_rois<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>其他数据如 <code>bbox_target</code> 等类似进行打包。</p><p>准备好 image 数据以及 target 数据之后，就可以进行前向传播了。 batched image 经过 VGG-16 ，在 <code>conv5_3</code> 这个 layer 输出 feature maps，size 大约是 <code>40x60</code>（backbone 降采样率为 <code>16</code>），然后执行步骤：</p><ol><li><p>在 feature maps 上根据 <code>rois</code> crop 出 feature patches，并执行 ROI pooling 得到 <code>7x7</code> 的特征</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python">scale <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span><span class="token number">16</span>x <span class="token operator">=</span> conv5_3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>      <span class="token comment"># (B, C, H, W)</span>B <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>pooled_feats <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> roi <span class="token keyword">in</span> batched_rois<span class="token punctuation">:</span>    ltrb <span class="token operator">=</span> roi<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> scale      <span class="token comment"># left, top, right, bottom</span>    <span class="token comment"># x1, y1, x2, y2</span>    feat <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>roi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    feat <span class="token operator">=</span> feat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> ltrb<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ltrb<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ltrb<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>ltrb<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    pooled_feat <span class="token operator">=</span> pool<span class="token punctuation">(</span>feat<span class="token punctuation">)</span>    pooled_feats<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pooled_feat<span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>pooled_feats<span class="token punctuation">)</span><span class="token comment"># x.shape (N, 512, 7, 7)，N 为 batch image 中所选的 rois 数量：128</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>上一步的输出，连续经过两个全连接层 <code>fc+relu+drop</code>，输出特征的 shape 为 <code>(N, 4096)</code>，这个特征分别经 cls layer（<code>out_channel=1+C</code> 的全连接层，其中 <code>C</code> 为分类数量，<code>1</code> 为背景数量），以及 reg layer （<code>out_channel=4x(1+C)</code> 的全连接层）这两个并列输出分支，得到（未归一化）分类得分，以及 bbox 的坐标偏差（与分类有关）。</p></li><li>分类损失和坐标回归损失与 RPN 中的相同，使用 <code>CrossEntropyLoss</code> 作为分类损失，<code>SmoothL1Loss</code> 作为坐标回归损失。</li></ol><p>以上分析过程参照 <code>alt_opt</code> 训练方法，即交替训练方法。</p><h1 id="近似联合训练"><a href="#近似联合训练" class="headerlink" title="近似联合训练"></a>近似联合训练</h1><p>源码还提供了 <code>end2end</code> 训练方法，即<strong>近似联合训练</strong>方法（真正的端到端训练方法是一个 non trivial 问题，比较复杂，而采用近似端到端训练方法，已经可以取得较好的结果）。近似联合训练思路：</p><ol><li>backbone , RPN 和 Fast R-CNN 均合并到一个网络中，前向传播时，RPN 生成 proposals，然后使用 proposals 得到 rois，与 backbone 的 feature maps 一起作为 Fast R-CNN 的输入，继续进行前向传播。反向传播时，RPN 和 Fast R-CNN 的损失一起反向传播，用于更新网络参数。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Connectionist Temporal Classification (2)</title>
      <link href="/2021/12/04/dl/ctc2/"/>
      <url>/2021/12/04/dl/ctc2/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章介绍了 CTC 的算法和损失函数，现在继续讨论 CTC 的推断部分。</p><span id="more"></span><h1 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h1><p>训练好模型后，可以对一个新输入进行推断，求最可能的输出序列，</p><script type="math/tex; mode=display">Y^{\star}=\arg \max_Y p(Y|X)</script><p>一种方法是在每个时刻分别独立地求最有可能的输出，即</p><script type="math/tex; mode=display">A^{\star}=\arg\max_A \prod_{t=1}^T p_t(a_t |X)</script><p>然后 $Y=B(A^{\star})$ 得到最终的输出序列。</p><p>这种方法某些情况下效果很好，尤其当每个时刻的输出概率向量中，大部分 概率 mass 集中在单个元素上。但是这种方法没有从全局角度进行考虑，有时候得到的输出序列并非概率最大的那个，例如</p><p>假设 RNN 输出 $[a,a,\epsilon]$ 和 $[a,a,a]$ 的概率均比 $[b,b,b]$ 的概率低，但是前两者的概率和比第三者的概率高，如果采用上面的那个简单方法，得到输出序列为 $[b]$，然而实际应该是 $[a]$。</p><p>我们采用 beam search 方法来解决这个问题。常规的 beam search 方法如图 1 所示，</p><p><img src="/images/dl/CTC4.png" alt=""></p><p>+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</p><center>图 1 （来源于 ref 1）</center><p>将常规的 beam search 加以修改，使得适合本问题：将连续重复的值进行合并，并移除 $\epsilon$，在每个时间步，对每个 prefix 序列，累加所有有关的标签序列，这些标签序列均 collapsed 到这个 prefix，如图 2，</p><p><img src="/images/dl/CTC5.png" alt=""><br>图 2. CTC beam search 算法，输出字母表为 $\{\epsilon, a, b\}$。</p><p>需要注意的是，在 <code>T=3</code> 时，prefix 为 <code>[a]</code>，proposed extension 为 <code>a</code> 时，输出（即叠加后的 prefix）可以是 <code>[a]</code>，也可以是 <code>[a, a]</code>，后者由 $[a, \epsilon, a]$ 转化而来，也就是说此时 prefix 实际是 $[a, \epsilon]$：ending in $\epsilon$。所以，对于 prefix，我们需要在内部存储其 ending in $\epsilon$ 和 not ending in $\epsilon$ 两个概率（prefix 概率为这两个概率之和）。如图 3 所示，</p><p><img src="/images/dl/CTC6.png" alt=""></p><p>图 6. <code>T=2</code> 时（图中间部分），prefix 为 $[a]$，proposed extension 分别取 $\epsilon$ 和 $a$ 时，均输出 $[a]$，然而，前者实际上是 ending in $\epsilon$，看 <code>T=3</code> 部分中蓝色节点 $[a]$ 的下方较小地显示出来。</p><p>整个代码实现参考这个代码片段 <a href="https://gist.github.com/awni/56369a90d03953e370f3964c826ed4b0">gist</a> 。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://distill.pub/2017/ctc/">Sequence Modeling With CTCT</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Connectionist Temporal Classification (1)</title>
      <link href="/2021/12/04/dl/ctc/"/>
      <url>/2021/12/04/dl/ctc/</url>
      
        <content type="html"><![CDATA[<p>隐马尔可夫模型中，可观测序列 $X$ 与隐状态序列 $Y$ 的长度是相等的，但是在语音识别中，语音序列被转为文字序列，这两者长度可能不相等，也就是说，语音片与文字无法一一对应。这就需要寻找其他解决方法。<br><span id="more"></span></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>我们将“对数据序列打标签”看作是 <strong>时序分类</strong>，通常可采用 RNN 网络实现，这称为 connectionist temporal classification（CTC），所适用的任务包括 语音识别，图片中的文字识别等。</p><p>记输入序列为 $X=[x_1,\ldots, x_T]$，输出序列为 $Y=[y_1,\ldots,y_U]$，（通常 $T &gt; U$）。我们的任务是找到一个准确的 $X \rightarrow Y$ 的映射，但是可以想象这其中的难点：</p><ol><li>$X, \ Y$ 长度可变</li><li>$X, \ Y$ 长度之比可变</li><li>$X, \ Y$ 序列元素之间没有明确关系。</li></ol><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>采用负对数似然函数。给定一个输入 $X$ 以及对应的输出 $Y$，我们的目标是求 $p(Y|X)$ 的最大化。</p><h2 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h2><p>给定输入 $X$，求最有可能的输出 $Y$，即</p><script type="math/tex; mode=display">Y^{\star}=\arg \max_Y p(Y|X)</script><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><h2 id="对齐方式"><a href="#对齐方式" class="headerlink" title="对齐方式"></a>对齐方式</h2><p>通常，输入序列的一个或多个元素用于生成一个输出元素，是多对一的关系，所以输出序列长度小于输入序列长度。例如一个输入序列长度为 6，输出序列长度为 3，如下<br><pre class="line-numbers language-none"><code class="language-none">x1 x2 x3 x4 x5 x6       input(X)c  c  a  a  a  t        alignment c  |    a   | t        output(Y)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>通过将连续相邻的重复的输出元素进行合并（去重），可以得到输出序列为 <code>cat</code>。</p><p>但是这种做法也存在以下两个问题：</p><ol><li>有时候输入元素不一定必须要对应一个输出元素。例如语音识别中，语音之中存在沉默片段，这部分不应对应任何一个文字（或单词）。</li><li>将相邻的重复元素去重，会使得例如 “hello” 变成 “helo”，而无法得到想要的 “hello”。</li></ol><p>为了解决这两个问题，CTC 引入了一个新的 token $\epsilon$ 表示空白（blank token），这个 $\epsilon$ 最终从输出序列中移除。于是，对于一段语音，可以通过如下方式进行识别，</p><div class="table-container"><table><thead><tr><th>h</th><th>h</th><th>e</th><th>$\epsilon$</th><th>$\epsilon$</th><th>l</th><th>l</th><th>l</th><th>$\epsilon$</th><th>l</th><th>l</th><th>o</th><th>操作</th></tr></thead><tbody><tr><td>h</td><td></td><td>e</td><td>$\epsilon$</td><td></td><td>l</td><td></td><td></td><td>$\epsilon$</td><td>l</td><td></td><td>o</td><td>合并相邻重复的元素</td></tr><tr><td>h</td><td></td><td>e</td><td></td><td></td><td>l</td><td></td><td></td><td></td><td>l</td><td></td><td>o</td><td>移除 $\epsilon$</td></tr></tbody></table></div><p>最后就得到了 <code>hello</code> 这个输出序列。</p><h2 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h2><p>我们采用 RNN 网络结构，记输入序列长度为 $T$，那么 RNN 一共有 $T$ 个输出，每个时刻 $t$ 的输出 $z_t$ 为一个长度为 $L+1$ 的得分向量，其中 $L$ 为输出字符集大小，$+1$ 是由于我们增加了一个 $\epsilon$。RNN 的输出序列记为 $A$，那么通过上述的合并相邻重复和去掉 $\epsilon$ 这个操作，可得到最终的输出序列 $Y$，记这个操作为 $B$，即 $Y=B(A)$，显然 $A$ 与 $Y$ 是多对一的关系，即 $A \in B^{-1}(Y)$，那么似然函数</p><script type="math/tex; mode=display">p(Y|X)=\sum_{A \in B^{-1}(Y)} \prod_{t=1}^T p_t(a_t|X)</script><p>对于一个输出 $Y$，有很多个 $Z$，故如果想暴力计算，那么计算量会非常大，考虑动态规划方法。</p><p>空白 token  $\epsilon$ 可出现在输出序列 $Y$ 的任意位置，那么不妨我们将每两个 $y_i , \ i \in [U]$ 之间均插入 $\epsilon$，以及最起始位置和最后位置也插入  $\epsilon$，那么序列变为</p><script type="math/tex; mode=display">Z=[\epsilon, y_1,\epsilon, y_2,\ldots, \epsilon, y_U, \epsilon]</script><p>仍以语音识别为例，如果语音开头有沉默，那么 RNN 输出序列 $A$ 以 $\epsilon$，否则以 $y_1$ 开头。具体而言，将语音等分为 $T$ 个语音片，即 $A=[a_1,a_2,\ldots,a_T]$，第 1 个语音片为沉默（无声音），那么对应 $\epsilon$，否则对应 $y_1$，第 2 个语音片则需要根据上一个语音片的情况进行讨论，如下表所示，</p><script type="math/tex; mode=display">\begin{array}{c|c|c}a_1 & a_1 & (a_1,a_2)\\\hline\\a_1=y_1 & \begin{aligned}a_2&=\epsilon \\ a_2&=y_1 \\ a_2&=y_2 (y_2\neq y_1)\end{aligned} & \begin{aligned} &(y_1, \epsilon) \\ &(y_1,y_1) \\ &(y_1,y_2)\end{aligned}\\\hline\\a_1=\epsilon & \begin{aligned}a_2&=\epsilon \\ a_2&=y_1\end{aligned} & \begin{aligned} &(\epsilon, \epsilon) \\ &(\epsilon,y_1)\end{aligned}\end{array}</script><p>注意，$a_1=y_1, \ a_2=y_2$ 时，必须保证 $y_1\neq y_2$ 这个条件成立，否则 $B(a_1,a_2)=B(y_1,y_1)=(y_1)$，即，经过合并后，就少了一个 $y_1$。</p><p>我们讨论更一般的情况。</p><p>输出 $Y$ 的长度为 $U$，$Z$ 的长度为 $2U+1$，另外 $U \le T$，如果 ：</p><ol><li>$2U+1 &lt;= T$，这表示需要重复 $Z$ 中的部分元素，共重复 $T-(2U+1)$ 次。</li><li>$2U+1 &gt; T$，这表示需要跳过 $Z$ 中的部分 $\epsilon$ ，共跳过 $2U+1-T$ 次。</li></ol><p>为了使用动态规划方法，定义 $\alpha_{s,t}$ 表示到达 $t$ 时刻止，预测为 $Z_{1:s}$ 的概率，</p><script type="math/tex; mode=display">\alpha_{s,t}=P\{C(A_{1:t}) = Z_{1:s}\}</script><p>其中 $C$ 表示合并连续重复的元素操作。</p><p>对于 $Z$ 中连续的三个元素 $z_{s-2}, z_{s-1},z_s$，有两种情况：</p><p><strong>1. 无法跳过 $z_{s-1}$</strong>，即，必须有一个 RNN 输出 $a_j$ 对齐到 $z_{s-1}$。</p><p>第一个原因是 $z_{s-2}=z_s \ \neq \epsilon$，如果跳过预测 $z_{s-1}$，那么有一个 $y_i$ 值被合并，导致 $Y$ 长度减小了 1。 第二个原因是 $z_s=\epsilon$，由于 $\epsilon$ 与 $y_i$ 是间隔的，说明 $z_{s-1}=y_i$，此时若跳过预测 $z_{s-1}$，那么就少了一个 $y_i$，导致 $Y$ 长度减小了 1 。</p><p>如图1 所示，</p><p><img src="images/dl/CTC1.png" alt=""></p><center>图 1 （来源于 ref 1）</center><p>也就是说 $\alpha_{s,t}$ 可由 $\alpha_{s,t-1}$ 转化而来，即 $a_t=a_{t-1}$，也可由 $\alpha_{s-1,t-1}$ 转化而来，即 $a_t \neq a_{t-1}$，只能是这两种之一。</p><p>转化公式为</p><script type="math/tex; mode=display">\alpha_{s,t}=(\alpha_{s-1,t-1}+\alpha_{s,t-1}) \cdot p_t(z_s|X)</script><p><strong>2. 允许跳过 $z_{s-1}$</strong>，允许跳过，即，可以跳过，也可以不跳过。<br>如图 2 所示，</p><p><img src="images/dl/CTC2.png" alt=""></p><center>图 2 （来源于 ref 1）</center><p>可见，只有 $z_{s-1}=\epsilon$，且 $z_{s-2}\neq z_s$ 时才允许跳过预测 $z_{s-1}$。此时，$\alpha_{s,t}$ 可由 $\alpha_{s-2,t-1}$ 或 $\alpha_{s-1,t-1}$ 或者 $\alpha_{s,t-1}$ 转化而来。</p><script type="math/tex; mode=display">\alpha_{s,t}=(\alpha_{s-2,t-1}+\alpha_{s-1,t-1}+\alpha_{s,t-1})\cdot p_t(z_s|X)</script><p><strong>综上</strong></p><p>对于连续的三个元素 $z_{s-2},z_{s-1},z_s$，只有以下三种可能的情形：<br><pre class="line-numbers language-none"><code class="language-none">z(s-2)    z(s-1)     z(s)a         epsilon    aepsilon   a          epsilona         epsilon    b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>例如，一个输入序列长度为 6，输出序列 $Y=[a,b]$，那么所有可能的预测路径如下图，</p><p><img src="images/dl/CTC3.png" alt=""></p><center>图 3 （来源于 ref 1）</center><p>从图3可知，只有两个有效的起始节点，以及两个有效的终止节点。</p><p>现在，就可以快速地计算似然函数了，损失函数采用负对数似然，对于一个训练集 $\mathcal D$，损失函数为 </p><script type="math/tex; mode=display">\sum_{(X,Y) \in \mathcal D} -\log p(Y|X)</script><p>接下来就是计算梯度并训练模型了。<br>将 CTC 损失函数对每个时刻的输出概率求导。</p><p>推断一节在下一篇讨论。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://distill.pub/2017/ctc/">Sequence Modeling With CTCT</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>容器使用示例</title>
      <link href="/2021/11/26/tools/docker/"/>
      <url>/2021/11/26/tools/docker/</url>
      
        <content type="html"><![CDATA[<p>介绍简单的容器使用示例。<br><span id="more"></span></p><h1 id="All-in-Docker"><a href="#All-in-Docker" class="headerlink" title="All in Docker"></a>All in Docker</h1><p>To check all docker images, you can type<br><pre class="line-numbers language-none"><code class="language-none">sudo docker images<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>The output of this command may be<br><pre class="line-numbers language-none"><code class="language-none">REPOSITORY                                                            TAG               IMAGE ID       CREATED        SIZEtensorflow&#x2F;tensorflow                                                 latest-gpu        edb49f6a133b   2 days ago     5.53GB...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><blockquote><p>tensorflow/tensorflow is an image provided by <code>tensorflow</code> official organization. It’s is actually a linux OS and the tensorflow library is installed systematicly.</p></blockquote><p>Take the first image as an example. This image is used to provide an environment for deep learning. Now we show how to clone this image to make a highly customized and suitable for ourselves deep-learning enrivonment, and we can keep modifing this new cloned image without influncing the original image. Input the following command,<br><pre class="line-numbers language-none"><code class="language-none">sudo docker tag tensorflow&#x2F;tensorflow:latest-gpu tensorflow&#x2F;tensorflow:public<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>By using another tag name, we create a new image. Please type a command to see what has happened,<br><pre class="line-numbers language-none"><code class="language-none">sudo docker images<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>and the output will be<br><pre class="line-numbers language-none"><code class="language-none">REPOSITORY                                                            TAG               IMAGE ID       CREATED        SIZEtensorflow&#x2F;tensorflow                                                 latest-gpu        edb49f6a133b   2 days ago     5.53GBtensorflow&#x2F;tensorflow                                                 public            edb49f6a133b   18 hours ago   5.53GB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>Whenever want to do deep learning in future, we should first run this new image, and then train or evaluate data in our own enviromment. So, how to run an image?<br><pre class="line-numbers language-none"><code class="language-none">sudo nvidia-docker run -p 6010:6006 -p 9527:22 -v &#x2F;home&#x2F;shajianjian&#x2F;work:&#x2F;workspace -itd --name tf-public  tensorflow&#x2F;tensorflow:public<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>Be aware that we use <code>nvidia-docker</code> instead of <code>docker</code> because <code>nvidia-docker</code> can help us to load <code>cuda</code> related components automatically when lauching this deep learning environment, otherwise, we cannot use <code>GPU</code> accelarating learning.</p><p>We may have a great experience with our deep learning environment for a couple of days, but afterwards, we find that some matured deep learning projects are implemented with PyTorch, which is not existed in our environment, how to do?</p><p>Don’t worry, be happy!</p><p>Login our environment and change current directory to</p><pre class="line-numbers language-none"><code class="language-none">ssh domain-user@192.168.5.116cd &#x2F;workspace<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>Install miniconda, and then install pytorch by conda(details are ignored because we don’t focus on it in this artical). They say that all modications in <code>/workspace</code> are saved and even when reboot our deep learning environment(re-run our image). Suppose we install pytorch systematicly, like tensorflow, then we should save it as a new image(marked it as B, and our first cloned image is marked as A), or else the pytorch library will be disgarded when stop image <code>A</code>. Let’s see how to save A as B after changing A systematicly,</p><pre class="line-numbers language-none"><code class="language-none">sudo docker commit tf-public localharbor.xxxx.com&#x2F;tf&#x2F;public:v1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>where <code>tf-public</code> is the name of container when we run A, and A has a tag of <code>public</code>. Use the above command, we commit our changes and re-save it as the new image B with a tag of <code>public-v1</code>. Notice that iamge <code>A</code> is not changed, our changes maked to <code>A</code> are saved in <code>B</code>, i.e. <code>B</code>=<code>A</code>+<code>changes</code>.</p><p><code>localharbor.xxxx.com/tf/public:v1</code> can be substituted by any other value, but we use it here because we will push the image <code>B</code> to localharbor which is an online image repository, and anyone else can pull it(image <code>B</code>) to use directly without install tensorflow and pytorch again. This process saves his/her time.</p><p>Login harbor and then pull this image,<br><pre class="line-numbers language-none"><code class="language-none">sudo docker login localharbor.xxxx.comsudo docker push localharbor.xxxx.com&#x2F;tf&#x2F;public:v1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><p>Take my favorite DL framework pytorch as an example, the whole steps are:</p><p>1.<br>print all running containers<br><pre class="line-numbers language-none"><code class="language-none">sudo docker ps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>the printing msg is:<br><pre class="line-numbers language-none"><code class="language-none">CONTAINER ID   IMAGE                                                                  COMMAND                  CREATED         STATUS       PORTS                                          NAMES0f3dc93c8ebc   localharbor.xxxx.com&#x2F;pytorch&#x2F;pytorch:1.7.1-cuda11.0-cudnn8-devel   &quot;&#x2F;bin&#x2F;bash&quot;              3 weeks ago     Up 3 weeks   0.0.0.0:9528-&gt;9528&#x2F;tcp, 0.0.0.0:9527-&gt;22&#x2F;tcp   pytorch209def4f9cd0   scrapinghub&#x2F;splash                                                     &quot;python3 &#x2F;app&#x2F;bin&#x2F;sp…&quot;   5 weeks ago     Up 5 weeks   0.0.0.0:8050-&gt;8050&#x2F;tcp                         thirsty_wu5917c29d675e   localharbor.xxxx.com&#x2F;tf&#x2F;pml:tf-remote-latest                       &quot;&#x2F;bin&#x2F;bash&quot;              10 months ago   Up 5 weeks   0.0.0.0:23-&gt;22&#x2F;tcp, 0.0.0.0:6009-&gt;6006&#x2F;tcp     tf-remote<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>2.<br>print all images<br><pre class="line-numbers language-none"><code class="language-none">sudo docker imagesthe printing msg islocalharbor.xxxx.com&#x2F;pytorch&#x2F;pytorch                              1.7.1-cuda11.0-cudnn8-devel      d0d89d27be2a   10 months ago   13.2GB...(omitted)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>3.<br>Exec the following commands in sequence order<br><pre class="line-numbers language-none"><code class="language-none">sudo docker commit pytorch localharbor.xxxx.com&#x2F;pytorch&#x2F;pytorch:1.7.1-cuda11.0-cudnn8-devel_latestsudo docker login localharbor.xxxx.comsudo docker push localharbor.xxxx.com&#x2F;pytorch&#x2F;pytorch:1.7.1-cuda11.0-cudnn8-devel_latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><h1 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h1><p>Specially, please execute the following command to launch a <code>PyTorch</code> environment,<br><pre class="line-numbers language-none"><code class="language-none">sudo docker run -itd --gpus all --runtime&#x3D;nvidia -p 9527:22 -p 9528:9528 --shm-size 8G -v &#x2F;home&#x2F;shajianjian&#x2F;pytorch:&#x2F;workspace --name pytorch --hostname pytorch localharbor.xxxx.com&#x2F;pytorch&#x2F;pytorch:1.7.1-cuda11.0-cudnn8-devel<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>where the path and port mappings should be replaced with your own values.</p><p>Maybe you should first start the <code>ssh</code> service,<br><pre class="line-numbers language-none"><code class="language-none"># if not install ssh service, please run this command first# apt install openssh-serverservice ssh start<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>Check the status of <code>ssh</code>,<br><pre class="line-numbers language-none"><code class="language-none">service ssh status<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>reset the password for the user <code>root</code> on the docker os:<br><pre class="line-numbers language-none"><code class="language-none">passwd# operate according to hints<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><p>If cannot connect to os by <code>ssh root@192.158.5.116 -p 9527</code> and then input the correct password, please modify the <code>/etc/ssh/sshd_config</code> by adding the following line:<br><pre class="line-numbers language-none"><code class="language-none">PermissionLoginRoot yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>This virtual system has a default <code>root</code> user whose password is <code>pytorch</code>, so let’s login this virtual system by<br><pre class="line-numbers language-none"><code class="language-none">&gt; ssh root@192.168.5.116 -p 9527input password: pytorch(base) root@pytorch:&#x2F;workspace#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>Enjoy it~</p>]]></content>
      
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高斯混合模型</title>
      <link href="/2021/11/13/ml/GMM/"/>
      <url>/2021/11/13/ml/GMM/</url>
      
        <content type="html"><![CDATA[<p>机器学习中，我们常用某种方式去表征数据，例如选取合适的模型。单一模型的表征能力很弱，故可以采用混合模型，例如混合高斯分布。<br><span id="more"></span></p><p>混合模型是由多个单个模型凸组合而成，例如 $K$ 个简单分布凸组合成分布</p><script type="math/tex; mode=display">p(\mathbf x) = \sum_{k=1}^K \pi_k p_k(\mathbf x)$$ (GMM1)$$0 \le \pi_k \le 1, \quad \sum_{k=1}^K \pi_k = 1</script><p>本文主要讨论高斯混合模型 (GMM)，即，每个简单分布都是高斯分布。</p><h1 id="GMM"><a href="#GMM" class="headerlink" title="GMM"></a>GMM</h1><p>K 个高斯分布的线性组合如下，</p><script type="math/tex; mode=display">p(\mathbf x|\theta)=\sum_{k=1}^K \pi_k \mathcal N(\mathbf x|\mu_k, \Sigma_k)$$ (GMM2)$$0 \le \pi_k \le 1, \quad \sum_{k=1}^K \pi_k = 1</script><p>定义参数 $\theta := \{\mu_k, \Sigma_k, \pi_k: k = 1,\ldots, K\}$</p><h2 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h2><p>根据最大似然学习参数</p><p>记数据集为 $\mathcal X = \{\mathbf x_1, \cdots, \mathbf x_N\}$ 。似然函数为</p><script type="math/tex; mode=display">p(\mathcal X|\theta)=\prod_{n=1}^N p(\mathbf x_n |\theta)$$ (GMM3)$$p(\mathbf x_n|\theta)=\sum_{k=1}^K \pi_k \mathcal N(\mathbf x_n |\mu_k,\Sigma_k)$$ (GMM4)对数似然为$$\log p(\mathcal X|\theta)=\underbrace {\sum_{n=1}^N \log \sum_{k=1}^K \pi_k \mathcal N(\mathbf x_n |\mu_k,\Sigma_k)}_{=:\mathcal L}$$ (GMM5)考虑单个高斯分布（即，非高斯混合），那么单个样本的似然函数为$$\log \mathcal N(\mathbf x|\mu,\Sigma)=-\frac D 2 \log(2\pi)-\frac 1 2 \log \det(\Sigma) - \frac 1 2 (\mathbf x-\mu)^{\top}\Sigma^{-1}(\mathbf x-\mu)</script><p>此时我们可以求得关于参数 $\mu$ 和 $\Sigma$ 的最大似然估计的解析解。但是 {eq}<code>GMM5</code> 中，<code>log</code> 无法放入 $\sum_{k=1}^K$ 中，所以无法求得解析解。</p><p>我们依然使用求偏导并令偏导为 0 的方法进行求解，</p><script type="math/tex; mode=display">\frac {\partial \mathcal L} {\partial \mu_k} =\mathbf 0 \Leftrightarrow \sum_{n=1}^N \frac {\partial \log p(\mathbf x_n |\theta)} {\partial \mu_k} = \mathbf 0</script><script type="math/tex; mode=display">\frac {\partial \mathcal L} {\partial \Sigma_k} =\mathbf 0 \Leftrightarrow \sum_{n=1}^N \frac {\partial \log p(\mathbf x_n |\theta)} {\partial \Sigma_k} = \mathbf 0</script><script type="math/tex; mode=display">\frac {\partial \mathcal L} {\partial \pi_k} =\mathbf 0 \Leftrightarrow \sum_{n=1}^N \frac {\partial \log p(\mathbf x_n |\theta)} {\partial \pi_k} = \mathbf 0</script><p>此外，log 函数的求导规则为</p><script type="math/tex; mode=display">\frac {\log p(\mathbf x_n|\theta)} {\partial \theta}=\frac 1 {p(\mathbf x_n |\theta)}\cdot \frac {\partial p(\mathbf x_n |\theta)} {\partial \theta}</script><h2 id="Responsibility"><a href="#Responsibility" class="headerlink" title="Responsibility"></a>Responsibility</h2><p>定义GMM 中第 $k$ 个高斯分量对第 $n$ 个数组点的 responsibility 为</p><script type="math/tex; mode=display">r_{nk}=\frac {\pi_k \mathcal N(\mathbf x_n|\mu_k, \Sigma_k)} {\sum_{j=1}^K \pi_j \mathcal N(\mathbf x_n|\mu_j,\Sigma_k)}$$ (GMM6)或者说是第 $n$ 个数据点属于第 $k$ 个高斯分量的概率（数据点由这个高斯分量产生的概率，这个概率不是真实的概率，而是基于最大似然估计）。$\mathbf r_n :=[r_{n1},\ldots,r_{nK}]^{\top}$ 为一个归一化的概率向量。将 $K$ 个高斯分量对 $N$ 个数据点的 responsibilities 写成矩阵形式 $R \in \mathbb R^{N \times K}$，那么矩阵中第 $n$ 行表示数据 $\mathbf x_n$ 来自各个高斯分量的概率，这是一个归一化向量，第 $k$ 列表示高斯分量 $\mathcal N(\mu_k,\Sigma_k)$ 对所有数据的 responsibilities（注意这不是归一化的向量）。基于 responsibilities，我们可以对模型参数 $\theta$ 进行更新，而 responsibilities 又依赖于模型参数，所以对 $\theta$ 更新时，需要固定 responsibilities，然后更新 $\theta$，然后再计算新的 responsibilities，然后再更新 $\theta$，如此迭代更新下去，直到达到一个预设的最大迭代次数，或者参数的变化量（例如 F2 范数的变化量）小于一个预设的阈值。## 更新 Mean均值（期望）参数 $\mu_k$ 的更新为$$\mu_k^{new}=\frac {\sum_{n=1}^N r_{nk}\mathbf x_n} {\sum_{n=1}^N r_{nk}}$$ (GMM7)证：计算单个数据的概率对参数 $\mu_k$ 的梯度，$$\begin{aligned} \frac {\partial p(\mathbf x_n |\theta)}{\partial \mu_k}&=\sum_{j=1}^K \pi_j \frac {\partial \mathcal N(\mathbf x_n|\mu_j,\Sigma_j)} {\partial \mu_k}=\pi_k \frac {\partial \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)} {\partial \mu_k}\\&=\pi_k (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1} \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)\end{aligned}</script><p>于是，数据集的对数似然对 $\mu_k$ 的梯度为</p><script type="math/tex; mode=display">\begin{aligned} \frac {\partial \mathcal L} {\partial \mu_k}&=\sum_{n=1}^N \frac {\partial \log p(\mathbf x_n|\theta)}{\partial \mu_k}=\sum_{n=1}^N \frac 1 {p(\mathbf x_n|\theta)} \frac {\partial p(\mathbf x_n|\theta)}{\partial \mu_k}\\&=\sum_{n=1}^N (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1} \underbrace {\frac {\pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)} {\sum_{j=1}^N \pi_j \mathcal N(\mathbf x_n|\mu_j,\Sigma_j)}}_{=r_{nk}}\\&=\sum_{n=1}^N r_{nk}(\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1}\end{aligned}</script><p>令上式这个梯度为零，得</p><script type="math/tex; mode=display">\sum_{n=1}^N r_{nk} (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1}=\mathbf 0</script><p>上式两端右乘 $\Sigma_k$，得</p><script type="math/tex; mode=display">\sum_{n=1}^N r_{nk} \mathbf x_n = \sum_{n=1}^N r_{nk} \mu_k \Leftrightarrow \mu_k^{new}=\frac {\sum_{n=1}^N r_{nk}\mathbf x_n} {\sum_{n=1}^N r_{nk}}=\frac 1 {N_k} \sum_{n=1} r_{nk}\mathbf x_n</script><p>其中 $N_k :=\sum_{n=1}^N r_{nk}$ 就是上面我们所说的 responsibilites 矩阵的 第 $k$ 列的和，表示第 $k$ 个高斯分量对所有数据的 responsibilities 之和。</p><p>{eq}<code>GMM7</code> 可以看作是所有数据在分布 </p><script type="math/tex; mode=display">\mathbf r_k := [r_{1k},\cdots, r_{Nk}]/N_k$$ (GMM8)下的期望，$$\mu_k \leftarrow \mathbb E_{\mathbf r_k} [\mathcal X]</script><p>（类比，数据 $1,2,\ldots, 6$ 在 $[1/6,1/6,\cdots,1/6]$ 分布下的期望）</p><h2 id="更新协方差"><a href="#更新协方差" class="headerlink" title="更新协方差"></a>更新协方差</h2><p>协方差矩阵 $\Sigma_k$ 的更新为</p><script type="math/tex; mode=display">\Sigma_k^{new} = \frac 1 {N_k} \sum_{n=1}^N r_{nk} (\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}$$ (GMM9)从形式上看，{eq}`GMM9` 式可以看作是所有数据在分布 {eq}`GMM8` 分布下的二阶中心矩。下面来证明 {eq}`GMM9` 式。证：计算数据集的对数似然对 $\Sigma_k$ 的梯度，$$\frac {\partial \mathcal L}{\partial \Sigma_k}= \sum_{n=1}^N \frac {\partial \log p(\mathbf x_n|\theta)} {\partial \Sigma_k}=\sum_{n=1}^N \frac 1 {p(\mathbf x_n|\theta)} \frac {\partial p(\mathbf x_n|\theta)}{\partial \Sigma_k}$$ (GMM10)$p(\mathbf x_n|\theta)$ 由 {eq}`GMM4` 式给出，故只要计算$$\begin{aligned} \frac {\partial p(\mathbf x_n|\theta)} {\partial \Sigma_k}&=\frac {\partial}{\partial \Sigma_k}\left(\pi_k (2\pi)^{-D/2} \det(\Sigma_k)^{-1/2} \exp (-\frac 1 2 (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1} (\mathbf x_n-\mu_k))\right)\\&=\pi_k (2\pi)^{-D/2} [{\color{red}\frac {\partial}{\partial \Sigma_k}\det(\Sigma_k)^{-1/2}}\exp(-\frac 1 2 (\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}(\mathbf x_n-\mu_k))\\& \quad +\det(\Sigma_k)^{-1/2} \frac {\partial}{\partial \Sigma_k} \exp(-\frac 1 2 (\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}(\mathbf x_n-\mu_k))]\end{aligned}$$ (GMM11)红色部分表示一个整体，即求导不包括后面的 $\exp$ 部分。根据矩阵的求导规则可知，$$\frac {\partial}{\partial \Sigma_k} \det(\Sigma_k)^{-1/2}=-\frac 1 2 \det(\Sigma_k)^{-1/2} \Sigma_k^{-1}</script><script type="math/tex; mode=display">\frac {\partial} {\partial \Sigma_k}(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}(\mathbf x_n-\mu_k) = -\Sigma_k^{-1}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}</script><p>将上面两式 代入 {eq}<code>GMM11</code>式 得</p><script type="math/tex; mode=display">\begin{aligned} \frac {\partial p(\mathbf x_n|\theta)}{\partial \Sigma_k}&=\pi_k (2\pi)^{-D/2} [-\frac 1 2 \det(\Sigma_k)^{-1/2} \Sigma_k^{-1} \exp(-\frac 1 2 (\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}(\mathbf x_n-\mu_k)) \\ & \quad +\frac 1 2 \det(\Sigma_k)^{-1/2} \Sigma_k^{-1}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1} \exp(-\frac 1 2 (\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}(\mathbf x_n-\mu_k))]\\& = \pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)[-\frac 1 2 \Sigma_k^{-1}+\frac 1 2\Sigma_k^{-1}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1}]\\&=\pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)\cdot [-\frac 1 2 (\Sigma_k^{-1}-\Sigma_k^{-1}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1})]\end{aligned}</script><p>将上式和 {eq}<code>GMM4</code> 式代入 {eq}<code>GMM10</code> 式，得</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial \mathcal L} {\partial \Sigma_k}&= \sum_{n=1}^N \underbrace {\frac {\pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)} {\sum_{j=1}^K \pi_j \mathcal N(\mathbf x_n|\mu_j,\Sigma_j)}}_{=r_{nk}} \cdot  [-\frac 1 2 (\Sigma_k^{-1}-\Sigma_k^{-1}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1})]\\&=-\frac 1 2 \sum_{n=1}^N r_{nk} (\Sigma_k^{-1}-\Sigma_k^{-1}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\Sigma_k^{-1})\\&=-\frac 1 2 \Sigma_k^{-1} \underbrace{\sum_{n=1}^N r_{nk}}_{=N_k} + \frac 1 2 \Sigma_k^{-1}\left(\sum_{n=1}^N r_{nk}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\right)\Sigma_k^{-1}\end{aligned}</script><p>令上式这个梯度为零，得</p><script type="math/tex; mode=display">N_k\Sigma_k^{-1}=\Sigma_k^{-1}\left(\sum_{n=1}^N r_{nk}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\right)\Sigma_k^{-1}</script><p>上式两边右乘 $\Sigma_k^{-1}$，得</p><script type="math/tex; mode=display">N_k \mathbf I = \left(\sum_{n=1}^N r_{nk}(\mathbf x_n-\mu_k)(\mathbf x_n-\mu_k)^{\top}\right)\Sigma_k^{-1}</script><p>然后左乘 $\Sigma_k$ 得到 {eq}<code>GMM9</code> 。</p><h2 id="更新混合权重"><a href="#更新混合权重" class="headerlink" title="更新混合权重"></a>更新混合权重</h2><p>混合模型的权重参数 $\pi_k$ 的更新为</p><script type="math/tex; mode=display">\pi_k^{new} = \frac {N_k} N$$ (GMM11)证：由于 $\sum_{k=1}^N \pi_k=1$ 这个约束条件，我们采用拉格朗日乘子法，$$\begin{aligned}L &=\mathcal L + \lambda \left(\sum_{k=1}^K \pi_k-1\right)\\&= \sum_{n=1}^N \log \sum_{k=1}^K \pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k) + \lambda \left(\sum_{k=1}^K \pi_k-1\right)\end{aligned}</script><p>求梯度，由于 $\pi_k$ 不存在于 $\mathcal N$ 中，故梯度非常容易计算，</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial L}{\partial \pi_k}&=\sum_{n=1}^N \frac {\mathcal N(\mathbf x_n|\mu_k,\Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal N(\mathbf x_n|\mu_j, \Sigma_j)} + \lambda\\&= \frac 1 {\pi_k} \underbrace{ \sum_{n=1}^N \frac {\pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal N(\mathbf x_n|\mu_j, \Sigma_j)}}_{=N_k} + \lambda = \frac {N_k} {\pi_k}+\lambda\end{aligned}</script><script type="math/tex; mode=display">\frac {\partial L}{\partial \lambda}=\sum_{k=1}^K \pi_k -1</script><p>令上面两个梯度均为零，得</p><script type="math/tex; mode=display">\pi_k = - \frac {N_k}{\lambda}</script><script type="math/tex; mode=display">\sum_{k=1}^K \pi_k -1 = \sum_{k=1}^K \left(-\frac {N_k} {\lambda}\right)-1=0 \Leftrightarrow \lambda = -\sum_{k=1}^K N_k=-N</script><p>于是</p><script type="math/tex; mode=display">\pi_k^{new} = \frac {N_k} N</script><p>其中 $N$ 为数据集大小。</p><h1 id="EM"><a href="#EM" class="headerlink" title="EM"></a>EM</h1><p>EM 算法迭代步骤：</p><ol><li>初始化 $\ \pi_k, \mu_k, \Sigma_k$，$k=1,\ldots, K$ 。例如可以初始化为 $\pi_k=1/K$，$\mu_k=\mathbf 0$，$\Sigma_k=\mathbf I$ 。</li><li>E-step。 计算每个分量对每个数据 $\mathbf x_n$ 的 responsibility，{eq}<code>GMM6</code> 式。</li><li>M-step。 更新参数的值。{eq}<code>GMM7</code> ，{eq}<code>GMM9</code> ， {eq}<code>GMM11</code> 式。</li></ol><h1 id="隐变量视角"><a href="#隐变量视角" class="headerlink" title="隐变量视角"></a>隐变量视角</h1><p>可以将 GMM 看作是一个具有隐变量 $z$ 的模型。</p><p>生成过程：</p><p>数据点 $\mathbf x$ 是由 GMM 中 K 个概率中的某个确定的概率生成，记 $z_k \in \{0,1\}$ 表示是否选择第 k 个概率，如果 $z_k=1$ 表示选择第 k 个概率，然后生成 $\mathbf x$，故</p><script type="math/tex; mode=display">p(\mathbf x|z_k=1)=\mathcal N(\mathbf x|\mu_k, \Sigma_k)</script><p>定义 $\mathbf z=[z_1,\ldots,z_K]^{\top}$ 为随机向量，它是一个 one-hot 向量，显然有</p><script type="math/tex; mode=display">p(\mathbf z)=\pi, \quad \sum_{k=1}^K \pi_k=1</script><p>单个样本的最大似然为</p><script type="math/tex; mode=display">p(\mathbf x|\theta) = \sum_{\mathbf z} p(\mathbf x|\theta, \mathbf z)\cdot p(\mathbf z|\theta)=\sum_{k=1}^K \pi_k \mathcal N(\mathbf x|\mu_k,\Sigma_k)</script><h2 id="后验概率分布"><a href="#后验概率分布" class="headerlink" title="后验概率分布"></a>后验概率分布</h2><p>上面所讨论的 responsibility 实际上就是隐变量 $\mathbf z$ 的后验概率，</p><script type="math/tex; mode=display">\begin{aligned}p(z_k=1|\mathbf x_n)&=\frac {p(z_k=1)p(\mathbf x_n|z_k=1)}{p(\mathbf x)}\\&=\frac {\pi_k \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal N(\mathbf x_n|\mu_j,\Sigma_j)}\\&=r_nk\end{aligned}</script><h2 id="EM-算法回顾"><a href="#EM-算法回顾" class="headerlink" title="EM 算法回顾"></a>EM 算法回顾</h2><p>从隐变量视角回顾 EM 算法，发现 E-step 实际上就是计算 $\mathbf z$ 的后验概率 $p(\mathbf z|\mathbf x, \theta^{(t)})$，M-step 是求最大化</p><script type="math/tex; mode=display">\begin{aligned}Q(\theta|\theta^{(t)})&=\mathbb E_{\mathbf z|\mathbf x, \theta^{(t)}} [\log p(\mathbf x, \mathbf z|\theta)]\\&=\int [\log p(\mathbf x, \mathbf z|\theta)] \cdot p(\mathbf z|\mathbf x, \theta^{(t)}) \ d \mathbf z\end{aligned}$$ (GMM12)的参数 $\theta$ 。对于离散型隐变量 $\mathbf z$ 而言，上式可写为$$Q(\theta|\theta^{(t)})=\sum_{\mathbf z} [\log p(\mathbf x, \mathbf z|\theta)] \cdot p(\mathbf z|\mathbf x, \theta^{(t)})$$ (GMM13)**证：**我们验证对 $\mu_k$ 的梯度是否与上面的推导一致，对 $\Sigma_k$ 的梯度验证完全类似。对 $\mu_k$ 求梯度，$$\begin{aligned} \frac {\partial Q}{\partial \mu_k}&=\frac {\partial} {\partial \mu_k} \log p(\mathbf x_n, z_k=1|\theta) p(z_k=1|\mathbf x_n, \theta^{(t)})\\&=\frac {\partial} {\partial \mu_k} \log \mathcal N(\mathbf x_n|\mu_k,\Sigma_k) \cdot r_{nk}\\&=\frac 1 {\mathcal N(\mathbf x_n|\mu_k,\Sigma_k)} \frac {\partial \mathcal N(\mathbf x_n|\mu_k,\Sigma_k)} {\partial \mu_k} \cdot r_{nk}\\&=\frac 1 {\mathcal N(\mathbf x_n|\mu_k,\Sigma_k)} (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1} \mathcal N(\mathbf x_n|\mu_k,\Sigma_k) \cdot r_{nk}\\&= (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1} \cdot r_{nk}\end{aligned}</script><p>这是单个数据点的对数最大似然 对 $\mu_k$ 的梯度，如果扩展到整个数据集，那么梯度为</p><script type="math/tex; mode=display">\frac {\sum_{n=1}^N \partial Q} {\partial \mu_k}=\sum_{n=1}^N  (\mathbf x_n-\mu_k)^{\top} \Sigma_k^{-1} \cdot r_{nk}</script><p>这与 {eq}<code>GMM7</code> 式的证明中所推导的梯度 $\partial \mathcal L / \partial \mu_k$ 完全一样。</p><p>根据后验概率 $p(\mathbf z|\mathbf x, \theta^{(t)})$，那么迭代更新时</p><script type="math/tex; mode=display">p(z_k=1)=\sum_{\mathbf x} p(z_k=1,\mathbf x| \theta^{(t)}) = \sum_{\mathbf x} p(\mathbf z|\mathbf x, \theta^{(t)}) p(\mathbf x)=\frac 1 N \sum_{n=1}^N r_{nk}=\frac {N_k} N</script>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lstm</title>
      <link href="/2021/11/12/ml/lstm/"/>
      <url>/2021/11/12/ml/lstm/</url>
      
        <content type="html"><![CDATA[<p>Long short term memory<br><span id="more"></span></p><h1 id="1-RNN"><a href="#1-RNN" class="headerlink" title="1. RNN"></a>1. RNN</h1><p>RNN 适合处理时序输入，例如机器翻译、语言识别等。RNN 结构如下图，</p><p><img src="/images/ml/lstm1.png" alt=""></p><center>图 1. RNN结构</center><p>但是 RNN 存在 long-term 依赖的问题，根据图 1</p><script type="math/tex; mode=display">\begin{aligned}h^{(t+1)}&=Wh^{(t)} + U x^{(t+1)}\\ &= W(W h^{(t-1)}+Ux^{(t)})+ U x^{(t+1)}\\&=\cdots\\ &=W^{t+1}h^{(0)}+W^tU x^{(1)}+\cdots + WU x^{(t)}+Ux^{(t+1)}\end{aligned}</script><p>易知，从 $0$ 时刻开始，经过 $t$ 个 step 后，矩阵系数的幂最高达到 $W^t$，为了方便讨论，假设 $W$ 可以特征分解为 $W=V \text {diag}(\lambda) V^{-1}$，那么 </p><script type="math/tex; mode=display">W^t = (V \text {diag}(\lambda) V^{-1})^t = V \text{diag}(\lambda)^t V^{-1}</script><p>（注：为了方便，本文中向量不采用粗体字符，但是根据上下文，不难理解它们表示的是向量）</p><p>如果特征值 $\lambda_i$ 不在 <code>1</code> 或者 <code>-1</code> 附近，那么 $\lambda_i^t$ 将会特别大或者特别小（只关心其绝对值，因为正负号只影响梯度方向）。如果特别大，则会导致“梯度爆炸”，训练过程极不稳定；如果特别小，导致“梯度消失”，那么无法确定参数的更新方向，从而无法正确的学习更新。</p><h1 id="2-LSTM"><a href="#2-LSTM" class="headerlink" title="2. LSTM"></a>2. LSTM</h1><p>全称：long short term memory networks</p><p>LSTM 是一种可以学习 long-term 依赖的 RNN 结构。</p><p>先给出标准 RNN 的结构图，激活函数用 <code>tanh</code> 为例，如图 2</p><p><img src="/images/ml/lstm2.png" alt=""></p><center>图 2. 标准 RNN 结构</center><p>数学表示为：</p><script type="math/tex; mode=display">a^{(t)} = b+W h^{(t-1)}+Ux^{(t)}</script><script type="math/tex; mode=display">h^{(t)} = \tanh(a^{(t)})</script><script type="math/tex; mode=display">o^{(t)} = c + V h^{(t)}</script><script type="math/tex; mode=display">\hat y^{(t)} = \text{softmax} (o^{(t)})</script><p>图 2 中，模型输出未画出，但这没关系，不影响我们理解 lstm 。</p><p>LSTM 与标准 RNN 有大体相似的连接结构，但是方框中的部分不同，如图 3</p><p><img src="/images/ml/lstm3.png" alt=""></p><center>图 3 lstm 结构</center><p>图 3 下方的 5 种操作，其中 <code>concatenate</code> 是将两个输入向量 合并起来 变成一个长的向量（而非相加），例如在图 2 中，隐层输出和输入两个向量（看作列向量）合并为 </p><script type="math/tex; mode=display">x'=\begin{bmatrix}h^{(t-1)} \\ x^{(t)}\end{bmatrix}</script><p>那么对应的参数矩阵也需要合并为 $W’=[W, U]$，最终的操作结果则为</p><script type="math/tex; mode=display">W'x'=[W, U]\begin{bmatrix}h^{(t-1)} \\ x^{(t)}\end{bmatrix}=W h^{(t-1)}+Ux^{(t)}</script><p><strong>总结各变量 shape：</strong></p><p>$x^{(t)} \in \mathbb R^{d}$，输入特征维度为 $d$； $U \in \mathbb R^{n \times d}$</p><p>$h^{(t)} \in \mathbb R^{n}$，隐层输出维度为 $n$； $W \in \mathbb R^{n \times n}$</p><p>$o^{(t)} \in \mathbb R^{c}$，输出层维度为 $c$； $V \in \mathbb R^{c \times n}$</p><h2 id="2-1-核心思想"><a href="#2-1-核心思想" class="headerlink" title="2.1 核心思想"></a>2.1 核心思想</h2><p>LSTM 的关键是引入了 cell 状态，即图 3 中的上面那条水平线，cell state 相当于一个传送带，在整个链中，从头到尾，中间仅受到一点点小影响：门（gate）对 cell 信息流的控制。</p><p>如图 4，</p><p><img src="/images/ml/lstm4.png" alt=""></p><center>图 4. 遗忘门（gate）结构</center><p>这个门由 一个 sigmoid 激活函数以及一个按位相乘操作组成，sigmoid 函数位于 $(0,1)$ 之间，越接近 0 则表示不让 cell 中的信息通过，越接近 1 表示尽量让 cell 中信息通过。</p><h2 id="2-2-摸清-LSTM-脉络"><a href="#2-2-摸清-LSTM-脉络" class="headerlink" title="2.2 摸清 LSTM 脉络"></a>2.2 摸清 LSTM 脉络</h2><p>LSTM 中，链接起来的方框称为 <code>cell</code>，每个 <code>cell</code> 包含几个重要的变量：</p><ol><li>输入 $x$</li><li>state $C$（或者用 $s$ 表示）</li><li>输出 $h$ （隐层输出）</li></ol><p>控制信息流可以使用 leaky unit，即 <code>running_mean</code> 来实现，$\mu_t=(1-\alpha) \mu_{t-1} + \alpha x_t$，当 $\alpha$ 越大，表示遗忘很快，$\alpha$ 时，表示记忆很好，能记住较长时间之前的信息。但是 $\alpha$ 是固定的，不够灵活，在 LSTM 中采用 遗忘门 来控制信息流的传递，遗忘门的输出由 <code>cell</code> 状态，输入，和输出三者共同动态的决定。</p><h3 id="2-2-1-遗忘门"><a href="#2-2-1-遗忘门" class="headerlink" title="2.2.1 遗忘门"></a>2.2.1 遗忘门</h3><p>如图 5 （a），</p><p><img src="/images/ml/lstm5.png" alt=""></p><center>图 5</center><p>遗忘门的数学表示为</p><script type="math/tex; mode=display">f_t=\sigma (W_f \cdot [h_{t-1}, x_t] + b_f)</script><p>其中 上一时刻 <code>cell</code> 的输出 $h_{t-1}$ 与本时刻的输入 $x_t$ 进行 concatenate，$W_f$ 和 $b_f$ 为遗忘门的权重和偏置参数，$\sigma$ 表示 sigmoid 激活。</p><h3 id="2-2-2-输入门"><a href="#2-2-2-输入门" class="headerlink" title="2.2.2 输入门"></a>2.2.2 输入门</h3><p>前面遗忘门控制 cell state 中，哪些信息是需要保留的，哪些信息是需要遗忘的。现在我们需要确定，新信息如何加到 cell state。</p><p>如图 5(b) 所示，右侧的 tanh layer 用于生成 $\hat C_t$，它是由新信息生成，并将叠加到 cell state 上，也就是说，$\hat C_t$ 可以看作是 cell state 的更新量，但是这个更新量还不能直接加到 cell state 上，需要一个输入门控制这个更新量或者说是对更新量做一个 scale 操作，（输入门结构与遗忘门类似，只是参数不同）。数学表示为</p><script type="math/tex; mode=display">i_t=\sigma(W_i \cdot [h_{t-1}, x_t]+b_i)</script><script type="math/tex; mode=display">\hat C_t = \tanh (W_C \cdot [h_{t-1}, x_t] + b_C)</script><p><strong>总结：</strong></p><p>旧的 cell state $C_{t-1}$ 按位乘以遗忘门输出 $f_t$，以便遗忘掉过去的一些无用信息，然后再按位加上更新量 $i_t \star \hat C_t$，其中 $\star$ 表示按位乘。如图 5 (c) 所示，更新 cell state 的数学表示为</p><script type="math/tex; mode=display">C_t = f_t \star C_{t-1} + i_t \star \hat C_t</script><h3 id="2-2-3-输出门"><a href="#2-2-3-输出门" class="headerlink" title="2.2.3 输出门"></a>2.2.3 输出门</h3><p>现在来确定 cell 的输出。首先与 普通 RNN 一样，使用一个输出门，输出门的输入为 本时刻的输入 $x_t$ 和 上一时刻 cell 的输出 $h_{t-1}$，进行 concatenate 然后经过仿射变换后经 sigmoid 激活函数，就得到输出门的 output。</p><p>但是输出门的 output 还不能作为 cell 的输出。将 cell state 经 tanh 压缩到 <code>(-1,1)</code> 之间，然后按位乘以输出门的 output 得到 cell 的输出，显然，此举可看作是对输出进行 scale。</p><p>数学表示为</p><script type="math/tex; mode=display">o_t=\sigma(W_o [h_{t-1},x_t]+b_o)</script><script type="math/tex; mode=display">h_t=o_t \star \tanh (C_t)</script><h2 id="2-3-LSTM-变体"><a href="#2-3-LSTM-变体" class="headerlink" title="2.3 LSTM 变体"></a>2.3 LSTM 变体</h2><p>上述 LSTM 结构是一个标准形式，实际上还有很多变体，在很多论文中都对标准 LSTM 进行了一些微小改变。</p><p><strong>第一个变体</strong> 结构如下 图 6(a)，</p><p><img src="/images/ml/lstm6.png" alt=""></p><center>图 6. LSTM 变体</center><p>图 6 (a) 中增加了一个 窥视孔 连接，即，将 cell state 连接到 gates 上，其中 输入门和遗忘门连接的是上一时刻的 cell state，而输出门连接的是本时刻的 cell state，于是</p><script type="math/tex; mode=display">f_t = \sigma (W_f \cdot [C_{t-1}, h_{t-1}, x_t]+b_f)</script><script type="math/tex; mode=display">i_i = \sigma(W_i \cdot [C_{t-1}, h_{t-1}, x_t] + b_i)</script><script type="math/tex; mode=display">o_t = \sigma(W_o \cdot [C_t, h_{t-1}, x_t]+b_o)</script><p><strong>第二个变体</strong> 结构如图 6(b) 所示，将遗忘门和输入门耦合起来，将 $1-f_t$ 作为输入门，而不是使用独立的输入门，这样做的思想是：$f_t$ 中用于记忆旧信息的部分，相应的 输入门 $1-f_t$ 不增加新输入信息，而 $f_t$ 中用于遗忘的旧信息的部分，输入门 $1-f_t$ 将会增加新信息进来到 cell state，数学表示为</p><script type="math/tex; mode=display">C_t = f_t \star C_{t-1} + (1-f_t) \star \hat C_t</script><p><strong>第三个变体</strong> 结构的改变更加明显，如图 6 (c) 所示，将 cell state 与 hidden state 合并，统一用 hidden state $h_t$ 表示。</p><p>数学表示为，</p><script type="math/tex; mode=display">z_t = \sigma(W_z \cdot [h_{t-1},x_t])</script><script type="math/tex; mode=display">r_t = \sigma(W_r \cdot [h_{t-1},x_t])</script><script type="math/tex; mode=display">\hat h_t = \tanh(W \cdot [r_t \star h_{t-1}, x_t])</script><script type="math/tex; mode=display">h_t = (1-z_t) \star h_{t-1} + z_t \star \hat h_t</script><h2 id="2-4-Bi-LSTM"><a href="#2-4-Bi-LSTM" class="headerlink" title="2.4 Bi-LSTM"></a>2.4 Bi-LSTM</h2><p>如图 7，</p><p><img src="/images/ml/lstm7.png" alt=""></p><center>图 7 双层 LSTM 结构。图源 ref 2</center><p>第一层从左到右，得到表征向量，例如 $h_1^{(t)}$，第二层从右到左，得到表征向量 $h_2^{(t)}$，两层向量可以 concatenate 或者 element-wise sum 得到第三次向量 $h^{(t)}$，然后使用全连接层得到 $o^{(t)}$，然后使用 softmax 得到 $y^{(t)}$ 。</p><p>ref</p><ol><li><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></p></li><li><p><a href="https://arxiv.org/pdf/1508.01991.pdf">Bidirectional LSTM-CRF Models for Sequence Tagging</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 循环神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EM 算法</title>
      <link href="/2021/11/01/ml/em/"/>
      <url>/2021/11/01/ml/em/</url>
      
        <content type="html"><![CDATA[<p>EM （Expection-Maximization）算法，是一种迭代算法，求期望和求最大交替迭代，从而更新我们所关心的变量，直到收敛（更新足够小）。EM 算法通常用于含有隐变量的概率模型参数的极大似然估计。<br><span id="more"></span></p><p>在 <a href="2021/11/13/ml/GMM">高斯混合模型</a>一文中，讲到迭代更新模型参数，这正是 EM 算法</p><ol><li>E 步：估计 responsibility  $r_{nk}$ 值（数据 $\mathbf x_n$ 来自第 $k$ 个分量的后验概率）。</li><li>M 步：使用 $r_{nk}$ 的值更新参数 $\theta$ 。</li></ol><p>注：需要给出初始化参数 $\theta_0$。</p><h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>（三硬币模型）：假设有 A,B,C 三枚硬币，正面出现的概率分布为 $\pi, p, q$。定义一次试验为：先抛 A，如出现正面，那么选择 B，否则选择 C，然后再抛所选的硬币（B 或 C），正面向上记为 1，反面向上记为 0 。独立重复试验 10 次，观测结果为<br><pre class="line-numbers language-none"><code class="language-none">1,1,0,1,0,0,1,0,1,1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>选择的是 B 还是 C 是不可知的 ，这是隐变量记为 $z$，$z=1$ 表示选择 B，$z=0$ 表示选择 C 。观测结果变量记为 $x$，参数记为 $\theta=(\pi, p, q)$，根据以上试验的观测结果估计参数值。</p><p>一次试验观测结果为 x，概率为</p><script type="math/tex; mode=display">\begin{aligned}P(x;\theta)&=\sum_z P(z;\theta) P(x|z;\theta)\\&=\pi p^x(1-p)^{1-x}+(1-\pi)q^x(1-q)^{1-x}\end{aligned}</script><p>那么对于所有的试验结果 $X$，概率为</p><script type="math/tex; mode=display">\begin{aligned}P(X;\theta)&=\sum_Z P(Z;\theta) P(X|Z;\theta)\\&=\prod_{i=1}^n [\pi p^{x_i}(1-p)^{1-x_i}+(1-\pi)q^{x_i}(1-q)^{1-x_i}]\end{aligned}</script><p>极大似然估计为</p><script type="math/tex; mode=display">\hat \theta =\arg \max_{\theta} \log P(X;\theta)</script><p>显然上式没有解析解，故想到通过迭代方法求数值解，于是 EM 算法就大显身手了。</p><p>既然是迭代，必然要设置一个初始值，记初值 $\theta_0=(\pi_0, p_0, q_0)$ 。</p><p>当第 $i$ 次迭代后，参数为 $\theta_i=(\pi_i, p_i, q_i)$，那么第 $i+1$ 次迭代时，</p><p><strong>E step：</strong> </p><p>计算观测数据 $x_j$ 来自硬币 B ($z=1$) 的概率，</p><script type="math/tex; mode=display">\begin{aligned} r_{j1}&=P(z=1|X=x_j)\\&=\frac {P(X=x_j,z=1)}{P(X=x_j)}\\&=\frac {P(X=x_j,z=1)}{P(X=x_j,z=1)+P(X=x_j,z=0)}\\&=\frac {\pi_i p_i^{x_j}(1-p_i)^{1-x_j}}{\pi_i p_i^{x_j}(1-p_i)^{1-x_j}+(1-\pi_i) q_i^{x_j}(1-q_i)^{1-x_j}}\end{aligned}</script><p>其中 $x_j$ 表示第 $j$ 次试验的观测结果。易得</p><script type="math/tex; mode=display">r_{j0}=P(z=0|X=x_j)=1-r_{j1}</script><p><strong>M step：</strong> </p><p>计算模型的新估值</p><p>首先计算 $N_1=\sum_{j=1}^n r_{j1}$，然后根据 <a href="2021/11/13/ml/GMM">高斯混合模型</a> 中的 {eq}<code>GMM7</code>， {eq}<code>GMM9</code>，{eq}<code>GMM11</code> 式，得</p><p>权重 </p><script type="math/tex; mode=display">\pi_{i+1}=\frac 1 n \sum_{j=1}^n r_{j1}</script><p>两个分布的期望值为</p><script type="math/tex; mode=display">p_{i+1}=\frac 1 {N_1} \sum_{j=1}^n r_{j1} x_j</script><script type="math/tex; mode=display">q_{i+1}=\frac 1 {N_0} \sum_{j=1}^n r_{j0} x_j</script><h1 id=""><a href="#" class="headerlink" title=" "></a> </h1>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>隐马尔可夫模型的参数学习</title>
      <link href="/2021/11/01/ml/hmm_learn/"/>
      <url>/2021/11/01/ml/hmm_learn/</url>
      
        <content type="html"><![CDATA[<p>本文根据最大似然法则求模型参数：状态转移矩阵 $A$ 和发射矩阵 $B$（初始状态概率 $\pi$ 被包含在 $A$ 中，即 $\pi=A_{1,2:}$，下标从 1 开始计算）。<br><span id="more"></span></p><h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><p>所谓有监督，指对于观测序列，有对应的（人工标注）状态序列。记某个样本为 $(\mathbf x, \mathbf z)$，包括观测序列 $\mathbf x$ 和状态序列 $\mathbf z$，那么其概率为</p><script type="math/tex; mode=display">\begin{aligned}P(\mathbf x, \mathbf z;A, B)&=\prod_{t=1}^T P(z_t|z_{t-1};A)P(x_t|z_t;B)\\&=\prod_{t=1}^T A_{z_{t-1}z_t} B_{z_tx_t}\end{aligned}</script><p>取对数，</p><script type="math/tex; mode=display">\log P = \sum_{i=1}^{|S|} \sum_{j=1}^{|S|} \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t =s_j]\log A_{ij}+\sum_{j=1}^{|S|}\sum_{k=1}^{|V|}\sum_{t=1}^T \mathbb I[z_t=s_j \land x_t=v_k]\log B_{jk}</script><p>对训练集 $\mathcal D =(\mathbf x^{(1)},\mathbf z^{(1)}), \cdots, (\mathbf x^{(m)}, \mathbf z^{(m)})$，对数似然函数为</p><script type="math/tex; mode=display">L=\sum_{l=1}^m \sum_{i=1}^{|S|} \sum_{j=1}^{|S|} \sum_{t=1}^{T_l} \mathbb I[z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j]\log A_{ij}\\+\sum_{l=1}^m \sum_{j=1}^{|S|}\sum_{k=1}^{|V|}\sum_{t=1}^{T_l} \mathbb I[z_t^{(l)}=s_j \land x_t^{(l)}=v_k]\log B_{jk} \tag{1}</script><p>约束条件为 </p><script type="math/tex; mode=display">\sum_{j=1}^{|S|} A_{ij}=1, \quad i=1,\cdots, |S|\\ A_{ij} \ge 0, \quad i,j=1,\cdots, |S|\\ \sum_{k}^{|V|} B_{jk}=1, \quad j=1,\cdots, |S|\\ B_{jk} \ge 0, \quad j=1,\cdots, |S|, k=1,\cdots, |V|</script><p>使用拉格朗日乘子法，拉格朗日函数为</p><script type="math/tex; mode=display">\mathcal L = L+ \sum_{i=1}^{|S|} \alpha_i \left(1-\sum_{j=1}^{|S|} A_{ij}\right)+\sum_{j=1}^{|S|} \beta_j \left(1-\sum_{k}^{|V|} B_{jk}\right)</script><p>对各参数求偏导，令其为 0，</p><script type="math/tex; mode=display">\frac {\partial \mathcal L} {\partial A_{ij}}=\frac 1 {A_{ij}} \sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j]-\alpha_i=0</script><script type="math/tex; mode=display">\Rightarrow A_{ij}=\frac 1 {\alpha_i} \sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j]</script><script type="math/tex; mode=display">\frac {\partial \mathcal L} {\partial \alpha_i}=1-\sum_{j=1}^{|S|} A_{ij}=0\\\Rightarrow  1-\sum_{j=1}^{|S|}\frac 1 {\alpha_i} \sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j]=0\\ \Rightarrow  \alpha_i=\sum_{j=1}^{|S|}\sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j]=\sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i]</script><p>于是，</p><script type="math/tex; mode=display">A_{ij}=\frac {\sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j]}{\sum_{l=1}^m \sum_{t=1}^{T_l}\mathbb I[z_{t-1}^{(l)}=s_i]} \tag{2}</script><p>类似地推导可得</p><script type="math/tex; mode=display">B_{jk}=\frac {\sum_{l=1}^m \sum_{t=1}^{T_l} \mathbb I[z_t^{(l)}=s_j \land x_t^{(l)}=v_k]}{\sum_{l=1}^m \sum_{t=1}^{T_l} \mathbb I[z_t^{(l)}=s_j]} \tag{3}</script><p>为了防止除零错误，即 $z_{t-1}^{(l)}=s_i$ 仅出现一次，可以采用 $+1$ 处理，例如，额外让每组 $z_{t-1}^{(l)}=s_i \land z_t^{(l)} =s_j$ 出现一次，那么 $z_{t-1}^{(l)}=s_i$ 出现 $|S|$ 次，此时 $A_{ij}=1/|S|$，这表示从状态 $i$ 等概率地转移到任意下一状态，同样类似地，$B_{jk}=1/|V|$ 。</p><h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><p>由于这里存在隐变量 $\mathbf z$ （状态），根据 <a href="2021/11/13/ml/GMM">GMM</a> 中的 EM 算法进行迭代，步骤如下：</p><hr><center>使用 EM 算法进行 HMM 学习</center><p>初始化模型参数 $A^{(0)}, \ B^{(0)}$</p><p><strong>for t=1,2,…</strong></p><ol><li><p>E-step，计算状态后验概率</p><script type="math/tex; mode=display">r(\mathbf z)=p(\mathbf z|\mathbf x;A^{(t-1)},B^{(t-1)})</script></li><li><p>M-step，求以下最大值优化问题</p><script type="math/tex; mode=display">A^{(t)},B^{(t)}=\arg \max_{A,B} \sum_{\mathbf z} r(\mathbf z) \log \frac {P(\mathbf x, \mathbf z;A, B)} {r(\mathbf z)}</script><script type="math/tex; mode=display">\sum_{j=1}^{|S|} A_{ij}=1, \ i=1,\ldots,|S|; A_{ij}\ge 0, i,j=1,\ldots |S|</script><script type="math/tex; mode=display">\sum_{k=1}^{|V|}B_{ik}=1, \ i=1,\ldots,|S|; B_{ik} \ge 0, i=1,\ldots, |S|, k = 1,\ldots,|V|</script></li></ol><p>（也可以通过计算 $A, B$ 的变化值 (例如矩阵的 F 范数)，当变化值小于某一预设阈值时，停止收敛。）</p><hr><p>上述算法的一个缺点是 $\mathbf z$ （状态序列） 有 $|S|^T$ 个取值（其中 $T$ 为观测序列长度，$|S|$ 为状态集数量），这个值很容易过大，导致计算耗时。考虑使用前向或后向算法，即，通过迭代的形式计算最值（动态优化）。</p><p>首先重写目标函数，</p><script type="math/tex; mode=display">\begin{aligned}A,B &=\arg\max_{A,B} \sum_{\mathbf z} r(\mathbf z) \log \frac {P(\mathbf x, \mathbf z;A, B)} {r(\mathbf z)}\\& = \arg\max_{A,B} \sum_{\mathbf z} r(\mathbf z) \log P(\mathbf x, \mathbf z;A, B)\\&=\arg\max_{A,B} \sum_{\mathbf z} r(\mathbf z) \log \left(\prod_{t=1}^T p(x_t|z_t;B)\right)\left(\prod_{t=1}^T p(z_t|z_{t-1};A)\right)\\&=\arg\max_{A,B} \sum_{\mathbf z} r(\mathbf z) \left(\sum_{t=1}^T (\log B_{z_t,x_t}+\log A_{z_{t-1},z_t})\right)\\&=\arg\max_{A,B} \sum_{\mathbf z} r(\mathbf z) \left(\sum_{j=1}^{|S|} \sum_{k=1}^{|V|}\sum_{t=1}^T \mathbb I[z_t=s_j \land x_t=v_k] \log B_{jk}\right) \\& \quad + \left(\sum_{i=1}^{|S|} \sum_{j=1}^{|S|}\sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] \log A_{ij} \right)\end{aligned}</script><p>上式推导中，第二行是由于 $-\log r(\mathbf z)$ 与 $A,B$ 无关，所以可以去掉。</p><p>不等式约束条件 $A_{ij} \ge 0$ 和 $B_{ik} \ge 0$ 可以忽略，这是因为目标函数中有 $\log A_{ij}$ 和 $\log B_{ik}$，这势必要求不等式约束条件必须成立，故只考虑等式约束条件（概率和为 1），使用拉格朗日乘子法，</p><script type="math/tex; mode=display">\begin{aligned}L(A,B,\delta,\epsilon)&=\sum_{\mathbf z} r(\mathbf z) \left(\sum_{j=1}^{|S|} \sum_{k=1}^{|V|}\sum_{t=1}^T \mathbb I[z_t=s_j \land x_t=v_k] \log B_{jk}\right) \\& \quad + \left(\sum_{i=1}^{|S|} \sum_{j=1}^{|S|}\sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] \log A_{ij} \right)\\& \quad + \sum_{j=1}^{|S|} \epsilon_j(1-\sum_{k=1}^{|K|}) + \sum_{i=1}^{|S|} \delta_i (1-\sum_{j=1}^{|S|} A_{ij})\end{aligned}</script><p>求目标函数对各参数的梯度，</p><script type="math/tex; mode=display">\frac {\partial L}{\partial A_{ij}} = \sum_{\mathbf z} r(\mathbf z) \frac 1 {A_{ij}} \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] - \delta_i \equiv 0</script><script type="math/tex; mode=display">A_{ij} = \frac 1 {\delta_i} \sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] \tag{4}</script><p>类似地，</p><script type="math/tex; mode=display">B_{jk}=\frac 1 {\epsilon_j} \sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_t=s_j \land x_t=v_k] \tag{5}</script><p>对朗格朗日乘子参数求梯度，</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial L}{\partial \delta_i} &= 1-\sum_{j=1}^{|S|}A_{ij}\\&=1-\sum_{j=1}^{|S|}\frac 1 {\delta_i}\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] \equiv 0\end{aligned}</script><p>得</p><script type="math/tex; mode=display">\begin{aligned}\delta_i &= \sum_{j=1}^{|S|}\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]\\&=\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i]\end{aligned}</script><p>类似地有</p><script type="math/tex; mode=display">\epsilon_j = \sum_{\mathbf z} r(\mathbf z)\sum_{t=1}^T \mathbb I[z_t=s_j]</script><p>将 $\delta_i, \ \epsilon_j$ 代入 $A_{ij}, \ B_{jk}$ 的表达式 (4)、(5) 两式，得</p><script type="math/tex; mode=display">\hat A_{ij}=\frac {\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]} {\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i]}</script><script type="math/tex; mode=display">\hat B_{jk}=\frac {\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_t=s_j \land x_t=v_k]}{\sum_{\mathbf z} r(\mathbf z)\sum_{t=1}^T \mathbb I[z_t=s_j]}</script><p>然而，上两式仍然需要对所有 $|S|^T$ 个状态序列 $\mathbf z$ 计算求和。使用动态优化的前向和后向算法。考虑 $A_{ij}$ 中的分子计算，</p><script type="math/tex; mode=display">\begin{aligned}&\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]\\=&\sum_{t=1}^T \sum_{\mathbf z}  \mathbb I[z_{t-1}=s_i \land z_t=s_j] r(\mathbf z)\\=&\sum_{t=1}^T \sum_{\mathbf z}  \mathbb I[z_{t-1}=s_i \land z_t=s_j] p(\mathbf z|\mathbf x;A,B)\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{t=1}^T \sum_{\mathbf z}  \mathbb I[z_{t-1}=s_i \land z_t=s_j] p(\mathbf z,\mathbf x;A,B)\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{t=1}^T p(z_{t-1}=s_i,z_t=s_j,\mathbf x;A,B)\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{t=1}^T \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)\end{aligned}</script><p>类似地计算分母部分，</p><script type="math/tex; mode=display">\begin{aligned}&\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i]\\=& \sum_{j=1}^{|S|}\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{j=1}^{|S|}\sum_{t=1}^T \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)\end{aligned}</script><p>于是 $\hat A_{ij}$ 的表达式可写为</p><script type="math/tex; mode=display">\hat A_{ij}=\frac {\sum_{t=1}^T \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)}{\sum_{k=1}^{|S|}\sum_{t=1}^T \alpha_i(t-1) A_{ik} B_{k,x_t} \beta_k(t)} \tag{6}</script><p>这样，计算复杂度从 $|S|^T$ 降为 $T\cdot |S|^2$，例如 $|S|=4$，$T=10$，显然此时后者远小于前者，降低了计算复杂度。</p><p>同样地有 $\hat B_{jk}$ 的分子</p><script type="math/tex; mode=display">\begin{aligned}&\sum_{\mathbf z} r(\mathbf z) \sum_{t=1}^T \mathbb I[z_t=s_j \land x_t=v_k]\\=& \frac 1 {p(\mathbf x;A,B)} \sum_{t=1}^T \sum_{\mathbf z} \mathbb I[z_t=s_j \land x_t = v_k] p(\mathbf z,\mathbf x;A,B)\\=& \frac 1 {p(\mathbf x;A,B)} \sum_{i=1}^{|S|}\sum_{t=1}^T \sum_{\mathbf z}\mathbb I[z_{t-1}=s_i \land z_t=s_j \land x_t = v_k] p(\mathbf z,\mathbf x;A,B)\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{i=1}^{|S|}\sum_{t=1}^T \mathbb I[x_t=v_k] \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)\end{aligned}</script><p>$\hat B_{jk}$ 的分母为</p><script type="math/tex; mode=display">\begin{aligned}&\sum_{\mathbf z} r(\mathbf z)\sum_{t=1}^T \mathbb I[z_t=s_j]\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{i=1}^{|S|}\sum_{t=1}^T \sum_{\mathbf z}\mathbb I[z_{t-1}=s_i \land z_t=s_j] p(\mathbf z,\mathbf x;A,B)\\=& \frac 1 {p(\mathbf x;A,B)}\sum_{i=1}^{|S|}\sum_{t=1}^T \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)\end{aligned}</script><p>于是</p><script type="math/tex; mode=display">\hat B_{ij}=\frac {\sum_{i=1}^{|S|}\sum_{t=1}^T \mathbb I[x_t=v_k] \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)}{\sum_{i=1}^{|S|}\sum_{t=1}^T \alpha_i(t-1) A_{ij} B_{j,x_t} \beta_j(t)}\tag{7}</script><hr><center> 用于 HMM 学习的前后向算法</center><p>初始化：随机初始化 $A, \ B$ 为某有效概率矩阵，且使得 $A_{i0}=0$， $B_{0k}=0$。例如 $A_{:,1:}=1/S$，$B_{1:,:}=1/V$，这里 $A \in \mathbb R^{(S+1)\times(S+1)}$，$B \in \mathbb R^{(S+1)\times V}$。为了简单，令 $|S| \rightarrow S$，$|V| \rightarrow V$ 。</p><p>循环：</p><p><strong>for m=1,2,…</strong></p><ol><li><p>E-step， 计算</p><script type="math/tex; mode=display">\alpha_i(t), \beta_i(t), \quad i=0,\ldots,S, \ t=1,\ldots, T</script><script type="math/tex; mode=display">\gamma_t(i,j)=\alpha_i(t-1) A_{ij}B_{j,x_t} \beta_j(t), \quad i=0,1,\ldots, S, \ j=1,2,\ldots, S</script></li><li><p>M-step， 计算</p><script type="math/tex; mode=display">A_{ij}=\frac {\sum_{t=1}^T \gamma_t(i,j)}{\sum_{j=1}^S \sum_{t=1}^T \gamma_t(i,j)}</script><script type="math/tex; mode=display">B_{jk}=\frac {\sum_{i=1}^S \sum_{t=1}^T \mathbf I[x_t=v_k]\gamma_t(i,j)}{\sum_{i=1}^S \sum_{t=1}^T \gamma_t(i,j)}</script></li></ol><hr>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>隐马尔可夫模型</title>
      <link href="/2021/10/29/ml/hmm/"/>
      <url>/2021/10/29/ml/hmm/</url>
      
        <content type="html"><![CDATA[<p>马尔可夫模型用于处理序列数据，但是实际上并不常用，这是因为马尔可夫模型中观测值就是我们所关心的值，然而实际上很多时候并非如此，例如 part-of-speech （POS） 标记任务中，我们观测到的是单词，而非 POS，或者在语音识别中，观测到的是语音而非单词自身。这个时候就需要用到 隐马尔可夫模型（HMM）了。<br><span id="more"></span></p><h1 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h1><p>观测到的序列 $\mathbf x=\{x_1,\cdots, x_T\}$，其中每个观测值来自集合 $V=\{v_1,\cdots, v_{|V|}\}$，我们感兴趣的状态序列（不可观测）为 $\mathbf z=\{z_1,\cdots, z_T\}$，其中每个状态均来自状态集 $S=\{s_1,\cdots, s_{|S|}\}$ 。状态转移矩阵依然记作 $A$ 。</p><p>将状态看作隐变量，那么输出序列是状态的函数，并作如下假设：</p><ol><li><p>观测独立假设</p><script type="math/tex; mode=display">P(x_t=v_k|z_t=s_j)=P(x_t=v_k|x_1,\cdots, x_T, z_1,\cdots,z_T)=B_{jk}</script><p> 即，$t$ 时刻的的观测值仅跟 $t$ 时刻的状态有关。矩阵 $B$ 表示由隐式状态到观测值的概率。</p></li></ol><p>例如 <a href="">马尔可夫模型</a> 中的天气的那个例子，天气状态无法直接观测，但是可以观测当天冰淇淋消费的数量，以 4 天为一个观测序列，那么一个观测序列可以是 $\mathbf x=(x_1=3, x_2=2,x_3=1,x_4=2)$。</p><h2 id="观测序列概率"><a href="#观测序列概率" class="headerlink" title="观测序列概率"></a>观测序列概率</h2><p>我们这样构建数据生成过程：假设有一个状态序列 $\mathbf z$，由马尔可夫模型生成，对应的状态转移矩阵为 $A$，在每个时刻 $t$，观测输出 $x_t$ 是状态 $z_t$ 的函数，于是观测序列的概率为</p><script type="math/tex; mode=display">P(\mathbf x;A,B)=\sum_{\mathbf z}P(\mathbf x, \mathbf z;A,B)=\sum_{\mathbf z} P(\mathbf x|\mathbf z;A,B)P(\mathbf z;A,B)</script><p>根据观测独立假设，可以进一步简化上面这个概率，</p><script type="math/tex; mode=display">\begin{aligned}P(\mathbf x;A,B)&=\sum_{\mathbf z} P(\mathbf x|\mathbf z;A,B)P(\mathbf z;A,B)\\&=\sum_{\mathbf z}\left(\prod_{t=1}^T P(x_t|z_t;B) \right)\left(\prod_{t=1}^T P(z_t|z_{t-1};A)\right)\\&=\sum_{\mathbf z} \left(\prod_{t=1}^T B_{z_tx_t} \right)\left() \prod_{t=1}^T A_{z_{t-1}z_t}\right)\end{aligned}</script><p>上式概率是对 $\mathbf z$ 的各种情况求和，而 $\mathbf z$ 序列长度为 $T$，每个状态有 $|S|$ 种可能，所以一共有 $|S|^T$ 个这样的状态序列，故计算复杂度为 $O(|S|^T)$ 。</p><p><strong>快速计算概率的方法——前向过程</strong></p><p>定义 $\alpha_i(t)=P(x_1,x_2,\cdots,x_t,z_t=s_i;A,B)$，表示截止到观测时刻 $t$，$t$ 时刻状态为 $s_i$ 的观测序列的概率，于是最终的观测序列的概率为</p><script type="math/tex; mode=display">\begin{aligned}P(\mathbf x;A,B)&=P(x_1,x_2,\cdots,x_T;A,B)\\&=\sum_{i=1}^{|S|} P(x_1,x_2,\cdots,x_T;z_T=s_i;A,B)\\&=\sum_{i=1}^{|S|} \alpha_i(T)\end{aligned}</script><p>根据 $\alpha_i(t)$ 的定义，不难知道有以下迭代关系，</p><script type="math/tex; mode=display">\alpha_j(t)=\sum_{i=1}^{|S|} \alpha_i(t-1) A_{ij}B_{jx_t}, \quad j=1,\cdots,|S|, t=1,\cdots, T</script><p>上式表明，$t$ 长度的观测序列是在 $t-1$ 长度的观测序列的基础上，再观测一个$t$ 时刻的值得到，这个 $t$ 时刻观测值为 $x_t$，其状态 $z_t=s_j$ 可以是由 $t-1$ 时刻的状态转移得到，$z_{t-1}$ 可以是 $1,2,\cdots,|S|$ 中的任意一个，然后根据 $z_t=s_j$ 这个状态生成观测值 $x_t$，这个概率为 $B_{jx_t}$。迭代关系的初始条件为</p><script type="math/tex; mode=display">\alpha_i(0)=A_{0i}, \quad i=1,\cdots, |S|</script><p>这表示，$0$ 时刻状态为 $s_i$，即初始状态为 $s_i$ 的概率，此时，观测序列长度为 0，故只要考虑初始状态的出现概率即可。</p><p>在每个时刻，我们均需要计算 $|S|$ 个值 $\alpha_1(t),\cdots,\alpha_{|S|}(t)$，故计算复杂度为 $O(|S| \cdot T)$ 。</p><p><strong>后向过程</strong></p><p>采用后向过程也可以快速计算概率，需要定义相关量为 $\beta_i(t)=P(x_T,x_{T-1},\cdots,x_{t+1},z_t=s_i;A,B)$，那么观测序列概率为</p><script type="math/tex; mode=display">P(\mathbf x;A,B)=\sum_{i=1}^{|S|} A_{0i} B_{i,x_1}\beta_i(1)</script><p>迭代公式为</p><script type="math/tex; mode=display">\begin{aligned}\beta_i(t)&=P(x_{t+1},\cdots,x_T,z_t=i)\\&=\sum_{j=1}^{|S|}P(j|i)P(x_{t+1}|j)P(x_{t+2},\cdots,x_T,z_{t+1}=j)\\&=\sum_{j=1}^{|S|}A_{ij}B_{j,x_{t+1}}\beta_j(t+1)\end{aligned}</script><p>初始条件为 $\beta_i(T)=1, \quad i=1,\cdots,|S|$，这是因为根据定义 $\beta_i(T)=P(x_{T},x_{T+1},z_{T}=s_i)$，由于从 $T+1$ 时刻到 $T$ 时刻的观测（子）序列不存在，为了使上式迭代成立，令其为 1 。</p><!-- **前后下关系**前向算法和后向算法的相关量的关系，根据定义有$$\begin{aligned}P(\mathbf x,\mathbf z;A,B)&=\sum_{i=1}^{|S|} P(x_1,\ldots,x_t,z_t=s_i;A,B) P(x_t,x_{t+1},\ldots, x_T, z_t=s_i)\\&=\sum_{i=1}^{|S|} \alpha_i(t) \beta_i(t)\\&=\sum_{i=1}^{|S|} \sum_{j}^{|S|} \alpha_i(t) A_{ij}\beta_j(t+1)\end{aligned} \tag{1}$$ --><h2 id="最可能的状态序列（解码）"><a href="#最可能的状态序列（解码）" class="headerlink" title="最可能的状态序列（解码）"></a>最可能的状态序列（解码）</h2><p>给定一个观测序列，求最有可能的状态序列，即求下式最大值问题的解</p><script type="math/tex; mode=display">\arg \max_{\mathbf z} P(\mathbf z|\mathbf x;A,B)=\arg \max_{\mathbf z} \frac {P(\mathbf x,\mathbf z;A,B)}{P(\mathbf x;A,B)}=\arg \max_{\mathbf z} P(\mathbf x,\mathbf z;A,B)</script><p>如果我们对每个 $\mathbf z$ 计算上式右端概率，然后取最大值，那么计算复杂度为 $O(|S|^T)$ 。可以采用动态规划算法，我们先给出算法过程如下：</p><p>记 $t$ 时刻状态为 $z_t=s_i$ 时所有局部状态路径 $(z_1,\cdots,z_{t-1})$ 的最大概率为</p><script type="math/tex; mode=display">\delta_i(t)=\max_{z_1,\cdots,z_{t-1}} \ P(x_1,\cdots,x_t,z_1,\cdots,z_{t-1},z_t=s_i;A,B), \quad i=1,\cdots,|S|</script><p>于是递归公示为，</p><script type="math/tex; mode=display">\begin{aligned}\delta_j(t+1)&=\max_{z_1,\cdots,z_t} \ P(x_1,\cdots, x_{t+1},z_1,\cdots,z_t,z_{t+1}=j)\\&=\max_{z_1,\cdots,z_t} \ P(x_1,\cdots,x_t,z_1,\cdots,z_t)A_{z_tj}B_{jx_{t+1}}\\&\stackrel{z_t=i}=\max_i \delta_i(t)A_{ij}B_{jx_{t+1}}\end{aligned}</script><p>上式中 $j=1,\cdots,|S|$ 。</p><p>初始条件 </p><pre><code>$$\delta_i(1)=\max_&#123;z_0&#125; P(x_1;z_1=s_i;A,B)=A_&#123;0i&#125; B_&#123;i,x_1&#125;, \ i=1,2,\ldots, |S|$$</code></pre><p>这样，对 $t+1$ 时刻的每一种可能的状态 $j$，均可计算出一个确定的 $t$ 时刻的状态 $i$，使得 $\delta_j(t+1)$ 最大，这表示，在任意时刻 $t$，对 $t$ 时刻的任意一个状态 $i$，均可确定一条状态路径 $path(z_t=i)=(z_1,\cdots,z_{t-1})$ 使得局部概率 $\delta_i(t)$ 最大，根据 $\delta_i(t)$ 的定义，最终目标的最大概率为 $\max_i \delta_i(T)$，求出  $\hat i = \arg \max_i \delta_i(T)$ 后，就可以确定最优状态路径 $path(z_T=\hat i)=(z_1,\cdots,z_{T-1})$ 了。</p><p>使用一个列表 $L$，$L$ 里面有 $T-1$ 个 列表 $l^t, \ t=1,\cdots,T-1$，每个列表 $l^t$ 表示一个时刻，列表 $l_t$ 的长度均为 $|S|$，$l^t$ 中下标 $i$ 表示当前时刻 $t+1$ 在状态为 $i$ 时前一时刻状态。</p><p>另外使用一个列表 $L^1$，长度为 $|S|$，记录 $t$ 时刻为各个状态的局部路径最大值 $\delta_j(t)$，每个时刻均对 $L^1$ 进行更新，直到 $T$ 时刻计算后，就是全局路径（终结时刻为各个状态）的最大概率值，此时选择 $L^1$ 中最大的概率值，对应的下标就是 $z_T$ 的值，然后再根据 $L$ 列进行路径回溯，即 $l^{T-1}$ 列表中取下标为 $z_T$ 的元素值 $z_{T-1}=l_{z_T}^{T-1}$，这就是最优路径商 $T-1$ 时刻的状态，然后在 $l^{T-2}$ 表中取下标 $z_{T-1}$ 的元素值，此为最优路径上 $T-2$ 时刻的状态，依次如此回溯，直到取出 $t=1$ 时刻的状态。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马尔可夫模型</title>
      <link href="/2021/10/29/ml/mm/"/>
      <url>/2021/10/29/ml/mm/</url>
      
        <content type="html"><![CDATA[<p>马尔可夫模型用于学习和处理（时间）序列数据，例如将音频转为文字，或者给一句话添加标注。<br><span id="more"></span></p><h1 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h1><p>给定一个状态集 $S=\{s_1,s_2,\cdots, s_{|S|}\}$ 。观察到一个时间序列 $\mathbf z \in S^T$ 。 例如一个天气系统 $S=\{晴,多云,雨\}$，一个观察到的序列为 $(z_1=晴,z_2=多云,z_3=多云,z_4=雨,z_5=多云)$，此时 $T=5$ 。在这个例子中，观察到的状态可以看作是一个随机系统随着时间的输出。不做任何假设时，在 $t$ 时刻的观察状态 $s_j$ 可以是任意多变量的一个函数，这些变量包括从 $1$ 时刻到 $t-1$ 时刻的状态值，以及其他很多我们可能都无法知晓的变量，我们可以做马尔可夫假设以简化模型。马尔可夫假设为：</p><ol><li><p>有限视野假设（齐次假设）</p><p> $t$ 时刻的状态仅依赖于 $t-1$ 时刻的状态，跟 $t-1$ 时刻之前的状态无关。</p><script type="math/tex; mode=display">P(z_t|z_{t-1},z_{t-2},\ldots,z_1)=P(z_t|z_{t-1})</script></li></ol><p>按照惯例，我们假设有一个初始状态 $s_0$，以及一个初始观察 $z_0 \equiv s_0$ ，有了这个假设，我们就可以将第一个观察状态 $z_1$ 的分布 $p(z_1)$ 写成基于初始状态的后验概率 $p(z_1|z_0)$  ，有时候我们会用向量 $\pi \in \mathbb R^{|S|}$ 来表示初始状态的分布 $P(z_0)$ 。</p><p>定义状态转移矩阵 $A \in \mathbb R^{(|S|+1) \times (|S|+1)}$，算上初始状态，一共有 $|S|+1$ 个状态，$A_{ij}$ 表示从状态 $s_i$ 到状态 $s_j$ 的概率，由于 $s_i$ 一定会转移到下一个某个状态，故行和 $\sum_j A_{ij}=1$ 。例如上面那个天气的例子，</p><script type="math/tex; mode=display">\begin{array}{c|cccc}A_{ij} & s_0 & 晴 & 多云 & 雨\\\hline\\s_0 & 0 & .33 & .33 & .33\\晴 & 0 & .8 & .1 & .1 \\多云 & 0 & .2 & .6 & .2\\雨 & 0 & .1 & .2 & .7\end{array}</script><ol><li><p>平稳过程假设</p><p> 基于当前观测值的下一观测值的条件分布随着时间保持不变。</p><script type="math/tex; mode=display">P(z_t=s_j|z_{t-1}=s_i)=P(z_2=s_j|z_1=s_i), \quad t=2,3,\ldots,T</script><p> 这个假设其实是指，状态转移矩阵随着时间推移保持不变。</p></li></ol><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>预测是指已知转移矩阵，计算状态序列的概率</p><p>为了方便，以下用下标 $i$ 表示状态 $s_i$，观察状态序列 $\mathbf z$ 的概率为</p><script type="math/tex; mode=display">\begin{aligned} P(\mathbf z)&=P(z_t,z_{t-1},\cdots,z_1;A)\\&=P(z_t|z_{t-1},\cdots,z_1;A)P(z_{t-1}|z_{t-2},\cdots,z_1;A)\cdots P(z_1|z_0;A)\\&=P(z_t|z_{t-1};A)P(z_{t-1}|z_{t-2};A)\cdots P(z_2|z_1;A) P(z_1|z_0;A)\\&=\prod_{t=1}^T P(z_t|z_{t-1};A)\\&=\prod_{t=1}^T A_{z_{t-1}z_t}\end{aligned}</script><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><p>根据观测到的序列，求转移矩阵 $A$ 。根据最大似然准则求解。对数似然函数为</p><script type="math/tex; mode=display">\begin{aligned}l(A)&=\log P(\mathbf z;A)\\&=\log \prod_{t=1}^T A_{z_{t-1}z_t}\\&=\sum_{t=1}^T \log A_{z_{t-1}z_t}\\&=\sum_{i=1}^{|S|}\sum_{j=1}^{|S|}\sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] \log A_{ij}\end{aligned}</script><p>于是问题转化为求优化问题的最优解：</p><script type="math/tex; mode=display">\max_A \quad l(A)\\s.t.  \quad \sum_{j=1}^{|S|}A_{ij}=1, \ i=1,2,\cdots, |S| \\A_{ij} \ge 0, \ i,j=1,2,\cdots, |S|</script><p>使用拉格朗日乘子法求解，</p><script type="math/tex; mode=display">L(A,\boldsymbol \alpha)=\sum_{i=1}^{|S|}\sum_{j=1}^{|S|}\sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j] \log A_{ij}+\sum_{i=1}^{|S|} \alpha_i \left(1-\sum_{j=1}^{|S|}A_{ij}\right)</script><p>求偏导数并令其为 0，</p><script type="math/tex; mode=display">\begin{aligned}\frac {\partial L(A,\boldsymbol \alpha)} {\partial A_{ij}}&=\frac 1 {A_{ij}} \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]-\alpha_i=0\\\Rightarrow \\A_{ij}&=\frac 1 {\alpha_i} \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]\end{aligned}</script><script type="math/tex; mode=display">\frac {\partial L(A,\boldsymbol \alpha)} {\partial \alpha_i}=1-\sum_{j=1}^{|S|} A_{ij}=1-\sum_{j=1}^{|S|}\frac 1 {\alpha_i} \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]=0</script><p>于是，</p><script type="math/tex; mode=display">\alpha_i=\sum_{j=1}^{|S|}\sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]=\sum_{t=1}^T \mathbb I[z_{t-1}=s_i]</script><p>最优解为</p><script type="math/tex; mode=display">\hat A_{ij}=\frac {\sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]} {\sum_{t=1}^T \mathbb I[z_{t-1}=s_i]}</script><p>如果有多个序列，$\mathbf z_1, \cdots, \mathbf z_K$，那么似然函数为 $P(\mathbf z_1)\cdots P(\mathbf z_K)$，对数似然则变成求和，易知，最优解形式变为</p><script type="math/tex; mode=display">\hat A_{ij}=\frac {\sum_{k=1}^K \sum_{t=1}^T \mathbb I[z_{t-1}=s_i \land z_t=s_j]} {\sum_{k=1}^K \sum_{t=1}^T \mathbb I[z_{t-1}=s_i]}</script>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性规划的单纯形方法</title>
      <link href="/2021/10/15/algo/lp_simplex/"/>
      <url>/2021/10/15/algo/lp_simplex/</url>
      
        <content type="html"><![CDATA[<p>线性规划问题在应用中很常见，有必要搞清楚如何解决这类问题。常用的方法有单纯形方法（The Simplex Method）<br><span id="more"></span></p><h1 id="基本形式"><a href="#基本形式" class="headerlink" title="基本形式"></a>基本形式</h1><p>优化问题可以写成如下形式：</p><script type="math/tex; mode=display">\min \ \mathbf {cx}=z\\s.t. \ A \mathbf {x=b} \\\quad \mathbf x \ge \mathbf 0</script><h2 id="形式转换"><a href="#形式转换" class="headerlink" title="形式转换"></a>形式转换</h2><p>对于不同于上述形式的线性规划问题，我们可以转换成上述形式。</p><ol><li><p>不等式约束条件</p><p> 对于约束条件，如果存在不等式，可以通过增加变量的方式转为不等式。例如 $a_1x_1+a_2x_2\le b$，那么增加一个变量 $e_1 \ge 0$，不等式变为 $a_1x_1+a_2x_2+e_1=b$，如果是 $a_1x_1+a_2x_2\ge b$，那么增加变量 $e_1$ 后，不等式变为 $a_1x_1+a_2x_2-e_1=b$。<strong>对每一个不等式，增加一个独立的变量 $e_i \ge 0$，而不能是相同的变量。</strong> 通常，对于 “$\le$”  的不等关系，添加的辅助变量称为松弛变量 （slack variable），而 “$\ge$” 不等关系对应的则为过载变量（excess variable）。</p></li><li><p>符号非受限变量</p><p> 如果在实际线性规划问题中，某个变量是为负，即“符号非受限变量”，例如 $x_j$，那么可以使用 $x_j’-x_j’’$ 代替 $x_j$，其中 $x_j’, x_j’’ \ge 0$。</p></li><li><p>最小 or 最大目标函数</p><p> 如果是最大化目标函数 $\max \ z$，那么可以先求 $\min \ (-z)$，然后对最优目标值取反即可。</p></li></ol><h1 id="单纯形方法"><a href="#单纯形方法" class="headerlink" title="单纯形方法"></a>单纯形方法</h1><h2 id="先导概念"><a href="#先导概念" class="headerlink" title="先导概念"></a>先导概念</h2><p>对于 $A \mathbf {x=b}, \ \mathbf x \ge \mathbf 0$，其中 $A \in \mathbb R^{m,n}$，$\mathbf b \in \mathbb R^m$。</p><p>假设 $\ rank(A,\mathbf b)=rank(A)=m$ ：</p><p>这个假设是合理的，如果 $rank(A)<m$，这说明方程组 $A \mathbf {x=b}$ 有 $m-rank(A)$ 个方程是冗余的，如果 $rank(A,\mathbf b)>rank(A)$，那么  $A \mathbf {x=b}$ 无解。另一方面，$m \ge rank(A,\mathbf b)\ge rank(A)$ 在任何条件下恒成立，如果 $rank(A)=m$，那么自然有 $rank(A,\mathbf b)=rank(A)=m$ 。</p><p>将矩阵 $A$ 的列重新排列为 $A=[B, N]$，使得 $B \in \mathbb R^{m,m}$ 是可逆矩阵，$\mathbf x=\begin{bmatrix}\mathbf x_B \\ \mathbf x_N\end{bmatrix}$ 是 $A \mathbf {x=b}$ 的解，其中 $\mathbf x_B=B^{-1}\mathbf b$，且 $\mathbf x_N=\mathbf 0$ 。注意满足 $[B, N]\begin{bmatrix}\mathbf x_B \\ \mathbf x_N\end{bmatrix}=\mathbf b$ 的 $\mathbf x_B$ 不一定只能是 $B^{-1}$，同样 $\mathbf x_N$ 不一定只能是 $\mathbf 0$。$\mathbf x_B=B^{-1}\mathbf b, \ \mathbf x_N=\mathbf 0$ 只是其中一个解（称为基本解）。</p><p>如果满足 $\mathbf x_B=B^{-1}\mathbf b \ge \mathbf 0$，称 $\mathbf x$ 是一个 <strong>基本可行解</strong>，回顾一下 $A=[B, N]$，其中 $B$ 是 m 阶可逆矩阵，这相当于已知 $n$ 列里面 <strong>最多</strong> 有 $m$ 个线性无关的列， 显然要选取这 $m$ 个线性无关的列，有 $\begin{pmatrix}n \\ m \end{pmatrix}$ 取法，所以自然有 $\begin{pmatrix}n \\ m \end{pmatrix}$ 个 $B$，称 $B$ 为基本矩阵，$N$ 为非基本矩阵，$\mathbf x_B$ 中各元素为 <strong>基本变量</strong> ，$\mathbf x_N$ 中各元素为 <strong>非基本变量</strong> 。</p><h2 id="方法实现"><a href="#方法实现" class="headerlink" title="方法实现"></a>方法实现</h2><p>使用表格形式实现单纯形方法，初始表格形式为</p><div class="table-container"><table><thead><tr><th>$z$</th><th>-$\mathbf c$</th><th>0</th></tr></thead><tbody><tr><td>$\mathbf 0$</td><td>A</td><td>$\mathbf b$</td></tr></tbody></table></div><p>这是根据 $z-\mathbf {cx}=0$ 以及 $A\mathbf {x=b}$，然后省略了 $\mathbf x$，按列可以分为三个部分，第一部分表示优化目标 $z$，第二部分表示 $\mathbf x$ 的系数，每列对应一个 $x_i$，第三部分表示等式右侧。然后采用迭代方法，具体实现步骤如下：</p><ol><li><p>寻找第一行 (Row 0) 中系数最大且为正的那个列 ($-c_i$)，即这列编号为 $i$，此时 $x_i$ 就作为“当前将要进入的基本变量”</p></li><li><p>找到“当前将要进入的基本变量” $x_i$ 后，执行“比例测试”：将第三部分的列中的值（也就是 $\mathbf b$）除以每一行中第 $i$ 列的系数（$x_i$ 的系数），例如第 $j$ 行的 $b_j$ 变成 $b_j/A_{ji}$，但是如果 $A_{ji} \le 0$，那么第 $j$ 行将不执行“比例测试”，注意 Row 0 行也不执行“比例测试”。对所有执行了“比例测试”的行的比例，选择 <strong>比例最小且为正</strong> 的行，记行号为 $j$，如果有多个行，其比例为正且均为最小，那么随意选择其中一行即可。</p></li><li><p>通过前两步，找到了“当前将要进入的基本变量” $x_i$，以及 $x_i$ 将要进入的行号 $j$。然后通过矩阵的基本行变换，使得第 $i$ 变成单位矩阵的第 $i$ 列，即，第 $i$ 列的 第 $j$ 行为 1，其余行为 0，注意这里 Row 0 行也参与行基本变换。通过这个变换，$x_i$ 已经进入了基本变量，由于此时 $x_i$ 的系数为 $1$，其值就是第三部分的列在第 $j$ 行的值，即 $x_i=b_j/A_{ji}$，$A_{ji}$ 是本次矩阵基本行变换之前的系数。 之前的位于第 $j$ 行的基本变量则被移除出去 。这里，“进入”指变量进入基本变量集合，“移除”指将变量从基本变量集合中移除出去。</p></li><li><p>重复以上过程，直到 Row 0 行没有正数，即第二部分 ($-\mathbf c$ ）没有正分量，结束迭代。此时，所有基本变量的值均已确定，非基本变量的值为 0，也就是说，最优解 $\mathbf x=\begin{bmatrix}\mathbf x_B \\ \mathbf x_N\end{bmatrix}$ 已经确定，代入原始的目标函数 $z=\mathbf {cx}$ 即可求得最优值。</p></li></ol><h3 id="例子说明"><a href="#例子说明" class="headerlink" title="例子说明"></a>例子说明</h3><p>有以下线性规划问题：</p><script type="math/tex; mode=display">\begin{aligned} \min z &= -3x_1+8x_2\\ s.t. \ 4x_1+2x_2 &\le 12 \\2x_1+3x_2 & \le 6\\ x_1, x_2 \ge 0\end{aligned}</script><p>第一步是将上述 LP 转换为标准形式，对两个不等式增加两个辅助变量，于是</p><script type="math/tex; mode=display">\begin{aligned} \min z &= -3x_1+8x_2\\ s.t. \ 4x_1+2x_2 + s_1 &= 12 \\2x_1+3x_2 +s_2& = 6\\ x_1, x_2, s_1, s_2 \ge 0\end{aligned}</script><p>根据 $z-\mathbf {cx}=0$ 以及 $A\mathbf {x=b}$，为相应表格如下，</p><div class="table-container"><table><thead><tr><th>Row</th><th>$z$</th><th>$x_1$</th><th>$x_2$</th><th>$s_1$</th><th>$s_2$</th><th>RHS</th><th>BV</th><th>ratio</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>3</td><td>-8</td><td>0</td><td>0</td><td>0</td><td>z=0</td><td>-</td></tr><tr><td>1</td><td>0</td><td>4</td><td>2</td><td>1</td><td>0</td><td>12</td><td>$s_1=12$</td><td>12/4=3</td></tr><tr><td>2</td><td>0</td><td>2</td><td>3</td><td>0</td><td>1</td><td>6</td><td>$s_2=6$</td><td>6/2=3</td></tr></tbody></table></div><p>由于 $s_1, \ s_2$ 是添加的辅助变量，所以其系数为 1， 在 $A$ 中的对应的列与单位矩阵对应的列相同，所以以 $s_1, \ s_2$ 为初始“基本变量”，RHS 列表示 “right hand side”，即 $\mathbf b$ 这列，BV 表示 basic variable 基本变量，ratio 表示各行“比例测试”后的比值。根据基本变量 $\mathbf x_B=B^{-1}\mathbf b$，这里 $B=I$ 为单位矩阵，所以 $\mathbf x_B=\mathbf b$，于是 $s_1=12, \ s_2=6$。</p><p>然后执行上述步骤 1，Row 0 行最正系数为 3，所以选中 $x_1$ 这列，接着执行“比例测试”，这列的 Row 1 和 Row 2 的系数均为正，所以全部参与“比例测试”（Row 0 永不参加“比例测试”），令 $b_j’=b_j/A_{ji}$，得到 ratio 列的值，选择其中最小的值，即 最小正比值，这里 $b_1’=b_2’$，故可以任选一行，不妨选择 Row 1 这行，接着执行“矩阵行基本变换”，使得 $A_{:,1}$ 这列为单位矩阵的列，其中 $A_{1,1}=1$，其余 $A_{j,1}=0, \ j \neq 1$。</p><p>矩阵行基本变换包含 $-\mathbf c$ 列和  RHS 列。</p><p>矩阵行基本变换之后，从 $x_1$ 到 RHS 各列的值已经确定，如下表中所示，</p><div class="table-container"><table><thead><tr><th>Row</th><th>$z$</th><th>$x_1$</th><th>$x_2$</th><th>$s_1$</th><th>$s_2$</th><th>RHS</th><th>BV</th><th>ratio</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>0</td><td>-19/2</td><td>-3/4</td><td>0</td><td>-9</td><td>z=-9</td><td>-</td></tr><tr><td>1</td><td>0</td><td>1</td><td>1/2</td><td>1/4</td><td>0</td><td>3</td><td>$x_1=12$</td><td>-</td></tr><tr><td>2</td><td>0</td><td>0</td><td>1</td><td>-1/4</td><td>1/2</td><td>0</td><td>$x_2=0$</td><td>-</td></tr></tbody></table></div><p>变换过程为：先将 Row 0 行 到 Row 2 行 分别乘以 $1/3, \ 1/4,\ 1/2$，然后 Row 0 行和 Row 2 行均各自减去 Row 1 行，为了使 Row 0 行 $z$ 的系数为 1，Row 0 再乘以 $3$。<br>此时 基本变量 BV 列的值很好确定，对每行，选择值为 1 的那些列，于是</p><p>Row 0 -&gt; z</p><p>Row 1 -&gt; $x_1$</p><p>Row 2 -&gt; $x_2$</p><p>即， $\mathbf x_B=[z, x_1, x_2]^{\top}$，子矩阵 $B=I$ 为单位矩阵，所以 $\mathbf x_B=B^{-1} \mathbf b$，得到 $z=-9, \ x_1=3, \ x_2=0$。</p><p>此时由于 Row 0 行中对应 $A$ 矩阵的变量的系数均为 负，故迭代结束，最优解为<br>$x_1=3, \  x_2=0$，最优值为 $z=-9$ 。（若 Row 0 行变量系数不全为 0，那么接着上表的结果，继续执行迭代）</p><h1 id="其他例外情况"><a href="#其他例外情况" class="headerlink" title="其他例外情况"></a>其他例外情况</h1><p>上面的例子中，添加的辅助变量 $s_1, \ s_2$ 在 $A$ 中的系数均为 $1$，使得这两列构成单位矩阵，即 $[A_{:,3}, \  A_{:,4}]=I_{2\times 2}$，但是如果约束条件中包含等式，或者是 “大于等于” 关系，等式使得 $A$ 中对应行全为 0，大于等于使得 $A$ 中对应行有 $-1$。对于“大于等于”这个情况，不能简单将这行乘以 $-1$ 使得变成“小于等于”关系，因为这会使得 RHS 列的值为 负，根据基本变量 $\mathbf x_B=B^{-1}\mathbf b$，这一行对应的基本变量值也是负，与 $\mathbf x \ge 0$ 矛盾。下面介绍两种解决方法。</p><h2 id="Two-Phase-Method"><a href="#Two-Phase-Method" class="headerlink" title="Two-Phase Method"></a>Two-Phase Method</h2><p>考虑以下优化问题</p><script type="math/tex; mode=display">\begin{aligned} \min \ 2x_1-x_2+x_3 &\\ s.t. \ 2x_1+x_2-2x_3 & \le 8\\ 4x_1-x_2+2x_3 & = 2\\ 2x_1+3x_2-x_3 &\ge 4\\ x_1, x_2,x_3 &\ge 0\end{aligned}</script><p>为第一个和第三个不等关系分别添加变量 $s_1$ 和 $e_3$，于是单纯形表为</p><div class="table-container"><table><thead><tr><th>z</th><th>$x_1$</th><th>$x_2$</th><th>$x_3$</th><th>$s_1$</th><th>$e_3$</th><th>RHS</th></tr></thead><tbody><tr><td>1</td><td>-2</td><td>1</td><td>-1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>2</td><td>1</td><td>-2</td><td>1</td><td>0</td><td>8</td></tr><tr><td>0</td><td>4</td><td>-1</td><td>2</td><td>0</td><td>0</td><td>2</td></tr><tr><td>0</td><td>2</td><td>3</td><td>-1</td><td>0</td><td>-1</td><td>4</td></tr></tbody></table></div><p>这里 $A \in \mathbb R^{3,5}$，显然没有 $3\times 3$ 的单位矩阵，也就没有初始的“基本变量”。为约束条件 2 和 3 分别添加两个变量 $a_1$ 和 $a_3$，注意到目标函数中没有 $a_1$ 和 $a_3$，目标函数改为 $\min z=a_1+a_3$，表格为</p><div class="table-container"><table><thead><tr><th>z</th><th>$x_1$</th><th>$x_2$</th><th>$x_3$</th><th>$e_3$</th><th>$s_1$</th><th>$a_1$</th><th>$a_3$</th><th>RHS</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td>0</td></tr><tr><td>0</td><td>2</td><td>1</td><td>-2</td><td>0</td><td>1</td><td>0</td><td>0</td><td>8</td></tr><tr><td>0</td><td>4</td><td>-1</td><td>2</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td></tr><tr><td>0</td><td>2</td><td>3</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>1</td><td>4</td></tr></tbody></table></div><p>将 Row 2 和 Row 3 加到 Row 0 上，使得 Row 0 上 $a_1$ 和 $a_3$ 的系数为 0，这样 Row 0 中出现正系数，这就是 Phrase 1 阶段的数据表，使用 单纯形方法，最后数据表变为</p><div class="table-container"><table><thead><tr><th>z</th><th>$x_1$</th><th>$x_2$</th><th>$x_3$</th><th>$e_3$</th><th>$s_1$</th><th>$a_1$</th><th>$a_3$</th><th>RHS</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>-2.14</td><td>0.43</td><td>1</td><td>-0.29</td><td>-0.43</td><td>5.71</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0.36</td><td>-0.07</td><td>0</td><td>0.21</td><td>0.07</td><td>0.71</td></tr><tr><td>0</td><td>0</td><td>1</td><td>-0.57</td><td>-0.29</td><td>0</td><td>-0.14</td><td>0.29</td><td>0.86</td></tr></tbody></table></div><p>显然 $x_1$ 和 $x_2$ 以及 $s_1$ 构成了这个阶段的最终基本变量集合。</p><p>然后是 phrase 2，将目标函数恢复成原来的目标函数，并删除 $a_1$ 和 $a_3$ 这两个列，此时表格为</p><div class="table-container"><table><thead><tr><th>z</th><th>$x_1$</th><th>$x_2$</th><th>$x_3$</th><th>$e_3$</th><th>$s_1$</th><th>RHS</th></tr></thead><tbody><tr><td>1</td><td>-2</td><td>1</td><td>-1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>-2.14</td><td>0.43</td><td>1</td><td>5.71</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0.36</td><td>-0.07</td><td>0</td><td>0.71</td></tr><tr><td>0</td><td>0</td><td>1</td><td>-0.57</td><td>-0.29</td><td>0</td><td>0.86</td></tr></tbody></table></div><p>将 Row 2 乘以 2 加到 Row 0 上，Row 3 乘以 -1 加到 Row 0 上，使得 <strong>Row 0 上基本变量的系数为 0</strong>，</p><div class="table-container"><table><thead><tr><th>z</th><th>$x_1$</th><th>$x_2$</th><th>$x_3$</th><th>$e_3$</th><th>$s_1$</th><th>RHS</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>0</td><td>0.29</td><td>0.14</td><td>0</td><td>0.57</td></tr><tr><td>0</td><td>0</td><td>0</td><td>-2.14</td><td>0.43</td><td>1</td><td>5.71</td></tr><tr><td>0</td><td>1</td><td>0</td><td>0.36</td><td>-0.07</td><td>0</td><td>0.71</td></tr><tr><td>0</td><td>0</td><td>1</td><td>-0.57</td><td>-0.29</td><td>0</td><td>0.86</td></tr></tbody></table></div><p>然后使用单纯形方法求解，最后得到的基本变量的解就是原优化问题的最优解。</p>]]></content>
      
      
      
        <tags>
            
            <tag> linear programming </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二分排序</title>
      <link href="/2021/10/12/ml/bi_rank/"/>
      <url>/2021/10/12/ml/bi_rank/</url>
      
        <content type="html"><![CDATA[<p>本文讨论二分排序的问题。所谓“二分排序”，指的是 $\mathbf y \in \{\pm 1\}^r$ ，表示样例 $\mathbf x_i$ 要么是相关的，要么是不相关的。</p><span id="more"></span><p>乍一看，二分排序跟二分类很像，但是用二分类的常用方法来解决二分排序问题，往往效果不好，这是因为排序问题中，相关的实例（或直接称作 正例）的占比很小，例如在缺陷检测中，绝大多少样本（例如 99.9%）都是良好的，那么二分类的学习方法得到的判决器对所有样本都判为负例，那么错误率已经非常小（0.1%），这显然对我们的缺陷检测这一目标毫无意义。二分类学习方法不奏效的根本原因是使用了 0-1 损失（或者它的凸替代），这一损失不足以解决排序问题。我们介绍另外的对二分排序问题适用的损失函数。</p><h1 id="损失"><a href="#损失" class="headerlink" title="损失"></a>损失</h1><p>实例序列 $\overline {\mathbf x}=(\mathbf x_1,\cdots, \mathbf x_r)$，预测值 $\mathbf y’=\mathbf w^{\top} \mathbf x \in \mathbb R^r$，这里为简单起见，直接使用 $\mathbf x$ 而非 $\Psi(\mathbf x, \mathbf y)$ 作为特征， target 值为 $\mathbf y \in \{\pm 1\}^r$，所以还需要一个参数 $\theta$，以便将预测向量转化为二值向量，</p><script type="math/tex; mode=display">b(\mathbf y')=(\text{sign}(y_1'-\theta),\cdots, \text{sign}(y_r'-\theta))</script><p>通常设置 $\theta=0$，但也有时候在某些具体问题中需要满足某些约束，从而调整 $\theta$ 值。</p><p>列出 <code>真阳，假阳，假阴，真阴</code> 四个概念如下：</p><p>True positives： $\ a=|\{i:y_i=+1 \land \text{sign}(y_i’-\theta)=+1\}|$</p><p>False positives： $\ b=|\{i:y_i=-1 \land \text{sign}(y_i’-\theta)=+1\}|$</p><p>False negatives： $\ c=|\{i:y_i=+1 \land \text{sign}(y_i’-\theta)=-1\}|$</p><p>True negatives： $\ d=|\{i:y_i=-1 \land \text{sign}(y_i’-\theta)=-1\}|$</p><p>recall（真阳在阳例中的占比）： $\ \frac a {a+c}$</p><p>precision（真阳在预测阳例中的占比）： $\ \frac a {a+b}$</p><p>specificity（特异度：真阴在阴例中的占比）： $\ \frac d {d+b}$</p><p>如果 $\theta \uparrow$，那么 $recall \downarrow$，但是 $precision \uparrow$</p><p>以下损失结合了 recall 以及 precision，也称 “多变量性能测度” （$0-1$ 损失在这里为 $\frac {b+d}{a+b+c+d}$）。</p><ol><li><p>利用 recall 和 specificity 的均值作为测度</p><script type="math/tex; mode=display">\Delta(\mathbf y', \mathbf y)=1-\frac 1 2 (\frac a {a+c}+\frac d {d+b})</script><p> 当 $b=c=0$ 时，即没有假阳和假阴，全部预测正确，此时 $\Delta=0$</p></li><li><p>F1-score</p><p> $F_1$ -score 计算如下</p><script type="math/tex; mode=display">F_1=\frac 1 {\frac 1 {\text{precision}}+\frac 1 {\text{recall}}}=\frac {2a}{2a+b+c}</script><p> 相关损失</p><script type="math/tex; mode=display">\Delta(\mathbf y', \mathbf y)=1-F_1</script></li><li><p>$F_{\beta}$-score</p><script type="math/tex; mode=display">F_{\beta}=\frac {1+\beta^2} {\frac 1 {\text{precision}}+\beta^2\frac 1 {\text{recall}}}=\frac {(1+\beta^2)a} {(1+\beta^2)a+b+\beta^2 c}</script><p> 相关损失</p><script type="math/tex; mode=display">\Delta(\mathbf y', \mathbf y)=1-F_{\beta}</script></li></ol><p>以下介绍两个概念：</p><ol><li><p>Recall at $k$ ：$a+b \le k$</p></li><li><p>precision at $k$：$a+b \ge k$</p></li></ol><h1 id="线性预测器"><a href="#线性预测器" class="headerlink" title="线性预测器"></a>线性预测器</h1><p>记参数为 $\mathbf w$，线性预测器为</p><script type="math/tex; mode=display">\mathbf y'=h_{\mathbf w}(\overline {\mathbf x})=(\mathbf w^{\top}\mathbf x_1, \cdots, \mathbf w^{\top}\mathbf x_r)</script><p>转到二值向量，</p><script type="math/tex; mode=display">\begin{aligned}b(\mathbf y')&=(\text{sign}(y_1'-\theta),\cdots, \text{sign}(y_r'-\theta))\\&=\arg \max_{\mathbf v \in V} \ \sum_{i=1}^r v_i y_i'\end{aligned}</script><p>其中 $V=\{\pm 1\}^r$ 。</p><h2 id="凸替代"><a href="#凸替代" class="headerlink" title="凸替代"></a>凸替代</h2><p>记损失函数为 $\Delta$，可以是上述三个损失之一。那么有</p><script type="math/tex; mode=display">\begin{aligned}\Delta(h_{\mathbf w}(\overline {\mathbf x}), \mathbf y)&=\Delta(b(h_{\mathbf w}(\overline {\mathbf x})), \mathbf y)\\ & \le \Delta(b(h_{\mathbf w}(\overline {\mathbf x})), \mathbf y)+\sum_{i=1}^r (b(h_{\mathbf w}(\overline {\mathbf x}))_i-y_i)\mathbf w^{\top}\mathbf x_i\\ & \le \max_{\mathbf v \in V} \left[\Delta(\mathbf v, \mathbf y)+\sum_{i=1}^r(v_i-y_i) \mathbf w^{\top}\mathbf x \right]\end{aligned} \tag{1} \label{1}</script><p>由于 $|V|=2^r$，当 $r$ 较大时，$|V|$ 较大，这就导致 $\eqref{1}$ 式右侧最大值计算较为耗时，需要寻求一种高效的计算方法。</p><p>对 $\forall a,b \in [r]$，令</p><script type="math/tex; mode=display">\mathcal Y_{a,b}=\{\mathbf v: |\{i: v_i=1 \land y_i=1\}|=a \land |\{i:v_i=1 \land y_i=-1\}|=b\}</script><p>$\mathcal Y_{a,b}$ 表示在给定 target $\mathbf y$ 的情况下，满足真阳数量为 $a$，且假阳数量为 $b$ 的所有预测序列集合。</p><p>固定 $a,b$ 值，在 $\mathcal Y_{a,b}$ 集合中求目标局部最大值，然后比较各个局部最大值，进而求得全局最大值。</p><p>在 $\mathcal Y_{a,b}$ 集合中求局部最大值的时候，观察  $\eqref{1}$ 式优化目标，发现 $y_i \mathbf w^{\top}\mathbf x$ 是固定不变的，由于固定了 $a,b$，所以 $c,d$ 也确定下来，所以对任意 $\mathbf v \in \mathcal Y_{a,b}$，$\Delta(\mathbf v, \mathbf y)$ 也固定不变（这对上述三个损失均成立），所以只要求以下最大值即可，</p><script type="math/tex; mode=display">\max_{\mathbf v \in \mathcal Y_{a,b}} \ \sum_{i=1}^r v_i \mathbf w^{\top} \mathbf x_i \tag{2} \label{2}</script><p>要求 $\eqref{2}$ 这个最大值，由于 $v_i \in \{\pm 1\}$，所以理论上只需要令 $v_i=\text{sign}(\mathbf w^{\top}\mathbf x_i)$。</p><p>然而由于 $\mathcal Y_{a,b}$ 的存在，使得真阳数量必须为 $a$，假阳数量必须为 $b$，也就是说，预测 $v_i=1$ 的数量固定为 $a+b$，因为 $v_i=1$，所以 $v_i \mathbf w^{\top} \mathbf x_i=\mathbf w^{\top} \mathbf x_i$，故需要 $\mathbf w^{\top} \mathbf x_i$ 尽可能大，才符合 $\eqref{2}$ 式的求最大值这一目标，即，尽可能地将较大的 $\mathbf w^{\top} \mathbf x_i$ 赋予 $v_i=1$ 。于是，根据真阳数量 $a$ 和假阳数量 $b$，分别在正例中将 top-a 的 $\mathbf w^{\top} \mathbf x_i$ 以及负例中 top-b 的 $\mathbf w^{\top} \mathbf x_i$ 所对应的样本预判为正 $v_i=1$，具体操作如下：</p><p>对样例进行排序，使得 </p><script type="math/tex; mode=display">\mathbf w^{\top} \mathbf x_1 \ge \cdots \ge \mathbf w^{\top} \mathbf x_r</script><p>其下标 $1,2,\cdots, r$ 是排序后的下标。此时根据 target $\mathbf y$ 值，将样例分为正例和负例两部分，每个部分内部是保持 $\mathbf w^{\top} \mathbf x_i$ 的降序排列，记这两部分的下标集合为</p><script type="math/tex; mode=display">S_+=\{i_1,\cdots, i_P\}\\S_-=\{j_1,\cdots, j_N\}</script><p>其中 $P=|\{i:y_i=1\}|, \ N=|\{i:y_i=-1\}|$，且有</p><script type="math/tex; mode=display">\mathbf w^{\top} \mathbf x_{i_1} \ge \cdots \ge \mathbf w^{\top} \mathbf x_{i_P}\\\mathbf w^{\top} \mathbf x_{j_1} \ge \cdots \ge \mathbf w^{\top} \mathbf x_{j_N}</script><p>那么，只要令 $i_1,\cdots, i_a$ 以及 $j_1,\cdots, j_b$ 对应的样本预测为正，</p><script type="math/tex; mode=display">v_{i_1}=\cdots = v_{i_a}=v_{j_1}=\cdots = v_{j_b}=1</script><p>另外，剩余的样例中，由于其 $\mathbf w^{\top} \mathbf x_i$ 较小，所以 $v_i \mathbf w^{\top} \mathbf x_i=-\mathbf w^{\top} \mathbf x_i$ 也是尽可能地大，符合 $\eqref{2}$ 求最大值这一目标。</p><p>求 $\eqref{2}$ 式的解 $\mathbf v^{\star}$ 后，根据 $\eqref{1}$ 式计算相应地目标局部最大值</p><script type="math/tex; mode=display">L_{a,b}=\left[\Delta(\mathbf v^{\star}, \mathbf y)+\sum_{i=1}^r(v_i^{\star}-y_i) \mathbf w^{\top}\mathbf x \right]</script><p>对每一组 $(a,b)$ 值，均计算其局部最大值 $L_{a,b}$ 以及对应的解 $\mathbf v^{\star}$，最后进行比较，可以求得全局最大值以及相应的解。</p><p>当然，由于 $y_i\mathbf w^{\top} \mathbf x_i$ 与 $\mathbf v$ （以及 $a,b$）无关，所以也可以更简单的求 </p><script type="math/tex; mode=display">L_{a,b}=\left[\Delta(\mathbf v^{\star}, \mathbf y)+\sum_{i=1}^r v_i^{\star} \mathbf w^{\top}\mathbf x \right]</script><p>然后比较求全局最大值和相应的解。</p><p>以上这种算法高效的本质是，将 $V$ 按 $(a,b)$ 值划分成若干组，每组求组内最大值，而每组内部由于 $\Delta(\mathbf v, \mathbf y)$ 以及 $y_i\mathbf w^{\top}\mathbf x$ 均相等，所以在组内演变成求 $\eqref{2}$ 式，而 $\eqref{2}$ 式可以快速求最优值和最优解。</p><p>注：上述计算过程中，$\theta$ 采用默认值 0 。</p><p>计算 $\eqref{1}$ 式步骤总结如下：</p><hr><p><strong>输入：</strong> $(\mathbf x_1, \cdots, \mathbf x_r)$，$(y_1,\cdots, y_r)$，$\mathbf w, \ V, \Delta$</p><p><strong>初始化：</strong></p><p>&emsp; $P=|\{i:y_i=1\}|, \ N=|\{i:y_i=-1\}|$</p><p>&emsp; $\boldsymbol \mu=(<script type="math/tex">\mathbf w^{\top} \mathbf x_1 , \cdots , \mathbf w^{\top} \mathbf x_r</script>)$，$\alpha^{\star}=-\infty$</p><p>&emsp; 排序使得 $\mu_1 \ge \cdots \ge \mu_r$</p><p>&emsp; 排序后正、负例下标集合分别为： $S_+=\{i_1,\cdots, i_P\}, \ S_-=\{j_1,\cdots, j_N\}$</p><p><strong>for</strong> $\ a=0,1,\cdots, P$</p><p>&emsp; $c=P-a$</p><p>&emsp; <strong>for</strong> $\ b=0,1,\cdots,N$</p><p>&emsp; &emsp; $d=N-b$</p><p>&emsp;&emsp; 计算 $\Delta$</p><p>&emsp;&emsp; 设置 $\mathbf v$ 使得 $v_{i_1}=\cdots = v_{i_a}=v_{j_1}=\cdots = v_{j_b}=1$，其余的 $v_i$ 全部设置为 $v_i=-1$</p><p>&emsp;&emsp; $\alpha=\Delta+\sum_{i=1}^r v_i \mu_i$</p><p>&emsp;&emsp; <strong>if</strong> $\alpha &gt; \alpha^{\star}$</p><p>&emsp;&emsp;&emsp; $\alpha = \alpha^{\star}, \ \mathbf v^{\star}=\mathbf v$</p><p><strong>输出：</strong> $\ \mathbf v^{\star}$</p><hr><p>然后可以使用 <a href="2021/09/29/ml/multiclass_algo">多分类算法</a> 一文中所述算法学习模型参数。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>排序问题</title>
      <link href="/2021/10/09/ml/rank/"/>
      <url>/2021/10/09/ml/rank/</url>
      
        <content type="html"><![CDATA[<p>排序问题的应用场景例如：搜索引擎根据搜索相关度对结果进行排序。</p><span id="more"></span><h1 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h1><p>记序列集合 $\mathcal X^{\star}=\bigcup_{n=1}^{\infty} \mathcal X^n$，其中每个序列长度可能不等，记序列 $\overline {\mathbf x}=(\mathbf x_1,\cdots,\mathbf x_r) \in \mathcal X^{\star}$，长度为 $r \in \mathbb N_+$，序列中每个实例 $\mathbf x \in \mathbb R^d$。假设函数 $h(\overline {\mathbf x}) \in \mathbb R^r$，记这个输出为向量 $\mathbf y$，对 $\mathbf y$ 排序（本文如不特别指定，则均为升序排序），记排序为 $\pi(\mathbf y)$，例如 $\mathbf y=(2,1,6,-1,0.5)$，那么 $\pi(\mathbf y)=(4,3,5,1,2)$ 表示 $\mathbf y$ 个元素在排序后的位置下标，例如 $2$ 升序排列为第 $4$ 位。</p><h1 id="损失"><a href="#损失" class="headerlink" title="损失"></a>损失</h1><p>对于这个有标记的样本，记样本域为 $Z=\bigcup_{r=1}^{\infty}(\mathcal X^r \times \mathbb R^r)$。定义损失</p><script type="math/tex; mode=display">l(h,(\overline {\mathbf x}), \mathbf y))=\Delta(h(\overline {\mathbf x}), \mathbf y)</script><p>损失可以取以下三种形式</p><ol><li><p>0-1 损失</p><p> $\Delta(\mathbf y’, \mathbf y)=\mathbb I[\pi(\mathbf y’)=\pi(\mathbf y)]$，这个损失缺点是无法区分 $\pi(\mathbf y’)$ 与 $\pi(\mathbf y)$ 差异程度。实际应用中这个损失几乎不使用。</p></li><li><p>Kendall-Tau 损失</p><script type="math/tex; mode=display">\Delta(\mathbf y', \mathbf y)=\frac 2 {r(r-1)} \sum_{i=1}^{r-1}\sum_{j=i+1}^r \mathbb I[\text{sign}(y_i'-y_j')\neq \text{sign}(y_i-y_j)] \tag{1}</script><p> 求和项数为一个等差数列的和 $1+2+\cdots+(r-1)=r(r-1)/ 2$ 。</p></li><li><p>Normalized Discounted Cumulative Gain (NDCG)</p><p> 借助一个非递减折扣函数 $D: \mathbb N \rightarrow \mathbb R_+$，累积增益函数为</p><script type="math/tex; mode=display">G(\mathbf y', \mathbf y)=\sum_{i=1}^r D(\pi(\mathbf y')_i) y_i</script><p> 由于 $D$ 是非递减的，所以 $D(\pi(\mathbf y’))$ 可以看作是 $\mathbf y’$ 的非负权重，$y_i’$ 越大，其权值越大，故有 $0 \le G(\mathbf y’, \mathbf y) \le G(\mathbf y, \mathbf y)$ 。定义损失为</p><script type="math/tex; mode=display">\Delta(\mathbf y', \mathbf y)=1-\frac {G(\mathbf y', \mathbf y)} {G(\mathbf y, \mathbf y)}=\frac 1 {G(\mathbf y, \mathbf y)} \sum_{i=1}^r [D(\pi(\mathbf y)_i)-D(\pi(\mathbf y')_i)] y_i \tag{2}</script><p> 一个常用的折扣函数为</p><script type="math/tex; mode=display">D(i)=\begin{cases} \frac 1 {\log_2 (r-i+2)} & i \in \{r-k+1,\cdots, r\} \\ 0 & \text{o.w.} \end{cases}</script><p> 上式，$k$ 用于调节序列中 top-k 的元素对损失起作用，或者说对排名有影响，top-k 以下的元素即使排名错误，我们也不关心。</p></li></ol><h1 id="线性预测器"><a href="#线性预测器" class="headerlink" title="线性预测器"></a>线性预测器</h1><p>线性函数为</p><script type="math/tex; mode=display">h_{\mathbf w}(\mathbf x_1, \cdots, \mathbf x_r)=(\mathbf w^{\top}\mathbf x_1, \cdots, \mathbf w^{\top}\mathbf x_r)</script><p>其中 $\mathbf w \in \mathbb R^d$ 。</p><p>样本集 $S=(\overline {\mathbf x}_1, \mathbf y_1), \cdots ,(\overline {\mathbf x}_m, \mathbf y_m)$，其中 $(\overline {\mathbf x}_i, \mathbf y_i) \in (\mathcal X, \mathbb R)^{r_i}$ 。 寻找 $\mathbf w$ 使得经验损失 $\sum_{i=1}^m \Delta(h_{\mathbf w}(\overline {\mathbf x}_i), \mathbf y_i)$ 最小。由于上面介绍的第二、三种损失无法求导，所以使用凸替代方法，与前面分类问题相似，下面介绍这两种损失的 Hinge Loss 形式。</p><h2 id="损失凸替代"><a href="#损失凸替代" class="headerlink" title="损失凸替代"></a>损失凸替代</h2><p>首先是 Kendall-Tau 损失的凸替代。</p><p>注意到 $\mathbb I[\text{sign}(y_i’-y_j’)\neq \text{sign}(y_i-y_j)]=\mathbb I[\text{sign}(y_i-y_j)(y_i’-y_j’)]$，这里可以将 sign 函数写成</p><script type="math/tex; mode=display">\text{sign}(x)=\begin{cases} 1 & x \ge 0 \\ -1 & x <0\end{cases}</script><p>然后根据 $y_i’-y_j’=\mathbf w^{\top}(\mathbf x_i-\mathbf x_j)$，所以</p><script type="math/tex; mode=display">\mathbb I[\text{sign}(y_i-y_j)(y_i'-y_j')]\le \max \{0, 1- \text{sign}(y_i-y_j)\mathbf w^{\top}(\mathbf x_i-\mathbf x_j)\}</script><p>代入 Kendall Tau 损失，得</p><script type="math/tex; mode=display">\Delta(h_{\mathbf w}(\overline {\mathbf x}), \mathbf y)\le\frac 2 {r(r-1)}\sum_{i=1}^{r-1}\sum_{j=i+1}^r \max \{0,  1- \text{sign}(y_i-y_j)\mathbf w^{\top}(\mathbf x_i-\mathbf x_j)\} \tag{3}</script><p>接着是 NDCG 的凸替代。</p><p>记 $[r]$ 的所有排列为 $V$，注意到有关系</p><script type="math/tex; mode=display">\pi(\mathbf y')=\arg \max_{\mathbf v \in V} \ \sum_{i=1}^r v_i y_i' \tag{4} \label{4}</script><p>根据 $\pi(\mathbf y’)$ 的定义， $y_i’$ 越大，其对应在 $\pi(\mathbf y’)$ 中的值就越大，将 $v_i$ 看作 $y_i’$ 的权值，由于权值非负，那么较大的数分配较大的权值，加权和自然是最大。</p><p>定义 $\Psi(\overline {\mathbf x}, \mathbf v)=\sum_{i=1}^r v_i \mathbf x_i$，那么根据 $\eqref{4}$ 式有</p><script type="math/tex; mode=display">\begin{aligned} \pi(h_{\mathbf w}(\overline {\mathbf x}))&=\arg \max_{\mathbf v \in V} \ \sum_{i=1}^r v_i \mathbf w^{\top} \mathbf x_i\\&=\arg \max_{\mathbf v \in V} \  \mathbf w^{\top} \left(\sum_{i=1}^r v_i \mathbf x_i \right)\\&=\arg \max_{\mathbf v \in V} \ \mathbf w^{\top} \Psi(\overline {\mathbf x}, \mathbf v)\end{aligned}</script><p>上式意味着 $\mathbf w^{\top} \Psi(\overline {\mathbf x}, \pi(h_{\mathbf w}(\overline {\mathbf x}))) \ge \mathbf w^{\top} \Psi(\overline {\mathbf x}, \pi(\mathbf y))$，当且仅当 $ \pi(h_{\mathbf w}(\overline {\mathbf x})) = \mathbf y$ 时等号成立，于是</p><script type="math/tex; mode=display">\begin{aligned}\Delta(h_{\mathbf w}(\overline {\mathbf x}), \mathbf y)&\le \Delta(h_{\mathbf w}(\overline {\mathbf x}), \mathbf y)+ \mathbf w^{\top}[\Psi(\overline {\mathbf x}, \pi(h_{\mathbf w}(\overline {\mathbf x})))-\Psi(\overline {\mathbf x}, \pi(\mathbf y))]\\& \le \max_{\mathbf v \in V} \ \{\Delta(\mathbf v, \mathbf y)+\mathbf w^{\top}[\Psi(\overline {\mathbf x}, \mathbf v)-\Psi(\overline {\mathbf x}, \pi(\mathbf y))]\}\\&=\max_{\mathbf v \in V} \ \left[\Delta(\mathbf v, \mathbf y)+\sum_{i=1}^r(v_i-\pi(\mathbf y)_i) \mathbf w^{\top}\mathbf x_i\right]\end{aligned}</script><p>上面的推导过程中，$\Delta(\mathbf v, \mathbf y)$ 的参数 $\mathbf v$ 实际应为对应的某个 $\mathbf y’$ 满足 $\pi(\mathbf y’)=\mathbf v$，但是为了突出这个凸替代函数与 $\mathbf v$ 有关，所以直接使用 $\mathbf v$ 作为参数。代入 NDCG 损失，则优化目标为</p><script type="math/tex; mode=display">L= \frac 1 {G(\mathbf y, \mathbf y)}\sum_{i=1}^r [D(\pi(\mathbf y)_i)-D(v_i)]y_i+\sum_{i=1}^r (v_i-\pi(\mathbf y)_i)\mathbf w^{\top}\mathbf x_i</script><p>优化问题（即，NDCG 损失的凸替代）可以进一步改写为</p><script type="math/tex; mode=display">\arg \min_{\mathbf v \in V} \ \sum_{i=1}^r (\alpha_i v_i+\beta_i D(v_i))</script><p>其中 $\alpha_i=-\mathbf w^{\top}\mathbf x_i, \ \beta_i=y_i/G(\mathbf y, \mathbf y)$ 。定义矩阵 $A \in \mathbb R^{r,r}$ 如下</p><script type="math/tex; mode=display">A_{ij}=j \alpha_i + D(j) \beta_i</script><p>可以将 $A_{ij}$ 理解为将任务 $i$ 分配给工人 $j$ 完成所需的成本，总共 $r$ 个工人， $r$ 个任务，目标则变成求如何分配，使得总成本最小。这个分配问题可以采用“KM算法”或者“线性规划算法”解决。</p><h2 id="线性规划算法"><a href="#线性规划算法" class="headerlink" title="线性规划算法"></a>线性规划算法</h2><p>将分配问题重新改写如下</p><script type="math/tex; mode=display">\arg \min_{B \in \mathbb R_+^{r,r}} \sum_{i,j=1}^r A_{ij} B_{ij}</script><script type="math/tex; mode=display">\begin{aligned} s.t. \quad & \forall i \in [r], \ \sum_{j=1}^r B_{ij}=1\\& \forall j \in [r], \ \sum_{i=1}^r B_{ij}=1\\& \forall i,j, \ B_{ij} \in \{0,1\}\end{aligned}</script><p>上式中，$B$ 矩阵相当于将 $r$ 个 $1$ 放在不同行不同列，其余矩阵元素均为 $0$。这样的 $B$ 一共有 $r!$ 种，这种矩阵称作置换矩阵。为方面起见，记 $\langle A, B\rangle=\sum_{i,j} A_{ij}B_{ij}$ 。</p><p>上面最后一个约束条件 $\forall i,j, \quad B_{ij} \in \{0,1\}$ 可以直接去掉，即 $B_{ij} \in \mathbb R$ 就可以，最终解不变。下面对此进行证明。</p><p>分配问题：</p><script type="math/tex; mode=display">\arg \min_{B \in \mathbb R_+^{r,r}} \sum_{i,j=1}^r A_{ij} B_{ij}</script><script type="math/tex; mode=display">\begin{aligned} s.t. \quad & \forall i \in [r], \ \sum_{j=1}^r B_{ij}=1\\& \forall j \in [r], \ \sum_{i=1}^r B_{ij}=1\end{aligned} \tag{5} \label{5}</script><p>令 $B$ 为 $\eqref{5}$ 的最优解。$B$ 可以写为</p><script type="math/tex; mode=display">\begin{aligned} B=\sum_i \gamma_i C_i\\ \gamma_i > 0, \ \sum_i \gamma_i = 1 \end{aligned}\tag{6} \label{6}</script><p>其中 $C_i$ 为置换矩阵，即 $r$ 个 $1$ 分别位于不同行不同列，其余元素为 $0$。这个等到后面再予以证明。</p><p>由于 B 是最优解，那么必然有 $\forall i, \ \langle A, B\rangle \le \langle A,C_i\rangle$，且必然 $\exists \ i$ 使得等号成立，这是因为如果 $\forall i, \ \langle A, B\rangle &lt; \langle A,C_i\rangle$，那么必然有 </p><script type="math/tex; mode=display">\langle A, B\rangle=\langle A, \sum_i \gamma_i C_i\rangle = \sum_i \gamma_i \langle A, C_i\rangle > \sum_i \gamma_i \langle A, B\rangle = \langle A, B\rangle</script><p>显然矛盾。所以必然 $\exists \ i$，使得 $\langle A, B\rangle = \langle A,C_i\rangle$，由于 $B$ 是最优解，那么自然 $C_i$ 也是最优解，即 $\eqref{5}$ 式最优解为一个置换矩阵。证毕。</p><p>下面证明 $\eqref{6}$ 式成立。</p><p>根据 $B=\sum_i \gamma_i C_i$，前面讲到置换 $C_i$ 一共有 $r!$ 个，于是有关系</p><script type="math/tex; mode=display">B=\sum_{i=1}^{r!} \gamma_i C_i</script><p>所以，如果上式存在解，那么就表明上式关系成立。代入矩阵各元素，那么上式实际上是 $r^2$ 个等式，$r!$ 个变量，即由 $r^2$ 组成的 $r!$ 元一次方程组。现在我们将这 $r^2$ 个 $r!$ 元一次方程按矩阵行分组进行列举，</p><p>第 1 组</p><script type="math/tex; mode=display">\sum_{i \in S_{11}} \gamma_i=B_{11}\\ \vdots\\\sum_{i \in S_{1r}} \gamma_i=B_{1r}</script><p>其中 $S_{mn}$ 表示满足关系 $(C_i)_{mn}=1$ 的那些置换矩阵 $C_i, \ i \in [r!]$ 的下标集合，且 $\bigcup_{n=1}^r S_{mn}=[r!]$，于是</p><script type="math/tex; mode=display">\sum_{k=1}^r B_{1k}=\sum_{k=1}^r \sum_{i \in S_{1k}} \gamma_i =\sum_{i=1}^{r!} \gamma_i=1</script><p>这证明了 $\eqref{6}$ 式中第二个等式关系。</p><p>第 k 组</p><script type="math/tex; mode=display">\sum_{i \in S_{k1}} \gamma_i=B_{k1}\\ \vdots\\\sum_{i \in S_{kr}} \gamma_i=B_{kr}</script><p>$\cdots$</p><p>根据 $B$ 的行和和列和均为 1，那么 $B$ 中元素取值自由度实际上 $r^2-2r+1=(r-1)^2$，令 $f(r)=(r-1)^2$，这表示只要确定了 $B$ 中任意 $f(r)$ 个元素的值，那么 $B$ 中所有元素的值均被确定。这是因为，原本 $B$ 的元素取值自由度为 $r^2$，根据行和为 1，自由度变成 $r^2-r$，即每行有一个值由本行其他元素值确定，不妨令最后一个元素值不自由；根据列和为 1，那么每列有一个值由本列其他元素值确定，显然最后一列不用考虑了，因为最后一列的值已经不自由了，所以此时是少了 $r-1$ 个自由度，于是最终元素取值自由度为 $r^2-r-(r-1)=(r-1)^2$。</p><p>例如，$r=2$，此时 $f(2)=1$，$B$ 的形式为 $\begin{bmatrix}B_{11} &amp; 1-B_{11} \\ 1-B_{11} &amp; B_{11}\end{bmatrix}$；或者 $r=3$，此时 $f(3)=4$，此时矩阵形式为</p><script type="math/tex; mode=display">\begin{bmatrix}B_{11} &  B_{12} & 1-B_{11}-B_{12} \\  B_{21} & B_{22} & 1-B_{21} - B_{22}\\ 1-B_{11}-B_{21} &  1-B_{12}-B_{22} & B_{11}+B_{12}+B_{21}+B_{22}-1\end{bmatrix}</script><p>所以，我们只需要 $(r-1)^2$ 个等式，例如 $B$ 的左上角的 $r-1$ 阶子方阵的元素，即</p><script type="math/tex; mode=display">\sum_{i \in S_{1,1}} \gamma_i=B_{1,1}\\ \vdots\\\sum_{i \in S_{1,r-1}} \gamma_i=B_{1,r-1}\\\vdots \\\sum_{i \in S_{r-1,1}} \gamma_i=B_{r-1,1}\\ \vdots\\\sum_{i \in S_{r-1,r-1}} \gamma_i=B_{r-1,r-1}</script><p>剩余的 $2r-1$ 个等式则全部与 $\sum_{i=1}^{r!} \gamma_i=1$ 这一个等式等价，所以最终变成 <strong>具有 $(r-1)^2+1$ 个等式的 $r!$ 元一次方程组</strong> 。</p><p>令 $d=r!-[(r-1)^2+1]$ ，即 $d$ 个 $\gamma_i$ 值是自由的，可以令它们均为 0，从而确定剩余的 $(r-1)^2+1$ 个 $\gamma_i$ 的值，再根据 $\sum_{i=1}^{r!} \gamma_i=1$，可知剩余的 $(r-1)^2+1$ 个 $\gamma_i$ 的和依然为 1，</p><p>于是 </p><script type="math/tex; mode=display">B=\sum_i^{(r-1)^2+1} \gamma_i C_i \ , \quad \sum_i^{(r-1)^2+1} \gamma_i=1</script><p>当 $r=2$ 时，$r!=(r-1)^2+1$，方程组具有唯一解。</p><p>当 $r\ge3$ 时，$r!&gt;(r-1)^2+1$，方程组具有无穷多解。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>结构化预测——一个多分类例子</title>
      <link href="/2021/10/08/ml/multiclass_algo_demo/"/>
      <url>/2021/10/08/ml/multiclass_algo_demo/</url>
      
        <content type="html"><![CDATA[<p>前面介绍了 <a href="2021/09/29/ml/multiclass_algo">多分类问题的算法实现</a>，现在讨论一个具体的多分类问题的例子。</p><span id="more"></span><h1 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h1><p>考虑一个 OCR 问题：预测一个手写单词的图片中的单词。为简单起见，假设所有的单词长度均为 $r$，字母表中字母数量为 $q$，且知道如何将一个图片切割成 $r$ 个子图，每个子图 size 相同，且有一个字母，定义 class-sensitive 特征映射函数为 $\Psi(\mathbf x, \mathbf y)$，其中 $\mathbf x$ 可以看成是 $n \times r$ 的一个矩阵，$n$ 为每个图片的像素数量，$\mathbf y$ 中每个元素对应一个字母在字母表中的索引，索引范围 $[1, q]$。$\Psi$ 的值域维度为 $nq+q^2$，其中前 $nq$ 部分记作 “类型1” 的特征，形式为</p><script type="math/tex; mode=display">\Psi_{i,j,1}(\mathbf x, \mathbf y)=\frac 1 r \sum_{t=1}^r x_{i,t} \mathbb I_{[y_t=j]}</script><p>上式表明，$\Psi_{i,j,1}(\mathbf x, \mathbf y)$ 表示在像素位置 $i$ 处表征字母 $j$ 的强度，这是 $r$ 个子图的在 $i$ 处的像素均值，当然也可以考虑跟子图相关的特征，但是那样的话，缺点是特征向量的维度非常大，优点是子图的 size 不必相同，然而我们这里简单起见，所以如此处理。“类型2” 的特征形式为</p><script type="math/tex; mode=display">\Psi_{i,j,2}(\mathbf x, \mathbf y)=\frac 1 r \sum_{t=2}^r \mathbb I_{[y_t=i]} \mathbb I_{[y_{t-1}=j]}</script><p>这是单词中 字母 $i$ 和 $j$ 相邻的强度均值。例如，<code>qu</code> 在单词中常见，而 <code>rz</code> 在单词中不常见。</p><p>从上面的分析可见，特征向量中不仅包含了单个字母的强度，还包含了相邻字母之间的关系强度。</p><h1 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h1><p>最后可通过如下方法预测</p><script type="math/tex; mode=display">h_{\mathbf w}(\mathbf x)=\arg \max_{\mathbf y \in \mathcal Y} \ \langle \mathbf w, \Psi(\mathbf x,\mathbf y) \rangle \tag{1} \label{1}</script><p>由于 $\mathcal Y$ 的大小随 $r$ 指数增涨，于是采用动态规划来有效的计算 $\eqref{1}$ 式。首先将特征写成如下形式</p><script type="math/tex; mode=display">\Psi(\mathbf x, \mathbf y)=\frac 1 r \sum_{t=1}^r \phi(\mathbf x, y_t, y_{t-1})</script><p>于是有</p><script type="math/tex; mode=display">\Psi_{i,j,1}(\mathbf x, \mathbf y)=\frac 1 r \sum_{t=1}^r \phi_{i,j,1}(\mathbf x, y_t, y_{t-1})</script><script type="math/tex; mode=display">\Psi_{i,j,2}(\mathbf x, \mathbf y)=\frac 1 r \sum_{t=1}^r \phi_{i,j,2}(\mathbf x, y_t, y_{t-1})</script><p>其中 $y_0=0$，且</p><script type="math/tex; mode=display">\phi_{i,j,1}(\mathbf x, y_t, y_{t-1})=x_{i,t} \mathbb I_{[y_t=j]}</script><script type="math/tex; mode=display">\phi_{i,j,2}(\mathbf x, y_t, y_{t-1})=\mathbb I_{[y_t=i]} \mathbb I_{[y_{t-1}=j]}</script><p>于是 $\eqref{1}$ 可以改写为</p><script type="math/tex; mode=display">h_{\mathbf w}(\mathbf x)=\arg \max_{\mathbf y \in \mathcal Y} \sum_{t=1}^r \langle \mathbf w, \phi(\mathbf w, y_t, y_{t-1}) \rangle \tag{2} \label{2}</script><p>由于 $r$ 是常量，故省略了 $1/ r$ 这一因子。采用动态规划计算时，我们使用一个矩阵 $M \in \mathbb R^{q,r}$，其中元素</p><script type="math/tex; mode=display">M_{s, \tau}=\max_{(y_1,\cdots y_{\tau}):y_{\tau}=s} \ \sum_{t=1}^{\tau} \langle \mathbf w, \phi(\mathbf w, y_t, y_{t-1}) \rangle</script><p>于是 $\eqref{2}$ 式变成求 $\max_s M_{s,\tau}$。而 $M$ 矩阵元素的计算遵循以下迭代关系：</p><script type="math/tex; mode=display">M_{s,\tau}=\max_{s'} \ (M_{s',\tau-1}+\langle \mathbf w, \phi(\mathbf x, s, s')\rangle) \tag{3} \label{3}</script><p>计算 $\eqref{2}$ 式的整个过程为</p><hr><p>算法 1</p><p><strong>输入：</strong> 原始数据 $\mathbf x \in \mathbb R^{n,r}$，参数 $\mathbf w$</p><p><strong>初始化：</strong></p><p>&emsp; <strong>foreach</strong> $\ s \in [q]$</p><p>&emsp;&emsp; $M_{s,1}=\langle w, \phi(\mathbf x, s, -1)\rangle$</p><p><strong>for</strong> $\ \tau=2,\cdots, r$</p><p>&emsp; <strong>foreach</strong> $\ s \in [q]$</p><p>&emsp;&emsp; 按 $\eqref{3}$ 式计算 $M_{s,\tau}$</p><p>&emsp;&emsp; 设置 $I_{s,\tau}=\arg \eqref{3}$ # 使 $\eqref{3}$ 式最大的那个 $s’$</p><p><strong>设置</strong> $y_t=\arg \max_s M_{s,r}$</p><p><strong>for</strong> $\ \tau=r,r-1,\cdots, 2$</p><p>&emsp; <strong>set</strong> $y_{\tau-1}=I_{y_{\tau}, \tau}$</p><p><strong>输出：</strong> $\mathbf y = (y_1,\cdots, y_r)$</p><hr><p>上面的步骤中，$M_{s,1}=\langle w, \phi(\mathbf x, s, -1)\rangle$ ，这里由于字母索引取值范围为 $[0,q-1]$，所以设置 $y_0=-1$。$I_{s,\tau}$ 记录了第 $\tau$ 个字母为 $s$ 时的前一个字母 $s’$，所以 $I$ 矩阵的第 $s$ 行记录了第 $r$ 个字母为 $s$ 时，最大化目标值 $M_{s,r}$ 的所有字母路径。</p><h1 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h1><p>定义损失函数为 </p><script type="math/tex; mode=display">\Delta(\mathbf y', \mathbf y)=\frac 1 r \sum_{i=1}^r \mathbb I_{[y_i \neq y_i']} \tag{4}</script><p>学习过程采用 <a href="2021/09/29/ml/multiclass_algo_demo">多分类问题的算法实现</a> 一文中的 SGD 学习算法，但是由于 $\mathcal Y$ 较大，计算 $h_{\mathbf w}(\mathbf x)$ 时采用了动态规划算法，所以还不能直接套用 SGD 的计算步骤。下面对几个关键点进行讨论，其中求</p><script type="math/tex; mode=display">\hat y=\arg \max_{y' \in \mathcal Y} (\Delta(y', y)+\langle \mathbf w^{(t)}, \Psi(\mathbf x, y')-\Psi(\mathbf x, y)\rangle)</script><p>考虑到 $1/r$ 是常量因子，故统一省略，上式在本例中变成</p><script type="math/tex; mode=display">\hat {\mathbf y}=\arg \max_{\mathbf y' \in \mathcal Y} \ \left(\sum_{i=1}^r \mathbb I_{[y_i \neq y_i']}+\langle \mathbf w^{(t)}, \phi(\mathbf x, y_i', y_{i-1}')-\phi(\mathbf x, y_i, y_{i-1})\rangle \right) \tag{5} \label{5}</script><p>将上面的 $M$ 矩阵改写为 $M’$，</p><script type="math/tex; mode=display">M_{s, \tau}'=\max_{(y_1',\cdots y_{\tau}'):y_{\tau}'=s}  \ \left(\sum_{i=1}^{\tau} \mathbb I_{[y_i \neq y_i']}+\langle \mathbf w^{(t)}, \phi(\mathbf x, y_i', y_{i-1}')-\phi(\mathbf x, y_i, y_{i-1})\rangle \right)</script><p>于是优化目标变成了求 $\max_s M_{s,r}’$，迭代关系为</p><script type="math/tex; mode=display">M_{s,\tau}'=\max_{s'} \ (M_{s', \tau-1}'+\mathbb I_{[y_{\tau} \neq s]}+\langle \mathbf w^{(t)}, \phi(\mathbf x, s, s')-\phi(\mathbf x, y_{\tau}, y_{\tau-1})\rangle) \tag{6} \label{6}</script><p>其中  $M_{s,1}’=\mathbb I_{[y_1 \neq s]}+\langle \mathbf w^{(1)}, \phi(\mathbf x,s,0)-\phi(\mathbf x, y_1,0)\rangle$</p><p>注意上式中 $\mathbf y$ 向量元素下标从 $1$ 开始，且字母表中字母索引也从 $1$ 开始，故 $\phi$ 函数中最后一个参数为 $0$，而上面的算法步骤中，遵循程序的约定，下标和索引均从 $0$ 开始，$\phi$ 函数中最后一个参数需要改为 $-1$，这一点需要搞清楚。</p><p>现在，就可以通过动态规划计算出 $\hat {\mathbf y}$。梯度 $\mathbf v_t=\Psi(\mathbf x, \hat y)-\Psi(\mathbf x, y)$，各参数均已确定，可以直接计算出梯度 $\mathbf v_t$ 。于是，整个 SGD 方法求解参数 $\mathbf w$ 的学习算法步骤均已确定，总结如下：</p><hr><p>算法 2</p><p><strong>参数：</strong></p><p>&emsp; 学习率 $\eta$，迭代次数 $T$。</p><p>&emsp; 原损失函数 $\Delta: \mathcal Y \times \mathcal Y \rightarrow \mathbb R_+$</p><p>&emsp; 映射到特征空间的函数 $\Psi: \mathcal X \times \mathcal Y \rightarrow \mathbb R^d$</p><p><strong>初始化：</strong> $\ \mathbf w^{(1)}=\mathbf 0 \in \mathbb R^d$</p><p><strong>for</strong> $t=1,2,\cdots, T$</p><p>&emsp; 随机取样 $(\mathbf x, \mathbf y) \in \mathcal D$</p><p>&emsp; 根据 $\eqref{5}, \eqref{6}$ 和“算法 1” 计算 $\hat {\mathbf y}$</p><p>&emsp; $\mathbf v_t=\Psi(\mathbf x, \hat {\mathbf y})-\Psi(\mathbf x, \mathbf y)$</p><p>&emsp; $\mathbf w^{(t+1)}=\mathbf w^{(t)}-\eta \mathbf v_t$</p><p><strong>输出：</strong> $\ \overline {\mathbf w}=\frac 1 T \sum_{t=1}^T \mathbf w^{(t)}$</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多分类的学习算法</title>
      <link href="/2021/09/29/ml/multiclass_algo/"/>
      <url>/2021/09/29/ml/multiclass_algo/</url>
      
        <content type="html"><![CDATA[<p>多分类问题，对于线性可分的训练集，可以使用 Perception 算法学习，此时损失相当于使用了 $0-1$ 损失，而对于非线性可分的情况，$0-1$ 损失显然由于其不可导，不再适用，需要寻找一种“凸替代”（convex surrogate）损失函数。<br><span id="more"></span></p><h1 id="凸替代"><a href="#凸替代" class="headerlink" title="凸替代"></a>凸替代</h1><p>凸替代需要满足两个条件：</p><ol><li>是凸函数</li><li>凸替代损失必须是 upper bound 原损失（是原损失的上边界）。</li></ol><p>例如，使用 hinge 损失作为 $0-1$ 的凸替代，以二分类问题为例说明，</p><script type="math/tex; mode=display">l^{0-1}(\mathbf w, (\mathbf x, y))=\mathbb I_{y\neq \text{sign}(\langle \mathbf w, \mathbf x\rangle)}=\mathbb I_{y \langle \mathbf w, \mathbf x\rangle \le 0}</script><script type="math/tex; mode=display">l^{hinge}(\mathbf w, (\mathbf x, y))=\max \{0, 1-y \langle \mathbf w, \mathbf x\rangle\}</script><p>显然有 $\forall \ y \langle \mathbf w, \mathbf x\rangle \in \mathbb R, \ l^{hinge}(\mathbf w, (\mathbf x, y)) \ge l^{0-1}(\mathbf w, (\mathbf x, y))$。</p><h1 id="泛-Hinge-损失"><a href="#泛-Hinge-损失" class="headerlink" title="泛 Hinge 损失"></a>泛 Hinge 损失</h1><p>上一节是二分类情况下的凸替代，现在需要确定多分类问题下的凸替代，即，泛 Hinge 损失。根据 <a href="/2021/09/22/ml/multiclass">多分类的基本介绍</a>，给出预测函数的一般形式：</p><script type="math/tex; mode=display">h_{\mathbf w}(\mathbf x)=\mathop{\arg}\max_{y' \in \mathcal Y} \langle \mathbf w, \Psi(\mathbf x, y')\rangle \tag{1}</script><p>根据上式，即，$h_{\mathbf w}(\mathbf x)$ 是使 得分 最高的那个分类，在当前参数 $\mathbf w$ 下，得分最高的那个分类不一定是样本真实分类，</p><script type="math/tex; mode=display">\langle \mathbf w, \Psi(\mathbf x, y)\rangle \le \langle \mathbf w, \Psi(\mathbf x, h_{\mathbf w}(\mathbf x))\rangle</script><p>其中 $y$ 为样本真实分类，在当前参数 $\mathbf w$ 下，如果得分最高的那个分类恰好是样本真实分类（或者说，当前参数对这个样本分类预测正确），那么等式成立。</p><p>记原损失函数为 $\Delta(h_{\mathbf w}(\mathbf x), y)$，其中 $y$ 表示样本真实分类，$h_{\mathbf w}(\mathbf x)$ 表示样本预测分类。原损失函数常见的可以是 $0-1$ 损失，我们需要构造原损失函数的凸替代，根据上式不等式关系以及上面凸替代的第二个要求，不难想到写出如下关系</p><script type="math/tex; mode=display">\Delta(h_{\mathbf w}(\mathbf x), y) \le \Delta(h_{\mathbf w}(\mathbf x), y)+\langle \mathbf w, \Psi(\mathbf x, h_{\mathbf w}(\mathbf x))-\Psi(\mathbf x, y)\rangle</script><p>由于 $h_{\mathbf w}(\mathbf x) \in \mathcal Y$，可以将上面这个不等式的右端 upper bound 为</p><script type="math/tex; mode=display">\max_{y' \in \mathcal Y} \ (\Delta(y', y)+\langle \mathbf w, \Psi(\mathbf x, y')-\Psi(\mathbf x, y)\rangle) \stackrel{def}=  l(\mathbf w, (\mathbf x, y)) \tag{100} \label{100}</script><p>于是 $l(\mathbf w, (\mathbf x, y)) \ge \Delta(h_{\mathbf w}(\mathbf x), y)+\langle \mathbf w, \Psi(\mathbf x, h_{\mathbf w}(\mathbf x))-\Psi(\mathbf x, y)\rangle\ge \Delta(h_{\mathbf w}(\mathbf x), y)$，第一个非严格不等关系中，当</p><script type="math/tex; mode=display">h_{\mathbf w}(\mathbf x)=\mathop{\arg} \max_{y' \in \mathcal Y} \ (\Delta(y', y)+\langle \mathbf w, \Psi(\mathbf x, y')-\Psi(\mathbf x, y)\rangle) \tag{2}</script><p>时，等号成立。第二个非严格不等关系中，当 </p><script type="math/tex; mode=display">h_{\mathbf w}(\mathbf x)=y \tag{3}</script><p>时, 等号成立，将 (3) 式代入 (2) 式 有</p><script type="math/tex; mode=display">\Delta(y, y)+\langle \mathbf w, \Psi(\mathbf x, y)-\Psi(\mathbf x, y)\rangle \ge \Delta(y', y)+\langle \mathbf w, \Psi(\mathbf x, y')-\Psi(\mathbf x, y)\rangle, \ \forall y' \in \mathcal Y \setminus \{y\}</script><p>由于 $\Delta(y,y)=0$，化简上式得</p><script type="math/tex; mode=display">\langle \mathbf w,\Psi(\mathbf x, y)\rangle \ge \langle \mathbf w, \Psi(\mathbf x, y')\rangle+\Delta(y', y) \tag{4}</script><p>即，满足 (4) 式关系时，下面不等式关系中等号成立。</p><script type="math/tex; mode=display">l(\mathbf w, (\mathbf x, y)) \ge \Delta(h_{\mathbf w}(\mathbf x), y) \tag{5}</script><p>注：(5) 式恒成立，只是在满足 (4) 条件时，(5) 式中等号成立。</p><p>$l(\mathbf w, (\mathbf x, y))$ 是若干个有关 $\mathbf w$ 的线性函数的最大值函数，根据本文附录的 <strong>定理 1</strong>， <strong>$l(\mathbf w, (\mathbf x, y))$ 是 $\mathbf w$ 的凸函数。并且 $l(\mathbf w, (\mathbf x, y))$ 是 $\rho-$Lipschitz 函数。</strong>（证明见下方附录）</p><p>$\eqref{100}$ 式定义的 $l(\mathbf w, (\mathbf x, y))$ 就是泛 hinge 损失。对于二分类情况，令原损失 $\Delta$ 为 $0-1$ 损失，当 $\mathcal Y = \{\pm 1\}$ 时，设置 $\Psi(\mathbf x, y)=y\mathbf x/2$，那么泛 hinge 损失将退化为普通 hinge 损失，</p><script type="math/tex; mode=display">l(\mathbf w, (\mathbf x, y))=\max_{y'\in \{y, -y\}} \Delta(y', y)+\langle \mathbf w, (y'-y)\mathbf x/2 \rangle</script><p>当 $y’=y$ 时， $\Delta(y’, y)=0$，$\langle \mathbf w, (y’-y)\mathbf x/2 \rangle=0$</p><p>当 $y’=-y$ 时，$\Delta(y’, y)=1$，$\langle \mathbf w, (y’-y)\mathbf x/2 \rangle=-y \langle \mathbf w, \mathbf x\rangle$</p><p>于是 $l(\mathbf w, (\mathbf x, y))=\max \{0, 1-y \langle \mathbf w, \mathbf x\rangle\}$，这与前文 <a href="/2021/09/22/ml/multiclass">多分类的基本介绍</a> 中所讨论的完全一致。</p><p>再以 $\mathcal Y=\{1, 2\}$ 的二分类为特例，介绍这个 泛 hinge 损失。前文 <a href="/2021/09/22/ml/multiclass">多分类的基本介绍</a> 中已经给出了 $\Psi(\mathbf x, y)$ 和 $\mathbf w$ 的具体形式，这里直接引用过来，</p><script type="math/tex; mode=display">\mathbf w'=\begin{bmatrix} \mathbf w \\\\ -\mathbf w \end{bmatrix}\\ \Psi(\mathbf x, y=1)=[x_1,\cdots, x_n, 0,\cdots 0]^{\top}=\begin{bmatrix} \mathbf x \\\\ \mathbf 0 \end{bmatrix}\\ \Psi(\mathbf x, y=2)=[0,\cdots 0, x_1,\cdots, x_n]^{\top}=\begin{bmatrix} \mathbf 0 \\\\ \mathbf x \end{bmatrix}\\h(\mathbf x)=arg \max_{y \in \mathcal Y} \mathbf w'^{\top} \Psi(\mathbf x, y)</script><p>根据 $\eqref{100}$ 式，有</p><script type="math/tex; mode=display">l(\mathbf w, (\mathbf x, y))=\max_{y' \in \{1,2\}} \Delta(y', y)+\mathbf w'^{\top}(\Psi(\mathbf x, y')-\Psi(\mathbf x, y))</script><ol><li>当 $y’=y$</li></ol><p>显然有 $\Delta(y’, y)+\mathbf w’^{\top}(\Psi(\mathbf x, y’)-\Psi(\mathbf x, y))=0$</p><ol><li>当 $y’ \neq y$，那么 $\Delta(y’, y)=1$</li></ol><p>如果是 $y’=1, y=2$，那么 $\mathbf w^{\top}(\Psi(\mathbf x, y’)-\Psi(\mathbf x, y))=2\mathbf w^{\top}\mathbf x$</p><p>如果是 $y’=2, y=1$，那么 $\mathbf w^{\top}(\Psi(\mathbf x, y’)-\Psi(\mathbf x, y))=-2\mathbf w^{\top}\mathbf x$</p><p>综合以上，有 $l(\mathbf w, (\mathbf x, y))=\max \{0, 1-(-1)^{y-1}2 \mathbf w^{\top}\mathbf x\}$ 。 不难看出，这个损失函数的形式与上面的是一致的。</p><h1 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h1><p>解决多分类问题，其核心是将原来二分类中的 $\mathbf w, \ \mathbf x \in \mathbb R^n$ 映射到更高维的空间中 $\mathbf w, \ \Psi(\mathbf x, y) \in \mathbb R^{nk}$ 中去。现在我们使用 SGD 学习算法，并给损失函数增加一个正则项，</p><script type="math/tex; mode=display">L=\mathbb E_{(\mathbf x, y)\sim \mathcal D}[l(\mathbf w, (\mathbf x, y))]+ \frac {\lambda} 2 \Vert \mathbf w \Vert^2</script><p>$t$ 时刻更新的梯度向量 $\mathbf v_t \in \partial l(\mathbf w^{(t)})$，其中 $\partial l(\mathbf w^{(t)})$ 表示真实分布 $\mathcal D$ 下，泛 hinge 损失函数在 $\mathbf w^{(t)}$ 的次梯度集。从训练集中随机抽取一个样本 $(\mathbf x, y)$，计算 $\partial l(\mathbf w^{(t)},(\mathbf x, y))$，选择学习率 $\eta$，那么更新公式为</p><script type="math/tex; mode=display">\begin{aligned}\mathbf w^{(t+1)}&=\mathbf w^{(t)}-\eta(\lambda \mathbf w^{(t)}+\mathbf v_t)\\ &= \frac {t-2} t \mathbf w{(t-1)}-\eta \mathbf v_{t-1}-\eta \mathbf v_t\\ &= \cdots\\&=\frac 0 t \mathbf w^{(1)}-\eta\sum_{i=1}^t \mathbf v_i\\&=-\eta\sum_{i=1}^t \mathbf v_i\end{aligned}</script><p>其中初始化 $\mathbf w^{(t)}=\mathbf 0$ 。 具体推导过程与 <a href="/2021/09/22/ml/svm">SVM</a> 中完全一样。</p><p>由于 $\mathbf v_i$ 是泛 hinge 损失在 $\mathbf w{(i)}$ 处的次梯度，根据 $\eqref{100}$ 式，易知次梯度为 </p><script type="math/tex; mode=display">\mathbf v_i=\Psi(\mathbf x, \hat y)-\Psi(\mathbf x, y)</script><p>其中 $\hat y= \arg_{y’}  l(\mathbf w, (\mathbf x, y))$，显然当 $\hat y=y$ 时，次梯度 $\mathbf v_i=\mathbf 0$。</p><p>总结算法步骤如下</p><hr><center> 多分类问题的 SGD 算法</center><p><strong>参数：</strong></p><p>&emsp; 学习率 $\eta$，迭代次数 $T$。</p><p>&emsp; 原损失函数 $\Delta: \mathcal Y \times \mathcal Y \rightarrow \mathbb R_+$</p><p>&emsp; 映射到特征空间的函数 $\Psi: \mathcal X \times \mathcal Y \rightarrow \mathbb R^d$</p><p><strong>初始化：</strong> $\ \mathbf w^{(1)}=\mathbf 0 \in \mathbb R^d$</p><p><strong>for</strong> $t=1,2,\cdots, T$</p><p>&emsp; 随机取样 $(\mathbf x, y) \in \mathcal D$</p><p>&emsp; $\hat y=\arg \max_{y’ \in \mathcal Y} (\Delta(y’, y)+\langle \mathbf w^{(t)}, \Psi(\mathbf x, y’)-\Psi(\mathbf x, y)\rangle)$</p><p>&emsp; $\mathbf v_t=\Psi(\mathbf x, \hat y)-\Psi(\mathbf x, y)$</p><p>&emsp; $\mathbf w^{(t+1)}=\mathbf w^{(t)}-\eta \mathbf v_t$</p><p><strong>输出：</strong> $\ \overline {\mathbf w}=\frac 1 T \sum_{t=1}^T \mathbf w^{(t)}$</p><hr><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><p><strong>1. 定理1</strong></p><p>对 $i=1,\cdots, r$，令 $f_i: \mathbb R^d \rightarrow \mathbb R$ 为凸函数，那么 $g(x)=\max_{i \in [r]} f_i(x)$ 也是凸函数。</p><p>证：</p><script type="math/tex; mode=display">\begin{aligned} g(\alpha u +(1-\alpha)v) &= \max_i f_i(\alpha u + (1-\alpha)v)\\\\ & \le \max_i [\alpha f_i(u)+(1-\alpha)f_i(v)]\\\\ &=\alpha \max_i f_i(u) + (1-\alpha) \max_i f_i(v)\\\\ &=\alpha g(u) + (1-\alpha) g(v)\end{aligned}</script><p>上面推导中，$\alpha \in (0,1)$。证毕。</p><p><strong>2. $l(\mathbf w, (\mathbf x, y))$ 是 $\rho-$Lipschitz 函数。</strong></p><p>对任意 $\mathbf w_1, \mathbf w_2$，记 $y_i=\arg_{y’} \ l(\mathbf w_i, (\mathbf x, y))$，注意，这里的下标 $i$ 不对应分类下标 $1,2,\cdots , k$，是为了方便，仅对应 $\mathbf w_i$ 的下标。</p><p>对 $\mathbf w_1$ 而言，$y_1$ 是使得 $(\Delta(y’, y)+\langle \mathbf w, \Psi(\mathbf x, y’)-\Psi(\mathbf x, y)\rangle)$ 最大的值，这意味着 $(\Delta(y_1, y)+\langle \mathbf w, \Psi(\mathbf x, y_1)-\Psi(\mathbf x, y)\rangle)&gt;(\Delta(y_2, y)+\langle \mathbf w, \Psi(\mathbf x, y_2)-\Psi(\mathbf x, y)\rangle)$</p><p>如果 $l(\mathbf w_1, (\mathbf x, y)) \ge l(\mathbf w_2, (\mathbf x, y))\ge 0$，那么有</p><script type="math/tex; mode=display">\begin{aligned}\|l(\mathbf w_1, (\mathbf x, y)) - l(\mathbf w_2, (\mathbf x, y))\|&=\|(\Delta(y_1, y)+\langle \mathbf w_1, \Psi(\mathbf x, y_1)-\Psi(\mathbf x, y)\rangle)-(\Delta(y_2, y)+\langle \mathbf w_2, \Psi(\mathbf x, y_2)-\Psi(\mathbf x, y)\rangle)\|\\\\& \le \|(\Delta(y_1, y)+\langle \mathbf w_1, \Psi(\mathbf x, y_1)-\Psi(\mathbf x, y)\rangle)-(\Delta(y_1, y)+\langle \mathbf w_2, \Psi(\mathbf x, y_1)-\Psi(\mathbf x, y)\rangle)\|\\\\ & \le \|\mathbf w_1-\mathbf w_2\|\cdot \|\Psi(\mathbf x, y_1)-\Psi(\mathbf x, y)\|\end{aligned}</script><p>同理，如果 $l(\mathbf w_2, (\mathbf x, y)) \ge l(\mathbf w_1, (\mathbf x, y)) \ge 0$，那么有</p><script type="math/tex; mode=display">\begin{aligned}\|l(\mathbf w_1, (\mathbf x, y)) - l(\mathbf w_2, (\mathbf x, y))\|&=\|(\Delta(y_2, y)+\langle \mathbf w_2, \Psi(\mathbf x, y_2)-\Psi(\mathbf x, y)\rangle)-(\Delta(y_1, y)+\langle \mathbf w_1, \Psi(\mathbf x, y_1)-\Psi(\mathbf x, y)\rangle)\|\\\\& \le \|(\Delta(y_2, y)+\langle \mathbf w_2, \Psi(\mathbf x, y_2)-\Psi(\mathbf x, y)\rangle)-(\Delta(y_2, y)+\langle \mathbf w_1, \Psi(\mathbf x, y_2)-\Psi(\mathbf x, y)\rangle)\|\\\\ & \le \|\mathbf w_1-\mathbf w_2\|\cdot \|\Psi(\mathbf x, y_2)-\Psi(\mathbf x, y)\|\end{aligned}</script><p>综上，$|l(\mathbf w_1, (\mathbf x, y)) - l(\mathbf w_2, (\mathbf x, y))|\le \rho |\mathbf w_1 - \mathbf w_2|$，其中 </p><script type="math/tex; mode=display">\rho=\max_{y' \in \mathcal Y} \|\Psi(\mathbf x, y')-\Psi(\mathbf x, y)\|</script>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多分类</title>
      <link href="/2021/09/28/ml/multiclass/"/>
      <url>/2021/09/28/ml/multiclass/</url>
      
        <content type="html"><![CDATA[<p>前面讲过二分类模型，例如 SVM，本文讨论更一般的情况，即多分类问题。</p><span id="more"></span><h1 id="Reduction"><a href="#Reduction" class="headerlink" title="Reduction"></a>Reduction</h1><p>首先我们考虑一些降解思路即，将多分类问题转化为二分类。要学习的假设函数为 $h: \mathcal X \rightarrow \mathcal Y$。对于多分类，记 $\mathcal Y=\{1,\cdots,k\}$，训练集为 $S=\{(\mathbf x_1, y_1), \cdots, (\mathbf x_m, y_m)\}, \ y_i \in \mathcal Y$。</p><h2 id="One-V-S-All"><a href="#One-V-S-All" class="headerlink" title="One-V.S.-All"></a>One-V.S.-All</h2><p>其本质是 One-V.S.-Rest，也就是说，训练 k 个二分类器 $h_i: \mathcal X \rightarrow \{1,-1\}, \ \forall i \in [k]$，每个二分类器用于判别某个分类和其他所有分类。首先创建 k 个二分类训练集 $S_1, \cdots, S_k$，其中</p><script type="math/tex; mode=display">S_i=\{(\mathbf x_1, (-1)^{\mathbb I(y_1\neq i)}), \cdots, (\mathbf x_m, (-1)^{\mathbb I(y_m\neq i)})\}</script><p>上式表面，第 $j$ 个数据 $(\mathbf x_j, y_j)$，如果 $y_j=i$，那么这个数据为 $S_i$ 中的正例，否则为负例。二分类器 $h_i$ 的训练集为 $S_i$，所有二分类器训练完成后，构建多分类器如下</p><script type="math/tex; mode=display">h(\mathbf x) \in arg \max_{i \in [k]} \ h_i(\mathbf x)</script><p>理解为什么这样构建这个多分类器：对于训练集中的某样本 $(\mathbf x_j, y_j)$，记其分类 $y_j=c$，那么理想情况下，只有 $h_c(\mathbf x_j)=1$，其他 $h_i(\mathbf x_j)=-1, \ \forall i \neq c$，所以 $h_c(\mathbf x_j)$ 可取得最大值，即，样本所属的那个分类取得最大值 $-1$。</p><p>但是，对于一个新的样本点 $\mathbf x$，可能有多个 $h_i(\mathbf x)=1$，即，多个最大值，如下图所示，$k=3$，训练集位于三个圆内，那么如果新样本位于阴影区域，那么 $h_1(\mathbf x)=h_2(\mathbf x)=1$，这个时候可以采用 $h_i(\mathbf x)=\mathbf w_i^{\top} \mathbf x$，这表示（非归一化）置信度，通过置信度来做分类决策。</p><p><img src="/images/ml/multiclass_fig1.png" alt=""></p><center>图1： h1:蓝色为正例；h2:橙色为正例；h3:绿色为正例</center><h2 id="All-Pairs"><a href="#All-Pairs" class="headerlink" title="All Pairs"></a>All Pairs</h2><p>思想与上面类似，仍然是训练 k 个二分类器，不同的是训练集，对任意 $1 \le i &lt; j \le k$，创建一个二分类训练集 </p><script type="math/tex; mode=display">S_{ij}=\{(\mathbf x_l, (-1)^{I(y_l=j)}): y_l=i \lor y_l=j \}</script><p>上式说明在训练集 $S_{ij}$ 中，样本 $(\mathbf x_l, y_l)$ 的分类必须是 $i$ 或者 $j$，否则样本不在 $S_{ij}$ 中。这样的训练集一共有 $C_k^2$ 个，这是一个组合数，对应的则有 $C_k^2$ 个判别函数 $h_{ij}: \mathcal X \rightarrow \{\pm 1\}$。这样，每一个样本分类 $c$ 均有 $k-1$ 个分类器 $h_{ij}$，其中满足 $i=c$ 或者 $j=c$。</p><p><strong>构建最终多分类器的准则是：对每个分类 $c$，均执行 $k-1$ 次预测，预测正确的次数之和作为这个分类的得分，那么得分最大的分类就是最终的预测分类。</strong></p><p>注：这里的“预测正确”指的是：对 $\forall i &lt; c, \ h_{ic}(\mathbf x)=-1$，以及对 $\forall i&gt;c, \ h_{ci}(\mathbf x)=1$。</p><p>伪代码如下：</p><hr><center>All-Pairs 学习算法</center><p><strong>input:</strong> 训练集 $S=\{(\mathbf x_1, y_1), \cdots, (\mathbf x_m, y_m)\}$，二分类学习算法 $A$.</p><p><strong>for</strong> $\ i = 1, \cdots, k-1$</p><p>&emsp; <strong>for</strong> $\ j=i+1, \cdots, k$</p><p>&emsp;&emsp; <strong>for</strong> $\ t=1,\cdots, m$</p><p>&emsp;&emsp;&emsp; 如果 $y_t=i$，$S_{ij} += \{(\mathbf x_t, 1)\}$</p><p>&emsp;&emsp;&emsp; 如果 $y_t=j$，$S_{ij} += \{(\mathbf x_t, -1)\}$</p><p>&emsp;&emsp; $h_{ij}= A(S_{ij})$</p><p><strong>output:</strong></p><script type="math/tex; mode=display">h(\mathbf x) \in arg\max_{i \in [k]}\left(\sum_{j=1}^k \text{sign}(j-i) \cdot h_{ij}(\mathbf x)\right)</script><hr><p>同样的，可能出现得分相同的情况，与上面分析相同，可以使用 $h_{ij}(\mathbf x)=\mathbf w_{ij}^{\top}\mathbf x$。</p><h2 id="reduction-缺点"><a href="#reduction-缺点" class="headerlink" title="reduction 缺点"></a>reduction 缺点</h2><p>上面这两种 reduction 方法的缺点是，对于二分类器 $h_i$ 或者 $h_{ij}$，它们自己并不知道是被用来做多分类预测的，这会导致一些问题。以 One-V.S.-All 方法为例说明，如图 2 所示，<br><img src="/images/ml/multiclass_fig2.png" alt=""></p><center>图2：k=3，样本位于各自圆内</center><p>假设分类 $1,2,3$ 的样本数量比例分别为 $40\%, 20\%, 40\%$，那么在训练 $h_2$ 的时候，由于线性不可分，$h_2$ 会将所有样本判为负，于是所有分类为 $2$ 的样本均被预测错误。然而，如果选择 $\mathbf w_1=(-1/\sqrt 2, 1/\sqrt 2), \ \mathbf w_2=(0,1), \ \mathbf w_3=(1/\sqrt 2, 1/\sqrt 2)$，那么 $h(\mathbf x)=arg\max_i h_i(\mathbf x)=arg\max_i \mathbf w_i^{\top}\mathbf x$ 则会全部样本分类正确。</p><p>上面示例表示，尽管假设空间 $\mathcal H=\{\mathbf x \rightarrow  arg\max_i \mathbf w_i^{\top}\mathbf x: \mathbf w \in \mathbb R^d\}$ 的 approximation error 为 0，但是 One-V.S.-All 学习方法却无法从中找到最好的分类器。</p><blockquote><p>approximation error: 假设空间中某判别函数在真实分布上的最小损失。</p></blockquote><p>鉴于 reduction 方法存在不足之处，研究适用于多分类预测的更直接的方法。</p><h1 id="线性多分类预测器"><a href="#线性多分类预测器" class="headerlink" title="线性多分类预测器"></a>线性多分类预测器</h1><script type="math/tex; mode=display">h(\mathbf x)=arg\max_{i \in [k]} W^{\top} \mathbf x</script><p>其中，参数矩阵 $W \in \mathbb R^{d \times k}$，向量 $\mathbf x \in \mathbb R^n$，$W^{\top} \mathbf x$ 是一个向量，其中每个元素表示对应分类的得分，这个向量中最大值的下标就是预测分类。但是这里 $W$ 是一个矩阵，参数矩阵可写为 $W=[\mathbf w_1, \cdots, \mathbf w_k]$，相当于每个分类有一个独立的参数向量，而线性分类中常用的是参数向量 $\mathbf x$，所以把它改写为向量形式，</p><script type="math/tex; mode=display">h(\mathbf x)=arg \max_{y \in \mathcal Y} \mathbf w^{\top} \Psi(\mathbf x, y) \tag{1}\label{1}</script><p>其中，$\Psi(\mathbf x, y)$ 将样本 $(\mathbf x, y)$ 映射为相应的特征，且有</p><script type="math/tex; mode=display">\Psi(\mathbf x, y)=[\underbrace {0,\cdots, 0}_{(y-1)n}, \underbrace {x_1,\cdots, x_n}_{n}, \underbrace { 0,\cdots 0}_{(k-y)n}]^{\top}</script><p>上式中，$x_1$ 前面有 $(y-1)n$ 个 0，$x_n$ 后面有 $(k-y)n$ 个 0。$\Psi(\mathbf x, y), \mathbf w \in \mathbb R^{nk}$。$\mathbf w$ 可以写成 </p><script type="math/tex; mode=display">\mathbf w=\begin{bmatrix} \mathbf w_1 \\\\ \vdots \\\\ \mathbf w_k \end{bmatrix}</script><p>此时，预测函数变成</p><script type="math/tex; mode=display">h(\mathbf x)=arg \max_{y \in \mathcal Y} \mathbf w_y^{\top} \mathbf x \tag{2}\label{2}</script><p>于是，上面两种 $h(\mathbf x)$ 的形式是等价的，称后一种为一般形式。</p><p>二分类中只有一个分类无关的参数向量 $\mathbf w$，事实上，二分类也可以有两个权值向量 $\mathbf w_1, \mathbf w_2$，只不过我们令 $\mathbf w_2=-\mathbf x_1$，从而简化成一个参数向量，如果写成上面的两种形式，则分别为：</p><ol><li><p>矩阵形式</p><script type="math/tex; mode=display">h(\mathbf x)=arg \max_{i\in \{1, 2\}} \begin{bmatrix} \mathbf w_1, & -\mathbf w_1 \end{bmatrix}^{\top} \mathbf x</script></li><li><p>向量形式</p></li></ol><script type="math/tex; mode=display">\mathbf w=\begin{bmatrix} \mathbf w_1 \\\\ -\mathbf w_1 \end{bmatrix}</script><script type="math/tex; mode=display">\Psi(\mathbf x, y=1)=[x_1,\cdots, x_n, 0,\cdots 0]^{\top}</script><script type="math/tex; mode=display">\Psi(\mathbf x, y=2)=[0,\cdots 0, x_1,\cdots, x_n]^{\top}</script><script type="math/tex; mode=display">h(\mathbf x)=arg \max_{y \in \mathcal Y} \mathbf w^{\top} \Psi(\mathbf x, y)</script><p>前面文章讨论的二分类器函数为 $h(\mathbf x)=\text{sign}(\mathbf w_1^{\top} \mathbf x)$，它们都是一致的，例如当 $\mathbf w_1^{\top} \mathbf x&gt;0$ 时，$\text{sign}(\mathbf w_1^{\top} \mathbf x)=1$，而矩阵形式中 $\begin{bmatrix} \mathbf w_1 , &amp; -\mathbf w_1 \end{bmatrix}^{\top} \mathbf x=[y_1, \ -y_1]^{\top}$，显然 $y_1&gt;-y_1$，故判断结果为分类 $1$。</p><p>另一方面，二分类的一般形式中， $\mathbf w$ 的通常可写为</p><script type="math/tex; mode=display">\mathbf w=\begin{bmatrix} \mathbf w_1 \\\\ \mathbf w_2 \end{bmatrix}</script><p>而且不一定需要有 $\mathbf w_2=-\mathbf w_1$ 成立，下一篇文章讨论多分类的学习算法之后，就能理解了。</p><h2 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子"></a>一个例子</h2><p>这个例子如下图所示，$\mathcal X = \mathbb R^2, \ \mathcal Y =\{1,2,3,4\}, \ k=4$，<br><img src="/images/ml/multiclass_fig3.png" alt=""></p><p>样本分布在一个圆内，每个类别用不同的颜色标注，每个类别的样本均匀分布在某个扇形区域内，那么有</p><script type="math/tex; mode=display">\mathbf w=\begin{bmatrix} \mathbf w_1 \\\\ \vdots \\\\ \mathbf w_4 \end{bmatrix}</script><p>且有 $\forall i \in [4], \ \mathbf w_i \in \mathbb R^2$。</p><p>根据前面的分析，并利用式 $\eqref{2}$，对于任意某分类 $i \in [k]$，需要这个分类中的所有样本 $\mathbf x$ 与对应的参数分量 $\mathbf w_i$ 的内积最大，等价于求</p><script type="math/tex; mode=display">\max_{\mathbf w_i} \sum_{j \in [m]:\ y_j = i} \mathbf w_i^{\top} \mathbf x_j \tag{3} \label{3}</script><p>我们知道，$(\alpha \mathbf w^{\top})\mathbf x=\alpha (\mathbf w^{\top} \mathbf x)$，当 $\alpha$ 任意大时，表达式的值是没有上边界的，所以不妨增加限制 $|\mathbf w|=1$，否则求最大值没有意义。</p><p>我们先固定 $|\mathbf x|$ 为某个值，然后求得 $\eqref{3}$ 式的最优解，记为 $\mathbf w_i^{\star}$，那么当改变 $|\mathbf x|$ 为另一个固定值值时，由于样本均匀分布在扇形内，$\eqref{3}$ 式的最优解仍是 $\mathbf w_i^{\star}$，故我们只需要考虑  $|\mathbf x|$ 为某个固定值的情况，不妨令  $|\mathbf x|=1$。</p><p>记分类 $i$ 的样本 $\mathbf x$ 与 x 轴正向的夹角为 $\theta$，扇形的起始边与终止边与 x 轴正向的夹角分别为 $\theta_1, \ \theta_2$，参数向量 $\mathbf w_i$ 与 x 轴正向夹角为 $\theta_0$，则有</p><script type="math/tex; mode=display">\mathbf w_i=(\cos \theta_0, \sin \theta_0), \quad \mathbf x=(\cos \theta, \sin \theta)</script><p>目标函数转化为如下优化问题</p><script type="math/tex; mode=display">\begin{aligned}\max_{\theta_0}& \int_{\theta_1}^{\theta_2} \cos \theta_0 \cos \theta+\sin \theta_0 \sin \theta d\theta\\\\ &=\cos \theta_0 \sin \theta - \sin \theta_0 \cos \theta |_{\theta_1}^{\theta_2}\\\\&=-(\cos \theta_2-\cos \theta_1) \sin \theta_0+(\sin \theta_2-\sin \theta_1)\cos \theta_0\\\\ &=\sqrt{a^2+b^2} \sin(\theta_0+\phi)\end{aligned}</script><p>上式最后一个等式使用了三角函数的辅助角公式，其中 </p><script type="math/tex; mode=display">a=-(\cos \theta_2-\cos \theta_1), \quad b = \sin \theta_2-\sin \theta_1</script><script type="math/tex; mode=display">\sin \phi=\frac b {\sqrt{a^2+b^2}}, \quad \cos \phi = \frac a {\sqrt{a^2+b^2}}</script><p>根据上面推导，易知最大值满足 $\theta_0+\phi=\pi / 2 + 2k\pi, \ k \in \mathbb Z$，即</p><script type="math/tex; mode=display">\theta_0=\pi/2- \phi+2k \pi, \ k \in Z \tag{4}\label{4}</script><p>下一步求 $\phi$  。</p><script type="math/tex; mode=display">\begin{aligned}\sin \phi&=\frac {\sin \theta_2-\sin \theta_1}{[(\cos \theta_2-\cos \theta_1)^2+(\sin \theta_2-\sin \theta_1)^2]^{1/2}}\\\\ &=\frac {2 \cos \alpha \sin \beta} {[2-2(\cos \theta_2\cos \theta_1+\sin \theta_2 \sin \theta_1)]^{1/2}}\\\\ &=\frac {2 \cos \alpha \sin \beta} {[2-2\cos(\theta_2-\theta_!)]^{1/2}}\\\\ &=\frac {2 \cos \alpha \sin \beta} {(4 \sin^2 \beta)^{1/2}}\\\\ &= \frac {\cos \alpha \sin \beta} {(\sin^2 \beta)^{1/2}}\end{aligned}</script><p>其中 $\alpha=(\theta_2+\theta_1)/2, \ \beta=(\theta_2-\theta_1)/2$，上式推导中，第二个等号用了“和差化积”公式，第三个等号用了“两角和差”公式，第四个等号用了“二倍角”公式。同理可得</p><script type="math/tex; mode=display">\cos \phi=\frac {\sin \alpha \sin \beta} {(\sin^2 \beta)^{1/2}}</script><p>回顾一下本例示意图，不难理解有 $\theta_2-\theta_1 &lt; 2\pi$，于是 $\beta &lt; \pi \Rightarrow \sin \beta &gt; 0$，<br>此时上述两个等式变成 $\sin \phi = \cos \alpha, \ \cos \phi=\sin \alpha$ 。<br>我们现在需要将 $\cos \alpha$ 变成 $\sin (\pm \alpha+\gamma)$ 的形式，并且将 $\sin \alpha$ 变成 $\cos (\pm \alpha+\gamma)$，这样就容易得到 $\phi=\pm \alpha+\gamma$，其中 $\gamma$ 是某个待定角，且 $\alpha$ 前面是 $+$ 还是 $-$ 还是 $+,-$ 均可，这一点也需要确定。根据三角函数的诱导公式，列出如下关系：</p><script type="math/tex; mode=display">\begin{array}{c|c} & \pi/ 2 + \alpha &&  \pi/ 2 - \alpha && 3\pi/ 2 + \alpha && 3\pi/ 2 - \alpha \\\\\hline \alpha \in (0, \pi/2) \quad \sin(\cdot)  & + && + && - && -\\\\\hline=&\cos \alpha && \cos \alpha && - \cos \alpha && - \cos \alpha\\\\\hline\\\\\hline\alpha \in (0, \pi/2) \quad \cos(\cdot)  & - && + && + && -\\\\\hline=&-\sin \alpha && \sin \alpha &&  \sin \alpha && - \sin \alpha\end{array}</script><p>（表中，第一项列举了几个范式，第二行表示当 $\alpha \in (0,\pi)$ 时，$\sin(\cdot)$ 的符号，其中 $\cdot$ 表示第一行各范式。第三行表示 $\sin(\cdot)$ 等价关系，这里的等价关系对 $\forall \alpha \in \mathbb R$ 均成立。注意范式中忽略了周期项 $2m\pi$）</p><p>根据上表，只有当 $\phi=\pi/2-\alpha$ 时，满足 $\sin \phi=\cos \alpha, \ \cos \phi=\sin \alpha$。故结合 $\eqref{4}$ 式有</p><script type="math/tex; mode=display">\phi=\pi/2-\alpha+2m \pi, \ m \in \mathbb Z</script><script type="math/tex; mode=display">\theta_0=\alpha+2k \pi=(\theta_2+\theta_1)/2+2k \pi, \ k \in \mathbb Z</script><p>由于周期为 $2\pi$，所以不需要考虑周期项，得 $\theta_0=(\theta_2+\theta_1)/2$，这正如图中所示的 $\mathbf w_i$ 的方向，也就是位于扇形的中间方向。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习中的核方法</title>
      <link href="/2021/09/26/ml/kernel/"/>
      <url>/2021/09/26/ml/kernel/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为了更好的使用线性分类，有时候需要将线性不可分的数据映射到一个更高维空间，使其线性可分。虽然高维空间的 Halfspace 假设更加具有表达能力（假设空间更加丰富），但是同时也会引入样本复杂度以及计算复杂度的上升。通过引入 margin （训练集中某样本与超平面具有最小距离），可以解决样本复杂度这个问题，而计算复杂度则可以通过另一种方法解决，即本篇所介绍的 “核方法”。<br><span id="more"></span></p><h1 id="特征空间"><a href="#特征空间" class="headerlink" title="特征空间"></a>特征空间</h1><p>以一个简单的例子开始，考虑域中样本点 $\{-10,-9,-8,\cdots, 0, 1, \cdots 9, 10\}$，其中满足 $|x|&gt;2$ 的样本分类为 $+1$，其余样本分类为 $-1$，显然这是一个非线性可分的问题，但是我们可以通过以下映射 $\psi: \mathbb R \rightarrow \mathbb R^2$</p><script type="math/tex; mode=display">\psi(x)=(x, x^2)</script><p>使得数据在 $\mathbb R^2$ 空间中线性可分，令 $\mathbf w=(0, 1), \ b=5$，那么 $h(x)=\text{sign}(\mathbf w^{\top} \psi(x) - b)$ 线性可分。</p><p><strong>这一过程总结如下：</strong></p><ol><li><p>给定域集合 $\mathcal X$ 和一特定的学习任务，根据先验知识，选择一个映射函数 $\psi: \mathcal X \rightarrow \mathcal F$。</p></li><li><p>给定样本集 $S=\{(\mathbf x_1, y_1), \cdots, (\mathbf x_m, y_m)\}$，计算得到映射后的集合 $\hat S=\{(\psi(\mathbf x_1), y_1), \cdots ,(\psi(\mathbf x_m), y_m)\}$</p></li><li><p>在 $\hat S$ 上训练一个线性分类器</p></li><li><p>预测一个新的样本 $\mathbf x$ 为 $h(\psi(\mathbf x))$</p></li></ol><p><strong>多项式映射是一个常用的较好的 $\psi$</strong></p><p>考虑一维情况，为 $p=\sum_{i=0}^k w_i x^i$，那么 $\psi(x)=(x^0, x^1, \cdots, x^k)$。考虑一般情况下的多变量 $\mathbf x$，多项式 $p(\mathbf x): \mathbb R^n \rightarrow \mathbb R$ 可写为</p><script type="math/tex; mode=display">p(\mathbf x)=\sum_{J \in [n]^r: \ r\le k} w_J \prod_{i=1}^r x_{J_i}</script><p>未知向量 $\mathbf x$ 是 $n$ 维，$J$ 是具有 $r$ 个元素的列表，每个元素表示 $\mathbf x$ 的下标。当固定一个 $r$ 时，然后每次从 $\mathbf x=[x_1, \cdots, x_n]$ 中可重复（或称 可放回）地选择 $r$ 个变量，这 $r$ 个变量相乘为 $\prod_{i=1}^r x_{J_i}$，最后每个乘积项加权求和。具体过程如下：</p><ol><li><p>阶数为 0， $r=0$，表示不选择任何变量，此时乘积项 为 1，共 $1$ 个乘积项。</p></li><li><p>阶数为 1，$r=1$，从 $[x_1, x_2, \cdots, x_n]$ 中选择一个变量即 $x_{J_1}$，共 $n$ 个乘积项。</p></li><li><p>阶数为 2，$r=2$，从 $[x_1, x_2, \cdots, x_n]$ 中可放回地选择两个变量即 $x_{J_1}, \ x_{J_2}$，乘积项 $x_{J_1} x_{J_2}$ 共有 $n^2$ 个。</p></li><li><p>阶数为 k，$r=k$，从 $[x_1, x_2, \cdots, x_n]$ 中可放回地选择 k 个变量即 $x_{J_1}, \cdots, x_{J_k}$，乘积项 $\prod_{i=1}^k x_{J_i}$ 共 $n^k$ 个。</p></li></ol><p>各阶数的乘积项数量形成一个等比数量，根据求和公式，所有乘积项数量为</p><script type="math/tex; mode=display">S_{k+1}=\frac {a_1(1-n^{k+1})}{1-n}=\frac {n^{k+1}-1} {n-1}</script><p>特别的，当公比 $n=1$ 时，求和为 $S_{k+1}=a_1 \times (k+1)=k+1$。</p><p>于是，多变量的多项式映射 $\psi(\mathbf x): \mathbb R^n \rightarrow \mathbb R^d$，当考虑多项式为 k 阶时，特征空间的维数 $d=S_{k+1}$。$\psi(\mathbf x)$ 中每一项就是上们的乘积项 $\prod_{i=1}^r x_{J_i}$。</p><p>从上面分析来看，特征空间的维度 $d=S_{k+1}$ 很大，导致计算复杂度增加，所以不使用常规的线性分类学习方法（如 SVM），下文介绍的 核方法 就是为了解决计算复杂度增加这个问题。</p><h1 id="核方法"><a href="#核方法" class="headerlink" title="核方法"></a>核方法</h1><p>给定映射函数 $\psi$ 将域空间 $\mathcal X$ 映射到某个 Hilbert 空间，定义核函数为映射后向量的内积</p><script type="math/tex; mode=display">K(\mathbf x, \mathbf x')=\psi^{\top}(\mathbf x) \psi(\mathbf x')</script><p>可以认为核函数 $K$ 用于指定两个映射向量之间的相似度（未归一化）。</p><p>我们将线性分类问题转化为如下的更一般的优化问题</p><script type="math/tex; mode=display">\min_{\mathbf w} f(\mathbf w^{\top} \psi(\mathbf x_1), \cdots, \mathbf w^{\top} \psi(\mathbf x_m)) + R(\|\mathbf w\|) \tag{1} \label{1}</script><p>其中 $f:\mathbb R^m \rightarrow \mathbb R$ 是任意函数，$R: \mathbb R_+ \rightarrow \mathbb R$ 是单调递增函数，作为正则惩罚项。</p><p>例如 Soft-SVM 中（非齐次型可转换为齐次型），$R(a)=\lambda a^2$，$f(a_1, \cdots, a_m)=\frac 1 m \sum_{i} \max \{0, 1- y_ia_i\}, \ a_i=\mathbf w^{\top}\mathbf x_i$。</p><p>Hard-SVM 中，$R(a)=a^2$，且如果 $\forall i \in [m]$ 均有 $y_i(a_i+b)\ge 1$，那么 $f(a_1, \cdots, a_m)=0$，否则 $f(a_1, \cdots, a_m)=\infty$，这是因为 Hard-SVM 保证是线性可分的，所以只要有一个样本分类错误，那么总的分类错误损失就是 $\infty$。</p><p><strong>存在一个向量 $\boldsymbol \alpha \in \mathbb R^m$，使得 $\mathbf w=\boldsymbol \alpha^{\top} \boldsymbol \psi$ 是 (1) 式的最优解。</strong></p><p>其中 $\boldsymbol \psi = [\psi(\mathbf x_1), \cdots, \psi(\mathbf x_m)]$。事实上，在上一篇文章 <a href="/2021/09/22/ml/svm">SVM</a> 中，我们已经讨论到，$\mathbf w$ 是训练集中若干支持向量的线性组合，自然也是训练集中所有向量的线性组合。</p><p>证：</p><p>令 $\mathbf w^{\ast}$ 是 $\eqref{1}$ 式的最优解。由于 $\mathbf w^{\ast}$ 位于 Hilbert 空间，必然可以分解为两个向量，其中一个来自 $[\psi(\mathbf x_1), \cdots, \psi(\mathbf x_m)]$ 所张（span）空间的一个向量 $\mathbf w$，另一个向量 $\mathbf u$ 位于与这个所张空间垂直的空间，故可写为</p><script type="math/tex; mode=display">\mathbf w^{\ast}=\mathbf w + \mathbf u=\sum_{i=1}^m \alpha_i \psi(\mathbf x_i)+\mathbf u</script><p>其中 $\mathbf u^{\top} \psi(\mathbf x_i)=0, \ \forall i \in [m]$。</p><p>于是有 $|\mathbf w^{\ast}|^2=|\mathbf w|^2+|\mathbf u|^2+2\mathbf w^{\top} \mathbf u$，由于 $\mathbf w$ 所在空间与 $\mathbf u$ 所在空间垂直，故 $\mathbf w^{\top}\mathbf u=0$，故 $|\mathbf w^{\ast}|^2=|\mathbf w|^2+|\mathbf u|^2 \ge |\mathbf w|^2$，由于 $R$ 是单调增函数，所以 $R(|\mathbf w^{\ast}|) \ge R(|\mathbf w|)$。</p><p>另外注意到</p><script type="math/tex; mode=display">\mathbf w^{\top} \psi(\mathbf x_i)=(\mathbf w^{\ast}-\mathbf u)^{\top} \psi(\mathbf x_i)=\mathbf w^{\ast}\psi(\mathbf x_i)</script><p>所以</p><script type="math/tex; mode=display">f(\mathbf w^{\top} \psi(\mathbf x_1), \cdots, \mathbf w^{\top} \psi(\mathbf x_m))=f(\mathbf w^{\ast \top} \psi(\mathbf x_1), \cdots, \mathbf w^{\ast \top} \psi(\mathbf x_m))</script><p>记 $\eqref{1}$ 式中的优化目标为 $L(\cdot)$，所以 $L(\mathbf w^{\ast}) \ge L(\mathbf w)$ ，由于 $\mathbf w^{\ast}$ 是最优解，那么 $\mathbf w$ 也是最优解。证毕。</p><p>于是 $\eqref{1}$ 式的最优解具有形式 $\mathbf w =\sum_{i=1}^m \alpha_i \psi(\mathbf x_i)$。由于</p><script type="math/tex; mode=display">\mathbf w^{\top}\psi(\mathbf x_i)=\left(\sum_{j=1}^m \alpha_j \psi(\mathbf x_j)\right)^{\top} \psi(\mathbf x_i)=\sum_{j=1}^m \alpha_j \psi^{\top}(\mathbf x_j)\psi(\mathbf x_i) \tag{2}</script><script type="math/tex; mode=display">\|\mathbf w\|^2=\Vert \sum_{i=1}^m \alpha_i \psi(\mathbf x_i) \Vert^2=\sum_{i=1}^m \sum_{j=1}^m\alpha_i \alpha_j \psi^{\top}(\mathbf x_i)\psi(\mathbf x_j) \tag{3}</script><p>所以 $\eqref{1}$ 式可改写为</p><script type="math/tex; mode=display">\min_{\boldsymbol \alpha \in \mathbb R^m} f\left(\sum_{j=1}^m \alpha_j K(\mathbf x_j, \mathbf x_1), \cdots, \sum_{j=1}^m \alpha_j K(\mathbf x_j, \mathbf x_m)\right) + R \left(\sqrt{\sum_{i=1}^m \sum_{j=1}^m\alpha_i \alpha_j K(\mathbf x_i,\mathbf x_j)}\right) \tag{4}</script><p>将变量从 $\mathbf w \in \mathbb R^d$ 转换为 $\boldsymbol \alpha \in \mathbb R^m$，当 $m &lt;&lt; d$ 时，可以降低计算复杂度。</p><p>记 $G_{m \times m}$，其中 $G_{ij}=K(\mathbf x_i,\mathbf x_j)$，表示样本之间的内积矩阵，通常称为 Gram 矩阵。那么，(2,3) 式变为</p><script type="math/tex; mode=display">\mathbf w^{\top}\psi(\mathbf x_i)=\sum_{j=1}^m \alpha_j K(\mathbf x_i, \mathbf x_j)=G_{i,:} \cdot \boldsymbol \alpha=(G \boldsymbol \alpha)_i</script><script type="math/tex; mode=display">\|\mathbf w\|^2=\sum_{i=1}^m \sum_{j=1}^m\alpha_i \alpha_j K(\mathbf x_i, \mathbf x_j)=\boldsymbol \alpha^{\top} G \boldsymbol \alpha</script><p>以 Soft-SVM 为例，根据 $\min_{\mathbf w} (\lambda |\mathbf w|^2+\frac 1 m \sum_{i=1}^m \max\{0, 1-y_i(\mathbf w^{\top} \mathbf x_i)\})$， 写成（4）式的形式为</p><script type="math/tex; mode=display">\min_{\boldsymbol \alpha \in \mathbb R^m} \ \frac 1 m \sum_{i=1}^m \max\{0, 1-y_i(G \boldsymbol \alpha)_i\} + \lambda \boldsymbol \alpha^{\top} G \boldsymbol \alpha</script><p>学习到了 $\boldsymbol \alpha$ 之后，那么对新样本的预测为</p><script type="math/tex; mode=display">\mathbf w^{\top}\psi(\mathbf x)=\sum_{j=1}^m \alpha_j K(\mathbf x, \mathbf x_j)</script><p>注意，$K(\mathbf x, \mathbf x_j)$ 不是 G 矩阵元素。</p><h1 id="带核-Soft-SVM-的实现"><a href="#带核-Soft-SVM-的实现" class="headerlink" title="带核 Soft-SVM 的实现"></a>带核 Soft-SVM 的实现</h1><p>上一篇 <a href="/2021/09/22/ml/svm">SVM</a> 中介绍了 Soft-SVM 的 SGD 学习过程。现在考虑带核 Soft-SVM 的学习。首先给出优化目标</p><script type="math/tex; mode=display">\min_{\mathbf w} \left(\frac {\lambda} 2 \|\mathbf w\|^2+\frac 1 m \sum_{i=1}^m \max \{0, 1-y_i \mathbf w^{\top} \psi(\mathbf x_i)\}\right) \tag{5} \label{5}</script><p>仿照  <a href="/2021/09/22/ml/svm">SVM</a> 中 Soft-SVM 的 SGD 实现中的分析，彼时令 </p><script type="math/tex; mode=display">\boldsymbol {\theta}^{(t+1)}=\boldsymbol {\theta}^{(t)}-\mathbf v_t=\boldsymbol {\theta}^{(t)}+y_i \mathbf x_i</script><p>那么带核后，变为</p><script type="math/tex; mode=display">\boldsymbol \theta^{(t+1)}=\boldsymbol \theta^{(t)} +y_i\psi(\mathbf x_i)</script><p>且有</p><script type="math/tex; mode=display">\mathbf w^{(t)}=\frac 1 {\lambda t} \boldsymbol \theta^{(t)}</script><p>由于 $\mathbf w, \boldsymbol \theta \in \mathbb R^d$，维数 $d$ 较大，所以我们不直接更新 $\boldsymbol \theta$。由于最优解可写成 $\mathbf w = \sum_{i=1}^m \alpha_i \psi(\mathbf x_i)$ 的形式，所以我们考虑直接求解 $\boldsymbol \alpha$，或者说，是以 $\psi(\mathbf x_1), \cdots, \psi(\mathbf x_m)$ 作为基向量时的坐标，对应地，$\mathbf w$ 是对应标准基向量的坐标，维度 $dim(\boldsymbol \alpha)=m &gt; dim(\mathbf w)=d$。我们还需要给出 $\boldsymbol \theta$ 在以$\psi(\mathbf x_1), \cdots, \psi(\mathbf x_m)$ 作为基向量时的坐标，记为 $\boldsymbol \beta$，有</p><script type="math/tex; mode=display">\boldsymbol \theta^{(t)}=\sum_{j=1}^m \beta_j^{(t)} \psi(\mathbf x_j)</script><p>显然有以下关系</p><script type="math/tex; mode=display">\boldsymbol \alpha = \frac 1 {\lambda t} \boldsymbol \beta</script><p>于是，<a href="/2021/09/22/ml/svm">SVM</a> 中 Soft-SVM 的 SGD 实现中，迭代更新（基于标准基向量的） $\boldsymbol \theta$，等价的，这里带核情况的实现中，则是迭代更新（基于 $\psi(\mathbf x_1), \cdots, \psi(\mathbf x_m)$ 的）$\boldsymbol \beta$。</p><p>根据前面 $\boldsymbol {\theta}$ 的更新公式，</p><script type="math/tex; mode=display">\boldsymbol \theta^{(t+1)}=\boldsymbol \theta^{(t)} +y_i\psi(\mathbf x_i)=\sum_{j=1}^m \beta_j^{(t)} \psi(\mathbf x_j)+y_i \psi(\mathbf x_i)=\sum_{j=1}^m \beta_j^{(t+1)} \psi(\mathbf x_j)</script><p>可知 $\boldsymbol \beta$ 的更新为（在随机选择一个样本下标 $i$ 后）</p><script type="math/tex; mode=display">\boldsymbol \beta_{j}^{(t+1)}= \begin{cases} \boldsymbol \beta_{j}^{(t)} & j \neq i \\\\ \boldsymbol \beta_{i}^{(t)}+y_i & j=i \end{cases}</script><p>最后，随机选择了样本下标 $i$ 后，判断条件变为</p><script type="math/tex; mode=display">y_i \mathbf w^{\top} \psi(\mathbf x_i)=y_i \left(\sum_{j=1}^m \alpha_j^{(t)} \psi(\mathbf x_j)\right)^{\top} \psi(\mathbf x_i)=y_i\sum_{j=1}^m \alpha_j^{(t)} K(\mathbf x_j, \mathbf x_i)</script><p>最后，整个过程与 <a href="/2021/09/22/ml/svm">SVM</a> 中 Soft-SVM 的 SGD 实现基本类似，现总结如下：</p><hr><center>带核 Soft-SVM 的 SGD 实现</center><p><strong>目标：</strong> 求解 $\eqref{5}$ 式</p><p><strong>参数：</strong> 总迭代次数 $T$</p><p><strong>初始化：</strong> $\boldsymbol \beta^{(1)}=\mathbf 0$</p><p><strong>for</strong> $\ t=1,\cdots, T$</p><p>&emsp; $\boldsymbol \alpha^{(t)}=\frac 1 {\lambda t} \boldsymbol \beta^{(t)}$</p><p>&emsp; 随机选择一个下标 $i \in [m]$</p><p>&emsp; 对 $\forall j \in [m]$ 且 $j\neq i$， $\beta_j^{(t+1)}=\beta_j^{(t)}$</p><p>&emsp; 如果 $\ y_i\sum_{j=1}^m \alpha_j^{(t)} K(\mathbf x_j, \mathbf x_i) &lt; 1$</p><p>&emsp; &emsp; $\beta_i^{(t+1)}=\beta_i^{(t)}+y_i$</p><p>&emsp; 否则</p><p>&emsp; &emsp; $\beta_i^{(t+1)}=\beta_i^{(t)}$</p><p><strong>输出</strong> $\overline {\boldsymbol \alpha}=\frac 1 T \sum_{t=1}^T \boldsymbol \alpha^{(t)}$</p><hr><p>最后从 $\boldsymbol \alpha$ 变回 $\mathbf w$，</p><script type="math/tex; mode=display">\overline {\mathbf w}=\sum_{i=1}^m \overline {\boldsymbol \alpha}\psi(\mathbf x_i)</script><p>将 $\overline {\boldsymbol \alpha}$ 的表达式代入上式，验证如下</p><script type="math/tex; mode=display">\overline {\mathbf w}=\sum_{i=1}^m \left(\frac 1 T \sum_{t=1}^T \boldsymbol \alpha^{(t)}\right)\psi(\mathbf x_i)=\frac 1 T \sum_{t=1}^T\left(\sum_{i=1}^m \boldsymbol \alpha^{(t)}\psi(\mathbf x_i)\right)=\frac 1 T \sum_{t=1}^T \mathbf w^{(t)}</script><p>可见于普通的 Soft-SVM 完全一致。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>支持向量机</title>
      <link href="/2021/09/22/ml/svm/"/>
      <url>/2021/09/22/ml/svm/</url>
      
        <content type="html"><![CDATA[<p>支持向量机搜索具有最大“边距”的分类器，最大“边距”使得分类器更加健壮。</p><span id="more"></span><h1 id="边距和-Hard-SVM"><a href="#边距和-Hard-SVM" class="headerlink" title="边距和 Hard-SVM"></a>边距和 Hard-SVM</h1><p>训练集记为 $S=(\mathbf x_1,y_1), \cdots, (\mathbf x_m, y_m)$，其中 $\mathbf x \in \mathbb R^d, \ y \in \{1,-1\}$。假设这个训练集线性可分，那么有</p><script type="math/tex; mode=display">\forall i \in [m], \quad y_i (\mathbf w^{\top} \mathbf x_i+b )>0</script><p>满足上式的所有 halfspace $(\mathbf w , b)$，有多解， 均属于 ERM 假设（$L_S(h)=0$），我们根据“边距”最大这一条件来选择最好的 $(\mathbf w, b)$。</p><blockquote><p>判别超平面与数据集之间的“边距”定义为：超平面与数据集中某样本点之间的最小距离。</p></blockquote><p>如果这个“最小距离”较大，那么即使对样本点有进行小的扰动，也不影响判别效果。</p><h2 id="距离"><a href="#距离" class="headerlink" title="距离"></a>距离</h2><p><strong>样本点 $\mathbf x$ 与超平面 $(\mathbf w, b)$ （其中 $|\mathbf w|=1$）之间的距离为 $|\mathbf w^{\top}\mathbf x+b|$。</strong></p><p>这里给了 $\Vert \mathbf w \Vert=1$ 这个约束，如果没有这个约束，那么同一个超平面会有无穷多个表达，即 $a\mathbf w \mathbf x+ab=1, \ \forall a \neq 0$。给定 $\mathbf w$ 约束条件后，$b$ 可以唯一确定，故不需要对其作约束。</p><p><strong>证：</strong></p><p>这个距离定义为</p><script type="math/tex; mode=display">\min\{\Vert\mathbf {x-v}\Vert: \mathbf w^{\top}\mathbf v+b=0\}</script><p>取 $\mathbf v=\mathbf x-(\mathbf w^{\top} \mathbf x+b)\mathbf w$，验证这个值在超平面上，因为</p><script type="math/tex; mode=display">\mathbf w^{\top} \mathbf v+b=\mathbf w^{\top}\mathbf x-(\mathbf w^{\top} \mathbf x+b)\|\mathbf w\|^2+b=0</script><p>验证完毕。</p><p>此时 $\mathbf x, \ \mathbf v$ 之间的距离为</p><script type="math/tex; mode=display">\|\mathbf x-\mathbf v\|=|\mathbf w^{\top} \mathbf x+b|\|\mathbf w\|=|\mathbf w^{\top} \mathbf x+b|</script><p>另一方面，任取超平面上一点 $\mathbf u$，有</p><script type="math/tex; mode=display">\begin{aligned} \Vert \mathbf {x-u}\Vert^2 &=\|\mathbf {x-v+v-u}\|^2\\ &=\|\mathbf {x-v}\|^2+\|\mathbf {v-u}\|^2+2(\mathbf {x-v})^{\top}(\mathbf {v-u})\\ &\ge\|\mathbf {x-v}\|^2+2(\mathbf {x-v})^{\top}(\mathbf {v-u})\\ &=\|\mathbf {x-v}\|^2+2(\mathbf w^{\top} \mathbf x+b)\mathbf w^{\top}(\mathbf {v-u})\\ &=\|\mathbf {x-v}\|^2\end{aligned}</script><p>上式倒数第二个等式用了 $\mathbf v$ 的定义，倒数第一个等式是因为 $\mathbf w^{\top}\mathbf v=\mathbf w^{\top}\mathbf u=-b$。</p><p>从上式可见，$\mathbf x$ 与超平面的距离应该为 $|\mathbf {x-v}|^2$，也就是 $|\mathbf w^{\top} \mathbf x+b|$。</p><h2 id="Hard-SVM"><a href="#Hard-SVM" class="headerlink" title="Hard-SVM"></a>Hard-SVM</h2><p>Hard-SVM 的学习准则是令超平面与数据集的“边距”最大，即，求解以下最优问题的解，</p><script type="math/tex; mode=display">\arg \max_{(\mathbf w, b): \|\mathbf w\|=1} \ \min_{i \in [m]} |\mathbf w^{\top} \mathbf x_i+b| \quad s.t. \ \forall i \in [m], \ y_i(\mathbf w^{\top} \mathbf x_i+b)>0</script><p>在训练集线性可分这一前提条件下，上式等价于</p><script type="math/tex; mode=display">\arg \max_{(\mathbf w, b): \|\mathbf w\|=1} \ \min_{i \in [m]} y_i(\mathbf w^{\top} \mathbf x_i+b) \tag{1} \label{1}</script><h3 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h3><p>对满足 $|\mathbf w|=1$ 的任意 $(\mathbf w, b)$, 记 $\gamma=\min_{i \in [m]} \ y_i(\mathbf w^{\top}\mathbf x_i+b)$，于是 $\forall i \in [m]$ 有</p><script type="math/tex; mode=display">y_i (\mathbf w^{\top}\mathbf x_i+b) \ge \gamma</script><p>根据数据集线性可分这一假设，有 $\gamma&gt;0$，于是变换上式为</p><script type="math/tex; mode=display">y_i (\frac {\mathbf w^{\top}} {\gamma}\mathbf x_i+\frac {b}{\gamma}) \ge 1</script><p>而上面 $\eqref{1}$ 式要求 $\gamma$ 最大，<br>而 $|\mathbf w|=1$，<br>那么意味着 $\frac {|\mathbf w^{\top}|}{\gamma}$ 最小（$b$ 由 $\mathbf w$ 唯一确定，不对其作约束），也就是说，(1) 式可以变换为如下问题：</p><script type="math/tex; mode=display">\arg \min_{(\mathbf w, b)}\|\mathbf w\|^2 \quad s.t. \quad \forall i \in [m], \ y_i(\mathbf w^{\top} \mathbf x_i+b) \ge 1 \tag{2}</script><h1 id="Soft-SVM"><a href="#Soft-SVM" class="headerlink" title="Soft-SVM"></a>Soft-SVM</h1><p>Hard-SVM 假设训练集线性可分，但是这是一强假设，对这个假设适当放宽就得到 Soft-SVM，即训练集可能线性不可分。我们在 (2) 式的基础上引入松弛变量 $\{\xi_i:\xi_i \ge 0, \forall i \in [m]\}$，使得约束条件变为 $y_i(\mathbf w^{\top} \mathbf x_i+b) \ge 1-\xi_i$，我们的目的除了使 $\Vert \mathbf w\Vert$ 最小之外，还需要使松弛变量尽量小，即尽量减小这种放宽量，或者说尽量满足 Hard-SVM 中的约束条件，这就是 Soft-SVM 优化问题：</p><hr><center>Soft-SVM 求解思路</center><p><strong>input:</strong> $(\mathbf x_1, y_1), \cdots (\mathbf x_m, y_m)$</p><p><strong>parameter:</strong>  $\lambda &gt;0$ （平衡因子）</p><p><strong>solve:</strong></p><script type="math/tex; mode=display">\min_{\mathbf w, b, \boldsymbol \xi} \left(\lambda \|\mathbf w\|^2 + \frac 1 m \sum_{i=1}^m \xi_i\right)</script><script type="math/tex; mode=display">s.t. \ \forall i, \ y_i(\mathbf w^{\top} \mathbf x_i+b) \ge 1- \xi_i, \ \xi_i \ge 0</script><p><strong>output:</strong> $\mathbf w, b$</p><hr><p>我们可以使用正则化的损失最小化来改写上式。使用 hinge 损失，</p><script type="math/tex; mode=display">l(\mathbf w, b, \mathbf x, y)=\max \{0, 1-y(\mathbf w^{\top}\mathbf x+b)\}</script><p>分类器在训练集 $S$ 上的损失记为 $L_S(\mathbf w, b)$，那么正则化损失最小问题为</p><script type="math/tex; mode=display">\min_{\mathbf w, b} (\lambda \|\mathbf w\|^2+L_S(\mathbf w, b))</script><p>固定 $(\mathbf w, b)$ 的值，对于某个样本 $(\mathbf x_i, y_i)$，由于 $\xi_i \ge 0$，所以如果 $y_i(\mathbf w^{\top} \mathbf x_i+b) \ge 1$，那么 $\xi_i=0$，如果 $y_i(\mathbf w^{\top} \mathbf x_i+b) &lt; 1$，那么损失为 $1-y_i(\mathbf w^{\top} \mathbf x_i+b) =\xi_i$，所以 $L_S(\mathbf w, b)=\frac 1 m \sum_{i=1}^m \xi_i$。</p><p>另外，如果 $0&lt;\xi&lt;1$，表示样本虽然分类正确，但是太过靠近判别超平面；如果 $\xi_i \ge 1$，这表示第 $i$ 个样本分类错误。故，<strong>Soft-SVM 允许一定程度的错误，这是我们所期望的，因为有时候训练集的数据由于噪声干扰，出现了一些错误数据，如果完全按照训练集误差为零进行训练，得到的分类器在真实数据上性能反而会下降。</strong></p><h2 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h2>SVM 中的“支持向量”这一词语来自 Hard-SVM 中的 $\mathbf w_0=\frac {\mathbf w^{\ast}} {\gamma^{\ast}}$，其中 $\mathbf w^{\ast}$ 是 (1) 式的解，$\gamma^{\ast}$ 则是 (1) 式的值，即 $\forall i \in [m], \ y_i(\mathbf w^{{\ast}\top} \mathbf x_i+b)\ge\gamma^{\ast}$，那么，向量 $\mathbf w_0$ 由训练集中的样本子集$\{(\mathbf x_i, y_i): y_i(\mathbf w^{{\ast}\top} \mathbf x_i+b)=\gamma^{\ast}\}$ 支持（支撑），这个样本子集中的样本到判别超平面距离最小，均为 $\gamma^{\ast}$，称这个样本子集中的数据向量为“支持向量”。<p>考虑齐次型，即偏置 $b=0$（事实上，可以将 $b$ 作为 $w_1$，且 $\mathbf x$ 前面增加一个元素 $\mathbf x_1=1$，使得非齐次型转换为齐次型）。那么对于 Hard-SVM 有</p><script type="math/tex; mode=display">\min_{\mathbf w} \ \|\mathbf w\|^2 \quad s.t. \quad \forall i \in [m], \ y_i \mathbf w^{\top} \mathbf x \ge 1 \tag{3}</script><p>上面所说的 $\mathbf w_0$ 则是上式的解，支持向量则为 $I=\{\mathbf x_i: |\mathbf w_0^{\top}\mathbf x_i|=1\}$。<strong>存在系数 $\alpha_1, \cdots$ 使得</strong></p><script type="math/tex; mode=display">\mathbf w_0=\sum_{i \in I} \alpha_i \mathbf x_i</script><p>可以使用拉格朗日乘子法证明上述结论，略。</p><h2 id="对偶"><a href="#对偶" class="headerlink" title="对偶"></a>对偶</h2><p>考虑以下函数</p><script type="math/tex; mode=display">g(\mathbf w)=\max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \sum_{i=1}^m \alpha_i (1-y_i \mathbf w^{\top}\mathbf x_i)=\begin{cases} 0 & \forall i, \ y_i(\mathbf w^{\top}\mathbf x_i) \ge 1 \\ \infty & \text{otherwise} \end{cases}</script><p>上式中 $\alpha_i$ 全部非负，显然在 $y_i(\mathbf w^{\top}\mathbf x_i) \ge 1$ 条件下，$\forall i , \ \alpha=0$ 可使得 $g(\mathbf w)$ 最大，为 $0$，否则，$\forall i, \ \alpha=\infty$ 可使得 $g(\mathbf w)$ 最大，为 $\infty$。</p><p>对于线性可分训练集，考虑齐次型，即 $\eqref{3}$ 式，问题可等价为</p><script type="math/tex; mode=display">\min_{\mathbf w}\ (\|\mathbf w\|^2+ g(\mathbf w))</script><p>综合起来就是</p><script type="math/tex; mode=display">\min_{\mathbf w} \max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \left(\frac 1 2 \|\mathbf w\|^2+\sum_{i=1}^m \alpha_i (1-y_i \mathbf w^{\top}\mathbf x_i)\right)</script><p>增加 $\frac 1 2$ 因子是为了后面计算方便。现在将最小最大位置对调，那么目标值只可能变小（弱对偶），</p><script type="math/tex; mode=display">\min_{\mathbf w} \max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \left(\frac 1 2 \|\mathbf w\|^2+\sum_{i=1}^m \alpha_i (1-y_i \mathbf w^{\top}\mathbf x_i)\right)\\ \ge \max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \min_{\mathbf w} \left(\frac 1 2 \|\mathbf w\|^2+\sum_{i=1}^m \alpha_i (1-y_i \mathbf w^{\top}\mathbf x_i)\right)</script><p>实际上在这里，强对偶也成立，即上式中等式成立，于是问题转化为对偶问题</p><script type="math/tex; mode=display">\max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \min_{\mathbf w} \left(\frac 1 2 \|\mathbf w\|^2+\sum_{i=1}^m \alpha_i (1-y_i \mathbf w^{\top}\mathbf x_i)\right)</script><p>当固定 $\boldsymbol \alpha$ 时，优化问题转换为无约束条件且目标可微，根据梯度为 0 求解，得</p><script type="math/tex; mode=display">\mathbf w-\sum_{i=1}^m \alpha_i y_i \mathbf x_i=\mathbf 0 \Rightarrow \mathbf w=\sum_{i=1}^m \alpha_i y_i \mathbf x_i</script><p>这表示解 $\mathbf w$ 处于样本向量所张空间中。于是对偶问题变成</p><script type="math/tex; mode=display">\max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \left(\frac 1 2 \|\sum_{i=1}^m \alpha_i y_i \mathbf x_i\|^2+\sum_{i=1}^m \alpha_i \left(1-y_i \sum_{j=1}^m \alpha_j y_j \mathbf x_j^{\top}\mathbf x_i \right)\right)</script><p>简化上式，其中第一项，</p><script type="math/tex; mode=display">\frac 1 2 \|\sum_{i=1}^m \alpha_i y_i \mathbf x_i\|^2=\frac 1 2 \left(\sum_i \alpha_i y_i \mathbf x_i^{\top}\right)\left(\sum_j \alpha_j y_j \mathbf x_j \right)</script><p>第二项为</p><script type="math/tex; mode=display">\sum_{i=1}^m \alpha_i \left(1-y_i \sum_{j=1}^m \alpha_j y_j \mathbf x_j^{\top}\mathbf x_i \right)=\sum_i \alpha_i-\left(\sum_{j=1}^m \alpha_j y_j \mathbf x_j^{\top}\right)\left(\sum_{i=1}^m \alpha_i y_i \mathbf x_i\right)</script><p>于是对偶问题简化为</p><script type="math/tex; mode=display">\max_{\boldsymbol \alpha \in \mathbb R^m:\boldsymbol \alpha \ge \mathbf 0} \left(\sum_{i=1}^m \alpha_i-\frac 1 2 \sum_{1=1}^m \sum_{j=1}^m \alpha_i  \alpha_j y_iy_j \mathbf x_i^{\top}\mathbf x_j \right)</script><p>在 <a href="2021/09/26/ml/kernel">核方法</a> 这篇文章中，也有类似的思想，两个地方联系起来看看，会更有心得。</p><h2 id="SGD-求解-Soft-SVM"><a href="#SGD-求解-Soft-SVM" class="headerlink" title="SGD 求解 Soft-SVM"></a>SGD 求解 Soft-SVM</h2><p>使用 hinge 损失，那么 Soft-SVM 可写为</p><script type="math/tex; mode=display">\min_{\mathbf w} \left(\frac {\lambda} 2 \|\mathbf w\|^2 + \frac 1 m \sum_{i=1}^m \max \{0, 1-y_i \mathbf w^{\top} \mathbf x_i\}\right) \tag{4} \label{4}</script><p>将上式写成 $f(\mathbf w)=\frac {\lambda} 2 |\mathbf w|^2+L_S(\mathbf w)$ 的形式，这是带正则项的经验损失，然而我们使用随机梯度下降算法，需要求真实损失的梯度，即 $t$ 时刻更新的梯度向量 $\mathbf v_t \in \partial l_{\mathcal D}(\mathbf w^{(t)})$，其中 $\partial l_{\mathcal D}(\mathbf w^{(t)})$ 表示损失在真实样本分布 $\mathcal D$ 下的 $\mathbf w^{(t)}$ 处的次梯度集，$l$ 这里表示 hinge 损失函数，由于真实分布 $\mathcal D$ 未知，我们构造其无偏估计，即 从训练集中 $S$ 均匀随机抽取一个样本 $z$，然后计算 $\partial l(\mathbf w^{(t)}, z)$，于是 $\mathbb E[\lambda \mathbf w^{(t)}+\mathbf v_t]$ 就是 $f=\frac {\lambda} 2 |\mathbf w|^2+L_{\mathcal D}(\mathbf w)$ 在 $\mathbf w^{(t)}$ 处的一个次梯度，选择学习率 $\eta=\frac 1 {\lambda t}$，于是更新公式为</p><script type="math/tex; mode=display">\begin{aligned}\mathbf w^{(t+1)} &=\mathbf w^{(t)}-\frac 1 {\lambda t}(\lambda \mathbf w^{(t)}+\mathbf v_t)\\\\ &=\left(1-\frac 1 t\right)\mathbf w^{(t)}-\frac 1 {\lambda t} \mathbf v_t\\\\ &=\frac {t-1} t \mathbf w^{(t)}-\frac 1 {\lambda t} \mathbf v_t\\\\ &=\frac {t-1} t \left(\frac {t-2}{t-1}\mathbf w^{(t-1)}-\frac 1 {\lambda (t-1)}\mathbf v_{t-1}\right)-\frac 1 {\lambda t} \mathbf v_t\\\\ &=\frac {t-2} t \mathbf w^{(t-1)}-\frac 1 {\lambda t} \mathbf v_{t-1}-\frac 1 {\lambda t} \mathbf v_t\end{aligned}</script><p>根据上述迭代公示，可知</p><script type="math/tex; mode=display">\mathbf w^{(t+1)}=-\frac 1 {\lambda t}\sum_{i=1}^t \mathbf v_i</script><p>$\mathbf v_i$ 是损失（不包括正则损失）即 hinge 损失函数在 $\mathbf w^{(i)}$ 处的次梯度，当 $y\mathbf w^{(i)\top} \mathbf x \ge 1$ 时，次梯度为 $0$，当 $y\mathbf w^{(i)\top} \mathbf x &lt; 1$ 时，次梯度为 $-y\mathbf x$，记 $\boldsymbol {\theta}^{(t)}=-\sum_{i=1}^t \mathbf v_i$，那么 SGD 学习过程具体步骤为</p><hr><center>SGD 求解 Soft-SVM</center><p><strong>目标：</strong> 求解式 $\eqref{4}$</p><p><strong>参数：</strong> $T$ （总迭代次数）</p><p><strong>初始化：</strong> $\boldsymbol {\theta}^{(1)}=\mathbf 0$</p><p><strong>for</strong> $\ t=1,\cdots, T$</p><p>&emsp; $\mathbf w^{(t)}=\frac 1 {\lambda t} \boldsymbol {\theta}^{(t)}$</p><p>&emsp; 从 $[m]$ 中均匀随机选择一个值 $i$</p><p>&emsp; 若 $\ y_i\mathbf w^{(t)\top} \mathbf x_i &lt; 1$</p><p>&emsp; &emsp; $\boldsymbol {\theta}^{(t+1)}=\boldsymbol {\theta}^{(t)}-\mathbf v_t=\boldsymbol {\theta}^{(t)}+y_i \mathbf x_i$</p><p>&emsp; 否则</p><p>&emsp; &emsp; $\boldsymbol {\theta}^{(t+1)}=\boldsymbol {\theta}^{(t)}$</p><p><strong>输出：</strong> $\overline {\mathbf w}=\frac 1 T \sum_{t=1}^T \mathbf w^{(t)}$</p><hr><p>当然也可以使用 $\mathbf w^{T}$ 或者 $\overline {\mathbf w}=\frac 1 {k} \sum_{t=T-k+1}^T \mathbf w^{(t)}$ （latest k 个 $\mathbf w{(t)}$ 的平均） 作为最终的输出。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k fold 交叉验证</title>
      <link href="/2021/09/19/ml/k_fold/"/>
      <url>/2021/09/19/ml/k_fold/</url>
      
        <content type="html"><![CDATA[<p>交叉验证通常用于训练集很小的情况，这时候如果再从中取一部分数据作为验证集，导致训练集进一步减小，更加难以反映真实数据分布，从而使得经验误差与真实误差的差距更大。这时，K 折交叉验证则是一个不错的方法。</p><span id="more"></span><h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><p>操作步骤：</p><ol><li>将训练集（大小为 m）分为 k 份，每一个样本数量为 $m/k$。</li><li>循环 k 次，在第 i 次循环时，除第 i 份之外其他所有样本作为本次训练集进行训练，训练完成后计算模型在第 i 份样本上的验证误差。</li><li>k 个验证误差的平均，则为对真实误差的估计值。</li></ol><h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><p>有时候模型有一些超参数，例如多项式中的阶数 $d$，步骤如下：</p><hr><center>用于模型选择的 k fold 交叉验证</center><p><strong>input:</strong></p><ol><li>训练集 $S=(\mathbf x_1, y_1), \cdots, (\mathbf x_m, y_m)$</li><li>超参数集合 $\Theta$</li><li>模型学习算法 $A$</li><li>k-fold 中的 $k$</li></ol><p><strong>切分</strong></p><ol><li>将 $S$ 切分为 $S_1, \cdots, S_k$</li></ol><p><strong>foreach</strong> $\theta \in \Theta$</p><p>&emsp; <strong>for</strong> $i=1,\cdots,k$</p><p>&emsp; &emsp; $h_{i,\theta}=A(S - S_i; \theta)$</p><p> &emsp; error$(\theta)=\frac 1 k \sum_{i=1}^k L_{S_i}(h_{i, \theta})$</p><p> <strong>output</strong></p><ol><li>$\theta^*=\argmin_{\theta} [\text{error}(\theta)]$</li><li>$h_{\theta^<em>}=A(S;\theta^</em>)$</li></ol><hr><p>总结：</p><ol><li>遍历超参数集合，对于每个超参数，分别计算 k-fold 验证误差的平均</li><li>选择最小平均误差所对应的超参数，然后利用这个超参数和所有数据集作为训练集，进行训练</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归预测</title>
      <link href="/2021/09/17/ml/linear/"/>
      <url>/2021/09/17/ml/linear/</url>
      
        <content type="html"><![CDATA[<p>讨论线性回归问题<br><span id="more"></span></p><h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>线性回归问题的假设（hypothesis）为</p><script type="math/tex; mode=display">\mathcal H = L_d=\{\langle \mathbf w, \mathbf x \rangle+b: \mathbf w \in \mathbb R^d, b \in \mathbb R\}</script><p>损失使用平方差，即</p><script type="math/tex; mode=display">l(h,(\mathbf x, y))=(h(\mathbf x) - y)^2</script><p>对于一个大小为 $m$ 的样本集，经验损失为</p><script type="math/tex; mode=display">L_S(h)=\frac 1 m \sum_{i=1}^m (h(\mathbf x_i) - y_i)^2</script><h2 id="ERM"><a href="#ERM" class="headerlink" title="ERM"></a>ERM</h2><p>求 ERM 解，即经验损失最小化，对上式求梯度，令其为0，得</p><script type="math/tex; mode=display">\sum_{i=1}^m (\mathbf w^{\top} \mathbf x_i - y_i)\mathbf x_i = \mathbf 0 \Rightarrow \sum_{i=1}^m(\mathbf x_i^{\top} \mathbf w)\mathbf x_i=\sum_{i=0}^m y_i \mathbf x_i</script><p>写成 $A \mathbf w=\mathbf b$ 的形式，其中</p><script type="math/tex; mode=display">A=\left(\sum_{i=1}^m\mathbf x_i \mathbf x_i^{\top} \right), \quad \mathbf b = \sum_{i=0}^m y_i \mathbf x_i</script><p>上面的简写中用到了 $(\mathbf x^{\top} \mathbf w)\mathbf x=\mathbf x(\mathbf x^{\top} \mathbf w)=(\mathbf {x x}^{\top}) \mathbf w$ 这样一个事实。</p><h3 id="A-可逆"><a href="#A-可逆" class="headerlink" title="A 可逆"></a>A 可逆</h3><p>如果 $A$ 是可逆矩阵，那么 ERM 的解为</p><script type="math/tex; mode=display">\mathbf w = A^{-1} \mathbf b</script><p>根据 $A$ 的定义，</p><hr><p><strong>如果训练集中的向量能张开（span）整个 $\mathbb R^d$，那么 $A$ 就是可逆的。</strong></p><p>下面简单的证明一下这个结论。</p><p><strong>证：</strong></p><p>对于 $\forall \ \mathbf v \in \mathbb R^d$，</p><script type="math/tex; mode=display">A \mathbf v=\left(\sum_{i=1}^m\mathbf x_i \mathbf x_i^{\top} \right)\mathbf v=\sum_{i=1}^m\mathbf x_i \mathbf x_i^{\top} \mathbf v=\sum_{i=1}^m\mathbf x_i (\mathbf x_i^{\top} \mathbf v)=\sum_{i=1}^m(\mathbf x_i^{\top} \mathbf v)\mathbf x_i</script><p>因为训练集中的样本向量可以张开 $\mathbb R^d$ 空间，这表示有 $d$ 个非线性相关的向量，不妨假设它们的编号是前 $d$，即 $\mathbf x_1, \cdots, \mathbf x_d$，任意一个样本向量可表示为这 $d$ 个样本向量的线性组合，即 $\mathbf x_j=\sum_{i=1}^d c_{ji} \mathbf x_i$，记 $\mathbf x_i^{\top} \mathbf v=p_i, \ \forall i \in [m]$，于是</p><script type="math/tex; mode=display">\begin{aligned}A \mathbf v&=\sum_{i=1}^d p_i\mathbf x_i + \sum_{j=d+1}^m \sum_{k=1}^d p_j c_{jk} \mathbf x_k\\&=\sum_{i=1}^d p_i\mathbf x_i + \sum_{k=1}^d\sum_{j=d+1}^m  p_j c_{jk} \mathbf x_k\\&=\sum_{i=1}^d \left(p_i + \sum_{j=d+1}^m p_j c_{ji}\right)\mathbf x_i\\&=\sum_{i=1}^d q_i \mathbf x_i\end{aligned}</script><p>可见，$A$ 的映射空间为 $\mathbf x_1, \cdots, \mathbf x_d$ 这一组非线性相关向量线性组合而成，且 $\exists \ \mathbf v \in \mathbb R^d$，使得 $\forall i \in [d], \ q_i\neq 0$。显然如果 $A$ 不可逆，那么至少会有一个 $q_i$ 值为 0，矛盾，所以 $A$ 可逆。</p><h3 id="A-不可逆"><a href="#A-不可逆" class="headerlink" title="A 不可逆"></a>A 不可逆</h3><hr><p>从 $A$ 的定义可以发现它是一个对称矩阵，并且巧合地是，$b$ 恰好处在 $A$ 的映射空间中。</p><p><strong>证：</strong></p><p>$A$ 是对称矩阵，可以进行特征值分解 $A=VDV^{\top}$，其中 $D$ 是由特征值组成的对角矩阵，$V$ 是由特征向量组成的矩阵，且 $V$ 是一个正交矩阵即 $V^{\top}V=I_{d\times d}$，定义对角矩阵 $D^+$</p><script type="math/tex; mode=display">D_{ii}^+=\begin{cases}  1 /D_{ii} & D_{ii} \neq 0 \\ 0 & D_{ii}=0\end{cases}</script><script type="math/tex; mode=display">A^+=VD^+V^{\top}, \quad \hat {\mathbf w}=A^+b</script><p>将 $V$ 写成</p><script type="math/tex; mode=display">V=[\mathbf v_1, \cdots, \mathbf v_d]</script><p>于是</p><script type="math/tex; mode=display">\begin{aligned}A\hat {\mathbf w}&=AA^+ \mathbf b\\&=VDV^{\top} VD^+ V^{\top}  \mathbf b\\&=VDD^+V^{\top}\mathbf b\\&=\sum_{i:D_{ii}\neq 0} \mathbf v_i \mathbf v_i^{\top} \mathbf b\\&= \overline A \ \mathbf b\\&=\sum_{i:D_{ii}\neq 0}( \mathbf v_i^{\top} \mathbf b) \mathbf v_i\\&= \sum_{i=1}^d q_i \mathbf v_i\end{aligned}</script><p>其中 </p><script type="math/tex; mode=display">q_i=\begin{cases} \mathbf v_i^{\top} \mathbf b & D_{ii}\neq 0 \\ 0 & D_{ii} = 0 \end{cases}</script><p>借鉴上面 $A$ 是可逆矩阵的证明可知（注意这里 $A$ 不假设为可逆矩阵），上式最后一项表示将 $\mathbf b$ 投影到 $\overline A$ 的投影空间，这个投影空间是由所有 $D_{ii} \neq 0$ 所对应的向量 $\mathbf v_i$ 张开（span）。而</p><script type="math/tex; mode=display">A=\left(\sum_{i=1}^m\mathbf x_i \mathbf x_i^{\top} \right)=[\mathbf v_1, \cdots, \mathbf v_d]D[\mathbf v_1^{\top}, \cdots, \mathbf v_d^{\top}]^{\top}=\sum_{i:D_{ii} \neq 0} \mathbf v_i\mathbf v_i^{\top}</script><p>这表示 $\mathbf x_1, \cdots , \mathbf x_m$ 所张空间与 $\{\mathbf v_i: D_{ii} \neq 0\}$ 所张空间相同，且 $\mathbf b = \sum_{i=1}^m y_i \mathbf x_i$ 处在 $\mathbf x_1, \cdots , \mathbf x_m$ 所张空间中，也就是处在 $\{\mathbf v_i: D_{ii} \neq 0\}$ 所张空间中， 由于 $\{\mathbf v_i: D_{ii} \neq 0\}$ 是正交规范向量，可看到这个空间中的一组正交基，<strong>它对处在这个空间中的向量的变换保持不变</strong>，即 $(\sum_{i:D_{ii}\neq 0} \mathbf v_i \mathbf v_i^{\top})\mathbf b=\mathbf b$，于是有</p><script type="math/tex; mode=display">A \hat{\mathbf w}=\mathbf b</script><p>这表明 $\hat {\mathbf w}=A^+b$ 是符合条件的解，证毕。</p><p>注：实际应用中 $A$ 的特征分解可使用 <code>scipy</code> 包。</p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Perceptron for Halfspaces</title>
      <link href="/2021/09/15/ml/halfspace/"/>
      <url>/2021/09/15/ml/halfspace/</url>
      
        <content type="html"><![CDATA[<p>关于线性可分二分类问题的讨论<br><span id="more"></span></p><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p>数据集为 $S=\{(\mathbf x_i, y_i)\}_{i=1}^m$，数据集可分（不可分的情况这里不讨论），仿射函数为</p><script type="math/tex; mode=display">L_d=\{h_{\mathbf w, b}: \mathbf w \in \mathbb R^d, b \in \mathbb R\}=\{\langle \mathbf w, \mathbf x \rangle+b: \mathbf w \in \mathbb R^d, b \in \mathbb R\}</script><p>假设类 为 </p><script type="math/tex; mode=display">HS_d=\text{sign} \circ L_d</script><p>令 $\mathbf w’=(b, w_1, \cdots w_d)$，$\mathbf x’=(1, x_1, \cdots x_d)$，那么可写为齐次形式</p><script type="math/tex; mode=display">h_{\mathbf w, b}(\mathbf x) = \langle \mathbf w', \mathbf x' \rangle</script><p>以下讨论如不特别说明，均使用齐次形式进行说明。现在，我们要求 ERM（经验损失最小化）预测器，那么就是要求一个 $\mathbf w^<em>$，使得 $\forall i = 1, \cdots , m$，有 $\text{sign}(\langle \mathbf w^</em>, \mathbf x_i \rangle)=y_i$，即</p><script type="math/tex; mode=display">y_i \langle \mathbf w^*, \mathbf x_i \rangle > 0, \quad \forall i = 1, \cdots, m$$ (1)由于假设了数据集是线性可分的，$\mathbf w^*$ 必然存在。## Perceptron 迭代算法在迭代时刻 $t$，参数记为 $\mathbf w^{(t)}$，初始时为 $\mathbf w^{(1)}=\mathbf 0$。在 $t$ 迭代时，寻找一个样本使得 $\mathbf w^{(t)}$ 将其分类错误，即 $y_i \langle \mathbf w^{(t)}, \mathbf x_i \rangle \le 0$，那么迭代更新为$$\mathbf w^{(t+1)}=\mathbf w^{(t)}+y_i \mathbf x_i</script><p>由于</p><script type="math/tex; mode=display">y_i \langle \mathbf w^{(t+1)}, \mathbf x_i \rangle=y_i \langle \mathbf w^{(t)}+y_i \mathbf x_i, \mathbf x_i \rangle=y_i \langle \mathbf w^{(t)}, \mathbf x_i \rangle+\|\mathbf x_i \|^2</script><p>样本 $(\mathbf x_i, y_i)$ 被 $\mathbf w^{(t)}$ 分类错误，故上式右侧第一项 $\le 0$，而 $| \mathbf x_i |^2 \ge 0$，所以是朝着正确的方向更新 $\mathbf w$。</p><p>求解步骤:</p><hr><p>输入：训练集 $(\mathbf x_1, y_1), \cdots , (\mathbf x_m, y_m)$</p><p>初始化: $\mathbf w^{(1)}=(0,\cdots,0)$</p><p>$\quad \text{for} \ t=1,2,\dots$</p><p>$\quad \quad \text{if} \ (\exists \ i \ s.t. \ y_i \langle \mathbf w^(t), \mathbf x_i \rangle \le 0) \ \text{then}$</p><p>$\quad \quad \quad \mathbf w^{(t+1)}=\mathbf w^{(t)}+y_i \mathbf x_i$</p><p>$\quad \quad \text{else}$</p><p>$\quad \quad \quad \text{output} \ \mathbf w^{(t)}$</p><hr><p>我们还可以证明在有限的迭代次数后能得到符合条件的 $\mathbf w$。</p><p>令 $B=\min \{|\mathbf w|: \forall \ i \in [m], \ y_i \langle \mathbf w, \mathbf x_i \rangle \ge 1\}$， $R=\max_i | \mathbf x_i |$，那么上述算法最多在 $(RB)^2$ 次迭代后结束，且结束时有 $\forall \ in \in [m], \ y_i \langle \mathbf w^{(t)}, \mathbf x_i \rangle &gt; 0$。</p><p>注意， $\{|\mathbf w|: \forall \ i \in [m], \ y_i \langle \mathbf w, \mathbf x_i \rangle \ge 0\}$  没有最小值，因为如果 $\mathbf w$ 满足条件，那么对 $\forall \ 0&lt;\gamma &lt;1$， $\gamma \mathbf w$ 也满足条件，而 $|\gamma \mathbf w|^2=\gamma^2 |\mathbf w|^2 &lt; |\mathbf w |^2$。</p><p>但是 $\{|\mathbf w|: \forall \ i \in [m], \ y_i \langle \mathbf w, \mathbf x_i \rangle \ge 1\}$ 有最小值，因为 $|y_i\langle \mathbf w, \mathbf x_i \rangle|=|\mathbf w |\cdot|\mathbf x_i| \cdot|\cos \theta_i|\ge 1 \Rightarrow |\mathbf w | \ge 1/(|\mathbf x_i| \cdot|\cos \theta_i|)$  对 $\forall i \in [m]$ 均成立，式 (1)只是限制了 $\mathbf w$ 的方向，故一定存在某个 $\mathbf w$，使得 $|\mathbf x_i| \cdot|\cos \theta_i|$ 最大。</p><p>下面证明在最多 $(RB)^2$ 的迭代次数后算法结束。</p><p><strong>证：</strong></p><p>令 $\mathbf w^<em>$ 为某个满足 $B$ 的解，即 $\forall \ i \in [m]$，均有 $y_i \langle \mathbf w^</em>, \mathbf x_i \rangle \ge 1$，且 $\mathbf w^*$ 范数最小。</p><p>由于 $\mathbf w^{(1)}=\mathbf 0$，故 $\langle \mathbf w^*, \mathbf w^{(1)}\rangle=0$，那么</p><script type="math/tex; mode=display">\langle \mathbf w^*, \mathbf w^{(t+1)}\rangle - \langle \mathbf w^*, \mathbf w^{(t)}\rangle=\langle \mathbf w^*, \mathbf w^{(t+1)}-\mathbf w^{(t)}\rangle=\langle \mathbf w^*, y_i \mathbf x_i\rangle=y_i\langle \mathbf w^*, \mathbf x_i\rangle \ge 1</script><p>于是</p><script type="math/tex; mode=display">\langle \mathbf w^*, \mathbf w^{(T+1)} \rangle=\sum_{t=1}^T \left( \langle \mathbf w^*, \mathbf w^{(t+1)}\rangle-\langle \mathbf w^*, \mathbf w^{(t)}\rangle \right) \ge T</script><p>另有</p><script type="math/tex; mode=display">\|\mathbf w^{(t+1)}\|^2=\|\mathbf w^{(t)}+y_i \mathbf x_i\|^2=\|\mathbf w^{(t)}\|^2+2y_i \langle \mathbf w^{(t)}, \mathbf x_i\rangle+y_i^2\| \mathbf x_i\|^2 \le \|\mathbf w^{(t)}\|^2+R^2</script><p>上面最后一个不等式中，由于 $t+1$ 次更新时，使用的是令 $\mathbf w^{(t)}$ 分类错误的样本 $(\mathbf x_i, y_i)$，故 $2y_i \langle \mathbf w^{(t)}, \mathbf x_i\rangle \le 0$，且根据上面定义，有 $| \mathbf x_i |^2 \le R$，再根据 $|\mathbf w^{(1)}|^2=0$所以有</p><script type="math/tex; mode=display">\|\mathbf w^{(T+1)} \|^2 \le TR^2</script><p>故</p><script type="math/tex; mode=display">\frac {\langle \mathbf w^*, \mathbf w^{(T+1)} \rangle} {\|\mathbf w^*\| \cdot \|\mathbf w^{(T+1)}\|} \ge \frac T {B \sqrt T R}=\frac {\sqrt T} {BR}</script><p>根据 Cauchy-Schwartz 不等式，上式最左边项 $<1$，于是有 $1 > \sqrt T / (BR)$，即迭代次数满足关系</p><script type="math/tex; mode=display">T \le (RB)^2</script><h2 id="VC-维"><a href="#VC-维" class="headerlink" title="VC 维"></a>VC 维</h2><h2 id="齐次形式"><a href="#齐次形式" class="headerlink" title="齐次形式"></a>齐次形式</h2><p>$\mathbb R^d$ 中齐次 Halfspance 类的 VC 维等于 $d$。</p><p><strong>证：</strong></p><p>要证明 $VCdim(\mathcal H)=d$，需要满足两个条件：</p><ul><li>存在样本集 $C$，其大小为 $|C|=d$，此样本可以被 $\mathcal H$ shattered。 </li><li>任意一个大小为 $|C|=d+1$ 的样本集均不能被 $\mathcal H$ shattered。</li></ul><p>首先，考虑标准正交基向量 $\mathbf e_1, \cdots, \mathbf e_d$（one-hot），这个向量集可以被齐次 Halfspace shattered，这里的假设类具有如下形式</p><script type="math/tex; mode=display">\mathcal H=\{\text{sign}(\langle \mathbf w , \mathbf x\rangle): \mathbf w \in \mathbb R^d\}</script><p>对于任意的 $(y_1, \cdots, y_d)$，令 $\mathbf w=(y_1, \cdots, y_d)$，就可以得到 $h(\mathbf e_i)=\text{sign}(\langle \mathbf w , \mathbf x\rangle)=y_i$，所以 $\mathbf e_1, \cdots, \mathbf e_d$ 被 $\mathcal H$ shattered，第一个条件满足。</p><p>另一方面，令任意集合 $\mathbf x_1, \cdots, \mathbf x_{d+1} \in R^d$，向量数据大于维度，故这 $d+1$ 个向量必然线性相关，即 $\sum_{i=1}^{d+1} a_i \mathbf x_i=\mathbf 0$，其中 $a_1, \cdots, a_{d+1}$ 不全为 $0$，记 $I=\{i:a_i&gt;0\}$，$J=\{j:a_j&lt;0\}$，所以 $I, \ J$ 至少有一个集合不为空。</p><ul><li>$I, \ J$ 均不为空，那么</li></ul><script type="math/tex; mode=display">\sum_{i \in I}a_i \mathbf x_i = \sum_{j \in J} |a_j|\mathbf x_j</script><p>假设 $\mathbf x_1, \cdots, \mathbf x_{d+1}$ 被 $\mathcal H$ shattered，那么存在一个 $\mathbf w$，使得 $\langle \mathbf w, \mathbf x_i \rangle &gt;0, \ \forall \ i \in I$，且 $\langle \mathbf w, \mathbf x_i \rangle &lt;0, \ \forall \ i \in J$，于是有</p><script type="math/tex; mode=display">0 < \sum_{i \in I} a_i \langle \mathbf w, \mathbf x_i \rangle=\langle \mathbf w, \sum_{i \in I} a_i \mathbf x_i \rangle=\langle \mathbf w, \sum_{j \in J} |a_j| \mathbf x_j \rangle=\sum_{j \in J} |a_j| \langle \mathbf w, \mathbf x_j \rangle <0</script><p>矛盾，也就是说不存在这样的 $\mathbf w$，即 $\mathbf x_1, \cdots, \mathbf x_{d+1}$ 不能被 $\mathcal H$ shattered。</p><ul><li>$I=\emptyset, \ J \neq \emptyset$，那么</li></ul><script type="math/tex; mode=display">\sum_{j \in J} |a_j|\mathbf x_j=0</script><p>假设 $\mathbf x_1, \cdots, \mathbf x_{d+1}$ 被 $\mathcal H$ shattered，那么存在一个 $\mathbf w$，使得 $\langle \mathbf w, \mathbf x_i \rangle &lt;0, \ \forall \ i \in J$，于是有</p><script type="math/tex; mode=display">0=\langle \mathbf w, \sum_{j \in J} |a_j|\mathbf x_j \rangle= \sum_{j \in J} |a_j| \langle \mathbf w, \mathbf x_j \rangle <0</script><p>矛盾，也就是说不存在这样的 $\mathbf w$，即 $\mathbf x_1, \cdots, \mathbf x_{d+1}$ 不能被 $\mathcal H$ shattered。</p><ul><li>$I \neq \emptyset, \ J = \emptyset$，情况与上一点相同。</li></ul><p>综上，任意 $\mathbf x_1, \cdots, \mathbf x_{d+1}$ 不能被 $\mathbf H$ shattered，故 $VCdim(\mathbf H)=d$，证毕。</p><h2 id="非齐次形式"><a href="#非齐次形式" class="headerlink" title="非齐次形式"></a>非齐次形式</h2><p>$\mathbb R^d$ 中非齐次 Halfspance 类的 VC 维等于 $d+1$。</p><p><strong>证：</strong></p><p>令大小为 $d+1$ 的集合 $C=(\mathbf 0, \mathbf e_1, \cdots, \mathbf e_d)$，假设类为</p><script type="math/tex; mode=display">\mathcal H=\{\text{sign}(\langle \mathbf w, \mathbf x \rangle + b): \mathbf w \in \mathbb R^d\}</script><p>对于任意的 label 值 $(y_1, \cdots, y_{d+1})$，参数 $\mathbf w, b$ 满足条件</p><script type="math/tex; mode=display">y_1 \cdot b > 0</script><script type="math/tex; mode=display">y_i(w_i+b)>0, \ \forall i \in [d]</script><p>均有解，所以找到一个集合 $C$ 可以被 $\mathcal H$ shattered。</p><p>然后，对任意向量集合 $\mathbf x_1, \cdots, \mathbf x_{d+2}$，假设能被 $\mathcal H$ shattered，我们记 $\mathbb R^{d+1}$ 中的齐次形式的 halfspace 类假设的一般形式为 $\mathcal H’=\{\text{sign}(\langle \mathbf w’, \mathbf x’\rangle): \mathbf w’ \in \mathbb R^{d+1}\}$，显然令 $\mathbf w’=(b, w_1, \cdots , w_d)$，且 $\mathbf x’=(1,x_1, \cdots, x_d)$ 就得到 $\mathcal H$ （$\mathbb R^d$  中的非齐次类），也就是说 $\mathcal H \subset \mathcal H’$，于是集合 $\mathbf x_1, \cdots, \mathbf x_{d+2}$ 也应该能被 $\mathcal H’$ shattered，然而，根据前面齐次情况的讨论，$\mathbb R^{d+1}$ 中，任意向量集合 $\mathbf x_1, \cdots, \mathbf x_{d+2}$ 不能被 $\mathcal H’$ shattered，产生矛盾，故假设错误。</p><p>综合，<script type="math/tex">VCdim(\mathcal H)=d+1</script></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jupyter-book</title>
      <link href="/2021/08/24/tools/jupyter-book/"/>
      <url>/2021/08/24/tools/jupyter-book/</url>
      
        <content type="html"><![CDATA[<p>介绍使用 jupyter-book 写博客（通常是一个在线电子书）的方法。<br><span id="more"></span></p><p>Jupyter Book <a href="https://jupyterbook.org/start/overview.html">官方文档</a></p><p>另一个文档在<a href="https://predictablynoisy.com/jupyter-book/guide/01_overview">这里</a>。</p><p>使用 Jupyter Book 可以创建基于 markdown 的文档，并使用 <code>jupyter-book</code> 将这些文档转为托管到 web（例如 github）的电子书。</p><p>安装步骤：<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">conda create -n jupyter python&#x3D;3.9 # 新建一个专用 envconda activate jupyterpip install jupyter-book<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><h1 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h1><p>创建一个 Jupyter Book，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">jupyter-book create mybookname&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h1 id="文件目录结构"><a href="#文件目录结构" class="headerlink" title="文件目录结构"></a>文件目录结构</h1><h2 id="内容文件"><a href="#内容文件" class="headerlink" title="内容文件"></a>内容文件</h2><p>有两种文件格式 <code>.md</code> 和 <code>.ipynb</code>，前者是标记文档，主要包含文本内容，后者则包含了计算内容（代码）和叙述内容（文本）。这两者不多说，大家或多或少都了解。</p><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p><code>_config.yml</code></p><h2 id="内容表"><a href="#内容表" class="headerlink" title="内容表"></a>内容表</h2><p> Table of Content：<code>_toc.yml</code></p><h1 id="生成"><a href="#生成" class="headerlink" title="生成"></a>生成</h1><p>如果当前目录在 <code>mybookname</code> 父级目录，那么执行<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">jupyter-book build mybookname&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>生成的文件全部位于 <code>mybookname/_build</code> 文件夹下。</p><p>如果当前目录在 <code>mybookname</code>，那么执行<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">jupyter-book build .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>因为有 cache，未修改的 source 文件不再重新生成，如果需要全部重新生成，执行<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">jupyter-book build --all .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>如果报错：<br><pre class="line-numbers language-none"><code class="language-none">ImportError: DLL load failed while importing win32api: The specified module could not be found<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>解决方法：<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">python C:\path\to\miniconda3\Scripts\pywin32_postinstall.py -install<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>所有的内容文件和配置文件均为 source 文件，生成的文件位于 <code>_build</code> 目录，称为 build 文件。 在 git 项目中，main 主分支中 ignore <code>_build</code> 目录，并将 <code>_build</code> 中文件 push 到 另一个分支（例如 <code>gh-pages</code>）中，用于在 web 中展示。</p><h1 id="预览"><a href="#预览" class="headerlink" title="预览"></a>预览</h1><p>可以在本地文件<code>_build/html/index.html</code> 上双击打开，也可以在浏览器中输入文件路径 （例如 <code>file://Users/my_path_to_book/_build/html/index.html</code>）</p><h1 id="发布上线"><a href="#发布上线" class="headerlink" title="发布上线"></a>发布上线</h1><h2 id="创建在线仓库"><a href="#创建在线仓库" class="headerlink" title="创建在线仓库"></a>创建在线仓库</h2><p>在 github 上创建新仓库，仓库名可取为 <code>mybook</code>，可为仓库添加一句描述，仓库初始化时不要 <code>README</code> 文件，即完全空仓库，然后 clone 仓库到本地，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">git clone https:&#x2F;&#x2F;github.com&#x2F;&lt;my-account&gt;&#x2F;mybook<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>将 book 中的所有文件和文件夹拷贝到这个本地仓库，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">cp -r mybookname&#x2F;* mybook&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p><strong>也可以使用以下方法创建一个在线书籍，例如想创建一个线性规划相关的书籍</strong>，</p><ol><li>按上一步创建 github 在线仓库，仓库名为 <code>linear_programming</code></li><li>克隆空仓库到本地，然后 <code>cd</code> 到本地目录 <code>linear_programming</code></li><li>执行 <code>jupyter-book create lp</code>，这样就在当前目标创建了书籍，书籍相关的源码文件全部位于 <code>lp</code> 这个子目录下。</li></ol><p>创建成果参见 <a href="https://github.com/JianjianSha/linear_programming">线性规划在线书籍</a> 。</p><p>添加 <code>.gitignore</code> 文件，文件内容为，<br><pre class="line-numbers language-none"><code class="language-none">mybook&#x2F;_build&#x2F;*.ipynb_checkpoints.DS_Store__pycache__&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>然后同步到本地仓库和远程仓库，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">cd mybookgit add .&#x2F;*git commit -m &quot;adding my first book&quot;git push<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="使用-Github-Page-将-book-发布上线"><a href="#使用-Github-Page-将-book-发布上线" class="headerlink" title="使用 Github Page 将 book 发布上线"></a>使用 Github Page 将 book 发布上线</h2><p>我们已经将源文件推送到 github 库，此时还需要将生成的文件发布上线，使得生成一个 web 页面。最简单的办法是使用 <code>ghp-import</code> 包，</p><p><code>ghp-import</code> 工作机制是将生成的内容 （<code>_build/html</code> 目录）拷贝到仓库分支 <code>gh-pages</code>，并推送到 github，<code>ghp-import</code> 自动创建<code>gh-pages</code> 分支并填充生成的文件。</p><p>操作步骤：</p><ol><li><p>安装</p> <pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">pip install ghp-import<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>更新 Github pages 站点设置</p><ul><li>使用 <code>gh-pages</code>分支托管网站。（这一步可以忽略，可以直接执行第三步，这样会自动设置。）</li></ul></li><li><p>在 <code>main</code> 分支下（即 <code>master</code> 分支，不包含 <code>_build/html</code> 文件夹），调用</p> <pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">ghp-import -n -p -f _build&#x2F;html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <code>-n</code> 选项是告诉 Github 不用使用 <code>Jekyll</code> 来生成 book，因为我们的 HTML 已经生成。这个命令在 _build 所在目录下执行。</p></li></ol><p>几分钟之后，book 可以通过 <code>https://&lt;user&gt;.github.io/mybook/</code> 访问。</p><h2 id="修改-book"><a href="#修改-book" class="headerlink" title="修改 book"></a>修改 book</h2><p>checkout 仓库的 <code>main</code> 分支，然后进行修改 book 内容，然后 re-build <code>jupyter-book build .</code>，然后使用 <code>ghp-import -n -p -f _build/html</code> 推送到 <code>gh-pages</code>。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>function vs. macro</title>
      <link href="/2021/08/10/cpp/cmake/func_macro/"/>
      <url>/2021/08/10/cpp/cmake/func_macro/</url>
      
        <content type="html"><![CDATA[<h1 id="macro"><a href="#macro" class="headerlink" title="macro"></a>macro</h1><p>宏定义语法，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">macro</span><span class="token punctuation">(</span>&lt;name<span class="token punctuation">></span> [&lt;arg1<span class="token punctuation">></span> ...]<span class="token punctuation">)</span>  &lt;commands<span class="token punctuation">></span><span class="token keyword">endmacro</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>宏名称 <code>&lt;name&gt;</code> 后跟参数 <code>&lt;arg1&gt;,...</code>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> cmake, c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCC common usages</title>
      <link href="/2021/08/06/cpp/gcc_common_usages/"/>
      <url>/2021/08/06/cpp/gcc_common_usages/</url>
      
        <content type="html"><![CDATA[<p>示例程序<br><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">// hello.c</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv<span class="token punctuation">)</span><span class="token punctuation">&#123;</span> <span class="token function">printf</span><span class="token punctuation">(</span>“hello world\n”<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="生成可执行文件"><a href="#生成可执行文件" class="headerlink" title="生成可执行文件"></a>生成可执行文件</h1><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -o hello hello.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>生成可执行文件这一过程其实是分成了很多中间步骤，下面给出关键的几个步骤。</p><h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><p>使用 <code>-E</code> 使得预处理之后就立即停止，不进行后面的编译<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">gcc -E -o hello.pp.c hello.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -S hello.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此命令在编译后立即停止，不进行汇编（汇编后生成二进制文件，即目标文件）。结果生成文件 <code>hello.s</code>。</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c hello.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编译并汇编但不进行链接，生成目标 <code>hello.o</code>。</p><p>gcc 命令选项可以查看 <a href="https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html">官方文档</a>。</p><p>编译后的目标文件有多个 section，和一个符号表：</p><ol><li><code>Text</code>：可执行代码 （T）</li><li><code>Data</code>: 预分配变量存储 （D）</li><li><code>Constants</code>：只读数据    （R）</li><li><code>Undefined</code>: 已经用到但是未定义的符号 （U）</li><li><code>Debug</code>：调试信息（例如，行号）</li></ol><p>这些条目可以通过 <code>nm</code> 或者 <code>readelf</code> 查看。</p><h1 id="链接命令"><a href="#链接命令" class="headerlink" title="链接命令"></a>链接命令</h1><p>链接使用如下命令，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -o hello hello.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>gcc 其实是调用 <code>ld</code> 讲目标文件 <code>crt1.o</code> 和我们的 <code>hello.o</code> 链接到一起，其中 <code>crt1.o</code> 为启动目标，<code>crtn.o</code> 为结束目标，<code>crt1.o</code> 包含了 <code>_start</code> 入口点，其中会调用 <code>main</code> 函数，执行我们所实现的函数主体。这可以通过 <code>nm</code> 查看，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ nm &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;crt1.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>其中会有 <code>U main</code> 这一行，表示 <code>main</code> 这个符号未定义，这是由我们自己实现 <code>main</code> 函数。</p><p>其实还有 <code>crti.o</code> 目标文件也会链接进入，这个目标文件中实现了 <code>_init</code> 和 <code>_finit</code> 函数，分别在 <code>main</code> 函数之前和 之后执行。<br><img src="/images/cpp/C_linking_process.png" alt=""><center>C 程序链接过程 参考[文章](https://akaedu.github.io/book/ch19s02.html)</center></p><h1 id="静态库"><a href="#静态库" class="headerlink" title="静态库"></a>静态库</h1><p>使用 <code>ar</code> 命令生成静态库，静态库是有着全局符号表的目标文件的集合。<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ ar crv libhello.a hello.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>关于 <code>ar</code> 命令的更多介绍可参考<a href="https://linux.die.net/man/1/ar">这篇文章</a></p><p>当链接到一个静态库时，目标代码拷贝进最终的可执行体，所有的符号地址重新计算。</p><p>静态库抽取出目标文件，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ ar -x libhello.a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h1 id="动态库"><a href="#动态库" class="headerlink" title="动态库"></a>动态库</h1><p>动态库比静态库更接近于可执行体（executable），动态库相当于 executable 少了 <code>main</code> 函数，而静态库相当于多个目标文件的打包。</p><p>生成动态库命令，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -fPIC -c hello.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>这里不能链接，否则编译器会报错：<code>main</code> 函数未定义。</p><p>然后链接生成动态库，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ ld -shared hello.o -o libhello.so<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>我们也可以直接一步生成动态库，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">gcc -shared -fPIC -o hello.c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h1 id="链接过程"><a href="#链接过程" class="headerlink" title="链接过程"></a>链接过程</h1><p>链接器分为静态链接器和动态（运行时）链接器。</p><ol><li>静态链接器 static linker 负责生成 shared library 和 executable，linux 上为 <code>ld</code>，google 还提供了一个替代 <code>gold</code>。</li><li>动态链接器 dynamic linker 负责在执行期间载入 shared library，linux 上使用 <code>ld.so</code>。</li></ol><p>为了称呼简便，下文将 static linker 称为 linker，将 dynamic linker 称为 loader。</p><h2 id="搜索路径"><a href="#搜索路径" class="headerlink" title="搜索路径"></a>搜索路径</h2><ol><li>对于 linker，使用 <code>-L</code> option，例如 <code>ld -o main main.c -L. -lhello</code></li><li>对于 loader，使用 <code>-rpath</code>，例如 <code>gcc -o main main.c -Wl,-rpath=. -L. -lhello</code></li></ol><p>动态库搜索路径的设置方法有以下几种：</p><ol><li><p>如果当前目录 <code>.</code> 下 hello 库为静态库 <code>libhello.a</code>，那么 使用第 <code>1</code> 条命令即可，如果是 动态库 <code>libhello.so</code>，那么仅指定 <code>-L. -lhello</code> 还不够，还需要指定 <code>-Wl,-rpath=.</code>，其他 <code>-Wl</code> 表示逗号之后的 option 均传给链接器 linker，<code>-rpath</code> 表示将动态库的目录嵌入到可执行体，这样运行时 loader 才能找到动态库。</p></li><li><p>设置 <code>LD_LIBRARY_PATH</code> 这个环境变量，使得 loader 在运行时尝试从这个环境变量指定的目录中寻找动态库。</p></li><li><p>将动态库目录添加至配置文件。配置文件通常为 <code>/etc/ld.so.conf</code>，在此文件中添加搜索路径条目，然后再执行 <code>ldconfig</code>。如果将动态库安装到 <code>/lib</code> 或 <code>/usr/lib</code> ，则不需要修改配置文件，只需要执行 <code>ldconfig</code>即可。</p></li></ol><p>注意：<code>LD_LIBRARY_PATH</code> 有副作用，不是一个好的方法，应尽量避免使用。</p><p>给 <code>-rpath</code> 选项赋值，有时候会使用 <code>$ORIGIN</code>，这个路径表示可执行体所在的目录，而 <code>.</code> 则表示当前的工作目录（编译链接命令执行的路径）。如果是在 Makefile 文件中，则需要写成 <code>-Wl,-rpath=&#39;$$ORIGIN&#39;</code>，在命令窗口中写成 <code>-Wl,-rpath=&#39;$ORIGIN&#39;</code>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++ 边学边忘——类型声明</title>
      <link href="/2021/07/05/cpp/type_declare/"/>
      <url>/2021/07/05/cpp/type_declare/</url>
      
        <content type="html"><![CDATA[<h1 id="const-与-constexpr"><a href="#const-与-constexpr" class="headerlink" title="const 与 constexpr"></a>const 与 constexpr</h1><p><code>const</code> 常量，一定定义后无法更改其值。</p><p><code>constexpr</code> 常量表达式，除了定义后无法更改其值，还必须是编译期可知的常量，或者说被 <code>constexpr</code> 修饰的变量需要有一个常量表达式的初始化器。</p><p>可被 <code>constexpr</code> 修饰的类型为 字面量类型，包括 数值型，引用，和指针类型（我们自定义的class类型则不属于字面量类型）。由于有编译期可知这一限制条件，<code>constexpr</code> 指针可以初始化为 <code>nullptr</code> 或者 <code>0</code>，以及具有固定地址的变量，对这些变量取址可对 <code>constexpr</code> 指针初始化。定义在函数外部的变量以及函数内部 <code>static</code> 修饰的变量具有固定地址。</p><p><code>constexpr</code> 指针：<code>constexprt</code> 关键字修饰指针自身，而非指针所指向对象，例：<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; 函数外部const int i &#x3D; 1;int j &#x3D; 2;constexpr int *q &#x3D; &amp;j;          &#x2F;&#x2F; OK, q 是常量指针，其存储的地址不可改变，但是可以修改其指向对象的值constexpr int *p &#x3D; &amp;i;          &#x2F;&#x2F; error，p 所执对象类型为 int，不能用 const int 来初始化constexpr const int *cp &#x3D; &amp;i;   &#x2F;&#x2F; OK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h1><p>直接看代码示例，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">typedef char *pstring;          &#x2F;&#x2F; pstring 为 char *const pstring cstr &#x3D; 0;         &#x2F;&#x2F; cstr 是常量指针，指向 char 类型对象const pstring *ps;              &#x2F;&#x2F; ps 是一个普通指针，指向 char * const 类型，即指向一个常量指针，这个常量指针指向 char 类型对象<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>注意：不可直接用 <code>char *</code> 替换！！！ </p><p><code>const</code> 修饰的是 <code>pstring</code>，由于 <code>pstring</code> 是指针，所以 <code>const pstring</code> 是常量指针，实际效果是 <code>char * const</code>。那你要问，既然 <code>const pstring cstr</code> 不是指向一个 const 对象，那么指向一个 const 对象 正确写法是什么？当然是 <code>typedef const char *cpstring</code>。</p><h1 id="auto"><a href="#auto" class="headerlink" title="auto"></a>auto</h1><p>由编译器根据初始化器来确定变量类型。简单场景这里不再讨论，需要注意一条声明仅包含一个基本类型，多个变量的初始化器类型不同将会报错。</p><h2 id="复合类型，const-和-auto"><a href="#复合类型，const-和-auto" class="headerlink" title="复合类型，const 和 auto"></a>复合类型，const 和 auto</h2><ol><li><p>使用引用类型作为初始化器时，实际使用的是被引用的对象，所以 <code>auto</code> 应该为被引用的对象类型</p></li><li><p><code>auto</code> 忽略 top-level 的 <code>const</code>，保留 low=level 的 <code>const</code>，如需保留 top-level <code>const</code>，显示声明 <code>const auto</code>，例</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">const int i &#x3D; 123;const int *const p &#x3D; &amp;i;auto x &#x3D; pi;                &#x2F;&#x2F; x 是普通指针，指向 const intconst auto cx &#x3D; pi;         &#x2F;&#x2F; cx 是常量指针，并指向 const int<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>指定 <code>auto</code> 的引用类型，此时 top-level <code>const</code> 不能忽略，这很好理解，因为 “引用” 指明不拷贝创建新对象，而绑定已有对象，如果忽略 top-level <code>const</code>，那么将导致通过引用来修改 <code>const</code> 对象。</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">const int i &#x3D; 123;  &#x2F;&#x2F; top-level constauto &amp;r &#x3D; i;    &#x2F;&#x2F; r 是 i 的引用，由于不能修改 i，所以 r 应该是 const int &amp; 类型，而不能是 int &amp; 类型。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>引用 <code>&amp;</code> 和指针 <code>*</code> 不是基础类型的一部分，而 <code>const</code> 是基础类型一部分，即 <code>int</code> 和 <code>const int</code> 基础类型不同，故不能声明</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">int i &#x3D; 123;const int j &#x3D; 234;auto &amp;r &#x3D; i, *p &#x3D; &amp;j    &#x2F;&#x2F; error. r 是 int &amp; 类型，p 是 const int * 类型，基础类型不一致，不能出现在同一声明中<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h1 id="decltype"><a href="#decltype" class="headerlink" title="decltype"></a>decltype</h1><p>编译器从表达式推断出类型，而不用实际计算表达式。</p><ol><li><p>decltype 应用到 变量 上，结果为 变量 的类型，包括 top-level <code>const</code> 和 引用符号</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">const int ci &#x3D; 123, &amp;cj &#x3D; ci;decltype(ci) x &#x3D; 0;             &#x2F;&#x2F; x 是 const intdecltype(cj) y &#x3D; x;             &#x2F;&#x2F; y 是 const int &amp;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>decltype 应用到 表达式 上，结果为 表达式 的类型。如果表达式生成可位于赋值左侧的对象，那么 <code>decltype(expr)</code> 结果为一引用类型</p></li></ol><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">int i &#x3D; 123, *p &#x3D; &amp;i, &amp;r &#x3D; i;decltype(r+1) b;                &#x2F;&#x2F; OK b 是 int 类型，由于 r+1 不是左值，所以 b 类型不是引用类型decltype(*p) c;                 &#x2F;&#x2F; error, c 是 int &amp; 类型，因为 *p 可用于左值（可被赋值）, c 未被初始化，所以报错<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol><li>如果变量被括号包围，例如 <code>(x)</code>，那么就是一个表达式了，此时 <code>decltype((x))</code> 结果为一引用类型</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>C++ 边学边忘——构造函数</title>
      <link href="/2021/06/28/cpp/constructor/"/>
      <url>/2021/06/28/cpp/constructor/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>C++ 边学边忘——字符（串）</title>
      <link href="/2021/06/25/cpp/string/"/>
      <url>/2021/06/25/cpp/string/</url>
      
        <content type="html"><![CDATA[<p>C++ 中的字符串编码。<br><span id="more"></span></p><h1 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h1><p>我们写的源码（source code）被保存在文件中，我们知道文件也是有编码格式的，例如打开微软的 VS 2019，新建一个C++ Console App，会自动生成一个 <code>ConsoleApplication1.cpp</code> 文件，这个文件的编码可以通过 VS 2019 的 “文件”菜单下的 “高级保存选项”命令进行设置（如果没有说明被 VS 隐藏了，请百度如何显示这个命令），默认是<code>GB2312</code>，可以把它改为 <code>utf-8</code> 等。vscode 中也可以更改文件编码，通过 <code>ctrl+shift+p</code> 打开命令搜索框，然后输入 <code>encode</code> 关键词，就有 <code>Change File Encoding</code> 命令出来，然后 vscode 右下角 也出现 <code>UTF-8</code>、<code>CRLF</code> 等按钮，可以直接点击进行修改。</p><p>这里强调一下，unicode 与 UTF-8 的关系，准确的讲，unicode 是字符集（也有编码，分 UCS2 和 UCS4 两种），UTF-8 是 unicode 的一种编码，是一种变长编码，但所覆盖的字符集范围与 unicode 是相同的，而 unicode 是定长编码，UTF-8 是为了便于传输（省流量）以及与 ASCII 兼容。编码 gb2312 与 UTF-8 两者对应的字符集不兼容。编码 GBK 兼容 gb2312，GBK 字符集是 gb2312 字符集的超集。编码 UTF-8 、GBK 和 gb2312 兼容 ASCII，而 unicode 不兼容 ASCII。关于字符集和编码的更多知识请百度。</p><p>对于一个源文件，我们可以在 Windows 上使用 ultraedit 或 UEStudio 来查看文件的十六进制数据，在 Linux 上使用 vim 打开源文件后，使用命令 <code>:%!xxd</code>，切换到十六进制，也可以使用命令 <code>hexdump &lt;filename&gt; -C</code> 查看文件的 16 进制数据。</p><blockquote><p>使用 vim <code>:%!xxd</code> 查看文件 16 进制时，发现 gb2312 的文件总是会先被转换为 utf-8 编码，导致查看的都是 utf-8 编码的 16 进制，由于对 vim 不是特别熟悉，不知道是什么原因。</p></blockquote><p>现在我们需要搞清楚的是：编译器读取源文件，将源文件中的字符映射得到编译时的字符，这个编译时字符集称为 <code>源字符集</code>，经过映射的字符作为预处理阶段的输入，经过预处理后，字符串和字符常量会再转换为 <code>执行字符集</code>，保存在可执行文件中。这里的映射均由编译器实现定义。</p><h2 id="源字符集"><a href="#源字符集" class="headerlink" title="源字符集"></a>源字符集</h2><p>Windows 上编译 C++ 使用 <code>cl.exe</code> 工具。默认使用当前活动页对应的编码作为 <code>源字符集</code>，可以使用 <code>chcp</code> 查看当前活动页，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&gt; chcpActive code page: 936<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>936 对应编码 <code>gb2312</code>。我们举一个例子说明，例如代码<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cppint main(int argc, char** argv) &#123;    wchar_t c &#x3D; L&#39;好&#39;;    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>使用 vs 2019 创建 Console App 项目后，直接将上面代码替换掉自动生成的代码，这里默认的源文件编码方式为 <code>gb2312</code>，在系统开始菜单中找到 Visual Studio 2019 文件夹，然后打开 <code>Developer Command Prompt for VS 2019</code>，输入以下命令进行预处理，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&gt; cd myproj&gt; cl main.cpp &#x2F;E &gt; main-gb2312.i<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>得到预处理后的文件 <code>main-gb2312.i</code> 编码为 <code>gb2312</code>，可以检测其中的中文 <code>好</code> 被编码为 <code>BAC3</code>。</p><p>当然我们还可以修改源文件的编码方式，在 VS 2019 文件菜单下的 “高级保存选项” 窗口，设置为 <code>UTF-8 with signature</code>，保存好后，再次执行预处理，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&gt; cl main.cpp &#x2F;E &gt; main-utf8-sig.i<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>得到预处理后的文件 <code>main-utf8-sig.i</code> 编码为 <code>gb2312</code>，可以检测其中的中文 <code>好</code> 被编码为 <code>BAC3</code>。</p><p>but，如果将源文件编码改为 <code>UTF-8 without signature</code>，那么源文件将是 <code>UTF-8</code> 编码，且 <code>cl.exe</code> 无法识别，此时采用默认的 <code>gb2312</code> 进行解码，那么将会导致编译出现意想不到的结果，甚至无法通过编译。在以上这个例子中，<code>好</code> 的 UTF-8 编码为 <code>E5A5BD</code>，后面一个字符单引号 <code>&#39;</code> 的UTF-8 编码为 <code>27</code>，而 <code>E5A5</code> 被 gb2312 错误的识别为 <code>濂</code>， 剩余的一个字节 <code>BD</code> 将会与后面的字节 <code>27</code> 连起来，但是这不是一个有效的 gb2312 字符编码，所以无法识别，预处理阶段，将它替换为一个问好 <code>?</code> 的编码 <code>3F</code>，这导致丢失了单引号字符 <code>&#39;</code>。我们使用 VS 直接编译这个源文件，报错如下，</p><p><img src="/images/cpp/string1.png" alt=""></p><p>有的时候，如果源码中出现的中文 utf-8 的编码全部处于 gb2312 编码范围内，那就不会报错，但却被编译器错误的识别为其他字符，导致程序能生成，但是执行结果不对。</p><p>那么，对于这个 <code>UTF-8 without signature</code> 的源文件，我们就无法处理了吗？</p><p>显然不是，一个是修改系统的 CODE PAGE 为 65001，这样，<code>源字符集</code> 默认就改成 UTF-8，肯定是可以的，预处理后的文件也是 <code>UTF-8</code> 编码的，但是这种方法牵一发而动全身，我们选用另一个方法， 即，通过命令行选项 <code>\source-charset:utf-8</code> 指定，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&gt; cl &#x2F;source-charset:utf-8 main.cpp &#x2F;E &gt; main-gb2312.i<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>Linux 上，我们以 GCC 为例，默认的 <code>源字符集</code> 为 UTF-8，预处理命令为<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -E main.cpp -o main-utf8.i<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>查看 <code>main-utf8.i</code> ，发现中文 <code>好</code> 编码为 <code>E5A5BD</code>，这说明确实是 UTF-8 编码。</p><p>使用 vscode 将源文件编码改为 <code>gb2312</code> ，继续执行命令 <code>gcc -E main.cpp -o main-gb2312.i</code>，查看 <code>main-gb2312.i</code>，发现中文 <code>好</code> 编码为 <code>BAC3</code>，这是 gb2312 编码，加入其他中文，发现全部都保留了 gb2312 编码，事实上，这是因为 gcc 默认按照 UTF-8 解码，在第一个单引号 <code>&#39;</code> 之后，遇到 <code>好&#39;</code>，其 gb2312 编码为 <code>BAC327</code>，但是 gcc 使用 UTF-8 解码时，被解码成一个<code>ڃ&#39;</code>，这是一个乱码后跟一个单引号，也就是说，<code>BAC3</code> 在 UTF-8 中是有对应字符的，所以本质上<font color="red">不是 gb2312 编码，而仍然是 UTF-8 编码</font>，将中文的 gb2312 编码按 UTF-8 解码势必出错，所以我们需要通过 gcc 的 <code>-finput-charset</code> 命令选项来指出源文件的编码，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -finput-charset&#x3D;gb2312 -E main.cpp -o main-gb2312-ic.i<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>注意这个选项仅用于指出源文件编码，而生成的预处理文件 <code>main-gb2312-ic.i</code> 仍然是 UTF-8 编码，可以发现，中文 <code>好</code> 的编码为 <code>E5A5BD</code>。GCC 中 <code>源字符集</code> 为 UTF-8，本人暂时没有找到可以更改 gcc <code>源字符集</code> 的方法。</p><blockquote><p>查询 UTF-8 编码可使用 <a href="https://www.branah.com/unicode-converter">https://www.branah.com/unicode-converter</a> ， 查询 gb2312 编码可使用 <a href="https://www.qqxiuzi.cn/bianma/zifuji.php">https://www.qqxiuzi.cn/bianma/zifuji.php</a> 。</p></blockquote><h2 id="执行字符集"><a href="#执行字符集" class="headerlink" title="执行字符集"></a>执行字符集</h2><p>预处理之后进行编译，字符串和字符常量将会被转换为 <code>执行字符集</code>，根据<a href="https://docs.microsoft.com/en-us/cpp/build/reference/execution-charset-set-execution-character-set?view=msvc-160">微软官方说明</a>，<code>执行字符集</code> 是对文本进行编码然后作为在预处理之后的后续编译阶段的输入。</p><p>在 VS 上，可以使用 <code>/execution-charset:&lt;charset&gt;</code> 命令选项进行设置，在 GCC 上可以设置命令选项 <code>-fexec-charset=&lt;charset&gt;</code> ，对于宽字符，则需要设置 <code>-fwide-exec-charset=&lt;charset&gt;</code>。</p><p>以 GCC 为例（Ubuntu 上），首先修改源码如下，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cppint main(int argc, char** argv) &#123;    char c &#x3D; &#39;好&#39;;    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>这里变量 <code>c</code> 的类型改为 char 类型，然后编译，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c main.cpp -o main.o$ objdump -Sr main.of:  c6 45 ff bd    movb    $0xbd,-0x1(%rbp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>注意到 <code>0xbd</code> 就是 <code>好</code> 的 utf-8 编码 <code>E5A5BD</code> 的低位的第一个字节，因为 char 类型只能存储一个字节，其他字节被截掉。现在加上 <code>执行字符集</code> 命令选项，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c main.cpp -o main.o -fexec-charset&#x3D;gb2312$ objdump -Sr main.of:  c6 45 ff c3     movb    $0xc3,-0x1(%rbp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>这里 <code>0xc3</code> 是 <code>好</code> 的 gb2312 编码 <code>BAC3</code> 的低位字节。现在将源码改为，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cppint main(int argc, char** argv) &#123;    wchar_t c &#x3D; &#39;好&#39;;    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>注意这里字符字面量没有前缀 <code>L</code>，编译和反编译如下，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c main.cpp -o main.o$ objdump -Sr main.of:  c7 45 fc bd a5 e5 00    movl    $0xe5a5bd,-0x4(%rbp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>可见 <code>好</code> 编码为 UTF-8 的 <code>E5A5BD</code>。加上 <code>执行字符集</code> 命令选项，那么有<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c main.cpp -o main.o -fexe-charset&#x3D;gb2312$ objdump -Sr main.of:  c7 45 fc c3 ba 00 00    movl    $0xbac3,-0x4(%rbp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>这与预料的一样，<code>好</code> 编码为 gb2312 的 <code>BAC3</code>。现在我们继续修改源码，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cppint main(int argc, char** argv) &#123;    wchar_t c &#x3D; L&#39;好&#39;;    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>不使用 <code>源字符集</code> 命令选项，结果为，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c main.cpp -o main.o$ objdump -Sr main.of:  c7 45 fc 7d 59 00 00    movl    $0x597d,-0x4(%rbp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>这个 <code>0x597d</code> 为 <code>好</code> 的 UTF-32 编码。不难想象，如果源码改为 <code>char = L&#39;好&#39;</code>，那么目标文件中只有 <code>好</code> 的 UTF-32 编码的低位字节，即 <code>7D</code>，这个可以自己试一下。</p><p>这是因为带 <code>L</code> 前缀的字符（串）字面量的默认 <code>执行字符集</code> 为 <code>UTF-32</code> （我这里的 wchar_t 为 4 字节，如果是 2 字节，那么对应 <code>执行字符集</code> 为 <code>UTF-16</code>）。我们现在增加 <code>-fwide-exec-charset</code> 命令选项修改 <strong>宽</strong> 字符（串）字面量的 <code>执行字符集</code>，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ gcc -c main.cpp -o main.o -fwide-exec-charset&#x3D;gb2312$ objdump -Sr main.of:  c7 45 fc 00 00 ba c3   movl    $0xc3ba0000,-0x4(%rbp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>可见确实将宽字符编码为 <code>gb2312</code>。</p><p>总结：</p><ol><li><code>-fexec-charset</code> 改变窄字符（例如 <code>&#39;好&#39;</code>）的字符集</li><li><code>-fwide-exec-char</code> 改变宽字符（带前缀 <code>L</code>）的字符集</li><li>GCC 默认，窄字符的 <code>执行字符集</code> 为 <code>UTF-8</code>，宽字符的 <code>执行字符集</code> 为 <code>UTF-32</code></li></ol><p>可以使用如下源码试一试，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cppint main(int argc, char** argv) &#123;    wchar_t c &#x3D; L&#39;好&#39;;      &#x2F;&#x2F; -fwide-exec-charset&#x3D;gb2312    wchar_t d &#x3D; &#39;好&#39;;       &#x2F;&#x2F; -fexec-charset&#x3D;gb2312    char32_t e &#x3D; U&#39;好&#39;;     &#x2F;&#x2F; 宽字符，对应 -fwide-exec-charset 命令选项    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h1><p>本节内容以 GCC 作为编译器进行讨论说明。现在我们来看字符（串）的输出。给出测试代码如下，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cpp#include &lt;stdio.h&gt;int main(int argc, char** argv) &#123;    wchar_t a &#x3D; L&#39;好&#39;;    char32_t b &#x3D; U&#39;好&#39;;    char c &#x3D; &#39;好&#39;;    int d &#x3D; 0x597D;    wint_t e &#x3D; 0x597D;    printf(&quot;a-&gt;%c, b-&gt;%c, c-&gt;%c, d-&gt;%c, e-&gt;%c\n&quot;, a, b, c, d, e);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>生成命令如下，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ g++ main.cpp -o main$ .&#x2F;maina-&gt;&#125;, b-&gt;&#125;, c-&gt;?, d-&gt;&#125;, e-&gt;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br><code>c</code> 打印为乱码（这里乱码使用 问号 <code>?</code> 表示，这里乱码仅指无法识别为 ASCII 和 中文的意思），<code>a,b,d,e</code> 打印为右大括号 <code>&#125;</code>，这很好理解，参考 <a href="http://www.cplusplus.com/reference/cstdio/printf/">printf 函数格式串说明</a>，<code>a,b</code> 在执行文件中才有 UTF-32 编码 <code>597D</code>，与 <code>d,e</code> 相同，在格式化过程时先被转换为了 char 类型，即 <code>7D</code>，这是 <code>&#125;</code> 的 ASCII。<code>c</code> 保存了 <code>好</code> 的 UTF-8 编码的低位字节（GCC 中窄字符采用 UTF-8 编码）， 为 <code>BD</code>（等效于设置 <code>char c = 0xBD</code>），超出了 <code>%c</code> 的有效范围（127），在 ASCII 的扩展字符集（即 128~255）中才有，我们应该明确避免这种打印超过范围字符。可以改为 <code>wchar_t c=0xBD</code>，并使用 <code>%lc</code> 来打印这个 ASCII 扩展字符，同样的 <code>好</code> 的编码值也超出了 <code>char</code> 类型的有效范围，故上面使用 <code>wchar_t</code> 类型变量保存，同时也应该改为使用 <code>%lc</code> 打印。这里需要说明，C 程序执行时默认使用标准的 <code>C</code> locale，这个 locale 使得在终端上无法正常显示宽字符，而显示乱码，可以增加 locale 设置语句，可以使用指令 <code>locale</code> 查看系统相关配置，打印代码如下，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;wchar.h&gt;int main(int argc, char** argv) &#123;    setlocale(LC_CTYPE, &quot;&quot;);    &#x2F;&#x2F; 对应宽字符，即，字符串字面量有 L, u, U 前缀，指示使用系统当前 locale。    wchar_t a &#x3D; L&#39;好&#39;;    char32_t b &#x3D; U&#39;好&#39;;    wchar_t c &#x3D; 0xBD;   &#x2F;&#x2F; ASCII 扩展字符    int d &#x3D; 0x597D;    wint_t e &#x3D; 0x597D;    printf(&quot;a-&gt;%lc, b-&gt;%lc, c-&gt;%lc, d-&gt;%lc, e-&gt;%lc\n&quot;, a, b, c, d, e);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>结果为<br><pre class="line-numbers language-none"><code class="language-none">a-&gt;好, b-&gt;好, c-&gt;½, d-&gt;好, e-&gt;好<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>注意这里打印 <code>c</code> 变量使用 <code>%lc</code>，以宽字符形式打印，打印结果为 <code>½</code>（分数 1/2），可以查看 <a href="https://www.w3school.com.cn/charsets/ref_html_8859.asp">扩展 ASCII 表</a>。另外注意到 <code>好</code> 使用 unicode 编码值 <code>597D</code>，所以如果 <code>wchar_t c=0xE5A5BD</code>（ UTF-8 编码值），那么将无法在终端正确打印 <code>好</code>。可能有人会好奇，前面说 GCC 中 <code>exec-charset</code> 默认为 <code>UTF-8</code>，为什么 <code>UTF-8</code> 编码值就无法用来打印字符呢？</p><p>因为 <code>exec-charset</code> 是对应窄字符的，所以不能使用 <code>%lc</code> 来打印，但是我们可以使用 <code>%s</code> 来打印，即打印字符串，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;locale.h&gt;#include &lt;wchar.h&gt;#include &lt;stdio.h&gt;int main(int argc, char** argv) &#123;    setlocale(LC_CTYPE, &quot;&quot;);    &#x2F;&#x2F; 显示宽字符时，使用系统当前 locale。这使得变量 &#96;a,b,g&#96; 可以被正确打印    const wchar_t* a &#x3D; L&quot;好&quot;;    const char32_t* b &#x3D; U&quot;好&quot;;    const char* c &#x3D; &quot;好&quot;;    const char* d &#x3D; &quot;\xE5\xA5\xBD&quot;;    unsigned char e[4] &#x3D; &#123;0xE5, 0xA5, 0xBD&#125;;    const char f[4] &#x3D; &#123;&#39;\xE5&#39;, &#39;\xA5&#39;, &#39;\xBD&#39;&#125;;    const char32_t* g &#x3D; U&quot;\x597D&quot;;    printf(&quot;a-&gt;%ls, b-&gt;%ls, c-&gt;%s, d-&gt;%s, e-&gt;%s, f-&gt;%s, g-&gt;%ls\n&quot;, a, b, c, d, e, f, g);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>其中，<code>c</code> 对应 <code>%s</code>，用于打印窄字符，而 <code>a,b</code> 均需要用 <code>%ls</code> 来打印宽字符（否则无法正确打印），我们不能搞混，否则可能无法正常打印。</p><p>结果为<br><pre class="line-numbers language-none"><code class="language-none">a-&gt;好, b-&gt;好, c-&gt;好, d-&gt;好, e-&gt;好, f-&gt;好， g-&gt;好<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>上面，<code>d,f</code> 是字符串 <code>&quot;好&quot;</code> 的 16 进制表示（UTF-8 编码），<code>e</code> 存储了 <code>好</code> 和 <code>\0</code> 两个字符，其中 <code>好</code> 依然是 UTF-8 编码。<code>d,e,f</code> 变量的字符串打印使用 <code>%s</code>，如上结果所示，可正常打印。此外，<code>d,f</code> 可以直接打印，即 <code>printf(d);printf(f);</code>。</p><p>上面代码中，我又增加了一个变量 <code>g</code>，如果要用 <code>0x</code> 形式的字符串，那么需要注意，<code>0x</code> 后面只能跟两个16进制数，因为 char 类型是 8 bit，如果后面的 16 进制数多于两个，那么需要增加前缀 <code>L</code> 或者 <code>U</code>（64 bit ，对于 32 bit，则使用 <code>u</code> 前缀），且打印的指示器 specifier 使用 <code>%ls</code>。</p><blockquote><ol><li><p>可以使用 printf(“%x\n”, a); 打印一个字符变量的 16 进制值。</p></li><li><p>GCC 中不要混用 <code>printf</code> 和 <code>wprintf</code>，相关知识点可搜索 <code>fwide</code> 函数.</p></li></ol></blockquote><h2 id="C-打印"><a href="#C-打印" class="headerlink" title="C++ 打印"></a>C++ 打印</h2><p>C++ 中，我们还可以使用 <code>cout</code> 打印字符串，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;iostream&gt;int main(int argc, char** argv) &#123;    const char* a &#x3D; &quot;好&quot;;    std::cout &lt;&lt; a &lt;&lt; &quot;-好&quot; &lt;&lt; std::endl;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>注意不要使用 <code>std::cout &lt;&lt; &#39;好&#39;;</code> 打印字符 <code>好</code>，<code>&#39;好&#39;</code> 表示窄字符，使用 UTF-8 编码为 <code>E5A5BD</code>，这显然超出 char 有效范围，<code>std::cout &lt;&lt; &#39;好&#39;;</code> 将会打印出 <code>15050173</code>，此即 <code>E5A5BD</code> 的十进制表示。</p><p>使用 <code>wcout</code> 打印，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;wchar.h&gt;int main(int argc, char** argv) &#123;    const w_char* a &#x3D; L&quot;好&quot;;    std::wcout &lt;&lt; a &lt;&lt; L&quot;-好&quot; &lt;&lt; std::endl;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>以上代码无法正确打印宽字符（仅 ASCII 字符 <code>-</code> 被正确打印）。<br>GCC 对于窄字符，使用 <code>UTF-8</code> 编码，而我的系统终端（Ubuntu terminal）的 <code>locale</code> 命令显示使用的是 <code>LC_CTYPE=en_US.UTF-8</code>，所以可以直接打印。如果使用使用 <code>std::wcout</code> 宽字符形式打印，由于宽字符使用 <code>UTF-32</code>（UCS2 还是 UCS4，取决于系统），所以还需要指示 <code>std::wcout</code> 进行转换，转换的目标字符集根据 <code>locale</code> 设置获得，这样才能与终端所用字符集匹配，代码如下，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;wchar.h&gt;#include &lt;locale&gt;int main(int argc, char** argv) &#123;    std::setlocale(LC_CTYPE, &quot;&quot;);       &#x2F;&#x2F; 或者使用下一句进行 C++ 的全局设置，也行    &#x2F;&#x2F; std::locale::global(std::locale(&quot;&quot;));    const w_char* a &#x3D; L&quot;好&quot;;    std::wcout &lt;&lt; a &lt;&lt; L&quot;-好&quot; &lt;&lt; std::endl;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python C/C++ Extension Type</title>
      <link href="/2021/06/16/python/ext3/"/>
      <url>/2021/06/16/python/ext3/</url>
      
        <content type="html"><![CDATA[<p>python 的 C/C++ 扩展类型简介。<br><span id="more"></span><br>每个 Python 对象均是 <code>PyObject*</code> 的变体，<code>PyObject</code> 仅包含 引用计数 以及 类型对象的指针。因为 Python 是动态类型语言，每个对象自身包含了其类型，这个 类型对象决定了可以用 Python 解释器 对这个对象调用哪些函数，例如获取对象的属性，调用对象方法等。要定义一个新对象，需要创建一个新的类型对象。例子，</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PY_SSIZE_T_CLEAN</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;Python.h></span></span><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token punctuation">&#123;</span>    PyObject_HEAD    <span class="token comment">/* Type-specific fields go here. */</span><span class="token punctuation">&#125;</span> CustomObject<span class="token punctuation">;</span><span class="token keyword">static</span> PyTypeObject CustomType <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token function">PyVarObject_HEAD_INIT</span><span class="token punctuation">(</span><span class="token constant">NULL</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span>tp_name <span class="token operator">=</span> <span class="token string">"custom.Custom"</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_doc <span class="token operator">=</span> <span class="token string">"Custom objects"</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_basicsize <span class="token operator">=</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>CustomObject<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_itemsize <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_flags <span class="token operator">=</span> Py_TPFLAGS_DEFAULT<span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_new <span class="token operator">=</span> PyType_GenericNew<span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token keyword">static</span> PyModuleDef custommodule <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    PyModuleDef_HEAD_INIT<span class="token punctuation">,</span>    <span class="token punctuation">.</span>m_name <span class="token operator">=</span> <span class="token string">"custom"</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>m_doc <span class="token operator">=</span> <span class="token string">"Example module that creates an extension type."</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>m_size <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span>PyMODINIT_FUNC<span class="token function">PyInit_custom</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    PyObject <span class="token operator">*</span>m<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">PyType_Ready</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>CustomType<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    m <span class="token operator">=</span> <span class="token function">PyModule_Create</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>custommodule<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>m <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    <span class="token function">Py_INCREF</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>CustomType<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">PyModule_AddObject</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token string">"Custom"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>PyObject <span class="token operator">*</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>CustomType<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">Py_DECREF</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>CustomType<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">Py_DECREF</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> m<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述代码，首先定义了一个结构体，表示自定义对象，<br><code>CustomObject</code> 结构体中，<code>PyObject_HEAD</code> 是强制必须有的，且在结构体第一个位置，这个宏定义了 <code>ob_base</code> 字段，类型为 <code>PyObject</code>，这个字段中包含一个类型对象 <code>ob_type</code> 和一个引用计数 <code>ob_refcnt</code>，可以分别使用 <code>Py_TYPE</code> 和 <code>Py_REFCNT</code> 进行访问。<code>PyObject_HEAD</code> 之后可以列出类型的其他字段，例如<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token punctuation">&#123;</span>    PyObject_HEAD    <span class="token keyword">double</span> ob_fval<span class="token punctuation">;</span><span class="token punctuation">&#125;</span> PyFloatObject<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>然后是对象的类型定义（这个类型本身也是一个对象），<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyTypeObject CustomType <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token function">PyVarObject_HEAD_INIT</span><span class="token punctuation">(</span><span class="token constant">NULL</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span>tp_name <span class="token operator">=</span> <span class="token string">"custom.Custom"</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_doc <span class="token operator">=</span> <span class="token string">"Custom objects"</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_basicsize <span class="token operator">=</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>CustomObject<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_itemsize <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_flags <span class="token operator">=</span> Py_TPFLAGS_DEFAULT<span class="token punctuation">,</span>    <span class="token punctuation">.</span>tp_new <span class="token operator">=</span> PyType_GenericNew<span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>这里使用的是 C99 的初始化风格，这样不用列出所有的字段，且不用考虑字段的顺序，实际上 <code>PyTypeObject</code> 有很多的字段，上面没有列出来的字段，均由编译器初始化为 <code>0</code>。如果不使用 C99 初始化风格，那么将会是，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyTypeObject CustomType <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token function">PyVarObject_HEAD_INIT</span><span class="token punctuation">(</span><span class="token constant">NULL</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token string">"custom.Custom"</span><span class="token punctuation">,</span>    <span class="token string">"Custom objects"</span><span class="token punctuation">,</span>    <span class="token keyword">sizeof</span><span class="token punctuation">(</span>CustomObject<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    Py_TPFLAGS_DEFAULT<span class="token punctuation">,</span>    PyType_GenericNew<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>来依次分析，<br><pre class="line-numbers language-none"><code class="language-none">PyVarObject_HEAD_INIT(NULL, 0)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>这句是强制的，用于初始化 <code>ob_base</code>，这个宏是初始化可变对象的头部，宏定义为<br><pre class="line-numbers language-none"><code class="language-none">#define PyVarObject_HEAD_INIT(type, size) 1, type, size,<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><pre class="line-numbers language-none"><code class="language-none">.tp_name &#x3D; &quot;custom.Custom&quot;, # 类型名.tp_basicsize &#x3D; sizeof(CustomObject),   # 指示如何分配内存.tp_itemsize &#x3D; 0,   # 可变大小的对象用到，不可变大小例如 bool，int，则为0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">.tp_new &#x3D; PyType_GenericNew,<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>提供一个 <code>tp_new</code> 句柄，等价于 <code>__new__()</code>，用于创建对象，<code>PyType_GenericNew</code> 是创建对象的默认实现。</p><h2 id="添加数据成员和方法"><a href="#添加数据成员和方法" class="headerlink" title="添加数据成员和方法"></a>添加数据成员和方法</h2><p>参考<a href="https://docs.python.org/3.9/extending/newtypes_tutorial.html">官方文档</a></p><h1 id="循环垃圾回收"><a href="#循环垃圾回收" class="headerlink" title="循环垃圾回收"></a>循环垃圾回收</h1><p>循环垃圾回收机制使得 Python 可以识别 引用计数不为 0 但是已经不再需要的对象，并将其回收，例如<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">>></span><span class="token operator">></span> l<span class="token punctuation">.</span>append<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">del</span> l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>当删除 <code>l</code> 这个列表时，它仍然有引用，引用计数不为 0，但是 Python 的循环垃圾回收器可以识别并释放这个对象。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python C/C++ Extension（二）</title>
      <link href="/2021/06/16/python/ext2/"/>
      <url>/2021/06/16/python/ext2/</url>
      
        <content type="html"><![CDATA[<p>python 的 C/C++ 扩展使用说明（二）。<br><span id="more"></span></p><h1 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h1><p>C/C++ 动态申请的内存，需要手动释放，否则出现内存泄漏。同时已经释放掉的内存块，不可以再次使用。Python 中采取的策略是引用计数，原理：每个对象包含一个计数器，当对象的一个引用被存储，那么增加一次计数，当对象的一个引用被删除，则减小一次计数，当计数归 0，表示对象的最后一个引用被删除，此时是否对象所占内存。</p><p>另一种策略是自动垃圾回收，这种策略的优点是使用者无需显式调用 <code>free()</code> 释放内存，缺点是 C 中没有一个真正的轻便的自动垃圾回收器，而引用计数则可以很方便的实现。</p><h2 id="Python-中的引用计数"><a href="#Python-中的引用计数" class="headerlink" title="Python 中的引用计数"></a>Python 中的引用计数</h2><p><code>Py_INCREF(x)</code> 和 <code>Py_DECREF(x)</code> 这两个宏，用于增加和减小计数。当计数将为 0 时，<code>Py_DECREF(x)</code> 会释放对象。如何使用这两个宏？</p><p>为此我们需要弄清楚一些概念。我们不直接拥有对象，而是拥有对象的一个引用，对象的引用计数就是拥有引用的数量。当引用不再被需要时，引用的拥有者负责调用 <code>Py_DECREF()</code> 。引用的拥有关系可以被转移。有三种方式处置所拥有的引用：1. 将引用转移；2. 存储引用；3. 调用 <code>Py_DECREF()</code>。不处理引用将导致内存泄漏。</p><p>可以借用一个对象的引用，但是借方不能比这个引用的拥有者存活更久。通过调用 <code>Py_INCREF()</code>，这个出借的引用可以变成借方拥有的引用，这不影响原先拥有者的状态。</p><h2 id="拥有关系规则"><a href="#拥有关系规则" class="headerlink" title="拥有关系规则"></a>拥有关系规则</h2><p>大部分返回对象引用的函数，都是转移引用的拥有关系。具体而言，所有用于创建一个新对象的函数，例如 <code>PyLong_FromLong()</code> 和 <code>Py_BuildValue()</code>，将拥有关系转移给接收者。</p><p>当你将一个对象引用传递给一个函数时，通常，函数是向你借用引用，如果函数需要存储这个引用，那么它将使用 <code>Py_INCREF()</code>，从而成为一个独立的引用拥有者。</p><p>python 中调用一个 C 函数时，C 函数从调用者那里借用对象引用。调用者拥有引用，在 C 函数中，引用的生命周期可以得到保证。</p><h1 id="为扩展模块提供-C-API"><a href="#为扩展模块提供-C-API" class="headerlink" title="为扩展模块提供 C API"></a>为扩展模块提供 C API</h1><p>大多数时候扩展模块的函数都是在 Python 中使用，但是有时候扩展模块的函数可以在另一个扩展模块中使用。例如，一个扩展模块中可以实现一个类似 <code>list</code> 的集合类型，但是元素是无序的，这个新集合类型包含一些 C 函数，可以在其他扩展模块中直接使用。</p><p>乍一看好像很简单，C 函数不再声明 static 即可。这在扩展模块静态链接至 Python 解释器时有效，如果扩展模块是动态链接库，那么一个模块中的符号在另一个模块中将不可见。</p><p>所以我们不应该对符号可见性有任何预先设定，所以除了模块初始化函数，其他符号都应该声明为 <code>static</code>，以避免名称冲突。Python 提供一个特殊机制以实现 C level 的信息传输————从一个扩展模块到另一个扩展模块————胶囊。胶囊是一个Python 数据类型，存储了一个 <code>void *</code> 类型指针，胶囊仅在它的 C API 中被创建和访问，无法传递到其他 Python 对象。每个胶囊在扩展模块的命名空间里有自己的名称，其他扩展模块可以导入这个扩展模块，然后得到胶囊的名称，从而获取胶囊的指针。</p><p>用于导出 C API 的胶囊应该遵循以下命名规则：<br><pre class="line-numbers language-none"><code class="language-none">modulename.attributename<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>以一个例子说明，<br><pre class="line-numbers language-CPP" data-language="CPP"><code class="language-CPP">static intPySpam_System(const char *command)&#123;    return system(command);&#125;static PyObject *spam_system(PyObject *self, PyObject *args)&#123;    const char *command;    int sts;    if (!PyArg_ParseTuple(args, &quot;s&quot;, &amp;command))        return NULL;    sts &#x3D; PySpam_System(command);    return PyLong_FromLong(sts);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>紧接着 <code>#include &lt;Python.h&gt;</code> 之后添加<br><pre class="line-numbers language-none"><code class="language-none">#define SPAM_MODULE#include &quot;spammodule.h&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>然后定义模块初始化函数，<br><pre class="line-numbers language-CPP" data-language="CPP"><code class="language-CPP">PyMODINIT_FUNCPyInit_spam(void)&#123;    PyObject *m;    static void *PySpam_API[PySpam_API_pointers];    PyObject *c_api_object;    m &#x3D; PyModule_Create(&amp;spammodule);    if (m &#x3D;&#x3D; NULL)        return NULL;    &#x2F;* Initialize the C API pointer array *&#x2F;    PySpam_API[PySpam_System_NUM] &#x3D; (void *)PySpam_System;    &#x2F;* Create a Capsule containing the API pointer array&#39;s address *&#x2F;    c_api_object &#x3D; PyCapsule_New((void *)PySpam_API, &quot;spam._C_API&quot;, NULL);    if (PyModule_AddObject(m, &quot;_C_API&quot;, c_api_object) &lt; 0) &#123;        Py_XDECREF(c_api_object);        Py_DECREF(m);        return NULL;    &#125;    return m;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><code>spammodule.h</code> 头文件内容如下，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifndef</span> <span class="token expression">Py_SPAMMODULE_H</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">Py_SPAMMODULE_H</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifdef</span> <span class="token expression">__cplusplus</span></span><span class="token keyword">extern</span> <span class="token string">"C"</span> <span class="token punctuation">&#123;</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span><span class="token comment">/* Header file for spammodule */</span><span class="token comment">/* C API functions */</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PySpam_System_NUM</span> <span class="token expression"><span class="token number">0</span></span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PySpam_System_RETURN</span> <span class="token expression"><span class="token keyword">int</span></span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PySpam_System_PROTO</span> <span class="token expression"><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>command<span class="token punctuation">)</span></span></span><span class="token comment">/* Total number of C API pointers */</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PySpam_API_pointers</span> <span class="token expression"><span class="token number">1</span></span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifdef</span> <span class="token expression">SPAM_MODULE</span></span><span class="token comment">/* This section is used when compiling spammodule.c */</span><span class="token keyword">static</span> PySpam_System_RETURN PySpam_System PySpam_System_PROTO<span class="token punctuation">;</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">else</span></span><span class="token comment">/* This section is used in modules that use spammodule's API */</span><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span>PySpam_API<span class="token punctuation">;</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PySpam_System</span> <span class="token punctuation">\</span> <span class="token expression"><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token function">PySpam_System_RETURN</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span>PySpam_System_PROTO<span class="token punctuation">)</span> PySpam_API<span class="token punctuation">[</span>PySpam_System_NUM<span class="token punctuation">]</span><span class="token punctuation">)</span></span></span><span class="token comment">/* Return -1 on error, 0 on success. * PyCapsule_Import will set an exception if there's an error. */</span><span class="token keyword">static</span> <span class="token keyword">int</span><span class="token function">import_spam</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    PySpam_API <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">PyCapsule_Import</span><span class="token punctuation">(</span><span class="token string">"spam._C_API"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>PySpam_API <span class="token operator">!=</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifdef</span> <span class="token expression">__cplusplus</span></span><span class="token punctuation">&#125;</span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span> <span class="token comment">/* !defined(Py_SPAMMODULE_H) */</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>客户端模块内容如下，<br><pre class="line-numbers language-CPP" data-language="CPP"><code class="language-CPP">PyMODINIT_FUNCPyInit_client(void)&#123;    PyObject *m;    m &#x3D; PyModule_Create(&amp;clientmodule);    if (m &#x3D;&#x3D; NULL)        return NULL;    if (import_spam() &lt; 0)        return NULL;    &#x2F;* additional initialization can happen here *&#x2F;    return m;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python C/C++ Extensions（一）</title>
      <link href="/2021/06/15/python/ext1/"/>
      <url>/2021/06/15/python/ext1/</url>
      
        <content type="html"><![CDATA[<p>python 的 C/C++ 扩展使用说明（一）。<br><span id="more"></span><br>本文假设已经熟悉了 Python 的基本知识。 对于 Python 的更多介绍，可参考<a href="https://docs.python.org/3/tutorial/index.html#tutorial-index"> The Python Tutorial</a>。 <a href="https://docs.python.org/3/reference/index.html#reference-index">The Python Language Reference</a> 提供了更多关于 Python 语言的介绍。<a href="https://docs.python.org/3/library/index.html#library-index">The Python Standard Library</a> 则归档了 Python 对象类型，函数以及模块。 </p><p>如要获取更全面的 Python/C API, 请参考 <a href="https://docs.python.org/3/c-api/index.html#c-api-index">Python/C API Reference Manual</a>。</p><p>有很多第三方工具可用来创建 python 扩展，例如 Cython， cffi， SWIG 以及 Numba，但这里不借助这些第三方工具。</p><h1 id="使用-C-C-扩展-Python"><a href="#使用-C-C-扩展-Python" class="headerlink" title="使用 C/C++ 扩展 Python"></a>使用 C/C++ 扩展 Python</h1><p>Python API 定义了一系列的 函数，宏 以及变量用以访问 Python 运行时系统，方便扩展。Python API 包含在头文件 <code>Python.h</code> 中。</p><p>举一个例子，创建 <code>spam</code> 扩展模块，其中提供对应于 C 语言库函数 <code>system()</code> 的 python 接口。这个库函数的参数为 null 结尾的字符串，函数返回为一个整数。我们希望 <code>spam</code> 模块中这个接口使用形式为，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> spam<span class="token operator">>></span><span class="token operator">></span> status <span class="token operator">=</span> spam<span class="token punctuation">.</span>system<span class="token punctuation">(</span><span class="token string">"ls -l"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>首先创建一个文件 <code>spammodule.c</code>，这个源文件中实现 <code>spam</code> 模块，头两行代码为<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">PY_SSIZE_T_CLEAN</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;Python.h></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>注意：Python 中可能会包含一些预处理定义，这些定义会影响其他标准头文件，所以通常第一个包含 <code>&lt;Python.h&gt;</code>，然后再考虑包含其他头文件。此外，推荐定义 <code>PY_SSIZE_T_CLEAN</code> 宏。</p><p>下一步定义一个 C 函数，当调用 <code>spam.system(string)</code> 时，这个 C 函数将被调用，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyObject <span class="token operator">*</span><span class="token function">spam_system</span><span class="token punctuation">(</span>PyObject <span class="token operator">*</span>self<span class="token punctuation">,</span> PyObject <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>command<span class="token punctuation">;</span>    <span class="token keyword">int</span> sts<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">PyArg_ParseTuple</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> <span class="token string">"s"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>command<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    sts <span class="token operator">=</span> <span class="token function">system</span><span class="token punctuation">(</span>command<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token function">PyLong_FromLong</span><span class="token punctuation">(</span>sts<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>这个 C 函数有两个参数，按惯例命名为 <code>self</code> 和 <code>args</code>，其中 <code>self</code> 对模块级别的函数而言表示 模块对象自身，对于 类方法而言表示 类实例自身；<code>args</code> 指向 Python 元组对象，这个元组包含了函数参数，元组中每个 item 均为 Python 对象，需要将他们转为 C 类型值，才能调用 C 函数 <code>system()</code>，使用 <code>PyArg_ParseTuple</code> 完成这种转换，如果元组中每个 item 均转换成功，那么返回 true。</p><h2 id="错误和异常"><a href="#错误和异常" class="headerlink" title="错误和异常"></a>错误和异常</h2><p>当函数调用失败，设置一个异常，并返回一个错误值（通常为 <code>NULL</code>），异常保存再一个静态全局变量中，如果这个变量为 <code>null</code>，那么说明没有异常发生。第二个全局变量存储了异常的关联值 （raise 中第二个参数：<code>raise expr from expr</code> 中后一个 <code>expr</code>，表示原始异常对象），第三个变量包含了堆栈的 traceback 信息，这三个变量是 Python 中执行 <code>sys.exc_info()</code> 返回结果的 C 等价体。</p><p>Python API 中有一系列的函数用于设置异常类型。最常见的是 <code>PyErr_SetString()</code>，参数是一个异常对象和一个 C 字符串，其中 异常对象通常是预定义类型对象，例如 <code>PyExc_ZeroDivisionError</code>，C 字符串表明错误原因。调用这个函数就完成了异常设置（相当于 python 中抛出异常）。</p><p>我们可以使用 <code>PyErr_Occurred()</code> 测试是否有异常发生，如有，则返回异常对象，否则返回 <code>NULL</code>。</p><p>当调用了 函数 <code>g</code> 的函数 <code>f</code> 检测出 <code>g</code> 函数调用失败，<code>f</code> 应该返回一个错误值 <code>NULL</code> 或者 <code>-1</code>，而不需要调用 <code>PyErr_*()</code> 函数来设置异常，因为在 <code>g</code> 中已经设置过。调用 <code>f</code> 的函数也应该返回一个错误值，同样不需要调用 <code>PyErr_*()</code>。</p><p>通过显示调用 <code>PyErr_Clear()</code> 可以忽略异常。调用 <code>malloc</code> 或者 <code>realloc</code> 失败时，需要设置异常，调用 <code>PyErr_NoMemory</code>。所有的创建对象的函数（例如 <code>PyLong_FromLong()</code> 已经实现了这个规则，这里说明一下，仅是为了针对那些直接调用  <code>malloc</code> 或者 <code>realloc</code> 的地方，在调用失败时不要忘记设置 <code>PyErr_NoMemory</code>。</p><p>注意，除了 <code>PyArg_ParseTuple()</code> 以及其他类似的函数之外，其他返回一个整型状态值的函数都在执行成功时返回一个非负值，在执行失败时，返回 <code>-1</code>，这与 Unix 系统类似。</p><p>最后需要注意，当返回一个错误值时，需要对我们自己创建的对象清除和垃圾回收（调用 <code>Py_XDECREF()</code> 或者 <code>Py_DECREF()</code>）。</p><p>有很多预定义的 异常类型，当然也可以自定义异常，例如要定义对当前模块唯一的异常，为此，在模块实现文件的开始处定义一个静态对象变量，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyObject <span class="token operator">*</span>SpamError<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>然后在模块初始化函数 <code>PyInit_spam()</code> 中进行初始化，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">PyMODINIT_FUNC<span class="token function">PyInit_spam</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    PyObject <span class="token operator">*</span>m<span class="token punctuation">;</span>    m <span class="token operator">=</span> <span class="token function">PyModule_Create</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>spammodule<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>m <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    SpamError <span class="token operator">=</span> <span class="token function">PyErr_NewException</span><span class="token punctuation">(</span><span class="token string">"spam.error"</span><span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">Py_XINCREF</span><span class="token punctuation">(</span>SpamError<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">PyModule_AddObject</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token string">"error"</span><span class="token punctuation">,</span> SpamError<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">Py_XDECREF</span><span class="token punctuation">(</span>SpamError<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">Py_CLEAR</span><span class="token punctuation">(</span>SpamError<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">Py_DECREF</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> m<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><code>PyErr_NewException()</code> 函数将创建一个 Exception 类型的子类，对应的 python 类型为 <code>spam.error</code>。现在我们在<code>system()</code> 调用失败时设置异常，代码如下，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyObject <span class="token operator">*</span><span class="token function">spam_system</span><span class="token punctuation">(</span>PyObject <span class="token operator">*</span>self<span class="token punctuation">,</span> PyObject <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>command<span class="token punctuation">;</span>    <span class="token keyword">int</span> sts<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">PyArg_ParseTuple</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> <span class="token string">"s"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>command<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    sts <span class="token operator">=</span> <span class="token function">system</span><span class="token punctuation">(</span>command<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>sts <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">PyErr_SetString</span><span class="token punctuation">(</span>SpamError<span class="token punctuation">,</span> <span class="token string">"System command failed"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> <span class="token function">PyLong_FromLong</span><span class="token punctuation">(</span>sts<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>如果调用的是一个返回 void 的 C 函数，那么对应的 Python 函数则应该返回 None，所以使用如下代码实现，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token function">Py_INCREF</span><span class="token punctuation">(</span>Py_None<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span> Py_None<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>或者使用宏 <code>Py_RETURN_NONE</code> 更简洁。</p><h2 id="模块的方法表以及初始化"><a href="#模块的方法表以及初始化" class="headerlink" title="模块的方法表以及初始化"></a>模块的方法表以及初始化</h2><p>以下代码显示了如何从 Python 程序中调用 <code>spam_system()</code>，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyMethodDef SpamMethods<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">&#123;</span><span class="token string">"system"</span><span class="token punctuation">,</span>  spam_system<span class="token punctuation">,</span> METH_VARARGS<span class="token punctuation">,</span>     <span class="token string">"Execute a shell command."</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">&#123;</span><span class="token constant">NULL</span><span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">&#125;</span>        <span class="token comment">/* Sentinel */</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>这个数组中每一项表示一个模块方法（python 到 C 方法映射）。数组的每个条目中，第一个为字符串，表示 python 方法明，第二个为 C 方法，第三个参数可以是 <code>METH_VARARGS</code> 或者 <code>METH_VARARGS | METH_KEYWORDS</code>，对于<code>METH_VARARGS</code>，表示在 python 侧，参数以元组形式传递进来，然后使用 <code>PyArg_ParseTuple()</code> 解析成 C 类型变量。对于 <code>METH_KEYWORDS</code>，表示传递关键字参数（参数有默认值），这种情况下，C 侧函数还有第三个参数 <code>PyObject *</code> 类型，使用 <code>PyArg_ParseTupleAndKeywords()</code> 解析。</p><p>整个模块定义为，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> <span class="token keyword">struct</span> <span class="token class-name">PyModuleDef</span> spammodule <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    PyModuleDef_HEAD_INIT<span class="token punctuation">,</span>    <span class="token string">"spam"</span><span class="token punctuation">,</span>   <span class="token comment">/* name of module */</span>    spam_doc<span class="token punctuation">,</span> <span class="token comment">/* module documentation, may be NULL */</span>    <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>       <span class="token comment">/* size of per-interpreter state of the module,                 or -1 if the module keeps state in global variables. */</span>    SpamMethods<span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>这个结构体需要传给 python 解释器的模块初始化函数，初始化函数名为 <code>PyInit_&lt;modulename&gt;()</code>，其中 <code>&lt;modulename&gt;</code> 表示 python 模块名，在模块定义文件中，初始化函数是唯一非静态修饰的。<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">PyMODULEINIT_FUNC<span class="token function">PyInit_spam</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">return</span> <span class="token function">PyModule_Create</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>spammodule<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>当在 python 程序中首次 import  <code>spam</code> 模块时，<code>PyInit_spam()</code> 方法被调用，其中调用 <code>PyModule_Create()</code>，返回一个模块对象指针。</p><p>在 C 代码中嵌入 Python 时，<code>PyInit_spam()</code> 不会自动调用，除非 <code>PyImport_Inittab</code> 中插入相应的一项。如下代码所示，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">int</span><span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    <span class="token keyword">wchar_t</span> <span class="token operator">*</span>program <span class="token operator">=</span> <span class="token function">Py_DecodeLocale</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>program <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">fprintf</span><span class="token punctuation">(</span><span class="token constant">stderr</span><span class="token punctuation">,</span> <span class="token string">"Fatal error: cannot decode argv[0]\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token comment">/* Add a built-in module, before Py_Initialize */</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">PyImport_AppendInittab</span><span class="token punctuation">(</span><span class="token string">"spam"</span><span class="token punctuation">,</span> PyInit_spam<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">fprintf</span><span class="token punctuation">(</span><span class="token constant">stderr</span><span class="token punctuation">,</span> <span class="token string">"Error: could not extend in-built modules table\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token comment">/* Pass argv[0] to the Python interpreter */</span>    <span class="token function">Py_SetProgramName</span><span class="token punctuation">(</span>program<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">/* Initialize the Python interpreter.  Required.       If this step fails, it will be a fatal error. */</span>    <span class="token function">Py_Initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">/* Optionally import the module; alternatively,       import can be deferred until the embedded script       imports it. */</span>    PyObject <span class="token operator">*</span>pmodule <span class="token operator">=</span> <span class="token function">PyImport_ImportModule</span><span class="token punctuation">(</span><span class="token string">"spam"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>pmodule<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">PyErr_Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">fprintf</span><span class="token punctuation">(</span><span class="token constant">stderr</span><span class="token punctuation">,</span> <span class="token string">"Error: could not import module 'spam'\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token function">PyMem_RawFree</span><span class="token punctuation">(</span>program<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>注：所谓嵌入 python，是指将 CPython 运行时嵌入到一个更大的程序中，而不仅仅局限在实现 Python 的 C 扩展并在 Python 解释器中执行。</p><h2 id="编译和链接"><a href="#编译和链接" class="headerlink" title="编译和链接"></a>编译和链接</h2><p>实现 C 扩展代码后，还需要进行编译和链接。后面会专门讨论如何实现编译链接成动态库，这里简单介绍如何将实现的 C 扩展模块作为 python 解释器的一部分，即内置模块。</p><p>将 <code>spammodule.c</code> 文件至于 python 源码的 <code>Modules/</code> 目录下，然后再 <code>Modules/Setup.local</code> 中添加一行：<br><pre class="line-numbers language-none"><code class="language-none">spam spammodule.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>然后在 top-level 目录下运行 <code>make</code> 以重新生成 python 解释器。</p><p>如果我们自己实现的C扩展模块需要额外的链接库，也可以在配置文件 <code>Modules/Setup.local</code> 中列出，例如，<br><pre class="line-numbers language-none"><code class="language-none">spam spammodule.o -lX11<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>这种将自定义模块作为解释器一部分的思路并不常见，所以不过多介绍，重点还是后面即将介绍的动态库生成。</p><h2 id="从-C-中调用-Python-函数"><a href="#从-C-中调用-Python-函数" class="headerlink" title="从 C 中调用 Python 函数"></a>从 C 中调用 Python 函数</h2><p>前面介绍了如何从 Python 中调用 C 函数，现在反过来，从 C 中如何调用 python？这在支持回调的函数中尤其有用，Python 侧调用 C 扩展时，需要提供一个 回调。</p><p>还以上面那个 <code>spammodule.c</code> 文件为例，我们现在需要提供一个函数，用于接收 Python 侧提供的回调，并将回调函数对象保存到一个全局变量中，代码如下，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">static</span> PyObject <span class="token operator">*</span>my_callback <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span><span class="token keyword">static</span> PyObject <span class="token operator">*</span><span class="token function">my_set_callback</span><span class="token punctuation">(</span>PyObject <span class="token operator">*</span>dummy<span class="token punctuation">,</span> PyObject <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>    PyObject <span class="token operator">*</span>result <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    PyObject <span class="token operator">*</span>temp<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">PyArg_ParseTuple</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> <span class="token string">"O:set_callback"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>temp<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">PyCallable_Check</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            <span class="token function">PyErr_SetString</span><span class="token punctuation">(</span>PyExc_TypeError<span class="token punctuation">,</span> <span class="token string">"parameter must be callable"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>        <span class="token function">Py_XINCREF</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment">/* Add a reference to new callback */</span>        <span class="token function">Py_XDECREF</span><span class="token punctuation">(</span>my_callback<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">/* Dispose of previous callback */</span>        my_callback <span class="token operator">=</span> temp<span class="token punctuation">;</span>       <span class="token comment">/* Remember new callback */</span>        <span class="token comment">/* Boilerplate to return "None" */</span>        <span class="token function">Py_INCREF</span><span class="token punctuation">(</span>Py_None<span class="token punctuation">)</span><span class="token punctuation">;</span>        result <span class="token operator">=</span> Py_None<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>同样的，这个函数，需要注册到 <code>spam</code> 模块中，与上面 <code>spam_system()</code> 类似，例如<br><pre class="line-numbers language-none"><code class="language-none">static PyMethodDef SpamMethods[] &#x3D; &#123;    ...    &#123;&quot;set_cb&quot;,  my_set_callback, METH_VARARGS,     &quot;Set a callback function&quot;&#125;,    ...    &#123;NULL, NULL, 0, NULL&#125;        &#x2F;* Sentinel *&#x2F;&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>在 Python 侧调用 <code>spam.set_cb()</code> 就可以设置回调函数了，之后可以在 C 代码中任意其他地方调用这个回调， 例如另一个 C 函数 <code>use_cb()</code> 中，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">int</span> arg<span class="token punctuation">;</span>PyObject <span class="token operator">*</span>arglist<span class="token punctuation">;</span>PyObject <span class="token operator">*</span>result<span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>arg <span class="token operator">=</span> <span class="token number">123</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token comment">/* Time to call the callback */</span>arglist <span class="token operator">=</span> <span class="token function">Py_BuildValue</span><span class="token punctuation">(</span><span class="token string">"(i)"</span><span class="token punctuation">,</span> arg<span class="token punctuation">)</span><span class="token punctuation">;</span>result <span class="token operator">=</span> <span class="token function">PyObject_CallObject</span><span class="token punctuation">(</span>my_callback<span class="token punctuation">,</span> arglist<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Py_DECREF</span><span class="token punctuation">(</span>arglist<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>使用 <code>PyObject_CallObject()</code> 调用回调，有两个参数，第一个是回调对象，第二个是回调函数的参数列表，这个参数列表是一个 tuple 对象，如果回调函数无参数，那么这个参数列表可以是 <code>NULL</code>，或者一个 empty tuple。不能使用 C 类型参数，而应该使用 <code>Py_BuildValue()</code> 转换为 Python相关的类型。</p><p><code>PyObject_CallObject()</code> 对于其参数而言，是“引用计数中立”的，所以在调用 <code>PyObject_CallObject()</code> 之后，需要立即将参数 <code>Py_DECREF()</code>。</p><p><code>PyObject_CallObject()</code> 的返回值也需要 <code>Py_DECREF()</code>，除非将返回值保存至一个全局变量中（这个变量已经增加其引用计数）。当然在降低引用计数之前需要检查返回值是否为 <code>NULL</code>，</p><pre class="line-numbers language-none"><code class="language-none">PyObject *arglist;...arglist &#x3D; Py_BuildValue(&quot;(l)&quot;, eventcode);result &#x3D; PyObject_CallObject(my_callback, arglist);Py_DECREF(arglist);if (result &#x3D;&#x3D; NULL)    return NULL; &#x2F;* Pass error back *&#x2F;&#x2F;* Here maybe use the result *&#x2F;Py_DECREF(result);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也可以使用 <code>PyObject_Call()</code> 来调用有关键字参数的函数，例如，<br><pre class="line-numbers language-none"><code class="language-none">PyObject *dict;...dict &#x3D; Py_BuildValue(&quot;&#123;s:i&#125;&quot;, &quot;name&quot;, val);result &#x3D; PyObject_Call(my_callback, NULL, dict);Py_DECREF(dict);if (result &#x3D;&#x3D; NULL)    return NULL; &#x2F;* Pass error back *&#x2F;&#x2F;* Here maybe use the result *&#x2F;Py_DECREF(result);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>python setup</title>
      <link href="/2021/06/12/python/setup/"/>
      <url>/2021/06/12/python/setup/</url>
      
        <content type="html"><![CDATA[<p>python 的 setup 介绍。<br><span id="more"></span></p><p>研究 python setup.py 脚本中的 setup 方法使用。</p><p>一个简单的例子<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">from distutils.core import setupsetup(name&#x3D;&#39;Distutils&#39;,      version&#x3D;&#39;1.0&#39;,      description&#x3D;&#39;Python Distribution Utilities&#39;,      author&#x3D;&#39;Greg Ward&#39;,      author_email&#x3D;&#39;gward@python.net&#39;,      url&#x3D;&#39;https:&#x2F;&#x2F;www.python.org&#x2F;sigs&#x2F;distutils-sig&#x2F;&#39;,      packages&#x3D;[&#39;distutils&#39;, &#39;distutils.command&#39;],     )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>下面分别对各参数进行解释说明</p><h2 id="packages"><a href="#packages" class="headerlink" title="packages"></a>packages</h2><p>packages 列举了需要处理（生成、分发以及安装等）的纯 python 包。这里需要注意 包名称与文件路径之间的映射关系。例如，<code>distutils</code> 包应该对应 root 目录下的 <code>distutils</code> 文件夹，root 目录即 <code>setup.py</code> 文件所在目录。如果指定 <code>packages=[&#39;foo&#39;]</code>，那么 root 目录下应该有 <code>foo/__init__.py</code> 文件。</p><p>当然，以上是默认约定规则，也可以手动建议映射关系：使用 <code>package_dir</code> 参数。</p><h2 id="package-dir"><a href="#package-dir" class="headerlink" title="package_dir"></a>package_dir</h2><p>例如所有的 python 源文件均位于 root 目录下的 <code>lib</code> 文件夹中，也就是说 “root package” 实际上对应 <code>lib</code> 文件夹，例如 <code>foo</code> 包则对应 <code>lib/foo</code>文件夹，那么设置<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">package_dir &#x3D; &#123;&#39;&#39;: &#39;lib&#39;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>这是一个字典，key 表示包名称，empty string 表示 “root package”，value 表示文件目录（相对于 setup.py 所在目录），故如果此时设置 <code>packages=[&#39;foo&#39;]</code>，这表示 <code>lib/foo/__init__.py</code> 一定存在。</p><p>如果 <code>package_dir = &#123;&#39;foo&#39;: &#39;lib&#39;&#125;</code>，这表示只有 <code>foo</code> 包不对应 root 目录下的 <code>foo</code> 文件夹，而直接对应 <code>lib</code> 文件夹，即 <code>lib/__init__.py</code> 一定存在。package_dir 的规则将（递归）应用到某个包内的所有包上，所以 <code>foo.bar</code> 包对应 <code>lib/bar</code>，即 <code>lib/bar/__init__.py</code> 一定存在。</p><p>注意：<code>packages</code> 不会递归应用到某个包的所有子包上，所以如果要处理子包，需要显式的列出来。</p><h2 id="py-modules"><a href="#py-modules" class="headerlink" title="py_modules"></a>py_modules</h2><p>对于小的模块分发，可能想直接列出模块，而不是包，那么使用这个参数，例如<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">py_modules &#x3D; [&#39;mod1&#39;, &#39;pkg.mod2&#39;]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>记住，模块以根目录为相对起点，所以上面例子中 <code>pkg</code> 必须是一个包，即 <code>pkg/__init__.py</code> 必须要存在。</p><p>当然也可以通过设置 <code>package_dir</code> 来手动定义 包 - 目录 的映射关系。</p><h2 id="ext-modules"><a href="#ext-modules" class="headerlink" title="ext_modules"></a>ext_modules</h2><p>写 python 扩展模块比写 纯 python 模块复杂一些，同样，描述如何处理这些 模块模块 也比 描述如何处理纯 python 模块要复杂，需要指定扩展模块名称，源文件，编译链接需求（头文件包含路径，链接库，flags 等）</p><p>ext_modules 是 <code>Extension</code> 的列表， <code>Extension</code> 描述扩展模块。一个简单的例子，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">Extension(&#39;foo&#39;, [&#39;foo.c&#39;])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>表示扩展模块名称为 <code>foo</code>，相关的源文件为 <code>foo.c</code>。</p><h3 id="扩展名和包"><a href="#扩展名和包" class="headerlink" title="扩展名和包"></a>扩展名和包</h3><p><code>Extension</code> 构造器的第一个参数为扩展模块的名称，也可以是包名称，<br><pre class="line-numbers language-none"><code class="language-none">Extension(&#39;foo&#39;, [&#39;src&#x2F;foo1.c&#39;, &#39;src&#x2F;foo2.c&#39;])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>指定了一个名为 <code>foo</code> 且位于 root package 下的扩展模块，而<br><pre class="line-numbers language-none"><code class="language-none">Extension(&#39;pkg.foo&#39;, [&#39;src&#x2F;foo1.c&#39;, &#39;src&#x2F;foo2.c&#39;])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>制定了一个相同的扩展模块，但是位于 <code>pkg</code> 包内。</p><h3 id="扩展源文件"><a href="#扩展源文件" class="headerlink" title="扩展源文件"></a>扩展源文件</h3><p><code>Extension</code> 构造器的第二个参数为扩展源文件，目前支持 C/C++/Objective-C，也可以是 SWIG 接口文件 (<code>.i</code> 后缀)。</p><h3 id="预处理器选项"><a href="#预处理器选项" class="headerlink" title="预处理器选项"></a>预处理器选项</h3><p><code>Extension</code> 有三个可选参数，1. <code>include_dirs</code>，2. <code>define_macros</code>，3. <code>undef_macros</code>，分别指定头文件包含路径，定义宏，取消定义宏。</p><p>例如，指定相对于项目 root 路径的 <code>include</code> 文件夹为头文件包含路径，<br><pre class="line-numbers language-none"><code class="language-none">Extension(&#39;foo&#39;, [&#39;foo.c&#39;], include_dirs&#x3D;[&#39;include&#39;])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>当然也可以使用绝对路径，但是尽量避免使用绝对路径，这对分发不友好。</p><p>生成 python 扩展库时，Python 包含目录会自动被搜索，例如我的机器上 python 包含目录为<br><pre class="line-numbers language-none"><code class="language-none">~&#x2F;tool&#x2F;miniconda3&#x2F;include&#x2F;python3.8<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>所以这个头文件目录不需要手动添加到 <code>include_dirs</code> 中。</p><p>这个路径可以使用 sysconfig 模块中的方法获得。</p><p><code>define_macros</code> 用于定义宏，它是一个 <code>(name, value)</code> 元组的列表，其中 <code>name</code> 为宏名称，<code>value</code> 为宏值，是字符串类型或者 <code>None</code> 类型，<code>value</code> 等于 <code>None</code> 时，相当于 C 中定义宏 <code>#define FOO</code> ，这在一些编译器中，<code>FOO</code> 值为 <code>1</code> 。</p><p><code>undef_macros</code> 则是取消定义宏的列表。例如，<br><pre class="line-numbers language-none"><code class="language-none">Extension(...,          define_macros&#x3D;[(&#39;NDEBUG&#39;, &#39;1&#39;),                         (&#39;HAVE_STRFTIME&#39;, None)],          undef_macros&#x3D;[&#39;HAVE_FOO&#39;, &#39;HAVE_BAR&#39;])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>等价于 C 源码<br><pre class="line-numbers language-none"><code class="language-none">#define NDEBUG 1#define HAVE_STRFTIME#undef HAVE_FOO#undef HAVE_BAR<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><h3 id="库选项"><a href="#库选项" class="headerlink" title="库选项"></a>库选项</h3><p><code>Extension</code> 构造器中，可以指定链接库： <code>libraries</code> 参数，链接库的链接时搜索目录：<code>library_dirs</code> 参数，链接库运行时的搜索目录（动态库加载时搜索目录）：<code>runtime_library_dirs</code>。</p><h3 id="其他选项"><a href="#其他选项" class="headerlink" title="其他选项"></a>其他选项</h3><p><code>Extension</code> 构造器还有一些其他选项参数。</p><ol><li><p><code>optional</code> bool 类型，如为 true，那么扩展库生成失败时不会导致整个 生成过程退出。</p></li><li><p><code>extra_objects</code> 是目标文件的列表，这些目标文件提供给连接器进行链接。</p></li><li><p><code>extra_compile_args</code> 指定额外的命令行选项供编译器使用，<code>extra_link_args</code> 指定命令行选项供链接器使用。</p></li><li><p><code>export_symbols</code> Windows 系统上使用，这里略。</p></li><li><p><code>depends</code> 是文件列表，指定扩展库所依赖的文件，例如头文件，那么当依赖文件有所改变时，生成命令将调用编译器重新编译。</p></li></ol><p>以上是 <code>Extension</code> 扩展的参数介绍。</p><h2 id="分发和包之间的联系"><a href="#分发和包之间的联系" class="headerlink" title="分发和包之间的联系"></a>分发和包之间的联系</h2><p>分发可以 依赖/提供/废除 包或者模块，这在 <code>distutils.core.setup()</code> 中实现。</p><p>对其他 python 模块/包 的依赖可以通过 <code>setup()</code> 中的 <code>requires</code> 参数指定，这个参数值是字符串列表，其他每个字符串指示一个包，并且可选择是否附加包的 version。例如指定任意 version 模块 <code>mymodule</code> 或者 <code>xml.parsers.expat</code>，如果需要指定版本，那么在括号中指定版本修饰，可以有多个版本修饰，每个修饰之间使用 <code>,</code> 逗号分隔，修饰可以包含一个比较符，<br><pre class="line-numbers language-none"><code class="language-none">&lt;   &gt;   &#x3D;&#x3D;&lt;&#x3D;  &gt;&#x3D;  !&#x3D;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>例如，<br>|依赖库版本| 解释|<br>|—|—|<br>|==1.0| 仅 1.0 版本兼容|<br>|&gt;1.0, !=1.5.1, &lt;2.0|在 1.0 以后 2.0 以前的版本兼容，其中 1.5.1 除外|</p><p>上面指定了所依赖的版本，我们也可以提供当前项目包/模块的版本，供其他项目依赖，通过<code>setup()</code> 中的 <code>provides</code> 参数指定，参数值是字符串列表，每个字符串指示 python 的模块或包名称，且可选地提供其版本，如果未提供版本，那么认为与分发版本一致。例如，<br>|提供库表达式|解释|<br>|—|—|<br>|mypkg| 提供库 <code>mypkg</code>，使用分发版本|<br>|mypkg (1.1)| 提供库 <code>mypkg</code>，版本为 1.1|</p><p>通过 <code>obsoletes</code> 参数指定废除一些包/模块，与上面的 <code>requires</code> 值类似，是字符串列表，其他每个字符串指定 包/模块 地名称，后面可跟一个或多个版本修饰，版本修饰至于 <code>()</code> 中。</p><h2 id="安装脚本"><a href="#安装脚本" class="headerlink" title="安装脚本"></a>安装脚本</h2><p>上面介绍的内容，处理了 python 的包和模块，这些包和模块自己不会运行，而是在脚本中被导入使用。</p><p>脚本中包含 python 源码，且可以在命令行中启动执行。<code>scripts</code> 参数指定了脚本文件列表，这样，分发安装后，脚本文件就被复制到 <code>PATH</code> 下。例如，<br><pre class="line-numbers language-none"><code class="language-none">setup(...,      scripts&#x3D;[&#39;scripts&#x2F;xmlproc_parse&#39;, &#39;scripts&#x2F;xmlproc_val&#39;]      )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>文件路径是相对于分发 root 路径，安装后，脚本文件被拷贝到<code>PATH</code> 下，于是就可以直接在命令行中，<br><pre class="line-numbers language-none"><code class="language-none">$ xmlproc_parse...$ xmlproc_val...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="安装包数据"><a href="#安装包数据" class="headerlink" title="安装包数据"></a>安装包数据</h2><p>有时，其他一些文件也需要被安装，例如一些数据文件，或者包含文档的文本文件。这些文件统称为 包数据。</p><p>使用 <code>package_data</code> 参数指定包数据，参数值是一个映射（字典类型），从包名称到相对路径列表的映射，相对路径指示数据文件，这些文件应该被拷贝到对应的包。相对路径是相对于 包 对应的目录（注意，可能由 <code>package_dir</code> 修改过，而非默认目录）。</p><p>例如，源码目录如下，<br><pre class="line-numbers language-none"><code class="language-none">setup.pysrc&#x2F;    mypkg&#x2F;        __init__.py        module.py        data&#x2F;            tables.dat            spoons.dat            forks.dat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><code>setup()</code> 函数调用为<br><pre class="line-numbers language-none"><code class="language-none">setup(...,     packages&#x3D;[&#39;mypkg&#39;],     package_dir&#x3D;&#123;&#39;mypkg&#39;: &#39;src&#x2F;mypkg&#39;&#125;,     package_data&#x3D;&#123;&#39;mypkg&#39;: [&#39;data&#x2F;*.dat&#39;]&#125;,     )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="安装其他文件"><a href="#安装其他文件" class="headerlink" title="安装其他文件"></a>安装其他文件</h2><p>安装分发所需的其他文件，可以使用 <code>data_files</code> 参数，参数值是 <code>(directory, files)</code> 元组的列表，例如<br><pre class="line-numbers language-none"><code class="language-none">setup(...,      data_files&#x3D;[(&#39;bitmaps&#39;, [&#39;bm&#x2F;b1.gif&#39;, &#39;bm&#x2F;b2.gif&#39;]),                  (&#39;config&#39;, [&#39;cfg&#x2F;data.cfg&#39;])],     )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p><code>files</code> 中每个文件均相对于 <code>setup.py</code> 所在目录。可以重定义文件被安装的目录，但不能改变文件名。</p><p><code>directory</code> 相对于安装 prefix，系统级安装则为 <code>sys.prefix</code>，用户级安装则为 <code>site.USER_BASE</code>。 <code>directory</code> 也可以为绝对路径，但是通常不建议，会导致与 wheel 包格式的不兼容。</p>]]></content>
      
      
      
        <tags>
            
            <tag> cmake </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cmake TARGET</title>
      <link href="/2021/06/08/cpp/cmake_target/"/>
      <url>/2021/06/08/cpp/cmake_target/</url>
      
        <content type="html"><![CDATA[<p>cmake 的目标 TARGET。<br><span id="more"></span></p><h1 id="target-compile-definitions"><a href="#target-compile-definitions" class="headerlink" title="target_compile_definitions"></a>target_compile_definitions</h1><pre class="line-numbers language-none"><code class="language-none">target_compile_definitions(&lt;target&gt;  &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]  [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>指定编译给定目标 <code>&lt;target&gt;</code> 时的编译定义。目标 <code>&lt;target&gt;</code> 由 <code>add_executable()</code> 或者 <code>add_library()</code> 创建。</p><ul><li><p>PRIVATE, PUBLIC</p><p>  这两个选项指定给 <code>&lt;target&gt;</code> 的 <code>COMPILE_DEFINITIONS</code> 属性赋值（append）</p></li><li><p>PUBLIC, INTERFACE</p><p>  指定给 <code>&lt;target&gt;</code> 的 <code>INTERFACE_COMPILE_DEFINITIONS</code> 属性赋值（append）</p></li></ul><p>编译定义中的前导 <code>-D</code> 会被移除，空定义项被忽略。以下各行等价，<br><pre class="line-numbers language-none"><code class="language-none">target_compile_definitions(foo PUBLIC FOO)target_compile_definitions(foo PUBLIC -DFOO)  # -D removedtarget_compile_definitions(foo PUBLIC &quot;&quot; FOO) # &quot;&quot; ignoredtarget_compile_definitions(foo PUBLIC -D FOO) # -D becomes &quot;&quot;, then ignored<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="set-target-properties"><a href="#set-target-properties" class="headerlink" title="set_target_properties"></a>set_target_properties</h1><pre class="line-numbers language-none"><code class="language-none">set_target_properties(target1 target2 ...                      PROPERTIES prop1 value1                      prop2 value2 ...)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>设置目标的属性。</p><h1 id="target-include-directories"><a href="#target-include-directories" class="headerlink" title="target_include_directories"></a>target_include_directories</h1><pre class="line-numbers language-none"><code class="language-none">target_include_directories(&lt;target&gt; [SYSTEM] [AFTER|BEFORE]  &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]  [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>为目标添加头文件路径。</p><ul><li><p>PRIVATE, PUBLIC</p><p>  给目标的 <code>INCLUDE_DIRECTORIES</code> 属性添加值</p></li><li><p>PUBLIC, INTERFACE</p><p>  给目标的 <code>INTERFACE_INCLUDE_DIRECTORIES</code> 属性添加值</p></li></ul><p>指定的包含目录可以是绝对或相对路径，对同一个目标调用多次这个命令，则会按顺序附加包含目录。</p><p><code>target_include_directories</code> 命令参数可能会使用 “生成器表达式”，语法为 <code>$&lt;...&gt;</code>。关于生成器表达式可参考<a href="https://cmake.org/cmake/help/latest/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7">这里</a>)。 例如，</p><pre class="line-numbers language-none"><code class="language-none">target_include_directories(mylib PUBLIC  $&lt;BUILD_INTERFACE:$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&#x2F;include&#x2F;mylib&gt;  $&lt;INSTALL_INTERFACE:include&#x2F;mylib&gt;  # &lt;prefix&gt;&#x2F;include&#x2F;mylib)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>给目标添加包含目录。如果使用 <code>export()</code> 导出这个目标的包含目录属性，那么使用 <code>$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/include/mylib&gt;</code>，如果使用 <code>install(EXPORT)</code> 导出目标的包含目录属性，那么使用 <code>include/mylib&gt;</code>。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>cmake 查找</title>
      <link href="/2021/06/08/cpp/cmake_find/"/>
      <url>/2021/06/08/cpp/cmake_find/</url>
      
        <content type="html"><![CDATA[<p>cmake 的包查找。<br><span id="more"></span></p><h1 id="find-package"><a href="#find-package" class="headerlink" title="find_package"></a>find_package</h1><ol><li>CMake 内置模型引入依赖包</li></ol><p>为了方便我们在项目中引入外部依赖包，cmake官方为我们预定义了许多寻找依赖包的Module，他们存储在<code>path_to_your_cmake/share/cmake-&lt;version&gt;/Modules</code>目录下。每个以<code>Find&lt;LibaryName&gt;.cmake</code>命名的文件都可以帮我们找到一个包。我们也可以在官方文档中查看到哪些库官方已经为我们定义好了，我们可以直接使用find_package函数进行引用官方文档：<a href="https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html">Find Modules</a>。</p><p>例如 <code>CURL</code>，可直接使用<br><pre class="line-numbers language-none"><code class="language-none">find_package(CURL)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>每一个模块都会定义以下几个变量 -</p><pre class="line-numbers language-none"><code class="language-none">&lt;LibaryName&gt;_FOUND&lt;LibaryName&gt;_INCLUDE_DIR or &lt;LibaryName&gt;_INCLUDES &lt;LibaryName&gt;_LIBRARY or &lt;LibaryName&gt;_LIBRARIES<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol><li>引入支持 cmake 编译安装的库</li></ol><p>例如项目引用库 <code>glog</code>，cmake 的 Module 目录下没有 <code>FindGlog.cmake</code>，于是需要自行安装 glog 库，安装过程如下，</p><pre class="line-numbers language-none"><code class="language-none"># clone该项目git clone https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;glog.git # 切换到需要的版本 cd gloggit checkout v0.40  # 根据官网的指南进行安装cmake -H. -Bbuild -G &quot;Unix Makefiles&quot;cmake --build buildcmake --build build --target install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时我们便可以通过与引入curl库一样的方式引入glog库了<br><pre class="line-numbers language-none"><code class="language-none">find_package(GLOG)add_executable(glogtest glogtest.cc)if(GLOG_FOUND)    # 由于glog在连接时将头文件直接链接到了库里面，所以这里不用显示调用target_include_directories    target_link_libraries(glogtest glog::glog)else(GLOG_FOUND)    message(FATAL_ERROR ”GLOG library not found”)endif(GLOG_FOUND)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>find_package 内部是如何查找依赖库的呢？有两种模式，</p><h2 id="Module-模式"><a href="#Module-模式" class="headerlink" title="Module 模式"></a>Module 模式</h2><p>如 curl 库的引用方式。cmake 首先找到 <code>Find&lt;LibraryName&gt;.cmake</code> 文件，这个 <code>.cmake</code> 文件可以从 <code>share/cmake-&lt;version&gt;/Modules</code> 目录下寻找，还可以从 <code>CMAKE_MODULE_PATH</code> 这个变量指定的搜索目录下搜索。</p><p>如果 Module 模式没有找到这个 <code>.cmake</code> 文件，那么尝试 Config 模式，这就是另外一个模式。</p><h2 id="Config-模式"><a href="#Config-模式" class="headerlink" title="Config 模式"></a>Config 模式</h2><p>通过 <code>&lt;LibraryName&gt;Config.cmake</code> 或 <code>&lt;lower-case-package-name&gt;-config.cmake</code> 这个配置文件来引入依赖库。创建包配置文件可以参考我的另一篇文章 <a href="/2021/06/03/cpp/cmake_im_ex">cmake 导入导出</a>。</p><h1 id="find-library"><a href="#find-library" class="headerlink" title="find_library"></a>find_library</h1><p>简单形式为<br><pre class="line-numbers language-none"><code class="language-none">find_library (&lt;VAR&gt; name1 [path1 path2 ...])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>一般形式为<br><pre class="line-numbers language-none"><code class="language-none">find_library (          &lt;VAR&gt;          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]          [HINTS path1 [path2 ... ENV var]]          [PATHS path1 [path2 ... ENV var]]          [PATH_SUFFIXES suffix1 [suffix2 ...]]          [DOC &quot;cache documentation string&quot;]          [NO_DEFAULT_PATH]          [NO_CMAKE_ENVIRONMENT_PATH]          [NO_CMAKE_PATH]          [NO_SYSTEM_ENVIRONMENT_PATH]          [NO_CMAKE_SYSTEM_PATH]          [CMAKE_FIND_ROOT_PATH_BOTH |           ONLY_CMAKE_FIND_ROOT_PATH |           NO_CMAKE_FIND_ROOT_PATH]         )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>命令用于查找库，结果保存在一个名为 <code>&lt;VAR&gt;</code> 的缓存条目里面。如果没有找到，那么结果为 <code>&lt;VAR&gt;-NOTFOUND</code>。搜索库的名为 <code>name1</code> 等。搜索路径可以通过 <code>PATHS</code> 选项指定。<code>PATH-SUFFIXES</code> 指定在查找搜索路径之外还查找搜索路径的子目录。如果 <code>NO_DEFAULT_PATH</code> 指定，那么不使用默认搜索路径，否则，搜索过程如下：</p><ol><li><p>搜索某些特定 cmake 的缓存变量中的路径，例如在命令行中指定 <code>-DVAR=value</code>。如果设置了 <code>NO_CMAKE_PATH</code>，那么不考虑这条搜索规则。下面考虑这些特定 cmake 缓存变量</p><ul><li>如果设置了 <code>CMAKE_LIBRARY_ARCHITECTURE</code>，那么搜索 <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code> 路径；以及 <code>&lt;prefix&gt;/lib</code> 路径，其中 <code>&lt;prefix&gt;</code> 是 <code>CMAKE_PREFIX_PATH</code> 指定的路径集合之一。</li><li>搜索 <code>CMAKE_LIBRARY_PATH</code> 中的路径</li><li>搜索 <code>CMAKE_FRAMEWORD_PATH</code> 中的路径</li></ul></li><li><p>搜索某些特征 cmake 的环境变量中的路径。环境变量在用户的 shell 配置中设置，例如 <code>~/.bashrc</code>。如果设置了 <code>NO_CMAKE_ENVIRONMENT_PATH</code>，那么不考虑这条规则。</p><ul><li>如果设置了 <code>CMAKE_LIBRARY_ARCHITECTURE</code>，那么搜索 <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code> 路径；以及 <code>&lt;prefix&gt;/lib</code> 路径，其中 <code>&lt;prefix&gt;</code> 是 <code>CMAKE_PREFIX_PATH</code> 指定的路径集合之一。</li><li>搜索 <code>CMAKE_LIBRARY_PATH</code> 中的路径</li><li>搜索 <code>CMAKE_FRAMEWORD_PATH</code> 中的路径</li></ul></li><li><p>搜索由 <code>HINTS</code> 指定的路径。这个选项不是特别理解。暂不详述。</p></li><li><p>搜索标准的系统环境变量，如果设置了 <code>NO_SYSTEM_ENVIRONMENT_PATH</code>，那么这条规则不启用。</p><ul><li>如果设置了 <code>CMAKE_LIBRARY_ARCHITECTURE</code>，那么搜索 <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>，此外搜索 <code>PATH</code> 环境变量中每个路径条目，如果路径条目形式为 <code>&lt;prefix&gt;/[s]bin</code>，那么搜索路径 <code>&lt;prefix&gt;/lib</code>，否则就以路径条目为 <code>&lt;prefix&gt;</code> 来搜索路径 <code>&lt;prefix&gt;/lib</code>已经路径条目自身 <code>&lt;prefix&gt;</code></li></ul></li><li><p>搜索与当前操作系统相关的 cmake 变量。如果设置了 <code>NO_CMAKE_SYSTEM_PATH</code>，那么这条规则不启用。</p><ul><li>如果设置了 <code>CMAKE_LIBRARY_ARCHITECTURE</code>，那么搜索 <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code> 路径；以及 <code>&lt;prefix&gt;/lib</code> 路径，其中 <code>&lt;prefix&gt;</code> 是 <code>CMAKE_SYSTEM_PREFIX_PATH</code> 指定的路径集合之一。</li><li>搜索 <code>CMAKE_SYSTEM_LIBRARY_PATH</code> 中的路径</li><li>搜索 <code>CMAKE_SYSTEM_FRAMEWORD_PATH</code> 中的路径</li></ul></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>链接</title>
      <link href="/2021/06/08/cpp/link/"/>
      <url>/2021/06/08/cpp/link/</url>
      
        <content type="html"><![CDATA[<h2 id="动态库目录"><a href="#动态库目录" class="headerlink" title="动态库目录"></a>动态库目录</h2><ol><li>加入 <code>/lib</code>, <code>/usr/lib</code> 等默认搜索路径</li><li>设置 <code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:&lt;YOUR LIB PATH&gt;</code></li><li>修改配置文件 <code>/etc/ld.so.conf</code>，然后执行 <code>ldconfig</code></li><li><code>gcc</code> 添加选项 <code>-Wl,-rpath=&lt;YOUR LIB PATH&gt;</code>。这个路径会保存到程序中。<br>以上是动态（运行时）链接器（也可称为加载器）寻找动态库的搜索目录。</li></ol><h3 id="Wl"><a href="#Wl" class="headerlink" title="-Wl"></a>-Wl</h3><p>这个参数表示后面的参数传递给链接器 <code>ld</code></p><h3 id="rpath"><a href="#rpath" class="headerlink" title="-rpath"></a>-rpath</h3><p>添加一个目录到运行库搜索路径，可以使用 <code>$ORIGIN</code>，它表示执行文件所在的目录，注意在 Makefile 中需要写为 <code>$$ORIGIN</code>。</p><h3 id="—as-needed"><a href="#—as-needed" class="headerlink" title="—as-needed"></a>—as-needed</h3><p>链接器参数，表示仅链接其 symbol 在 binary 中用到的库。默认是开启这个 flag，若要关闭，使用 <code>--no-as-needed</code>，例如</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; main.cvoid foo();int main(void) &#123;    foo();    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; lib&#x2F;foo.c#include &lt;stdio.h&gt;void foo() &#123; printf(&quot;foo\n&quot;); &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; lib&#x2F;bar.c#include &lt;stdio.h&gt;void bar() &#123; printf(&quot;bar\n&quot;); &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-makefile" data-language="makefile"><code class="language-makefile"><span class="token comment"># Makefile</span><span class="token symbol">main</span><span class="token punctuation">:</span> main.c lib/libfoo.so lib/libbar.so    gcc -o main main.c -Wl,--no-as-needed,-rpath<span class="token operator">=</span><span class="token string">'$$ORIGIN/lib'</span> -L. -lfoo -lbar<span class="token symbol">lib/libfoo.so</span><span class="token punctuation">:</span> lib/foo.c    gcc -fPIC -shared -o lib/libfoo.so lib/foo.c<span class="token symbol">lib/libbar.so</span><span class="token punctuation">:</span> lib/bar.c    gcc -fPIC -shared -o lib/libbar.so lib/bar.c<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看 <code>main</code> 链接的库，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ ldd main<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p>]]></content>
      
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cmake 常用命令（一）</title>
      <link href="/2021/06/04/cpp/cmake_cmds_1/"/>
      <url>/2021/06/04/cpp/cmake_cmds_1/</url>
      
        <content type="html"><![CDATA[<p>cmake 的几个常用命令。<br><span id="more"></span></p><h2 id="find-program"><a href="#find-program" class="headerlink" title="find_program"></a>find_program</h2><pre class="line-numbers language-none"><code class="language-none">find_program (          &lt;VAR&gt;          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]          [HINTS path1 [path2 ... ENV var]]          [PATHS path1 [path2 ... ENV var]]          [PATH_SUFFIXES suffix1 [suffix2 ...]]          [DOC &quot;cache documentation string&quot;]          [REQUIRED]          [NO_DEFAULT_PATH]          [NO_PACKAGE_ROOT_PATH]          [NO_CMAKE_PATH]          [NO_CMAKE_ENVIRONMENT_PATH]          [NO_SYSTEM_ENVIRONMENT_PATH]          [NO_CMAKE_SYSTEM_PATH]          [CMAKE_FIND_ROOT_PATH_BOTH |           ONLY_CMAKE_FIND_ROOT_PATH |           NO_CMAKE_FIND_ROOT_PATH]         )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>简单形式为 <code>find_program (&lt;VAR&gt; name1 [path1 path2 ...])</code>。</p><p>查找程序。一个缓存条目 <code>VAR</code> 存储命令结果，如果没有找到，结果为 <code>&lt;VAR&gt;-NOTFOUND</code>。</p><ul><li>NAMES</li></ul><p>指定一个或多个程序名称</p><ul><li>HINTS, PATHS</li></ul><p>指定在默认目录之外的搜索路径。<code>ENV var</code> 指定环境变量。</p><ul><li>PATH-SUFFIXES</li></ul><p>指定在每个搜索路径下要检查的子路径。</p><p>如果 <code>NO_DEFAULT_PATH</code> 指定，那么默认搜索路径不再考虑，否则搜索过程如下：</p><p>…</p><h2 id="file"><a href="#file" class="headerlink" title="file"></a>file</h2><p><code>file(WRITE filename &quot;message to write&quot; ...)</code><br>将信息写如文件 <code>filename</code> 中。</p><p><code>file(APPEND filename &quot;message to write&quot; ...)</code><br>将信息追加到文件末尾</p><p><code>file(READ filename variable [LIMIT numBytes] [OFFSET offset] [HEX])</code><br>读取文件内容并存储到 <code>variable</code> 中。<code>HEX</code> 表示二进制数据转为为十进制。</p><p><code>file(&#123;GLOB|GLOB_RECURESE&#125; &lt;variable&gt; ... [&lt;globbing-expressions&gt;...])</code><br>根据表达式 <code>&lt;globbing-expressions&gt;</code> 匹配文件，并将文件列表保存到 <code>&lt;variable&gt;</code> 中。</p><p><code>GLOB_RECURSE</code> 将会遍历匹配的目录的子目录，从而匹配文件，例：<br><pre class="line-numbers language-none"><code class="language-none">&#x2F;dir&#x2F;*.py  - match all python files in &#x2F;dir and subdirectories<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h2 id="configure-file"><a href="#configure-file" class="headerlink" title="configure_file"></a>configure_file</h2><p><code>configure_file(&lt;input&gt; &lt;output&gt;               [NO_SOURCE_PERMISSIONS | USE_SOURCE_PERMISSIONS |                FILE_PERMISSIONS &lt;permissions&gt;...]               [COPYONLY] [ESCAPE_QUOTES] [@ONLY]               [NEWLINE_STYLE [UNIX|DOS|WIN32|LF|CRLF] ])</code></p><p>将 <code>input</code> 文件内容复制到 <code>output</code> 文件中。根据参数规则，替换 <code>@VAR@</code> 或 <code>$&#123;VAR&#125;</code> 变量。</p><p><code>&lt;input&gt;</code> 文件中 <code>#cmakedefine VAR</code> 会被替换为：</p><ol><li>如果 <code>VAR</code> 设置为 <code>ON</code>，那么替换为 <code>#define VAR</code></li><li>如果 <code>VAR</code> 设置为 <code>OFF</code>，那么替换为 <code>/* #undef VAR */</code></li></ol><p>同理，<code>#cmakedefine01 VAR</code> 则会被替换为 <code>#define VAR 1</code> 或 <code>#define VAR 0</code></p><p>注：这个命令的 <code>IMMEDIATE</code> 选项已经被弃用，因为文件复制已经是立即执行。</p><h2 id="内置模块"><a href="#内置模块" class="headerlink" title="内置模块"></a>内置模块</h2><p>cmake 提供了一些内置模块，可以直接 include 然后使用，参见 <a href="https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html">这里</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>cmake import export</title>
      <link href="/2021/06/03/cpp/cmake_im_ex/"/>
      <url>/2021/06/03/cpp/cmake_im_ex/</url>
      
        <content type="html"><![CDATA[<p>cmake 的导入导出机制。<br><span id="more"></span></p><h1 id="导入目标"><a href="#导入目标" class="headerlink" title="导入目标"></a>导入目标</h1><p>被导入的目标位于当前 cmake 项目的外部。要创建一个被导入目标，可在 <code>add_executable()</code> 和 <code>add_library()</code> 中加入 <code>IMPORTED</code> 选项，<code>IMPORTED</code> 选项是的这两个命令不会生成真正的目标文件（即，没有物理文件生成，而是将外部的目标文件作为当前cmake 项目的逻辑目标）。使用这两个命令导入后，被导入目标可以像其他目标一样被引用并使用。被导入目标的默认 scope 为当前目录以及子目录，可以使用 <code>GLOBAL</code> 使得被导入目标在 cmake 生成系统全局可见，<br><pre class="line-numbers language-none"><code class="language-none">add_executable(&lt;name&gt; IMPORTED [GLOBAL])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h2 id="导入可执行体"><a href="#导入可执行体" class="headerlink" title="导入可执行体"></a>导入可执行体</h2><p>以一个例子说明，完整代码位于 cmake 官方代码库的 Help/guide/importing-exporting 目录下。</p><p>操作命令如下，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ cd Help&#x2F;guide&#x2F;importing-exporting&#x2F;MyExe$ mkdir build$ cd build$ cmake ..$ cmake --build .$ cmake --install . --prefix &lt;install location&gt;$ &lt;install location&gt;&#x2F;myexe$ ls[...] main.cc [...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>为了方便，也给出了 CMakeLists.txt 文件内容，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span><span class="token punctuation">(</span>MyExe<span class="token punctuation">)</span><span class="token comment"># specify the C++ standard</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token variable">CMAKE_CXX_STANDARD</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token variable">CMAKE_CXX_STANDARD_REQUIRED</span> True<span class="token punctuation">)</span><span class="token comment"># Add executable</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>myexe main.cxx<span class="token punctuation">)</span><span class="token comment"># install executable</span><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS myexe<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>整个文件目录为，<br><pre class="line-numbers language-none"><code class="language-none">MyExe&#x2F;    CMakeLists.txt    main.cxx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>main.cxx 文件 main 函数执行后会创建一个 main.cc 的文件。</p><p>现在我们将这个生成的 <code>myexe</code> 可执行体导入到另一个项目中。另一个项目源码位于 Help/guide/importing-exporting/Importing，其中 CMakeLists.txt 文件内容为，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span><span class="token punctuation">(</span>Importing<span class="token punctuation">)</span><span class="token comment"># specify the C++ standard</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token variable">CMAKE_CXX_STANDARD</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token variable">CMAKE_CXX_STANDARD_REQUIRED</span> True<span class="token punctuation">)</span><span class="token comment"># Add executable</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>myexe <span class="token property">IMPORTED</span><span class="token punctuation">)</span><span class="token comment"># Set imported location</span><span class="token keyword">set_property</span><span class="token punctuation">(</span>TARGET myexe PROPERTY             <span class="token property">IMPORTED_LOCATION</span> <span class="token string">"../InstallMyExe/bin/myexe"</span><span class="token punctuation">)</span><span class="token comment"># Add custom command to create source file</span><span class="token keyword">add_custom_command</span><span class="token punctuation">(</span>OUTPUT main.cc COMMAND myexe<span class="token punctuation">)</span><span class="token comment"># Use source file</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>mynewexe main.cc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>以上，<code>myexe</code> 使用 <code>IMPORTED</code> 告诉 CMAKE 这是一个外部引用，并设置其属性 <code>IMPORTED_LOCATION</code>，这样就知道外部目标文件的位置。</p><pre class="line-numbers language-none"><code class="language-none">add_custom_command(OUTPUT main.cc COMMAND myexe)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上面这句命令指定构建时执行的命令为 <code>myexe</code>，生成的输出文件为 <code>main.cc</code> （这是一个相对于当前源目录的文件路径），这句指令本身不会让 cmake 构建，而是下一句，<br><pre class="line-numbers language-none"><code class="language-none">add_executable(mynewexe main.cc)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>这句构建一个可执行目标，该目标构建依赖于 <code>main.cc</code>。</p><h2 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h2><p>与可执行目标导入类似，库文件也可以被导入。<br><pre class="line-numbers language-none"><code class="language-none">add_library(foo STATIC IMPORTED)set_property(TARGET foo PROPERTY             IMPORTED_LOCATION &quot;path&#x2F;to&#x2F;libfoo.a&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>添加一个导入静态库，并设置其路径属性。</p><p>使用这个导入库如下，<br><pre class="line-numbers language-none"><code class="language-none">add_executable(myexe src1.c src2.c)target_link_libraries(myexe PRIVATE foo)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><h1 id="导出目标"><a href="#导出目标" class="headerlink" title="导出目标"></a>导出目标</h1><p>导入库有用，但是需要知道被导入库的文件路径。被导入目标的真正强大之处在于，当 cmake 项目提供目标文件时，cmake 项目同时提供一个 CMake 文件 .cmake，使得在其他地方可以非常方便的导入这些目标。</p><p>首先定位到 cmake 官方代码库的 Help/guide/importing-exporting/MathFunctions 目录，其中头文件 <code>MathFunctions.h</code> 的内容为，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">once</span></span><span class="token keyword">namespace</span> MathFunctions <span class="token punctuation">&#123;</span><span class="token keyword">double</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token keyword">double</span> x<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>源文件 <code>MathFunctions.cxx</code> 为，<br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"MathFunctions.h"</span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cmath></span></span><span class="token keyword">namespace</span> MathFunctions <span class="token punctuation">&#123;</span><span class="token keyword">double</span> <span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token keyword">double</span> x<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">return</span> std<span class="token double-colon punctuation">::</span><span class="token function">sqrt</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>CMakeLists.txt 文件内容较多，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span><span class="token punctuation">(</span>MathFunctions<span class="token punctuation">)</span><span class="token comment"># make cache variables for install destinations</span><span class="token keyword">include</span><span class="token punctuation">(</span>GNUInstallDirs<span class="token punctuation">)</span><span class="token comment"># specify the C++ standard</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token variable">CMAKE_CXX_STANDARD</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token variable">CMAKE_CXX_STANDARD_REQUIRED</span> True<span class="token punctuation">)</span><span class="token comment"># create library</span><span class="token keyword">add_library</span><span class="token punctuation">(</span>MathFunctions <span class="token namespace">STATIC</span> MathFunctions.cxx<span class="token punctuation">)</span><span class="token comment"># add include directories</span><span class="token keyword">target_include_directories</span><span class="token punctuation">(</span>MathFunctions                           <span class="token namespace">PUBLIC</span>                           <span class="token string">"$&lt;BUILD_INTERFACE:<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_SOURCE_DIR</span><span class="token punctuation">&#125;</span></span>>"</span>                           <span class="token string">"$&lt;INSTALL_INTERFACE:<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_INCLUDEDIR</span><span class="token punctuation">&#125;</span></span>>"</span><span class="token punctuation">)</span><span class="token comment"># install the target and create export-set</span><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS MathFunctions        EXPORT MathFunctionsTargets        LIBRARY DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span>        ARCHIVE DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span>        RUNTIME DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_BINDIR</span><span class="token punctuation">&#125;</span>        INCLUDES DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_INCLUDEDIR</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token comment"># install header file</span><span class="token keyword">install</span><span class="token punctuation">(</span>FILES MathFunctions.h DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_INCLUDEDIR</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token comment"># generate and install export file</span><span class="token keyword">install</span><span class="token punctuation">(</span>EXPORT MathFunctionsTargets        FILE MathFunctionsTargets.cmake        NAMESPACE MathFunctions::        DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span>/cmake/MathFunctions<span class="token punctuation">)</span><span class="token comment"># include CMakePackageConfigHelpers macro</span><span class="token keyword">include</span><span class="token punctuation">(</span>CMakePackageConfigHelpers<span class="token punctuation">)</span><span class="token comment"># set version</span><span class="token keyword">set</span><span class="token punctuation">(</span>version <span class="token number">3.4.1</span><span class="token punctuation">)</span><span class="token keyword">set_property</span><span class="token punctuation">(</span>TARGET MathFunctions PROPERTY <span class="token property">VERSION</span> <span class="token punctuation">$&#123;</span>version<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">set_property</span><span class="token punctuation">(</span>TARGET MathFunctions PROPERTY <span class="token property">SOVERSION</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">set_property</span><span class="token punctuation">(</span>TARGET MathFunctions PROPERTY  <span class="token variable">INTERFACE_MathFunctions_MAJOR_VERSION</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">set_property</span><span class="token punctuation">(</span>TARGET MathFunctions APPEND PROPERTY  <span class="token property">COMPATIBLE_INTERFACE_STRING</span> <span class="token variable">MathFunctions_MAJOR_VERSION</span><span class="token punctuation">)</span><span class="token comment"># generate the version file for the config file</span><span class="token function">write_basic_package_version_file</span><span class="token punctuation">(</span>  <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_BINARY_DIR</span><span class="token punctuation">&#125;</span></span>/MathFunctionsConfigVersion.cmake"</span>  <span class="token property">VERSION</span> <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">version</span><span class="token punctuation">&#125;</span></span>"</span>  COMPATIBILITY AnyNewerVersion<span class="token punctuation">)</span><span class="token comment"># create config file</span><span class="token function">configure_package_config_file</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_SOURCE_DIR</span><span class="token punctuation">&#125;</span>/Config.cmake.in  <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_BINARY_DIR</span><span class="token punctuation">&#125;</span></span>/MathFunctionsConfig.cmake"</span>  INSTALL_DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span>/cmake/MathFunctions<span class="token punctuation">)</span><span class="token comment"># install config files</span><span class="token keyword">install</span><span class="token punctuation">(</span>FILES          <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_BINARY_DIR</span><span class="token punctuation">&#125;</span></span>/MathFunctionsConfig.cmake"</span>          <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_BINARY_DIR</span><span class="token punctuation">&#125;</span></span>/MathFunctionsConfigVersion.cmake"</span>        DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span>/cmake/MathFunctions<span class="token punctuation">)</span><span class="token comment"># generate the export targets for the build tree</span><span class="token keyword">export</span><span class="token punctuation">(</span>EXPORT MathFunctionsTargets       FILE <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_CURRENT_BINARY_DIR</span><span class="token punctuation">&#125;</span></span>/MathFunctionsTargets.cmake"</span>       NAMESPACE MathFunctions::<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>构建库 <code>MathFunctions</code> 之后需要为其指定头文件目录，根据是生成库还是从已安装路径使用库，分别指定不同的头文件目录，如果对头文件目录不加以区分，那么 CMake 在创建导出信息时，将会导出依赖于当前生成目录的一个路径，这个路径显然在其他项目中无效。</p><p><code>install(TARGETS)</code> 和 <code>install(EXPORT)</code> 安装库目标和 .cmake 文件，这里 .cmake 文件则方便其他 CMake 项目导入这个库目标。生成的导出文件（.cmake文件）中包含了创建导入库的代码，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token comment"># Create imported target MathFunctions::MathFunctions</span><span class="token keyword">add_library</span><span class="token punctuation">(</span><span class="token inserted class-name">MathFunctions::MathFunctions</span> <span class="token namespace">STATIC</span> <span class="token property">IMPORTED</span><span class="token punctuation">)</span><span class="token keyword">set_target_properties</span><span class="token punctuation">(</span><span class="token inserted class-name">MathFunctions::MathFunctions</span> <span class="token namespace">PROPERTIES</span>  <span class="token property">INTERFACE_INCLUDE_DIRECTORIES</span> <span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">_IMPORT_PREFIX</span><span class="token punctuation">&#125;</span></span>/include"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>这段代码与上面我们手动导入库的 cmake 代码很相似。外部其他项目可以 include 这个 .cmake 文件，从而引用导入库 <code>MathFunctions</code>，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">include</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span>INSTALL_PREFIX<span class="token punctuation">&#125;</span>/lib/cmake/MathFunctionTargets.cmake<span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>myexe src1.c src2.c <span class="token punctuation">)</span><span class="token keyword">target_link_libraries</span><span class="token punctuation">(</span>myexe <span class="token namespace">PRIVATE</span> <span class="token inserted class-name">MathFunctions::MathFunctions</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>注：这段代码来自官方文档，但是个人觉得这里路径错了，应该是<br><code>include($&#123;INSTALL_PREFIX&#125;/lib/cmake/MathFunctions/MathFunctionTargets.cmake)</code>。</p><p>任意数量的目标都可以关联到相同的导出名称，且 <code>install(EXPORT)</code> 只需要调用一次。<strong>导出名称是全局 scope 的，所以任何目录都可以使用</strong> 。例如以下的导出名称 <code>myproj-targets</code>，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token comment"># A/CMakeLists.txt</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>myexe src1.c<span class="token punctuation">)</span><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS myexe DESTINATION lib/myproj        EXPORT myproj-targets<span class="token punctuation">)</span><span class="token comment"># B/CMakeLists.txt</span><span class="token keyword">add_library</span><span class="token punctuation">(</span>foo <span class="token namespace">STATIC</span> foo1.c<span class="token punctuation">)</span><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS foo DESTINATION lib EXPORTS myproj-targets<span class="token punctuation">)</span><span class="token comment"># Top CMakeLists.txt</span><span class="token keyword">add_subdirectory</span> <span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token keyword">add_subdirectory</span> <span class="token punctuation">(</span>B<span class="token punctuation">)</span><span class="token keyword">install</span><span class="token punctuation">(</span>EXPORT myproj-targets DESTINATION lib/myproj<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="创建包"><a href="#创建包" class="headerlink" title="创建包"></a>创建包</h2><p>我们还可以生成一个配置文件，以便 <code>find_package()</code> 可以发现目标。步骤如下，</p><ol><li>include <code>CMakePackageConfigHelpers</code> 模块，获得创建配置文件的函数。</li></ol><h3 id="创建包配置文件"><a href="#创建包配置文件" class="headerlink" title="创建包配置文件"></a>创建包配置文件</h3><p>使用 <code>CMakePackageConfigHelpers</code> 模块中的 <code>configure_package_config_file()</code> 命令生成包配置文件，<br><pre class="line-numbers language-none"><code class="language-none">configure_package_config_file($&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&#x2F;Config.cmake.in  &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;&#x2F;MathFunctionsConfig.cmake&quot;  INSTALL_DESTINATION $&#123;CMAKE_INSTALL_LIBDIR&#125;&#x2F;cmake&#x2F;MathFunctions)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br><code>INSTALL_DESTINATION</code> 的路径值为 <code>MathFunctionsConfig.cmake</code> 安装路径。</p><p><code>configure_package_config_file</code> 命令用于创建一个配置文件 <code>&lt;PackageName&gt;Config.cmake</code> 或者 <code>&lt;PackageName&gt;-Config.cmake</code>，<br><pre class="line-numbers language-none"><code class="language-none">configure_package_config_file(&lt;input&gt; &lt;output&gt;  INSTALL_DESTINATION &lt;path&gt;  [PATH_VARS &lt;var1&gt; &lt;var2&gt; ... &lt;varN&gt;]  [NO_SET_AND_CHECK_MACRO]  [NO_CHECK_REQUIRED_COMPONENTS_MACRO]  [INSTALL_PREFIX &lt;path&gt;]  )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><code>INSTALL_DESTINATION</code> 可以是绝对路径，或者是相对 <code>INSTALL_PREFIX</code> 的路径。这个命令根据输入文件替换变量（@@包围的变量）的值得到输出文件。然后再安装到指定路径，这个配置文件中设置了 <code>MathFunctionsTargets.cmake</code> 的路径。</p><h2 id="创建包版本文件"><a href="#创建包版本文件" class="headerlink" title="创建包版本文件"></a>创建包版本文件</h2><p>使用 <code>write_basic_package_version_file()</code> 创建包版本文件，当 CMAKE 使用 <code>find_package</code> 时，这个包版本文件将被 CMAKE 读取以决定版本是否兼容。</p><h2 id="从生成树中导出目标"><a href="#从生成树中导出目标" class="headerlink" title="从生成树中导出目标"></a>从生成树中导出目标</h2><p>通常，一个项目都是在被外部其他项目使用之前就生成并安装完成，但是有些情况下，我们想在生成项目后直接导出目标，跳过安装过程，这时可以使用 <code>export()</code> 达成这一目的，如上文那一大段 CMakeLists.txt 内容的最后一个命令调用，在这个调用中，我们在生成目录创建文件 <code>MathFunctionsTargets.cmake</code>，但是需要注意，这个文件与 <code>lib/cmake/MathFunctions/MathFunctionsTargets.cmake</code> 不同，不具有路径重定向功能，因为其中 <code>MathFunctions</code> 目标的几个路径属性值全部是 hardcode 的，而非使用 <code>$&#123;_IMPORT_PREFIX&#125;</code>。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>cmake tutorial</title>
      <link href="/2021/06/02/cpp/cmake_1/"/>
      <url>/2021/06/02/cpp/cmake_1/</url>
      
        <content type="html"><![CDATA[<p>cmake 的使用示例。<br><span id="more"></span></p><p>记录 cmake 的各种用法。从一个简单的例子开始入手。</p><h1 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h1><p><strong>main.cpp</strong></p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Hello World!\n"</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>CMakeLists.txt</strong><br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span><span class="token punctuation">(</span>hello_world<span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>app main.cpp<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>以上两个文件在同一目录 <code>demo</code> 下，<br><pre class="line-numbers language-none"><code class="language-none">demo| -- main.cpp| -- CMakeLists.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>在 <code>demo</code> 目录下，使用以下两个命令生成，<br><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&gt; cmake .&gt; cmake --build .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>第一个命令是 生成 Makefile，第二个命令是生成 可执行文件。这种生成方式会生成一些文件，扰乱源码，于是可以在 <code>demo</code> 下创建一个 <code>build</code> 目录，所有生成的文件均放在 <code>build</code> 目录下，这样不污染源码文件，命令如下，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">&gt; mkdir build&gt; cd build&gt; cmake ..&gt; cmake --build .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="多个源文件的生成"><a href="#多个源文件的生成" class="headerlink" title="多个源文件的生成"></a>多个源文件的生成</h1><p>文件目录为<br><pre class="line-numbers language-none"><code class="language-none">demo| -- build| -- main.cpp| -- foo.h| -- foo.cpp| -- CMakeLists.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>各文件内容为，</p><p><strong>main.cpp</strong><br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"foo.h"</span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>foo.h</strong><br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p><strong>foo.cpp</strong><br><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"foo.h"</span></span><span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Hello World!\n"</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>CMakeLists.txt</strong><br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span><span class="token punctuation">(</span>hello_world<span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>app main.cpp foo.cpp<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>如果将头文件统一放入 <code>includes</code> 目标中，即<br><pre class="line-numbers language-none"><code class="language-none">demo| -- build| -- inlcude    |-- foo.h| -- main.cpp| -- foo.cpp| -- CMakeLists.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>那么还需要指定头文件搜索路径，否则找不到头文件，指定头文件搜索路径可使用<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake">...<span class="token function">inlcude_directories</span><span class="token punctuation">(</span><span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">PROJECT_SOURCE_DIR</span><span class="token punctuation">&#125;</span></span>/includes"</span><span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>app main.cpp foo.cpp<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>其中 路径的引号可以去掉。</p><h1 id="生成库和链接库"><a href="#生成库和链接库" class="headerlink" title="生成库和链接库"></a>生成库和链接库</h1><p>修改 CMakeLists.txt 文件，其他不变，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span> <span class="token punctuation">(</span>hello_world<span class="token punctuation">)</span><span class="token keyword">include_directories</span><span class="token punctuation">(</span><span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">PROJECT_SOURCE_DIR</span><span class="token punctuation">&#125;</span></span>/includes"</span><span class="token punctuation">)</span><span class="token keyword">add_library</span><span class="token punctuation">(</span>foo foo.cpp<span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>app main.cpp<span class="token punctuation">)</span><span class="token keyword">target_link_libraries</span><span class="token punctuation">(</span>app foo<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="添加头文件搜索路径"><a href="#添加头文件搜索路径" class="headerlink" title="添加头文件搜索路径"></a>添加头文件搜索路径</h1><p>语法：</p><ul><li><code>include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])</code></li></ul><div class="table-container"><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>dirN</td><td>一个或多个相对路径或绝对路径</td></tr><tr><td>AFTER, BEFORE</td><td>搜索路径是添加到当前搜索路径列表的后面还是前面。默认行为由 CMAKE_INCLUDE_DIRECTORIES_BEFORE 指定</td></tr><tr><td>SYSTEM</td><td>添加的路径是否视作系统头文件路径</td></tr></tbody></table></div><p>由于可以是相对路径，故前面添加头文件路径也可以写作<br><pre class="line-numbers language-none"><code class="language-none">include_directories(include)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>添加的头文件搜索路径，对当前 directory 中所有 targets 以及所有 subdirectories （由 add_subdirectory() 给定） 均有效。</p><h1 id="生成目标"><a href="#生成目标" class="headerlink" title="生成目标"></a>生成目标</h1><p>语法：</p><ul><li><code>add_executable(target_name [EXCLUDE_FROM_ALL] source1 [source2...])</code></li><li><code>add_library(lib_name [STATIC|SHARED|MODULE][EXCLUDE_FROM_ALL] source1 [source2...])</code></li></ul><p>例如，<br><pre class="line-numbers language-none"><code class="language-none">add_executable(my_ext main.cpp util.cpp)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>这会生成 <code>my_exe</code> 目标（例如 linux 上使用 <code>make my_exe</code>），默认情况下，所有的可执行目标均添加到 <code>all</code> 目标下，如果要从 <code>all</code> 下排除某个目标，可使用 <code>EXCLUDE_FROM_ALL</code> 参数，<br><pre class="line-numbers language-none"><code class="language-none">add_executable(my_exe EXCLUDE_FROM_ALL main.cpp)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p><code>add_library</code> 用于生成库，<code>BUILD_SHARED_LIBS</code> BOOL 型变量控制生成一个 static 库还是 shared 库，例如 <code>cmake .. -DBUILD_SHARED_LIBS=ON</code>，也可以直接指定，<br><pre class="line-numbers language-none"><code class="language-none">add_library(my_lib SHARED lib.cpp)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><code>MODULE</code> 指定这个库在 runtime 时使用 <code>dlopen</code> 之类的函数进行动态加载。</p><h1 id="MACROS"><a href="#MACROS" class="headerlink" title="MACROS"></a>MACROS</h1><p>宏和函数的区别是，函数本身是一个新的 scope，而宏则在当前 context 中执行，因此，函数中定义的变量在函数结束后变得未知，而宏中的变量在宏结束后继续保持定义。<br>例子：<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">macro</span><span class="token punctuation">(</span>set_my_variable _INPUT<span class="token punctuation">)</span>  <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">"<span class="token interpolation"><span class="token punctuation">$&#123;</span><span class="token variable">_INPUT</span><span class="token punctuation">&#125;</span></span>"</span> <span class="token operator">STREQUAL</span> <span class="token string">"Foo"</span><span class="token punctuation">)</span>    <span class="token keyword">set</span><span class="token punctuation">(</span>my_output_variable <span class="token string">"foo"</span><span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">set</span><span class="token punctuation">(</span>my_output_variable <span class="token string">"bar"</span><span class="token punctuation">)</span>  <span class="token keyword">endif</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">endmacro</span><span class="token punctuation">(</span>set_my_variable<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>使用宏，<br><pre class="line-numbers language-none"><code class="language-none">set_my_variable(&quot;Foo&quot;)message(STATUS $&#123;my_output_variable&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><h1 id="多层级项目"><a href="#多层级项目" class="headerlink" title="多层级项目"></a>多层级项目</h1><p>项目目录<br><pre class="line-numbers language-none"><code class="language-none">CMakeLists.txteditor&#x2F;    CMakeLists.txt    src&#x2F;        editor.cpphighlight&#x2F;    CMakeLists.txt    include&#x2F;        highlight.h    src&#x2F;        highlight.cpp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>文件内容为，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token comment"># CMakeLists.txt</span><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span> <span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token keyword">add_subdirectory</span><span class="token punctuation">(</span>highlight<span class="token punctuation">)</span><span class="token keyword">add_subdirectory</span><span class="token punctuation">(</span>editor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>highlight 库，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token comment"># highlight/CMakeLists.txt</span><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span> <span class="token punctuation">(</span>highlight<span class="token punctuation">)</span><span class="token keyword">add_library</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span><span class="token variable">PROJECT_NAME</span><span class="token punctuation">&#125;</span> src/highlight.cpp<span class="token punctuation">)</span><span class="token keyword">target_include_directories</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span><span class="token variable">PROJECT_NAME</span><span class="token punctuation">&#125;</span> <span class="token namespace">PUBLIC</span> include<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>使用 <code>target_include_directories()</code> 代替 <code>include_directories()</code>，那么头文件搜索路径可以传递到这个库的使用者那里。</p><p>可执行程序，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token comment"># editor/CMakeLists.txt</span><span class="token keyword">cmake_minimum_required</span><span class="token punctuation">(</span><span class="token property">VERSION</span> <span class="token number">3.15</span><span class="token punctuation">)</span><span class="token keyword">project</span> <span class="token punctuation">(</span>editor<span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span><span class="token variable">PROJECT_NAME</span><span class="token punctuation">&#125;</span> src/editor.cpp<span class="token punctuation">)</span><span class="token keyword">target_link_libraries</span><span class="token punctuation">(</span><span class="token punctuation">$&#123;</span><span class="token variable">PROJECT_NAME</span><span class="token punctuation">&#125;</span> <span class="token namespace">PUBLIC</span> highlight<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>cmake 自动处理 highlight 的库文件路径和头文件路径。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>指定安装时的所作的事情，即 <code>make install</code>，或者使用 <code>cmake --install .</code>。</p><h2 id="安装目标文件"><a href="#安装目标文件" class="headerlink" title="安装目标文件"></a>安装目标文件</h2><p><code>install(TARGETS &lt;target&gt;... [...])</code></p><p>target 指定被安装的目标，可以是多个，<code>[...]</code> 中指定安装选项，常见选项有，</p><ul><li>DESTINATION</li></ul><p>指定目标安装的路径，可以是绝对路径或者相对路径，如果是相对路径，那么路径是相对于 <code>CMAKE_INSTALL_PREFIX</code>，此值默认为 <code>/usr/local</code>（linux），可以在命令选项中更改 <code>cmake -DCMAKE_INSTALL_PREFIX=/my/path ..</code></p><ul><li>PERMISSIONS</li></ul><p>指定安装文件的权限，值可以是 <code>OWNER_READ, OWNER_WRITE, OWNER_EXECUTE, GROUP_READ, GROUP_WRITE, GROUP_EXECUTE, WORLD_READ, WORLD_WRITE, WORLD_EXECUTE, SETUID, SETGID</code> </p><p>多个目标可以是可执行文件，动态库，静态库，以及头文件等，可以通过选项 <code>RUNTIME, LIBRARY, ARCHIVE, PUBLIC_HEADER, PRIVATE_HEADER</code> 等分别指定，例如，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token function">INSTALL</span><span class="token punctuation">(</span>TARGETS myapp, mylib, mystaticlib    RUNTIME DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_BINDIR</span><span class="token punctuation">&#125;</span>    LIBRARY DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span>    ARCHIVE DESTINATION <span class="token punctuation">$&#123;</span><span class="token variable">CMAKE_INSTALL_LIBDIR</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><ul><li>CONFIGURATIONS</li></ul><p>指定安装规则所应用的生成配置，例如 Debug，Release，这仅适用于 <code>CONFIGURATIONS</code> 之后的选项上，例如，对于 Debug 和 Release 配置，分别指定不用的安装路径，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS target    CONFIGURATIONS Debug    RUNTIME DESTINATION Debug/bin<span class="token punctuation">)</span><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS target    CONFIGURATIONS Release    RUNTIME DESTINATION Release/bin<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>注：可通过 <code>-DCMAKE_BUILD_TYPE=Debug</code> 指定生成配置。</p><ul><li>RENAME</li></ul><p>重命名被安装的目标文件。这个选项仅在命令中只有一个文件被安装的时候可以用。</p><ul><li>OPTIONAL</li></ul><p>如果被安装的文件不存在，那么不会抛出错误。</p><ul><li>EXCLUDE_FROM_ALL</li></ul><p>从默认安装中排除此文件的安装。</p><ul><li>COMPONENT</li></ul><p>给安装规则指定一个组件名，于是可以安装指定的组件，而其他组件则不被安装。在全安装（不知道组件名）时，所有除了 EXCLUDE_FROM_ALL 的安装规则都将被执行。默认情况安装规则的组件名为 <code>Unspecified</code>。</p><p>完整的安装目标的命令如下，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>TARGETS targets... [EXPORT &lt;export-name<span class="token punctuation">></span>]        [[ARCHIVE|LIBRARY|RUNTIME|OBJECTS|<span class="token property">FRAMEWORK</span>|<span class="token property">BUNDLE</span>|          <span class="token property">PRIVATE_HEADER</span>|<span class="token property">PUBLIC_HEADER</span>|<span class="token property">RESOURCE</span>]         [DESTINATION &lt;dir<span class="token punctuation">></span>]         [PERMISSIONS permissions...]         [CONFIGURATIONS [Debug|Release|...]]         [COMPONENT &lt;component<span class="token punctuation">></span>]         [NAMELINK_COMPONENT &lt;component<span class="token punctuation">></span>]         [OPTIONAL] [<span class="token property">EXCLUDE_FROM_ALL</span>]         [NAMELINK_ONLY|NAMELINK_SKIP]        ] [...]        [INCLUDES DESTINATION [&lt;dir<span class="token punctuation">></span> ...]]        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><ul><li>EXPORT</li></ul><p>给安装的目标文件关联到一个导出上，导出名字为 <code>export-name</code>。EXPORT 必须出现在其他选项之前。</p><h2 id="安装普通文件"><a href="#安装普通文件" class="headerlink" title="安装普通文件"></a>安装普通文件</h2><p>命令如下，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>&lt;FILES|PROGRAMS<span class="token punctuation">></span> files...        <span class="token property">TYPE</span> &lt;type<span class="token punctuation">></span> | DESTINATION &lt;dir<span class="token punctuation">></span>        [PERMISSIONS permissions...]        [CONFIGURATIONS [Debug|Release|...]]        [COMPONENT &lt;component<span class="token punctuation">></span>]        [RENAME &lt;name<span class="token punctuation">></span>] [OPTIONAL] [<span class="token property">EXCLUDE_FROM_ALL</span>]<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>如果给出的是文件相对路径，那么是相对于当前源目录 <code>CMAKE_SOURCE_DIR</code>。<br>FILES 表示普通文件，PROGRAMS 表示非目标文件的可执行程序，如脚本。</p><ul><li>TYPE</li></ul><p>不同的 TYPE 值，默认安装路径也不同。</p><h2 id="安装目录"><a href="#安装目录" class="headerlink" title="安装目录"></a>安装目录</h2><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>DIRECTORY dirs...        <span class="token property">TYPE</span> &lt;type<span class="token punctuation">></span> | DESTINATION &lt;dir<span class="token punctuation">></span>        [FILE_PERMISSIONS permissions...]        [DIRECTORY_PERMISSIONS permissions...]        [USE_SOURCE_PERMISSIONS] [OPTIONAL] [MESSAGE_NEVER]        [CONFIGURATIONS [Debug|Release|...]]        [COMPONENT &lt;component<span class="token punctuation">></span>] [<span class="token property">EXCLUDE_FROM_ALL</span>]        [FILES_MATCHING]        [[PATTERN &lt;pattern<span class="token punctuation">></span> | REGEX &lt;regex<span class="token punctuation">></span>]         [EXCLUDE] [PERMISSIONS permissions...]] [...]<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>DIRECTORY</li></ul><p>此选项后面跟一个或多个目录，用于被安装到指定 <code>DESTINATION</code> 下。dirs 这个目录如果末尾没有 <code>/</code>，那么这个目录内容连同目录自身都将被安装，否则只安装目录的内容。</p><ul><li>USE_SOURCE_PERMISSIONS</li></ul><p><code>FILE_PERMISSIONS</code> 和 <code>DIRECTORY_PERMISSIONS</code> 用于指定目录中文件和目录的权限。如果指定了 <code>USE_SOURCE_PERMISSIONS</code> 且未指定 <code>FILE_PERMISSIONS</code>，那么从源目录结构中复制文件权限。</p><ul><li>PATTERN REGEX</li></ul><p>精细粒度的控制目录安装。PATTERN 匹配完整的文件名，REGEX 使用正则匹配。例子，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>DIRECTORY icons scripts/ DESTINATION share/myproj        PATTERN <span class="token string">"CVS"</span> EXCLUDE        PATTERN <span class="token string">"scripts/*"</span>        PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ                    GROUP_EXECUTE GROUP_READ<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>将 <code>icons</code> 目录和 <code>scripts</code> 目录内容 安装到 <code>share/myproj</code>， 其中 <code>CVS</code> 子目录或文件不被安装。对于 <code>scripts/*</code> 中的文件，指定权限）。</p><p>在 <code>PATTERN &quot;CVS&quot; EXCLUDE</code> 中，如果去掉 <code>EXCLUDE</code>，那么 “CVS” 子目录或文件依然会被安装。</p><ul><li>FILES_MATCHING</li></ul><p>默认情况下，无论文件是否匹配中，都会被安装。如果在所有匹配模式前面增加 <code>FILES_MATCHING</code> 选项，那么那些未被任何模式匹配中的文件或目录则不会被安装。例如，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>DIRECTORY src/ DESTINATION include/myproj        FILES_MATCHING PATTERN <span class="token string">"*.h"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>仅安装源目录中的头文件。</p><h2 id="安装时脚本运行"><a href="#安装时脚本运行" class="headerlink" title="安装时脚本运行"></a>安装时脚本运行</h2><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>[[SCRIPT &lt;file<span class="token punctuation">></span>] [CODE &lt;code<span class="token punctuation">></span>]]        [COMPONENT &lt;component<span class="token punctuation">></span>] [<span class="token property">EXCLUDE_FROM_ALL</span>] [...]<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>SCRIPT 指定安装时需要执行的 CMAKE 脚本，如果脚本文件是相对路径，那么是相对于当前源路径。</p><p>CODE 指定安装时需要执行的 CMAKE 代码，例如，<br><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token keyword">install</span><span class="token punctuation">(</span>CODE <span class="token string">"MESSAGE(\"Sample install message.\")"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h2 id="安装导出"><a href="#安装导出" class="headerlink" title="安装导出"></a>安装导出</h2><pre class="line-numbers language-none"><code class="language-none">install(EXPORT &lt;export-name&gt; DESTINATION &lt;dir&gt;        [NAMESPACE &lt;namespace&gt;] [[FILE &lt;name&gt;.cmake]|        [PERMISSIONS permissions...]        [CONFIGURATIONS [Debug|Release|...]]        [EXPORT_LINK_INTERFACE_LIBRARIES]        [COMPONENT &lt;component&gt;]        [EXCLUDE_FROM_ALL])install(EXPORT_ANDROID_MK &lt;export-name&gt; DESTINATION &lt;dir&gt; [...])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装导出。导出目标在 <code>install(TARGETS)</code> 中的 <code>EXPORT</code> 选项指定。<code>NAMESPACE</code> 指定导出目标名称的命令空间（相当于前缀），默认情况下安装的导出文件名为 <code>&lt;export-name&gt;.cmake</code>，但可以通过 <code>FILE</code> 进行重命名。<code>DESTINATION</code> 指定这个 .cmake 文件安装的路径。</p>]]></content>
      
      
      
        <tags>
            
            <tag> cmake </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Normalization</title>
      <link href="/2021/03/08/dl/norm/"/>
      <url>/2021/03/08/dl/norm/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Batch-Norm"><a href="#1-Batch-Norm" class="headerlink" title="1. Batch Norm"></a>1. Batch Norm</h1><p>对 channel 之外的所有维度做归一化，即在 <code>(B,H,W)</code> 上做归一化，每个 channel 独立进行，</p><script type="math/tex; mode=display">y=\frac {x-E[x]} {\sqrt{Var[x]+\epsilon}} \cdot \gamma + \beta</script><p>其中 $\gamma, \beta$ 是需要学习的参数。</p><p>作用：</p><ol><li>防止过拟合。单个样本的输出依赖于整个 mini-batch，防止对某个样本过拟合</li><li>加快收敛。梯度下降过程中，每一层的 W 和 b 都会不断变化，导致输出结果分布也不断变化，后层网络需要不停地适应这种变化，而 BN 可使得每一层输入分布近似不变。</li><li>防止梯度消失。以 sigmoid 激活函数为例，经过 BN 使得输出在中心附近，梯度较大。</li></ol><h1 id="2-Layer-Norm"><a href="#2-Layer-Norm" class="headerlink" title="2. Layer Norm"></a>2. Layer Norm</h1><p>Layer Norm 对每个样本进行归一化，即在 <code>(C,H,W)</code> 上做归一化，每个样本独立进行。</p><h1 id="3-Instance-Norm"><a href="#3-Instance-Norm" class="headerlink" title="3. Instance Norm"></a>3. Instance Norm</h1><p>Instance Norm 对每个样本的每个 channel 进行归一化，即在 <code>(H,W)</code> 上做归一化。</p><h1 id="4-Group-Norm"><a href="#4-Group-Norm" class="headerlink" title="4. Group Norm"></a>4. Group Norm</h1><p>与 Layer Norm 类似，不同的是 Group Norm 将 <code>(C,H,W)</code> 在 channel 上分组，假设分为 <code>G</code> 组，那么在 <code>(C/G, H, W)</code> 上做归一化。</p><h1 id="5-Weight-Norm"><a href="#5-Weight-Norm" class="headerlink" title="5. Weight Norm"></a>5. Weight Norm</h1><p>论文：<a href="https://arxiv.org/abs/1602.07868">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</a></p><p>神经网络的一个节点计算为</p><script type="math/tex; mode=display">y=\phi(\mathbf w\cdot \mathbf x+b) \tag{5-1}</script><p>其中参数 $\mathbf w$ 可解耦为一个标量和一个方向向量，</p><script type="math/tex; mode=display">\mathbf w=\frac g {||\mathbf v||} \mathbf v \tag{5-2}</script><p>使得 $\mathbf w$ 的欧氏范数等于 $g$，与 $\mathbf v$ 无关，仅方向与 $\mathbf v$ 相关，给了 $\mathbf v$ 更多的自由度。</p><p>损失关于 $g$ 的梯度为</p><script type="math/tex; mode=display">\nabla_g L=\frac {\nabla_{\mathbf w}L \cdot \mathbf v}{||\mathbf v||} \tag{3}</script><p>由于 </p><script type="math/tex; mode=display">\mathbf w = g (\mathbf v^{\top}\mathbf v)^{-1/2} \mathbf v</script><p>故有</p><script type="math/tex; mode=display">\begin{aligned}\frac {\mathbf w}{d\mathbf v}&=g(\mathbf v^{\top}\mathbf v)^{-1/2}\frac {d\mathbf v}{d\mathbf v} +\mathbf v \frac {d(g(\mathbf v^{\top}\mathbf v)^{-1/2})}{d\mathbf v}\\&=g(\mathbf v^{\top}\mathbf v)^{-1/2}I+\mathbf v(-g (\mathbf v^{\top}\mathbf v)^{-3/2} \mathbf v^{\top})\\&=\frac g {||\mathbf v||} I - \frac g {||\mathbf v||^3} \mathbf v \mathbf v^{\top}\end{aligned}</script><p>损失关于 $\mathbf v$ 的梯度为</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\mathbf v}L&=\nabla_{\mathbf w}L \left(\frac g {||\mathbf v||}- g \mathbf v \mathbf v^{\top}\right)\\&=\frac g {||\mathbf v||}\nabla_{\mathbf w}L- \frac g {||\mathbf v||^3}(\nabla_{\mathbf w}L )\mathbf v \mathbf v^{\top}\\&=\frac g {||\mathbf v||}\nabla_{\mathbf w}L-\frac {g\nabla_g L} {||\mathbf v||^2} \mathbf v\end{aligned}</script><p>实现时不直接更新 $g$，因为 $g \ge 0$ 这个必要条件的限制，我们改用 $g$ 的 log-scale 即 $s=\log g$ 进行更新，这样 $s \in \mathbb R$ 的更新更加直接。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lightweight</title>
      <link href="/2021/03/05/obj_det/lightweight/"/>
      <url>/2021/03/05/obj_det/lightweight/</url>
      
        <content type="html"><![CDATA[<h1 id="ThunderNet"><a href="#ThunderNet" class="headerlink" title="ThunderNet"></a>ThunderNet</h1><p>(two-stage detector)</p><p>移动设备上计算能力有限，而现在的很多 CV 实现方式都需要较强的计算力，这导致这些任务难以在移动设备上 real-time 的实现。本文研究了 two-stage 目标检测 real-time 的有效性，并提出了一个轻量级的 two-stage 检测器，名为 ThunderNet。</p><span id="more"></span><p>简介：</p><ol><li>研究了先前轻量级 backbone 的缺点，并提出了一个新的为目标检测而设计的轻量级 backbone  <code>SNet</code></li><li>沿用 Light-Head R-CNN 的 detection head 结构</li><li>进一步压缩 RPN 和 R-CNN 两个 subnet，以加快计算速度。 </li><li>small backbone 会带来一定的性能降级，所以设计两个高效率模块 <code>Context Enhancement Module</code> 和 <code>Spatial Attention Module</code>。CEM 结合多个 scale 的 feature （backbone 中浅层到深层的 feature）以利用 local 和 global 信息。SAM 利用 RPN 学习到的信息来微调 RoI warping 中的特征。</li><li>input resolution：<code>320x320</code>，小 size 可以加快网络的 inference 速度。</li></ol><h2 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h2><p><strong>Receptive Field:</strong></p><p>大感受野可以利用更多的上下文信息，同时能有效地 encode 像素间的 long-range 关系，这对目标尤其大目标的定位非常关键。</p><p><strong>early &amp; late stage feature:</strong></p><p>高层特征具有更强的语义性，更具有辨别性，低层特征具有更丰富的空间细节信息，所以高低层特征都需要用到。</p><p><strong>SNet</strong></p><p>SNet 作为专为 real-time 目标检测而设计的轻量级的 backbone。SNet 以 ShuffleNetV2 为基础进行改造，将所有的 <code>3x3</code> depthwise conv 改为 <code>5x5</code> depthwise conv，以获取更大的感受野，同时保持差不多的计算速度。还有其他的一些改动这里不一一指出。</p><p>depthwise conv: 每个通道独立进行二维卷积，需要 $c_{in}$ 个 $k \times k$ 卷积，得到的 feature 的 shape 与输入 feature shape 相同，然后再执行 $1 \times 1 \times c_{in}\times c_{out}$ 的跨通道卷积，输出 feature 的channel 为 $c_{out}$。 </p><h2 id="Detection-Part"><a href="#Detection-Part" class="headerlink" title="Detection Part"></a>Detection Part</h2><p>压缩 RPN 和 Detection Head。Light-Head R-CNN 的 detection head 虽然是轻量级，但是配合小的 backbone 时，依然太过 heavy，导致 backbone 与 dection head 之间产生 imbalance。</p><p>压缩 RPN：将原来的 256-d <code>3x3</code> conv 替换为 <code>5x5</code> 的 depthwise 和 256-d <code>1x1</code> conv。anchor 的配置为 scale：<code>&#123;32, 64, 128, 256, 512&#125;</code>，aspect ratio：<code>&#123;1:2, 3:4, 1:1, 4:3, 2:1&#125;</code>。</p><p>detection head： Light-head R-CNN 中的 thin feature map $\alpha \times p \times p$，其中 $p=7, \ \alpha=10$，由于 thundernet 中 backbone 和 input image size 均较小，所以继续降低 $\alpha=5$。采用 PSRoI，由于 PSRoI 输出的 feature 仅 245-d，那么 R-CNN subnet 中的 fc 全连接层为 1024-d。</p><h2 id="CEM"><a href="#CEM" class="headerlink" title="CEM"></a>CEM</h2><p>context enhancement module。</p><p>Light-Head R-CNN 使用 global convolutional network（GCN） 生成 thin feature map，GCN 具有 large kernel，使得 Receptive Field 增大，从而可以 encode 更多的上下文信息，但是 GCN 会给 SNet 带来很多计算量，thundernet 不使用 GCN，而是使用 CEM 解决这个问题。</p><p>借鉴 FPN 的思想（FPN 本身结构比较复杂），聚合multi-scale 的 局部信息和全局信息，得到具有较强判别性的 feature。CEM merge 来自以下 layer 的 feature：$C_4, \ C_5, \ C_{glb}$，其中 $C_{glb}$ 表示 global feature，通过对 $C_5$ 执行 global average pooling 得到。对以上三个 scale 的 feature 使用 <code>1x1-245</code> conv，输出 channel 均为 245，且 $C_5$ 的输出特征还需要 <code>2x</code> upsample，使得与 $C_4$ 的输出 feature 具有相同的 size，而 $C_{glb}$ 的输出本质是是一个标量，所以经 broadcast 具有与 $C_4$ 输出 feature 具有相同的 size，然后这三组相同 spatial size 的 feature 再合并。</p><h2 id="SAM"><a href="#SAM" class="headerlink" title="SAM"></a>SAM</h2><p>spatial attention module。</p><p>在 RoI warping 的输入 feature （上面说讨论的 thin feature maps）上，我们希望 负例 region 内的 feature 值足够小，正例 region 内的 feature 足够大，但是 thundernet 比正常的检测网络小，所以会难以学习到正确的 feature 分布，本文使用 SAM 解决这个问题。</p><p>SAM 利用 RPN 得到的信息来微调 RoI warping 的输入 feature 分布。RPN 被训练用来区分正负例，那么 RPN 的输出 feature 可以利用起来，于是，SAM 的两个输入：1. RPN 的输出 feature；2. CEM 输出的 thin feature maps。SAM 的输出 feature 为，</p><script type="math/tex; mode=display">\mathcal F^{SAM}=\mathcal F^{CEM} \cdot sigmoid[\theta(\mathcal F^{RPN})]</script><p>其中 $\theta$ 用于维度转换，使得 $\mathcal F^{RPN}$ 和 $\mathcal F^{CEM}$ 具有相同的维度，文中使用 <code>1x1</code> conv 来执行这个维度转换。</p><p>SAM 的输出将作为原先 RoI warping 的输入。</p><p>thunernet 整个网络结构如图 1，</p><p><img src="/images/obj_det/lightweight_fig1.png" alt=""><center>图 1</center></p><h1 id="Light-Head-R-CNN"><a href="#Light-Head-R-CNN" class="headerlink" title="Light-Head R-CNN"></a>Light-Head R-CNN</h1><p>(two-stage detector)</p><p>设计了一个轻量级的 detection head，有如下两种设计：</p><ol><li>L：配合 large backbone，文中采用 ResNet101</li><li>S：配合 small backbone，文中采用 Xception</li></ol><p>backbone 最后一个 conv block 记为 $C_5$，$C_5$ 之后使用一个 separable conv（依次为 <code>kx1</code> 和 <code>1xk</code> 两个 conv），最终输出 channel 为 $10 \times p \times p$，而 R-FCN 中对应的 channel 为 $(C+1) \times p \times p$（$p \times p$ 表示 bin，因为是 positive-sensitive），所以相对 R-FCN，这里的设计更加 small。</p><p><strong>R-CNN subnet</strong></p><p>PSRoI pooling 之后，使用一个 2048-d 的全连接层，然后分两支，一支用于分类预测，一支用于box 回归预测，其中分类分支使用一个 C-d 的全连接，回归分支使用 4-d 的全连接层。</p><p><strong>RPN</strong></p><p>RPN 作用于 $C_4$ 之上，根据 anchor box 预测出一组 proposals，anchor 的 scale 为 <code>&#123;32,64,128,256,512&#125;</code>，aspect ratio 为 <code>&#123;1:2,1:1,2:1&#125;</code>。</p><p>整个网络的结构图如下，<br><img src="/images/obj_det/lightweight_fig2.png" alt=""><center>图 2 </center></p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anchor-free Object Detection</title>
      <link href="/2021/02/25/obj_det/anchor_free/"/>
      <url>/2021/02/25/obj_det/anchor_free/</url>
      
        <content type="html"><![CDATA[<h1 id="FCOS"><a href="#FCOS" class="headerlink" title="FCOS"></a>FCOS</h1><p>每个 scale 的 detection head 输出的 feature maps 上的每一 location 处预测 <code>C</code> 个分类和 <code>4</code> 个坐标，以及一个 center 得分，对每种分类采用二值分类。某个 location 位于 gt box 内，则为正例样本，否则为负例样本，box 回归 target 记为 $\mathbf t^{<em>}=(l^{</em>}, t^{<em>}, r^{</em>}, b^{*})$，某一 location <code>(x,y)</code> 位于 gt box $B_i=(x_0^{(i)}, y_0^{(i)}, x_1^{(i)}, y_1^{(i)})$ 内部，那么有</p><script type="math/tex; mode=display">l^{*}=x-x_0^{(i)}, \quad t^{*}=y-y_0^{(i)}</script><script type="math/tex; mode=display">r^{*}=x_1^{(i)} - x, \quad b^{*}=y_1^{(i)} - y</script><p>损失为</p><script type="math/tex; mode=display">\begin{aligned} L({\mathbf p_{x,y}}, {\mathbf t_{x,y}})&=\frac 1 {N_{pos}} \sum_{x,y} L_{cls}(\mathbf p_{x,y}, c_{x,y}^{*}) \\ &+ \frac {\lambda} {N_{pos}} \sum_{x,y} \mathbb I(c_{x,y}^{*}>0) \cdot L_{reg}(\mathbf t_{x,y}, t_{x,y}^{*})\end{aligned}</script><p>其中，$c_{x,y}^{<em>}$ 表示 location <code>(x,y)</code> 处所属分类，如果是负例，$c_{x,y}^{</em>}=0$，如果是正例，那么 $c_{x,y}^{*}$ 为fg 分类id。分类损失 $L_{cls}$ 使用 Focal Loss。坐标损失 $L_{reg}$ 使用 IOU Loss。</p><p>如果某个 location 位于多个 gt box 交叠的区域，那么这个 location 该回归哪个 gt box 呢？ 答案是使用 multi-level 预测，见如下。</p><h2 id="FPN-for-FCOS"><a href="#FPN-for-FCOS" class="headerlink" title="FPN for FCOS"></a>FPN for FCOS</h2><p>引入 FPN，使用 multi-level 的 feature maps，分别记为 ${P_3, P_4, P_5, P_6, P_7}$，其中 $P_3, P_4, P_5$ 由 backbone 中的 $C_3, C_4, C_5$ 经 <code>1x1</code> conv 输出得到。$P_6, p_7$ 则分别在 $P_5, P_6$ 上使用 stride=2 的 conv 得到，各 level feature 上的 stride 分别为 <code>8,16,32,64,128</code>。</p><p>在不同 scale 的 feature 上限制所预测的 box 的回归值范围，具体而言，对于 $P_i$，如果某 location 满足 $\max(l^{<em>},t^{</em>},r^{<em>},b^{</em>})&gt;m_i$ 或者 $\max(l^{<em>},t^{</em>},r^{<em>},b^{</em>}) &lt; m_{i-1}$，那么这个 location 为负例，不计入坐标回归损失 $L_{reg}$。本文中 $m_2=0, \ m_3=64, \ m_4=128, \ m_5=256, \ m_6=512, \ m_7=\infty$（这是借鉴了 anchor based 中的 anchor 的 base scale 为 8）。</p><p>这样，不同的 level 的 feature 负责预测不同 size 范围的目标。同一 location 如果有多个目标，通常，这些交叠的目标大小不在同一个范围，于是降低了 ambiguous location，如果仍然存在 location 属于多个大小差不多目标，那么人为的将此 location 用来预测 size/area 最小的那个目标。</p><p>与其他基于 FPN 的目标检测器一样，不同 level 的 检测 head 分支上参数共享。观察到不同 level<br>的 feature 回归不同范围的目标（例如 $P_3$ 回归范围为 $[0,64]$），那么不同 level 的检测 head 如果完全相同，会显得不合理，所以，比起 single scale FCOS 中使用的 $exp(x)$（因为回归 target 为正，所以需要使用 $exp(x)$ 处理一下），在 multi scale FCOS 中，改为 $exp(s_i x)$，这里的 $s_i$ 是需要训练学习的参数，以自动调整其大小。</p><h2 id="Center-ness-for-FCOS"><a href="#Center-ness-for-FCOS" class="headerlink" title="Center-ness for FCOS"></a>Center-ness for FCOS</h2><p>实验发现，有大量低质量的预测 box，这是有距目标中心较远的 location 预测出来的结果。如何抑制它们？</p><p>增加一个 single-layer 分支，与分类分支并列，如图 1，</p><p><img src="/images/obj_det/anchor_free_fig1.png" alt=""><center>图 1</center></p><p>新增分支用于预测 location 的中心度 “center-ness”：是目标中心的置信度，用 location 与所属目标中心的归一化距离来表示，记回归目标为 $\mathbf t^{<em>}=(l^{</em>},t^{<em>},r^{</em>},b^{*})$，center-ness 目标为</p><script type="math/tex; mode=display">\text{centerness}^{*}=\sqrt{\frac {\min(l^*, r^*)} {\max(l^*,r^*)} \times \frac {\min(t^*, b^*)} {\max(t^*,b^*)}}</script><p>使用平方根是为了降低 center-ness 值的衰减速度，center-ness 值范围位于 $[0,1]$，使用 BCE loss 进行训练。</p><p>测试阶段，<strong>最终的得分计算为 center-ness 与分类得分 相乘</strong>，以最终得分进行预测 box 的 ranking，然后经 NMS，过滤掉那些低质量的预测结果。</p><p>另一种 center-ness 的替换方案是，仅仅使用 gt box 中心区域的 location 作为正例，代价是需要引入一个额外参数来指定中心区域的大小。当然，也可以两者结合使用。</p><h1 id="CornerNet"><a href="#CornerNet" class="headerlink" title="CornerNet"></a>CornerNet</h1><p>anchor based 目标检测的缺点：1. 需要大量的 anchor，导致正负例不均衡，训练速度慢。2. 需要很多超参数（例如，anchor 数量、大小以及 aspect ratio 等），在 multi-scale feature 情况下，超参数更多。</p><p>本文介绍了一个 anchor free 的目标检测方法，检测目标的左上和右下两个角点。为什么检测角点呢？</p><ol><li>box 中心难以定位，因为中心依赖于目标的 4 个边坐标，而定位一个角点仅需要两个边坐标，加上本文提出的另一个设计 <code>corner pooling</code>，利用角点的定义，例如左上角，<code>corner pooling</code> encoding 当前某 location 右侧的 feature vector，以及下方的 feature vector，这种 encoding 使得角点预测更加准确。</li><li>密集离散化 box 时，记 feature 的 size 为 <code>(w,h)</code>，那么所有可能的角点的数量为 O(wh)，而 anchor box 的可能性则非常大，根据排列组合原理， anchor 的宽有 w 种可能，高有 h 种可能，故 anchor 的 size 有 wh 种可能，然后分布在 feature 上时，每个 anchor 有 wh 种可能，故一共 $O(w^2h^2)$。当然如果考虑到 anchor 不要超出 feature map 之外，那么 anchor 的宽为 1 时，有 w 种可能，宽为 2 时，有 w-1 种可能，… 宽为 w 时，有 1 种可能，一共有 $w+(w-1)+\cdots +1$，同样地，高也一样，所以分布在 feature 上各种 anchor 的可能性一共有 $(1+2+\cdots+w)(1+2+\cdots+h)=\frac {w(w+1)h(h+1)} 4$。当然，anchor based 检测方法为了缩减 anchor 数量，在 feature 上每个 location 使用不同 scale 和 aspect ratio 的 anchor 共 K 个，故此时一共有 $Kwh$ 个。</li></ol><h2 id="网络框架"><a href="#网络框架" class="headerlink" title="网络框架"></a>网络框架</h2><p>base ConvNet 采用 hourglass network，后接两个模块，分别用于左上角点和右下角点。每个模块有独立的 corner pooling 模块（因为左上和右下角点的 corner pooling 的方向不同），hourglass network 的 feature 经过 pooling 之后，得到 heatmaps，embeddings 和 offsets。</p><p><strong>heatmap:</strong></p><p>两组 heatmaps，每组 heatmap 有 C channels，其中 C 为分类数量，heatmap 的大小为 $H \times W$，heatmap 表示某个 location 是角点且属于某个分类的得分，可见 heatmap 是 binary mask。</p><p>对某个 corner 而言，只有一个 location 对应到它，这个 location 作为正例，其他 location 相对这个 corner 而言均为负例，这里不对所有负例等值惩罚，而是对这个 corner 一定半径范围的负例 location 降低惩罚，这是考虑到，即使是负例 location，如果很靠近对应的 corner，这些负例构成的预测 box 依然可以很好的覆盖 gt box。半径大小由对应的 gt box 确定，根据 IOU 的阈值下限 t（文中 t 设为 0.3）。如何降低惩罚？</p><p>使用一个二维高斯函数，随着距离增大平滑的递减，</p><script type="math/tex; mode=display">f_{cij}=\begin{cases} e^{-\frac {x^2+y^2}{2 \sigma^2}} & x^2+y^2 \le r^2 \\ 0 & \text{otherwise} \end{cases}</script><p>其中，下标 <code>(i,j)</code> 表示 location （样本）的坐标，$x, y$ 表示 location 据对应 corner 的横纵坐标差，$c$ 表示 gt 的分类。$\sigma=r/3$ 用于控制衰减速度。$r$ 为半径。</p><p>heatmap 表示 location 是 corner 且属于某一分类的得分，采用 focal loss，考虑以上二维高斯函数作为惩罚因子，</p><script type="math/tex; mode=display">L_{det}=-\frac 1 N \sum_{c=1}^C\sum_{i=1}^H \sum_{j=1}^W \begin{cases} (1-p_{cij})^{\alpha} \log p_{cij} & y_{cij}=1 \\ (1-f_{cij})^{\beta}p_{cij}^{\alpha} \log (1-p_{cij}) & o.w. \end{cases}</script><p>其中，$p_{cij}$ 表示 heatmap 上某 location 预测值。$y_{cij}$ 表示 heatmap 上某处的 gt target 值。N 表示一个 image 上 object 的数量。$\alpha=2, \ \beta=4$ 为超参数，控制各项损失贡献。从上式可见，仅对 corner 一定半径范围内的 negative location 降低了惩罚。</p><p><strong>offset:</strong></p><p>由于下采样，hourglass 的 feature size 较原 image size 小，记下采样率为 n，那么 gt corner $(x,y)$ 到 heatmap 上的位置为 $(\lfloor x/n, y/n \rfloor)$，再映射回 image 上是，坐标精度有所损失，损失范围为 $[0,n)$，当目标size 较小时，影响 IOU，所以增加一个坐标偏差的预测，gt offset 为</p><script type="math/tex; mode=display">\mathbf o_k=\left(\frac {x_k} n - \lfloor \frac {x_k} n \rfloor, \frac {y_k} n - \lfloor \frac {y_k} n \rfloor \right)</script><p>其中 $k$ 表示第 k 个 gt corner，预测的 offset 记为 $\hat \mathbf o_k$，使用 smooth L1 损失。</p><p><strong>embedding:</strong></p><p>左上 corner 和右下 corner 是分开预测的，如何确定哪个左上和哪个右下是一对呢（来自同一个 gt box）？</p><p>为每个 corner 生成 embedding vector，如果某一对 corner 来自同一个 gt box，那么它们的 embedding 应该相似，例如 vector 的 L1 范数足够小。</p><p>由于 embedding 没有 target 值，作者使用 <code>pull</code> 和 <code>push</code> 两种损失来学习，记 $e_{tk}$ 为第 k 个目标左上 corner 的 embedding，$e_{bk}$ 为第 k 个目标右下 corner 的 embedding，那么损失为 </p><script type="math/tex; mode=display">L_{pull}=\frac 1 N \sum_{k=1}^N [(e_{tk}-e_k)^2+(e_{bk}-e_k)^2]</script><script type="math/tex; mode=display">L_{push}=\frac 1 {N(N-1)} \sum_{k=1}^N \sum_{j=1, j\ne k}^N \max (0, \Delta-|e_k-e_j|)</script><script type="math/tex; mode=display">e_k=\frac {e_{tk}+e_{bk}} 2</script><p>其中，N 为 image 中目标数量，$\Delta=1$ 表示两个来自不同目标的 corner 的 embeding 的最大区分度。</p><p>测试阶段，分别得到 K 个 top-left 角点和 K 个 bottom-right 角点，一共 $K^2$ 个 pair 的可能组合，计算每个 pair 的 embedding 的 L1 范数，如果超过一个阈值（设为 0.5），那么这个 pair 不成立，当然还有其他筛选条件，例如来自 heatmap 的得分筛选等，然后使用 soft nms，去除冗余检测结果。</p><h2 id="Corner-Pooling"><a href="#Corner-Pooling" class="headerlink" title="Corner Pooling"></a>Corner Pooling</h2><p>这个模块比较关键，从 hourglass 的输出特征到上面说的三个 feature <code>heatmap, offset, embedding</code>，中间经过了 Corner Pooling 模块。</p><p>hourglass 输出为 $f_t, f_l, f_b, f_r$ 分别表示 上左下右 四个 side，其中 $f_t, f_l$ 经过左上角点预测分支，$f_b, f_r$ 经过右下角点预测分支。以左上角点预测分支为例，记 corner pooling 的输入 feature size 为 $H \times W$，某一 location <code>(i,j)</code> 在 $f_t$ 上，经 corner pooling 后，从 <code>(i,j)</code> 到 <code>(H,j)</code> 之间的特征向量（从这个 location 开始垂直向下看）执行 max 操作得到输出值 $t_{ij}$，同理，从这个 location 向右看的特征向量经过 max 操作得到输出值 $l_{ij}$，</p><script type="math/tex; mode=display">t_{ij}=\begin{cases} \max[f_t(i,j), t_{(i+1)j}] & i < H \\ f_t(H,j) & i=H \end{cases}</script><script type="math/tex; mode=display">l_{ij}=\begin{cases} \max[f_l(i,j), l_{i(j+1)}] & i < H \\ f_l(i,W) & i=H \end{cases}</script><p>对于 $f_t$，从下到上递归执行，对于 $f_l$，从右到左递归执行。</p><p>预测模块的网络结构如图 2，<br><img src="/images/obj_det/anchor_free_fig2.png" alt=""><center>图 2. backbone 后接一个修改过的 residule module，下方是 shortcut 分支，上方是 2x conv，分别表示 left-most 和 top most，然后分别经 corner pooling 后，再 element-wise add，然后经 conv ，再与 shortcut 分支进行 merge（element-wise add)，然后经过右边的网络</center></p><h2 id="Hourglass-Network"><a href="#Hourglass-Network" class="headerlink" title="Hourglass Network"></a>Hourglass Network</h2><p>之前的 backbone 都是 VGG，ResNet 比较常见，也有用 densenet 的，但是 hourglass 网络还没见过，所以这里简单介绍一下。</p><p>Hourglass network 是由一个或多个 hourglass 模块组成的全卷积网络。Hourglass 模块先将 input feature 下采样，然后在上采样到原来的 resolution，由于下采样中的 maxpooling 损失了一些细节信息，所以使用 skip layer 将信息带到上采样的 feature 中。堆叠多个 hourglass 模块可捕获更高 level 的信息（这些信息的语义性更强）。</p><p>本文中，下采样使用 stride=2 的 conv 代替 maxpooling。</p><p>总损失为 </p><script type="math/tex; mode=display">L=L_{det}+\alpha L_{pull} + \beta L_{push} + \gamma L_{off}</script>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>One-stage Object Detection</title>
      <link href="/2021/02/23/obj_det/one_stage/"/>
      <url>/2021/02/23/obj_det/one_stage/</url>
      
        <content type="html"><![CDATA[<h1 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h1><ol><li><p>one-stage detector</p></li><li><p>unified detection：image 经过网络得到 <code>SxS</code> 大小的 feature map，相当于把 image 划分为 <code>SxS</code> 的 grid，如果其中目标中心落于某个 grid cell，那么这个 grid cell 负责预测这个目标，网络最终的输出为 <code>S*S*(C+B*5)</code>，其中 C 表示分类数量，最多 B 个目标中心落于同一个 grid cell，每个 box 有 4 个坐标和 1 个 conf，这个 conf 表示预测 box 包含目标的置信度，也可以认为是预测 box 与 gt box 的 IOU。C 个预测值表示在此处有目标时的条件概率值，<code>Pr(Classi|Object)</code>，这里分类条件概率与 box 数量 <code>B</code> 无关。测试阶段，分类类型相关的 conf 值则为</p><script type="math/tex; mode=display">Pr(Class_i|Object) * P(conf)</script></li><li><p>没有 SSD 中的 default box，也没有 Faster R-CNN 中的 anchor/proposal，YOLO 直接在 feature map 上每个点预测 box 坐标和分类概率，所以还需要一个 conf，表示预测 box 包含目标的置信度</p></li><li><p>文中input image size 为 <code>448x448</code>，经过6次下采样，得到<code>7x7</code>的feature，通过一个 fully connection（输出unit数量 <code>1470=7*7*30</code>），得到feature 上所有 box 的预测坐标、conf 以及分类得分</p></li><li><p>在 feature map 上使用 fully connection生成每个 grid cell 的预测数据，其中 (x,y) 表示预测目标中心坐标，这是归一化的，且表示<b>距所在 cell 的左端和上端的距离</b>。</p></li></ol><h1 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h1><p>YOLOv1 虽然是 fast 的，但是比起 SOTA 检测系统，缺点在于定位错误较明显，相较于 region proposal-based 的检测方法，YOLOv1 的 recall 低。YOLOv2 中对其进行改善，使用了：</p><ol><li><p>Batch Normalization。</p></li><li><p>High Resolution<br> \<br> YOLOv1 中baseline 分类预训练时 image size 为 <code>224x224</code>，然后迁移到检测数据集上训练时，image size 为 <code>448x448</code>，这种输入大小的突变对目标检测不友好，所以训练过程中一直调整输入大小，使得网络适应以增加稳定性，具体策略为：每隔 10 个训练 batch，调整输入大小为</p> <pre class="line-numbers language-none"><code class="language-none">int dim &#x3D; (rand() % 10 + 10) * 32<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 保证输入大小是 32 的整数倍，YOLOv2 中有 5 次下采样，这是匹配的。YOLOv1 有 6 次下采样，这里去掉一次下采样，为了使feature 具有 higher resolution，而这又是为了配合下面的 anchor box，在feature 上每个 position 使用一组 anchor box 来预测，可以降低定位误差。</p></li><li><p>Convolution with Anchor Boxes<br> \<br> 参考 Faster R-CNN 中的 RPN，使用 anchor box。feature 上每个 position 使用大小形状不同的 k 个 anchor 进行预测，k 的取值以及各 anchor 的大小形状，根据数据集中gt box 聚类（k-means）计算得到，聚类使用的距离采用 IOU，</p> <pre class="line-numbers language-none"><code class="language-none">d(anchor, cluster-center)&#x3D;1-IOU(anchor, cluster-center)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>Direct location prediction<br> \<br> 基于 region proposal 的位置预测过程为：记位置预测值 $(t_x, t_y)$ 为相对offset，根据anchor box坐标，计算最终预测box 中心坐标为</p><script type="math/tex; mode=display">x=t_x \cdot w_a+x_a, \quad y=t_y \cdot h_a + y_a</script><p> 在训练开始阶段，由于是随机初始化模型参数，上式会导致预测 box 位置与 anchor 偏差很大，这会使得训练要花很长一段时间才能使得 box 的预测位置稳定下来（<b>注意：不使用上式</b>）。YOLOv2 沿用 YOLOv1 中预测中心坐标与所在 cell 的左边线和上边线的距离，这样偏差就不会很大，设cell <code>(i,j)</code> 处的某个 anchor 对应的坐标预测值记为 $t_x, t_y, t_w, t_h$，feature 大小为 $(w_f, h_f)$，anchor 基于 feature 的宽高为 $(w_a,h_a)$，那么计算预测 box 的实际归一化坐标为</p><script type="math/tex; mode=display">x=(i+t_x)/w_f</script><script type="math/tex; mode=display">y=(j+t_y)/h_f</script><script type="math/tex; mode=display">w=\exp(t_w) \cdot w_a/w_f</script><script type="math/tex; mode=display">h=\exp(t_h) \cdot h_a/h_f</script></li></ol><p>每个 box 均有 5 个坐标预测值（包括 4 个坐标偏差和 1 个是否包含目标的 conf）和 C 个分类得分预测值，最终输出大小则为 $k \cdot s \cdot s \cdot (5+C)$，其中 k 为 anchor 数量。</p><h1 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h1><p>主要是借鉴别的好的 idea 整合到 YOLO 里面来。</p><ol><li><p>沿用 YOLOv2 中 anchor box，使用聚类得到 k 个 anchor，每个 anchor 预测 4 个坐标 offset，1 个 objectness conf，以及 C 个分类概率。坐标 offset 的计算与 YOLOv2 中相同</p></li><li><p>与 gt box 有最大 IOU 的 anchor 的 conf target 值为 1，而其他非最佳 IOU 但是 IOU 大于某个阈值（0.5）的 anchor 则被忽略。IOU 低于 0.5 的则为负例 anchor，负例 anchor 只需要计算 conf 损失，不需要计算坐标 offset 损失和分类损失。</p></li><li><p>YOLOv3 在三个 scale 的 feature 上进行预测，YOLOv1 和 YOLOv2 均只有单个 scale 的 feature。这是为了借鉴 FPN 的思想。由于有了 multi-scale 的 features，每个 feature 上的每个 position 处只预测 3 个 anchor boxes，假设某个 feature size 为 <code>NxN</code>，那么预测 tensor 为 <code>NxNx[3*(4+1+C)]</code>，其中 C 为 foreground 分类数量。</p></li><li><p>Baseline 结构如 darknet-53 所示，用于抽取 feature，在 ImageNet 上预训练。目标检测网络结构如 yolov3.cfg 配置文件中所示。借鉴了 ResNet 中 shortcut 技巧（主要也是因为网络更 deep 了）。聚类得到 9 个 anchor size，然后按大小排序，每 3 个一组作为对应 scale feature 上所用的 anchor。</p></li></ol><h1 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h1><ol><li>baseline: VGG 等</li><li>one-stage detector。与 Faster R-CNN 相比，省去了 proposals 生成过程，而是在 feature map 上每个 position 有一组 prior box（k 个），然后 feature maps 上使用具有 <code>(c+4)k</code> filters 的 conv，而非 fully connection，进行预测输出，每个position 输出 <code>(c+4)k</code> 个值，表示预 c 个分类得分，和此处 box 的坐标 offsets。同时，使用 multi scale 的 feature maps，以覆盖多个不同大小级别的目标预测。</li><li>论文中针对 300x300 的输入图像，一共使用了 6 个不同 scale 的 feature，每个 feature 上的各点生成 prior box 的数量为 <code>4,6,6,6,4,4</code>，因为认为数据集中，中间 scale 的目标数量要多一些。各 feature 的边长为 <code>38, 19, 10, 5, 3, 1</code>，单个 image 上所有 prior box 数量为 <code>(38*38+3*3+1*1)*4+(19*19+10*10+5*5)+6=8732</code></li><li>由于使用 multi scale feature maps，所以不同 level 的 feature 负责不同大小的目标检测，假设共 m 个不同 scale 的 feature（文中 m=6），那么每个 level 的 feature 上的 default box 的基础边长为<script type="math/tex; mode=display">s_k=s_{min}+\frac {s_{max}-s_{min}}{m-1}(k-1), \ k \in [1,m]</script> 其中最小最大边长为 <code>[min, max]=[0.2, 0.9]</code>，所有不同 scale 的边长 s 均匀散落在这个区间上</li><li>一个image上的 default box 数量非常多（第3点中指出高达 8732个），其中匹配的 default box是指与 gt 有最大 IOU 或者 IOU &gt; 0.5 的那些，称为正例，其余的为负例，显然负例会特别多，导致数据 unbalanced，所以将负例按 conf 预测损失倒序排列，选择 top N 的负例，这里 N 取正例数量的 3 倍，每个 level 的 feature 独立进行这种 hard negative mining</li></ol><h1 id="DSSD"><a href="#DSSD" class="headerlink" title="DSSD"></a>DSSD</h1><p>在 SSD 的基础上增加 deconvolution layer，具体是对 SSD 中用于预测所有 level 的 feautre，自顶向下，最顶 level 的 feature 上使用一个 prediction module 进行预测，然后这个 feature 经过 deconvolution，再与 SSD 中 resolution 更大一级的 feature 进行融合，然后使用 prediction module 进行预测，上一个融合后的 feature 再经 deconvolution，与 SSD 中 resolution 更大一级的 feature 进行融合，递归进行这个过程，直到原 SSD 中所有 level 的 feature 均进行了融合和预测，整个网络形成一个 hour-glass 结构，也就是 “encoder-decoder”。这与 FPN 其实很类似，只是这个 top-down 模块中的 upsample 换成了 deconvolution。</p><h1 id="RetinaNet-Focal-Loss"><a href="#RetinaNet-Focal-Loss" class="headerlink" title="RetinaNet(Focal Loss)"></a>RetinaNet(Focal Loss)</h1><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>one-stage 速度更快，结构更简单，但是比起 two-stage，准确率还差的不少，其中一个原因是 one-stage 使用了密集 location 采样，这就导致 fg-bg 分类不均衡，本文使用 Focal Loss，通过附加低权重，降低已经分类好的样本的对 loss 的贡献，从而 focus on hard examples。</p><blockquote><p>他方法如 OHEM 等也可以解决 one-stage 中的分类不平衡问题</p></blockquote><h3 id="Balanced-Cross-Entropy"><a href="#Balanced-Cross-Entropy" class="headerlink" title="Balanced Cross Entropy"></a>Balanced Cross Entropy</h3><script type="math/tex; mode=display">CE(p,y)=\begin{cases} - \alpha \log p & y=1 \\ -(1-\alpha) \log(1-p) & y=0\end{cases}</script><p>其中 $\alpha \in [0, 1]$，其值可取类频数的倒数，例如数据集大小 N，fg 数量为 $N_1$，bg 数量为 $N_0$（$N=N_1+N_0$），那么<br>$\alpha=\frac {N_0} N$，表示增大正例的损失贡献。</p><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><script type="math/tex; mode=display">FL(p,y)=\begin{cases} - （1-p)^{\gamma} \log p & y=1 \\ -p^{\gamma} \log(1-p) & y=0\end{cases}</script><p>其中 $\gamma&gt;0$。</p><p>记</p><script type="math/tex; mode=display">p_t=\begin{cases} p & y=1 \\ 1-p & y=0\end{cases}</script><script type="math/tex; mode=display">\alpha_t=\begin{cases} \alpha & y=1 \\ 1-\alpha & y=0\end{cases}</script><p>于是 $\alpha$ balanced CE 损失为</p><script type="math/tex; mode=display">CE(p_t)=-\alpha_t \log(p_t)</script><p>Base Focal Loss 为</p><script type="math/tex; mode=display">FL(p_t)=-(1-p_t)^{\gamma} \log (p_t)</script><p>$\alpha$ balanced Focal Loss 为</p><script type="math/tex; mode=display">FL(p_t)=-\alpha_t (1-p_t)^{\gamma} \log (p_t)</script><h2 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h2><p>为了验证 Focal Loss 的有效性，设计了这个 RetinaNet。Focal Loss 用在 Classification Subnet 中。</p><p><strong>backbone:</strong> FPN on ResNet。使用 $P_3 \sim P_7$ level 的 feature，其中 $P_3 \sim P_5$ 由 ResNet 的 $C_3 \sim C_5$ 获得，然后再使用一个 $3 \times 3$-s2 的 conv（无 ReLU） 得到 $P_6$，最后使用 ReLU + $3 \times 3$-s2 conv 得到 $P_7$。$P_l$ feature 的 stride 是 $2^l$，每个 feature 均为 C=256 channels。feature 上 anchor 的 base size 为 $2^{l+2}$，每个 position 有 9 个 anchors，aspect ratio 由配置给出，每个 anchor 均有 K 个分类得分（包含了背景），4 个位置坐标。</p><p>$IOU \ge 0.5$ 的为 正 anchor，$IOU &lt; 0.4$ 的为负 anchor，$0.4 \le IOU &lt; 0.5$ 的 anchor 忽略，不参加训练。正 anchor 与 对应的 gt box 之间计算 offset，作为 box regression target，classification target 则为 one-hot vector，向量中 anchor 所对应的目标分类的 entry 为 1， 其余 entry 为 0。</p><p>backbone 后接两个 subnetworks：用于分类和 box 回归（每个 level 的 feature 上均如此）。</p><p><strong>Classification Subnet:</strong> 这是一个 FCN 子网络，参数在所有 pyramid level 之间共享。在 pyramid feature 上，使用 4 个 <code>3x3</code> conv，每个 conv 均有 C=256 个 filters，且每个 conv 后跟一个 ReLU，然后是一个 <code>3x3</code> 的 conv，有 <code>KA</code> 个 filters，其中 K 为分类数量，A 为 anchor 数量。这个子网络比 RPN 有更 deep 的结构，文中发现，这种设计比某些超参数的选择还要重要。</p><p><strong>Box Regression Subnet:</strong> 与 Classification Subnet 结构类似，只是最后一个 conv 的 filters 数量为 <code>4A</code>。</p><p>这两个 subnet 的结构就像天线一样位于 FPN 之上，故称 RetinaNet。</p><p>以前使用 heuristic sampling（RPN）或 hard example mining(OHEM, SSD) 来选择 mini-batch（数量为 256）的 anchors，但是这里使用 Focal Loss，单个 image 上的 anchor 数量达到 ~100k（正例 anchor 与 负例 anchor 之和），总的 focal loss 则是这所有 anchor 上 Focal Loss 之和，并除以正例 anchor 数量。</p><h1 id="STDN"><a href="#STDN" class="headerlink" title="STDN"></a>STDN</h1><p>Scale-Transferrable Detection Network，为了解决目标 scale 多样性的问题。</p><p>主流的目标检测方法中， Faster RCNN 中只有单一 scale 的 feature，其 receptive field 是固定的，而目标的 scale 和 aspect ratio 则是各不相同的，所以存在不一致问题。 SSD 在不同 depth 的 layer 的 feature 上预测，anchor 的 scale 与 feature 的 scale 有关，这一定程度上解决了目标 scale 多样性的问题，但是在小目标上表现并不好，因为 low feature 用于预测小目标，而 low feature 的语义性较弱，于是使用 FPN，通过径向连接和 top-down 模块，将高层 feature 与低层 feature 融合，使得低层特征在保持更多细节信息的同时，兼具语义特征，FPN 缺点在于需要谨慎地构建 feature pyramids，并且 FPN 网络结构带来了一定的计算负担（FPN 是在 Faster RCNN 基础上将 baseline 增加 FPN 结构，所以是一个 two-stage 检测器）。</p><p>STDN 以 DenseNet 为 baseline，利用了 DenseNet 中高低层 feature concatenation 的特性，使得 feature 具有更强的表征能力。在 DenseNet 最后一个 DenseBlock 的最后一个 Layer 之上， 使用Scale-Transfer Module（STM），获得 multi scale features，用于预测，STM 没有参数，不会引入很多计算负担。</p><ol><li>使用 DenseNet-169 为 baseline (growth rate=32)</li><li>将 stem block 改为 3 个 <code>3x3</code> 的 conv 和一个 <code>2x2</code> 的 mean-pooling，其中第一个 <code>3x3</code> conv 的 stride=2。原来 DenseNet 中采用 <code>7x7-s2</code> 和 <code>3x3-s2</code> 的 conv，我们认为大卷积核和连续的下采样对检测小目标的准确性不利。</li><li>当 input size 为 <code>300x300</code>，DenseNet 的 输出 feature size 为 <code>9x9</code>。</li><li><p>网络结构为 stem —&gt; DB1 —&gt; T1 —&gt; DB2 —&gt; T2 —&gt; DB3 —&gt; T3 —&gt; DB4 =&gt; STM，其中 DB 表示 DenseBlock，T 表示 Transition Layer。T3 输出为 <code>640x9x9</code>，STM 包含 6 个 scale 的 features，如下表所示<br> | output size | layer |<br> | — | — |<br> |800x1x1 | 9x9 mean-pool, stride 9 (Input DB4_concat5)|<br> |960x3x3 | 3x3 mean-pool, stride 3 (Input DB4_concat10)|<br> |1120x5x5| 2x2 mean-pool, stride 2 (Input DB4_concat15)|<br> |1280x9x9| Identity layer (Input DB4_concat20) |<br> |360x18x18| 2x scale-transfer layer (Input DB4_concat25)|<br> |104x36x36| 4x scale-transfer layer (Input DB4_concat32)|</p><p> 已知 DenseBlock 中第 $l$ 个 layer 的 output channen 为 $k_0+l*32$，那么上表中第一个 layer 为 <code>9x9</code> 的均值池化层，输出为最小 scale 的 feature，输出 size 为 <code>800x1x1</code>，这个 layer 的输入为 DB4 中第 5 个 layer 的 output，根据公式其输出 channel 为 $640+5\times 32=800$。其他 layer 的输入也是 DB4 中某个 layer 的输出。</p><ul><li>Identity layer 表示输出就是输入本身</li><li>scale-transfer layer 表示将输入的 channel 压缩 $r^2$ 倍（$r \times$ scale-transfer layer），而 $W, H$ 则均增大 $r$ 倍，rearrange 公式为，<script type="math/tex; mode=display">I_{x,y,c}^{SR}=I_{\lfloor x/r \rfloor,\lfloor y/r \rfloor, r\cdot mod(y,r)+mod(x,r)+c\cdot r^2}^{LR}</script></li></ul></li><li><p>每个 scale 的 feature 分别根据 dense anchor 进行预测，anchor 与 gt box 匹配标准为：有最大 IOU 或者 IOU &gt; 0.5，其余 anchor 为负例，根据 hard negative mining 使得正负例数量比为 <code>1:3</code>。</p></li><li><p>抽取的 feature 分两路，分别到分类分支和 box 回归分支。分类分支由一个 <code>1x1</code> conv 和两个 <code>3x3</code> conv 组成，每个 conv 后接 BN+ReLU，最后一个 conv 的 channel 为 <code>KA</code>，其中 K 为分类数量（fg 数量 + 一个 bg），A 为每个 position 预测的 anchor 数量。回归分支的结构与分类分支相同，只是最后一个 conv 的 channel 为 <code>4A</code>。</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Two-stage Object Detection</title>
      <link href="/2021/02/20/obj_det/two_stage/"/>
      <url>/2021/02/20/obj_det/two_stage/</url>
      
        <content type="html"><![CDATA[<h1 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h1><ol><li>baseline: VGG, resnet</li><li>RPN: 生成 proposals</li><li>ROIPooling: RPN 生成的 proposals 在 conv5_3 上对应的 feature region 被 Pooling 成固定的 <code>7x7</code> 大小，然后在经 FC layer</li><li>detection head: 与 Fast R-CNN 中一样，两个分支，分别预测分类和坐标</li><li>从一个图中取 top 256 个 proposals 作为 mini-batch，送入 detection subnetwork</li><li>多个 scale 和 aspect ratio 组合，以应对不同尺寸和形状的目标检测</li></ol><h1 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h1><ol><li>在 Faster R-CNN 基础上，将 baseline 由 ResNet/VGG 换成 FPN（multi-scale + top-down feature fused)</li><li>in-network feature pyramids，每个 level 的 feature 独立做检测</li><li>low-level feature 有利于小目标检测，但是单纯的 low-level feature 还不够，因为其特征表达能力不够强，所以使用 top-down 和 径向连接，合并了 high-level feature。这对检测多种 scale 的目标非常有用。</li><li>backbone 选用 resnet，利用 FPN 生成 feature pyramids，而原来 faster rcnn 中为 single feature，故给每个 level 的 feature 配备 RPN 和 rcnn head 分支，这些分支在所有 level feature 上共享参数。resnet 有 conv2，conv3，conv4，conv5，这里在 conv5 之上增加一个 1x1 conv（有 subsampling），专门用于检测大目标，这样共 5 个 level。</li><li>feature level 为 P2，P3，P4，P5，P6，每个 level 上的 anchor 使用一个 scale <code>8</code>，由于stride 分别为 4，8，16，32，64，故 anchor 在 input image 上实际 size 为 32，64，128，256，512，分别作为每个 level 上的 base anchor，每个 anchor 的 aspect ratio 为 <code>[0.5, 1, 2]</code>。</li><li>RPN 生成的 proposals，根据不同的尺寸，使用不同的 level 分支来负责检测，分支 <code>Pk</code> 的下标确定方法为<script type="math/tex; mode=display">k=\lfloor 4 + \log_2(\sqrt {wh} / 224) \rfloor</script></li></ol><h1 id="Deformable-ConvNet"><a href="#Deformable-ConvNet" class="headerlink" title="Deformable ConvNet"></a>Deformable ConvNet</h1><p>可变形卷积网络提出两个模块。</p><h2 id="Deformable-Conv"><a href="#Deformable-Conv" class="headerlink" title="Deformable Conv"></a>Deformable Conv</h2><p>为卷积操作的 feature grid 中每一个 position 增加 2-d offset（横纵坐标偏差）。记输出 feature map 上某一点位置 $p_0$，输入 feature 上的 grid sampling 根据感受野</p><script type="math/tex; mode=display">\mathcal R=\{(-1,-1),(-1,0),...,(0,1),(1,1)\}</script><p>确定，那么这一点的常规卷积输出为</p><script type="math/tex; mode=display">y(p_0)=\sum_{p_n \in \mathcal R} w(p_n) \cdot x(p_0+p_n)</script><p>输入 feature grid 每一点 $p_n$ 增加一个坐标偏差 $\Delta p_n$，于是可变形卷积为</p><script type="math/tex; mode=display">y(p_0)=\sum_{p_n \in \mathcal R} w(p_n) \cdot x(p_0+p_n+\Delta p_n)</script><p>在这个输入 feature 上使用一个 conv，得到 resolution 相同，但是 channal 为 2N 的输出，表示没一点的 offset，显然 offset 不是整数。</p><p>记 $p=p_0+p_n+\Delta p_n$，使用双线性插值计算 $p$ 点的像素值，</p><script type="math/tex; mode=display">x(p)=\sum_{q} G(q,p) \cdot x(p)</script><p>其中 $q$ 是输入 feature 上任意一点，$G(q,p)$ 表示关联权重，</p><script type="math/tex; mode=display">G(q,p)=g(q_x, p_x) \cdot g(q_y, p_y)</script><script type="math/tex; mode=display">g(a,b)=\max(0, 1-|a-b|)</script><p>显然最多只用到 p 周围最近的 4 个点来做双线性插值。也就是说，p和 q 的坐标相差不超过 1，但是注意，$\Delta p_n$ 表示的坐标偏差可能会超过 1。</p><p>得到 offset 后，再在原来的 input feature 上进行变形卷积，得到 output feature map。</p><h2 id="Deformable-ROI-Pooling"><a href="#Deformable-ROI-Pooling" class="headerlink" title="Deformable ROI Pooling"></a>Deformable ROI Pooling</h2><p>Region proposal-based 目标检测均采样 ROI Pooling 将输入特征 池化到一个固定大小的 feature（例如 7x7）。先来看常规 ROI Pooling 操作，记 ROI Pooling 将 <code>wxh</code> 大小的输入特征池化为一个 <code>kxk</code> 的特征，输入特征的左上角记为 <code>p_0</code>，那么 output feature map 上一点 <code>(i,j)</code> 的值为</p><script type="math/tex; mode=display">y(i,j)=\sum_{p \in bin(i,j)} x(p_0+p)/n_{ij}</script><p>其中 $n_{ij}=|bin(i,j)|$，$bin(i,j)$ 表示输出上一点 <code>(i,j)</code> 对应到输入平面上一个 bin 中的各点（相对于左上角）的位置，这个 bin 由下式确定，</p><script type="math/tex; mode=display">\lfloor i \cdot w /k \rfloor \le p_x < \lceil (i+1) \cdot w / k \rceil</script><script type="math/tex; mode=display">\lfloor j \cdot h /k \rfloor \le p_y < \lceil (j+1) \cdot h / k \rceil</script><p>现在同样地，我们需要为这个 bin 生成坐标偏差，每一个 bin 对应一个 2-d offset，记 $bin(i,j)$ 的 2-d offset 为 $\Delta p_{ij}$，得到变形 ROI Pooling 为</p><script type="math/tex; mode=display">y(i,j)=\sum_{p \in bin(i,j)} x(p_0+p+\Delta p_{ij}) / n_{ij}</script><p>如何得到这个 bin 的坐标偏差呢?</p><p>在 input feature 上使用 ROI Pooling 得到池化后的 feature，然后再经过一个 fc（全连接层）生成归一化后的 offset，记为 $\Delta \hat p_{ij}$，再 element-wise 乘上 ROI 的 w 和 h，得到 bin 的坐标偏差 offset</p><script type="math/tex; mode=display">\Delta p_{ij}=\gamma \cdot \Delta \hat p_{ij} \ \circ \ (w,h)</script><p>其中 $\gamma$ 是一个预定义标量值，用于调节 offset 的幅度。文中取 $\gamma=0.1$。</p><p><b>offset 的归一化是必须的，这样使得 offset 的学习不受 ROI size 的影响。</b></p><h3 id="Position-Sentive-PS-ROI-Pooling"><a href="#Position-Sentive-PS-ROI-Pooling" class="headerlink" title="Position-Sentive(PS) ROI Pooling"></a>Position-Sentive(PS) ROI Pooling</h3><p>这里的 Position-Sentive 是指与 bin 的位置 <code>(i,j)</code> 有关。分类 subnet 和 box 回归 subnet 情况不同。</p><ol><li>分类分支。input feature 经过 conv 后得到 channel 为 $k^2(C+1)$，其中 k 为 池化后特征平面边长，C 为分类 fg 数量，每个分类每个 bin 有自己独立的 feature，池化时，使用这个独立的 feature，而上面的池化过程，对每个 bin 均采用同一个 feature（即 input feature）。</li><li>box 回归分支。同分类分支类似，input feature 经过 conv 得到 channel 为 $2k^2(C+1)$ 的 feature，同样特征值表示归一化后的 offset，element-wise 乘上 ROI 的 w 和 h，得到实际的 offset 值。</li></ol><h1 id="Deformable-ConvNet-v2"><a href="#Deformable-ConvNet-v2" class="headerlink" title="Deformable ConvNet v2"></a>Deformable ConvNet v2</h1><p>可变形卷积网络 v1 的缺点是对目标边界信息的捕获不够准确，在可变形卷积网络 v2（DCNv2）中，使用更多的 conv layer 学习 offset，且每个样本不仅学习 offset，还学习 feature 的幅值调整。</p><p>为了更好的理解可变形卷积，文中给出了如下视图：</p><ol><li>有效感受野</li><li>有效取样点位置</li><li>有界误差（小误差）的显著性区域</li></ol><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>Baseline 组成：Faster R-CNN + ResNet + aligned RoIPooling</p><p>应用 <strong>可变形：</strong><br>RPN 加在 stage4 的输出特征之上，conv5 中的 conv 则采用可变性卷积，RoIPooling 采用可变形 RoIPooling。conv5 中的 stride=16，而非原来的 32，这是为了提高 feature map 的 resolution，将 conv5_1 的 stride 改为 1 即可实现。</p><p>conv5 的输出特征之上，采用 Fast R-CNN 检测head，其他包括 RoIPooling 和两个 fc（全连接层），然后是两个并列的分类分支和回归分支。</p><h2 id="提升可变形能力"><a href="#提升可变形能力" class="headerlink" title="提升可变形能力"></a>提升可变形能力</h2><p>可变形卷积应用到 conv3，conv4 和 conv5 中所有的 3x3 conv 上（DCNv1 中仅 conv5 中的 3x3 conv 应用了可变形卷积）</p><p><strong>调整可变形 conv:</strong></p><p>引入一个调制机制，使得可变形卷积不但可以调整 offset，还可以调整 feature 的各 location 处的幅值。极端情况下，这个模块可以通过设置 feature 某处幅值为 0 从而决定不再注意这个 location 处的信号。</p><p>记卷积核卷积采样点（location）为 $K$，其中第 $k$ 个 location 的权值和 offset 分别为 $w_k, \ p_k$，例如 <code>3x3</code> 卷积的采样点数量为 $K=9$，且</p><script type="math/tex; mode=display">p_k \in \{(-1,-1), (-1,0),...,(1,1)\}</script><p>输入特征 x 和输出特征 y 上一点 p 处的特征值分别记为 $x(p), \ y(p)$，调整后的可变形卷积为</p><script type="math/tex; mode=display">y(p)=\sum_{k=1}^K w_k \cdot x(p+p_k+\Delta p_k)\cdot \Delta m_k</script><p>其中 $\Delta p_k$ 是可学习的 offset，$\Delta p_k$ 是非归一化的。$\Delta m_k \in [0,1]$ 是幅值修正系数。$x(p+p_k+\Delta p_k)$ 使用双线性插值求得。</p><p>$\Delta p_k, \ \Delta m_k$ 通过输入 feature map 上使用另一 conv layer 获得 <code>3K</code> channel 的输出，前 2K 表示 $\Delta p_k$，后 K channel 的数据继续经 sigmoid，得到 $\Delta m_k$。</p><p><strong>调整可变形RoIPooling:</strong></p><p>RoIPooling 将 RoI 划分为 <strong>K</strong> 个 bins（例如 <code>7x7</code>），每个 bin 中，取若干个采样点（例如 <code>2x2</code>），采样点的平均作为这个 bin 的输出。对 RoIPooling 赋予调整后的可变形能力，同可变形卷积一样，除了 offset 还有幅值，分别记为 $\Delta p_k$ 和 $\Delta m_k$，表示第 <code>k</code> 个 bin，那么这个 bin 的输出改为，</p><script type="math/tex; mode=display">y(k)=\sum_{j=1}^n x(p_{kj}+\Delta p_k) \cdot \Delta m_k / n</script><p>其中 $n$ 表示 bin 中采样点数量，$p_{kj}$ 表示第 <code>k</code> 个 bin 中第 <code>j</code> 个采样点坐标。与 DCNv1 中类似，针对每个 bin 有 offset 和幅值变化。$x(p_{kj}+\Delta p_K)$ 采样双线性插值计算该处特征值。</p><p><strong>分支结构：</strong></p><p>RoIPooling 从 feature maps 上得到 RoI feature patch，后跟 2x fc（两个全连接层），dimension 均为 1024，然后是一个 3K channel 的 fc，其他前 2K 表示归一化的 offset，乘以 RoI 的宽高得到实际的坐标 offset $\{\Delta p_k\}_{k=1}^K$。剩余的 K 通过 sigmoid layer 得到幅值伸缩系数 $\{\Delta m_k\}_{k=1}^K$。</p><h2 id="R-CNN-特征模拟"><a href="#R-CNN-特征模拟" class="headerlink" title="R-CNN 特征模拟"></a>R-CNN 特征模拟</h2><p>可视化显示，对于常规 ConvNet 和可变形 ConvNet，分类 node 对应的 error-bounded saliency region 超出 RoI 区域，导致 RoI 之外的 Image 内容影响了目标检测结果的准确性。R-CNN 论文中，分类预测集中在根据 RoI 来 crop 得到的 image 上，这使得分类准确性得到提升。我们这里的可变形 ConvNet 基于 Faster R-CNN，而直接结合 Faster R-CNN 和 R-CNN，使得训练和推断均变得缓慢。另一方面，可变形 ConvNet 可调整 bin 输出的幅值，通过令 幅值放缩系数为 0，可屏蔽范围之外多余的 context，但是实验效果并不理想，猜想这可能是因为传统的 Faster R-CNN 训练损失无法有效驱动这种表征（指可变形 RoIPooling）的学习过程。</p><p>于是，引进一个 feature 模拟的损失，与 R-CNN 从 cropped image 中抽取的特征类似，可以驱动可变形 Faster R-CNN 学习如何着重于特征表示。这种特征模拟仅用于正例 RoI 上，对负例 RoI 效果不好。<br>下图是网络结构，<br><img src="/images/obj_det/two_stage_fig2.png" alt=""></p><center>图2. 基于 Faster R-CNN 的可变形卷积和 R-CNN 特征模拟</center><p>给定一个 RoI <code>b</code>，在 feature 模拟分支上，<code>b</code> 对应的原输入 image 上的部分 crop 出来，并 resize 到 <code>224x224</code> 大小，经调整后的可变形卷积网络后得到 <code>14x14</code> 的 feature，然后使用调整的 RoIPooling 得到 <code>7x7</code>（这里的 <code>7x7</code> 是一个示例，其他情况下可修改），然后经 2x fc 得到最终的 RCNN 分支 1024-D 的特征，记为 $f_{RCNN}(b)$，这个特征经过 <code>C+1</code>-way 的 softmax 分类（这里笔者觉得应该再使用一个 <code>C+1</code>-D 的 fc 层后使用 softmax）。另外，Faster R-CNN 分支的输出特征也是 1024-D（由 Fast R-CNN head 输出得到），记为 $f_{FRCNN}(b)$，那么 feature 模拟损失定义如下，</p><script type="math/tex; mode=display">L_{mimic}=\sum_{b \in \Omega}[1-\cos (f_{RCNN}(b), f_{FRCNN}(b))]</script><p>其中，$\Omega$ 表示图中的 RoI 集，$\cos(\cdot, \cdot)$ 表示向量的余弦相似度。</p><h1 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h1><p>在 Faster R-CNN 基础上，增加一个预测目标 mask 的分支，实现 instance segmentation。</p><p>mask 分支为每个 ROI 生成 binary mask。Mask R-CNN 与其他系统不同，其他系统将 classification 和 segmentation 耦合起来（生成 K+1 dimension 的 mask）。</p><p><strong>损失</strong></p><script type="math/tex; mode=display">L=L_{cls}+L_{box}+L_{mask}</script><p>其中，前两项与 Faster R-CNN 中一致。mask 分支的输出为 $Km^2$ 维度，K 表示 foreground 分类数量 ，<code>mxm</code> 表示 resolution，每个 pixel 上应用 sigmoid，于是 $L_{mask}$ 为 binary cross-entropy 损失平均，$L_{mask}$ 中仅对 resolution 每个 position 实际所属分类 <code>k</code> 的那一项，相当于 $L_{mask}$ 实际是 $m^2$ 个 binary cross-entropy loss 的平均。</p><p>每个 ROI 经 mask 分支得到 <code>mxm</code> 的 mask，mask 分支是 FCN（全卷积网络），其中每个 layer 均可保留目标的空间信息，比起使用 fc（全连接层），FCN 使用更少的参数，预测也更准确。</p><h2 id="RoIAlign"><a href="#RoIAlign" class="headerlink" title="RoIAlign"></a>RoIAlign</h2><p>Faster R-CNN 中利用 RoIPool 从 RoI feature（例如在 conv4 上根据 RoI 抠出）抽取得到一个更小的固定的 feature map（例如 <code>7x7</code>），而在 conv4 的输出 feature 上抠出 RoI，这就带来了不对齐问题，因为 conv4 的 feature 上 stride=16，那么 RoI 在 conv4 的 feature 上的坐标为 $[x/16]$，其中 $[\cdot]$ 表示四舍五入，浮点数被离散化处理，同样地，RoI feature 映射到 <code>7x7</code> 上（相当于在 RoI feature 上划分得到 <code>7x7</code> bins）时，也进行了这种离散化处理，这就使得原 input image 上的 RoI 与最终抽取的feature 之间不对齐，这个问题对分类没有影响，但是对 pixel 级别的 mask 预测则有很大的影响。</p><p>解决办法就是去掉离散化处理，使用 $x/16$ 浮点数代替 $[x /16]$ 整数，在 conv4 feature 上得到准确的浮点数 RoI 的坐标，如图 1，<br><img src="/images/obj_det/two_stage_fig1.png" alt=""><center>fig1. RoIAlign 示意图</center></p><p>图1 中示例为 <code>2x2</code> bins，虽然与我们的 <code>7x7</code> bins 不同，但是这不影响，原理都差不多，那么，如何得到每个 bin 中 的 feature patch 呢？（得到每个 bin 的 feature patch，才能做 pooling）</p><p>对每个 bin，取 4 个采样点，每个采样点坐标不一定是整数，所以使用双线性插值计算每个点处的特征值，然后使用 max 或 average 进行 pooling，如图 1。</p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p><strong>backbone:</strong></p><p>backbone 采样两种：1. <code>ResNet-50-C4</code>，其中 <code>C4</code> 表示 ResNet stage 4 的输出 feature；2. <code>ResNet-FPN</code>。ResNet 可以替换为 ResNeXt。</p><p><strong>detection head:</strong></p><p>将 C4 中 RoI 对应的 feature 区域经过 RoIAlign 得到 <code>7x7x1024</code> 的输出，然后经 <code>res5</code>（ResNet 中的 stage 5，共 9 个 layer），输出 feature  tensor 的大小不变，然后分两路，其中一路用于分类预测和 box 坐标回归预测，另一路用于生成 mask。</p><h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p>resize image，使得短边固定在 800，训练时，每个 mini-batch 有 2 个 images，每个 image 有 N 个 RoIs，正负例比为 <code>1:3</code>。</p><h1 id="R-FCN"><a href="#R-FCN" class="headerlink" title="R-FCN"></a>R-FCN</h1><p>region-based fully convolutional networks</p><p>目标检测的 backbone 通常都是来自分类网络，而分类问题中 translation invariance 与目标检测中 translation variance 是不一致的，目标检测中，移动 proposal box 将会影响与 gt box 的 IOU。</p><p>R-FCN 中使用共享的全卷积网络，为了使 FCN 具有 translation variance，设计了一组 position-sensitive score maps，每个 score map encode 位置信息，如下图，<br><img src="/images/obj_det/two_stage_fig3.png" alt=""></p><p>RPN 网络用于生成 proposal box（RoI），RoI 被划分为 <code>kxk</code> grid，每个 cell 对于一个 score map（包含 C+1 个 channel，每个 channel 对应一个分类），执行 RoIPooling 时，不同的 cell 区域使用不同的 score maps。</p><p>Backbone 使用 ResNet-101，由于最后一个 conv 为 2048-d，为了降低 dimension，增加一个 <code>1x1</code> 1024-d 的 conv，然后再用 $k^2(C+1)$-d 的 conv 生成 positive-sensitive score maps。</p><h2 id="position-sensitive-roi-pooling"><a href="#position-sensitive-roi-pooling" class="headerlink" title="position-sensitive roi pooling"></a>position-sensitive roi pooling</h2><p>得到 positive-sensitive score maps 后，根据 RPN 生成的每个 RoI，划分出 <code>kxk</code> bin，每个 bin 对应一个 score map，在其上使用 pooling，记 RoI size 为 <code>wxh</code>，每个 bin 的 size 为 $\frac w k \times \frac h k$，对于第 <code>(i,j)</code> 个 bin， RoI pooling 在第 <code>(i,j)</code> 个 score map 上执行 average pooling，得到 <code>kxkx(C+1)</code> 的输出，然后进行 <strong>vote</strong> （averaging），得到 <code>C+1</code> 的 vector（对单个 RoI 而言），然后使用 softmax 计算分类得分。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Metrics</title>
      <link href="/2021/02/20/dl/Metrics/"/>
      <url>/2021/02/20/dl/Metrics/</url>
      
        <content type="html"><![CDATA[<p>总结机器学习/深度学习中常用的一些指标<br><span id="more"></span></p><ul><li><p>Precision</p><script type="math/tex; mode=display">\frac {\text{true positives}}{\text{true positives + false positives}}</script></li><li><p>Recall</p><script type="math/tex; mode=display">TPR=\frac {\text{true positives}}{\text{true positives + false negatives}}</script><p>我们既想要高准确率，又想要高召回率，也就是 <b>假阳和假阴</b> 都要少，这需要一个很好的模型。判断 positive 或 negative 需要一个阈值，调节这个阈值时，往往会提高一个指标，同时降低另一个指标。</p></li><li><p>F1 score</p><script type="math/tex; mode=display">\frac {2 \times \text {precision} \times \text{recall}} {\text{precision + recall}}</script><p>F1 score 随着 precision 或 recall 的增大而增大，当固定 precision 和 recall 其中一个时，F1 score 是另一个的增函数，已知 precision, recall  $\in [0,1]$，易知 F1 score $\in [0,1]$，F1 score 值越大越好。</p></li></ul><ul><li><p>ROC curve<br>\<br>受试者工作特征曲线（receiver operating characteristic curve），描绘了不同分类阈值下，真阳率（TPR）与假阳率（FPR）的关系。横坐标为 FPR， 纵坐标为 TPR。假阳率为</p><script type="math/tex; mode=display">FPR=\frac {\text{false positives}}{\text{false positives + true negatives}}</script><p>每个样本都有一个预测（为 positive 的）得分 score，当 score 大于阈值时判为 positive，否则为 negative。\<br>ROC 曲线图上的四个重要的点位：</p><ol><li><code>(0,1)</code>，左上角，FPR=0，TPR=1，<b>假阳和假阴均为0</b>，表示是一个完美的分类器</li><li><code>(1,0)</code>，右下角，FPR=1, TPR=0，<b>真阳和真阴均为0</b>，避开所有正确答案，是最差的分类器</li><li><code>(0,0)</code>，左下角，FPR=TRP=0，<b>真阳和假阳均为0</b>，该分类器将所有样本全部判断为 negative</li><li><code>(1,1)</code>，右上角，FPR=TRP=1，<b>真阴和假阴均为0</b>，该分类器将所有样本全部判断为 positive</li></ol><p>当阈值分别为 1 和 0 时，分别对应上面 <code>3.</code> 和 <code>4.</code> 两小点，故 ROC 曲线一定经过 <code>(0,0)</code> 和 <code>(1,1)</code> 这两点。显然，越靠近左上角的分类器性能越好。一个好的模型，它的 ROC 曲线从 0 上升到 1。<br>\</p><p>如何从 ROC 曲线上找到这个最优点（对应的阈值）呢？借助 ISO 精度线，表示为 $y=ax+b$，其斜率为数据集中负样本数目和正样本数目之比，</p><script type="math/tex; mode=display">a=\frac N P</script><p>ISO 精度线寻找最优点步骤：</p><ol><li>初始化截距 <code>b=0</code>，逐渐增大 b 的值，直到直线与 ROC 只有一个交点，这个交点就是最优点。</li></ol></li></ul><ul><li>AUC<br>\<br>ROC 曲线下方区域面积（Area under the ROC curve），计算这个面积得到一个标量值指标，便于量化表示模型好坏。 AUC=1 表示分类器最好，AUC=0.5 表示最差（随机猜测），AUC &lt; 0.5 表示分类器连随机猜都不如，这种分类器的预测，我们在反过来预测，就能优于随机猜测。<br>\<br>AUC 计算方法：<ol><li>选择一组阈值，计算一组 (FPR, TPR)</li><li>按 FPR 从小到大排序，计算第 <code>i</code> 和 第 <code>i+1</code> 个 FPR 之间的差，记为 <code>dx</code></li><li>获取 第 <code>i</code> 或第 <code>i+1</code> 个 TPR 的值，记为 <code>y</code></li><li>计算柱形面积 <code>ds=y * dx</code></li><li>所有柱形面积相加求和，得到 AUC 值</li></ol></li></ul><h3 id="指标名称："><a href="#指标名称：" class="headerlink" title="指标名称："></a>指标名称：</h3><ol><li>召回率 Recall / 命中率 hit rate / 灵敏度 Sensitivity /TPR</li><li>FPR / fall-out</li><li>特异度 Specificity / TNR  = 1-FPR</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Training Operations</title>
      <link href="/2021/02/19/dl/Training-Operations/"/>
      <url>/2021/02/19/dl/Training-Operations/</url>
      
        <content type="html"><![CDATA[<p>深度学习中的训练有很多技巧，这里总结一些常用的操作技巧。</p><h1 id="Weight-Decay"><a href="#Weight-Decay" class="headerlink" title="Weight Decay"></a>Weight Decay</h1><p>权重衰减</p><h1 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h1>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convolution</title>
      <link href="/2021/02/19/dl/conv/"/>
      <url>/2021/02/19/dl/conv/</url>
      
        <content type="html"><![CDATA[<h1 id="膨胀卷积"><a href="#膨胀卷积" class="headerlink" title="膨胀卷积"></a>膨胀卷积</h1><p>膨胀卷积在卷积核中引入 空洞（holes），将卷积核变大，记膨胀率为 $\alpha$，卷积核大小为 $k$，那么膨胀后卷积核大小变为 $\alpha(k-1)+1$，使用膨胀后的卷积核来做卷积计算。</p><p>膨胀卷积在图像（实例）分割中应用较多，为了扩大感知区域，同时减少计算量，膨胀卷积效果较好。</p><p>Dilated Convolution 的设计是为了获取 long-range information，故对大物体比较适用，对小物体则不太适用。Dilated Convolution 一个明显的缺点是 kernel 不连续，产生栅格效应，所以又提出了 Hybrid Dilated Convolution（HDC）混合膨胀卷积。</p><p>HDC 的一般设计原则：</p><ol><li>各膨胀卷积的膨胀率不能有大于 1 的公约数（例如 [2,4,6] 公约数为 2），否则会有栅格效应</li><li>膨胀率设计为锯齿状结构，例如 [1,2,5,1,2,5] 这样的循环结构</li><li>膨胀率满足如下关系<script type="math/tex; mode=display">M_i=\max[M_{i+1}-2r_i, 2r_i-M_{i+1}, r_i]</script>其中 $r_i$ 为第 <code>i</code> 层的膨胀率，$M_i$ 为第 <code>i</code> 层的最大 dilated rate，网络总共 <code>L</code> 层，$M_L=r_L$。</li></ol><h1 id="分组卷积"><a href="#分组卷积" class="headerlink" title="分组卷积"></a>分组卷积</h1><p>假设输入 feature shape 为 $(c_0,h,w)$，original filter 为 $(k,k,c_0,c_1)$，输出 feature shape 为 $(c_1,h,w)$。对于分组卷积，假设分 n 组，那么每一组输入 feature shape 为 $(c_0/n, h, w)$，每一组使用独立的卷积核， filter shape 为 $(k,k,c_0/n, c_1/n)$，于是每一组的输出 feature shape 为 $(c_1/n, h, w)$，最后所有组的输出沿着 channel 进行 concatenate，得到最终输出 feature shape $(c_1, h, w)$，这个过程中，卷积核参数数量为</p><script type="math/tex; mode=display">k \times k \times \frac {c_0} n \times \frac {c_1} n \times n</script><p>参数数量减小。</p><h1 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h1><p>假设输入 shape 为 $(c_0, h, w)$，输出 shape 为 $(c_1, h, w)$，那么 filter 为 $k \times k \times c_0 \times c_1$，参数数量较大，改用 bottleneck 可以缩减参数数量，即：先使用 $1\times 1 \times c_0 \times c_2$ 的 filter，然后使用 $k \times k \times c_2 \times c_2$ 的 filter，最后使用 $1 \times 1 \times c_2 \times c_1$ 的 filter，其中 $c_2 &lt; c_1, c_0$。</p><h1 id="Depthwise-Conv"><a href="#Depthwise-Conv" class="headerlink" title="Depthwise Conv"></a>Depthwise Conv</h1><p>假设输入 shape 为 $(c_0, h, w)$，每个 channel 独立进行（二维卷积），卷积 filter 为 $k \times k \times c_0$（注意这里 filter shape 中没有 $c_1$），得到 $(c_0, h, w)$ 的中间输出，然后再使用 $1 \times 1 \times c_0 \times c_1$，得到 $(c_1, h, w)$ 的最终输出。</p><h1 id="可变形卷积"><a href="#可变形卷积" class="headerlink" title="可变形卷积"></a>可变形卷积</h1><p>略（参考 <a href="/obj_det/two_stage">deformable conv</a>）</p>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Receptive Field</title>
      <link href="/2021/02/18/dl/receptive_field/"/>
      <url>/2021/02/18/dl/receptive_field/</url>
      
        <content type="html"><![CDATA[<h1 id="Size"><a href="#Size" class="headerlink" title="Size"></a>Size</h1><p>对于一个 fully CNN 的网络，第 <code>k</code> layer 的 receptive field 大小为，</p><script type="math/tex; mode=display">l_k=l_{k-1} + ((f_k-1)*\prod_{i=1}^{k-1} s_i)</script><p>其中，$l_{k-1}$ 表示第 <code>k-1</code> layer 上的 receptive field 大小，$f_k$ 是第 <code>k</code> layer 的 filter 大小，$s_i$ 是第 <code>i</code> layer 上的 stride 大小。这是自底向上计算，从 $l_1$ 开始，$l_1=f_1$。</p><p>还有一种自顶向下的计算方法。假设总共有 <code>L</code> 个 layer，每个 layer 的输出 feature map 记为 $f_l, \ l=1,…,L$，每个 layer 的 filter 大小为 $k_l$，stride 大小记为 $s_l$，记 $r_l$ 为最后一个 layer 关于 feature map $f_l$ 的 receptive field 大小，也就是说，$r_l$ 表示 $f_l$ 上多少个像素点对 $f_L$ 的一个像素点有贡献（这里仅考虑一维 feature map，如果是多维，那么分别独立考虑即可）。那么易知，$r_L=1$，</p><p>$r_{L-1}=k_L$，这个也很好理解，上一层 feature map 中，$k_L$ 个像素点对应本层（最后一层）一个像素点。考虑一般情况，已知 $r_l$，求 $r_{l-1}$。</p><p>首先假设 $k_l=1$，这样情况就简单些，若 $s_l=1$，那么 $r_{l-1}=r_l$，若 $s_l&gt;1$，那么 $r_{l-1}=s_l \cdot r_l -(s_l-1)$，因为 $r_l$ 中每两个像素点之间对应到 $f_{l-1}$ 上有 $s_l-1$ 个点，所以 $r_{l-1}=(s_l-1)\cdot(r_l-1)+ r_l=s_l \cdot r_l-s_l+1$。</p><p>然后当 $k_l&gt;1$，那么需要在 $f_{l-1}$ 上增加 $k_l-1$ 个像素点，于是</p><script type="math/tex; mode=display">r_{l-1}=s_l \cdot r_l + (k_l-s_l)</script><p>其中，$r_L=1, \ r_{L-1}=k_L$。求解上式过程如下：</p><script type="math/tex; mode=display">r_{L-2}=s_{L-1} r_{L-1}+(k_{L-1}-s_{L-1})=s_{L-1}(k_L-1)+k_{L-1}</script><script type="math/tex; mode=display">r_{L-3}=s_{L-2} r_{L-2}+(k_{L-2}-s_{L-2})=s_{L-2}s_{L-1}(k_L-1)+s_{L-2}(k_{L-1}-1)+k_{L-2}</script><script type="math/tex; mode=display">\cdots</script><script type="math/tex; mode=display">r_{l}=s_{l+1}\cdots s_{L-1}(k_L-1)+s_{l+1}\cdots s_{L-2}(k_{L-1}-1)+ \cdots s_{l+1}(k_{l+2}-1)+k_{l+1}=1+\sum_{j=l+1}^{L} \left[(k_{j}-1) \prod_{i=l+1}^{j-1}s_i \right]</script><p>其中令 <script type="math/tex">\prod_{l+1}^{l}s_i=1</script></p><p>于是，</p><script type="math/tex; mode=display">\begin{aligned} r_{l-1}&=1+\sum_{j=l}^{L} \left[(k_{j}-1) \prod_{i=l}^{j-1}s_i \right] \\ &=1+(k_l-1)+\sum_{j=l+1}^{L} \left[(k_{j}-1) \prod_{i=l+1}^{j-1}s_i \cdot s_l \right] \\&=k_l-s_l+s_l \left(1+\sum_{j=l+1}^{L} \left[(k_{j}-1) \prod_{i=l+1}^{j-1}s_i \right] \right) \\&=s_l \cdot r_l +k_l-s_l\end{aligned}</script><p>与前面递推式一致，说明通项式计算正确。</p><p>output feature size 的计算为，</p><script type="math/tex; mode=display">w_l=\frac {w_{l-1}+2p_l-k_l} {s_l}+1</script><p>其中 $w$ 表示宽，高 $h$ 的计算类似（以 2D image 数据为例）。</p><h1 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h1><p>对输出 feature map 上一点有贡献的 region （Receptive Field）大小计算如上，还有一个参数也很重要：定位这个 region 的位置。例如输出 feature map 上一点 $f_L(i,j)$，产生这个特征的输入图像上的 region 位置如何求得。</p><p>记在特征平面 $f_l$ 上这个 region 的左端和右端的坐标分别为 $u_l, \ v_l$，这里的<b>坐标从 0 开始</b>，即，第一个像素点的坐标为 <code>0</code>，在输出特征平面 $f_L$ 上有 $u_L=v_L=i$，同样地，仅考虑一维情况，对于二维情况，另一维度独立地进行类似计算可得。</p><p>同样使用递推的思想，已知 $u_l, \ v_l$，求 $u_{l-1}, v_{l-1}$。</p><p>首先从一个简单的情况开始，假设 $u_l=0$，这表示 $f_l$ 中的 region 左侧位于第一个像素点，此时 $u_{l-1}=-p_l$，即$f_{l-1}$ 左侧填充 $p_l$ 个像素；如果 $u_l=1$，那么 $u_{l-1}=s_l-p_l$，这也很好理解，从 $f_{l-1}$ 最左侧第一个像素点（填充之后为 $-p_l$）向右移动 $s_l$；如果 $u_l=2$，那么继续向右移动 $s_l$，即 $u_{l-1}=2s_l-p_l$，于是一般地，</p><script type="math/tex; mode=display">u_{l-1}=u_l \cdot s_l -p_l</script><script type="math/tex; mode=display">v_{l-1}=v_l \cdot s_l - p_l + k_l-1</script><p>完全式的计算过程如下：</p><script type="math/tex; mode=display">u_{L-1}=u_L \cdot s_L - p_L</script><script type="math/tex; mode=display">u_{L-2}=u_{L-1} \cdot s_{L-1}-p_{L-1}=s_{L-1}s_L u_L-s_{L-1}p_L-p_{L-1}</script><script type="math/tex; mode=display">u_{L-3}=u_{L-2} \cdot s_{L-2}-p_{L-2}=s_{L-2}s_{L-1}s_L u_L-s_{L-2}s_{L-1}p_L-s_{L-2}p_{L-1}-p_{L-2}</script><script type="math/tex; mode=display">\cdots</script><script type="math/tex; mode=display">u_l=s_{l+1}\cdots s_L u_L-s_{l+1}\cdots s_{L-1} p_{L}-\cdots-s_{l+1} p_{l+2}-p_{l+1}=u_L\prod_{i=l+1}^L s_i-\sum_{j=l+1}^L p_j \prod_{i=l+1}^{j-1} s_i</script><p>其中，$\prod_{i=l+1}^l s_i=1$, 类似地，</p><script type="math/tex; mode=display">v_l=v_L \prod_{i=l+1}^L s_i - \sum_{j=l+1}^L(1+p_j-k_j)\prod_{i=l+1}^{j-1} s_i</script><h1 id="Relation"><a href="#Relation" class="headerlink" title="Relation"></a>Relation</h1><p>Receptive Field size 与 region 之间的联系，</p><script type="math/tex; mode=display">r_l=v_l-u_l+1</script><h1 id="Stride-amp-Padding"><a href="#Stride-amp-Padding" class="headerlink" title="Stride &amp; Padding"></a>Stride &amp; Padding</h1><p>定义两个变量，有效 stride 和 有效 padding，这两者分别定义如下：</p><script type="math/tex; mode=display">S_l=\prod_{i=l+1}^L s_i</script><script type="math/tex; mode=display">P_l=\sum_{j=l+1}^L p_j \prod_{i=l+1}^{j-1}s_i</script><p>他们的递推公式为，</p><script type="math/tex; mode=display">S_{l-1}=s_l \cdot S_l</script><script type="math/tex; mode=display">P_{l-1}=p_l+s_l \cdot P_l</script><p>有着这两个定义变量，region 位置公式可表示为，</p><script type="math/tex; mode=display">u_l=u_L \cdot S_l - P_l</script><h1 id="Center"><a href="#Center" class="headerlink" title="Center"></a>Center</h1><p>receptive field 的中心可由 region 位置计算得到，在第 <code>l</code> layer 上为，</p><script type="math/tex; mode=display">c_l=\frac {u_l+v_l} 2</script>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TODO</title>
      <link href="/2021/02/02/TODO/"/>
      <url>/2021/02/02/TODO/</url>
      
        <content type="html"><![CDATA[<p>牛顿法/拟牛顿法</p><p><a href="https://blog.csdn.net/songbinxu/article/details/79677948">https://blog.csdn.net/songbinxu/article/details/79677948</a></p><p><a href="https://blog.csdn.net/itplus/article/details/21896453">https://blog.csdn.net/itplus/article/details/21896453</a></p><p><a href="https://blog.csdn.net/itplus/article/details/21896619">https://blog.csdn.net/itplus/article/details/21896619</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu zsh 使用</title>
      <link href="/2021/01/23/tools/shell/"/>
      <url>/2021/01/23/tools/shell/</url>
      
        <content type="html"><![CDATA[<p>安装 zsh<br><pre class="line-numbers language-none"><code class="language-none">sudo apt-get install zsh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>查看版本，验证是否安装成功<br><pre class="line-numbers language-none"><code class="language-none">zsh --version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>更改默认 shell 为 zsh<br><pre class="line-numbers language-none"><code class="language-none">chsh -s &#x2F;bin&#x2F;zsh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>查看 shell<br><pre class="line-numbers language-none"><code class="language-none">echo $SHELL<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>如果失败，那么重启 shell 即可。</p><p>安装 oh-my-zsh，这是一个 zsh 配置框架。<br><pre class="line-numbers language-none"><code class="language-none">wget https:&#x2F;&#x2F;raw.github.com&#x2F;robbyrussell&#x2F;oh-my-zsh&#x2F;master&#x2F;tools&#x2F;install.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>修改文件权限，<br><pre class="line-numbers language-none"><code class="language-none">chmod +x install.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br> 执行安装，<br> <pre class="line-numbers language-none"><code class="language-none">.&#x2F;install.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>安装 powerlevel10k 这个主题，<br><pre class="line-numbers language-none"><code class="language-none">git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;romkatv&#x2F;powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME&#x2F;.oh-my-zsh&#x2F;custom&#125;&#x2F;themes&#x2F;powerlevel10k<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>设置主题，将以下内容添加到 <code>~/.zshrc</code>，<br><pre class="line-numbers language-none"><code class="language-none">ZSH_THEME&#x3D;&quot;powerlevel10k&#x2F;powerlevel10k&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h1 id="redirect-printing-message-to-file"><a href="#redirect-printing-message-to-file" class="headerlink" title="redirect printing message to file"></a>redirect printing message to file</h1><h2 id="stop-output-to-console-but-file"><a href="#stop-output-to-console-but-file" class="headerlink" title="stop output to console but file"></a>stop output to console but file</h2><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">ls -al &gt;&gt; output.txtls -al &gt;&gt; output.txt 2&gt;&amp;1 # redirect the stderr to stdout<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="output-to-console-and-file"><a href="#output-to-console-and-file" class="headerlink" title="output to console and file"></a>output to console and file</h2><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">ls -al 2&gt;&amp;1 | tee output.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>img_cls/resnet.md</title>
      <link href="/2021/01/19/img_cls/resnet/"/>
      <url>/2021/01/19/img_cls/resnet/</url>
      
        <content type="html"><![CDATA[<p>本篇罗列一些 Resnet 网络的细节。<br><span id="more"></span></p><h1 id="ImageNet"><a href="#ImageNet" class="headerlink" title="ImageNet"></a>ImageNet</h1><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><ol><li>scale 增强：输入图像的短边（w,h 较小者）被 resize 到 <code>[256,418]</code> 中的一个随机数。</li><li>在 resized 的图像或其水平翻转图像上随机位置（随机 center） crop 出一个 <code>224x224</code> 大小的部分。</li><li>10-crop testing：测试阶段，对每个测试图像，crop 出上下左右四个角以及center处共 5 个 patch，以及水平翻转后同样的 5 个 patch，这 10 个 patch 经过网络之后的预测结果（softmax 层的输出）再进行平均，即得到这个图像的最终预测，预测为长度等于类别数量的向量。</li></ol><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><ol><li>baseline 使用 VGG，记为 plain，每个 conv 层与 activation 层之间均插入一个 BatchNorm 层。</li><li>网络结构如下图，其中 conv3_1,  conv4_1, conv5_1 进行了下采样（stride=2）<br><img src="/images/img_cls/resnet_1.png" alt=""><center>图 1. 网络结构</center></li><li>每个 conv block 均额外增加一个 shortcut，两个 output 在通道维度上进行 concatenate。由于 conv3_1,  conv4_1, conv5_1 进行了下采样，output 的 (H,W) 分别减小到一半，而通道 (C) 增大一倍，故需要将对应的 shortcut 作调整，有两种方法：a. identity mapping（注意 stride=2，以降低 H 和 W），额外维度上 0 填充；b. <code>1x1</code> conv，stride=2 的下采样，且输出 channel 增大一倍。</li><li>在 ResNet-18 和 ResNet-34 上，使用 identity mapping（以及 zero-padding 维度填充）。</li><li>conv3_1,  conv4_1, conv5_1 进行了下采样，具体而言，对 ResNet-18 和 ResNet-34，conv block 是由两个 <code>3x3</code> conv layer 组成，所以是 conv3_1,  conv4_1, conv5_1 这三个 conv block 中的第一个 conv layer 执行了下采样；对于 ResNet-50，ResNet-101 以及 ResNet-152，conv block 是由三个 conv layer 组成的（也叫 bottleneck），这三个conv 按顺序分别是 <code>1x1</code>, <code>3x3</code>, <code>1x1</code>， 所以其实是 conv3_1,  conv4_1, conv5_1 这三个 conv block 中的 <code>3x3</code> 执行了下采样操作。</li><li>整个网络的下采样率为 <code>2x2x2x2x2=32</code>，输入为 <code>224x224</code>，那么最后的 conv 输出 feature 大小为 <code>7x7</code>。对每个 feature map 进行全局均值池化 GAP，那么每个 channel 得到一个值，然后经 full connection 层，得到 1000 个分类得分，最后由 softmax 将其归一化。</li><li>ResNet-x，后缀 <code>x</code> 表示有参数的 layer 数量。</li><li>shortcut 与 residual function 按 channel 维度连接之后再经过 relu 层。</li><li>如果 shortcut 需要下采样，那么令 stride=2 即可。<h2 id="实验说明"><a href="#实验说明" class="headerlink" title="实验说明"></a>实验说明</h2><h3 id="plain-vs-resnet"><a href="#plain-vs-resnet" class="headerlink" title="plain vs. resnet"></a>plain vs. resnet</h3>在 18 layers 和 34 layers 两个网络上，对比 plain 和 ResNet，top-1 错误率如下表</li></ol><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">plain</th><th style="text-align:center">ResNet</th></tr></thead><tbody><tr><td style="text-align:center">18 layers</td><td style="text-align:center">27.94</td><td style="text-align:center">27.88</td></tr><tr><td style="text-align:center">34 layers</td><td style="text-align:center">28.54</td><td style="text-align:center"><b> 25.03 </b></td></tr></tbody></table></div> <center>表 1. plain 与 Resnet 结果比较。ResNet 采用 identity shortcut。ImageNet 验证集上的错误率（10-crop testing）</center>说明：- plain，随着网络加深，准确率下降。- ResNet 采用 identity mapping （zero padding 增加channel）作为 shortcut。ResNet-34 比 ResNet-18 好，这表明加深网络导致恶化的问题可通过 ResNet 得到解决，且能获得更高的准确率。- ResNet-18 比 plain-18 收敛更快。### Projection Shortcut使用 `1x1` conv 代替 identity mapping，输出如下，其中第一项为 conv block 的输出，第二项为 shortcut 的输出，$$\mathbf y = \mathcal F(\mathbf x, \{W_i\}) + W_s \mathbf x $$以 34 layers 网络为例，对比如下三种情况：* A：所有 shortcut 均没有参数，即 identity mapping，以及 zero-padding 以增加维度。与上述 ResNet-34 一样。* B：除了需要增加维度的时候（conv3_1, conv4_1, conv5_1）使用 projection shortcut，其他 shortcut 采用 identity mapping。此时无需 zero-padding。* C：所有的 shortcuts 均采用 projection shortcut。此时无需 zero-padding。实验结果如下：|model|top-1 err | top-5 err||:--|:--|:--||plain-34| 28.54| 10.02||ResNet-34 A|25.03|7.76||ResNet-34 B|24.52|7.46||ResNet-34 C|24.19|7.4||ResNet-50|22.85|6.71||ResNet-101|21.75|6.05||ResNet-50|<b>21.43</b>|<b>5.71</b>|<center>表 2. projection shortcut 方案比较，以及 ResNet 不同深度的比较。<font color='clan'>ResNet-50/101/152 使用方案 B</font>。ImageNet 验证集上的错误率（10-crop testing）</center><p>结果分析：</p><ul><li>错误率：三种情况均比 plain 有所降低。B 比 A 有所降低，C 比 B 轻微降低。由于 A 中没有 projection shortcut，这表明对于解决准确率恶化的问题，projection shortcut 不是本质性地重要；另一方面，C 中由于引入过多的参数，内存占用和计算时间均增大，故综合起来，使用 B 方案。</li></ul><h3 id="Bottleneck-结构"><a href="#Bottleneck-结构" class="headerlink" title="Bottleneck 结构"></a>Bottleneck 结构</h3><p>图 1 中，每个 conv block 是由两层 conv 组成，把它改成 bottleneck 结构，即三层 conv：<code>1x1</code>, <code>3x3</code>, <code>1x1</code>，第一个 <code>1x1</code> 用于降低 channel（维度）（降为 1/4），(H,W) 不变，<code>3x3</code> 执行了下采样，(H,W) 均降为一半，channel 不变，最后一个 <code>1x1</code> 用于增加 channel，增大到 4 倍，这三个 conv layer 形成一个 bottleneck 结构，如下图右侧，<br><img src="/images/img_cls/resnet_2.png" alt=""><center>图 2. ImageNet 上使用的深度残差函数。左：与图 1 中相同的conv 块结构；右：bottleneck 结构，用在 ResNet-50/101/152 中</center></p><p>使用 Bottleneck 时，identity shortcut 显得尤其重要，如果使用 projection，model 大小和时间复杂度都会大大增加，因为此时 shortcut 连接的两端都是高维（即，输入输出的 channel 都增大到原来 4 倍），这使得 shortcut 上的参数量大大增加。</p><h3 id="ResNet-50-101-152"><a href="#ResNet-50-101-152" class="headerlink" title="ResNet-50/101/152"></a>ResNet-50/101/152</h3><p>将 ResNet-34 中的所有 conv block 替换为 bottleneck 结构，就得到 ResNet-50，如图 1，ResNet-34 有 <code>3+4+6+3=16</code> 个 conv block，增加的 layer 数量也就是 16。ResNet-50 使用方案 B。</p><p>在 ResNet-50 基础上增加更多的 bottleneck 块，得到 ResNet-101 和 ResNet152。</p><p>ResNet-50/101/152 比 ResNet-34 改善较多。实验结果如表 2，可见，使用 ResNet 结构可享受深度带来的益处。</p><p>除了单模型，作者还对比了各种模型的集成结果，这个集成结果我也不知道是怎么计算的，也许只是几种不同深度的 ResNet 网络的结果平均，这个<font color="red">有待考证</font>。</p><p>再在其他数据集上研究 ResNet 的表现。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><ol><li>使用 SGD 方法学习</li><li>mini-batch=256</li><li>学习率初始为 <code>0.1</code>，当错误率进入平稳期时，以  <code>1/10</code> 的倍率降低学习率。</li><li>权重衰减因子为 <code>0.0001</code>，momentum=0.9</li><li>由于使用了 BatchNorm，所以不使用 Dropout。</li></ol><h1 id="CIFAR-10"><a href="#CIFAR-10" class="headerlink" title="CIFAR-10"></a>CIFAR-10</h1><p>作者这里的目的是为了研究非常深的网络，而非为了 SOTA 的性能，所以仅使用了简单的框架，以 ResNet-34 和对应的 plain 网络为主体框架进行改造，这是因为输入 size 为 <code>32x32</code>，这比 ImageNet 数据集的输入 size <code>224x224</code> 小很多。</p><h2 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h2><p>第一个 layer 的 kernel 需要调小（ImageNet 数据集上使用的是 <code>7x7</code>，太大），使用的是 <code>3x3</code> 的 conv，stride=1，无下采样（输出 channel 增大到 16），接着，使用 6n（6 的整数倍）个 conv layer，每 2n 个 conv layer 划分为一组，共 3 组，每组的输出 feature size 分别为 <code>(32, 16, 8)</code>，channel （也就是卷积 filter 的数量）分别为 <code>(16, 32, 64)</code>。最后使用全局均值池化 GAP + full connection + softmax。有参数的 layer 一共 <code>6n+2</code> 个。</p><blockquote><p>第二组和第三组各做了一次 stride=2 的下采样。论文里面没有明说，但我认为可以使用第二、三组中各自第一个 conv layer 来做下采样，与图 1 中一致。</p></blockquote><p>网络结构说明如下：</p><div class="table-container"><table><thead><tr><th style="text-align:left">输出 map size</th><th style="text-align:left">32x32</th><th style="text-align:left">16x16</th><th style="text-align:left">8x8</th></tr></thead><tbody><tr><td style="text-align:left">#layers</td><td style="text-align:left">2n+1</td><td style="text-align:left">2n</td><td style="text-align:left">2n</td></tr><tr><td style="text-align:left">#filters</td><td style="text-align:left">16</td><td style="text-align:left">32</td><td style="text-align:left">64</td></tr></tbody></table></div><p>从这个表格可见，如果采用 identity shortcut，如果不进行下采样，那么这个 identity shortcut layer 的输出与输入完全一样，如果进行 rate=2 的下采样，那么 (H,W) 各变为一半大小，而 channel 增加一倍，变为原来 channel 的两倍，residual function 分支的 channel 也是原来输入 channel 的两倍，两个分支的输出 channel 和 (H,W) 均分别保持相同，才能进行 element-wise 的 add 操作。</p><p>6n 个 conv layer，每两个 conv layer 使用一个 shortcut，共 3n 个 shortcut，作者使用 identity shortcut。</p><h2 id="训练说明"><a href="#训练说明" class="headerlink" title="训练说明"></a>训练说明</h2><ul><li>与 ImageNet 上的训练类似，区别是 mini-batch=128，学习率初始为 <code>0.1</code>，在第 32k 次和第 48k 次迭代时，学习率降为 <code>1/10</code>，训练共迭代 64k 次。</li><li>CIFAR-10 训练集大小为 50k，测试集大小为 10k，类别数量为 10。将训练集按 45k/5k 分割为 train/val 集。</li><li>原图像采用 4 pixel 的填充，然后以 0.5 的概率水平翻转，再随机 crop 一个 32x32 的 patch，作为网络输入。</li></ul><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>当 <code>n=&#123;3,5,7,9&#125;</code> 时，分别得到 <code>20, 32, 44, 56</code> 个有参数的 layer 的网络。实验结果如图 3，<br><img src="/images/img_cls/resnet_3.png" alt=""><center>图 3. CIFAR-10 训练结果。细线表示训练错误率，粗线表示测试错误率。左图中 plain-110 的错误率大于 60%，没有在图中显示。</center></p><p>从图 3 中可见，ResNet 可以解决网络深度增加带来的准确率恶化问题。n=18 得到 ResNet-110，此时初始学习率 0.1 过大，导致开始训练时一直难以收敛，故初始化学习率为 0.01，当训练错误率降低到 80% 以下时（大约 400 次迭代），将学习率重置为 0.1 以加快收敛速度继续训练，之后就与训练 ImageNet 一样（阶梯降低学习率）。</p><p>训练结果：</p><p>ResNet-110 表现最好，比其他 deep &amp; thin 的网络有更少的参数和更好的性能，对比如下表，<br>||#layers|#params(M)|error(%)|<br>|:—-|:—-|:—-|:—-|<br>|FitNet|19|2.5|8.39|<br>|Highway|19|2.3|7.54(7.72 ± 0.16)|<br>|Highway|32|1.25|8.8|<br>|ResNet|20|0.27|8.75|<br>|ResNet|32|0.46|7.51|<br>|ResNet|44|0.66|7.17|<br>|ResNet|56|0.85|6.97|<br>|ResNet|110|1.7|<b>6.43</b>(6.61±0.16)|<br>|ResNet|1202|19.4|7.93|</p><center>CIFAR-10 测试集上的分类错误率。其中，与 Highway 中类似，对 ResNet-110 试验了 5 次，得到最佳结果 6.43% 的错误率，均值为 6.61%，标准差为0.16</center><h2 id="Layer-响应分析"><a href="#Layer-响应分析" class="headerlink" title="Layer 响应分析"></a>Layer 响应分析</h2><p>图 4 是 CIFAR-10 上网络（训练好之后）中各个 <code>3x3</code> layer 响应的标准差，响应指 BN 之后，activate 之前的 layer 响应。<br><img src="/images/img_cls/resnet_4.png" alt=""><center>图 4. 网络（3x3）各层的响应标准差。上：网络原始各层先后顺序；下：按标准差倒序排列。</center></p><p>从图 4中可见，ResNet 有着比 plain 更小的响应标准差，所以 ResNet 中各层的输出更加集中在 0 附近，避免了梯度消失（现在都使用 relu 而非 sigmoid 激活，避免梯度消失这一说还有意义吗？）。同时注意到，更深的 ResNet 的响应幅度更小，这表明当 layer 数量越多时，均摊到单个 layer 上，其对信号的改变越小。</p><h2 id="超深网络-layers-gt-1000"><a href="#超深网络-layers-gt-1000" class="headerlink" title="超深网络 layers&gt;1000"></a>超深网络 layers&gt;1000</h2><p>n=200，此时网络层数 6n+2=1202。训练结果（错误率）如上表 和图 3 中所示，训练集错误率 <code>&lt;0.1%</code>，测试集错误率 <code>7.93%</code>，差强人意，但是比起 ResNet-110，虽然训练错误率差不多，但是测试错误率已经上升，作者认为这是过拟合导致，此时网络太大，而数据集太小，可以使用 <code>maxout</code>，<code>dropout</code> 等手段来改善过拟合问题，但是作者自己并没有这么做，而只是在设计网络架构时，遵循 deep &amp; thin 的原则，简单地将网络正则化，这是因为本论文的重点在于解决（deep 网络的）优化困难，而非网络正则</p><blockquote><p>deep: 网络层数多；thin: 每层的操作少，例如常见的一层为 conv-bn-relu；wide: 每层的 feature size 较大。</p></blockquote><h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><p>检测采用 Faster R-CNN，将 baseline 从 VGG-16 替换为 ResNet-101。</p><h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><ol><li>在 ImageNet 上训练，然后再在目标检测数据上对网络进行 fine-tune。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> img cls </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Loss 2</title>
      <link href="/2021/01/13/pytorch/loss_2/"/>
      <url>/2021/01/13/pytorch/loss_2/</url>
      
        <content type="html"><![CDATA[<p>继上一篇 <a href="2021/1/12/pytorch/loss_1">loss 1</a>，本篇介绍 PyTorch 的其他损失。<br><span id="more"></span></p><h1 id="MarginRankingLoss"><a href="#MarginRankingLoss" class="headerlink" title="MarginRankingLoss"></a>MarginRankingLoss</h1><p>给定两个输入 $x_1, \ x_2$，以及一个 label 值 $y \in \{1,-1\}$。当 $y=1$，认为 $x_1$ 应该比 $x_2$ 大；当 $y=-1$，认为 $x_1$ 应该比 $x_2$ 小，所以损失为</p><script type="math/tex; mode=display">l=\max(0, -y(x_1-x_2) + \text{margin})</script><p>上式中增加了一个 <code>margin</code> 项，根据</p><script type="math/tex; mode=display">-y(x_1-x_2)+\text{margin} \le 0</script><p>当 $y=1$ 时，需要满足 $x_1\ge x_2+\text{margin}$ 损失才降为 0。</p><p>当 $y=-1$ 时，需要满足 $x_1+\text{margin} \le x_2$ 损失才降为 0。</p><p>适用于（二）<b>分类</b>问题。</p><h1 id="MultiLabelMarginLoss"><a href="#MultiLabelMarginLoss" class="headerlink" title="MultiLabelMarginLoss"></a>MultiLabelMarginLoss</h1><p>适用于多标签多分类问题。每个类别独立进行二分类（为正 or 为负）预测，预测值 x 是一个 2D tensor，shape 为 $(N,C)$，其中 $N$ 表示批大小，$C$ 表示类别数。target 与 x 同 shape。暂且考虑单个样本，此时 x 和 target 均为长度 <code>C</code> 的向量，x 表示各分类的预测概率，target （用 y 表示）表示样本所属分类索引，例如 $y=(3,0,-1,1)$，表示样本属于 <code>0</code> 分类和 <code>3</code> 分类，从第一个负值开始，之后的全部忽略。借鉴 <code>MarginRankingLoss</code> 思想，对于预测值 x，认为其中<b>样本所属分类的元素值比样本不属分类的元素值大</b>，这个例子中，样本所属分类为 $\{0,3\}$，所以认为应该是 $x_0,\ x_3 &gt; x_1,\ x_2$，据此不难理解单个样本的损失为</p><script type="math/tex; mode=display">l=\sum_{i,j} \frac {\max[0, 1-(x_{y_j} - x_i)]} C</script><p>其中，$j \in \mathcal J=\{0,1,…,k-1\}$，且 $y_k&lt;0$，$i \in \{0,1,…,C-1\}-\{y_j|j \in \mathcal J\}$，即， $j$ 为 target 向量中开始的连续非负元素索引，$y_j$ 表示样本所属分类索引，i 为样本不属分类索引。</p><p>当分类正确时，损失为0，此时需要满足条件 $1-(x_{y_j}-x_i)\le 0 \Rightarrow x_{y_j}\ge 1+x_i$，这说明降低损失会使得样本所属分类的预测概率 $x_{y_j} \rightarrow 0$，样本不属分类的预测概率 $x_i \rightarrow 0$。在 test 阶段，对预测值 x 设置一个低阈值即可。</p><h1 id="SoftMarginLoss"><a href="#SoftMarginLoss" class="headerlink" title="SoftMarginLoss"></a>SoftMarginLoss</h1><p>适用于二分类问题。上面两种 MarginLoss 均采用了 <code>max(0,x)</code> 函数，这个函数在 <code>x=0</code> 处不可导。<code>SoftMarginLoss</code> 借助 logistic 函数解决了这个问题。Logistic 函数</p><script type="math/tex; mode=display">\sigma(x)=\frac 1 {1+\exp (-x)}</script><p>预测值 x，分类 $y\in \{1,-1\}$，似然函数为</p><script type="math/tex; mode=display">\mathcal L =\mathbb I(y=1)f(x)+\mathbb I(y=-1)(1-f(x))=[1+\exp(-yx)]^{-1}</script><p> 负对数似然函数（损失）为</p><script type="math/tex; mode=display">l= \log(1+\exp(-yx))</script><p>所以 <code>SoftMarginLoss</code> <b>就是 logistic 回归的负对数似然损失</b>。预测输入 input tensor 的 shape 为 $(<em>)$，其中 $</em>$ 表示任意维度，target 与 input 的 shape 相同。损失按像素计算，输出与 input 同 shape，如果按求和或平均归约，那么输出为一标量。</p><h1 id="MultiLabelSoftMarginLoss"><a href="#MultiLabelSoftMarginLoss" class="headerlink" title="MultiLabelSoftMarginLoss"></a>MultiLabelSoftMarginLoss</h1><p>适用于多标签多分类问题。每个类别各自独立做二分类（为正或负）。input 和 target 有相同的 shape：$(N,C)$，target 值为 0 或 1（这与 SoftMarginLoss 的 1 或 -1 竟然不统一）。于是，单个样本的损失为，</p><script type="math/tex; mode=display">l=-\frac 1 C \sum_{i=1}^C y_i \log \left(\frac 1 {1+\exp(-x_i)}\right )+(1-y_i)\log \left(\frac {\exp(-x_i)} {1+\exp(-x_i)}\right)</script><p>由于这里考虑单个样本，所以上式 $x, \ y$ 均为长度 $C$ 的向量，由于 y 值取值范围不同，所以上式与 <code>SoftMarginLoss</code> 的损失表达式略有不同，但是本质上都是 logistic 负对数似然损失。</p><p>输出 tensor 的 shape 为 $(N,)$，如果按求和或平均归约，那么输出 tensor 为一标量。</p><p>类签名：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">MultiLabelSoftMarginLoss<span class="token punctuation">(</span>weight<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reduction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><code>weight</code> 如果给定，那么是一个 shape 为 $(C,)$  的 tensor，用于给每个 channel/类别 一个权重。</p><h1 id="MultiMarginLoss"><a href="#MultiMarginLoss" class="headerlink" title="MultiMarginLoss"></a>MultiMarginLoss</h1><p>适用于多分类（单标签）问题。input 为一个 2D tensor $(N,C)$，target shape 为 $(N,)$，表示样本的分类索引，故 $y_i \in \{0,1,…,C-1\}$，对于单个样本而言，此时输入为一个长度 C 的向量 x，target 为标量，也记为 y，表示样本分类索引，显然我们要 $x_y &gt; x_i$，其中 $i \neq y$，margin-based 损失为</p><script type="math/tex; mode=display">l=\frac {\sum_{i \neq y} \max(0, d-(x_y-x_i))^p} C</script><p>其中 $d$ 为 margin，也就是说需要 $x_y \ge x_i+d$，样本所属分类的预测概率比其他分类的预测概率大 $d$，损失才为 0。</p><p>p 值可为 1 或 2，用于控制损失变化速度。还可以给每个类型增加一个权重，此时损失为，</p><script type="math/tex; mode=display">l=\frac {\sum_{i \neq y} \max[0, w_y(d-(x_y-x_i))^p]} C</script><p>注意，权重 $w_y$ 不参与幂运算，且只有样本所属分类对于的权重因子起作用。</p><p>类签名：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">MultiMarginLoss<span class="token punctuation">(</span>p<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> margin<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> weight<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reduction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>input shape 为 $(N,C)$，target shape 为 $(N,)$，output 的 shape 为 $(N,)$，可以按求和或平均归约，此时 output 为一标量。</p><h1 id="TripletMarginLoss"><a href="#TripletMarginLoss" class="headerlink" title="TripletMarginLoss"></a>TripletMarginLoss</h1><p>三个tensor：$a, \ p, \ n$，分别表示 anchor，正例和负例，shape 均为 $(N,D)$，其中 $N$ 为批大小，$D$ 为特征数。p 表示与 a 同类的另一个样本的特征，n 表示与 a 不同类的样本特征，显然，需要 p 与 a 的特征尽量相近，n 与 a 的特征尽量远离。<br>传统上是以 pair 的形式来度量损失，即 $(p,a)$ 为正例对，$(n,a)$ 为负例对，一般表示为 $(x_1, x_2， l)$，当 $l=1$ 表示是正例对，$l=-1$ 表示是负例对，此时损失定义为</p><script type="math/tex; mode=display">l=\begin{cases} \Vert \mathbf x_1-\mathbf x_2 \Vert_2 & l=1 \\ \max(0, d-\Vert \mathbf x_1- \mathbf x_2\Vert_2) & l=-1 \end{cases}</script><p>$l=1$ 是正例对，所以 $\mathbf x_1$ 应该要尽量接近 $\mathbf x_2$；$l=-1$ 是负例对，$\mathbf x_1$ 尽量要远离 $\mathbf x_2$，且要相距 $d$ 以上。</p><p>这里 <code>TripletMarginLoss</code> 将 <code>(a,p,n)</code> 三者当成一个整体，margin ranking-based 损失定义如下，</p><script type="math/tex; mode=display">l=\max[d(a,p) - d(a,n)+d_0, 0]</script><script type="math/tex; mode=display">d(\mathbf x_1, \mathbf x_2)=\Vert \mathbf x_1 - \mathbf x_2 \Vert_p</script><p>其中，$d_0$ 为 margin，计算特征空间中的距离时，使用的是 p 范数，这个 p 与前面正例 p 不一样，根据上下文不难区分。</p><p>类签名：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">TripletMarginLoss<span class="token punctuation">(</span>margin<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> p<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> eps<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token operator">=</span><span class="token number">1e-06</span><span class="token punctuation">,</span> swap<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reduction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><code>swap</code> 指示是否交换 anchor 和 positive，这用于 hard negative mining。若 <code>swap=True</code>，那么 $d(a,n) = d(p,n)$，也就是说，使用 <code>(p,n)</code> 的距离作为 negative 与 anchor 的距离。</p><p>forward 方法的参数为 anchor, positive 和 negative 三个特征 tensor，shape 均为 $(N,D)$，输出 tensor 的 shape 为 $(N,)$，如果按求和或平均归约，那么输出为一标量。</p><p>更多细节可以参考 <a href="www.bmva.org/bmvc/2016/papers/paper119/paper119.pdf"><code>Learning local feature descriptors with triplets and shallow convolutional neural networks</code></a></p><h1 id="TripletMarginWithDistanceLoss"><a href="#TripletMarginWithDistanceLoss" class="headerlink" title="TripletMarginWithDistanceLoss"></a>TripletMarginWithDistanceLoss</h1><p><code>TripletMarginLoss</code> 中距离使用的是 p 范数，这里是通过参数提供自定义的距离参数。anchor，positive 和 negative 三个 tensor 的 shape 为 $(N,<em>)$ ，其中 $</em>$ 为任意维度，输出 tensor 的未归约 shape 为 $(N,)$，否则为一标量。</p><h1 id="HingeEmbeddingLoss"><a href="#HingeEmbeddingLoss" class="headerlink" title="HingeEmbeddingLoss"></a>HingeEmbeddingLoss</h1><p>$x$ 表示距离（例如 L1 范数），$y \in \{1,-1\}$ 标识是相似还是相反，损失为，</p><script type="math/tex; mode=display">l = \begin{cases} x & y=1 \\ \max(0, d-x) & y=-1 \end{cases}</script><p>其中 $d$ 为 margin。</p><p>输入 x 和 y 的 shape 均为任意维度 $(<em>)$，输出未归约的 shape 也是 $(</em>)$，否则为一标量。</p><h1 id="CosineEmbeddingLoss"><a href="#CosineEmbeddingLoss" class="headerlink" title="CosineEmbeddingLoss"></a>CosineEmbeddingLoss</h1><p><code>y=1</code> 表示两个（归一化）向量应该相近，<code>y=-1</code> 表示应该相差很远。<br>损失如下，</p><script type="math/tex; mode=display">l=\begin{cases} 1- \cos(x_1,x_2) & y=1 \\ \max[0, \cos(x_1,x_2) - d] & y=-1 \end{cases}</script><p>其中 $d$ 表示 margin，默认为 0。</p><h1 id="CTCLoss"><a href="#CTCLoss" class="headerlink" title="CTCLoss"></a>CTCLoss</h1><p>参考文献 <a href="https://www.cs.toronto.edu/~graves/icml_2006.pdf">Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</a><br>RNN 相关的应用领域暂未涉及。略，以后填坑。</p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Loss 1</title>
      <link href="/2021/01/12/pytorch/loss_1/"/>
      <url>/2021/01/12/pytorch/loss_1/</url>
      
        <content type="html"><![CDATA[<p>前面介绍了 <a href="2021/1/12/dl/x_ent_loss">交叉熵损失</a>，本篇就 PyTorch 中的各种 <a href="https://pytorch.org/docs/stable/nn.html#loss-functions">Loss</a> 进行分解并掌握其用法。<br><span id="more"></span></p><h1 id="L1Loss"><a href="#L1Loss" class="headerlink" title="L1Loss"></a>L1Loss</h1><p>基于L1 范数的损失，单个样本的L1损失为 $l_n=|x_n-y_n|$，其中 <code>n</code> 为批样本中的样本索引，$x_n$ 为预测值，$y_n$ 为 GT，L1 损失适用于<b>回归</b>问题。</p><h1 id="MSELoss"><a href="#MSELoss" class="headerlink" title="MSELoss"></a>MSELoss</h1><p>均方差（L2范数平方）损失，单个样本损失的计算公式为 $l_n=(x_n-y_n)^2$。适用于<b>回归</b>问题。</p><h1 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h1><p>负对数似然损失，适用于<b>分类</b>问题。对于单个样本，似然函数为</p><script type="math/tex; mode=display">\mathcal L=\prod_{i=1}^C x_i^{y_i}</script><p>其中输出向量 $\mathbf x = (x_1,…,x_C)$ 表示每个分类的预测概率，GT 向量为 $\mathbf y=(y_1,…,y_C)$，如果是单标签分类，$\mathbf y$ 为 one-hot，如果是多标签分类，$\mathbf y$ 中可能有多个元素值为 1。负对数似然则为，</p><script type="math/tex; mode=display">l=-\sum_{i=1}^C y_i \log x_i</script><p>实际在 PyTorch 中，NLLLoss 层的输入 Tensor 的 shape 以及 GT target 的 shape 与上面有所不同，以单标签多分类为例，网络输出 Tensor 的 shape 可以是 $(N,C)$，其中 N 表示批大小，C 表示通道也是类别数。GT target 的 shape 为 <code>N</code>，其中每个元素值的范围 <code>[0,C-1]</code>，表示某个样本的类别索引，NLLoss 层的输入已经表示样本各分类的概率对数（由<code>LogSoftmax</code>得到），负对数似然为</p><script type="math/tex; mode=display">L=(l_1,...,l_N), \quad l_n=- x_{n,y_n}</script><p>如果给定参数<code>weight</code>，那么其必须是 1-D tensor，长度与类别数<code>C</code> 相等，用于给每个类别增加一个权重，参考 <a href="2021/1/12/dl/x_ent_loss">交叉熵损失</a> 中的 <a href="2021/1/12/dl/x_ent_loss#Balanced-Cross-Entropy">$\alpha$ 均衡交叉熵</a>，这在非均衡数据集上较为有效。此时有</p><script type="math/tex; mode=display">l_n=- w_{y_n}  x_{n,y_n}</script><p>类签名<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span>weight<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> ignore_index<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reduction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p><code>size_average</code> 和 <code>reduce</code> 这两个参数已经过时。<code>reduction</code>用于指定批样本的损失向量是否归约（均值或求和）。</p><p><code>ignore_index</code> 如果指定，那么当 GT target 值等于 <code>ignore_index</code> 时，将会忽略对应的损失贡献。</p><p>input 通过 forward 方法指定，input 表示每个分类的概率对数，这可以通过 <code>LogSoftmax</code> 得到，input 的 shape 可以是 $(N,C)$，或者是 $(N,C,d_1,…,d_K)$，对于后者，其 target 的 shape 则为 $(N,d_1,…,d_K)$，此时的（未归约）损失 shape 也是 $(N,d_1,…,d_K)$，相比较于前者，后者就是扩展了维度而已，对于 $(d_1,…d_K)$ 中按像素级地计算负对数似然损失。</p><h1 id="CrossEntropyLoss"><a href="#CrossEntropyLoss" class="headerlink" title="CrossEntropyLoss"></a>CrossEntropyLoss</h1><p>交叉熵损失，适用于分类问题。PyTorch 中，这个类（layer）合并了 <code>LogSoftmax</code> 和 <code>NLLLoss</code>，所以这个 layer 的 input 为为归一化的各分类的原始得分，input 的 shape 可以是 $(N,C)$ 或 $(N,C,d_1,…,d_K)$。target 的 shape 则为 $(N,)$ 或 $(N,d_1,…,d_K)$。<br>以 input 的 shape 为 $(N,C)$ 为例，此 layer 的损失计算可表示为（单个样本）</p><script type="math/tex; mode=display">l_n=-\log \left(\frac {\exp x_{n,y_n}}{\sum_j \exp x_{n,j}}\right)</script><p>其中 $y_n \in [0,C-1]$ 为第 n 个样本的类别索引，$\sum_j$ 为某个样本对 C 个类别的求和。</p><p>除了增加了一个 <code>LogSoftmax</code> 的计算，其他均与 NLLoss 层类似，故类签名中的参数介绍略。</p><h1 id="PoissonNLLLoss"><a href="#PoissonNLLLoss" class="headerlink" title="PoissonNLLLoss"></a>PoissonNLLLoss</h1><p>Poisson 损失一般用于服从 poisson 分布的计数数据回归的问题，例如下周教堂人数预测。Poisson 分布如下</p><script type="math/tex; mode=display">P(X=k)=\frac {\lambda^k e^{-\lambda}} {k!}</script><p>随机变量 X 的期望 $E[X]=\lambda$。我们的预测值 $x$ 就是对期望 $\lambda$ 的预测，target 值就是真实的计数值（例如事件发生的次数，教堂的人数等），target 值用 $y$ 表示，也就是上式中的 $k$，于是单个样本的负对数似然可表示如下：</p><script type="math/tex; mode=display">l= -\log P(y|x) =-\log \frac {x^{y} e^{-x}} {y!}=x-y \log x+ \log(y!)</script><p>最后一项可以忽略或者适应 Stirling 公式近似求解。因为是一个常数，所以即使忽略掉，也不影响反向传播的计算。</p><p>类签名：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">PoissonNLLLoss<span class="token punctuation">(</span>log_input<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> full<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> eps<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token operator">=</span><span class="token number">1e-8</span><span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reduction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><code>log_input</code> 指明 forward 的输入 input 是否经过了 log 处理，如是 True，那么上式损失计算应改为 $l=e^x - yx$，否则损失计算式为 $l=x-y \log(x+eps)$。在 Poisson 回归中，假定期望的对数符合线性模型，所以很多时候是对期望的 log 值进行预测，即 <code>log_input=True</code>，此时 target 值也要经过 log 处理。</p><blockquote><p>程序中为了防止计算数值上下溢，往往会采用 log 处理</p></blockquote><p><code>full</code> 指示是否添加最后一项 $\log(y!)$。如需要添加，那么使用 Stirling 公式近似，Stirling 公式为</p><script type="math/tex; mode=display">n! \sim \sqrt{2 \pi} n^{n+1/2} e^{-n}</script><p>于是有</p><script type="math/tex; mode=display">\log(n!)=\frac 1 2 \log(2 \pi n)+ n \log n - n</script><p>forward 方法的 input 的 shape 是 $(N, <em>)$，其中 $</em>$ 表示对维度的扩展，且损失计算都是在 $<em>$ 维度上按像素级进行计算，故 target 的 shape 也是 $(N, </em>)$。如果 <code>reduction</code> 参数为 <code>none</code>，那么输出 shape 也是 $(N, *)$，否则将输出 Tensor 中所有值按 求和或平均 进行归约，最终得到一个标量值。</p><h1 id="KLDivLoss"><a href="#KLDivLoss" class="headerlink" title="KLDivLoss"></a>KLDivLoss</h1><p>KL 散度用于度量两个分布之间的差异。KL 散度损失适用于<b>回归</b>问题。</p><p>根据 KL 散度计算损失，KL 散度计算如下，</p><script type="math/tex; mode=display">D(P||Q)=\sum P(x) \cdot \log \frac {P(x)}{Q(x)}</script><script type="math/tex; mode=display">D(P||Q) = \int_x p(x) \log \frac {p(x)}{q(x)} dx</script><p>预测分布越接近真实分布，那么两者之间的 KL 散度应该越小，所以 KL 散度可以作为一种损失。<br>PyTorch 中的类签名：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">KLDivLoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> reduction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">,</span> log_target<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><code>log_target</code> 指示 target 是否经过 log 处理。</p><p>forward 方法中，参数 input 表示预测概率，且经过 log 处理，input 的 shape 为 $(N,<em>)$，其中 $</em>$ 表示单个样本的所有维度。KL 散度损失按像素级计算（可看作是连续分布的离散采样），</p><script type="math/tex; mode=display">l=y \cdot (\log y - x)</script><p>其中 $x$ 表示随机变量某个值对应的预测概率，且经过 log 处理，$y$ 表示这个随机变量在这个值处的真实概率。</p><p>forward 方法的输出结果的 shape 与 input 相同，为 $(N,*)$，如果 <code>reduction</code> 不为 <code>none</code>，那么输出结果将按 求和或平均 归约为一个标量值。</p><h1 id="BCEWithLogitsLoss"><a href="#BCEWithLogitsLoss" class="headerlink" title="BCEWithLogitsLoss"></a>BCEWithLogitsLoss</h1><p>PyTorch 中这个 layer 合并了 Sigmoid 层和 BCELoss 层，由于 BCELoss 层计算单个样本的 BCE 损失为，</p><script type="math/tex; mode=display">l=y \log x + (1-y) \log (1-x)</script><p>其中 $y \in \{0,1\}$ 表示样本的真实分类，$x\in [0,1]$ 表示样本的预测概率，通常使用 Sigmoid 层来将处于实数域的前一个 layer 输出值压缩到 $[0,1]$ 之间，故为了少写一个 Sigmoid 层，将这两者合并为单个 layer： <code>BCEWithLogitsLoss</code>。所以这个 layer 的输入是原始的未归一化的各类别的得分，单个样本的损失为，</p><script type="math/tex; mode=display">l_n=-w_n [y_n \log \sigma(x_n) +(1-y_n) \log (1-\sigma(x_n))]</script><p>这里，批样本中每个样本有各自的一个权重因子 $w_n$。</p><p>如果是多标签多分类问题，那么对于每个类别，均独立进行二分类（正或负），记类别索引为 $c$，那么单个样本的损失为</p><script type="math/tex; mode=display">l_n=\sum_{c=1}^C l_{n,c}=-\sum_{c=1}^C w_n [y_{n,c} \log \sigma(x_{n,c}) +(1-y_{n,c}) \log (1-\sigma(x_{n,c}))]</script><p>其中 $y_{n,c} \in \{0,1\}$，$x_{n,c} \in \mathbb R$。</p><p>还可以对正类样本增加一个权重因子 $p_c$，用于权衡最终的召回率和精度，于是上式变为</p><script type="math/tex; mode=display">l_n=\sum_{c=1}^C l_{n,c}=-\sum_{c=1}^C w_n [p_c y_{n,c} \log \sigma(x_{n,c}) +(1-y_{n,c}) \log (1-\sigma(x_{n,c}))]</script><p>当 $p_c &gt;1$ 时召回率增大，$p_c&lt;1$ 时 精度增大。$p_c$ 可以取类别 $c$ 下 负样本与正样本数量比，如此可认为正负例相等。</p><p>forward 方法中 input 的 shape 为 $(N,<em>)$，其中 $N$ 为批大小，$</em>$ 表示单个样本的维度大小，损失按像素计算，故 target 和未归约的 output 的 shape 均为 $(N,*)$，如果对 output 按求和或平均归约，则 output 为一个标量值。</p><blockquote><p>这个 layer 比起 Sigmoid 和 BCELoss 两个 layer，在数值计算上更加稳定（能避免数值上下溢），因为使用了 <code>log-sum-exp</code> 技巧。</p></blockquote><p>适用于<b>分类</b>问题。</p><h1 id="SmoothL1Loss"><a href="#SmoothL1Loss" class="headerlink" title="SmoothL1Loss"></a>SmoothL1Loss</h1><p>对 L1Loss 的改进，当 L1 范数低于一定值时，使用差的平方项来代替误差，这是因为当预测值越接近真实值时，损失的梯度应该越小，从而减缓参数的更新幅度。SmoothL1Loss 按像素计算，计算式为，</p><script type="math/tex; mode=display">l_i=\begin{cases} \frac 1 {2 \beta} (x_i-y_i)^2 & |x_i - y_i| < \beta \\ |x_i-y_i|-\frac 1 {2 \beta} & \text{otherwise}  \end{cases}</script><p>适用于<b>回归</b>问题。</p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross Entropy Loss</title>
      <link href="/2021/01/12/dl/x_ent_loss/"/>
      <url>/2021/01/12/dl/x_ent_loss/</url>
      
        <content type="html"><![CDATA[<p>深度学习中有很多损失计算方式，不同的损失适合不同的问题，所以有必要对损失进行归类总结一下。<br><span id="more"></span></p><h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>考虑以下两种分类问题。</p><h2 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h2><p>多分类（二分类可以看作是其特殊的一种情况）指每个样本属于<code>C</code> 个分类中的一个，预测值通常是一个长度为 <code>C</code> 的向量，ground truth 为 one-hot 向量。</p><h2 id="多标签分类"><a href="#多标签分类" class="headerlink" title="多标签分类"></a>多标签分类</h2><p>共 <code>C</code> 种分类，每个样本可以属于其中一种或多种分类，网络输出依然是 <code>C</code> 长度的向量，ground truth 向量元素值为 <code>0</code> 或 <code>1</code>，且可以有多个 <code>1</code>。</p><h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>对于分类问题，网络最后一层的输出为长度为<code>C</code> 的向量（通常使用全连接），其元素值的范围为实数域，所以需要一个激活层，从而方便损失计算（以及梯度反向传播计算）。激活层有以下几种：</p><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p>对向量的每个元素（神经元）使用 Sigmoid 函数，使得输出向量位于 <code>(0,1)</code> 之间，此时向量中最大元素对应的就是样本的预测分类。</p><p>Sigmoid 常用于二分类问题，此时标记为正类/负类，ground truth 为 <code>1/0</code>，网络最后一层可以使用单个神经元，神经元的输出经过 Sigmoid 后处于范围 <code>(0,1)</code>，如果值大于等于 0.5，那么就属于正类，否则属于负类。</p><h2 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h2><p>Softmax 除了可以将神经元输出压缩到 <code>(0,1)</code> 之间，还使各元素值和为 1。Softmax 通常用于多分类。</p><h1 id="分类损失"><a href="#分类损失" class="headerlink" title="分类损失"></a>分类损失</h1><h1 id="Cross-Entropy-Loss"><a href="#Cross-Entropy-Loss" class="headerlink" title="Cross-Entropy Loss"></a>Cross-Entropy Loss</h1><p>单个样本的交叉熵损失计算公式为，</p><script type="math/tex; mode=display">CE=-\sum_{i=1}^C y_i \log (x_i)</script><p>其中 $y_i$ 为 ground truth 向量中的第<code>i</code>个元素值，$x_i$ 为预测向量中第 <code>i</code> 个值，从这里也可以看出，正是有了上述激活层，才使得 $\log(x_i)$ 这一项有意义。多分类问题中，由于 GT 是 one-hot 向量，所以只有 $i=c$ 这项保留下来，其他项均为零。</p><p>二分类问题中，GT: $y=1$ 表示正，$y=0$ 表示负，最后一层输出为单个值（经过 Sigmoid 激活）<code>x</code>，所以单个样本的交叉熵损失为 </p><script type="math/tex; mode=display">CE=-y \log (x) - (1-y) \log(1-x)</script><p>这跟负对数似然是一样的。</p><p>多标签分类问题中，假设一共有 <code>C</code> 种分类，对于单个样本而言，需要做 <code>C</code> 次二分类预测，交叉熵损失为</p><script type="math/tex; mode=display">CE=-\sum_{i=1}^C y_i \log(x_i) - (1-y_i) \log(1-x_i)</script><h2 id="Balanced-Cross-Entropy"><a href="#Balanced-Cross-Entropy" class="headerlink" title="Balanced Cross Entropy"></a>Balanced Cross Entropy</h2><p>一种常见的解决分类不均衡的方法是引入一个权重因子 $\alpha \in [0,1]$，定义 </p><script type="math/tex; mode=display">\alpha_t=\begin{cases} \alpha & y=1 \\ 1-\alpha & y=0 \end{cases}</script><p>考虑二分类问题，为了表示简便，定义真实分类对应的预测值为</p><script type="math/tex; mode=display">x_t=\begin{cases} x & y=1 \\ 1-x & y=0 \end{cases}</script><p>$\alpha$ 均衡交叉熵损失为</p><script type="math/tex; mode=display">CE=-\alpha_t \log(x_t)</script><p>通常，取 $\alpha$ 为类别的频率的倒数，这样就增加了低频类别的贡献，降低了高频类别的贡献。也可以将 $\alpha$ 看作超参，并使用 cross validation 获取一个较好的值。</p><h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>单个样本的 Focal loss 为，</p><script type="math/tex; mode=display">FL=-(1-x_t) ^{\gamma} \log(x_t)</script><p>展开则为</p><script type="math/tex; mode=display">FL=-y(1-x)^{\gamma} \log(x) -(1-y)x^{\gamma} \log(1-x)</script><p>其中，$\gamma \ge 0$。</p><p>相比于交叉熵损失，Focal loss 增加了一个 scale 因子 $(1-x_t)^{\gamma}$，当 $x_t$ 越大，表明分类越是正确，越是应该降低其对损失的贡献，所以这个 scale 因子动态降低了那些 easy 样本对损失的贡献，从而使模型更专注于处理 hard 样本。</p><p>类似地，可以对 Focal loss 进行 $\alpha$ 均衡以处理类别不均衡的问题，此时 Focal loss 变体为</p><script type="math/tex; mode=display">FL=-\alpha_t (1-x_t)^{\gamma} \log (x_t)</script>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Learning Tricks1</title>
      <link href="/2021/01/08/dl/tricks_1/"/>
      <url>/2021/01/08/dl/tricks_1/</url>
      
        <content type="html"><![CDATA[<p>深度学习中有很多训练技巧，这里做一些总结。<br><span id="more"></span></p><h1 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h1><h2 id="BatchNorm-的作用："><a href="#BatchNorm-的作用：" class="headerlink" title="BatchNorm 的作用："></a>BatchNorm 的作用：</h2><ol><li>防止过拟合。每个样本均经过批归一化后，防止出现离群点，从而导致过拟合。</li><li>加快收敛。梯度下降过程中，每一层参数不断变化，导致输出结果的分布也在不断变化，后层网络就需要不停的适应这种变化。通常称这种变化为 <code>Internal Covariate Shift</code>，当数据流经深度网络的某层时，这层的计算结果可能会使得数据变的更大，或这更小，使得后面的网络层学习变得困难。使用 BN 后，BN 应用在每层计算函数之后，激活函数之前，使得数据分布集中在中间位置，这样再应用激活函数才有意义，并且 BN 之后的数据集中在激活函数的中间位置，此位置的梯度较大，从而有效防止了梯度弥散，并加快收敛速度。</li><li>防止梯度弥散。</li></ol><h2 id="BatchNorm-的计算公式"><a href="#BatchNorm-的计算公式" class="headerlink" title="BatchNorm 的计算公式"></a>BatchNorm 的计算公式</h2><p>假设批大小为 <code>m</code>，足够小的数 $\epsilon$，</p><p>$\mu=\frac 1 m \sum_{i=1}^m x_i$</p><p>$\sigma^2=\frac 1 m \sum_{i=1}^m (x_i - \mu)^2$</p><p>$\hat x_i=\frac {x_i -\mu} {\sqrt{\sigma^2+\epsilon}}$</p><p>$y_i=\gamma \hat x_i+\beta$</p><p>上面最后一步为 <code>scale and shift</code>操作，其中参数 $\gamma, \beta$ 是 BN 层需要学习的参数，因为对数据做了归一化处理，使得难以学习到输入数据的特征，所以引入可训练参数 $\gamma, \ \beta$，这样既实现了归一化，又增加参数以可以学习输入数据的特征。</p><h2 id="BatchNorm-适用范围"><a href="#BatchNorm-适用范围" class="headerlink" title="BatchNorm 适用范围"></a>BatchNorm 适用范围</h2><p>BatchNorm 降低了数据之间的绝对差异，考虑相对差异（归一化带来的），所以如果某任务中图像的绝对差异很重要，那么其实不适合使用 BatchNorm。</p>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 技巧1</title>
      <link href="/2021/01/08/pytorch/tricks_1/"/>
      <url>/2021/01/08/pytorch/tricks_1/</url>
      
        <content type="html"><![CDATA[<p>假设最后一层的 input shape 为 (N,H,W)，输出为 loss 为一标量，那么最后一层 input 的梯度 shape 为 (N,H,W)，与 input Tensor 自身 shape 相同，然后继续反向传播，倒数第二层的 input shape 为 (N’,H’,W’)，<br>假设某层输入input 的 shape 为 (N,H,W)，输出 output 的 shape 为 (N’,H’,W’)，这里为了叙述简单，不考虑 batch 的维度，反向传播时，output 变量的梯度的 shape 应该与 output 变量自身相同，output 对 input 的梯度 shape 应该为<br>(N’,H’,W’,N,H,W)，与 </p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Histogram Equalization</title>
      <link href="/2020/06/23/dip/hist_equal/"/>
      <url>/2020/06/23/dip/hist_equal/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>cv.methods</title>
      <link href="/2020/05/27/cv/methods/"/>
      <url>/2020/05/27/cv/methods/</url>
      
        <content type="html"><![CDATA[<p>来总结一下 CV 中的常见方法或技巧。      </p><span id="more"></span><h1 id="原始图像处理"><a href="#原始图像处理" class="headerlink" title="原始图像处理"></a>原始图像处理</h1><h2 id="crop-resize"><a href="#crop-resize" class="headerlink" title="crop resize"></a>crop resize</h2><p>由于</p><h2 id="resize"><a href="#resize" class="headerlink" title="resize"></a>resize</h2><p>图像resize 后，可能会变大，也可能变小。</p>]]></content>
      
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLO</title>
      <link href="/2020/04/20/obj_det/YOLO/"/>
      <url>/2020/04/20/obj_det/YOLO/</url>
      
        <content type="html"><![CDATA[<h1 id="1-YOLOv1"><a href="#1-YOLOv1" class="headerlink" title="1 YOLOv1"></a>1 YOLOv1</h1><h2 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h2><p>one-stage 检测方法，从图像像素到bbox 坐标和分类概率，一步到位。优点为：</p><ol><li>快。YOLO 每秒可处理 45 帧，可实时处理视频流。</li><li>从图像全局出发，作出预测。这种策略有效利用了上下文信息。</li><li>能学习目标的泛化特征。基于天然图像数据集上的训练，用于人工图像数据集上的测试，也能取得较好的结果。</li></ol><span id="more"></span><h2 id="1-2-方法"><a href="#1-2-方法" class="headerlink" title="1.2 方法"></a>1.2 方法</h2><p>YOLOv1 网络结构如图1，采用的是 VOC 数据集。<br><img src="/images/obj_det/YOLOv1_fig1.jpg" alt=""> <center>图 1 YOLOv1 网络结构</center></p><p>输入 shape : <code>448,448,3</code>，<br>输出 shape ：<code>7,7,35</code></p><h3 id="1-3-检测思想"><a href="#1-3-检测思想" class="headerlink" title="1.3 检测思想"></a>1.3 检测思想</h3><ol><li>将输入图像划分为 <code>SxS</code> 大小的网格，如果目标中心落于某个 grid cell，那么这个 grid cell 负责检测这个目标。对于 VOC 数据集，使用 <code>S=7</code>，这是综合考虑，平衡了计算量和准确率。</li><li>每个 grid cell 预测 <code>B</code> 个 box。这里取 <code>B=3</code>。</li><li>对每个 box 预测，需要 5 个数据 <code>(x,y,w,h,IOU)</code>（全部都是归一化的）。</li><li>VOC 数据集的分类数量 <code>C=20</code>。每个 grid cell 处预测 <code>C</code> 个分类概率，即，每个 grid cell 处的 <code>B</code> 个 box 共享这 <code>C</code> 个分类概率（因为实际上，<code>B</code> 个预测 box 中只有 一个 box 负责预测）。</li><li>从 <code>448</code> 到 <code>7</code>，网络的下采样率为 <code>448/7=64</code>。从图 1 也能看出，具有 <code>s-2</code> 字样的 layer 共有 6 个。输出 map 的 spatial size 变成 <code>7x7</code>，channel 变成 <code>35</code>，这是因为每个空间位置处需要 <code>B*5+C=3*5+20</code> 个预测数据。</li><li>训练阶段，计算损失，并求梯度，然后更新，具体参见下文详细分析。</li><li>测试阶段，共检测出 <code>S*S*B</code> 个 box，每个 box 有 4 个坐标值，1 个 IOU 以及 C 个分类概率。对分类概率进行一个阈值截断，阈值默认为 0.2。分别针对每个分类，根据分类概率倒序排列，对 box 进行非极大抑制（设置被抑制 box 的当前分类的概率为 0），非极大抑制阈值默认为 0.4。最后，筛选出所有检测 box 中具有大于阈值（0.2）的分类概率，为最终检测结果。</li></ol><p><strong>思考：</strong> 为什么每个 grid cell 处预测不是 1 个 box 而是多个 box？</p><p><strong>答：</strong> 我们假定不会有多个目标的中心落入同一个 grid cell，如果确实存在（这种概率很低），那么只有第一个目标的数据<code>x,y,w,h,IOU,class</code>会写入 gt <code>Y</code> 中。每个 grid cell 仍然预测多个 box，这是因为这些不同的预测 box 将具有不同的 size 或 aspect ratio。如果目标中心落入某个 grid cell，那么其上的 <code>B</code> 个预测 box 中，只有与目标 IOU 最大的预测 box 才负责预测。例如，某个预测 box 适合预测高的目标（人），而另一个预测 box 可能适合预测宽的目标（车）。</p><h3 id="1-4-损失"><a href="#1-4-损失" class="headerlink" title="1.4 损失"></a>1.4 损失</h3><script type="math/tex; mode=display">\begin{aligned} L&=\lambda_{coord} \sum_{i=1}^{S^2}\sum_{j=1}^B \mathbf 1_{ij}^{obj}(x_i-\hat x_i)^2+(y_i-\hat y_i)^2 \\\\ &+ \lambda_{coord} \sum_{i=1}^{S^2}\sum_{j=1}^B \mathbf 1_{ij}^{obj}(\sqrt {w_i}- \sqrt {\hat w_i})^2+(\sqrt {h_i}- \sqrt {\hat h_i})^2 \\\\ &+ \sum_{i=1}^{S^2}\sum_{j=1}^B \mathbf 1_{ij}^{obj} (C_i-\hat C_i)^2 \\\\ &+ \lambda_{noobj} \sum_{i=1}^{S^2}\sum_{j=1}^B \mathbf 1_{ij}^{noobj}(C_i-\hat C_i)^2 \\\\ &+ \sum_{i=1}^{S^2} \mathbf 1_i^{obj} \sum_{c \in classes}\left(p_i(c)-\hat p_i(c)\right)^2 \end{aligned}</script><p><strong>分析：</strong></p><p>带 <code>^</code> 的为网络输出，不带 <code>^</code> 则为 ground truth 值。<code>x, y, w, h</code> 为中心点坐标，<code>C</code> 为 IOU，<code>pi(c)</code> 为分类 <code>c</code> 的概率。</p><p>$\mathbf 1_{ij}^{obj}$ 表示第 <code>i</code> 个 grid cell 有目标（中心），且此 grid cell 上第 <code>j</code> 个预测 box 与 gt box 有最大 IOU，即，第 <code>j</code> box 负责预测。</p><p>对于较大 box 和 较小 box，在相同偏差$\Delta w, \ \Delta h$ 下，较大 box 的损失应该比较小 box 的损失更小才合理，然而两者平方差损失相同，所以我们对宽高 <code>w,h</code>，先求平方根，再求平方差，这在一定程度上降低了这种不合理性。</p><p>$\mathbf 1_{ij}^{noobj}$ 表示 i) 第 <code>i</code> 个 grid cell 无目标（中心），或者 ii) 有目标（中心），但是第 <code>j</code> 个预测 box 不负责预测（即，与 gt box 的 IOU 不是 <code>B</code> 个预测 box 中最大的）。</p><p>$\mathbf 1_i^{obj}$ 表示第 <code>i</code> 个 grid cell 有目标（中心）。</p><p>坐标损失与分类损失分属两类损失，需要进行平衡。此外，由于大部分预测 box 其实并不负责预测，来自这部分预测 box 的 IOU 损失（损失公式中第四行）将会压制负责预测的 box 的坐标损失和 IOU 损失（损失公式中前三行），所以需要提升被压制的那部分的损失贡献。综合考虑，设置 $\lambda_{coord}=5, \ \lambda_{noobj}=0.5$。</p><h2 id="1-5-细节"><a href="#1-5-细节" class="headerlink" title="1.5 细节"></a>1.5 细节</h2><ol><li>GT label 数据的 size 为 <code>S*S*(5+20)</code>，其中 <code>5</code> 包含了 4 个坐标值，1 个 IOU，20 为表示分类 id 的 one-hot vector 的长度。维度从高到低为 <code>(S,S,5+20)</code>，最低维数据顺序为 IOU, class id, x,y,w,h。</li><li>网络输出 size 为 <code>S*S*(B*5+20)</code>，维度从高到低为 <code>(5+20,S,S)</code>，通道顺序为 class id, IOU, x,y,w,h。</li><li>GT label 数据中， x,y,w,h 先进行归一化（除以图像宽/高），然后 <code>x=x*S-(int)x*S, y=y*S-(int)y*S</code>。</li><li>网络输出中的 x,y 与 GT label 中含义一致，表示相对于 grid cell 的（归一化）偏差，而 w,h 则是经过了平方根处理。</li></ol><h1 id="2-YOLOv2"><a href="#2-YOLOv2" class="headerlink" title="2. YOLOv2"></a>2. YOLOv2</h1><h2 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1 简介"></a>2.1 简介</h2><p>YOLOv2 是对 YOLOv1 的改进，包括：</p><ol><li>利用现有的分类数据集来扩展检测数据集，使得检测目标的分类种数更多。</li><li>增加 Batch Normalization</li><li>检测小目标更准确</li></ol><p>在分类集上预训练时，就使用较大分辨率的图像。YOLOv1 中使用 <code>224x224</code> 在分类集上预训练，然后直接将 <code>448x448</code> 大小的检测数据训练集喂给网络，这让网络同时适应高分辨率的图像以及学习目标检测，难免压力山大。YOLOv2 中，每隔十次 batch 训练，变更一次网络输入 size。</p><h2 id="2-2-方法"><a href="#2-2-方法" class="headerlink" title="2.2 方法"></a>2.2 方法</h2><p>以 VOC 数据集为例，YOLOv2 的网络结构可以从配置文件 <code>cfg/yolov2-voc.cfg</code> 中获取。</p><h3 id="2-2-1-实现细节"><a href="#2-2-1-实现细节" class="headerlink" title="2.2.1 实现细节"></a>2.2.1 实现细节</h3><ol><li>输入 size 每隔 10 个 batch 变更一次，从 <code>320, 352, ..., 608</code> 这十个值中随机选择。记输入大小为 <code>(3,d,d)</code>。</li><li><p>网络整体下采样率为 32，输出大小为 <code>(125, d/32, d/32)</code>。其中，<code>(d/32,d/32)</code> 与 YOLOv1 中类似，可以看作原图像上的 grid cell 数量 <code>S=d/32</code>。如果目标的中心落入某个 grid cell，那么这个 grid cell 负责预测目标。每个 grid cell 上有 <code>5</code> 个预测 box，每各 box 有 <code>1</code> 个 IOU 以及 <code>4</code> 个坐标值，每个 box 独立拥有 <code>20</code> 个分类得分，故输出 channel 为 <code>125=5*(1+4+20)</code>。注意，YOLOv1 中每个 cell 上的 <code>B</code> 个预测 box 共享 <code>20</code> 个分类得分。</p></li><li><p>人为假设每个图像中目标数量最多为 30，所以 GT label 大小为 <code>30x5</code>，其中 <code>5</code> 包含了 4 个坐标值以及 1 个分类 id。最低维数据顺序为 x,h,w,h,class id。GT label 靠前存储。</p></li><li><code>(route:-1，-4)</code> 层将浅层特征（高分辨率）与高层特征（低分辨率）融合，类似于 ResNet 中的 identity mapping，这种更细粒度的特征将有助于小目标的检测。</li></ol><h3 id="2-3-损失"><a href="#2-3-损失" class="headerlink" title="2.3 损失"></a>2.3 损失</h3><p>损失包括：分类损失，置信度损失，坐标损失三部分。</p><script type="math/tex; mode=display">L=L_p+L_{box}+L_C</script><p><strong>分类损失</strong></p><script type="math/tex; mode=display">L_p=\sum_{i=1}^{S^2} \sum_{j=1}^B \sum_{c=1}^{20} \mathbf 1_{ij}^{obj} [\hat p_{ij}(c)-p_{ij}(c)]^2</script><p><strong>坐标损失</strong></p><script type="math/tex; mode=display">\begin{aligned}L_{box}&=\lambda_{obj}^{coord} \sum_{i=1}^{S^2} \sum_{j=1}^B \mathbf 1_{ij}^{obj} (\hat x_{ij} - x_{ij})^2 + (\hat y_{ij} - y_{ij})^2+ (\hat w_{ij} - w_{ij})^2+ (\hat h_{ij} - h_{ij})^2 \\ &+ \lambda_{noobj}^{coord} \sum_{i=1}^{S^2} \sum_{j=1}^B \mathbf 1_{ij}^{noobj} (\hat x_{ij} - x_{ij}^a)^2 + (\hat y_{ij} - y_{ij}^a)^2+ (\hat w_{ij} - w_{ij}^a)^2+ (\hat h_{ij} - h_{ij}^a)^2 \end{aligned}</script><p><strong>置信度损失</strong></p><script type="math/tex; mode=display">\begin{aligned}L_C &=\lambda_{obj}^{conf}\sum_{i=1}^{S^2} \sum_{j=1}^B \mathbf 1_{ij}^{obj}[\hat C_{ij}-iou(\hat {\text{box}}_{ij}, \text{box}_{ij})]^2  \\&+ \lambda_{noobj}^{conf}\sum_{i=1}^{S^2}\sum_{j=1}^B \mathbf 1_{ij}^{noobj}[\hat C_{ij}-0]^2 \end{aligned}</script><p>以上，带 ^ 表示 network 输出，带 a 表示 anchor，不带这两个修饰的表示 GT label。</p><p><strong>分析：</strong></p><p>网络输出 shape 从高维到低维为，<code>batch, B, 4+1+C, S, S</code>（其实无论几维，在内存中都是一维）。这里假设了输出 feature map 的 height 和 width 相等，均为 <code>S</code> （grid size），且 <code>4</code> 表示 4 个坐标，<code>1</code> 表示 IOU，<code>C</code> 表示分类数量。</p><p>与 YOLOv1 中类似，目标中心落入某个 grid cell，那么这个 grid cell 负责预测目标。每个 grid cell 有 <code>B=5</code> 个预测 box，具有不同的 size。使用 5 组 anchor box 帮助预测，参考 yolov2-voc.cfg 文件中最后一个 layer 配置中 <code>anchors</code> 的值，给了 5 组 width height 的值，这些值基于输出 feature map 的 size <code>SxS</code>，即，并没有归一化。anchor box 的中心为所在 grid cell 坐标加 0.5，即 <code>(i,j)</code> 处 grid cell 的 anchor box 中心为 <code>(i+0.5, j+0.5)</code>。</p><p>网络输出坐标 <code>x,y,h,w</code> 的具体含义，如图 2，<br><img src="/images/obj_det/YOLOv2_fig2.png" alt=""> </p><center>图2 预测 box 与 anchor box 的关系</center><p>网络输出坐标实际含义就是 $\sigma(t_x), \sigma(t_y), t_w, t_h$。</p><p>一幅图像的 GT label 的 size 为 <code>30*5</code>，低维数据排列顺序为 <code>x,y,w,h, class id</code>，其中 <code>x,y,w,h</code> 是基于 original image 的 size 进行了归一化（<code>x,y</code> 与 YOLOv1 中稍有不同）。</p><p>坐标损失中 $x_{ij}, y_{ij}, w_{ij}, h_{ij}$ 使用的是 $\sigma(t_x), \sigma(t_y), t_w, t_h$，对于网络输出，不用做任何修改，而对于 GT box 以及 anchor box，则需要做变换，也就是说，将预测 box 分别替换为 GT box 和 anchor box 来计算 $\sigma(t_x), \sigma(t_y), t_w, t_h$。</p><p>位于某 location <code>(i,j)</code> 处，将 <code>B</code> 个预测 box 与 GT label 中所有目标 box 两两求 IOU，最后得到一个最大 IOU，如果这个最大 IOU 大于阈值 0.5，那么 $\mathbf 1_{ij}^{noobj}=0$，此时置信度损失中第二项为 0。</p><p>对于每个 GT box，找出与这个 GT box 有最大 IOU 预测 box，注意这个 IOU 没有阈值限制，然后设置 $\mathbf 1_{ij}^{obj}=1$（每个 GT box 有且只有一个负责预测的 box），此时置信度损失中第一项非零，且分类损失非零，此时计算分类损失时，$\sum_{c=1}^C$ 求和中，当且仅当 <code>c</code> 等于 GT label 中的 class id 时，$p_{ij}(c)=1$，其余 <code>C-1</code> 种情况 $p_{ij}(c)=0$。</p><h1 id="3-YOLOv3"><a href="#3-YOLOv3" class="headerlink" title="3. YOLOv3"></a>3. YOLOv3</h1><p>在 YOLOv2 基础上做了修改：</p><ol><li>三个 scale 的输出 feature maps。每组 feature maps 的大小为 <code>NxNx[3*(4+1+C)]</code>，三个不同的 <code>N</code>，依次增大 2 倍。</li><li>使用 <code>9</code> 个不同 scale 的 anchor box 帮助预测。由于有 <code>3</code> 个 scale 的 feature maps，所以实际上，每个 scale 大小的 feature maps 上每个 grid cell 仅使用 <code>9/3=3</code> 个 anchor box。</li></ol><p>以 VOC 数据集为例，网络结构参见 <code>cfg/yolov3-voc.cfg</code>。</p><ol><li>特征抽取网络的下采样率为 <code>32</code>。如果输入图像的大小为 <code>(h,w)</code>，那么输出feature map 大小为 <code>(h/32,w/32)</code>，另外两个 scale 的 feature maps 的大小则为 <code>(h/16,w/16)</code> 和 <code>(h/8, w/8)</code>。</li><li>单个图像的 GT label 大小 为 <code>90*5</code>。这表示单个图像中目标数量最大不超过 <code>90</code>。</li><li>大量使用 Residual layer。</li></ol><p><img src="/images/obj_det/YOLO_3.png" alt=""></p><center>图 3. Darknet53 结构</center><p>backbone 三个输出分支分别为：</p><ol><li>第三个 residual block 的输出，图 3 中的 <code>32x32x256</code></li><li>第四个 residual block 的输出，图 3 中的 <code>16x16x512</code></li><li>最后的 residual block 的输出，图 3 中的 <code>8x8x1024</code></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch.optim</title>
      <link href="/2020/01/08/pytorch/optim-2/"/>
      <url>/2020/01/08/pytorch/optim-2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Adam"><a href="#1-Adam" class="headerlink" title="1. Adam"></a>1. Adam</h1><p>Adam 表示 Adaptive Moment Estimation。<br><span id="more"></span></p><h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1 原理"></a>1.1 原理</h2><p>梯度和梯度平方的衰减如下，</p><script type="math/tex; mode=display">m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t\\\\ v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2 \qquad(1)</script><p>其中 $\beta_1 &lt; 1, \ \beta_2 &lt; 1$，$m_t$ 和 $v_t$ 分别是梯度 $g$ 的一阶矩和二阶矩的样本估计（$g$ 看作随机变量）。由于 $m$ 和 $v$ 均初始化为 0，即 $m_0=0, \ v_0 = 0$，所以这两个样本估计均是有偏估计，且偏向 0，尤其在刚开始的时间步（t 较小）和衰减率较小时（$1-\beta$ 较小，$\beta$ 接近 1）。</p><p>令 $E(g)=\mu$，$g_1, g_2, …$ 来自于 $g$ 且独立同分布，那么</p><script type="math/tex; mode=display">E(m_t)=E\left(\sum_{\tau=1}^t \beta_1^{t-\tau} (1-\beta_1) g_{\tau}\right)=(1-\beta_1)\sum_{\tau=1}^t \beta_1^{t-\tau}E(g_{\tau})=\mu (1-\beta_1)\sum_{\tau=1}^t \beta_1^{t-\tau}=\mu(1-\beta_1^t)</script><p>可见，当 t 较小且 $\beta_1 \rightarrow 1$，$E(m_t) \rightarrow 0$</p><p>为了抵消这些偏向，取以下计算进行校正，</p><script type="math/tex; mode=display">\hat m_t=\frac {m_t} {1-\beta_1^t}\\\\ \hat v_t = \frac {v_t} {1-\beta_2^t}</script><p>其中 上标 <code>t</code> 表示指数，即 <code>t</code> 个 $\beta$ 相乘。 通过上面的分析，可知，除以 $1-\beta^t$ 后，$E(\hat m_t)=\mu$，为无偏估计。</p><p>然后类似 Adadelta 和 RMSprop 中那样，更新公式为，</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t - \frac {\eta} {\sqrt{\hat v_t}+\epsilon} \hat m_t \qquad(2)</script><p>其中 $\eta$ 为初始学习率，是一个初始时给定的超参数。</p><h2 id="1-2-AMSGrad-变体"><a href="#1-2-AMSGrad-变体" class="headerlink" title="1.2 AMSGrad 变体"></a>1.2 AMSGrad 变体</h2><p>修改 $v$ 的计算式如下，</p><script type="math/tex; mode=display">v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2\\\\ v_{t,m} = \max\left(v_{t-1,m}, \ \beta_2 v_{t-1} + (1-\beta_2) g_t^2\right)</script><p>其中 $v_{0,m}=0$。</p><p>然后 $v$ 的无偏估计改为，</p><script type="math/tex; mode=display">\hat v_{t,m}=\frac {v_{t,m}} {1-\beta_2^t}</script><p>参数更新公式调整为，</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t - \frac {\eta} {\sqrt{\hat v_{t,m}}+\epsilon} \hat m_t \qquad(3)</script><p>其中 $\hat m_t$ 的计算部分与前面的保持一致。</p><p>AMSGrad 比 Adam 降低了学习率。</p><h1 id="2-Adamax"><a href="#2-Adamax" class="headerlink" title="2. Adamax"></a>2. Adamax</h1><p>在 Adam 的基础上将 (1) 式泛化，不局限于 $l_2$ 范数，如下</p><script type="math/tex; mode=display">v_t = \beta_2^p v_{t-1} + (1-\beta_2^p)|g_t|^p</script><p>其中注意 $p$ 为指数。</p><p>将上式中的 $v_{t-1}$ 展开，</p><script type="math/tex; mode=display">\begin{aligned} v_t  &= (1-\beta_2^p)|g_t|^p + \beta_2^p[(1-\beta_2^p)|g_{t-1}|^p+\beta_2^p v_{t-2}]\\\\ & = (1-\beta_2^p)\sum_{i=1}^t \beta_2^{p(t-i)} |g_i|^p\end{aligned}</script><p>令 $p \rightarrow \infin$，并定义 $u_t = \lim_{p \rightarrow \infin}(v_t)^{1/p}$，结合上式有，</p><script type="math/tex; mode=display">\begin{aligned} u_t  = \lim_{p \rightarrow \infin}(v_t)^{1/p} &= \lim_{p \rightarrow \infin}\left((1-\beta_2^p)\sum_{i=1}^t \beta_2^{p(t-i)} |g_i|^p\right)^{1/p}\\\\ &= \lim_{p \rightarrow \infin} (1-\beta_2^p)^{1/p} \left(\sum_{i=1}^t \beta_2^{p(t-i)} |g_i|^p\right)^{1/p}\\\\ &= \lim_{p \rightarrow \infin} \left(\sum_{i=1}^t \beta_2^{p(t-i)} |g_i|^p\right)^{1/p}\\\\ &=\max (\beta_2^{t-1}|g_1|,\beta_2^{t-2}|g_2|,...,\beta_2^{0}|g_t|)\end{aligned}</script><p>于是可得以下迭代公式，</p><script type="math/tex; mode=display">u_t = \max(\beta_2 u_{t-1}, \ |g_t|)</script><p>其中初始值 $u_0=0$。</p><p>用 $u_t$ 替换 Adam 中的 $\sqrt{\hat v_t}+\epsilon$，于是 更新公式为，</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac \eta {u_t} \hat m_t \qquad(4)</script><p>其中 $\hat m_t$ 的计算方式与 Adam 中一致。</p><h1 id="3-AdamW"><a href="#3-AdamW" class="headerlink" title="3. AdamW"></a>3. AdamW</h1><p>Adam 中，梯度中事先包含了正则惩罚项，即</p><script type="math/tex; mode=display">g := g+\lambda \theta</script><p>然后再计算梯度的一阶矩和二阶矩的无偏估计。现在考虑将权重衰减项从梯度 $g$ 中解耦出来，直接附加到参数衰减 $\theta$ 上，调整 (2) 式得到 AdamW 的参数更新公式，</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t - \lambda \eta \theta_t - \frac {\eta} {\sqrt{\hat v_t}+\epsilon} \hat m_t</script><h1 id="4-Nadam"><a href="#4-Nadam" class="headerlink" title="4. Nadam"></a>4. Nadam</h1><p>回顾一下 momentum 版本的 SGD 更新方式，</p><script type="math/tex; mode=display">v_{t+1} = \gamma v_t + \eta g_t\\\\ \theta_{t+1}=\theta_t - v_{t+1}</script><p>然后 NAG 的更新方式，先从当前参数处更新 momentum 的量到达一个新的位置 （(5) 式），然后从新位置处进行梯度下降，作为本次更新后的参数（(6, 7) 式），数学描述如下，</p><script type="math/tex; mode=display">y_t = \theta_t + \mu v_t  \qquad(5)\\\\ g_t = \nabla f(y_t)    \qquad(6)\\\\ \theta_{t+1}=y_t - \gamma g_t \qquad(7)</script><p>联合上面三式可知，</p><script type="math/tex; mode=display">v_{t+1}=\theta_{t+1}-\theta_t=\mu v_t - \gamma g_t</script><p>初始时，$t=0, \ v_0=0 \Rightarrow y_0=\theta_0$。</p><p>根据 <a href="2020/01/02/pytorch/optim_SGD">PyTorch.optim.SGD</a> 中的公式 (8)、(9)、(10)，易知 NAG 等价于以下更新过程，</p><script type="math/tex; mode=display">\begin{cases}g_t = \nabla f(\theta_t)\\\\ v_{t+1} = \gamma v_t + \eta g_t\\\\ v_{t+1}' = \gamma v_{t+1} + \eta g_t\\\\ \theta_{t+1} = \theta_t - v_{t+1}'\end{cases} \qquad(8)</script><p>可见，做了两次的 momentum 更新，相比普通的 momentum 的 SGD，增加了一次 look ahead 的 momentum。注意，$v_{t+1}’$ 与 $v_{t+2}$ 是不一样的。</p><p>接着再回顾 Adam 中的参数更新，根据 (2) 式，得</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t - \frac {\eta} {\sqrt{\hat v_t}+\epsilon} \frac {m_t} {1-\beta_1^t}\qquad(9)</script><p>其中 $m_t$ 包含了一次 momentum 更新，</p><script type="math/tex; mode=display">m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t</script><p>增加一次 momentum 更新，</p><script type="math/tex; mode=display">m_t'=\beta_1 m_t + (1-\beta_1) g_t</script><p>代入 (9) 式，于是参数更新变为，</p><script type="math/tex; mode=display">\begin{aligned}\theta_{t+1}&=\theta_t - \frac \eta {\sqrt {\hat v_t} + \epsilon}\frac {m_t'} {1-\beta_1^t}\\\\&=\theta_t - \frac \eta {\sqrt {\hat v_t} + \epsilon}\frac {\beta_1 m_t + (1-\beta_1) g_t} {1-\beta_1^t}\\\\&=\theta_t - \frac \eta {\sqrt {\hat v_t} + \epsilon}\left(\beta_1 \hat m_t+\frac {1-\beta_1}{1-\beta_1^t} g_t \right)\end{aligned} \qquad(10)</script><p>(10) 式就是 Nadam 的参数更新公式。</p><p>也可以按如下过程理解，</p><script type="math/tex; mode=display">\hat m_t = \frac {m_t} {1-\beta_1^t}=\frac {\beta_1 m_{t-1} + (1-\beta_1) g_t} {1-\beta_1^t}=\frac {\beta_1 \hat m_{t-1}(1-\beta_1^{t-1}) + (1-\beta_1) g_t} {1-\beta_1^t}=\beta_1 \hat m_{t-1}+\frac {1-\beta_1}{1-\beta_1^t} g_t</script><p>其中最后一步用了近似处理。事实上 (10) 式第一步中，将 $m_t$ 替换为 $m_t’$ 时，分母也应该替换为 $1-\beta_1^{t+1}$，因为 $m_t’$ 真正的无偏估计就应该要除以 $1-\beta_1^{t+1}$，但是我们都忽略这个微小的差别。</p><p>根据上式，可得，</p><script type="math/tex; mode=display">\hat m_t'=\beta_1 \hat m_t + \frac {1-\beta_1}{1-\beta_1^t} g_t</script><p>代入 (2) 得 Nesterov momentum 加成的 Adam 变体的 更新公式，与 (10) 式相同。 </p>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch.optim</title>
      <link href="/2020/01/06/pytorch/optim-1/"/>
      <url>/2020/01/06/pytorch/optim-1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Adagrad"><a href="#1-Adagrad" class="headerlink" title="1. Adagrad"></a>1. Adagrad</h1><span id="more"></span><h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1 原理"></a>1.1 原理</h2><p>所有的参数形成一个参数向量，对每个参数使用不同的学习率。例如在时间步 <code>t</code>，第 <code>i</code> 个参数 $\theta_i$ 的梯度为 $g_{t,i}$，</p><script type="math/tex; mode=display">g_{t,i} = \nabla_{\theta}J(\theta_{t,i})</script><p>SGD 的更新方式为，</p><script type="math/tex; mode=display">\theta_{t+1,i}=\theta_{t,i}-\eta \cdot g_{t,i}</script><p>其中学习率 $\eta$ 恒定。</p><p>Adagrad 对每个参数在不同时间步调整学习率，参数更新为</p><script type="math/tex; mode=display">\theta_{t+1,i}=\theta_{t,i}-\frac {\eta} {\sqrt{G_{t,ii}+\epsilon}} \cdot g_{t,i} \qquad(1)</script><p>其中 $G_t \in \mathbb R^{d \times d}$ 是一个对角矩阵，对角线上每个元素 $G_{t,ii}$ 是参数 $\theta_i$ 从时间步 <code>0</code> 到时间步 <code>t</code> 的梯度的平方和，</p><script type="math/tex; mode=display">G_{t,ii}=\sum_{\tau=0}^t g_{\tau,i}^2 \qquad(2)</script><p>$\epsilon$ 为平滑因子，用于避免分母为 0，一般取值 <code>1e-8</code>。</p><p>将 (1) 式向量化，</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t - \frac \eta {\sqrt {G_t+\epsilon}} \odot g_t \qquad(3)</script><p>其中 $\odot$ 表示矩阵与向量相乘。通常，$\eta=0.01$。</p><p>Adagrad 的优点是不需要手动调整学习率，缺点是随着迭代次数的增加，分母逐渐增大，导致最后变得非常小，学习过程非常缓慢甚至停止。</p><p>关于 Adagrad 调整学习率的理论分析可参考论文 [1]。</p><h2 id="1-2-PyTorch-实现"><a href="#1-2-PyTorch-实现" class="headerlink" title="1.2 PyTorch 实现"></a>1.2 PyTorch 实现</h2><p>PyTorch 的 Adagrad 实现中除了学习率 <code>lr</code> 和平滑因子 <code>eps</code>，还是增加了几个参数：</p><ol><li>学习率衰减因子 <code>lr_decay</code></li><li>权重衰减因子 <code>weight_decay</code></li><li>累加初始值 <code>G</code>，这是 (2) 式中累加的一个初始值</li></ol><p>参数更新步骤如下：</p><p>设置累加初值</p><script type="math/tex; mode=display">G_0=[G,...,G]</script><p>其中 $G_0$ 是一个向量（对角矩阵的对角线元素），与参数数量相同。</p><p>在时间步 <code>t</code>，</p><ol><li><p>增加权重衰减项（正则项）的梯度</p><script type="math/tex; mode=display">g_t := g_t + \lambda_{\theta} \cdot \theta_t</script></li><li><p>学习率衰减为 </p><script type="math/tex; mode=display">\eta := \frac {\eta} {1+ t \cdot \lambda_{\eta}}</script></li><li><p>累加梯度平方</p><script type="math/tex; mode=display">G_{t+1} = G_t+ g_t \cdot g_t</script></li><li><p>更新参数</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \frac \eta {\sqrt{G_t} + \epsilon}\cdot g_t</script></li></ol><p>以上，向量的计算全部按元素进行（标量则在需要的时候广播为向量）。（不同的参数具有不同的调整后的学习率）</p><h1 id="2-Adadelta"><a href="#2-Adadelta" class="headerlink" title="2. Adadelta"></a>2. Adadelta</h1><h2 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1 原理"></a>2.1 原理</h2><p>Adadelta 是在 Adagrad 的基础上对学习率一味单调递减进行修改，不再对之前所有时间步的梯度做平方和，而是限制一个最近时间步的窗口，窗口大小为 <code>w</code>。</p><p>然而，由于存储 <code>w</code> 个梯度平方值效率较低，所以改为使用梯度的衰减均值，如下</p><script type="math/tex; mode=display">E[g^2]_t = \gamma E[g^2]_{t-1} + (1- \gamma)g_t^2</script><p>它的平方根就变成了 RMS（均方根，区别是每个元素的权重由 <code>1/n</code> 变成依次递增的值），</p><script type="math/tex; mode=display">\text{RMS}[g]_t = \sqrt{E[g^2]_t + \epsilon}</script><p>这样，越早期时间步的梯度平方，其权重越低，贡献也小，越近期的梯度平方，贡献越大。$\gamma$ 可取 <code>0.9</code>。</p><p>于是，参数更新为，</p><script type="math/tex; mode=display">\Delta \theta_t = -\frac \eta {\text{RMS}[g]_t}\cdot g_t \qquad(4)\\\\\theta_{t+1}=\theta_t + \Delta \theta_t</script><p>更进一步地，更新量 $\Delta \theta$ 与 $\theta$ 在单位空间上不匹配，这在 SGD，momentum 以及 Adagrad 中也存在同样的问题，即</p><script type="math/tex; mode=display">\Delta x 单位 \propto g 单位 \propto \frac {\partial f} {\partial x} \propto  \frac 1 {x 单位}</script><p>上式最后一步中假定了目标函数 <code>f</code> 是无单位的。这个单位空间不匹配如何理解呢？假设 <code>x</code> 表示距离，例如 米 $m$，损失函数 <code>f</code> 无量纲，根据上式，发现 <code>x</code> 的更新量的单位为 $m^{-1}$，显然这是不匹配的。为了实现匹配的目的，首先类似 $g^2$ 的衰减均值，定义更新量的衰减均值，</p><script type="math/tex; mode=display">E[\Delta \theta^2]_t = \gamma \cdot E[\Delta \theta^2]_{t-1} + (1-\gamma)\Delta \theta_t^2</script><p>均方根为，</p><script type="math/tex; mode=display">\text{RMS}[\Delta\theta]_t=\sqrt {E[\Delta \theta^2]_t+\epsilon}</script><p>残念，由于 $\Delta \theta_t$ 未知，所以上式也未知，所以近似使用 $\text{RMS}[\Delta\theta]_{t-1}$ 来代替，然后这个值就作为 (4) 式中的 $\eta$。</p><p>于是最终参数更新方式为，</p><script type="math/tex; mode=display">\Delta \theta_t = -\frac {\text{RMS}[\Delta\theta]_{t-1}} {\text{RMS}[g]_t}\cdot g_t \qquad(5)\\\\\theta_{t+1}=\theta_t + \Delta \theta_t</script><p>注意到 <code>RMS</code> 中有平方根计算，所以，$\text{RMS}[\Delta\theta]_{t-1}$ 与 $\theta$ 量纲匹配，而 $\text{RMS}[g]_t$ 与 $g$ 量纲匹配，所以 (5) 式中 $\Delta \theta$ 与 $\theta$ 量纲匹配。</p><h2 id="2-2-PyTorch-实现"><a href="#2-2-PyTorch-实现" class="headerlink" title="2.2 PyTorch 实现"></a>2.2 PyTorch 实现</h2><p>PyTorch 的 Adadelta 实现使用 (5) 式，非常简单，不再啰嗦。</p><h1 id="3-RMSprop"><a href="#3-RMSprop" class="headerlink" title="3. RMSprop"></a>3. RMSprop</h1><p>RMSprop 就是 Adadelta 中 (4) 式，通常 $\gamma=0.9$，$\eta=0.001$。简单，我们直接看 PyTorch 实现部分。</p><h2 id="3-1-PyTorch-实现"><a href="#3-1-PyTorch-实现" class="headerlink" title="3.1 PyTorch 实现"></a>3.1 PyTorch 实现</h2><p>RMSprop 的 <code>step</code> 方法部分代码如下，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 对每个参数</span>square_avg <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token string">'square_avg'</span><span class="token punctuation">]</span>    <span class="token comment"># 参数对应的梯度平方的衰减均值（也称 moving average）</span>alpha <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'alpha'</span><span class="token punctuation">]</span>              <span class="token comment"># 对应上文公式中的 gamma</span><span class="token keyword">if</span> group<span class="token punctuation">[</span><span class="token string">'weight_decay'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>    grad <span class="token operator">=</span> grad<span class="token punctuation">.</span>add<span class="token punctuation">(</span>group<span class="token punctuation">[</span><span class="token string">'weight_decay'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token punctuation">.</span>data<span class="token punctuation">)</span>  <span class="token comment"># 添加正则项的梯度</span>square_avg<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span><span class="token punctuation">.</span>addcmul_<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>alpha<span class="token punctuation">,</span> grad<span class="token punctuation">,</span> grad<span class="token punctuation">)</span>    <span class="token comment"># 计算 E[g^2]</span><span class="token keyword">if</span> group<span class="token punctuation">[</span><span class="token string">'centered'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>               <span class="token comment"># 使用 centered 版本的 RMSprop</span>    grad_avg <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token string">'grad_avg'</span><span class="token punctuation">]</span>    <span class="token comment"># 获取 梯度衰减平均</span>    grad_avg<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>alpha<span class="token punctuation">,</span> grad<span class="token punctuation">)</span>    <span class="token comment"># 更新 梯度衰减平均</span>    <span class="token comment"># 先归一化，然后计算 RMS[g]</span>    avg <span class="token operator">=</span> square_avg<span class="token punctuation">.</span>addcmul_<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> grad_avg<span class="token punctuation">,</span> grad_avg<span class="token punctuation">)</span><span class="token punctuation">.</span>sqrt_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span>group<span class="token punctuation">[</span><span class="token string">'eps'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token comment"># 直接计算 RMS[g]</span>    avg <span class="token operator">=</span> square_avg<span class="token punctuation">.</span>sqrt_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span>group<span class="token punctuation">[</span><span class="token string">'eps'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">if</span> group<span class="token punctuation">[</span><span class="token string">'momentum'</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>       <span class="token comment"># 使用动量</span>    buf <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token string">'momentum_buffer'</span><span class="token punctuation">]</span>  <span class="token comment"># 获取动量缓存</span>    buf<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>group<span class="token string">'momentum'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>addcdiv_<span class="token punctuation">(</span>grad<span class="token punctuation">,</span> avg<span class="token punctuation">)</span>   <span class="token comment"># 更新 velocity，与 (6) 式一致</span>    p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token operator">-</span>group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> buf<span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>addcdiv_<span class="token punctuation">(</span><span class="token operator">-</span>group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad<span class="token punctuation">,</span> avg<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>上面代码中，如果不使用 <code>centered</code> 和 <code>momentum</code>，那么代码逻辑与 (4) 式完全一致，所以我们只看 <code>centered</code> 和 <code>momentum</code> 是如何进行的。</p><h3 id="centered"><a href="#centered" class="headerlink" title="centered"></a>centered</h3><p>对 梯度 $g$ 归一化，然后计算 平方 的衰减均值，如下</p><script type="math/tex; mode=display">E\{[g-E(g)]^2\}=E(g^2)-[E(g)]^2</script><p>其中 $E(\cdot)$ 计算衰减均值。于是，</p><script type="math/tex; mode=display">RMS[g]=\sqrt{E\{[g-E(g)]^2\}}+\epsilon=\sqrt{E(g^2)-[E(g)]^2}+\epsilon</script><h3 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h3><p>我们回顾一下普通的 SGD 参数更新方式：</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t - \eta \cdot \nabla f(\theta_t)</script><p>然后带有 momentum 的 SGD 参数更新方式：</p><script type="math/tex; mode=display">v_{t+1}=\mu \cdot v_t + \nabla f(\theta_t)\\\\\theta_{t+1}=\theta_t - \eta \cdot v_{t+1}</script><p>根据 (4) 式，现在已知 RMSprop 的参数更新方式为，</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t -\frac \eta {\text{RMS}[g]_t}\cdot g_t</script><p>类比 SGD，可知带有 momentum 的 RMSprop 参数更新方式为，</p><script type="math/tex; mode=display">v_{t+1}=\mu \cdot v_t + \frac {g_t} {\text{RMS}[g]_t} \qquad(6)\\\\ \theta_{t+1}=\theta_t - \eta \cdot v_{t+1}</script><h1 id="4-Rprop"><a href="#4-Rprop" class="headerlink" title="4. Rprop"></a>4. Rprop</h1><h2 id="4-1-原理"><a href="#4-1-原理" class="headerlink" title="4.1 原理"></a>4.1 原理</h2><p>Rprop 表示 resilient propagation。</p><p>在 SGD 中，参数更新方向为负梯度方向，更新步长为梯度乘以一个系数（学习率），但是让更新步长直接与梯度成正比不一定是好选择，例如（来源 [2]）<br><img src="" alt=""><center>图 1. 三个函数在相同的地方有最小值，但是 `f'(x)` 不同</center><br>上图中，三个函数的最小值均在相同地方，所以各自更新步长可以差不多，但是如果使用 学习率乘以梯度 作为步长，显然三者的更新步长将会相差几个数量级，更糟的是，可能还会出现 梯度消失 和 梯度爆炸。</p><p>Rprop 仅利用梯度的（负）方向，参数更新如下，</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t + \Delta \theta_t=\theta_t - \Delta_t \cdot \text{sign}[\nabla f(\theta_t)] \qquad(7)</script><p>其中 $\Delta_t$ 表示时间步 <code>t</code> 处的更新步长，并且不同参数的更新步长也不同，例如第 <code>i</code> 个参数在时间步 <code>t</code> 的更新步长为 $\Delta_{t,i}$。</p><p>在每个时间步，计算各参数的梯度以及更新步长。根据当前时间步的梯度与上一时间步的梯度的符号是否一致，来调整更新步长，思路如下：</p><ul><li>如果符号一致，那么应该增大更新步长，以更快的到达最小值处</li><li>如果符号相反，这表示刚好跨过最小值处，那么应该减小更新步长，以避免再次跨过最小值处</li></ul><p>更新步长调整方案如下，</p><script type="math/tex; mode=display">\Delta_t=\begin{cases}\min(\Delta_{t-1} \cdot \eta^+, \ \Delta_{max}) & \nabla f(\theta_t) \cdot \nabla f(\theta_{t-1}) > 0 \\\\ \max(\Delta_{t-1} \cdot \eta^-, \Delta_{min}) & \nabla f(\theta_t) \cdot \nabla f(\theta_{t-1}) < 0 \\\\ \Delta_{t-1} & \text{otherwise} \end{cases}</script><p>其中 $\eta^+ &gt; 1 &gt; \eta^-&gt;0$，$\eta^+, \ \eta^-$ 分别用于增大步长和减小步长，并使用 $\Delta_{min}, \ \Delta_{max}$ 来限制步长范围。通常，$\Delta_{min}$ 过小 或者 $\Delta_{max}$ 过大 都不是问题，因为实际的更新步长可以快速调整到合适值。$\alpha$ 通常取 <code>1.2</code>，$\beta$ 取 <code>0.5</code>。$\Delta_0$ 为初始更新步长，作为超参数，事先给定，在 PyTorch 实现中为 <code>0.01</code>。</p><p>在论文 [3] 中，作者具体讨论了四种参数更新方式，<code>Rprop+</code>，<code>Rprop-</code>，<code>iRprop+</code>，<code>iRprop-</code>，上述的参数更新方式对应 <code>Rprop-</code>，其余三种方法可阅读 [3]，这里不再一一具体介绍。[3] 的实验结果表明，<code>iRprop-</code> 的更新方式综合最优，PyTorch 的实现正是采用了 <code>iRprop-</code>。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. John Duchi.</p><p>[2] <a href="https://florian.github.io/rprop/">RProp</a> </p><p>[3] Improving the Rprop Learning Algorithm. Christian Igel.</p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch.optim.SGD</title>
      <link href="/2020/01/02/pytorch/optim_SGD/"/>
      <url>/2020/01/02/pytorch/optim_SGD/</url>
      
        <content type="html"><![CDATA[<h1 id="1-SGD"><a href="#1-SGD" class="headerlink" title="1. SGD"></a>1. SGD</h1><span id="more"></span><h2 id="1-1-weight-decay"><a href="#1-1-weight-decay" class="headerlink" title="1.1 weight decay"></a>1.1 weight decay</h2><p>为了过拟合，通常在损失函数中增加正则项，记原来损失（MSE 或者 CE 等）为 $L_0$，那么添加正则项后的损失为，</p><script type="math/tex; mode=display">L=L_0+\frac 1 2 \lambda \cdot \|\mathbf \theta\|_2^2</script><p>如图 1 所示，<br><img src="/images/pytorch/overfitting.png" alt=""> <center>图 1 过拟合图示（来源《Deep Learning with PyTorch》）</center><br>下半部分展示了过拟合的图，这种曲线的多项式比上图曲线的多项式，其系数 $\mathbf \theta$ 的绝对值更大（曲线的部分段变化更快，说明斜率绝对值更大，也就是 $|\mathbf \theta_i|$ 更大），所以增加正则项作为惩罚，其中 $\lambda$ 作为平衡因子，也称 <code>weight decay</code>。于是，求导时，损失对每个权重参数的梯度多了一项</p><script type="math/tex; mode=display">\frac {\partial L}{\partial \mathbf \theta_i}=\frac {\partial L_0}{\partial \mathbf \theta_i}+\lambda \cdot \mathbf \theta_i</script><h2 id="1-2-momentum"><a href="#1-2-momentum" class="headerlink" title="1.2 momentum"></a>1.2 momentum</h2><p>使用 SGD 训练时，有时候下降比较慢，甚至会陷入导局部最小值中，如图 2 所示，引入 momentum 可以加快收敛速度，我们知道 SGD 的参数更新公式为</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t -\epsilon \cdot d\theta_t</script><p>而使用 momentum 的更新公式为</p><script type="math/tex; mode=display">\begin{aligned} v_{t+1} & = \mu \cdot v_t + d\theta_t\\\\ \theta_{t+1} &= \theta_t - \epsilon \cdot v_{t+1}=\theta_t-\epsilon \cdot \mu \cdot v_t - \epsilon \cdot d\theta_t \end{aligned} \qquad(1)</script><p>其中 $\theta_0$ 为初始权值参数值，$v_0=0$，$\epsilon$ 为学习率，$\mu$ 为 momentum 系数。从上两式中可见，如果当前 velocity（v 值） 与梯度方向一致，那么将会加快权值参数的变化量。在局部最小值附近（见图 2），由于 velocity 累计了之前的梯度，所以有望冲出局部最小值区域。<br><img src="/images/pytorch/momentum.png" alt=""> <center>图 2</center><br>有的地方写成如下形式：</p><script type="math/tex; mode=display">\begin{aligned}v_{t+1}&=\mu \cdot v_t - d\theta_t\\\\\theta_{t+1}&=\theta_t+\epsilon \cdot v_{t+1}=\theta_t +\epsilon \cdot \mu \cdot v_t-\epsilon \cdot d\theta_t \end{aligned}\qquad(2)</script><p>实际上，当 $v_0=0$ 时，这两组更新公式本质相同。</p><p>caffe 框架以及在 Sutskever. [1] 中，更新公式为：</p><script type="math/tex; mode=display">\begin{aligned}v_{t+1}&=\mu \cdot v_t + \epsilon \cdot d\theta_t\\\\ \theta_{t+1}&=\theta_t - v_{t+1}=\theta_t-\mu \cdot v_t-\epsilon \cdot d\theta_t\end{aligned} \qquad(3)</script><p>或者 </p><script type="math/tex; mode=display">\begin{aligned}v_{t+1}&=\mu \cdot v_t - \epsilon \cdot d\theta_t\\\\ \theta_{t+1}&=\theta_t + v_{t+1}=\theta_t+\mu \cdot v_t-\epsilon \cdot d\theta_t\end{aligned} \qquad(3')</script><p>假设学习率 $\epsilon$ 保持不变，那么在 $v_0=0$ 时，(3) 式中的 $v_{t+1}$ 是 (1) 式中的 $\epsilon$ 倍（在其他变量均相同的情况下），</p><script type="math/tex; mode=display">\begin{aligned}v_1^{(3)}&=\epsilon \cdot d\theta_0 = \epsilon \cdot v_1^{(1)}\\\\ v_2^{(3)}& = \mu \cdot v_1^{(3)}+\epsilon \cdot d\theta_1=\epsilon \cdot [\mu \cdot v_1^{(1)}+d\theta_1]=\epsilon \cdot v_2^{(1)}\\\\ &\cdots \end{aligned}</script><p>所以 (1) 式中更新 $\theta_{t+1}$ 时 $v_{t+1}$ 前面添加了系数 $\epsilon$ 后，(1) 和 (3) 也是等价的，但是前提条件是: 1. $v_0=0$；2. 学习率 $\epsilon$ 保持不变。</p><p>随着训练 epoch 增加，学习率可能会衰减，例如衰减为 10%，那么 (1) 和 (3) 会出现不同，我们继续写下迭代计算过程以探究为何会发生不同。记 在 t+1 时刻发生 $\epsilon$ 衰减，衰减前后分别为 $\epsilon_1, \ \epsilon_2$，且 $\epsilon_2 = 0.1 \epsilon_1$，</p><script type="math/tex; mode=display">\begin{aligned}v_t^{(3)} &= \epsilon_1 \cdot v_t^{(1)}\\\\ \theta_{t+1}^{(3)}&=\theta_t- \mu \cdot v_t^{(3)} - \epsilon_2 \cdot d\theta_t=\theta_t- \epsilon_1 \cdot \mu \cdot v_t^{(1)} - \epsilon_2 \cdot d\theta_t\\\\ \theta_{t+1}^{(1)}&=\theta_t-\epsilon_2\cdot \mu \cdot v_t^{(1)} - \epsilon_2 \cdot d\theta_t=\theta_t-0.1\epsilon_1\cdot \mu \cdot v_t^{(1)} - \epsilon_2 \cdot d\theta_t\end{aligned}</script><p>显然，(1) 式的更新方式在学习率衰减时能够有更加明显的体现，参数更新量明显变小，而 (3) 式此时的 velocity 相对较大，参数更新的量没有明显变小。当然随着训练迭代的推进，(3) 式的参数更新量也会逐渐变小，这是因为 velocity 不断更新后，逐渐被较新的 $\epsilon_2 \cdot d\theta$ 主导，而先前累积的 $v_t^{(3)}$ 占比会越来越小，</p><script type="math/tex; mode=display">\begin{aligned} v_{t+n}&=\mu \cdot v_{t+n-1}+\epsilon_2 d\theta_{t+n-1}\\\\ &=\mu^2 \cdot v_{t+n-2}+\mu \cdot \epsilon_2 \cdot d\theta_{t+n-2}+\epsilon_2 \cdot d\theta_{t+n-1}\\\\&=\cdots\\\\&=\mu^n \cdot v_t + \mu^{n-1} \cdot \epsilon_2 \cdot d\theta_{t}+\mu^{n-2} \cdot \epsilon_2 \cdot  d\theta_{t+1} + \cdots + \mu^0 \cdot \epsilon_2 \cdot d\theta_{t+n-1}\end{aligned}</script><p>由于 $\mu &lt;1$，当 $n$ 较大时，上式第一项即 $v_t$ 对 velocity 贡献可以忽略。</p><h3 id="1-2-1-dampening"><a href="#1-2-1-dampening" class="headerlink" title="1.2.1 dampening"></a>1.2.1 dampening</h3><p>阅读 PyTorch 中这部分的<a href="https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71">源码</a>，发现还使用了一个参数 <code>dampening</code>，这个参数指使用 momentum 更新时，对当前梯度的抑制，即 (1) 式中 velocity 更新变为</p><script type="math/tex; mode=display">v_{t+1} = \mu \cdot v_t + \text{dampening} \cdot d\theta_t</script><p>其实很多地方写成 $v_{t+1} = \mu \cdot v_t + (1-\mu) \cdot d\theta_t$，由于 $0 \le \mu &lt; 1$，这表示 $v_{t+1}$ 在 $\min (v_t, d\theta_t)$ 与 $\max (v_t, d\theta_t)$ 之间。不过，实际计算中，<code>dampening</code> 常使用默认值 <code>0</code>。</p><h2 id="1-3-Nesterov"><a href="#1-3-Nesterov" class="headerlink" title="1.3 Nesterov"></a>1.3 Nesterov</h2><p>在 momentum 一节使用式 (1) (3) 进行介绍，其实是为了与 PyTorch <a href="https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71">源码</a> 或者 <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.SGD">文档</a> 对应，但是很多论文或者博客中更常用式 (3’) 的形式（将学习率放入 $v_{t+1}$ 的计算式中），</p><script type="math/tex; mode=display">\theta_{t+1}=\theta_t+v_{t+1}</script><p>这里，$v_{t+1}$ 的定义有很多种，例如经典 momentum，NAG (Nesterov Accelerated Gradient) 等。</p><h3 id="1-3-1-经典-momentum（CE）"><a href="#1-3-1-经典-momentum（CE）" class="headerlink" title="1.3.1 经典 momentum（CE）"></a>1.3.1 经典 momentum（CE）</h3><p>我们重写一遍经典 momentum 的参数更新公式（式 2），</p><script type="math/tex; mode=display">\begin{aligned}v_{t+1}&=\mu \cdot v_t - \epsilon \cdot \nabla f(\theta_t)\\\\ \theta_{t+1}&=\theta_t + \mu \cdot v_t - \epsilon \cdot \nabla f(\theta_t)\end{aligned}</script><h3 id="1-3-2-NAG"><a href="#1-3-2-NAG" class="headerlink" title="1.3.2 NAG"></a>1.3.2 NAG</h3><p>NAG 一次迭代过程分为两步：</p><ol><li><p>梯度下降步骤</p><script type="math/tex; mode=display">\theta_{t+1} = y_t - \epsilon_t \cdot \nabla f(y_t) \qquad(4)</script></li><li><p>momentum</p><script type="math/tex; mode=display">y_{t+1}=\theta_{t+1} + \mu_{t+1} \cdot (\theta_{t+1}-\theta_t) \qquad(5)</script></li></ol><p>初始时令 $y_0=\theta_0$，即这两个变量起点相同。</p><p>NAG 中我们对 $y$ 做梯度下降，得到的值为 $\theta$ 的新值，而非 $y$ 新值，$y$ 的新值是在 $\theta$ 的基础之上再增加 $\mu_{t+1} \cdot (\theta_{t+1}-\theta_t)$ 这么多的更新量。如图 3，<br><img src="/images/pytorch/NAG_0.png" alt=""> <center>图 3. NAG 过程示意图</center><br>如果 $\mu \equiv 0$，NAG 就是普通的梯度下降 SD。</p><p>注意，这里将 $\mu, \ \epsilon$ 系数带上时刻下标。下面我们推导 velocity 的迭代计算式。</p><h3 id="1-3-3-Sutskever-Nesterov-Momentum"><a href="#1-3-3-Sutskever-Nesterov-Momentum" class="headerlink" title="1.3.3 Sutskever Nesterov Momentum"></a>1.3.3 Sutskever Nesterov Momentum</h3><p>NAG 中参数 $\theta$ 的更新在梯度下降之后，在 momentum 之前。现在我们根据 NAG 推导出 velocity 项。首先要说明的是，需要将 NAG 迭代过程的两个步骤顺序对换，即 <code>momentum-GD-momentum-GD-...</code> 的顺序。</p><p>已知，</p><script type="math/tex; mode=display">y_t=\theta_t+\mu_t \cdot(\theta_t-\theta_{t-1})</script><p>写成以下形式，</p><script type="math/tex; mode=display">y_t=\theta_t + \mu_t \cdot v_t</script><p>可根据 (4) 式消去 $y_t$，需要注意的是，(4) 式表示 t 时刻迭代过程中的梯度下降步骤，到 Sutskever Nesterov Momentum 中则为 t-1 时刻迭代中的 momentum 步骤，即 $\theta_{t+1} = y_t - \epsilon_t \cdot \nabla f(y_t)$，与上式联合可消去 $y_t$， 得</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t+\mu_t \cdot v_t-\epsilon_t \cdot \nabla f(\theta_t + \mu_t \cdot v_t) \qquad(6)</script><p>于是，</p><script type="math/tex; mode=display">v_{t+1} = \mu_t \cdot v_t - \epsilon_t \cdot \nabla f(\theta_t+\mu_t \cdot v_t)  \qquad(7)</script><p>图 4 是经典 momentum 与 NAG 方法的图示比较。<br><img src="/images/pytorch/NAG.png" alt=""> <center>图 4 </center></p><h3 id="1-3-4-Bengio-Nesterov-Momentum"><a href="#1-3-4-Bengio-Nesterov-Momentum" class="headerlink" title="1.3.4 Bengio Nesterov Momentum"></a>1.3.4 Bengio Nesterov Momentum</h3><p>NAG 中我们的模型参数是 $\theta$，但是其更新不是对自身做梯度下降，而是对 $y$ 做梯度下降，进一步地，$y$ 的更新则又反过来依赖于 $\theta$ 的 momentum。</p><p>定义一个新变量，表示经过 momentum 更新后的 $\theta$ 值，或者更准确地讲，是 momentum 更新后的模型参数的值。</p><script type="math/tex; mode=display">\Theta_{t-1}=\theta_{t-1} + \mu_{t-1} \cdot v_{t-1}</script><p>这里可能感觉有点绕，一会 $\theta$，一会 $\Theta$，到底哪个是表示模型参数。我是这么理解的，初始时模型参数为 $\theta_0$，此后更新迭代过程中，$\Theta$ 才表示模型参数，$\theta$ 只作为中间变量。</p><p>根据 velocity 的定义 (7) 式，有</p><script type="math/tex; mode=display">v_t=\mu_{t-1} \cdot v_{t-1} - \epsilon_{t-1} \cdot \nabla f(\Theta_{t-1})</script><p>$v_t$ 依然是 $\theta$ “中间”变量的更新量。</p><p>根据 $\Theta$ 定义，</p><script type="math/tex; mode=display">\Theta_{t+1}-\mu_{t+1} \cdot v_{t+1}= \theta_{t+1}</script><script type="math/tex; mode=display">\Theta_t-\mu_t \cdot v_t= \theta_t</script><p>以及 (6) 式，有</p><script type="math/tex; mode=display">\Theta_{t+1}-\mu_{t+1} \cdot v_{t+1}=\Theta_t-\mu_t \cdot v_t+\mu_t \cdot v_t - \epsilon_t \cdot \nabla f(\Theta_t)</script><p>化简得，</p><script type="math/tex; mode=display">\Theta_{t+1}=\Theta_t+\mu_{t+1} \cdot v_{t+1}-\epsilon_t \cdot \nabla f(\Theta_t)</script><p>继续代入 (7) 式，有</p><script type="math/tex; mode=display">\Theta_{t+1}=\Theta_t+\mu_{t+1} \cdot[\mu_t \cdot v_t - \epsilon_t \cdot \nabla f(\Theta_t)]-\epsilon_t \cdot \nabla f(\Theta_t)</script><p>展开得，</p><script type="math/tex; mode=display">\Theta_{t+1}=\Theta_t+\mu_{t+1} \cdot \mu_t \cdot v_t-\mu_{t+1} \cdot \epsilon_t \cdot \nabla f(\Theta_t)-\epsilon_t \cdot \nabla f(\Theta_t) \qquad(8)</script><p>写成 $\Theta_{t+1}=\Theta_t + V_{t+1}$ 的形式，于是</p><script type="math/tex; mode=display">V_{t+1}=\mu_{t+1} \cdot \mu_t \cdot v_t-\mu_{t+1} \cdot \epsilon_t \cdot \nabla f(\Theta_t)-\epsilon_t \cdot \nabla f(\Theta_t)</script><p> 就是 $\Theta$ 的更新量，等价于 <code>(3&#39;)</code> 式中的 $v_{t+1}$，对应到 (1) 式中的 $v_{t+1}$ 的形式，去掉 $\epsilon$，以及 $-$ 变成 $+$，易得， </p><script type="math/tex; mode=display">\begin{aligned} V_{t+1}&=\mu_{t+1} \cdot \mu_t \cdot v_t+\mu_{t+1} \cdot \nabla f(\Theta_t)+ \nabla f(\Theta_t) \\\\ &=\mu_{t+1} \cdot [\mu_t \cdot v_t+ \nabla f(\Theta_t)] + \nabla f(\Theta_t)  \end{aligned} \qquad(9)</script><p>此时 $\Theta$ 的更新为</p><script type="math/tex; mode=display">\Theta_{t+1}=\Theta_t - \epsilon_t \cdot V_{t+1} \qquad(10)</script><p><strong>(9) 和 (10) 式就对应 PyTorch 源码中 <code>SGD.step</code> 在 <code>nesterov=True</code> 时的计算过程。</strong></p><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>[1] On the importance of initialization and momentum in deep learning. Ilya Sutskever</p><p>[2] <a href="https://jlmelville.github.io/mize/mesterov.html">Nesterov Accelerated Gradient and Momentum</a></p><h1 id="更多阅读"><a href="#更多阅读" class="headerlink" title="更多阅读"></a>更多阅读</h1><p>[1] <a href="https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/">ORF523: Nesterov’s Accelerated Gradient Descent</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DenseNet</title>
      <link href="/2019/12/31/img_cls/densenet/"/>
      <url>/2019/12/31/img_cls/densenet/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a></p><p>随着现在数据集越来越大，网络容量也需要增大，否则容易出现过拟合现象，一种增大网络容量的方法是增加更多的 layer ，让网络更深（deep），但是这也会带来新的问题：随着输入（或梯度）经过越来越多的 layer，信息可能在到达最后一层（对于梯度则是反向传播在到达网络第一层）之前就消失了。ResNet 增加 shortcut，即 early layer 到 later layer 之间直接连接，以此来解决这个问题。本文提出 densenet，将这种连接风格贯彻到底，网络结构如图1，<br><span id="more"></span></p><p><img src="/images/img_cls/densenet_1.png" alt=""></p><h2 id="DenseNet-数学描述"><a href="#DenseNet-数学描述" class="headerlink" title="DenseNet 数学描述"></a>DenseNet 数学描述</h2><p>假设输入为 $\mathbf x_0$，网络共有 $L$ 层，每层非线性转换操作记为 $H_l(\cdot)$，输出记为 $\mathbf x_l$。</p><h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>传统的网络，第 $l$ 层操作为 $\mathbf x_l = H_l(\mathbf x_{l-1})$ ResNet 增加一个 Identity 分支后为 $\mathbf x_l = H_l(\mathbf x_{l-1})+\mathbf x_{l-1}$，ResNet 中一个 layer 其实是一个 block，不是单层 layer，block 内部的 layer 没有 shortcut 分支，这点需要注意。</p><h3 id="Dense-连接"><a href="#Dense-连接" class="headerlink" title="Dense 连接"></a>Dense 连接</h3><p>从某个 layer 到所有后继 layer 之间增加直接连接，对于第 $l$ 层 layer 来说，其输入是所有前序 layer 的输出以及原始网络输入，所以有</p><script type="math/tex; mode=display">\mathbf x_l=H_l([\mathbf x_0, ... , \mathbf x_{l-1}])</script><p>其中 $[\mathbf x_0, … , \mathbf x_{l-1}]$ 表示 <code>concatenate</code> 操作，这与 ResNet 的 <code>sum</code> 操作不同。</p><h3 id="组合函数"><a href="#组合函数" class="headerlink" title="组合函数"></a>组合函数</h3><p>DenseNet 中每个 layer 的操作 $H_l(\cdot)$ 是由：</p><ol><li>批规范化 BN；</li><li>ReLU；</li><li><code>3x3</code> conv</li></ol><p>组合而得。</p><h3 id="Pooling-层"><a href="#Pooling-层" class="headerlink" title="Pooling 层"></a>Pooling 层</h3><p>网络肯定存在下采样，这就导致 early layer 与 later layer 可能有不同的 feature maps 大小，这就导致没法直接连接。一种解决的办法如图 2，将若干个 layer 分为一组作为一个 block，称为 Dense Block，block 内部的 feature maps 大小保持不变，从而 block 内部的 layer 之间可以进行密集连接，block 之间使用过渡层进行下采样，在作者实验中过渡层包含 BN 层、<code>1x1</code> 卷积层以及 <code>2x2</code> 均值池化层。<br><img src="/images/img_cls/densenet_2.png" alt=""></p><h3 id="Growth-rate"><a href="#Growth-rate" class="headerlink" title="Growth rate"></a>Growth rate</h3><p>记 $k_0$ 为 Dense Block 初始输入的 channels，如果每个 $H_l$ 输出均为 $k$ 个 feature maps，由于 $l^{th}$ layer 的输入为初始网络输入 $\mathbf x_0$ 以及前 $l-1$ 个 layer 输出的 concatenation，所以共有 $k_0+k(l-1)$ 个 feature maps，所以 $k$ 值即使较小，随着 $l^{th}$ 增大，深层 layer 的 <code>in_channels</code> 也可以很大，因为可以使用较小 $k$ 值，这就使得 DenseNet 与传统网络相比，拥有更少的网络参数。记 $k$ 为 _growth rate_ ，表示 layer 输入 feature maps 增长量。作者实验表明，即使非常小的 _growth rate_ 也可以获取很好的测试结果。作者解释为，每个 layer 可以利用同 block 内的前面所有 layer 的输出 feature maps，也就是 “collective knowledge”，将 feature maps 看作网络的 global state，每个 layer 贡献自己的 k 个 feature maps 到这个 global state，同时 _growth rate_ 控制了每个 layer 对 global state 的贡献量，并且每次某个 layer 对 global state 贡献完毕，此时的 global state 可以被之后所有 layer 利用。传统网络为了在 layer 到 layer 之间传递这种 global state，不得不使用越来越多的输出通道数，达到复制前面各阶段的 global states 的效果。</p><h3 id="Bottleneck-layers"><a href="#Bottleneck-layers" class="headerlink" title="Bottleneck layers"></a>Bottleneck layers</h3><p>later layer 的输入通道数较大，可以在这些 layer（通常是 <code>3x3</code> 卷积） 前面增加一个 <code>1x1</code> 卷积作为 bottleneck layer，降低 later layer 的输入通道数，提高计算效率。记这种带有 bottleneck layer 的 DenseNet 为 DenseNet-B，其中 layer 的操作 $H_l(\cdot)$ 变为 BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)（参考前面 <strong>组合函数</strong> 小节）。</p><h3 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h3><p>为了进一步压缩模型，可以在过渡层降低 feature maps 的数量，记 dense block 的输出 feature maps 数量为 $m$，注意是 dense block 初始输入和各 layer 输出的叠加，参见图 1，过渡层输出 feature maps 数量为 $\lfloor \theta m \rfloor$，其中 $0 &lt; \theta \le 1$，当 $\theta=1$，过渡层不改变 feature maps 的数量，当 $\theta &lt;1$ 记这样的 DenseNet 为 DenseNet-C，而 DenseNet-BC 则表示既有 bottleneck layer 又有 $\theta &lt;1$ 的 DenseNet。</p><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>作者在 CIFAR-10,CIFAR-100,SVHN 以及 ImageNet 四个数据集上评估了 DenseNet。</p><p>在前三个数据集上（这三个数据集的图像 size 均为 <code>32x32</code>），DenseNet 使用了 3 个 dense block，每个 dense block 有相等数量的 layer。在进入第一个 dense block 之前，输入图像数据先经过了一个 <code>1x1</code> 16-out_channels 的卷积层（对于 DenseNet-BC 网络，输出通道数为 _growth rate_ 的两倍）。对于 <code>3x3</code> conv，进行 padding=1 的 zero 填充，以保持 feature map size 不变。在最后一个 dense block 之后，进行全局均值池化以及 softmax 操作。三个 dense block 的 feature maps 大小分别为 <code>32x32, 16x16, 8x8</code>。使用最普通的 DenseNet（不带 B\C 后缀）进行实验时，dense block 配置分别为 $\{L=40,k=12\}$, $\{L=100,k=12\}$ 和 $\{L=100,k=24\}$，使用 DenseNet-BC 进行实验时，配置分别为 $\{L=100,k=12\}$, $\{L=250,k=24\}$ 和 $\{L=190,k=40\}$。</p><p>对于 ImageNet，使用 4 个 dense block 的 DenseNet-BC，输入图像大小为 <code>224x224</code>，初始 layer 为一个 <code>7x7</code> 2k-out_channels，stride=2 的卷积，其中 k 表示 _growth-rate_ ，所有 dense block 均为 $k=32$，网络具体描述如表 1 所示，<br><img src="/images/img_cls/densenet_3.png" alt=""> <center>ImageNet 对应的四个 DenseNet-BC 网络配置。所有网络的 k=32，表中所有 conv 均表示 __BN-ReLU-Conv__ </center></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验结果的对比可直接参考原论文。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><strong>CIFAR：</strong>  CIFAR-10 和 CIFAR-100 数据集包含 <code>32x32</code> 大小的彩色图像，其中 CIFAR-10 的图像分类数量为 10，CIFAR-100 图像分类数量为 100。训练集和测试集大小分别为 50000 和 10000，训练集中取 5000 作为验证集。数据扩增使用 镜像/平移 两种方法。预处理包括 RGB 三通道分别使用 <code>mean</code> 和 <code>std</code> 归一化。最后一轮训练时使用全部 50000 个图像，然后计算测试错误。</p><p><strong>SVHN：</strong>  SVHN 数据集包含 <code>32x32</code> 大小的彩色数字图像，训练集和测试集大小分别为 73257 和 26032，另有 531131 个图像作为额外的训练数据。作者实验中，不采用任何数据扩增手段，从训练集中取 6000 个图像作为验证集。选择具有最低验证错误的训练结果，然后计算测试错误。图像像素值除以 255 以落于 <code>[0,1]</code> 范围作为归一化处理方法。</p><p><strong>ImageNet：</strong>  使用 ILSVRC 2012 分类数据集，包含 120 万训练集以及 5 万的验证集，分类总数为 1000。使用与 ResNet 中相同的数据扩增方法，采用 single-crop 或者 10-crop 方法得到 <code>224x224</code> 的输入大小，最后计算验证集上的错误率。</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>CIFAR 和 SVHN 训练 batch 大小为 64，epoch 分别为 300 和 40。初始学习率 lr = 0.1，在 50% 和 75% 的 epoch 时分别再降为 10%。</p><p>ImageNet 训练 batch 大小为 256， epoch 为 90。初始学习率 lr=0.1，在 epoch = 30 和 epoch = 60 时分别降为 10%。</p><p>权重衰减因子为 $10^{-4}$，Nesterov momentum 为 0.9。</p><p>由于本文着重记录 DenseNet 的网络结构，所以实验结果数据的分析以及与其他网络的比较此处省略，可参考原文进行反复阅读理解。</p><h2 id="DenseNet-特点："><a href="#DenseNet-特点：" class="headerlink" title="DenseNet 特点："></a>DenseNet 特点：</h2><ol><li>dense block 内每两个 layer 之间均存在直接连接。</li><li>直接连接与普通前向传播的合并采用 <code>concatenate</code> 方式，而 ResNet 中则是 <code>sum</code> 方式。</li><li>比传统网络有更少的参数。layer 之间的连接更加密集，所以 layer 只需要很小的 filter 数量。</li><li>易于训练。这得益于 DenseNet 更优的信息流（梯度流）传递。early layer 可以直接利用到损失函数对原始输入的梯度，这种深度监督有益于训练。</li><li>layer 之间的密集直接连接有正则化效果，在小训练集上有助于降低过拟合。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> image classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Programming (3)</title>
      <link href="/2019/12/20/dp/DP4/"/>
      <url>/2019/12/20/dp/DP4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-库存问题"><a href="#1-库存问题" class="headerlink" title="1. 库存问题"></a>1. 库存问题</h2><p>一产品可通过生产或者购买获得，获得产品需要一定的成本，然后产品随着时间也会逐步被消耗掉。产品的库存也伴随着存储成本，而当需求未得到满足（供应不足，某个阶段库存为负表示消耗需求未得到满足）时也有一个惩罚损失。</p><span id="more"></span><p>使用 N-阶 序列决策过程来表述以上库存问题，在阶段 <code>k</code> 作出决策获得 <code>x</code> 单位的产品，损耗为 $C(k,x)$，状态为 $(k,s)$，表示在阶段 <code>k</code> 的库存数量为 <code>s</code>。$D(k)$ 表示在阶段 <code>k</code> 对产品的消耗需求，于是下一阶段状态为 $(k+1,s+x-D(k))$，这一状态转移过程的损耗包括获得产品的成本 $C(k,x)$，以及库存存储成本 $I(k,s,x), \ s&gt;0$，如果库存数量为负表示此阶段的消耗需求未得到满足，此时 $|s|$ 表示缺货的数量，所以惩罚损耗为 $I(k,s,x), \ s &lt; 0$，</p>]]></content>
      
      
      
        <tags>
            
            <tag> math </tag>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数字图像处理（二）</title>
      <link href="/2019/12/07/dip/DIP-2/"/>
      <url>/2019/12/07/dip/DIP-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考教材《数字图像处理》(Gonzalez)</p></blockquote><h1 id="1-空间滤波"><a href="#1-空间滤波" class="headerlink" title="1. 空间滤波"></a>1. 空间滤波</h1><p>使用空间滤波器（也称空间掩模，核，窗口）直接作用于图像，得到当前位置的像素值，通过平移得到其他位置的像素值。熟悉深度学习中的卷积操作的话，不难理解这个概念。<br><span id="more"></span></p><h2 id="1-1-平滑空间滤波"><a href="#1-1-平滑空间滤波" class="headerlink" title="1.1 平滑空间滤波"></a>1.1 平滑空间滤波</h2><p>用于模糊和降噪（通常是模糊后再阈值过滤）。例如以下线性滤波器，</p><ol><li>均值滤波</li><li>加权均值滤波</li></ol><p>又或者统计排序等非线性滤波器，</p><ol><li><p>中值滤波</p><p>中值就是统计里面的排序后位于中间的值。中值滤波提供降噪的同时，对图像的模糊程度要低</p></li></ol><h2 id="1-2-锐化空间滤波"><a href="#1-2-锐化空间滤波" class="headerlink" title="1.2 锐化空间滤波"></a>1.2 锐化空间滤波</h2><p>前面平滑处理使用求和平均，求和可看作积分，锐化操作则相反，通过空间微分实现，目的是突出灰度过渡部分。<br>对于一维函数 $f(x)$，一阶微分为</p><script type="math/tex; mode=display">\frac {\partial f} {\partial x} = f(x+1) - f(x)</script><p>二维函数 $f(x,y)$ 类似，分别沿两个轴微分。二阶微分为，</p><script type="math/tex; mode=display">\frac {\partial^2 f} {\partial x^2} = f'(x) - f'(x-1) = f(x+1) + f(x-1) - 2f(x)</script><p>以下为一些图像锐化增强的方法。</p><h3 id="1-2-1-拉普拉斯算子"><a href="#1-2-1-拉普拉斯算子" class="headerlink" title="1.2.1 拉普拉斯算子"></a>1.2.1 拉普拉斯算子</h3><script type="math/tex; mode=display">\nabla^2 f = \frac {\partial^2 f} {\partial x^2} + \frac {\partial^2 f} {\partial y^2}</script><p>又</p><script type="math/tex; mode=display">\frac {\partial^2 f} {\partial x^2} = f(x+1,y)+f(x-1,y) - 2f(x,y)\\\\ \frac {\partial^2 f} {\partial y^2} = f(x,y+1)+f(x,y-1) - 2f(x,y)</script><p>故</p><script type="math/tex; mode=display">\nabla^2 f = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)</script><p>还可以增加对角线方向的微分项，$f(x \pm 1,y \pm 1)$，以及 4 个 $-f(x,y)$，</p><p>当然，以上我们还可以将微分乘以 -1，这表示微分的方向反过来，但是其增强效果是跟上面等效的。</p><p>通常拉普拉斯算子增强得到将边线和突变点叠加到暗色背景中的图像，所以在叠加原图像，可以恢复背景并保持拉普拉斯锐化结果，如下：</p><script type="math/tex; mode=display">g(x,y)=f(x,y)+c\left[ \nabla^2 f(x,y) \right]</script><p>使用拉普拉斯算子后的图像可能存在负的像素值，此时可将负值转换为 0，超过 255 的值转换为 255（假设为 8 bit 灰度），但是这种处理方法显然过于草率，一种更好的方法是，记拉普拉斯图像为 <code>f</code>，然后</p><script type="math/tex; mode=display">f_m = f-\min(f)\\\\ f_s=(L-1)[f_m/\max(f_m)]</script><p>如此就能保证像素值位于 $[0,L-1]$ 之间。如果叠加原图像，则可能不需要做如此标定。</p><h3 id="1-2-2-非锐化掩蔽和高提升滤波"><a href="#1-2-2-非锐化掩蔽和高提升滤波" class="headerlink" title="1.2.2 非锐化掩蔽和高提升滤波"></a>1.2.2 非锐化掩蔽和高提升滤波</h3><p>操作步骤：</p><ol><li>模糊原图像</li><li>原图像减模糊图像（差为模板）</li><li>将模板加到原图像上</li></ol><script type="math/tex; mode=display">g_{mask}(x,y) = f(x,y) - \overline f(x,y)\\\\ g(x,y)=f(x,y) + k \cdot g_{mask}(x,y)</script><h3 id="1-2-3-梯度"><a href="#1-2-3-梯度" class="headerlink" title="1.2.3 梯度"></a>1.2.3 梯度</h3><p>二维图像 $f(x,y)$ 的梯度为</p><script type="math/tex; mode=display">\nabla f =\begin{bmatrix} g_x \\\\ g_y \end{bmatrix}= \begin{bmatrix} \frac {\partial f} {\partial x} \\\\ \frac {\partial f} {\partial x} \end{bmatrix}</script><p>这是一个二维列向量，幅值为</p><script type="math/tex; mode=display">M(x,y) = \sqrt {g_x^2 + g_y^2}</script><p>此为梯度图像，与原图像大小相同。有时候使用绝对值来近似，</p><script type="math/tex; mode=display">M(x,y)=|g_x|+|g_y|</script><p>将此滤波写成 $3 \times 3$ 的滤波模板，记一个 $3 \times 3$ 邻域像素值为，</p><script type="math/tex; mode=display">\mathbf z=\begin{bmatrix} z_1 & z_2 & z_3 \\ z_4 & z_5 & z_6 \\z_7 & z_8 & z_9 \end{bmatrix}</script><p>中心为 $z_5$，一阶微分为</p><script type="math/tex; mode=display">g_x=z_8-z_5, \quad g_y = z_6-z_5</script><p>早期的数字图像处理中， Roberts 提出使用交叉差分，</p><script type="math/tex; mode=display">g_x=z_9- z_5, \quad g_y = z_8-z_6</script><p>以上 <code>x,y</code> 方向哪个水平哪个垂直，在计算梯度幅值时其实是无所谓的，因为滤波模板在旋转 90° 整数倍时是各向同性的。</p><p><strong>sobel 算子</strong></p><p>$\mathbf w_x=\begin{bmatrix} -1 &amp; -2 &amp; -1 \\ 0 &amp; 0 &amp; 0 \\ 1 &amp; 2 &amp; 1 \end{bmatrix}$,  $\mathbf w_y=\begin{bmatrix} -1 &amp; 0 &amp; 1 \\ -2 &amp; 0 &amp; 2 \\ -1 &amp; 0 &amp; 1 \end{bmatrix}$</p><p>于是，</p><p><del><script type="math/tex">g_x = \mathbf w_x \ast \mathbf z, \qquad g_x = \mathbf w_x \ast \mathbf z</script></del></p><script type="math/tex; mode=display">g_x = \mathbf w_x \odot \mathbf z, \qquad g_x = \mathbf w_x \odot \mathbf z</script><p>sobel 算子常用于边缘检测。</p><h2 id="1-3-混合空间增强"><a href="#1-3-混合空间增强" class="headerlink" title="1.3 混合空间增强"></a>1.3 混合空间增强</h2><p>使用前述多种增加方法</p><h2 id="1-4-基于模糊技术的灰度变换"><a href="#1-4-基于模糊技术的灰度变换" class="headerlink" title="1.4 基于模糊技术的灰度变换"></a>1.4 基于模糊技术的灰度变换</h2><p>模糊集合是一个由 <code>z</code> 值和相应隶属度函数组成的序对，</p><script type="math/tex; mode=display">A = \{z, \mu_A(z)|z \in Z, \ \mu_A(z) \in (0,1]\}</script><p>其中 $Z$ 为元素 <code>z</code> 的取值空间，隶属度函数的值域为 $[0,1]$。</p><p><strong>空集：</strong> $\mu_A(z) = 0$</p><p><strong>相等：</strong> $\mu_A(z) = \mu_B(z), \ \forall z$</p><p><strong>补集：</strong> $\mu_{\overline A}(z) = 1- \mu_A(z)$</p><p><strong>子集：</strong> $\mu_A(z) \le \mu_B(z) \Rightarrow A \subseteq B$</p><p><strong>并集：</strong> $\mu_U(z)=\max [\mu_A(z), \mu_B(z)]$</p><p><strong>交集：</strong> $\mu_I(z) = \min [\mu_A(z), \mu_B(z)]$</p>]]></content>
      
      
      
        <tags>
            
            <tag> DIP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数字图像处理（一）</title>
      <link href="/2019/12/05/dip/DIP-1/"/>
      <url>/2019/12/05/dip/DIP-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>根据教材《数字图像处理》(Gonzalez)</p><h1 id="1-坐标变换"><a href="#1-坐标变换" class="headerlink" title="1. 坐标变换"></a>1. 坐标变换</h1><h2 id="1-1-仿射变换"><a href="#1-1-仿射变换" class="headerlink" title="1.1 仿射变换"></a>1.1 仿射变换</h2><p>特点：</p><ol><li>平直性：原图中的直线段在仿射变换后的图像中依然是直线段。</li><li>平行性：原图中平行的两个线段在仿射变换后的图中依然是平行的<span id="more"></span>   一般形式：<script type="math/tex; mode=display">(x,y)=\mathbf T[(v,w)]</script>其中 $(v,w)$ 是原图中的某点坐标，$(x,y)$ 是变换后图像中对应点的坐标<script type="math/tex; mode=display">\begin{bmatrix}x & y & 1 \end{bmatrix}=\begin{bmatrix}v & w & 1 \end{bmatrix}\mathbf T=\begin{bmatrix}v & w & 1 \end{bmatrix}\begin{bmatrix}t_{11} & t_{12} & 0 \\ t_{21} & t_{22} & 0 \\ t_{31} & t_{32} & 1\end{bmatrix}</script></li></ol></blockquote><script type="math/tex; mode=display">\begin{cases}x=t_{11} v + t_{21} w + t_{31} \\y=t_{12} v + t_{22} w + t_{32} \end{cases} \qquad(1)</script><p>反向映射：</p><script type="math/tex; mode=display">(v,w)=\mathbf T^{-1} [(x,y)]</script><h3 id="1-1-1-恒等变换"><a href="#1-1-1-恒等变换" class="headerlink" title="1.1.1 恒等变换"></a>1.1.1 恒等变换</h3><script type="math/tex; mode=display">\mathbf T = \begin{bmatrix} 1 & 0 & 0 \\ 0& 1&0 \\ 0&0&1\end{bmatrix}</script><h3 id="1-1-2-尺度变换"><a href="#1-1-2-尺度变换" class="headerlink" title="1.1.2 尺度变换"></a>1.1.2 尺度变换</h3><script type="math/tex; mode=display">\mathbf T = \begin{bmatrix} c_x & 0 & 0 \\ 0& c_y&0 \\ 0&0&1\end{bmatrix}</script><p>x 方向变为原来的 $c_x$ 倍，y 方向变为原来的 $c_y$ 倍。</p><h3 id="1-1-3-旋转变换"><a href="#1-1-3-旋转变换" class="headerlink" title="1.1.3 旋转变换"></a>1.1.3 旋转变换</h3><script type="math/tex; mode=display">\mathbf T = \begin{bmatrix} cos \theta & sin \theta & 0 \\ -sin \theta& cos \theta&0 \\ 0&0&1\end{bmatrix}</script><p>其中 $\theta$ 为（图像绕左上角顶点）顺时针旋转角度。</p><h3 id="1-1-4-平移变换"><a href="#1-1-4-平移变换" class="headerlink" title="1.1.4 平移变换"></a>1.1.4 平移变换</h3><script type="math/tex; mode=display">\mathbf T = \begin{bmatrix} 1 & 0 & 0 \\ 0& 1&0 \\ t_x&t_y&1\end{bmatrix}</script><h3 id="1-1-5-偏移变换"><a href="#1-1-5-偏移变换" class="headerlink" title="1.1.5 偏移变换"></a>1.1.5 偏移变换</h3><p>又称错切（shear）变换，分水平错切和垂直错切两种情况。水平错切：将每一点水平移动，移动长度和该点的纵坐标成比例，</p><script type="math/tex; mode=display">(v,w) \rightarrow (v+mw,w)</script><p>$m&gt;0$ 时向右移动，$m&lt;0$ 时向左移动。<br>类似地可以得到垂直方向变换为，</p><script type="math/tex; mode=display">(v,w) \rightarrow (v, vn+w)</script><p>于是错切变换矩阵为</p><script type="math/tex; mode=display">\mathbf T=\begin{bmatrix} 1 & n & 0 \\ m & 1 & 0 \\ 0 & 0 & 1\end{bmatrix}</script><h2 id="1-2-透视变换"><a href="#1-2-透视变换" class="headerlink" title="1.2 透视变换"></a>1.2 透视变换</h2><p>透视变换是二维 $(x,y)$ 到三维 $(x,y,z)$，然后再到二维 $(x’,y’)$ 的映射，所以也称为投影变换。</p><p>事实上，二维可看作三维上的一个平面 $(x,y,1)$，前面的仿射变换则是将这个平面上的点 $(x,y,1)$ 经过 $3 \times 3$ 变换矩阵后依然位于这个平面内 $(x’,y’,1)$，而透视变换则是先变换到三维空间任意点上，然后从三维空间在变换到 $(x’,y’,1)$，故不难想象变换矩阵具有如下形式，</p><script type="math/tex; mode=display">[x,y,1]=[v,w,1]T=[v,w,1]\begin{bmatrix} t_{11} & t_{12} & t_{13} \\t_{21} & t_{22} & t_{23} \\t_{31} & t_{32} & t_{33} \end{bmatrix}</script><p>其中 $t_{13}v+t_{23}w+t_{33}=1$。从变换矩阵也可以看出，仿射变换是一种特殊的透视变换。</p><p>正如下一节将要讲到的，需要知道输入图像和输出图像中分别 4 个约束点，才能确定透视变换的矩阵参数，这是因为 4 个约束点提供 8 个方程，加上自身的约束方程，共 9 个方程从而解出 9 个参数，可参考 opencv 的 python 教程中关于<a href="https://docs.opencv.org/4.1.2/da/d6e/tutorial_py_geometric_transformations.html">透视变换的例子</a>。</p><h1 id="2-图像配准"><a href="#2-图像配准" class="headerlink" title="2. 图像配准"></a>2. 图像配准</h1><p>有时候知道输入图像和经过某种变换后的输出图像，要求变换函数，这就是图像配准。主要方法是使用约束点（控制点），根据输入图像和输出图像上的一组 n 个约束点来估计变换函数，例如已知是仿射变换，那么只需要一组 3 个约束点（6个方程解6个参数），根据式 $(1)$ 即可求出参数；如果变换函数模型是双线性模型，那么有</p><script type="math/tex; mode=display">x=c_1v+ c_2w+c_3vw + c_4 \\ y=c_5v+c_6w+c_7vw+c_8</script><p>即，需要 4 个约束点得到变换函数参数。</p><p>还有其他更加复杂的策略，略。</p><h1 id="3-图像内插"><a href="#3-图像内插" class="headerlink" title="3. 图像内插"></a>3. 图像内插</h1><p>假设要求变换后图像中 $(x,y)$ 的像素值，根据反向映射得到原图对应点位置为 $(i+u,j+v)$（整数+小数的形式），$0\le u,v &lt; 1$</p><h2 id="3-1-最近邻内插"><a href="#3-1-最近邻内插" class="headerlink" title="3.1 最近邻内插"></a>3.1 最近邻内插</h2><p>对 $u,v$ 分别采用四舍五入，得到原来图像对应像素位置 $(\lfloor i+u+\frac 1 2\rfloor,\lfloor j+v+\frac 1 2 \rfloor)$</p><h2 id="3-2-双线性内插"><a href="#3-2-双线性内插" class="headerlink" title="3.2 双线性内插"></a>3.2 双线性内插</h2><p>使用 4 个最近邻即 $(i,j), (i+1,j),(i,j+1),(i+1,j+1)$ 根据下式进行确定，</p><script type="math/tex; mode=display">f(i+u,j+v)=(1-u)(1-v)f(i,j)+(1-u)v f(i,j+1)+u(1-v)f(i+1,j)+uvf(i+1,j+1)</script><h2 id="3-2-双三次内插"><a href="#3-2-双三次内插" class="headerlink" title="3.2 双三次内插"></a>3.2 双三次内插</h2><p>使用 16 个最近邻点，一种确定权重因子的方法是使用 BiCubic 函数，</p><script type="math/tex; mode=display">W(x)=\begin{cases} (a+2)|x|^3 - (a+3)|x|^2+1 & |x| \le 1 \\ a|x|^3-5a|x|^2+8a|x|-4a & 1 <|x|<2 \\ 0 & \text{otherwise} \end{cases}</script><p>其中， $x$ 是水平（垂直）方向上的距离，a 通常取 $a=-0.5$。</p><p>为了表示方便，坐标使用 $(x,y)$ 而非前面的 $(i,j)$ 表示。图像上目标点 $(x,y)$ 的 $4\times4$ 邻域的点 $(x_i,y_j), \ i,j=0,1,2,3$，按下式进行双三次插值，</p><script type="math/tex; mode=display">f(x,y)=\sum_{i=0}^3\sum_{j=0}^3 f(x_i,y_j) W(x-x_i) W(y-y_j)</script><h1 id="4-灰度变换"><a href="#4-灰度变换" class="headerlink" title="4. 灰度变换"></a>4. 灰度变换</h1><p>这里仅讨论部分灰度变换的方法。</p><h2 id="4-1-直方图均衡"><a href="#4-1-直方图均衡" class="headerlink" title="4.1 直方图均衡"></a>4.1 直方图均衡</h2><p>假设灰度范围为 $[0,L-1]$，变换形式为</p><script type="math/tex; mode=display">s=T(r)</script><p>表示将灰度 <code>r</code> 变换为 <code>s</code>。<br>这里假定变换函数单调增（若非特别说明，不一定是严格单调增），否则灰度变换后产生认为缺陷。</p><p>我们可以将 <code>r</code> 看作输入图像的表示灰度的随机变量，<code>s</code> 为输出图像的表示灰度的随机变量，令 $p_r(r), \ p_s(s)$ 分别表示 <code>r</code> 和 <code>s</code> 的概率密度函数，那么</p><script type="math/tex; mode=display">p_s(s)=p_r(r) \frac {dr} {ds} \qquad(2)</script><p>其中 $T(r)=s, \ r_1 \le r \le r_2$，非严格单调增时 $r_1&lt;r_2$，严格单调增时 $r_1=r_2$。</p><p>使用如下变换函数来实现直方图均衡，</p><script type="math/tex; mode=display">s=T(r)=(L-1)\int_0^r p_r(w) dw \qquad(3)</script><p>其中 积分项是归一化的，所以增加 $(L-1)$ 因子将灰度放大到合适的范围内。</p><p>对 (3) 式求导，</p><script type="math/tex; mode=display">\frac {ds} {dr} = \frac {dT(r)} {dr} = (L-1) \frac d {dr} \left[\int_0^r p_r(w)dw \right] = (L-1)p_r(r) \qquad(4)</script><p>将 (4) 式代入 (2) 式，</p><script type="math/tex; mode=display">p_s(s)=p_r(r) \frac {dr} {ds} = \frac 1 {L-1} \qquad(5)</script><p>这说明， 随机变量 <code>s</code> 是均匀分布的。</p><p>数字图像处理中常采用离散化处理，此时变换函数为，</p><script type="math/tex; mode=display">s=T(r)=(L-1) \sum_{0}^r p_r(r) \qquad(3')</script><p>其中 $p_r(r)=n_r/N$，$n_r$ 为灰度 <code>r</code> 的像素数量，<code>N</code> 为图像总像素数量。<br>此时 </p><script type="math/tex; mode=display">1=s - (s-1) = (L-1)\sum_0^{r_2}p_r(r) - (L-1)\sum_0^{r_1}p_r(r)=(L-1)\sum_{r_1}^{r_2}p_r(r)</script><p>于是，</p><script type="math/tex; mode=display">p_s(s) = \sum_{r_1}^{r_2}p_r(r)=\frac 1 {L-1}</script><p>注意，上式中由于 $r$ 取不到 $r_1$，故可能会出现近似等于 $1/(L-1)$。</p><h2 id="4-2-直方图匹配"><a href="#4-2-直方图匹配" class="headerlink" title="4.2 直方图匹配"></a>4.2 直方图匹配</h2><p>指定输出图像的直方图的形状。令 <code>r</code>  和 <code>z</code> 分别表示输入和输出图像的灰度随机变量，<code>s</code> 为一个均匀分布的灰度随机变量，有</p><script type="math/tex; mode=display">s=T(r)=(L-1)\int_0^r p_r(r) dw \qquad(6)\\\\ s=G(z)=(L-1)\int_0^z p_z(t) dt \qquad(7)</script><p>于是，</p><script type="math/tex; mode=display">z=G^{-1}(s)</script><p>此时要求变换函数 $G$ 是严格单调增，否则不存在反函数。</p><p>由于输入图像给定，容易计算出 $p_r(r)$，而指定输出图像的直方图形状，即 $p_z(z)$ 已知，根据 (7) 式可得 $G$（每个 z 到 s 的映射），于是直方图匹配步骤如下：</p><ol><li>计算 $p_r(r)$，然后计算 <code>s</code></li><li>根据式 (7) 计算 $G(z)$</li><li>求反函数 $G^{-1}(s)$，根据 <code>s</code> 计算出 <code>z</code></li></ol><p>实际处理过程为：对输入图像做直方图均衡得到 <code>s</code> 灰度的图，然后对此图中每个像素执行反映射 $z=G^{-1}(s)$（s 到 z 的映射），得到最终输出图像。</p><h2 id="4-3-局部直方图处理"><a href="#4-3-局部直方图处理" class="headerlink" title="4.3 局部直方图处理"></a>4.3 局部直方图处理</h2><p>对每个位置的邻域计算直方图，然后进行均衡化或者应用其他匹配变换函数，用于修改这个邻域中心的灰度，然后平移邻域（一个像素位置或者移到另一个非重叠区域）。</p><h2 id="4-4-直方图统计"><a href="#4-4-直方图统计" class="headerlink" title="4.4 直方图统计"></a>4.4 直方图统计</h2><p>令 <code>r</code> 为表示灰度的离散随机变量，归一化的直方图为 $p(r)$，应用概率相关的知识，<code>r</code> 的 n 阶（中心）矩定义为，</p><script type="math/tex; mode=display">\mu_n(r)=\sum_{i=0}^{L-1} (r_i-m)^n p(r_i)</script><p>其中 <code>m</code> 是期望（或称平均灰度）$m=\sum_0^{L-1} r_i p(r_i)$</p><p>二阶矩（灰度方差）为</p><script type="math/tex; mode=display">u_2(r)=\sum_{i=0}^{L-1}(r_i-m)^2 p(r_i)</script><p>通常用 $\sigma^2$ 表示，单独列出二阶矩是因为比较重要。</p><p>实际给定一个图像时，可以直接计算样本均值和样本方差，无需计算直方图，</p><script type="math/tex; mode=display">m=\frac 1 {MN} \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} f(x,y)\\\\ \sigma^2=\frac 1 {MN} \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} [f(x,y)-m]^2</script><p>以上方差计算有时候使用 $MN-1$ 作为分母，以获得一个无偏估计，实际中，使用 $MN$ 作为分母的偏差可忽略不计。</p><p>考虑点 $(x,y)$ 的邻域 $S_{xy}$，仿照上面全局统计量可写出局部均值和局部方差如下，</p><script type="math/tex; mode=display">m_{s_{xy}}=\sum_{i=0}^{L-1}r_i p_{s_{xy}} (r_i)\\\\ \sigma_{s_{xy}}^2 = \sum _{i=0}^{L-1} (r_i - m_{S_{xy}})^2 p_{s_{xy}}(r_i)</script><p>有时候只需要对图像上暗区进行增强，亮区保持不变，所以需要先判断当前邻域属于暗区还是亮区，记全局均值为 $m_G$，如果 $m_{s_{xy}} \le k_0 m_G$，其中 $0&lt; k_0 &lt; 1.0$，那么属于暗区，对其进行局部增强。</p><p>如果想增强低对比度的局部区域，那么判断方法为 $\sigma_{s_{xy}} \le k_2 \sigma_G$。当然一般还会设置一个阈值下限，例如对比度为 0 的恒定区域，其实是没必要增强的，所以 $k_1 \sigma_G \le \sigma_{s_{xy}} \le k_2 \sigma_G$。对于满足增强条件的点而言，增强操作可以是将像素值乘以一个常数 <code>E</code> ，这样这个点相对于图像上其他不需要增强的点，像素得以增大（或减小）。</p><p>总结增强方法如下，</p><script type="math/tex; mode=display">g(x,y)=\begin{cases} E \cdot f(x,y) & m_{s_{xy}} \le k_0 m_G, \ k_1 \sigma_G \le \sigma_{s_{xy}} \le k_2 \sigma_G \\\\ f(x,y) & \text{otherwise} \end{cases}</script>]]></content>
      
      
      
        <tags>
            
            <tag> DIP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch 方法总结</title>
      <link href="/2019/11/01/pytorch/PyTorch-mtd/"/>
      <url>/2019/11/01/pytorch/PyTorch-mtd/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Fold-Unfold"><a href="#1-Fold-Unfold" class="headerlink" title="1. Fold / Unfold"></a>1. Fold / Unfold</h1><h2 id="Fold"><a href="#Fold" class="headerlink" title="Fold"></a>Fold</h2><p>这是 torch.nn.Fold 类。</p><p>首先我们来复习一下卷积过程，设输入 size 为 <code>(N,C,H,W)</code>，卷积 kernel size 为 <code>(C,h,w)</code>，碰撞系数为 <code>d</code>，padding 为 <code>p</code>，stride 记为 <code>s</code>，那么整个过程相当于将 <code>Cxhxw</code> 大小的数据块在输入数据中滑动，每一次滑动做一次卷积，记共有 <code>L</code> 次卷积，即，从输入数据中切分出 <code>L</code> 个数据块与卷积核做卷积，当然每个数据块的大小与卷积核相同，为 <code>(C,h,w)</code>，最后得到的输出 map 大小为<br><span id="more"></span></p><script type="math/tex; mode=display">H_o= \frac {H - [d(h-1)+1] + 2p} {s}+1\\\\ W_o= \frac {W - [d(w-1)+1] + 2p} {s}+1</script><p>因为每一次卷积得到的值均作为输出 map 上的一点，故 <code>L</code> 为</p><script type="math/tex; mode=display">L=H_o * W_o=\left(\frac {H - [d(h-1)+1] + 2p} {s}+1\right) \left(\frac {W - [d(w-1)+1] + 2p} {s}+1\right)</script><p>好了，现在 Fold 要做的事情是反过来的，已知 fold 的输入为 <code>L</code> 个数据块，大小为 <code>(N,C*h*w,L)</code>，有关的构造参数为卷积核 size <code>(h,w)</code>，dilation，padding，stride，以及，指定最终的（Fold）输出大小 <code>(H,W)</code>，注意，Fold 做的事情是反过来的，也就是说，从 <code>L</code> 个数据块中恢复出原来普通卷积的输入 map 的大小，即 <code>(H,W)</code>，不是做完卷积之后的输出 map 的大小，记住，<strong>Fold 的输出是普通卷积的输入</strong>。</p><p>Fold 的这些构造参数指明了卷积核大小，以及卷积输入的大小，然后根据其（这里指 Fold）输入 <code>L</code> 个数据块的 tensor，size 为 <code>(N,C*h*w,L)</code>，恢复出卷积输入的 tensor，因为 Fold 的构造参数中指定了 卷据输入 map 的 <code>(H,W)</code>，而批大小 <code>N</code> 也已知，所以要求出通道 <code>C</code>，根据 Fold 输入 tensor 的 第二个维度值 <code>C*h*w</code> 以及 Fold 的构造参数中卷积核大小 <code>(h,w)</code> 很容易得到通道 <code>C</code>。</p><p>先使用 PyTorch 文档中的例子加以说明，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> fold <span class="token operator">=</span> nn<span class="token punctuation">.</span>Fold<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (H,W)=(4,5), (h,w)=(2,2)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span>   <span class="token comment"># (N, C*h*w,L)</span><span class="token operator">>></span><span class="token operator">></span> output <span class="token operator">=</span> fold<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># (N,C,H,W)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>将数据维度从 <code>H,W</code> 扩展到更多维度，就是 PyTorch 文档中关于 <code>L</code> 的计算式了，如下</p><script type="math/tex; mode=display">L=\prod_d \lfloor \frac {\text{output\_size} [d] + 2 \times \text{padding}[d]-\text{dilation}[d] \times (\text{kernel\_size}[d]-1) -1} {\text{stride}[d]} +1 \rfloor</script><p><strong>总结：</strong></p><p>Fold 的输入 size 为 $(N, C \times \prod(\text{kernel_size}), L)$，输出 size 为 $(N,C, \text{output_size}[0], \text{output_size}[1], …)$</p><h2 id="Unfold"><a href="#Unfold" class="headerlink" title="Unfold"></a>Unfold</h2><p>这是 torch.nn.Unfold 类，所做的事情与 Fold 相反，根据普通卷积的输入 tensor 以及卷积核大小，dilation，padding 和 stride 等计算得到 <code>L</code> 个与卷积核做卷积操作的数据块。<code>L</code> 计算方式如上。Unfold 的输入 size 为 $(N,C,<em>)$，其中 </em> 表示多维数据，输出 size 为 $(N,C \times \prod(\text{kernel_size}), L)$。</p><p>引用PyTorch 文档中的例子，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> unfold <span class="token operator">=</span> nn<span class="token punctuation">.</span>Unfold<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> output <span class="token operator">=</span> unfold<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token comment"># each patch contains 30 values (2x3=6 vectors, each of 5 channels)</span><span class="token operator">>></span><span class="token operator">></span> <span class="token comment"># 4 blocks (2x3 kernels) in total in the 3x4 input</span><span class="token operator">>></span><span class="token operator">></span> output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="2-Normalization"><a href="#2-Normalization" class="headerlink" title="2. Normalization"></a>2. Normalization</h1><h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><p>批归一化是针对一个 mini-batch 内的数据进行归一化。首先给出归一化公式：</p><script type="math/tex; mode=display">y=\frac {x-E[x]} {\sqrt{V[x]+\epsilon}} * \gamma + \beta</script><p>批归一化过程为：<br>BatchNorm Layer 的输入（mini-batch）为 $\mathcal B=\{x_{1…m}\}$，可学习参数为 $\gamma, \beta$。计算 mini-batch 的均值，方差</p><script type="math/tex; mode=display">\mu_{\mathcal B} = \frac 1 m \sum_{i=1}^m x_i, \quad \sigma_{\mathcal B}^2=\frac 1 m \sum_{i=1}^m(x_i - \mu_{\mathcal B})^2</script><p>然后计算归一化后的值</p><script type="math/tex; mode=display">\hat x_i = \frac {x_i - \mu_{\mathcal B}} {\sqrt {\sigma_{\mathcal B}^2+ \epsilon}}</script><p>最后进行 scale 和 shift，</p><script type="math/tex; mode=display">y_i=\hat x_i \cdot \gamma + \beta</script><p><strong>小结：</strong> 沿着 batch 方向进行归一化</p><h2 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a>LayerNorm</h2><p>Layer 归一化是针对某个数据（样本）内部进行归一化，假设某个数据样本到达 LayerNorm 层为 $x$，无论 $x$ 是多少维的 tensor，均可以看作是 1D vector，即 $x=(x_1,…x_H)$，$H$ 是 LayerNorm 层的单元数（也是 $x$ 的特征数），于是 LayerNorm 过程为</p><script type="math/tex; mode=display">\mu=\frac 1 H \sum_{i=1}^H x_i, \quad \sigma^2=\frac 1 H \sum_{i=1}^H (x_i-\mu)^2</script><p>于是 LayerNorm 后的值为</p><script type="math/tex; mode=display">y=\frac {x-\mu} {\sqrt {\sigma^2+\epsilon}} \cdot \gamma + \beta</script><p><strong>小结：</strong> 沿着特征方向进行归一化（特征包含了除 batch 维度外的其他所有维度）</p><p>有了前面的归一化介绍，我们知道归一化过程都很类似，区别在于如何计算 $\mu, \sigma$，或者说沿着什么方向进行归一化。</p><h2 id="InstanceNorm"><a href="#InstanceNorm" class="headerlink" title="InstanceNorm"></a>InstanceNorm</h2><p>对于每个样例的每个 channel 分别计算 $\mu, \sigma$。假设输入为 $(N,C,H,W)$，那么沿着 $(H,W)$ 方向做归一化。</p><h2 id="GroupNorm"><a href="#GroupNorm" class="headerlink" title="GroupNorm"></a>GroupNorm</h2><p>GroupNorm 是选择一组 channels 进行归一化，所以是介于 InstanceNorm（单个channel）和 LayerNorm （全部 channels）之间的。</p><h1 id="3-Pool"><a href="#3-Pool" class="headerlink" title="3. Pool"></a>3. Pool</h1><p>池化操作都比较简单易懂，这里介绍几个非常规的池化操作。</p><h2 id="FractionalMaxPool2d"><a href="#FractionalMaxPool2d" class="headerlink" title="FractionalMaxPool2d"></a>FractionalMaxPool2d</h2><p>引用论文 <a href="https://arxiv.org/abs/1412.6071">Fractional MaxPooling</a>。</p><p>pool 操作通常是用于降低 feature map 的大小，以常规的 <code>2x2</code> max-pooling 为例，记输入大小为 $N_{in} \times N_{in}$，输出大小为 $N_{out} \times N_{out}$，那么有</p><script type="math/tex; mode=display">N_{out}=\frac {N_{in}-k+2p} {s} + 1= N_{in} / 2 \Rightarrow N_{in} /N_{out} = 2</script><p>将 $N_{in} \times N_{in}$ 的 feature map 划分出 $N_{out}^2$ 个 pooling 区域 $(P_{i,j})$。我们用 $\{1,2,…,N_{in}\}^2$ （或 $[1,N_{in}]^2$）表示输入 feature map，pixel 使用坐标点表示，显然 pooling 区域满足</p><script type="math/tex; mode=display">P_{i,j} \subset \{1,2,...,N_{in}\}, \quad (i,j) \in \{1,...,N_{out}\}^2</script><p>现在，我们想让 $N_{in} / N_{out} \in (1,2)$，或者为了提高速度，让 $N_{in} / N_{out} \in (2,3)$，反正，这个比例不再是整数，这就是 Fractional max-pooling（FMP）。</p><p>那么，FMP 具体是如何实现的呢？</p><p>令两个递增序列 $(a_i)_{i=0}^{N_{out}}, \ (b_i)_{i=0}^{N_{out}}$ 均以 <code>1</code> 开始，$N_{in}$ 结尾，递增量为 <code>1</code> 或者 <code>2</code>，即 $\forall i,\ a_{i+1}-a_{i} \in \{1,2\}$，那么 pooling 区域可以有如下两种表示：</p><script type="math/tex; mode=display">P_{i,j}=[a_{i-1}, a_i-1] \times [b_{j-1},b_j-1], \quad i,j \in \{1,...,N_{out}\}\\\\ P_{i,j}=[a_{i-1}, a_i] \times [b_{j-1},b_j], \quad i,j \in \{1,...,N_{out}\}</script><p>注意下标 <code>i,j</code> 的范围。</p><p>第一种是 <code>disjoint</code> 表示，第二种是 <code>overlapping</code> 表示。显然使用第二种表示，相邻两个 pooling 区域是有重叠的，而第一种表示则不会。</p><p>记下采样率 $\alpha = N_{in} / N_{out}$，有如下两种方法得到 $(a_i)_{i=0}^{N_{out}}$</p><ol><li><p><code>random</code> 方法</p><p>当 $\alpha$ 给定，那么 $(a_i-a_{i-1})_{i=1}^{N_{out}}$ 这个序列中有多少个 <code>1</code> 和多少个 <code>2</code> 已经是确定的了，将适量的 <code>1</code> 和 <code>2</code> shuffle 或者 random permutation，然后可可到 $\alpha = N_{in} / N_{out}$</p></li><li><p><code>pseudorandom</code> 方法</p><p>经过 $(0,0), \ (N_{out}, N_{in}-1)$ 的直线，其斜率为 $\alpha$（实际上是比下采样率小一点点，但是没关系，这两个值只要同时位于 $(1,2)$ 之间即可），将这个直线沿 y 轴 平移 $\alpha \cdot u$，其中 $\alpha \in (1,2), \ u \in (0,1), \alpha \cdot u \in (0,1)$，即</p><script type="math/tex; mode=display">y=\alpha(i+u)</script><p>在此直线上取点，x 值依次为 $0,1,2,…,N_{out}$，对 y 值在应用 ceiling 函数，作为 $a_i$ 的值，</p><script type="math/tex; mode=display">a_i=\text{ceiling}(\alpha(i+u)), \quad i=0,1,2,...,N_{out}</script><p>验证一下 $\{a_i\}$ 序列是否满足上述条件：</p><ul><li>$i=0$，$a_0=\text{ceiling}(\alpha \cdot u)$，由于 $\alpha \cdot u \in (0,1)$，故 $a_0=1$</li><li>$i=N_{out}$，$a_{N_{out}}=\text{ceiling}(N_{in}-1+\alpha \cdot u)=N_{in}$</li><li><code>otherwise：</code> $a_{i+1}-a_i=\text{ceiling}(\alpha \cdot i+\alpha+\alpha \cdot u)-\text{ceiling}(\alpha \cdot i+\alpha \cdot u)$。验证说明如下。</li></ul><p>下面验证最后一种情况：</p><p>记 $\alpha \cdot i+\alpha \cdot u=f \in [k,k+1)$，k 是某个整数，那么当</p><ul><li><p><code>f=k</code> 时，</p><p>   $a_{i+1}-a_i=\text{ceiling}(k+\alpha)-k=k+\text{ceiling}(\alpha)-k=\text{ceiling}(\alpha)=2$</p></li><li><p><code>k&lt;f&lt;k+1</code> 时，</p><p>   $k+1&lt;f+\alpha&lt;k+3$</p><p>   $a_{i+1}-a_i=\text{ceiling}(f+\alpha)-k-1 \in \{1,2\}$</p></li></ul><p>至此，验证了 $(a_i)$ 序列满足条件。显然，基于直线取离散点然后应用 ceiling 函数得到的是一种伪随机序列。</p></li></ol><h1 id="4-ConvTranspose"><a href="#4-ConvTranspose" class="headerlink" title="4. ConvTranspose"></a>4. ConvTranspose</h1><h2 id="输出大小"><a href="#输出大小" class="headerlink" title="输出大小"></a>输出大小</h2><p>转置卷积，通常又称反卷积、逆卷积，然而转置卷积并非卷积的逆过程，并且转置卷积其实也是一种卷积，只不过与卷积相反的是，输出平面的大小通常不是变小而是变大。对于普通卷积，设输入平面边长为 $L_{in}$，输出平面边长为 $L_{out}$，卷积核边长为 $k$，dilation 、stride 和 padding 分别为 $d, p, s$，那么有</p><script type="math/tex; mode=display">L_{out}=\frac {L_{in}-(d(k-1)+1)+2p} s + 1 \tag {4-1}</script><p>对于转置卷积，令 $L_{in}^{\top}, \ L_{out}^{\top}$ 分别表示输入和输出的边长，于是有</p><script type="math/tex; mode=display">L_{out}^{\top}=s(L_{in}^{\top} - 1) +d(k-1)+1 - 2p \tag{4-2}</script><p>可见，转置卷积的输入输出边长的关系与普通卷积是反过来的。</p><h2 id="转置卷积计算"><a href="#转置卷积计算" class="headerlink" title="转置卷积计算"></a>转置卷积计算</h2><h3 id="第一种方法"><a href="#第一种方法" class="headerlink" title="第一种方法"></a>第一种方法</h3><p>回顾一下卷积过程，以二维卷积为例，假设输入大小为 $4 \times 4$，卷积核 $3 \times 3$，不考虑 padding，且 stride 为 1，那么根据 $(4-1)$ 式输出大小为 $2 \times 2$，我们可以用卷积核在输入平面上滑窗并做卷积来理解卷积，实际计算则是根据输入矩阵得到 $4 \times 9$ 的矩阵（<strong>部分 element 用 0 填充</strong>），然后将卷积核展开成 $9 \times 1$ 的矩阵，然后进行卷积相乘得到 $4 \times 1$ 的输出矩阵。</p><p>我们再看转置卷积，输入大小为 $2 \times 2$，卷积核大小为 $3 \times 3$，同样地，不考虑 padding 且 stride 为 1，那么根据 $(4-2)$ 式输出大小为 $4 \times 4$，实际的计算过程为：<strong>由于转置卷积也是一个普通卷积</strong>，所以先将输入矩阵 zero-padding 为 $6\times 6$ 的矩阵（$6 \times 6$ 的输入矩阵经过 $3 \times 3$ 的卷积才能得到 $4 \times 4$ 的输出大小），然后与普通卷积一样地得到为 $16 \times 9$ 的矩阵，卷积核 <strong>旋转 180°</strong>，然后 reshape 为 $9 \times 1$ 的矩阵，通过矩阵乘法，得到矩阵大小为 $16 \times 1$，然后 reshape 为 $4 \times 4$，此即输出矩阵。</p><p>下面我们画图来展示卷积和转置卷积地过程：</p><p><img src="/images/pytorch_mth_conv.png" alt=""></p><center>普通卷积</center><p><img src="/images/pytorch_mtd_conv_t.png" alt=""></p><center>转置卷积</center><p>使用 Pytorch 进行验证：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnconvt <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>convt<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>convt<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                            <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                            <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>output <span class="token operator">=</span> convt<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>output<span class="token comment"># tensor([[[[ 0., 12., 36., 24.],</span><span class="token comment">#           [24., 58., 61., 34.],</span><span class="token comment">#           [20., 66., 70., 24.],</span><span class="token comment">#           [ 0., 10., 37., 34.]]]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="第二种方法"><a href="#第二种方法" class="headerlink" title="第二种方法"></a>第二种方法</h3><p>还有另一种方法来理解计算卷积和转置卷积。还是以上面的例子进行说明。</p><p>普通卷积中，输入矩阵 reshape 为 $1 \times 16$。因为有 4 个滑窗卷积动作，所以将卷积核分别以四种不同的 zero-padding 方式得到 4 个 $4 \times 4$ 的矩阵（即，卷积核的 $3 \times 4$ 部分位于 $4 \times 4$ 矩阵的左上角、右上角，左下角和右下角，其他位置 zero-padding），然后 reshape 为 $16 \times 4$，记这个 $16 \times 4$ 的矩阵为 $K$， 得到 $1 \times 4$ 矩阵，reshape 为 $2 \times 2$ 即输出矩阵。</p><p>转置卷积中，输入矩阵大小为 $2 \times 2$（即 <code>[12,12,10,17]</code>），直接 reshape 为 $1 \times 4$，将上面的矩阵 $K$ <strong>转置</strong>，得到 $4 \times 16$ 的矩阵，然后矩阵相乘得到 $1 \times 16$ 矩阵，最后 reshape 为 $4 \times 4$ 即为输出矩阵。</p><p>普通卷积的过程如下图示意，转置卷积非常简单，读者可以自己画图验证。</p><p><img src="/images/pytorch_mtd_conv_t_1.png" alt="卷积的另一种计算过程"><center>卷积的另一种计算过程</center></p><p>从转置卷积得到的结果来看，很明显，转置卷积不是普通卷积的逆过程。</p><h3 id="dilation-gt-1"><a href="#dilation-gt-1" class="headerlink" title="dilation &gt; 1"></a>dilation &gt; 1</h3><p>现在，我们的讨论还未结束，来看 <code>dilation</code> 不为 1 的情况，例如 <code>dilation=2</code>，还是使用上面的例子，对于转置卷积，此时根据 $(4-2)$ 式得到输出矩阵大小为 $6 \times 6$，将卷积核膨胀后得到 $5 \times 5$ 矩阵（间隔填充 0），并 <strong>旋转 180°</strong>，由于转置卷积也是一种普通卷积，所以应该将输入矩阵 zero-padding 到 $10 \times 10$ 大小才能得到 $6 \times 6$ 的输出，也就是说，输入矩阵上下左右均进行 4 个单位的 zero-padding，</p><p>记 <code>input</code> 为 $I$，zero-padding后，$I[4:6,4:6]=[[12.,12],[10,17]]$，其余位置为 <code>0</code>，膨胀后的卷积核 <strong>旋转 180°</strong> 后为 $K’=[[2., 0, 1, 0, 0],[0,0,0,0,0],[0,0,2,0,2],[0,0,0,0,0],[2,0,1,0,0]]$，可以手动计算卷积后的输出矩阵，这里给出 python 代码计算示例，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">convt1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>dilation<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>convt1<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>convt1<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>output1 <span class="token operator">=</span> convt1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>output1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h3 id="stride-gt-1"><a href="#stride-gt-1" class="headerlink" title="stride &gt; 1"></a>stride &gt; 1</h3><p>依然以上面的例子进行说明，假设现在 <code>stride=2</code>，根据式 $(4-2)$ 转置卷积的输出大小为 $5 \times 5$。把转置卷积看作一种普通卷积，那么其输入大小应该为 $7 \times 7$，由于 <code>stride=2</code>，所以先将 $2 \times 2$ 输入矩阵膨胀为 $3 \times 3$ 的矩阵（2*(2-1)+1=3），然后再 zero-padding 成 $7 \times 7$ 的矩阵（上下左右 padding 的数量均为 (7-3)/2=2），经过这番处理，输入矩阵变为 $I[2,2]=I[2,4]=12, \ I[4,2]=10, \ I[4,4]=17$，其余位置均为 <code>0</code>，卷积核 <strong>旋转 180°</strong> 后为 $K’=[[2., 1, 0],[0,2,2],[2,1,0]]$，于是可以手动计算出卷积后的矩阵，这里给出 python 代码计算示例，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">convt<span class="token punctuation">.</span>stride <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>output <span class="token operator">=</span> convt<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>output<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><h3 id="padding-gt-0"><a href="#padding-gt-0" class="headerlink" title="padding &gt; 0"></a>padding &gt; 0</h3><p>继续以上面的例子进行说明，假设现在 <code>padding=1</code>，根据式 $(4-2)$ 转置卷积的输出大小为 $2 \times 2$。将输入矩阵上下左右均进行 1 单位的 zero-padding，得到矩阵大小 $4 \times 4$，卷积核大小 $3 \times 3$，计算过程还是将卷积核 <strong>旋转 180°</strong>，卷积计算过程略，不过相信这是足够简单的事情。</p><p>以上 <code>dialtion &gt; 1, stride &gt; 1, padding &gt; 0</code> 三种情况，除了可使用 python 程序验证，还可以使用 <code>第二种方法</code> 进行验证对输入矩阵以及卷积核的处理是正确的，并且，也可以使用 <code>第一种方法</code> 对输入矩阵和卷积核进行处理然后进行普通卷积计算得到输出矩阵。</p><h1 id="5-Upsample"><a href="#5-Upsample" class="headerlink" title="5. Upsample"></a>5. Upsample</h1><p>输入维度为 <code>minibatch x channels x [optional depth] x [optional height] x width</code>，即，输入可以是 3D/4D/5D。可用的算法包括 <code>nearest neighbor, linear, bilinear, bicubic, trilinear</code>。</p><h2 id="nearest-neighbor"><a href="#nearest-neighbor" class="headerlink" title="nearest neighbor"></a>nearest neighbor</h2><p>顾名思义，就是使用原平面上最近的一点作为上采样后的值。例如原平面 size 为 $m \times m$，在原平面上建立坐标系 S，上采样后的 size 为 $n \times n, \ n &gt; m$，设其上点的坐标为 $(x,y), \ x,y =0,1,…,n-1$。将上采样后平面点映射到 S 中，对应坐标记为 $(x’,y’)$，那么有</p><script type="math/tex; mode=display">\frac {x-0} {n-1-0}= \frac {x'-0}{m-1-0} \Rightarrow x' = \frac {m-1} {n-1} \cdot x</script><p>同理有 $y’ = \frac {m-1} {n-1} \cdot y$，然后找出与点 $(i’,j’)$ 最近的那个整数坐标点，显然必然在以下四个点中产生 $(\lfloor x’\rfloor, \lfloor y’ \rfloor), \ (\lfloor x’\rfloor, \lceil y’ \rceil), \ (\lceil x’\rceil, \lfloor y’ \rfloor), \ (\lceil x’\rceil, \lceil y’ \rceil)$ （这四个点可能有重合），分别计算 $(x’,y’)$ 与这四个点的距离，距离最小的那个点的值即作为 $(x,y)$ 上采样后的值。（使用哪种距离指标，可以查看 PyTorch 底层实现代码，这里本人尚未去查看。）</p><h2 id="bilinear"><a href="#bilinear" class="headerlink" title="bilinear"></a>bilinear</h2><p>输入必须是 4D。</p><h3 id="align-corners-True"><a href="#align-corners-True" class="headerlink" title="align_corners=True"></a>align_corners=True</h3><p>双线性插值。记四个顶点为 $(x_1,y_1), \ (x_1,y_2), \ (x_2,y_1), \ (x_2,y_2)$，然后求目标点 $(x,y), \ x_1 \le x \le x_2, \ y_1 \le y \le y_2$ 的值。沿 x 轴线性插值，</p><script type="math/tex; mode=display">f(x,y_1)=\frac {f_{21}-f_{11}} {x_2-x_1} \cdot (x-x_1)+f_{11}\\\\ f(x,y_2)=\frac {f_{22}-f_{12}} {x_2-x_1} \cdot (x-x_1)+f_{12}\\\\ f(x,y)=\frac {f_(x,y_2)-f(x,y_1)} {y_2-y_1} \cdot (y-y_1)+f(x,y_1)</script><p>与 <code>nearest neighbor</code> 中一样，首先将点 $(x,y)$ 映射到原平面上一点 $(x’,y’)$，然后四个顶点为 $(\lfloor x’\rfloor, \lfloor y’ \rfloor), \ (\lfloor x’\rfloor, \lceil y’ \rceil), \ (\lceil x’\rceil, \lfloor y’ \rfloor), \ (\lceil x’\rceil, \lceil y’ \rceil)$。用这种映射方法，显然原平面的四个 corners 和上采样后平面的四个 corners 分别对齐，这就是 <code>align_corners=True</code> 的由来。</p><h3 id="align-corners-False"><a href="#align-corners-False" class="headerlink" title="align_corners=False"></a>align_corners=False</h3><p>如下图所示，显示了 <code>align_corners</code> 不同值的区别。<br><img src="/images/pytorch_mtd_aligncorners.png" alt=""><center>图源 [pytorch 论坛](https://discuss.pytorch.org/t/what-we-should-use-align-corners-false/22663/9)</center></p><p>从图中可以发现，映射回原平面坐标时，坐标计算方式不同，例如上菜以后平面上一点 $(x,y)$，映射回 S 中的坐标为</p><script type="math/tex; mode=display">x'=(x+0.5)/2-0.5\\\\ y'=(y+0.5)/2-0.5</script><p>此后的插值方式一致（毕竟都是双线性插值），找到最近的 4 个点 $(\lfloor x’\rfloor, \lfloor y’ \rfloor), \ (\lfloor x’\rfloor, \lceil y’ \rceil), \ (\lceil x’\rceil, \lfloor y’ \rfloor), \ (\lceil x’\rceil, \lceil y’ \rceil)$ 进行双线性插值。</p><h2 id="linear"><a href="#linear" class="headerlink" title="linear"></a>linear</h2><p>与 bilinear 类似，但是输入维度必须是 3D。</p><h2 id="trilinear"><a href="#trilinear" class="headerlink" title="trilinear"></a>trilinear</h2><p>与 bilinear 类似，但是输入维度必须是 5D。</p>]]></content>
      
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习环境搭建</title>
      <link href="/2019/09/09/pytorch/DL-env/"/>
      <url>/2019/09/09/pytorch/DL-env/</url>
      
        <content type="html"><![CDATA[<p>本文仅针对 ubuntu 系统进行讨论。</p><span id="more"></span><p>搭建深度学习环境 tensorflow，pytorch 等，如需要 GPU 加速，一般选择安装 </p><p>NVIDIA cuda 工具包，以前通常需要预先安装：</p><ol><li>NVIDIA driver</li><li>cuda</li><li>cudnn</li></ol><h1 id="NVIDIA-driver"><a href="#NVIDIA-driver" class="headerlink" title="NVIDIA driver"></a>NVIDIA driver</h1><p>曾经安装 NVIDIA 驱动采取的比较复杂的方法，先是 close nouveau，让系统进入命令行，然后安装事先下载好的驱动安装文件 <code>NVIDIA-Linux-x86_64-xxx.xxx.run</code>，这里使用比较简单的安装方法，打开 ubuntu 的 Software &amp; Updates，点击 Additional Drivers，选择 <code>Using NVIDIA driver metapackage from nvidia-driver-xxx</code> 然后点击 <code>Apply Changes</code> 进行驱动安装。</p><h1 id="cuda-amp-cudnn"><a href="#cuda-amp-cudnn" class="headerlink" title="cuda &amp; cudnn"></a>cuda &amp; cudnn</h1><p>直接使用 conda 安装 pytorch，安装过程比较简单，执行以下命令即可，<br><pre class="line-numbers language-none"><code class="language-none">conda install pytorch torchvision cudatoolkit&#x3D;10.0 -c pytorch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>如果下载较慢，可使用清华源，执行命令，<br><pre class="line-numbers language-none"><code class="language-none">conda configconda config --set show_channel_urls yescd ~vi .condarc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>打开 <code>.condarc</code> 文件并添加<br><pre class="line-numbers language-none"><code class="language-none">channels:  - defaultsshow_channel_urls: truedefault_channels:  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main  - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;rcustom_channels:  conda-forge: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud  msys2: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud  bioconda: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud  menpo: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud  pytorch: https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>然后执行<br><pre class="line-numbers language-none"><code class="language-none">conda install pytorch torchvision cudatoolkit&#x3D;10.0 -c pytorch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><h1 id="安装-tensorflow"><a href="#安装-tensorflow" class="headerlink" title="安装 tensorflow"></a>安装 tensorflow</h1><pre class="line-numbers language-none"><code class="language-none">conda install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（注：或者使用 <code>pip install tensorflow</code>）</p><p>这条命令会自动安装合适的 cuda 和 cudnn</p><h2 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h2><p>源码安装基本参考<a href="https://www.tensorflow.org/install/source#ubuntu">官方文档</a></p><p>创建虚拟环境 name 为 tf，python 版本 3.10，确保 pip，wheel，numpy 等安装<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">conda create -n tf python&#x3D;3.10pip install -U numpypip install -U keras_preprocessing --no-deps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><p>安装 bazel，使用 ubuntu apt 仓库安装（其他安装方式参考<a href="https://docs.bazel.build/versions/main/install-ubuntu.html">这里</a>）<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">sudo apt install apt-transport-https curl gnupgcurl -fsSL https:&#x2F;&#x2F;bazel.build&#x2F;bazel-release.pub.gpg | gpg --dearmor &gt; bazel.gpgsudo mv bazel.gpg &#x2F;etc&#x2F;apt&#x2F;trusted.gpg.d&#x2F;echo &quot;deb [arch&#x3D;amd64] https:&#x2F;&#x2F;storage.googleapis.com&#x2F;bazel-apt stable jdk1.8&quot; | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;bazel.listsudo apt update &amp;&amp; sudo apt install bazel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>我的 ubuntu 中已经安装了 jdk1.8_281，然而上面的最后一条命令中 <code>jdk1.8</code> 仅仅是保持传统惯例，并非表示系统必须安装 <code>jdk1.8</code>，但是我仍然推荐安装一个 jdk，版本随意，不要低于 <code>1.8</code>，安装 jdk 是为了能 Bazel 能 <code>build</code> java 代码。</p><p><strong>GPU支持</strong></p><p>确保安装以下 package</p><ol><li>NVIDIA GPU drivers</li><li>CUDA</li><li>cuDNN</li></ol><p>安装好后，将 CUPTI（包含在 CUDA toolkit 中即，安装了 CUDA 后，CUPTI 也已经安装好）的安装路径附加到 <code>LD_LIBRARY_PATH</code> 环境变量，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>下载 tensorflow 源码，这一步时间较长，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">git clone https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tensorflow.gitcd tensorflow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><p>配置<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">.&#x2F;configure<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>根据提示进行下一步操作。当然这里使用虚拟环境，执行以下命令进行配置而非上面的配置命令，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">python configure.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>区别是前者默认使用虚拟环境外部的路径，而后者使用虚拟环境内部的路径，当然无论哪种配置命令，都可以手动修改默认值。</p><p><code>./configure</code> 命令执行结果展示<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">.&#x2F;configureYou have bazel 3.0.0 installed.Please specify the location of python. [Default is &#x2F;usr&#x2F;bin&#x2F;python3]: Found possible Python library paths:  &#x2F;usr&#x2F;lib&#x2F;python3&#x2F;dist-packages  &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packagesPlease input the desired Python library path to use.  Default is [&#x2F;usr&#x2F;lib&#x2F;python3&#x2F;dist-packages]Do you wish to build TensorFlow with OpenCL SYCL support? [y&#x2F;N]: No OpenCL SYCL support will be enabled for TensorFlow.Do you wish to build TensorFlow with ROCm support? [y&#x2F;N]: No ROCm support will be enabled for TensorFlow.Do you wish to build TensorFlow with CUDA support? [y&#x2F;N]: YCUDA support will be enabled for TensorFlow.Do you wish to build TensorFlow with TensorRT support? [y&#x2F;N]: No TensorRT support will be enabled for TensorFlow.Found CUDA 10.1 in:    &#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;targets&#x2F;x86_64-linux&#x2F;lib    &#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;targets&#x2F;x86_64-linux&#x2F;includeFound cuDNN 7 in:    &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu    &#x2F;usr&#x2F;includePlease specify a list of comma-separated CUDA compute capabilities you want to build with.You can find the compute capability of your device at: https:&#x2F;&#x2F;developer.nvidia.com&#x2F;cuda-gpus Each capability can be specified as &quot;x.y&quot; or &quot;compute_xy&quot; to include both virtual and binary GPU code, or as &quot;sm_xy&quot; to only include the binary code.Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities &gt;&#x3D; 3.5 [Default is: 3.5,7.0]: 6.1Do you want to use clang as CUDA compiler? [y&#x2F;N]: nvcc will be used as CUDA compiler.Please specify which gcc should be used by nvcc as the host compiler. [Default is &#x2F;usr&#x2F;bin&#x2F;gcc]: Please specify optimization flags to use during compilation when bazel option &quot;--config&#x3D;opt&quot; is specified [Default is -march&#x3D;native -Wno-sign-compare]: Would you like to interactively configure .&#x2F;WORKSPACE for Android builds? [y&#x2F;N]: Not configuring the WORKSPACE for Android builds.Preconfigured Bazel build configs. You can use any of the below by adding &quot;--config&#x3D;&lt;&gt;&quot; to your build command. See .bazelrc for more details.    --config&#x3D;mkl            # Build with MKL support.    --config&#x3D;monolithic     # Config for mostly static monolithic build.    --config&#x3D;ngraph         # Build with Intel nGraph support.    --config&#x3D;numa           # Build with NUMA support.    --config&#x3D;dynamic_kernels    # (Experimental) Build kernels into separate shared objects.    --config&#x3D;v2             # Build TensorFlow 2.x instead of 1.x.Preconfigured Bazel build configs to DISABLE default on features:    --config&#x3D;noaws          # Disable AWS S3 filesystem support.    --config&#x3D;nogcp          # Disable GCP support.    --config&#x3D;nohdfs         # Disable HDFS support.    --config&#x3D;nonccl         # Disable NVIDIA NCCL support.Configuration finished<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>注意配置过程中，设置 <code>cuda=Y</code> 以启用 CUDA，并指定 CUDA 和 cuDNN 的版本，这是因为一台机器上可能装有多个 CUDA 或 cuDNN 版本。指定 CUDA 的计算力，例如我这里是 <code>6.1</code> 。 CUDA 的计算力可以到 <a href="https://developer.nvidia.com/cuda-gpus">官网</a> 上查询。</p><p><strong>生成 pip 包</strong></p><p>依然是在 tensorflow 目录下，使用 <code>bazel build</code> 生成 TensorFlow 2.x 包，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">bazel build [--config&#x3D;option] &#x2F;&#x2F;tensorflow&#x2F;tools&#x2F;pip_package:build_pip_package<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>由于在 <code>./configure</code> 中启用了 <code>cuda</code>，故生成的包支持 GPU，当然也可以特别指定支持 GPU，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">bazel build --config&#x3D;cuda [--config&#x3D;option] &#x2F;&#x2F;tensorflow&#x2F;tools&#x2F;pip_package:build_pip_package<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>如果想生成 TensorFlow 1.x 版本，那么执行，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">bazel build --config&#x3D;v1 [--config&#x3D;option] &#x2F;&#x2F;tensorflow&#x2F;tools&#x2F;pip_package:build_pip_package<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>由于 bazel 生成 tensorflow 过程中会使用大量内存，如果内存不够大，那么为 <code>bazel build</code> 添加选项 <code>--local_ram_resources=2048</code></p><p><code>GCC</code> 版本使用 <code>7.3</code>。</p><p>bazel build 会生成名为 <code>build_pip_package</code> 的可执行文件，运行这个可执行文件会生成一个位于 <code>/tmp/tensorflow_pkg</code> 目录下的 <code>.whl</code> 包</p><p>从发行版本分支生成：<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">.&#x2F;bazel-bin&#x2F;tensorflow&#x2F;tools&#x2F;pip_package&#x2F;build_pip_package &#x2F;tmp&#x2F;tensorflow_pkg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>从 master 分支生成，使用 <code>--nightly_flag</code> 以便获取正确的依赖，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">.&#x2F;bazel-bin&#x2F;tensorflow&#x2F;tools&#x2F;pip_package&#x2F;build_pip_package --nightly_flag &#x2F;tmp&#x2F;tensorflow_pkg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>重新生成时，建议先执行 <code>bazel clean</code>。</p><p>最后，安装包，<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">pip install &#x2F;tmp&#x2F;tensorflow_pkg&#x2F;tensorflow-version-tags.whl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>测试是否支持 GPU<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tftf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>list_physical_devices<span class="token punctuation">(</span><span class="token string">'GPU'</span><span class="token punctuation">)</span><span class="token comment"># successful NUMA node read from SysFS had negative value (-1), </span><span class="token comment"># but there must be at least one NUMA node, so returning NUMA node zero</span><span class="token comment"># [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>会出现上述 NUMA node 值为 -1 的警告，这个可以忽略，不用管它。代码中逻辑为，如果 NUMA node 读取值为负，那么返回 0。一种修改 NUMA node 的方法为（<a href="https://stackoverflow.com/questions/44232898/memoryerror-in-tensorflow-and-successful-numa-node-read-from-sysfs-had-negativ">原帖</a>），</p><p>Annoyingly, the numa_node setting is reset (to the value -1) for every time the system is rebooted. To fix this more persistently, you can create a crontab (as root).</p><p>The following steps worked for me:<br><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh"># 1) Identify the PCI-ID (with domain) of your GPU#    For example: PCI_ID&#x3D;&quot;0000.81:00.0&quot;lspci -D | grep NVIDIA# 2) Add a crontab for rootsudo crontab -e#    Add the following line@reboot (echo 0 | tee -a &quot;&#x2F;sys&#x2F;bus&#x2F;pci&#x2F;devices&#x2F;&lt;PCI_ID&gt;&#x2F;numa_node&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h1><p>下载源码<br><pre class="line-numbers language-none"><code class="language-none">git clone https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>更新源码<br><pre class="line-numbers language-none"><code class="language-none">git reset --hardgit pull origin mastergit submodule syncgit submodule update --init --recursive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></p><p>安装<br><pre class="line-numbers language-none"><code class="language-none">python setup.py install<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>如果不想安装，仅仅编译生成，那么执行<br><pre class="line-numbers language-none"><code class="language-none">python setup.py build<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>由于我这里安装了 Clang 和 llvm，设置了 <code>CPLUS_INCLUDE_PATH</code>，导致生成的过程中 include 到 llvm 的头文件，所以可以临时屏蔽 llvm 的头文件路径，<br><pre class="line-numbers language-none"><code class="language-none">export CPLUS_INCLUDE_PATH&#x3D;&#39;&#39; &amp;&amp; python setup.py build<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>现在增加了 develop 模式，conda 环境下执行<br><pre class="line-numbers language-none"><code class="language-none">cd [pytorch github project root path]python setup.py develop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>这样只会生成一个位于 site-packages 中的 torch 的 egg-link，可以随时修改 pytorch 源码，而不用重装 pytorch。</p><p>容器运行 pytorch-gpu<br><pre class="line-numbers language-none"><code class="language-none">docker pull pytorch&#x2F;pytorch:1.7.1-cuda11.0-cudnn8-leveldocker run -p 9527:22 --gpus all -rm -itd --ipc&#x3D;host -v &#x2F;home&#x2F;xx&#x2F;xx:&#x2F;home&#x2F;xx&#x2F;xx --name pytorch pytorch&#x2F;pytorch:1.7.1-cuda11.0-cudnn8-level<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><h1 id="安装-mmdetection"><a href="#安装-mmdetection" class="headerlink" title="安装 mmdetection"></a>安装 mmdetection</h1><p>以 conda 虚拟环境名称 <code>base</code> 为例，其中已经安装了 PyTorch，cudatoolkit 等包，还有一些包如<code>matplotlib, pillow, opencv</code> 等图像处理相关的包也需要安装，可以使用<br><pre class="line-numbers language-none"><code class="language-none">conda list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>查看。现在要安装 mmdetection，</p><ol><li>安装 mmcv，这是 open-mmlab 一众库的基础，<pre class="line-numbers language-none"><code class="language-none">git clone https:&#x2F;&#x2F;github.com&#x2F;open-mmlab&#x2F;mmcv.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p>进入根目录<br><pre class="line-numbers language-none"><code class="language-none">cd mmcv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>以开发模式安装，<br><pre class="line-numbers language-none"><code class="language-none">MMCV_WITH_OPS&#x3D;1 pip install -e .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>其中，MMCV_WITH_OPS 默认为 0，表示 cpu 模式下运行 mmcv（轻量级模式），为 1 时 启用 cuda 加速。<code>pip install -e .</code> 表示可编辑模型安装当前目录的库，等同于 <code>python setup.py develop</code>。</p><p>下载 mmdetection 源码，<br><pre class="line-numbers language-none"><code class="language-none">git clone https:&#x2F;&#x2F;github.com&#x2F;open-mmlab&#x2F;mmdetection.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>同样地，以开发模式安装，<br><pre class="line-numbers language-none"><code class="language-none">cd mmdetectionpip install -r requirements&#x2F;build.txtpython setup.py develop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p>]]></content>
      
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Programming (3)</title>
      <link href="/2019/08/27/dp/DP3/"/>
      <url>/2019/08/27/dp/DP3/</url>
      
        <content type="html"><![CDATA[<p>本篇接上一篇 <a href="2019/08/14/DP2">DP2</a> 讨论各种 DP 问题模型。</p><h2 id="流水作业问题-FLOWSHOP"><a href="#流水作业问题-FLOWSHOP" class="headerlink" title="流水作业问题 FLOWSHOP"></a>流水作业问题 FLOWSHOP</h2><p>这是一个进程调度问题，每个进程有两个任务 A 和 B，B 必须在 A 完成之后才能执行。任务置于独立的处理器上执行，选择进程执行顺序，使得总执行时间（损失）最小。注意，A B 任务顺序与进程顺序一致。例如，有进程 $i=\{0,1,2,3\}$，且 A 任务的执行时间分别为 $p_i=\{3,4,8,10\}$，B 任务的执行时间分别为 $q_i=\{6,2,9,15\}$，如果选择进程执行顺序为 $0,1,2,3$，那么各任务执行的开始时间和结束时间如下表：</p><span id="more"></span><div class="table-container"><table><thead><tr><th style="text-align:center">processor 1</th><th style="text-align:center">$A_0: 0-3$</th><th style="text-align:center">$A_1:3-7$</th><th style="text-align:center">$A_2:7-15$</th><th style="text-align:center">$A_3:15-25$</th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>processor 2</strong></td><td style="text-align:center"></td><td style="text-align:center">$B_0: 3-9$</td><td style="text-align:center">$B_1:9-11$</td><td style="text-align:center">$B_2:15-24$</td><td style="text-align:center">$B_3:25-40$</td></tr></tbody></table></div><p>总执行时间为最后一个 B 任务的结束时间，这个例子中为 40。进程执行顺序是可变的，要寻找具有最小执行时间的进程顺序，可以使用 DP 解决。每次决策 d 表示选择某个进程，定义状态为 (k,S)，其中 k 表示最近调度的进程的 A B 任务结束时间之间的差，S 为剩余的未调度进程集合。初始时（尚未做任何决策）k 为 0。如果当前决策 d 满足 $k \le p_d$，那么 $B_d$ 任务的执行将不会有延时，也就是说 $A_d$ 执行完了立马执行 $B_d$ 任务，<strong>于是下一决策的 k’ 为 $q_d$</strong>，否则的话 $B_d$ 任务 在 $A_d$ 执行完了还需要延时 $k-p_d$ 才开始执行，这就导致下一决策 k’ 为  $k-p_d+q_d$。</p><p>例如上面例子中，初始时 k = 0，在第一次决策 $d_1=0$ 时，$k=0<p_0$，于是 $B_0$ 任务没有延时，紧接着 $A_0$ 完成后就开始执行，然后下一决策 $d_2=1$ 的 k 为 $q_0=6$，又因为此时 $k>p_1$，所以 $B_1$ 延时 $k-p_1=6-4=2$ 才开始执行，从上表中也可以看出，$B_1$ 从 $A_1$ 结束时间 7 时开始延时 2 时间才开始执行，于是下一决策 $d_3=2$ 对应的 k 为 $k:=k-p_1+q_1=6-4+2=4$，此时 $k&lt;p_2$，所以 $B_2$ 任务执行没有延时，紧接着 $A_2$ 结束之后就（在时间 15 时）开始执行，于是最后决策 $d_4=3$ 对应的 k 为 $k:=q_2=9$，此时 $k&lt;p_3$，这说明 $B_3$ 任务也没有延时，紧接着 $A_3$ 结束（在 25 时）就开始执行，下一决策对应的 k 为 $k=q_3=15$，由于此时决策空间已经为空，所以决策结束，此为基本条件，即 $f(k,S)=k  \ 当 S=\emptyset$。</p><p>DPFE 为</p><script type="math/tex; mode=display">f(k,S)=\min_{d \in S} \{p_d + f(\max (k-p_d,0)+q_d, S-\{d\})\}</script><p>终止条件为 $f(k,\emptyset)=k$。要求的目标为 $f(0,S^{\ast})$，$S^{\ast}$ 为初始进程集合。上面例子使用代码实现如下：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">i<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>p<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span>q<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">flowshop</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>S<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>S<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> k<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    m<span class="token operator">=</span><span class="token number">1e8</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>S<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        d<span class="token operator">=</span>S<span class="token punctuation">[</span>j<span class="token punctuation">]</span>        m1<span class="token punctuation">,</span> path1<span class="token operator">=</span>flowshow<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>k<span class="token operator">-</span>p<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">+</span>q<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">,</span> S<span class="token punctuation">[</span><span class="token punctuation">:</span>j<span class="token punctuation">]</span><span class="token operator">+</span>S<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        m1<span class="token operator">+=</span>p<span class="token punctuation">[</span>d<span class="token punctuation">]</span>        <span class="token keyword">if</span> m<span class="token operator">></span>m1<span class="token punctuation">:</span>            m<span class="token operator">=</span>m1            path<span class="token operator">=</span><span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token operator">+</span>path1    <span class="token keyword">return</span> m<span class="token punctuation">,</span> pathm<span class="token punctuation">,</span> path<span class="token operator">=</span>flowshow<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="汉诺塔问题-HANOI"><a href="#汉诺塔问题-HANOI" class="headerlink" title="汉诺塔问题 HANOI"></a>汉诺塔问题 HANOI</h2><p>移动 N 个盘子（大小从上到下递增）从一个桩 x 到另一个桩 y 上，使用第三个桩 z 作为辅助，并保证每个桩上的盘子大小从上到下递增，总共需要移动的次数记为 $f(N)$，一次移动指将盘子从某桩移动到另一个桩上。显然有关系：</p><script type="math/tex; mode=display">f(i)=2f(i-1)+1</script><p>这表明，从 x 移动 i 个盘子到 y 上，等价于从 x 移动 i-1 个盘子到 z 上，然后移动 x 的最后一个盘子到 y 上，最后从 z 上移动 i-1 个盘子到 y 上。基本态为 $f(1)=1$，于是递归可计算得 $f(2)=2 f(1)+1=3, \ f(3)=2f(2)+1=7, \ \cdots$</p><p>上式仅给出了移动次数，然而我们还需要确定移动序列。</p><h3 id="非最优问题"><a href="#非最优问题" class="headerlink" title="非最优问题"></a>非最优问题</h3><p>记从桩 x 移动一个盘子到桩 y 为 $<x,y>$，定义 $F(S)$ 为移动序列，与之前求最优问题中使用加法操作不同，这里使用连接操作（concatenation），那么有</p><script type="math/tex; mode=display">F(N,x,y)=F(N-1,x,z)F(1,x,y)F(N-1,z,y)</script><p>其中状态 $S=(N,x,y)$，原理与上面一致。基本态为 $F(1,x,y)=<x,y>$。于是可一步步推导得到：</p><script type="math/tex; mode=display">\begin{aligned} F(2,x,y)&=F(1,x,z)F(1,x,y)F(1,z,y)=<x,z><x,y><z,y>\\\\F(3,x,y)&=F(2,x,z)F(1,x,y)F(2,z,y)\\\\ &=<x,y><x,z><y,z><x,y><z,x><z,y><x,y>\end{aligned}</script><p>代码实现如下<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">pegs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">hanoi</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span>i<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>j<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> n<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>j<span class="token punctuation">)</span><span class="token punctuation">]</span>    k <span class="token operator">=</span> pegs<span class="token punctuation">.</span>difference<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>i<span class="token punctuation">,</span>j<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> hanoi<span class="token punctuation">(</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>k<span class="token punctuation">)</span><span class="token operator">+</span>hanoi<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">)</span><span class="token operator">+</span>hanoi<span class="token punctuation">(</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>k<span class="token punctuation">,</span>j<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    s<span class="token operator">=</span>hanoi<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="整型线性规划问题-ILP"><a href="#整型线性规划问题-ILP" class="headerlink" title="整型线性规划问题 ILP"></a>整型线性规划问题 ILP</h2><p>考虑如下形式的优化问题</p><script type="math/tex; mode=display">\max c^{\top}x\\\\ s.t. Ax \le b\\\\ x_1,...,x_n \in \mathbf N \cup \{0\}</script><p>其中，矩阵 A 和向量 b, c 中的元素均为非负整数。这其实是一种很典型的 DP 问题，首先选择某个 $x_1$ 的值，当然无论 $x_1$ 是何值，一旦选定，就转化为 $\sum_{i=2}^n c_i x_i$ 这个子问题的最优解，由于 $x$ 向量的所有元素一起需要满足一组条件，所以在决策 $x_i$ 元素为何值时，需要知道 $x_1,…,x_{i-1}$ 这些已经决策过的元素的值，以保证它们满足条件，所以状态 S 需要包含已经决策过的元素值以及元素在向量中的位置下标，我们约定在阶段 j 时决策 $x_{j+1}$ 的值（这个不是唯一的，也可以约定来决策 $x_j$ 的值，DPFE 形式稍作调整即可），于是 DPFE 为</p><script type="math/tex; mode=display">f(j,S)=\begin{cases} \max_{x_{j+1} \in D} \{c_{j+1}x_{j+1}+f(j+1,S \cup \{(j+1,x_{j+1})\})\} & j < n\\\\ 0 & j=n \end{cases}</script><p>决策空间 $D$ 由给定的条件以及状态 $S$ 决定。此问题的求解目标是 $f(0,\emptyset)$。</p><p>以上是一种求解思路，还有一种思路。从给定的条件出发，已知</p><script type="math/tex; mode=display">Ax \le b</script><p>记 $A$ 维度为 $m \times n$，于是上式表示一共有 m 个限制条件，每个限制条件形式为 </p><script type="math/tex; mode=display">A_{i,:}x \le b_i \Rightarrow \sum_{j=1}^n A_{i,j}x_j \le b_i</script><p>每做一次决策决定一个 $x_j$ 的值，将决策后的 $x_j$ 的值移到式子右边，在阶段 j，与上面一样，将决策 $x_{j+1}$ 的值，决策后上式不等式改写为</p><script type="math/tex; mode=display">\sum_{k=j+2}^n A_{i,k}x_k \le b_i - A_{i,1}x_1 - \cdots A_{i,j+1}x_{j+1}</script><p>也就是说，每次决策不等式右边部分均会变化，于是可定义状态 S 表示限制条件的不等式右侧部分，DPFE 如下</p><script type="math/tex; mode=display">f(j,(y_1,...,y_m))=\begin{cases} \max_{x_{j+1} \in D} \{c_{j+1}x_{j+1}+f(j+1,(y_1-A_{1,j+1}x_{j+1},...,y_m-A_{m,j+1}x_{j+1}))\} & j < n\\\\ 0 & j=n \end{cases}</script><p>求解目标是 $f(0,(b_1,…,b_m))$。我们来看一下决策空间 $D$，在阶段 j，状态为 $S=(j,(y_1,…,y_m))$，由于限制条件为</p><script type="math/tex; mode=display">A_{1,j+1}x_{j+1} + A_{1,j+2}x_{j+2} + \cdots + A_{1,n}x_n \le y_1\\\\ \vdots\\\\ A_{m,j+1}x_{j+1} + A_{m,j+2}x_{j+2} + \cdots + A_{m,n}x_n \le y_m</script><p>易知此时 $x_{j+1}$ 的决策空间为 </p><script type="math/tex; mode=display">\{0,...,\min \{\lfloor \frac{y_1}{A_{1,j+1}} \rfloor, ..., \lfloor \frac{y_m}{A_{m,j+1}} \rfloor\}\}</script><p>注意，如果出现 $\frac {y_i} 0$，则解释为正无穷 $\infty$，表示第 i 个限制条件对 $x_{j+1}$ 没有上限。</p><p>第一种解决方法中的决策空间 $D$ 也是类似求解，令 </p><script type="math/tex; mode=display">y_i=b_i-\sum_{p \in S} A_{i,p_1}p_2</script><p>然后就与第二章解决方法中的决策空间的求解一样了。</p><p>例：$c=(3,5), \ b=(4,12,18)$，$A=\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 2 \\\\ 3 &amp; 2 \end{pmatrix}$，求解 $x=(x_1,x_2)$。<br>代码如下<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">c<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>b<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">]</span>a<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>m<span class="token punctuation">,</span>n<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token keyword">def</span> d<span class="token operator">=</span><span class="token punctuation">(</span>j<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">//</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token keyword">if</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">1e8</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">ilp</span><span class="token punctuation">(</span>j<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> j<span class="token operator">==</span>n<span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    dm<span class="token operator">=</span>d<span class="token punctuation">(</span>j<span class="token punctuation">,</span>y<span class="token punctuation">)</span>    m_<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>    x_<span class="token operator">=</span><span class="token boolean">None</span>    <span class="token keyword">for</span> d_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>dm<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        y_<span class="token operator">=</span><span class="token punctuation">[</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">-</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">*</span>d_ <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">]</span>        m1<span class="token punctuation">,</span>x1<span class="token operator">=</span>ilp<span class="token punctuation">(</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>y_<span class="token punctuation">)</span>        m1<span class="token operator">+=</span>c<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">*</span>d_        <span class="token keyword">if</span> m_ <span class="token operator">&lt;</span> m1<span class="token punctuation">:</span>            m_ <span class="token operator">=</span> m1            x_ <span class="token operator">=</span> <span class="token punctuation">[</span>d_<span class="token punctuation">]</span><span class="token operator">+</span>x1    <span class="token keyword">return</span> m_<span class="token punctuation">,</span> x_<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    m_<span class="token punctuation">,</span> x_ <span class="token operator">=</span> ilp<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>m_<span class="token punctuation">)</span>   <span class="token comment"># 36</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x_<span class="token punctuation">)</span>   <span class="token comment"># [2,6]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="背包型-ILP-问题-ILPKNAP"><a href="#背包型-ILP-问题-ILPKNAP" class="headerlink" title="背包型 ILP 问题 ILPKNAP"></a>背包型 ILP 问题 ILPKNAP</h2><p>假设有三类物体 n=3，每种物体的价值为 $(v_0,v_1,v_2)=(15,25,24)$，重量为 $(w_0,w_1,w_2)=(10,18,15)$，假设背包总共可装物体重量上限为 22，现在每种物体各选择多少个装包，使得价值最大？这个问题可以使用 ILP 模型解决，每种物体选择的数量为 $(x_0,x_1,x_2)$，系数向量为 $c=(v_0,v_1,v_2)$，限制条件的不等式左侧矩阵 $A=(w_0,w_1,w_2)$，右侧向量为 $b=(22)$，且 $x_0,x_1,x_2 \in \mathbf N \cup \{0\}$。</p><h2 id="区间调度问题-INTVL"><a href="#区间调度问题-INTVL" class="headerlink" title="区间调度问题 INTVL"></a>区间调度问题 INTVL</h2><p>假设有 N 个进程，标号为 $P=\{0,…,N-1\}$，选择其中的一个子集，选中的进程放置在单处理器上执行，已知每个进程有区间 $(s_i,t_i)$ 表示起始时间和截止时间，在这个时间段内，进程 $i$ 得到运行，那么就获得收益 $w_i$，由于是单处理器，所以各进程执行时间不得重叠，求选择的子集，使得收益最大，DPFE 为</p><script type="math/tex; mode=display">f(p,q)=\max_{d \in P} \{f(p,s_d)+c(d|p,q)+f(t_d,q)\}</script><p>其中 f(p,q) 表示时间段 $[p,q]$ 内的最大收益，上式是很显然，如果做出当前决策 d，那么理论上 $[s_d,t_d]$ 这个时间段用来执行进程 d，然后还剩两个区间 $[p,s_d]$ 和 $[t_d,q]$ 再继续做决策。当前决策 d 有收益当且仅当 $p \le s_d, t_d \le q$。基本态是 $f(p,q)=0, \ p \ge q$，求解目标是 $f(0,T)$，其中 $T \ge \max_i \{t_i\}$。</p><p>根据上式，在当前决策之后的两个区间 $[p,s_d]$ 和 $[t_d,q]$ 求解最大收益 $f(p,s_d), \ f(t_d, q)$时，决策空间依然还是 $P$，虽然基本态 $f(p,q)=0, \ p \ge q$ 保证了递归过程可以退出，但显然决策空间应该缩小，这样可以减少递归次数，DPFE 为</p><script type="math/tex; mode=display">f(S,p,q)=\max_{d \in S} \{f(S_L,p,s_d)+c(d|p,q)+f(S_R,t_d,q)\}</script><p>其中 $S_L, \ S_R \subset P$ 分别对应 $[p,s_d]$ 和 $[t_d,q]$ 两个区间内合适的进程集合，所谓合适，就是进程的 $(s_i,t_i)$ 包含在对应区间内。基本态是 $f(S,p,q)=0, \ p \ge q \text{ or } S=\emptyset$，求解目标是 $f(P,0,T)$，其中 $T \ge \max_i \{t_i\}$。代码如下，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">P<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>s<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>t<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span>w<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>T<span class="token operator">=</span><span class="token builtin">max</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span>n<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">get_S</span><span class="token punctuation">(</span>prev_S<span class="token punctuation">,</span> p<span class="token punctuation">,</span> q<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> prev_S <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">>=</span>p <span class="token keyword">and</span> t<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">&lt;=</span>q<span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">intvl</span><span class="token punctuation">(</span>S<span class="token punctuation">,</span> p<span class="token punctuation">,</span> q<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>S<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span> <span class="token keyword">or</span> p<span class="token operator">>=</span>q<span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    m_<span class="token operator">=</span><span class="token number">0</span>    d_<span class="token operator">=</span><span class="token boolean">None</span>    <span class="token keyword">for</span> d <span class="token keyword">in</span> S<span class="token punctuation">:</span>        m1<span class="token punctuation">,</span> d1<span class="token operator">=</span>intvl<span class="token punctuation">(</span>get_S<span class="token punctuation">(</span>S<span class="token punctuation">,</span> p<span class="token punctuation">,</span> s<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> p<span class="token punctuation">,</span> s<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">)</span>        m2<span class="token punctuation">,</span> d2<span class="token operator">=</span>intvl<span class="token punctuation">(</span>get_S<span class="token punctuation">(</span>S<span class="token punctuation">,</span> t<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">,</span> q<span class="token punctuation">)</span><span class="token punctuation">,</span> t<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">,</span> q<span class="token punctuation">)</span>        m<span class="token operator">=</span>m1<span class="token operator">+</span>m2<span class="token operator">+</span>w<span class="token punctuation">[</span>d<span class="token punctuation">]</span>        <span class="token keyword">if</span> m_<span class="token operator">&lt;</span>m<span class="token punctuation">:</span>            m_<span class="token operator">=</span>m            d_<span class="token operator">=</span><span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token operator">+</span>d1<span class="token operator">+</span>d2    <span class="token keyword">return</span> m_<span class="token punctuation">,</span> d_<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    m<span class="token punctuation">,</span> d<span class="token operator">=</span> intvl<span class="token punctuation">(</span>P<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> T<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>还有一种思路。我们将进程按其截止时间升序排列，排列后的进程序号为 $P$，进程数量为 N，然后从 $P$ 的后端到前端依次做决策，也就是第 i 个决策决定是否选择 $P$ 中第 N-i-1 个进程，例如第一个决策决定是否选择最后一个进程，第 N 个决策决定是否选择第一个进程，这样的话，假设第 N-1-i 个决策决定选择第 i 个进程，那么接下来只有 $D_i=\{j|t_j \le s_i\}$ 的进程集合可供选择，我们令 $\pi(i)=\max D_i$，因为决策是按进程序号从大到小进行的，所以下一次决策直接决定是否选择序号为 $\pi(i)$ 的进程，DPFE 为</p><script type="math/tex; mode=display">f(k)=\max\{w_k+f(\pi(k)), f(k-1)\}</script><p>其中，k 所代表的进程下标从 1 开始编号（注意与程序中数组下标从 0 开始的区别）。理解上式也很简单，当前决策，要么选择进程 k，此时收益为 $w_k+f(\pi(k))$，要么不选择进程 k，此时收益为 $f(k-1)$，通过比较哪个收益大来决定是否选择进程 k。上式可改写为</p><script type="math/tex; mode=display">f(k)=\max_{d \in \{0,1\}} \{d\cdot(w_k+f(\pi (k-1)))+(1-d)\cdot f(k-1)\}</script><p>代码实现如下，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nps<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>t<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span>w<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>P<span class="token operator">=</span>np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>t<span class="token punctuation">)</span>t<span class="token operator">=</span>np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>t<span class="token punctuation">)</span>s<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">[</span>P<span class="token punctuation">]</span>w<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">[</span>P<span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">pi</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> t<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">&lt;=</span>s<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> i    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token keyword">def</span> <span class="token function">intvl1</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> k<span class="token operator">==</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    m1<span class="token punctuation">,</span>d1<span class="token operator">=</span>intvl1<span class="token punctuation">(</span>pi<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">)</span>    m2<span class="token punctuation">,</span>d2<span class="token operator">=</span>intvl2<span class="token punctuation">(</span>k<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> m1<span class="token operator">+</span>w<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">>=</span>m2<span class="token punctuation">:</span>        <span class="token keyword">return</span> m1<span class="token operator">+</span>w<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">+</span>d1    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> m2<span class="token punctuation">,</span> d2<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    m<span class="token punctuation">,</span> d<span class="token operator">=</span> intvl<span class="token punctuation">(</span>P<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> T<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>P<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p>]]></content>
      
      
      
        <tags>
            
            <tag> math </tag>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch-5</title>
      <link href="/2019/08/27/pytorch/PyTorch-5/"/>
      <url>/2019/08/27/pytorch/PyTorch-5/</url>
      
        <content type="html"><![CDATA[<p>本篇主要分析 PyTorch 中自动求导是如何进行的。要使得能够自动求导，需要设置 Tensor 的 <code>requires_grad=True</code>，例如<br><span id="more"></span><br><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>根据前面 torch.empty 的底层 C++ 实现的分析，易知 torch.ones 的 C++ 底层实现由位于 torch/csrc/autograd/generated/python_torch_functions.cpp 中的 THPVariable_ones 函数实现，此函数定义的部分代码为<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">auto size &#x3D; r.intlist(0);auto dtype &#x3D; r.scalartype(2);auto device &#x3D; r.device(4);const auto options &#x3D; TensorOptions()    .dtype(dtype)    .device(device)    .layout(r.layout(3).layout)    .requires_grad(r.toBool(5));return wrap(dispatch_ones(size, options));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><code>wrap</code> 则是将 C++ 的 Tensor 包装为 python 的 Tensor 类型 <code>torch.Tensor</code>。dispatch_ones 函数其内部调用 torch::ones 函数，此函数定义的关键部分为<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">at::Tensor tensor &#x3D; at::ones(size, at::TensorOptions(options).is_variable(false));auto result &#x3D; autograd::make_variable(tensor, options.requires_grad());<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>上面代码第一句是构造全 1 的 Tensor，第二句代码则是将 Tensor 转为 Variable。Variable 继承 Tensor，Tensor 内部有 c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl> 类型字段 <code>impl_</code>，Variable::Impl 类型继承 TensorImpl，并且 Variable 的字段 <code>impl_</code> 实际上相当于指向 Variable::Impl 的指针类型，而 Variable::Impl 内部包含了字段 <code>requires_grad_</code> 记录了 Variable 是否支持自动求导。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">y<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># y.requires_grad False</span>z<span class="token operator">=</span>x<span class="token operator">+</span>y           <span class="token comment"># z.requires_grad True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>torch.Tensor 的基类 torch._C._TensorBase 的方法位于 torch/csrc/autograd/generated/python_variable_methods.cpp 中的 variable_methods，其中我们发现重载运算符 <code>__add__</code> 的实现函数为 THPVariable_add，调用栈为<br><pre class="line-numbers language-none"><code class="language-none">THPVariable_add -&gt; dispatch_add -&gt; Tensor::add -&gt; TypeDefault::add -&gt; native::add -&gt; native::add_out<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p>]]></content>
      
      
      <categories>
          
          <category> DL Framework </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch-4</title>
      <link href="/2019/08/22/pytorch/PyTorch-4/"/>
      <url>/2019/08/22/pytorch/PyTorch-4/</url>
      
        <content type="html"><![CDATA[<h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>torch 模块中包含了各种 Tensor：FloatTensor，DoubleTensor，HalfTensor，ByteTensor 等。这些 Tensor 是怎么来的呢？首先，入口是 <code>torch/__init__.py</code> 中的 <code>_C._initExtension(manager_path())</code>，其中 manager_path 用于获取 torch_shm_manager 的文件路径，shm 实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，这里跳过。_initExtension 在 torch/csrc/Module.cpp 中初始化 _C 模块时注册到 _C 模块中，其底层 c++ 实现函数为 THPModule_initExtension，这个函数定义中初始化了很多东西，我们依次来看看。<br><span id="more"></span></p><h3 id="initializeLayouts"><a href="#initializeLayouts" class="headerlink" title="initializeLayouts"></a>initializeLayouts</h3><p>初始化内存布局。当前有三种布局（位于文件 c10/core/Layout.h 中）：</p><ol><li>Strided，使用密集多维数组的内存布局</li><li>Sparse，使用稀疏多维数组的内存布局</li><li>Mkldnn，使用 Intel 的 Mkldnn 库加速 CPU 时，由于 Mkldnn 使用了内部特殊内存布局，所以增加对应的内存布局枚举</li></ol><p>以最常用的 Strided 布局为例，使用 THPLayout_New 生成 THPLayoutType/THPLayout 的类型对象，指定 layout 为 Strided，name 为 “torch.strided”，然后 <strong>将这个类型添加到 torch 模块中</strong>，其他两种内存布局方式也类似处理。最后注册这些布局类型：</p><ul><li>CPU, CUDA, MSNPU, XLA, QuantizedCPU -&gt; strided_layout</li><li>SparseCPU, SparseCUDA -&gt; sparse_coo_layout</li><li>MkldnnCPU -&gt; mkldnn_layout</li></ul><p>即，将 Backend 与 Layout 关联起来，以便将来根据 Backend 获取对应的 Layout。</p><h3 id="initializeMemoryFormats"><a href="#initializeMemoryFormats" class="headerlink" title="initializeMemoryFormats"></a>initializeMemoryFormats</h3><p>初始化内存格式。内存格式表明 Tensor 中的数据是如何组织的。当前有三种：Preserve, Contiguous 和 ChannelsLast。例如 ChannelsLast 表示内存中数据的格式为 NHWC，假设正常顺序 NCHW 的各维度值为 sizes，那么 ChannelsLast 下的各维度步幅 strides 应为：<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">strides[1]&#x3D;1;           &#x2F;&#x2F; ChannelsLast 中 C 为最低一级维度，故步幅为 1strides[3]&#x3D;sizes[1];    &#x2F;&#x2F; ChannelsLast 中 W 为次低一级维度，故步幅为 C 维度即 sizes[1]strides[2]&#x3D;strides[3]*sizes[3]; &#x2F;&#x2F; ChannelsLast 中 H 为再次低一级维度，步幅为 W*Cstrides[0]&#x3D;strides[2]*sizes[2]; &#x2F;&#x2F; ChannelsLast 中 N 为最高一级维度，步幅为 H*W*C<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>注意，上面 strides 和 sizes 的顺序均为 NCHW。<br>创建三种内存格式类型对象 preserve_format, contiguous_format, channels_last 并 <strong>添加到 torch 模块中</strong>。</p><h3 id="initializeQScheme"><a href="#initializeQScheme" class="headerlink" title="initializeQScheme"></a>initializeQScheme</h3><p>初始化量化机制，量化是将连续型的输入限制为离散型，比如将浮点计算转为整型计算，显然使用小型整型比浮点型计算更高效，且内存占用更小，这在模型 inference 阶段尤其重要。关于量化的具体概念以及相关操作可参考 <a href="https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor">Introducing-Quantized-Tensor</a>。当前量化机制有 5 种，类似以上布局和内存格式，分别创建对应的类型对象，然后 <strong>添加到 torch 模块中</strong>。</p><h3 id="initializeDtypes"><a href="#initializeDtypes" class="headerlink" title="initializeDtypes"></a>initializeDtypes</h3><p>初始化数据类型。直接看此函数的部分定义<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#define DEFINE_SCALAR_TYPE(_1, n) at::ScalarType::n,at:ScalarType all_scalar_type[] &#x3D; &#123;    AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS(DEFINE_SCALAR_TYPE)&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>其中 AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS 这个宏罗列了所有的标量类型，包括 complex 类型和 quantization 类型，展开后为<br><pre class="line-numbers language-none"><code class="language-none">at::ScalarType::Byte,at::ScalarType::Char,at::ScalarType::Short,at::ScalarType::Int,at::ScalarType::Long,at::ScalarType::Half,at::ScalarType::Float,at::ScalarType::Double,at::ScalarType::ComplexHalf,at::ScalarType::ComplexFloat,at::ScalarType::ComplexDouble,at::ScalarType::Bool,at::ScalarType::QInt8,at::ScalarType::QUInt8,at::ScalarType::QInt32at::ScalarType::BFloat16<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>然后根据以上标量类型获取其主名称和传统旧名称，如没有传统旧名称，则默认为空字符串 <code>&quot;&quot;</code>，然后创建各个对应的类型对象，并注册这些类型对象（即，将类型对象与 at::ScalarType 值关联起来，存储到字典，以便将来能根据 at::ScalarType 获取对应的类型对象），相关代码如下<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">std::tie(primary_name, legacy_name) &#x3D; getDtypeName(scalarType);PyObject *dtype &#x3D; THPDtype_New(scalarType, primary_name);torch::registerDtypeObject((THPDtype*)dtype, scalarType);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>然后将类型对象（THPDtypeType/THPDtype 实例）<strong>添加到 torch 模块中</strong>，如果存在传统旧名称，则也同样添加到 torch 模块中。</p><h3 id="initialize-python-bindings"><a href="#initialize-python-bindings" class="headerlink" title="initialize_python_bindings"></a>initialize_python_bindings</h3><p>初始化 python 绑定</p><h4 id="initialize-aten-types"><a href="#initialize-aten-types" class="headerlink" title="initialize_aten_types"></a>initialize_aten_types</h4><p>根据 all_declared_types 函数获取所有声明过的类型，Backend 有 <code>CPU, CUDA, SparseCPU, SparseCUDA</code> 四种，ScalarType 除去 Complex 和 Quantization 类型，则一共有<br><pre class="line-numbers language-none"><code class="language-none">Byte, Char, Double, Float, Int, Long, Short, Half, Bool, BFloat16<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>然后所有 Backend 与 ScalarType 不同的组合构成这里所需要的声明类型，不过 (SparseCUDA|SparseCPU,Bool) 除外，这样的组合一共有 4*10-2=38 种，根据这 38 种组合构建对应的 PyTensorType 类型，看看这个 PyTensorType 类型定义，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">struct PyTensorType &#123;    PyTypeObject py_type;   &#x2F;&#x2F; python 类型对应的扩展类型，这个字段后文会再次讲到    THPDtype* dtype;        &#x2F;&#x2F; 对应上文 initializeDtypes 中注册的某个数据标量类型    THPLayout* layout;      &#x2F;&#x2F; 对应上文 initializeLayouts 中注册的某个内存布局类型    bool is_cuda;           &#x2F;&#x2F; 指示是 cuda 还是 cpu    char name[64];          &#x2F;&#x2F; tensor 类型名称    int backend;            &#x2F;&#x2F; CPU, CUDA, SparseCPU, SparseCUDA 四种之一    int scalar_type;        &#x2F;&#x2F; Byte 等十种之一&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>上述 38 种组合，每种组合构建一个 PyTensorType 对象。Python 接口中某种 Tensor，比如 FloatTensor 其底层就对应这里的某个 PyTensorType 对象。</p><ul><li>layout，根据 backend 字段获取，initializeLayouts 中注册了所有 Backend 与 Layout 的映射关系</li><li>is_cuda，当 backend = CUDA|SparseCUD 时为 true</li><li>name，名称构成为 <code>[模块名].[ScalarType名]Tensor</code>。<br>模块名：<pre class="line-numbers language-none"><code class="language-none">CPU -&gt; torchCUDA -&gt; torch.cudaSparseCPU -&gt; torch.sparseSparseCUDA -&gt; torch.cuda.sparse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>ScalarType名 就是 ScalarType 字面量的字符串形式，如 Byte -&gt; “Byte”, Float -&gt; “Float” 等。例如组合 (CPU, Float) 对应的 PyTensorType 对象名为 “torch.FloatTensor”，(SparseCUDA, Double) 对应的 PyTensorType 对象名为 “torch.cuda.sparse.DoubleTensor”。</li></ul><p>注意到，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">if (backend&#x3D;&#x3D;Backend::CPU &amp;&amp; scalar_type&#x3D;&#x3D;at::kFloat) &#123;    set_default_tensor_type(&amp;tensor_type);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>可见默认 Tensor 类型为 torch.FloatTensor（其 Backend 为 CPU，注意对应 CUDA 的为 torch.cuda.FloatTensor）。</p><p>总结：initialize_aten_types 根据 38 种组合构建 PyTensorType 类型对象，并保存到 tensor_types 这个 vector 中。</p><h4 id="py-initialize-metaclass-metaclass"><a href="#py-initialize-metaclass-metaclass" class="headerlink" title="py_initialize_metaclass(metaclass)"></a>py_initialize_metaclass(metaclass)</h4><p>初始化元类，这是一个 python 的扩展类型 PyTypeObject，对应的 python 类型名为 “torch.tensortype”，顾名思义表示 tensor 类型类，即，tensor 各种类型如 torch.FloatTensor 等的元类型，这个元类具有的属性为</p><ul><li>dtype<br>  对应 initializeDtypes 中某个 THPDtype 对象</li><li>layout<br>  对应 initializeLayouts 中某个内存布局类型 THPLayout 对象</li><li>is_cuda<br>  是否使用 cuda</li><li>is_sparse<br>  是否是稀疏存储</li></ul><p>具有方法</p><ul><li><code>__instancecheck__</code> 检测某个 Tensor 是否与当前 tensor 类型类匹配，当 type_id 和 scalar_type 这两个字段均分别相同时，则匹配，否则不匹配。</li></ul><p>PyTensorType 是表示 python 的 Tensor 类型，我们指定 python 的类型本身也是一种对象，这种类型对象的类型为元类型，也就是这里的 metaclass。</p><p>总结：初始化 PyTypeObject 类型对象 metaclass，它表示 tensor 类型的元类，且具有上述属性和方法。</p><h4 id="get-tensor-dict"><a href="#get-tensor-dict" class="headerlink" title="get_tensor_dict"></a>get_tensor_dict</h4><p>获取 torch.Tensor 以及其基类 _C._TensorBase 的初始属性（名称与值构成的字典）</p><h4 id="py-initialize-tensor-type"><a href="#py-initialize-tensor-type" class="headerlink" title="py_initialize_tensor_type"></a>py_initialize_tensor_type</h4><p>对于前面构造的 38 个 PyTensorType 对象，设置每个对象的 py_type 字段。py_type 类型为 PyTypeObject，表示一个类型对象，也就是 python 中的某个类型，为这个类型对象设置元类 metaclass，名称，以及将上一小节中的属性字典并入这个类型，从而使得类型具有 torch.Tensor 的全部初始属性。<br><pre class="line-numbers language-none"><code class="language-none">dir(torch.Tensor)dir(torch.FloatTensor)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>以上两个指令输出内容一样。</p><h4 id="py-bind-tensor-types"><a href="#py-bind-tensor-types" class="headerlink" title="py_bind_tensor_types"></a>py_bind_tensor_types</h4><p>至此，以上 38 种 PyTensorType 对象均已准备好，将他们添加进相应的模块中，前文可能说 “添加进 torch 模块中”，因为当时没有讨论到 PyTensorType 对象名，所以笼统的那么说了一下，实际上应为 “添加进相应的模块中”，比如 “torch.FloatTensor”，则将相应的 PyTensorType 对象以 FloatTensor 作为 python 端的名称添加进 torch 模块中，”torch.cuda.sparse.DoubleTensor” 则将相应的 PyTensorType 对象以 DoubleTensor 作为 python 端的名称添加进 torch.cuda.sparse 模块中，即最后一个 <code>.</code> 后面的部分表示类型，而之前的部分表示模块。</p><p>但是，现在还存在一个问题，那就是这些 torch.FloatTensor, torch.IntTensor 等类型与 torch.Tensor 是什么关系？<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">a<span class="token operator">=</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">)</span>  <span class="token comment"># True</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span>     <span class="token comment"># True</span><span class="token builtin">issubclass</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span>   <span class="token comment"># False</span><span class="token builtin">issubclass</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">)</span>   <span class="token comment"># False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>根据 <a href="2019/06/18/Pytorch-3">Pytorch-3</a> 最后的分析，我们知道 torch.empty 函数最后使用 THPVariable_Wrap 将 c++ Variable 类型包装成 python 的 torch.Tensor 类型，甚至直接调用 torch.IntTensor 构造的对象最后也是经过 THPVariable_Wrap 包装成 torch.Tensor 类型，<br><pre class="line-numbers language-none"><code class="language-none">&gt;&gt;&gt; type(torch.IntTensor([1,2]))&lt;class &#39;torch.Tensor&#39;&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>既然返回的都是 torch.Tensor 类型，那怎么跟 torch.IntTensor 联系起来的呢？其实，torch.IntTensor 等 38 个 Tensor 类型与 torch.Tensor 没有直接关系<br><pre class="line-numbers language-none"><code class="language-none">&gt;&gt;&gt; torch.IntTensor.__bases__(&lt;class &#39;object&#39;&gt;)&gt;&gt;&gt; torch.Tensor.__bases__(&lt;class &#39;torch._C._TensorBases&#39;&gt;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>上面所说的各种构造 Tensor 的方法返回的类型也确实是 torch.Tensor，但是 <code>isinstance(a, torch.IntTensor)</code> 结果为 True 也没错，因为 <code>isinstance</code> 实际上内部调用 <code>__instancecheck__</code> 进行判断，前面讨论 metaclass 时讲到这个方法的 c++ 底层实现函数为 Tensor_instancecheck，其定义如下<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">static PyObject *Tensor_instancecheck(PyTensorType *self, PyObject * arg) &#123;    try&#123;        if(THPVariable_Check(arg)) &#123;    &#x2F;&#x2F; 检测参数是否是 THPVariable 类型            auto&amp; var &#x3D; ((THPVariable*)arg)-&gt;cdata; &#x2F;&#x2F; 获取内部的 Variable 类型对象            if (var.type_id() &#x3D;&#x3D; self-&gt;get_type_id() &amp;&amp;                var.scalar_type() &#x3D;&#x3D; static_cast&lt;ScalarType&gt;(self-&gt;scalar_type)) &#123;                Py_RETURN_TRUE;     &#x2F;&#x2F; 如果 type_id 和 ScalarType 均分别相同，则返回 True            &#125;        &#125;        Py_RETURN_FALSE;    &#125; catch(python_error &amp; e)&#123;        return nullptr;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>所以，不难理解 <code>isinstance(a, torch.IntTensor)=True</code>。</p><p><strong>总结：在 <a href="">PyTorch-2</a> 中，我们讨论了 PyTorch 中的函数返回或直接构造的 Tensor 均为 torch.Tensor，其继承自 <code>torch._C.Tensor</code>，所以要理解 Tensor 类的各种方法，需要从 <code>torch._C.Tensor</code> 的类型构造开始着手。</strong></p><p>接下来是一系列的 THPxxxStorage_postInit 函数执行，这在 <a href="2019/06/13/PyTorch-2">PyTorch-2</a> 中已经进行了介绍（THPxxxStorage_init），这里仅仅给出结论：</p><ol><li><p>函数声明</p> <pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#define THPStorage_(NAME) TH_CONCAT_4(THP,Real,Storage_,NAME) &#x2F;&#x2F;torch&#x2F;csrc&#x2F;Storage.hbool THPStorage_(postInit)(PyObject *module);   &#x2F;&#x2F; torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> THPStorage_(NAME) 这个宏展开后就得到 THPxxxStorage_init， 其中 Real 在宏展开时被替换为具体的 ScalarType，NAME 被替换为 init。于是，最终得到的函数声明为 THPxxxStorage_init(PyObject *module);</p></li><li><p>torch/csrc/generic/Storage.cpp 中</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">PyObject *THPStorageClass &#x3D; nullptr;bool THPStorage_(postInit)(PyObject *module)&#123;    &#x2F;&#x2F; 从 torch 模块中获取名为 RealStorage 的属性，其中 Real 可为 Float, Bool, Double 等 ScalarType    THPStorageClass &#x3D; PyObject_GetAttrString(module, (char*)TH_CONCAT_STRING_2(Real, Storage));    at::Backend backend &#x3D; at::Backend::CPU;    #ifdef THC_GENERIC_FILE    backend &#x3D; at::Backend::CUDA;    #endif    #ifdef THQUANTIZED    backend &#x3D; at::Backend::QuantizedCPU;    #endif    torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, TH_CONCAT_2(at::k, Real));&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意到在 <code>torch/__init__.py</code> 中定义了 FloatStorage 等类型，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FloatStorage</span><span class="token punctuation">(</span>_C<span class="token punctuation">.</span>FloatStorageBase<span class="token punctuation">,</span> _StorageBase<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>torch._C.FloatStorageBase 等类型是在 THPxxxStorage_init 函数中被添加到模块 torch._C 中。THPxxxStorage_postInit 函数先是从 torch 模块中获取 RealStorage 类型对象，然后进行注册即，将 RealStorage 类型对象与对应的组合 (Backend, ScalarType) 进行映射，这样以后就可以根据 (Backend, ScalarType) 获取对应的 RealStorage 类型对象，反过来亦可。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> DL Framework </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Programming (2)</title>
      <link href="/2019/08/14/dp/DP2/"/>
      <url>/2019/08/14/dp/DP2/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章 <a href="2019/08/07/DP1">Dynamic Programming (1)</a> 介绍了动态规划的原理，以及几种常见模型的 DPFE。这篇文章则主要介绍一些实际应用。</p><h2 id="最佳分配问题-ALLOT"><a href="#最佳分配问题-ALLOT" class="headerlink" title="最佳分配问题 ALLOT"></a>最佳分配问题 ALLOT</h2><p>最佳分配问题简称为 ALLOT，描述了如何讲有限资源分配给一些用户，损失（或者利益，损失对应最小化，利益对应最大化）与用户以及分配到的资源量有关。ALLOT 也可以看作是背包问题 KSINT 的一个变种。</p><span id="more"></span><p>假设有 M 单位的资源要分配给 N 个用户，记 C(k,d) 表示分配 d 单位资源给用户 k 时的损失，分配决策按阶段进行，即第一阶段分配 $d_1$ 单位资源给用户 1，第二阶段分配 $d_2$ 单位资源给用户 2，依次进行，定义状态 (k,m) 为阶段 k 时剩余 m 单位资源，阶段 k 分配之前的资源量为 m，阶段 k 的分配损失为 C(k,d)，下一阶段状态为 (k+1,m-d)，于是根据 <a href="2019/08/07/DP1">Dynamic Programming (1)</a> 中式 (1.19) 可知 DPFE 为</p><script type="math/tex; mode=display">f(k,m)=\min_{d \in \{0,...,m\}} \{C(k,d)+f(k+1,m-d)\} \quad (2.1)</script><p>目标是求 f(1,M)，基本条件为 f(N+1,m)=0，其中 $m \ge 0$，这表示资源可以不用全部瓜分完。</p><p>现在假设有 M=4，N=3，且</p><script type="math/tex; mode=display">(C_{k,d})_{k\in \{1,2,3\};d\in \{0,...,4\}}=\begin{pmatrix}\infty & 1.0 & 0.8& 0.4 & 0.0 \\\\ \infty & 1.0& 0.5 & 0.0 & 0.0 \\\\ \infty & 1.0 & 0.6 & 0.3 & 0.0 \end{pmatrix}</script><p>那么，f(1,M)=1.0+0.5+1.0=2.5，最佳分配序列为 $d_1=1,d_2=2,d_3=1$。我们可以根据式 (2.1) 逐步展开计算，下面是代码实现，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">allot</span><span class="token punctuation">(</span>cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    M<span class="token operator">=</span><span class="token number">4</span>    N<span class="token operator">=</span><span class="token number">3</span>    max_float<span class="token operator">=</span><span class="token number">1e8</span>    cost<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span>max_float<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span>max_float<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span>max_float<span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> cache<span class="token punctuation">:</span>        cache_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">def</span> <span class="token function">allot_inner</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> cache <span class="token keyword">and</span> <span class="token punctuation">(</span>k<span class="token punctuation">,</span>m<span class="token punctuation">)</span> <span class="token keyword">in</span> cache_dict<span class="token punctuation">:</span>            <span class="token keyword">return</span> cache_dict<span class="token punctuation">[</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>m<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> k<span class="token operator">>=</span> N<span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span>        min_f<span class="token operator">=</span>max_float        min_ds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> d <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            ds<span class="token punctuation">,</span>f<span class="token operator">=</span>allot_inner<span class="token punctuation">(</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>m<span class="token operator">-</span>d<span class="token punctuation">)</span>            temp<span class="token operator">=</span>cost<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token operator">+</span>f            <span class="token keyword">if</span> min_f <span class="token operator">></span> temp<span class="token punctuation">:</span>                min_f <span class="token operator">=</span> temp                min_ds <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token operator">+</span>ds        <span class="token keyword">if</span> cache <span class="token keyword">and</span> k <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>            cache_dict<span class="token punctuation">[</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>m<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">(</span>min_ds<span class="token punctuation">,</span>min_f<span class="token punctuation">)</span>        <span class="token keyword">return</span> min_ds<span class="token punctuation">,</span> min_f    ds<span class="token punctuation">,</span> f<span class="token operator">=</span>allot_inner<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>M<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"min cost:"</span><span class="token punctuation">,</span>f<span class="token punctuation">,</span><span class="token string">"opt allotments:"</span><span class="token punctuation">,</span> ds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="所有结点对的最短路径问题-APSP"><a href="#所有结点对的最短路径问题-APSP" class="headerlink" title="所有结点对的最短路径问题 APSP"></a>所有结点对的最短路径问题 APSP</h2><p>在图中寻找从任一起点 s 到任一终点 t 之间的最短路径，记图中结点数量为 N，为简单起见，我们假设任意结点对之间没有非正长度的环，并且没有自环（self-loop）。</p><p>可以利用 <a href="2019/08/07/DP1">Dynamic Programming (1)</a> 中的最短路径模型，将 (s,t) 看作变量，求得一系列的最短路径值，然后再求最小值即可，但是这其中肯定存在一些重复计算，所以这里我们讨论更高效率的计算方法。</p><p><strong>Relaxation</strong> </p><p>定义 F(k,p,q) 为从 p 到 q 之间的最短路径长度，k 表示从 p 到 q 最多走 k 步（从一个节点到下一个节点为一步）。借助 <a href="2019/08/07/DP1">Dynamic Programming (1)</a> 中式 (1.27)，DPFE 为</p><script type="math/tex; mode=display">F(k,p,q)=\min \{F(k-1,p,q), \min_{r \in succ(p)} \{b(p,r)+F(k-1,r,q)\}\} \quad(2.2)</script><p>其中 r 是 p 的直接后继节点。基本条件为:</p><ol><li>$F(k,p,q)=0, k \ge 0, p=q$，表示当 p 就是 q 时，最多走 k 步，最短路径长度为 0。</li><li>$F(0,p,q)=\infty, p \ne q$， 表示当 p 不为 q 时，最多走 0 步，最短路径长度为无穷大。</li></ol><p>虽然我们假定没有自环，但是我们依然可以令 $b(p,p)=0$（实际路径中我们可以去掉环即可），那么式 (2.2) 可简化为</p><script type="math/tex; mode=display">\begin{aligned}F(k,p,q)&=\min \{F(k-1,p,q)+b(p,p), \min_{r \in succ(p)} \{b(p,r)+F(k-1,r,q)\}\} \\\\ &=\min_{r \in succ(p)\cup \{p\}} \{b(p,r)+F(k-1,r,q)\} \qquad(2.3) \end{aligned}</script><p><strong>Floyd-Warshall</strong> </p><p>式 (2.2) 这个 DPFE 是一种分而治之的思想：从 p 到 q 最多走 k 步的路径，可以分为从 p 走一步到 r 以及从 r 最多走 k-1 步到 q 两个子路径。还有一种替代方案是从 p 到 r 并且从 r 到 q，其中 p 到 r 的步数不再固定为 1，但是从 p 出发，到达 q 总共最多经过 k 个点，r 就是这 k 个中间点，不妨记这 k 个点为 $\{1,2,…,k\}$，那么求从 p 到 q 并使用 $\{1,2,…,N\}$ 作为可能的中间点的最短路径就是 p 到 q 的全局最短路径。DPFE 为</p><script type="math/tex; mode=display">F(k,p,q)=\min \{F(k-1,p,q), F(k-1,p,k)+F(k-1,k,q)\} \qquad(2.4)</script><p>为了便于理解，我们作如下说明：</p><ol><li>将 N 个节点编号为 $V=\{1,2,…,N\}$，$p,q \in V$</li><li>$F(k,p,q)$ 表示从 p 到 q 且以 $\{1,2,…,k\}$ 作为可能的中间节点</li><li>问题的求解目标为 $F(N,p,q)$</li><li>如何理解式 $(2.4)$？<ul><li>p 到 q 的路径不经过中间点 k，即，使用 $\{1,2,…,k-1\}$ 作为可能的中间节点</li><li>或者 p 到 q 的路径经过中间点 k，即，分为两个子路径 p 到 k 和 k 到 q，这两个子路径均使用 $\{1,2,…,k-1\}$ 作为可能的中间节点</li></ul></li><li>式 $(2.4)$ 这个递归操作需要条件 k&gt;0。k=0 时为基本条件 $F(0,p,q)=0, p=q$，以及 $F(0,p,q)=b(p,q), p\ne q$。前者表示当 p q 为同一节点时，不使用任何中间节点，损失为 0；后者表示当 p q 不同时，不使用任何中间节点，损失为 $b(p,q)$，需要注意这里 q 是 p 的直接后继，如果不是，那么有 $F(0,p,q)=\infty, p \notin succ(p) \cup \{p\}$</li><li>中间点序列 $\{1,2,…,k\}$ 可能会包含 p 和 q，如果包含了的话，由于我们假定所有的环都是正的，所以再求序列最小值的，带环的路径均会被过滤掉，而自环 $b(p,p)=0$，不会影响最短路径的长度，如果路径中出现自环，去掉即可（去掉连续重复的节点，只保留一个）。</li></ol><p>式 (2.2) 中 r 是 p 的后继节点，最多可取 $N-1$ 个节点（假设图中其他节点均为 p 的后继节点，就对应 $N-1$），k 最大为 $N-1$ 步，p 和 q 均各有 N 个取值，所以式 (2.2) 的时间复杂度为 $O(N^4)$，类似地，式 (2.4) 的时间复杂度为 $O(N^3)$。</p><p>实际中要解决 APSP 问题，可以根据式 (2.2) 求出矩阵序列 $\{F^{(1)},F^{(2)},…,F^{(N-1)}\}$，任一矩阵 $F^{(k)}$ 维度为 $N \times N$，$F_{p,q}^{k}$ 表示从 p 到 q 最多走 k 步的最短路径长度，然后求 $\min_{p,q} F_{p,q}^{(N-1)}$ 就是 APSP 的解。</p><p><strong>矩阵乘法</strong></p><p>为了借鉴矩阵乘法的思想，我们首先将式 (2.2) 作变换，</p><script type="math/tex; mode=display">\begin{aligned} F(k,p,q)&=\min \{F(k-1,p,q), \min_{r \in succ(p)} \{b(p,r)+F(k-1,r,q)\}\}\\\\ &= \min_{r \in succ(p)} \{b(p,p)+F(k-1,p,q), b(p,r)+F(k-1,r,q)\}\\\\ &= \min_{r \in succ(p) \cup \{p\}} \{b(p,r)+F(k-1,r,q)\}\\\\ &= \min_{r \in \{1,2,...,N\}} \{b(p,r)+F(k-1,r,q)\} \qquad(2.5) \end{aligned}</script><p>其中，$b(p,r)$ 是事先给定的任意两节点之间的距离，若两节点之间没有边 edge 相连，则距离为 $\infty$，这里称所有节点对之间的距离组成的矩阵为权重矩阵 $W_{N \times N}$。根据式 (2.2) 的基本条件，不难得知 $F^{(0)}$ 矩阵对角线全 0，其余元素均为 $\infty$：</p><script type="math/tex; mode=display">F^{(0)}=\begin{bmatrix}0 & \infty & \cdots & \infty\\\\                    \infty & 0  & \cdots & \infty\\\\                    \vdots & \vdots & \ddots & \vdots\\\\                    \infty & \infty & \cdots & 0 \end{bmatrix}_{N \times N}</script><script type="math/tex; mode=display">W=\begin{bmatrix}0 & w_{12} & \cdots & w_{1N}\\\\                    w_{21} & 0  & \cdots & w_{2N}\\\\                    \vdots & \vdots & \ddots & \vdots\\\\                    w_{N1} & w_{N2} & \cdots & 0 \end{bmatrix}_{N \times N}</script><p>根据式 (2.5)，已知 $F^{(k-1)}$ 求 $F^{(k)}$ 的代码为<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sysF_k<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token operator">*</span>N<span class="token punctuation">]</span><span class="token operator">*</span>N<span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">for</span> q <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>    F_k<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>info<span class="token punctuation">.</span>float_max    <span class="token comment"># F_k[p][q]=0</span>    <span class="token keyword">for</span> r <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>      F_k<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token operator">=</span><span class="token builtin">min</span><span class="token punctuation">(</span>F_k<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token punctuation">,</span>W<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token operator">+</span>F_k_1<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token comment"># F_k[p][q]=F_k[p][q]+W[p][r]*F_k_1[r][q])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>从上面代码片段可见，与矩阵乘法（注释部分）完全一个模样，而我们的目的是为了计算 $F^{(N-1)}$，中间的其他 $F^{(k)}$ 矩阵如无必要，可以不用计算出来，比如下面，</p><script type="math/tex; mode=display">\begin{aligned} F^{(1)}&=W \circ F^{(0)}=W\\\\ F^{(2)}&=W \circ F^{(1)}=W^2\\\\ F^{(3)}&=W \circ F^{(2)}=W^3\\\\ &\vdots\\\\ F^{(N-1)}&=W \circ F^{(N-2)}=W^{(N-1)} \end{aligned} \quad(2.6)</script><p>$\circ$ 表示某种运算符，比如矩阵乘法或者这里的最小值计算，我们改为如下序列计算，</p><script type="math/tex; mode=display">\begin{aligned} F^{(1)}&=W\\\\ F^{(2)}&=W^2=W \circ W\\\\ F^{(4)}&=W^4=W^2 \circ W^2\\\\ &\vdots\\\\ F^{2^{\lceil log(N-1) \rceil}}&=W^{2^{\lceil log(N-1) \rceil}} =W^{2^{\lceil log(N-1) \rceil-1}} \circ W^{2^{\lceil log(N-1) \rceil-1}} \end{aligned} \quad(2.7)</script><p>注意上面 $2^{\lceil log(N-1) \rceil}$ 中的向上取整 $\lceil \cdot \rceil$ 很重要，这保证了 $2^{\lceil log(N-1) \rceil} \ge N-1$，从而 $F^{2^{\lceil log(N-1) \rceil}} \le F^{(N-1)}$ （element-wise comparison）。</p><p>因为结合顺序无关紧要，才使得我们可以从式 (2.6) 可以改写为式 (2.7)，例如</p><script type="math/tex; mode=display">F^{(4)}=W \circ F^{(3)}=W \circ (W \circ F^{(2)})=\cdots =W \circ(W \circ (W \circ W)) \stackrel{*}=(W \circ W) \circ (W \circ W)=W^2 \circ W^2</script><p>将 $\circ$ 替换为 $\min$，即 $\min (W, \min(W, \min(W,W)))=\min(\min(W,W), \min(W,W))$，注意这里的 $\min$ 不是 element-wise operator，就跟矩阵乘法不是矩阵点乘一样。当然，以上内容只是帮助理解，不是式 (2.6) 可以变换为式 (2.7) 的严格证明。</p><p>好了，有了式 (2.7) 就可以更快的计算出 $F^{(M)}, M \ge N-1$，由于 $F^{(k)}$ 单调减，并收敛于 $F^{(N-1)}$，于是 $F^{(M)}$ 就是全局最短路径长度矩阵。</p><p>使用矩阵乘法加速的算法代码为<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sys<span class="token keyword">def</span> <span class="token function">fast_apsp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  k<span class="token operator">=</span><span class="token number">1</span>  F_prev<span class="token operator">=</span>W  <span class="token keyword">while</span> k<span class="token operator">&lt;</span>N<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>    F_next<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span>sys<span class="token punctuation">.</span>info<span class="token punctuation">.</span>float_max<span class="token punctuation">]</span><span class="token operator">*</span>N<span class="token punctuation">]</span><span class="token operator">*</span>N    <span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">for</span> q <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> r <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>          F_next<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token operator">=</span><span class="token builtin">min</span><span class="token punctuation">(</span>F_next<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token punctuation">,</span> F_prev<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token operator">+</span>F_prev<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token punctuation">)</span>    F_prev<span class="token operator">=</span>F_next    k<span class="token operator">*=</span><span class="token number">2</span>  <span class="token keyword">return</span> F_prev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>Floyd-Warshall</strong> 的代码</p><p>考虑式 (2.4)，注意 $F^{(k)}$ 中的 k 表示路径可以经过中间节点 $\{1,2,…,k\}$，所以 $F^{(0)}$ 表示不经过任何中间节点的两点之间最短路径长度矩阵，所以根据基本条件不难得到</p><script type="math/tex; mode=display">F^{(0)}=W=\begin{bmatrix}0 & w_{12} & \cdots & w_{1N}\\\\                    w_{21} & 0  & \cdots & w_{2N}\\\\                    \vdots & \vdots & \ddots & \vdots\\\\                    w_{N1} & w_{N2} & \cdots & 0 \end{bmatrix}_{N \times N}</script><p>根据式 (2.4)，不难写出原始的 <strong>Floyd-Warshall</strong> 算法的代码为<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">F_prev<span class="token operator">=</span>F_0<span class="token keyword">def</span> <span class="token function">floyd_warshall</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>    F_next<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token operator">*</span>N<span class="token punctuation">]</span><span class="token operator">*</span>N    <span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">for</span> q <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>        F_next<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token operator">=</span><span class="token builtin">min</span><span class="token punctuation">(</span>F_prev<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token punctuation">,</span> F_prev<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">+</span>F_prev<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>q<span class="token punctuation">]</span><span class="token punctuation">)</span>    F_prev<span class="token operator">=</span>F_next  <span class="token keyword">return</span> F_prev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="最优字母基数编码树问题-ARC"><a href="#最优字母基数编码树问题-ARC" class="headerlink" title="最优字母基数编码树问题 ARC"></a>最优字母基数编码树问题 ARC</h2><p>ARC 是霍夫曼编码树问题的一个变体。霍夫曼树要满足的条件是节点权值*路径长度，求和最小。比如常见的霍夫曼编码，节点权值对应词频，路径对应单个词的编码长度，加权求和就是编码后的序列总长度最小。构造霍夫曼树可以直接使用贪心算法，给定一个具有权值的节点序列，找出具有最小权值的两个节点，构造出一个子树，这两个节点为子树的子节点，子树的父节点权值为这两个子节点的权值之和，然后将这两个字节点从节点序列中移除，并插入新构造的父节点到节点序列，重复这个过程，直到节点序列中只剩一个节点。这是一个自底向上的构造过程。</p><p>ARC为，给定一个具有构造成本（权值）的节点序列，目标是构造一棵成本最小的树，整棵树的总成本为所有内部节点（internal nodes，包括 root）的成本之和，内部节点的损失为以此内部节点为根节点的子树中所有叶节点的成本之和。给定 $S=(w_0,w_1,…,w_{n-1})$ 为有序序列表示叶节点的权值，定义 $(i,j)$ 的态为 $(w_i,…,w_j)$，那么</p><script type="math/tex; mode=display">f(i,j)=\min_{}\{c(i,j,d)+f(i,d)+f(d+1,j)\}, \quad i<j \qquad(2.8)</script><p>其中 $f(i,j)$ 表示以节点 $(i,…,j)$ 为叶节点的子树总成本， $c(i,j,d)=\sum_{k=i}^j w_k$ 表示这个子树的根节点的成本，这里我们限制为二叉树，所以不难理解式 (2.8)，树的总成本为左子树的总成本与右子树的总成本以及树根节点成本三者之和。d 用于划分，其中 $(i,…,d)$ 为左子树的叶节点，$(d+1,…,j)$ 为右子树的叶节点，无论怎么划分（即选择任何 d 的有效值），以 $(i,…,j)$ 为叶节点的子树的根节点成本 $c(i,j,d)$ 均保持不变。</p><p>最后，目标是计算 $f(0,n-1)$，基本条件为 $f(i,i)=0, \ \forall i \in \{0,1,…,n-1\}$。</p><p>构造 ARC 比构造 Huffman 树多一个限制，那就是给定节点序列后，只能结合两个相邻节点构造一个子树。例如，$S=(1,2,3,4)$，最优树为 $(((1,2),3),4)$，$f(S)=3+6+10=19$（三个内部节点成本之和），再例如 $S=(2,3,3,4)$，那么最优树为 $((2,3),(3,4))$，$f(S)=5+7+12=24$。</p><h2 id="装配线平衡问题-ASMBAL"><a href="#装配线平衡问题-ASMBAL" class="headerlink" title="装配线平衡问题 ASMBAL"></a>装配线平衡问题 ASMBAL</h2><p>一个产品装配需要经过一系列的处理，每个处理步骤均有代价/损失，并且从一个处理站到另一个处理站之间也存在代价。这里举一个简单的例子进行说明，一个处理站看作一条处理线，一次处理为一个阶段 stage，转移发生在从 阶段 k，处理线 i 的节点到另一个位于阶段 k+1 处理线 j 的节点上。处理线之间的切换损失为 c(k,i,j)，通常 c(k,i,i)=0，即不切换处理线，那么切换损失应为 0，除了切换损失，每个节点自身还存在损失，初始状态 s 和终止状态 t 处于标记为 0 的处理线上，这只是为了说明初始时刻和终止时刻产品不应该在任何处理线上，初始决策的损失为 c(0,0,j)，最终决策的损失为 c(N,j,0)（j 为某个处理线）。 </p><p>某种可行的处理使用一个节点表示，记节点标号为 0~13 共 14 个节点，其中特别地 0 和 13 分别表示起始状态和终止状态，即表示不用处理。假设 14 个节点自身的损失分别为</p><script type="math/tex; mode=display">v=(0,7,8,9,5,3,6,4,8,5,4,7,0)</script><p>处理线之间的切换损失如下图，<br><img src="/images/DP2_fig1.png" alt=""></p><p>也可以写成 14x14 的毗邻矩阵。可见，总共有两条处理线。</p><p>在阶段 k，从 i 线到 j 线的损失由两部分组成 $R(k,i,j)=v(k,i)+c(k,i,j)$，DPFE 为</p><script type="math/tex; mode=display">f(k,i)=\min_j \{R(k,i,j)+f(k+1,j)\}</script><p>其中 $f(k,i)$ 表示从阶段 k 并处于线 i 上开始到最终态的损失，问题的目标就是求 $f(0,0)$，基本条件为 $f(k,i)=0, k &gt; N$，N 为总阶段数，图中为 N=6。计算过程如下：</p><script type="math/tex; mode=display">\begin{aligned} f(0,0)=\min \{R(0,0,0)+f(1,0), R(0,0,1)+f(1,1)\}\\\\ f(1,0)=\min \{R(1,0,0)+f(2,0), R(1,0,1)+f(2,1)\}\\\\ f(1,1)=\min \{R(1,1,0)+f(2,0), R(1,1,1)+f(2,1)\}\\\\ \cdots \ (omitted)\end{aligned}</script><h2 id="最佳分派问题-ASSIGN"><a href="#最佳分派问题-ASSIGN" class="headerlink" title="最佳分派问题 ASSIGN"></a>最佳分派问题 ASSIGN</h2><p>集合 B 中的每个成员需要唯一地被赋值为集合 A 中的成员，如何 A 是有序的，那么这个过程也可以看作是 A 的一种排列，例如 $\{1,2,3\}$ 的一种排列为 $\{3,2,1\}$（总共有 3! 种排列）。集合 $A=(a_0,a_1,…,a_{n-1})$ 的某个排列 $B=(b_0,b_1,…,b_{n-1})$ 可按如下过程得到：在阶段 i，赋值 $a_j$ 给 $b_i$，对应的损失为 $c(i,j)$。由于赋值必须是唯一的，所以每个阶段需要跟踪集合 A 中还有多少尚未使用的成员。具体而言，我们记状态为 $(k,S)$，表示阶段 k 集合 A 中尚未使用的成员集合为 S，阶段 k 时选择成员 d，相应的损失记为 $C(k,S,d)$，下一状态为 $(k+1,S-\{d\})$，DPFE 为</p><script type="math/tex; mode=display">f(k,S)=\min_{d \in S} \{C(k,S,d)+f(k+1,S-\{d\})\}</script><p>求解目标为 $f(1,S^{\ast})$，基本条件为 $f(k,S)=0, \ k=n+1 \ or \ S=\emptyset$</p><h2 id="最佳二叉搜索树问题-BST"><a href="#最佳二叉搜索树问题-BST" class="headerlink" title="最佳二叉搜索树问题 BST"></a>最佳二叉搜索树问题 BST</h2><p>假设包含 n 个数据的集合 $X=\{x_0,…,x_{n-1}\}$，并且是 <strong>有序</strong> 的，每个数据 $x_i$ 的被访问概率为 $p(x_i)$，或简写为 $p_i$，且有 $\sum_{i=0}^{n-1}p_i=1$，目标是建立一棵最小损失的二叉搜索树，其中树的损失定义为</p><script type="math/tex; mode=display">\sum_{i=0}^{n-1}(p_i \text{level}(x_i))</script><p>$\text{level}(x_i)$ 表示 $x_i$ 所在节点的深度。需要注意的是，节点不仅可存储在叶节点中，还可以存储在内部节点中。下面我们讨论如何使用 DP 来解决这个问题。</p><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>定义状态 S 为待安排到树中的元素集合，由于构造树是一个递归过程，易知 DPFE 为</p><script type="math/tex; mode=display">f(S)=\begin{cases} \min_{\alpha \in S} \{f(S_l)+f(S_r)+r(\alpha, S)\} & S \ne \emptyset\\\\ 0 & S=\emptyset \end{cases}</script><p>其中 $S_l = \{x \in S: x &lt; \alpha\}, \ S_r = \{x \in S: x &gt; \alpha\}$，决策代价 $r(\alpha, S)=\sum_{x \in S} p(x)$，根节点深度为 1。这个 DPFE 非常简单，不多说。</p><p>以上 $S_l,\ S_r$ 的划分保证了二叉树是 <strong>有序</strong> 的。（若不需要保持有序，此问题与霍夫曼编码相同）</p><p>上式可改写为</p><script type="math/tex; mode=display">f(S)=\begin{cases} \min_{\alpha \in S} \{f(S_l)+f(S_r)+r(\alpha, S)\} & |S|>1\\\\ p(x) & S=\{x\} \end{cases}</script><h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>定义状态为一对整数 $(i,j)$，分别表示数据的起始下标和截止下标，在此范围内的数据是需要被安排进树的，已知数据集合为 $X=\{x_0,…,x_{n-1}\}$，那么 DPFE 为</p><script type="math/tex; mode=display">f(i,j)=\begin{cases} \min_{k \in \{i,...,j\}} \{f(i,k-1)+f(k+1,j)+\sum_{l=i}^j p_l\} & i \le j\\\\ 0 & i > j \end{cases}</script><p>$(i,j)$ 表示待安排进树的节点下标的起止范围，即将从此范围中选择下标为 k 的数据作为当前节点，或称子树根节点，这个子树的所有节点对应数据下标范围为 $(i,j)$, 其中$(i,k-1)$ 用于被安排进当前子树的左子树，$(k+1,j)$ 用于被安排进当前子树的右子树，无论当前选择哪个决策 k，$(i,j)$ 范围内的数据的概率在当前层 level 均需被计算一次，因为是从上到下构造树的，所以每到达一个 level，所有到达这个 level 的数据其访问概率需要被计算一次，在 $f(i,j)$ 中，$(i,j)$ 范围内的数据均到达当前 level，属于待安排进树的数据，所以当前决策损失为累加所有到达当前 level 的数据的访问概率，即 $\sum_{l=i}^j p_l$。</p><p>与方法一同样地可改写上式为</p><script type="math/tex; mode=display">f(i,j)=\begin{cases} \min_{k \in \{i,...,j\}} \{f(i,k-1)+f(k+1,j)+\sum_{l=i}^j p_l\} & i < j\\\\ p_i & i = j \end{cases}</script><h2 id="最佳覆盖问题-COV"><a href="#最佳覆盖问题-COV" class="headerlink" title="最佳覆盖问题 COV"></a>最佳覆盖问题 COV</h2><p>假设有 k 个不同大小的灌木需要在严寒中被保护起来，k 个灌木按大小排序，标号为 0 的灌木尺寸最小，假设灌木的保护措施就是制造覆盖，将其覆盖起来进行保护，大小为 i 的覆盖其制造成本为 $c_i$。由于技术限制，只能制造不超过 n 种尺寸的覆盖，且 $n \le k$，已知大的覆盖能用于保护小的灌木，目标是选择 n 种覆盖尺寸，使得能覆盖所有的灌木，且成本最小。</p><p>使用 DP 解决上述问题，为了方便，我们假设灌木尺寸按从小到达排好序，编号为 $0,1,…,k-1$，编号为 $l$ 的灌木尺寸为 $s_l$，其对应的覆盖制造成本为 $c_{s_l}$，简记为 $c_l$，这里为了使问题简单，我们不考虑使用多个较小尺寸的覆盖来保护较大尺寸的灌木，即，每个灌木只使用单个覆盖。一种显然的想法是，从大到小来制造覆盖，因为大尺寸的覆盖总能保护小尺寸的灌木，令 $j$ 表示当前还可以制造多少种尺寸的覆盖，$l$ 表示当前未得到保护的最大尺寸灌木编号，于是 DPFE 为</p><script type="math/tex; mode=display">f(j,l)=\begin{cases} \min_{d \in \{j-2,...,l-1\}} \{(l-d)c_l+f(j-1,d)\} & j>1\\\\ (l+1)c_l & j=1 \end{cases}</script><p>d 表示灌木尺寸范围的起始下标（exclusive），也就是说当前决策是制造尺寸为 $s_l$ 的覆盖，用于保护 $\{d+1,…,l\}$ 范围内的灌木。显然 d 最大为 $l-1$，此时当前决策所制造的覆盖只用于保护编号为 $l$ 的灌木，d 最小为 $j-2$，这是因为当前决策所制造的覆盖最多能用于保护灌木的编号为 $\{j-1,…,l\}$，此时剩余尚未保护的灌木编号 $\{0,1,…,j-2\}$ 共 $j-1$ 种尺寸，正好剩余可以制造的覆盖尺寸也是 $j-1$ 种，两者一一对应。</p><p>再看基本条件，$f(j,l)=(l+1)c_l, j=1$，表示当前只能制造一种尺寸的覆盖时，那只能制造当前尚未得到保护的最大灌木的尺寸的覆盖，当前最大尺寸的灌木编号为 $l$，由于只有这一种尺寸的覆盖可以制造，其必须保护 $0,…,l$ 范围内的灌木。</p><h2 id="时限调度问题-DEADLINE"><a href="#时限调度问题-DEADLINE" class="headerlink" title="时限调度问题 DEADLINE"></a>时限调度问题 DEADLINE</h2><p>有一个进程集合，其中每个进程的执行时间均为单位时间，同时每个进程也各自有一个最后期限，如果在最后期限之前完成，则具有收益，否则收益为 0，现在要选择一个最优进程子集，放置在单处理器上执行，并且收益要最大。这个问题当然也可以使用贪心算法来解决，那些收益较大的进程我们总希望能被执行，无论是先执行还是后执行，反正只要在其最后期限之前被执行即可，那么不如优先执行这些收益最大的进程，即， <strong>每一步优先执行收益最大的进程</strong>。</p><p>假设进程编号为 $S^{\ast}=\{0,1,2,3,4\}$，对应收益为 $p=\{10,15,20,1,5\}$，截止期限为 $t=\{1,2,2,3,3\}$。贪心算法的代码如下：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npt<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>p<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>m<span class="token operator">=</span><span class="token number">0</span>   <span class="token comment"># 总收益</span>n<span class="token operator">=</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 最多决策数</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>  idx<span class="token operator">=</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>t<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token keyword">if</span> idx<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>    <span class="token keyword">break</span>   <span class="token comment"># 全部超出最后期限，决策结束</span>  c<span class="token operator">=</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>p<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 尚未超出期限的进程的最大收益，当前最优决策的收益（贪心策略）</span>  <span class="token keyword">if</span> c <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>    <span class="token keyword">break</span>  m<span class="token operator">+=</span>c  idx<span class="token operator">=</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>p<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span>idx<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 当前决策的进程的编号</span>  p<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">1e8</span>                   <span class="token comment"># 标记收益为负，表示后续决策不再考虑此进程</span>  t<span class="token operator">-=</span><span class="token number">1</span>                          <span class="token comment"># 更新进程的最后期限</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最大收益为'</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span>    <span class="token comment"># 40</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>使用 DP 解决这个问题，定义状态为 $(k,S)$，其中 k 为阶段编号，S 为所有尚未执行的进程集合，每一步的决策 d 是从 S 中选出，决策后的下一状态为 $(k+1,S-\{d\})$，根据最后期限从近到远对进程进行排序，DPFE 为</p><script type="math/tex; mode=display">f(k,S)=\max_{d \in S}\{c(d|S)+f(k+1,S-\{d\})\}</script><p>其中，当决策 d 的最后期限大于等于阶段 k 时（k 从 1 开始计算）$c(d|S)=w_d$ ，否则 $c(d|S)=0$。目标是求 $f(1,S^{\ast})$，基本条件为 $f(k,S)=0, k=n+1 \ or \ S=\emptyset$，其中 n 为进程数。使用上述例子，代码如下<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">t<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>p<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>S<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span>n<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">profit</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>d<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">return</span> p<span class="token punctuation">[</span>d<span class="token punctuation">]</span> <span class="token keyword">if</span> t<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token operator">>=</span>k <span class="token keyword">else</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">deadline</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>S<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">return</span> <span class="token number">0</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>S<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span> <span class="token keyword">or</span> k<span class="token operator">==</span>n<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">else</span> \    <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">[</span>profit<span class="token punctuation">(</span>k<span class="token punctuation">,</span>S<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span>deadline<span class="token punctuation">(</span>k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>S<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token operator">+</span>S<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>S<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>deadline<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> S<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 40</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="折现利润问题-DPP"><a href="#折现利润问题-DPP" class="headerlink" title="折现利润问题 DPP"></a>折现利润问题 DPP</h2><p>假设一个湖中第一年开始时有 $b_1$ 条鱼，第 t 年开始时的鱼数为 $b_t$，在第 t 年中售出 $x_t$ 条鱼，收益为 $r(x_t)$，捕鱼成本为 $c(x_t,b_t)$，鱼可以再生，再生长率为 s，表示某一年年初的鱼数量是上一年年底鱼数量的 s 倍，计划展望期为 $1,…,T$，即最多 T 年卖完所有鱼，其中货币年贬值率为 y，决策为 $x_t$ 表示 第 t 年卖出多少鱼，要求最大净收益，状态为 $(t,b)$，其中 t 表示年份，b 表示第 t 年初的鱼数，DPFE 为</p><script type="math/tex; mode=display">f(t,b)=\begin{cases} \max_{x_t \in \{0,...,b\}} \{r(x_t)-c(x_t,b)+\frac 1 {1+y} f(t+1, \lfloor s(b-x_t) \rfloor)\} & t \le T\\\\ 0 & t=T+1 \end{cases}</script><h2 id="编辑长度问题-EDP"><a href="#编辑长度问题-EDP" class="headerlink" title="编辑长度问题 EDP"></a>编辑长度问题 EDP</h2><p>编辑长度问题通常用于字符串的非精确匹配问题。记 $\Sigma$ 为一有限字符集，给定两个字符串 $x\in \Sigma^m, \ y \in \Sigma^n$，或者写为 $x=x_1\cdots x_m, \ y=y_1 \cdots y_n$，任务是将 x 转变为 y，并且只能使用如下三种编辑操作：</p><ul><li>删除操作 D。从某字符串中删除一个字符，损失为 $c(D)$</li><li>插入操作 I。向某字符串中插入一个字符，损失为 $c(I)$</li><li>替换操作 R。将某字符串中某个字符替换为另一个字符，损失为 $c(R)$，如果替换前后字符相同，则 $c(R)=0$</li></ul><p>要求一个编辑序列，使得 x 转变为 y，且具有最小损失，这里损失为所有操作的损失之和。DPFE 为</p><script type="math/tex; mode=display">f(i,j)=\begin{cases} jI & i=0\\\\ iD & j=0\\\\ \min \{f(i-1,j)+c(D),f(i,j-1)+c(I),f(i-1,j-1)+c(R)\} & i>0,j>0 \end{cases}</script><p>其中 $f(i,j)$ 表示从 $X_i$ 到 $Y_j$ 需要的操作损失，$X_i$ 为 x 的前 i 个字符形成的子串，$Y_j$ 为 y 的前 j 个字符形成的子串，当 i=0 时，向 $X_i$ 插入 j 个字符得到 $Y_j$，当 j=0 时，将 $X_i$ 删除 i 个字符得到 $Y_j$，当 i&gt;0 且 j&gt;0 时，从 $X_i$ 变换到 $Y_j$，总共可以有以下三种决策/操作，取损失最小的决策：</p><ul><li>删除 $X_i$ 的第 i 个字符，然后从 $X_{i-1}$ 变换到 $Y_j$，两部分损失分别为 $c(D)$ 和 $f(i-1,j)$</li><li>从 $X_i$ 变换到 $Y_{j-1}$，然后再在末尾插入一个字符得到 $Y_j$，两部分的操作损失分别为 $f(i,j-1)$ 和 $c(I)$</li><li>两个子串的最后一个字符，使用替换，$x_i \rightarrow y_j$，然后再从 $X_{i-1}$ 变换到 $Y_{j-1}$ 即可得到 $X_i$ 变换到 $Y_j$ 的过程，两部分的损失分别为 $f(i-1,j-1)$ 和 $c(R)$</li></ul><p>还可以写成如下形式的 DPFE</p><script type="math/tex; mode=display">f(X_i,Y_j)=\begin{cases} jI & i=0\\\\ iD & j=0\\\\ \min_{d \in \{D,I,R\}} \{f(t(X_i,Y_j,d))+c(d)\} & i>0,j>0\end{cases}</script><p>其中变换定义为</p><script type="math/tex; mode=display">t(X_i,Y_j,D)=(X_{i-1},Y_j)\\\\ t(X_i,Y_j,I)=(X_i,Y_{j-1})\\\\ t(X_i,Y_j,R)=(X_{i-1},Y_{j-1})</script>]]></content>
      
      
      
        <tags>
            
            <tag> math </tag>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Programming (1)</title>
      <link href="/2019/08/07/dp/DP1/"/>
      <url>/2019/08/07/dp/DP1/</url>
      
        <content type="html"><![CDATA[<p>我计划开启一系列动态规划的方法介绍，主要参考 《Dynamic Programming · A Computational Tool》这本书。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>动态规划用于解决一类优化问题，顺序地做出决策，每一次决策使得问题转变为对一个子问题的优化，直到问题解决，这个决策序列就是原始问题的最优解。我们也可以将 问题/子问题 看作状态，决策就是状态间的转移，问题得到解决就对应着<code>结束状态</code>。<br><span id="more"></span></p><h2 id="优化原理"><a href="#优化原理" class="headerlink" title="优化原理"></a>优化原理</h2><blockquote><p>一个最优决策满足：无论问题初始状态和初始决策是什么，剩余的决策序列构成做出初始决策之后问题状态的最优解。</p></blockquote><p>以最短路径问题为例说明：在一个指定了起点和终点的有权路径图中，无论之前选择了什么路径，我们必须保证从当前节点起，剩余的路径选择必须是最优的。<del>这是一种递归的处理方式，要解这个问题，直觉告诉我们似乎可以采用逆推法（隐马尔可夫预测问题的求解），这个直觉很重要，因为下文将会用到它。</del></p><h3 id="顺序决策过程"><a href="#顺序决策过程" class="headerlink" title="顺序决策过程"></a>顺序决策过程</h3><p>考虑具有如下形式的优化问题：$opt_{d \in \Delta} \{H(d)\}$，其中 d 为决策，决策空间为 $\Delta$，H 为目标函数，H(d) 的最优解记为 $d^{\ast}$：$d^{\ast}=\arg opt_d \{H(d)\}$。动态规划问题则要求寻找有序决策集 $\{d_1,…,d_n\}$，使得目标函数 $h(d_1,…,h_n)$ 取得最优 $H^{\ast}$。</p><p>我们可以枚举 $\{d_1,…,d_n\}$ 所有可能的取值，然后代入目标函数进行计算，这就是 “暴力” 解法，但是这只在决策空间较小时有效，在决策空间很大时，这种方法效率非常低不可取，所以此时我们需要按顺序做出决策 $d_1,…,d_n$，使得</p><script type="math/tex; mode=display">\begin{aligned}H^{\ast}&=opt_{(d_1,...,d_n)\in \Delta} \{h(d_1,...,d_n)\}\\\\ &=opt_{d_1 \in D_1} \{opt_{d_2 \in D_2}\{...\{opt_{d_n \in D_n}\{h(d_1,...,d_n)\}\}...\}\} \quad(1.1)\end{aligned}</script><p>其中 $(d_1,…,d_n) \in \Delta=D_1 \times … \times D_n$。通常，第 i 个决策空间依赖于前面所有的决策：$d_i \in D_i(d_1,…,d_{i-1})$，于是式 (1.1) 可改写为</p><script type="math/tex; mode=display">\begin{aligned}H^{\ast}&=opt_{(d_1,...,d_n)\in \Delta} \{h(d_1,...,d_n)\}\\\\ &=opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{h(d_1,...,d_n)\}\}...\}\} \quad(1.2)\end{aligned}</script><p>式 (1.2) 的优化操作是一个嵌套结构，可以由内向外解决问题，解最内层的优化问题，此时前序所有决策均看作已知，可得到最优 $d_n$，记作 $d_n^{\ast}(d_1,…,d_{n-1})$，可以将 $d_n^{\ast}$ 看作是其前序决策的函数。向外逆推，直到解出最外层优化问题 $opt_{d_1 \in D_1} \{h(d_1,d_2^{\ast},…,d_n^{\ast} \}$ 的解 $d_1^{\ast}$。</p><p>如果改变决策顺序目标函数的最优解相同，如</p><script type="math/tex; mode=display">\begin{aligned} &opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)} \{... \{opt_{d_n \in D_n(d_1,...,d_{n-1})} \{h(d_1,...,d_n)\}\}...\}\}\\\\ = \ & opt_{d_n \in D_n} \{opt_{d_{n-1} \in D_{n-1}(d_n)} \{... \{opt_{d_1 \in D_n(d_2,...,d_n)} \{h(d_1,...,d_n)\}\}...\}\} \quad(1.3) \end{aligned}</script><p>那么决策空间 $D_i$ 可能会跟之前有所不同，因为此时 $D_i$ 依赖于 $(d_{i+1},…,d_n)$，所以问题求解的效率会随着决策顺序的变化而有所改变。</p><p>回到前面式 (1.2)，假设我们暂时做出最外层决策 $d_1$，此时 $d_1$ 是否是最优决策还尚未可知，但是根据前面所说的优化原理，无论之前做出什么决策，之后的决策需要保证是最优的，所以有</p><script type="math/tex; mode=display">\begin{aligned}H^{\ast}&=opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{h(d_1,...,d_n)\}\}...\}\}\\\\ &=opt_{d_1 \in D_1}\{h(d_1,d_2^{\ast}(d_1),...,d_n^{\ast}(d_1)\} \qquad \qquad(1.4) \end{aligned}</script><p>其中 $d_i^{\ast}(d_1), \ i&gt;1$ 可以看作是输入参数 $d_1$ 的偏函数（partial function）。最外层决策的最优解则为 $d_1^{\ast}=\arg opt_{d_1 \in D_1} \{h(d_1,d_2^{\ast}(d_1),…,d_n^{\ast}(d_1))\}$，可以看出，$d_1$ 与其后序的决策互相耦合，要解这样的问题还是有点棘手。</p><h4 id="目标函数可分"><a href="#目标函数可分" class="headerlink" title="目标函数可分"></a>目标函数可分</h4><p>一种方法是将 $d_1$ 决策与 $d_2,…,d_n$ 决策独立开来，也就是说通过解决形如 $opt_{d_1 \in D_1}\{H’(d_1)\}$ 问题的最优解以得到 $d_1$ 的最佳决策，这是一种贪心算法，这种算法在局部最优 $opt_{d_1}\{H’(d_1)\}$ 与全局最优 $H^{\ast}$ 一致的情况下是有效的。我们先分析这种特殊情况，因为它足够简单：假设目标函数 h 强可分，即</p><script type="math/tex; mode=display">h(d_1,...,d_n)=C_1(d_1) \circ C_2(d_2) \circ ... \circ C_n(d_n) \qquad (1.5)</script><p>其中 $C_i$ 是决策 $d_i$ 关联的决策损失函数，$\circ$ 是某种关联二元操作（例如 加 或 乘）并具有属性 </p><script type="math/tex; mode=display">opt_d\{a \circ C(d)\}=a \circ opt_d\{C(d)\}</script><p>其中 a 不依赖于决策 d。在序列决策过程中，损失 $C_n$ 不仅依赖于 $d_n$，还依赖于当前问题所处的状态 $(d_1,d_2,…,d_{n-1})$，所以改写上式为</p><script type="math/tex; mode=display">h(d_1,...,d_n)=C_1(d_1|\emptyset) \circ C_2(d_2|d_1) \circ ... \circ C_n(d_n|d_1,...,d_{n-1}) \qquad(1.6)</script><p>定义如果目标函数 h 满足</p><script type="math/tex; mode=display">h(d_1,...,d_n)=C_1(d_1) \circ C_2(d_1,d_2) \circ ... \circ C_n(d_1,...,d_n) \qquad(1.7)</script><p>那么称其弱可分（强可分是弱可分的一种特殊情况），此时有</p><script type="math/tex; mode=display">\begin{aligned} & opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{h(d_1,...,d_n)\}\}...\}\}\\\\ = \ & opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{C_1(d_1) \circ C_2(d_1,d_2) \circ ... \circ C_n(d_1,...,d_n)\}\}...\}\}\\\\ = \ & opt_{d_1 \in D_1} \{C_1(d_1|\emptyset) \circ opt_{d_2 \in D_2(d_1)}\{C_2(d_1,d_2) \circ ... \circ \{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{C_n(d_1,...,d_n)\}...\}\} \qquad(1.8) \end{aligned}</script><p>最后一个等式根据 $\circ$ 操作的属性推导。</p><p>令 $f(d_1,…,d_n)$ 表示序列决策过程在已经做出决策 $d_1,…,d_{i-1}$ 时的最优解，即</p><script type="math/tex; mode=display">f(d_1,...,d_{i-1})=opt_{d_i}\{opt_{d_{i+1}}\{... \{opt_{d_n} \{C_i(d_i|d_1,...,d_{i-1}) \circ C_{i+1}(d_{i+1}|d_1,...,d_i) \circ ... \circ C_n(d_n|d_1,...,d_{n-1}) \}\}...\}\} \ (1.9)</script><p>其中因为篇幅起见省略了每个决策的取值空间 $D_i$。现在序列决策过程可表示为</p><script type="math/tex; mode=display">\begin{aligned}f(\emptyset)&=opt_{d_1}\{opt_{d_2}\{...\{opt_{d_n}\{C(d_1|\emptyset) \circ C_2(d_2|d_1) \circ ... \circ C_n(d_n|d_1,...,d_{n-1})\}\}...\}\}\\\\ &opt_{d_1}\{C_1(d_1|\emptyset) \circ opt_{d_2}\{C(d_2|d_1) \circ...\circ opt_{d_n}\{C_n(d_n|d_1,...,d_{n-1})\}...\}\}\\\\ &opt_{d_1}\{C_1(d_1|\emptyset) \circ f(d_1)\}  \qquad \quad (1.10) \end{aligned}</script><p>一般地，我们有</p><script type="math/tex; mode=display">f(d_1,...,d_{i-1})=opt_{d_i \in D_i(d_1,...,d_{i-1})}\{C_i(d_i|d_1,...,d_{i-1})\circ f(d_1,...,d_i)\} \qquad(1.11)</script><p>于是我们得到问题的递归函数形式，这就是优化问题的动态规划函数方程（DPFE）。</p><h3 id="DPFE"><a href="#DPFE" class="headerlink" title="DPFE"></a>DPFE</h3><p>求解 DPFE 中的 $f(d_1,…,d_{i-1})$，定义状态 $S=(d_1,…,d_{i-1})$，那么 $i=|S|+1=|\{d_1,…,d_{i-1}\}|+1$，于是可以改写 DPFE 为以下形式，</p><script type="math/tex; mode=display">f(S)=opt_{d_i \in D_i(S)}\{C_i(d_i|S) \circ f(S')\} \qquad (1.12)</script><p>其中 $S’=(d_1,…,d_i)$ 是下一状态，$\emptyset$ 是初始状态。记状态空间为 $\mathcal S$，由于 DPFE 是递归的，要终止递归，则要求具备一些基本情况（或称边界条件），例如 $f(S_0)=b, \ S_0 \in \mathcal S_{base}$，对于某个基本（终止）态 $S_0$，$f(S_0)$ 不使用 DPFE 计算其值，而是有一个给定的常数值 b，这就表示到达基本态时，递归结束。</p><p>值得注意的是决策序列的长度 n 并非固定，当决策使得目标到达基本态时结束决策过程。前面我们定义状态 S 表示已经做过的决策，下一决策 d 则从 D(S) 中进行选择，但实际上为了表示方便，直接定义状态 S 为下一决策 d 的可选决策空间，即 $d \in S$，于是 DPFE 变为</p><script type="math/tex; mode=display">f(S)=opt_{d \in S} \{C(d|S) \circ f(S')\} \qquad (1.13)</script><p>我们可以使用状态转移系统或者有向图对简单序列决策过程进行建模，状态 S 为节点，决策 d 使得状态从 S 转移到 S’，D(S) 表示处于状态 S 时的决策空间。考虑使用有向图建模，节点表示 DPFE 的状态，边表示状态间的转移，转移对应着决策，边标记为 b(S,S’)，表示决策 d 的损失 C(d|S)，其中下一状态 $S’=T(S,d), \ T: \mathcal S \times D \rightarrow \mathcal S$，T 是转移函数，于是 DPFE 转变为</p><script type="math/tex; mode=display">f(S)=opt_S\{b(S,S') \circ f(S')\} \qquad(1.14)</script><p>DPFE 的反转形式为</p><script type="math/tex; mode=display">f'(S)=opt_{S'}\{f'(S') \circ b(S',S)\} \qquad(1.15)</script><p>其中 f’(S) 表示从基本态 $S_0$ 到状态 S 的最优解，注意与前面 f(S) 表示从状态 S 到基本态 $S_0$ 的最优解区分开来。式 (1.14) 为后向形式（backward），式 (1.15) 为前向形式（forward）。</p><h3 id="动态规划的基本要素"><a href="#动态规划的基本要素" class="headerlink" title="动态规划的基本要素"></a>动态规划的基本要素</h3><p>动态规划的基本形式为</p><script type="math/tex; mode=display">f(S)=opt_{d \in D(S)} \{R(S,d) \circ f(T(S,d))\}  \quad (1.16)</script><p>其中，S 表示状态空间 $\mathcal S$ 中的某个状态，d 是决策空间 D(S) 中的某个决策，R(S,d) 是收益函数（或称损失函数，记为 C(d|S)，收益对应最大化，损失对应最小化），T(S,d) 是转移函数，$\circ$ 是二元操作符。为简单起见，我们只考虑离散情况。</p><h3 id="线性搜索"><a href="#线性搜索" class="headerlink" title="线性搜索"></a>线性搜索</h3><p>现在我们来看一个实际例子。问题是需要排列一个长度为 N 的数组 A 中的元素，元素 x 具有概率 $p_x$，通过最小化排列的损失来优化线性搜索过程，例如 A={a,b,c}，且 $p_a=0.2,p_b=0.5,p_c=0.3$，于是共有 6 中排列方式 abc,acb,bac,bca,cab,cba（注意：每个排列均代表一种决策序列），其中 bca 排列的损失为 1.7，计算如下：</p><ol><li>Strong separable，方法 S<br>$1p_b+2p_c+3p_a$</li><li>Weak separable，方法 W<br>$(p_a+p_b+p_c)+(p_a+p_c)+(p_a)$</li></ol><p>最优排列问题可看作是序列决策过程，每个决策用于决定将 A 的元素置于排列后 A’ 的哪个位置上。决策的损失可互相独立（强可分），即方法 S 损失定义为：元素 x 的损失为 $ip_x$，其中 i 为 x 在 A’ 中位置；对于 W 方法，决策的损失依赖于决策的顺序，或者说依赖于决策空间，如果以从 A’ 的开始到最后这样的顺序进行决策，还以 bca 排列为例说明，第一次决策的空间为 {a,b,c}，第一次决策选择 b 置于 A’ 第一个位置，然后第二次决策空间为 {a,c}… 依次类推，决策损失与决策空间相关，定义为决策空间中各元素概率之和 $\sum_{x\in D_i} p_x$。</p><p>假设决策顺序为 i=1,2,3，那么对应的决策空间为 $D_1=A,D_2=A-\{d_1\},D_3=A-\{d_1,d_2\}$，方法 S 的目标函数为 $h(d_1,d_2,d_3)=1p_{d_1}+2p_{d_2}+3p_{d_3}$，于是有</p><script type="math/tex; mode=display">\begin{aligned}f(\emptyset)&=\min_{d_1\in A}\{\min_{d_2\in A-\{d_1\}}\{\min_{d_3\in A-\{d_1,d_2\}}\{1p_{d_1}+2p_{d_2}+3p_{d_3}\}\}\}\\\\ &=\min_{d_1\in A}\{1p_{d_1}+\min_{d_2 \in A-\{d_1\}}\{2p_{d_2}+\min_{d_3\in A-\{d_1,d_2\}}\{3p_{d_3}\}\}\} \end{aligned}</script><p>方法 W 的目标函数为 $h(d_1,d_2,d_3)=\sum_{x \in A}p_x+\sum_{x\in A-\{d_1\}}p_x+\sum_{x \in A-\{d_1,d_2\}}p_x$，于是有</p><script type="math/tex; mode=display">\begin{aligned}f(\emptyset)&=\min_{d_1\in A}\{\min_{d_2\in A-\{d_1\}}\{\min_{d_3\in A-\{d_1,d_2\}}\{\sum_{x \in A}p_x+\sum_{x\in A-\{d_1\}}p_x+\sum_{x \in A-\{d_1,d_2\}}p_x\}\}\}\\\\ &=\min_{d_1\in A}\{\sum_{x \in A}p_x+\min_{d_2 \in A-\{d_1\}}\{\sum_{x\in A-\{d_1\}}p_x+\min_{d_3\in A-\{d_1,d_2\}}\{\sum_{x \in A-\{d_1,d_2\}}p_x\}\}\} \end{aligned}</script><p>有了损失的计算方法之后，<strong>线性搜索</strong> 就是依次计算并比较所有排列的损失，具有最小损失的就是最优排列。经过计算发现，bca 就是最佳排列。</p><h3 id="问题的表示和解"><a href="#问题的表示和解" class="headerlink" title="问题的表示和解"></a>问题的表示和解</h3><p>上一小节中的例子可以使用 DP 求解。定义状态 S 为元素的集合，可从中选择决策来确定哪个元素应该放置在 A’ 中的哪个位置。DPFE 的形式如下</p><script type="math/tex; mode=display">f(S)=\min_{x \in S} \{C(x|S)+f(S-\{x\})\}     \quad(1.17)</script><p>其中 $S \in 2^A$，$2^A$ 是 A 的幂集。基本态 $f(\emptyset)=0$，我们目标是要求出 $f(A)$。</p><p>注意这是前向形式的 DPFE。要写成这是后向形式的 DPFE，则根据式 (1.15) 改写如下</p><script type="math/tex; mode=display">f(S)=\min_{S'} \{C(x|S')+f(S')\}     \quad(1.18)</script><p>其中 $S \in 2^A$，此时我们目标是求 $f(\emptyset)$，基本态 $f(A)=0$。S’ 是 S 的前导状态，从前导状态 S’ 经过决策 x 到达状态 S。</p><p>基于方法 W，损失函数为</p><script type="math/tex; mode=display">C_W(x|S)=\sum_{y\in S}p_y</script><p>基于上一小节的讨论可知，当前的损失与当前决策 x 无关，而依赖于临决策之前的状态 S 有关，即 S 中各元素的概率和。</p><p>基于方法 S，那么损失函数为</p><script type="math/tex; mode=display">C_S(x|S)=(N+1-|S|)p_x</script><p>可见此时损失只与当前决策 x 以及决策的序号有关，其中与序号有关是假定了第一个决策确定某元素置于 A’ 的第一个位置，第二个决策确定 A’ 第二个位置上的元素…依次类推。如果决策顺序反过来，即第一个决策确定 A’ 最后一个位置上的元素，那么损失函数需要修改为 $C_S’(x|S)=|S|p_x$。如果将 S 中元素按概率降序排列，事实表明第一个元素（具有最大概率值）将会最小化 $C(x|S)+f(S-\{x\})$，这是一种贪心策略，即只求当前状态下的最优解。事实上确实存在一类 DP 问题用贪心策略也可解决，这个我们暂时不讨论。</p><p>现在我们来看下如何解 DP 问题，以式 (1.17) 表示的 DPFE 为例进行说明：</p><script type="math/tex; mode=display">\begin{aligned} f(\{a,b,c\}) &= \min\{C(a|\{a,b,c\})+f(\{b,c\}), C(b|\{a,b,c\})+f(\{a,c\}), C(c|\{a,b,c\})+f(\{a,b\})\}\\\\ f(\{b,c\}) &= \min\{C(b|\{b,c\}+f(\{c\}),C(c|\{b,c\}+f(\{b\})\}\\\\ f(\{a,c\}) &= \min\{C(a|\{a,c\}+f(\{c\}),C(c|\{a,c\}+f(\{a\})\}\\\\ f(\{a,b\}) &= \min\{C(a|\{a,b\}+f(\{b\}),C(c|\{a,b\}+f(\{a\})\}\\\\ f(\{c\}) &= \min \{C(c|\{c\})+f(\emptyset)\}\\\\ f(\{b\}) &= \min \{C(b|\{b\})+f(\emptyset)\}\\\\ f(\{a\}) &= \min \{C(a|\{a\})+f(\emptyset)\} \\\\ f(\emptyset) &= 0 \end{aligned}</script><p>其中损失函数可以分别使用方法 S 和方法 W 进行代入计算，这里略。</p><p>再以式 (1.18) 表示的 DPFE 进行说明：</p><script type="math/tex; mode=display">\begin{aligned} f(\{a,b,c\}) &= 0\\\\ f(\{b,c\}) &= \min\{C(a|\{a,b,c\}+f(\{a,b,c\})\}\stackrel W=\min \{1.0+0\}=1.0 \\\\ f(\{a,c\}) &= \min\{C(b|\{a,a,c\}+f(\{a,b,c\})\}\stackrel W=\min \{1.0+0\}=1.0\\\\ f(\{a,b\}) &= \min\{C(c|\{a,b,c\}+f(\{a,b,c\})\}\stackrel W=\min \{1.0+0\}=1.0\\\\ f(\{c\}) &= \min \{C(a|\{a,c\})+f(\{a,c\}), C(b|\{b,c\})+f(\{b,c\})\}\stackrel W = \min \{0.5+1.0,0.8+1.0\}=1.5\\\\ f(\{b\}) &= \min \{C(a|\{a,b\})+f(\{a,b\}), C(c|\{b,c\})+f(\{b,c\})\}\stackrel W = \min \{0.7+1.0,0.8+1.0\}=1.7\\\\ f(\{a\}) &= \min \{C(b|\{a,b\})+f(\{a,b\}), C(c|\{a,c\})+f(\{a,c\})\}\stackrel W = \min \{0.7+1.0,0.5+1.0\}=1.5\\\\ f(\emptyset) &= \min \{C(a|a)+f(\{a\}), C(b|b)+f(\{b\}), C(c|c)+f(\{c\})\}\stackrel W = \min \{0.2+1.5,0.5+1.7,0.3+1.5\}=1.7 \end{aligned}</script><p>以上式中 $\stackrel W=$ 之后部分均表示使用方法 W 进行计算，这是为了演示，方法 S 的代入计算略。</p><h3 id="带阶决策"><a href="#带阶决策" class="headerlink" title="带阶决策"></a>带阶决策</h3><p>第一次决策记为阶 1，第二次决策记为阶 2… 依次类推。将阶号包含进状态 S 的定义中有时候会带来方便甚至是非常有必要的。还以前面的例子进行说明，DPFE 形式 (1.17) 可改写为</p><script type="math/tex; mode=display">f(k,S)=\min_{x \in S} \{C(x|k,S)+f(k+1,S-\{x\})\} \quad(1.19)</script><h3 id="Path-States"><a href="#Path-States" class="headerlink" title="Path-States"></a>Path-States</h3><p>状态 S 可以定义为当前已经做过的决策 $(d_1,…,d_{i-1})$，在有向图中用节点表示状态，状态 S 与初始态 $\emptyset$ 到状态 S 之间的路径有关联（其实这个路径也可以表示为 $(d_1,…,d_{i-1})$），需要特别注意的是，前面的状态 S 是无序的，比如 S={a,b}，表示当前已经做出了决策 a 和 b（或者说做出决策选择了 a 和 b，读者根据具体语境进行调整理解），至于决策 a 和 b 的顺序则未定义，而这里 Path-States 中的状态是有序的，S=(a,b)，表示当前已经做出两个决策，第一个决策是 a 且第二个决策是 b。于是此时 DPFE 的形式可写为</p><script type="math/tex; mode=display">f(S)=\min_{x \notin S} \{C(x|S)+f(S + (x))\} \qquad(1.20)</script><p>前面线性搜索一节中的例子计算过程为</p><script type="math/tex; mode=display">\begin{aligned} f(\emptyset) &= \min \{C(a|\emptyset)+f(a),C(b|\emptyset)+f(b),C(c|\emptyset)+f(c)\}\stackrel S= \min\{0.2+1.9,0.5+1.2,0.3+1.6\}=1.7\\\\ f(a) &= \min \{C(b|a)+f(ab), C(c|a)+f(ac)\}\stackrel S= \min\{2*0.5+0.9,2*0.3+1.5\}=1.9\\\\ f(b) &= \min \{C(a|b)+f(ba), C(c|b)+f(bc)\}\stackrel S= \min\{2*0.2+0.9,2*0.3+0.6\}=1.2\\\\ f(c) &= \min \{C(a|c)+f(ca), C(b|c)+f(cb)\}\stackrel S= \min\{2*0.2+1.5,2*0.5+0.6\}=1.6\\\\ f(ab) &= \min \{C(c|ab)+f(abc)\}\stackrel S= 3*0.3=0.9\\\\ f(ac) &= \min \{C(b|ac)+f(acb)\}\stackrel S= 3*0.5=1.5\\\\ f(ba) &= \min \{C(c|ba)+f(bac)\}\stackrel S= 3*0.3=0.9\\\\ f(bc) &= \min \{C(a|bc)+f(bca)\}\stackrel S= 3*0.2=0.6\\\\ f(ca) &= \min \{C(b|ca)+f(cab)\}\stackrel S= 3*0.5=1.5\\\\ f(cb) &= \min \{C(a|cb)+f(cba)\} \stackrel S= 3*0.2=0.6\\\\ f(abc) &= f(acb)=f(bac)=f(bca)=f(cab)=f(cba)=0 \end{aligned}</script><p>由于状态是有序的，所以共有 $N!$ 个基本态，损失函数依然可以使用方法 S 和方法 W 计算，例如使用方法 S，损失 $C(c|ab)$ 表示第三次决策使用 c，那么根据方法 S 的定义有 $C(c|ab)=3p_c=3*0.3=0.9$。上面计算中 $\stackrel S=$ 之后部分均表示使用方法 S 进行计算。方法 W 的计算略。</p><h3 id="松弛-Relaxation"><a href="#松弛-Relaxation" class="headerlink" title="松弛 Relaxation"></a>松弛 Relaxation</h3><p>松弛在数学中指通过某种迭代方法逐步得到更好的近似解。考虑一个有限集合 $\{a_1,…,a_N\}$，其最小值可以通过计算结对元素最小化来求解</p><script type="math/tex; mode=display">x^{\ast}=\min\{\min\{...\{\min\{a_1,a_2\},a_3\},...\},a_N\}</script><p>偏最小化序列为 $x_1=a_1, x_2=\min\{x_1,a_2\},…$，为了表示的统一，可以令 $x_1=\min\{x_0,a_1\}, x_0=\infty$。序列 $x_1,x_2,…$ 逐步逼近并最终达到 $x^{\ast}$。松弛就是刻画这种逐步逼近的特性。借助松弛的思想，动态规划问题的 DPFE 可表示为</p><script type="math/tex; mode=display">\begin{aligned} f(S)&=\min_{x \in S} \{C(x|S)+f(S_x')\}\\\\ &=\min\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}'),...,C(x_m|S)+f(S_{x_m}')\} \end{aligned}</script><p>其中 $S=\{x_1,x_2,…,x_m\}$，$S_x’$ 是选择 x 之后的下一状态，与其计算所有的 $C(x|S)+f(S_x’)$ 值，我们不如逐步逼近最终值</p><script type="math/tex; mode=display">f(S)=\min\{\min\{...\min\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}')\},...\},C(x_m|S)+f(S_{x_m}')\} \quad (1.21)</script><p>注意 $C(x_i|S)$ 中状态全部是 S，并且所有的 $f(S_{x_i}’)$ 需要提前全部计算出来。</p><p>带阶形式的 DPFE 为</p><script type="math/tex; mode=display">f(k,S)=\min_x \{C(x|k,S) + f(k-1,S_x')\} \qquad(1.22)</script><p>其中 k 表示阶段，这里 k 可能不太好理解，我们可以想象从状态 S 经过恰好 k 次变换到达终止态 T，下文最短路径问题中会借鉴式 (1.22)，彼时再回过头来理解可能更加容易些。序列 $f(0,S),f(1,S),…$ 近似于 $f(S)$，序列最小值为 $f(S)$，但这个序列不保证单调性（比如振荡逼近），所以 $f(S)=\min_k \{f(k,S)\}$，注意 $f(k,S)$ 不是 $f(k-1,S)$ 的函数，而是 $f(k-1,S_x’)$ 的函数。既然 $f(k,S)$ 序列不一定单调，我们定义一个新的序列 $F(k,S)$ 来保证单调性，</p><script type="math/tex; mode=display">F(k,S)=\min\{F(k-1,S), \min_x \{C(x|k,S)+F(k-1,S_x')\}\} \quad(1.23)</script><p>这里我们可以将 $F(k,S)$ 理解为从状态 S 到终止态 T 最多变换 k 次的损失，与式 (1.22) 中恰好变换 k 次是有区别的。 </p><h3 id="最短路径问题"><a href="#最短路径问题" class="headerlink" title="最短路径问题"></a>最短路径问题</h3><p>在解决前述的线性搜索问题中，我们使用了状态转换图模型，不难发现解决这种线性搜索问题等价于在图中搜索最短路径。</p><p>考虑到有环图的复杂性，我们先讨论无环图。对于一个无环图，从起点 s 到终点 t 的最短路径使用 DPFE 可表示为</p><script type="math/tex; mode=display">f(p)=\min_q \{b(p,q)+f(q)\} \qquad(1.24)</script><p>其中 b(p,q) 表示从 p 到 q 的距离，q 是 p 的直接邻点，f(p) 表示从 p 到 t 的最短路径，基本态条件为 f(t)=0。如果 q 不是 p 的直接邻点，那么可以认为 $b(p,q)=\infty$。无环图中，要计算 f(p) 则需要先计算 f(q)。采用自底向上的方式计算，具体不展开。</p><p>在有环图中，p 和 q 可能互为后继节点，f(p) 和 f(q) 互相依赖。为了方便，我们假定有环图中没有自环，这样假设是有原因的，如果有自环，即一条从 p 到 p 的分支，考虑以下三种情况：</p><ol><li>b(p,p) &gt; 0，这条分支会被忽略，因为会增加距离</li><li>b(p,p) &lt; 0，问题本身不是定义良好的，可以不断的向路径中添加这条分支，从而一直缩短距离</li><li>b(p,p) = 0，问题本身不是定义良好的，可以不断的向路径中添加这条分支，却不改变距离</li></ol><p>所以可以忽略掉自环，以下所讨论的有环图中均没有自环。对于一个有环图，DPFE 为</p><script type="math/tex; mode=display">f(p) = \min_q \{b(p,q)+f(q)\} \qquad(1.25)</script><p>其中 f(q) 可能依赖于 f(p)，做特殊处理：初始时令 $f(p)=\infty, \forall p \ne t; \ f(t)=0$。式 (1.25) 与 (1.24) 一样，因为都是解最短路径模型，只是有环图中进行求解的时候需要做特殊处理。</p><p>举例说明，如图 1.2，<br><img src="/images/DP1_fig1.png" alt=""></p><p>根据式 (1.25) 计算过程如下</p><script type="math/tex; mode=display">\begin{aligned}f(s)&=\min \{b(s,x)+f(x),b(s,y)+f(y),b(s,t)+f(t)\}=\min \{3+f(x),5+f(y),\infty+f(t)\}\\\\f(x)&=\min \{b(x,y)+f(y),b(x,t)+f(t)\}=\min \{1+f(y),8+f(t)\}\\\\f(y)&=\min \{b(y,x)+f(x),b(y,t)+f(t)\}=\min \{2+f(x),5+f(t)\}\\\\f(t)&=0 \end{aligned}</script><p>显然 f(x) 与 f(y) 互相依赖。</p><p>初始化时假设 $f(s)=f(x)=f(y)=\infty$，第一次迭代，</p><script type="math/tex; mode=display">\begin{aligned}f(s)&=\min \{3+\infty,5+\infty,\infty+f(t)\}=\infty\\\\f(x)&=\min \{1+\infty,8+0\}=8\\\\f(y)&=\min \{2+\infty,5+0\}=5\\\\f(t)&=0 \end{aligned}</script><p>第二次迭代，</p><script type="math/tex; mode=display">\begin{aligned}f(s)&=\min \{3+8,5+5,\infty+0\}=10\\\\f(x)&=\min \{1+5,8+0\}=6\\\\f(y)&=\min \{2+8,5+0\}=5\\\\f(t)&=0 \end{aligned}</script><p>第三次迭代，</p><script type="math/tex; mode=display">\begin{aligned}f(s)&=\min \{3+6,5+5,\infty+0\}=9\\\\f(x)&=\min \{1+5,8+0\}=6\\\\f(y)&=\min \{2+6,5+0\}=5\\\\f(t)&=0 \end{aligned}</script><p>由于第三次迭代 $f(x),f(y),f(t)$ 均未改变，故第三次迭代后计算到的 f(s) 就是最终 f(s)。</p><p>还可以利用带阶 Relaxation 解决有环图问题，仿照式 (1.22)，我们针对最短路径模型改为 DPFE 为</p><script type="math/tex; mode=display">f(k,p)=\min_q \{b(p,q)+f(k-1,q)\} \qquad(1.26)</script><p>其中 f(k,p) 表示从 p 到 t 的最短距离，k 表示 p 到 t 的某个路径需要走恰好 k 步。于是基本条件为： $f(0,t)=0;f(k,t)=\infty, k&gt;0;f(0,p)=\infty, \forall p \ne t$，这表示 t 到 t 走 0 步，代价为 0，走大于 0 步，代价为 $\infty$，因为既然到了 t 点，我们不希望再继续走下去。p 到 t 走 0 步，代价为 $\infty$，这驱使我们从 p 点走出去。还以上面的例子说明，根据式 (1.26) 计算过程为</p><script type="math/tex; mode=display">\begin{aligned}f(k,s)&=\min \{b(s,x)+f(k-1,x),b(s,y)+f(k-1,y),b(s,t)+f(k-1,t)\}\\\\f(k,x)&=\min \{b(x,y)+f(k-1,y),b(x,t)+f(k-1,t)\}\\\\f(k,y)&=\min \{b(y,x)+f(k-1,x),b(y,t)+f(k-1,t)\}\\\\f(k,t) \end{aligned}</script><p>根据基本条件，也就是 k=0 的初始条件，第一次迭代，</p><script type="math/tex; mode=display">\begin{aligned}f(1,s)&=\min \{3+f(0,x),5+f(0,y),\infty+f(0,t)\}=\infty\\\\f(1,x)&=\min \{1+f(0,y),8+f(0,t)\}=8\\\\f(1,y)&=\min \{2+f(0,x),5+f(0,t)\}=5\\\\f(1,t)&=\infty \end{aligned}</script><p>第二次迭代，</p><script type="math/tex; mode=display">\begin{aligned}f(2,s)&=\min \{3+f(1,x),5+f(1,y),\infty+f(1,t)\}=10\\\\f(2,x)&=\min \{1+f(1,y),8+f(1,t)\}=6\\\\f(2,y)&=\min \{2+f(1,x),5+f(1,t)\}=10\\\\f(2,t)&=\infty \end{aligned}</script><p>第三次迭代，</p><script type="math/tex; mode=display">\begin{aligned}f(3,s)&=\min \{3+f(2,x),5+f(2,y),\infty+f(2,t)\}=9\\\\f(3,x)&=\min \{1+f(2,y),8+f(2,t)\}=11\\\\f(3,y)&=\min \{2+f(1,x),5+f(2,t)\}=8\\\\f(3,t)&=\infty \end{aligned}</script><p>假设图中总共有 N 个节点，那么从任意一点 p 到 t 可以走恰好 k 步，k 取值为 {0,1,…,N-1}，k 不能大于等于 N，否则就存在某个节点经过两次，从而路径中存在环 circle，在任意两点路径均大于 0 的情况下，显然有环的路径不可能是最短路径。这里的例子中，N=4，所以 k 最大为 3，经过三次迭代后，就没必要再迭代下去了，否则路径中存在环，迭代下去的 f 值只会越来越大。于是根据 $f(p)=\min_k \{f(k,p)\}$ 得</p><script type="math/tex; mode=display">\begin{aligned}f(s)&=\min \{\infty,\infty,10,9\}=9\\\\f(x)&=\min \{\infty,8,6,11\}=6\\\\f(y)&=\min \{\infty,5,10,8\}=5\\\\f(t)&=\min \{0,\infty,\infty,\infty\}=0 \end{aligned}</script><p>从以上求解过程不难发现，迭代计算结果序列并不收敛，这也说明了式 (1.22) 中 $f(k,S)$ 序列不单调性。</p><p>既然 $f(k,S)$ 序列不单调，我们参考式 (1.23) 为最短路径问题改写合适的 DPFE，如下</p><script type="math/tex; mode=display">F(k,p)=\min \{F(k-1,p), \ \min_q \{b(p,q)+F(k-1,q)\}\} \qquad(1.27)</script><p>其中 $F(k,p)$ 表示从 p 到 t 最多走 k 步的最短路径。显然要获得全局最短路径，我们必须考虑从 p 到 t 最多走 $N-1$ 步的最短路径，即目标是计算 $F(N-1,s)$，k 最大为 $N-1$，超过则路径出现环。基本条件不难得知为 $F(k,t)=0,k\ge 0; F(0,p)=\infty, p \ne t$，这个不用过多解释了，相信现在大家都能理解。</p><p>还有其他形式的 DPFE，由于篇幅有限就不一一介绍，待后面分析具体例子的时候再穿插说明。</p>]]></content>
      
      
      <categories>
          
          <category> math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> math </tag>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ImprovedGAN</title>
      <link href="/2019/08/01/gan/ImprovedGAN/"/>
      <url>/2019/08/01/gan/ImprovedGAN/</url>
      
        <content type="html"><![CDATA[<p>标题 <a href="https://arxiv.org/abs/1606.03498">Improved Techniques for Training GANs</a></p><p>源码 <a href="https://github.com/openai/improved_gan">improved_gan</a><br><span id="more"></span></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>GAN 是基于博弈论学习生成模型的一类方法总称。GAN 目的是训练一个生成网络其生成样本的分布可以拟合真实数据分布。虽然 <a href="2019/07/23/GAN">DCGAN</a> 在 GAN 中引入 conv+BN+ReLU 在一定程度上改善了生成器，但是我们认为 GAN 这个零和博弈问题具有高维参数且非凸，需要达到 Nash 均衡才是最佳解，而传统的基于目标函数梯度下降方法目的并非用于寻找 Nash 均衡。本文提出了以下改进方法：</p><ol><li>特征匹配</li><li>小批量特征</li><li>虚拟批归一化</li></ol><h1 id="GAN-训练收敛"><a href="#GAN-训练收敛" class="headerlink" title="GAN 训练收敛"></a>GAN 训练收敛</h1><p>训练 GAN 意味着寻找二人非合作博弈中的 Nash 均衡，每个玩家希望最小化自己的损失函数，即生成器损失 $J^{(G)}(\mathbf {\theta}^{(D)}, \mathbf {\theta}^{G})$ 和判别器损失 $J^{(D)}(\mathbf {\theta}^{(D)}, \mathbf {\theta}^{G})$，Nash 均衡指 $J^{(D)}$ 关于 $\theta^{(D)}$ 最小，同时 $J^{(G)}$ 关于 $\theta^{(G)}$ 最小。寻找 Nash 均衡点是一个比较困难的问题，虽然某些特殊情况下有算法可以解决，但是由于这里损失函数非凸且参数维度很高，那些方法均不适用。以上 Nash 均衡的说明让我们从直觉上认为需要同时最小化 G 和 D 的损失。但是很不幸，更新 $\theta^{(D)}$ 降低 $J^{(D)}$ 却增大 $J^{(G)}$，更新 $\theta^{(G)}$ 以降低 $J^{(G)}$ 但是会增大 $J^{(D)}$。这就是导致梯度下降法难以收敛（往往是在一个轨道上一直反复，而不会到达最佳点）。例如一个玩家根据 x 来最小化 xy，另一个玩家根据 y 来最小化 -xy，梯度下降法更新会使得 x 和 y 值构成的点在一个椭圆上往复，而不会收敛到 x=y=0。本文介绍以下方法启发式的促使更新达到收敛。</p><h2 id="特征匹配"><a href="#特征匹配" class="headerlink" title="特征匹配"></a>特征匹配</h2><p>特征匹配使用新的生成器损失函数以解决 GAN 训练不稳定问题。新的目标函数不是直接最大化 D 的输出（G 原本的目标是让 D 对生成样本有越大越好的输出），而是让 G 生成的样本能够匹配真实数据的统计量，这是一种更直接的思想。具体而言，训练 G 以匹配特征的期望值，这个特征来自于 D 的网络中间层。令 $\mathbf {f(x)}$ 表示 D 网络中间层的激活响应，即前面所指的特征，那么 G 的新目标函数为</p><script type="math/tex; mode=display">\|\Bbb E_{\mathbf x \sim p_{data}} \mathbf {f(x)}-\Bbb E_{\mathbf z \sim p_{\mathbf z}}\mathbf f(G(\mathbf z))\|_2^2</script><p>G 的训练目标就是最小化这个目标损失。</p><h2 id="小批量判别"><a href="#小批量判别" class="headerlink" title="小批量判别"></a>小批量判别</h2><p>GAN 训练失败的原因之一是生成器训练时总是会陷入一组参数无法逃脱，我这里称其为“陷入点”，当临近“陷入点”时，生成器的输出点总是很相似，而这些相似的点会让判别器总是指向一个差不多的方向，由于判别器 <strong>独立处理</strong> 每个样本，这些样本对应的梯度相互之间无法合作，缺乏一种反馈机制去通知生成器让其输出相互之间尽可能不相似，生成器所有的输出都向同一个点竞争，这个点是为了让判别器判别为真实的数据，所以结果就是生成器陷入一组模型参数无法自拔，陷入之后，判别器通过学习又能够将这个点判别为来自生成器，但是梯度 <strong>无法区分</strong> 各个不同的输出，于是判别器的梯度会一直在空间中将生成器产生的这个“陷入点”推来推去，导致算法无法收敛。一种显然的解决办法是让判别器不独立处理每个样本，而是一次能看到多个样本的合并，这就是小批量判别方法。</p><p>现在我们的实验建模瞄准于区分生成器的各个相互靠得很近得样本。小批量中样本之间接近程度按如下方法计算：<br>令 $\mathbf {f(x_i)} \in \Bbb R^A$ 表示输入 $\mathbf x_i$ 对应的特征向量，这个特征由 D 网络中间层产生，然后将特征向量乘以一个张量 $T \in \Bbb R^{A \times B \times C}$，结果是一个矩阵 $M_i \in \Bbb R^{B \times C}$，对于输入样本编号 $i \in \{1,…,n\}$，得到对应的矩阵 $\{M_i |i=1,…,n\}$，计算两两矩阵的各行向量之间的 L1 距离，然后应用负指数函数，</p><script type="math/tex; mode=display">c_b(\mathbf x_i, \mathbf x_j)=\exp(-\|M_{i,b}-M_{j,b}\| _ {L_1}) \in \Bbb R, \quad i,j \in \{1,...,n\}, \quad b \in \{1,...,B\}</script><p>其中下标 b 表示 row index。如图 1，minibatch layer 中样本 $\mathbf x_i$ 对应的输出定义为，</p><script type="math/tex; mode=display">\begin{aligned} &o(\mathbf x_i) _ b = \sum_{j=1}^n c _ b(\mathbf x_i, \mathbf x_j) \in \Bbb R\\\\ &o(\mathbf x_i)=\left[o(\mathbf x_i) _ 1,...o(\mathbf x_i) _ B \right] \in \Bbb R^B\\\\ &o(\mathbf X) \in \Bbb R^{n \times B} \end{aligned}</script><p>然后，将 minibatch layer 的输出 $o(\mathbf x_i)$ 与 minibatch layer 的输入 $\mathbf {f(x_i)}$ concatenate 起来，作为 D 的下一 layer 的输入。对生成样本和训练数据分别计算 minibatch layer 特征。<br><img src="/images/ImprovedGAN_fig1.png" alt=""></p><h2 id="历史平均"><a href="#历史平均" class="headerlink" title="历史平均"></a>历史平均</h2><p>修改每个玩家（G 和 D）的损失使得包含 $|\mathbf \theta -\frac 1 t \sum_{i=1}^t \theta[i]|^2$，其中 $\theta[i]$ 是历史时期 i 的参数值。</p><h2 id="单边标注平滑"><a href="#单边标注平滑" class="headerlink" title="单边标注平滑"></a>单边标注平滑</h2><p>Label 平滑，就是将分类器的 target 值由 0 和 1 替换为一个平滑的值如 0.9 或 0.1。我们将正例 target 替换为 $\alpha$，负例 target 替换为 $\beta$，那么最佳判别器变为</p><script type="math/tex; mode=display">D(\mathbf x)=\frac {\alpha p_{data}(\mathbf x) + \beta p_{model}(\mathbf x)}{p_{data}(\mathbf x)+p_{model}(\mathbf x)}</script><ul><li>当 $p_{data}(\mathbf x) \gg p_{model}(\mathbf x)$ 时，$D(\mathbf x) \rightarrow \alpha$</li><li>当 $p_{data}(\mathbf x) \ll p_{model}(\mathbf x)$ 时，$D(\mathbf x) \rightarrow \beta$</li></ul><p>当然我们也可以按 <a href="2019/7/23/GAN">GAN</a> 中那样推导 $D^{\ast}$，推导过程这里略过，只是此时目标变为</p><script type="math/tex; mode=display">\min_G \max_D V(D,G)=\Bbb E_{x \sim p_{data}(x)}[\log (D(x)-\beta)] + \Bbb E_{z \sim p_z(z)}[\log(\alpha-D(G(z)))] \quad (1)</script><p>这里约定正例 target 大于负例 target，即 $\alpha &gt; \beta$，由 (1) 式，可知 D 输出范围为 $\beta &lt; D(x) &lt; \alpha$。</p><p>由于分子中出现 $p_{model}$，那么当 $p_{data} \rightarrow 0$，且 $p_{model}$ 足够大时，来自 $p_{model}$ 的错误样本将得不到促使向真实数据靠近的激励，所以只对正例 label 平滑处理为 $\alpha$，负例 label 依然为 0。</p><h2 id="虚拟批归一化"><a href="#虚拟批归一化" class="headerlink" title="虚拟批归一化"></a>虚拟批归一化</h2><p>DCGAN 中使用了批归一化 BN 使得网络优化更加有效，但是也会带来问题，比如一个输入 $\mathbf x$，其对应的输出高度依赖于同一 minibatch 中的其他输入 $\mathbf x’$。为了避免这个问题，本文使用了虚拟批归一化 VBN，每个样本输入 $\mathbf x$ 的归一化过程基于 reference batch 中样本的统计量以及 $\mathbf x$ 自身，reference batch 是在训练初期选定并固定不变，reference batch 使用统计量进行归一化。由于 VBN 计算强度较高，故只在 G 网络中使用。</p><h1 id="图像质量评估"><a href="#图像质量评估" class="headerlink" title="图像质量评估"></a>图像质量评估</h1><p>GAN 的性能评估最直接的方法就是人类观察员判断，缺点是难以公平公正。本文提出了一个自动评估方法：应用 Inception 模型到每个生成样本上，以获得条件 label 分布 $p(y|\mathbf x)$，那些包含有意义目标的图像的条件 label 分布 $p(y|\mathbf x)$ 应该具有较低的信息熵，也就是说，具有较低的不确定性，这意味着，对于给定的输入 $\mathbf x$（包含有意义目标的图像），Inception 模型每次输出值 y （比如图像分类 c）比较稳定变化很小。但是我们又希望生成模型能够生成各种不同的图像，即对于不同的噪声输入 z，G 能够生成各种不同的图像，分别以这些不同的图像作为输入， Inception 模型的输出也尽可能不同（不确定性较大），这说明 $\int p(y|\mathbf x=G(z)) dz$ 应该具有较大的信息熵。结合以上这两点要求，性能指标为这两个分布 KL 散度的期望，</p><script type="math/tex; mode=display">\exp [\Bbb E_{\mathbf x} \mathbf {KL}(p(y|\mathbf x)\|p(y)) ]</script><p>应用指数函数仅仅是为了便于比较值的大小。</p><h1 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h1><p>考虑一个标准分类器，输入为 $\mathbf x$，共有 K 种类别，输出为长度 K 的向量 $[l_1,…,l_K]$，表示每个类别的得分，通过 softmax 得到对应的概率：</p><script type="math/tex; mode=display">p_{model}(y=j|\mathbf x)=\frac {\exp l_j} {\sum_{k=1}^K \exp l_k}</script><p>在监督学习中，此模型的训练是最小化交叉熵（或最大化 log 似然函数）。</p><p>增加来自生成器 G 的样本到数据集中，可以实现标准分类器的半监督学习，G 生成样本标记类别 y=K+1，分类器的输出维度改为 K+1，利用 $p_{model}(y=K+1|\mathbf x)$ 判断输入 $\mathbf x$ 是生成样本的概率，与 GAN 中的 $1-D(\mathbf x)$ 是对应的。也可以使用未标注数据进行学习，对于来自 K 个类别的真实数据，需要最大化 $\log p_{model}(y \in \{1,…,K\}|\mathbf x)$（log 似然函数），假设数据集中一半是真实数据，一半是生成数据，那么分类器训练的损失函数为，</p><script type="math/tex; mode=display">\begin{aligned} &L=-\Bbb E_{\mathbf x,y \sim p_{data}(\mathbf x,y)}[\log p_{model}(y|\mathbf x)] - \Bbb E_{\mathbf x \sim G} [\log p_{model}(y=K+1|\mathbf x)]=L_{supervised}+L_{unsupervised}\\\\ &L_{supervised}=-\Bbb E_{\mathbf x,y \sim p_{data}(\mathbf x,y)} \log p_{model}(y|\mathbf x, y <K+1)\\\\ &L_{unsupervised}=-\Bbb E_{\mathbf x \sim p_{data}(\mathbf x)} \log[1- p_{model}(y=K+1|\mathbf x)] - \Bbb E_{\mathbf x \sim G} [\log p_{model}(y=K+1|\mathbf x)]\end{aligned}</script><p>其中求期望实际上是经验期望也就是均值损失。其中 $L_{unsupervised}$ 就是标准 GAN 的 objective，在 $L_{unsupervised}$ 中作替换 $D(\mathbf x)=1-p_{model}(y=K+1|\mathbf x)$，就更明显了,于是有</p><script type="math/tex; mode=display">L_{unsupervised}=-\Bbb E_{\mathbf x \sim p_{data}(\mathbf x)} \log D(\mathbf x) - \Bbb E_{z \sim noise} \log (1-D(G(z)))</script><p>最小化 $L_{supervised}$ 和 $L_{unsupervised}$ 的最优解是满足 $\exp[l_j(\mathbf x)]=c(\mathbf x) p(y=j,\mathbf x), \ \forall j \in K+1$ 以及 $\exp[l_{K+1}(\mathbf x)]=c(\mathbf x) p_G(\mathbf x)$，其中 $c(\mathbf x)$ 是待定的系数函数。训练 G 以近似真实的数据分布，一种训练方法是最小化 GAN objective，使用这里的分类器作为判别器 D，这种方法引入了 G 和分类器之间的相互作用，经验表明，在半监督学习中，使用特征匹配 GAN 可以很好的优化 G。</p><p>分类器输出维度为 K+1 是过参数化的，由于输出向量中每个元素值均减去同一个值 $l_j(\mathbf x)\leftarrow l_j(\mathbf x)-f(\mathbf x)$，对 softmax 的值并不影响，所以可固定 $l_{K+1}(\mathbf x)=0, \ \forall \mathbf x$，于是 $L_{supervised}$ 变为具有 K 个类别的原始分类器的标准监督损失，此时判别器 D 为 $D(\mathbf x)=\frac {Z(\mathbf x)} {Z(\mathbf x)+1}$，其中 $Z(\mathbf x)=\sum_{k=1}^K \exp [l_k(\mathbf x)]$。</p>]]></content>
      
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CGAN/DCGAN</title>
      <link href="/2019/07/29/gan/CGAN/"/>
      <url>/2019/07/29/gan/CGAN/</url>
      
        <content type="html"><![CDATA[<h1 id="CGAN"><a href="#CGAN" class="headerlink" title="CGAN"></a>CGAN</h1><p>论文 <a href="https://arxiv.org/abs/1411.1784">Conditional Generative Adversarial Nets</a><br><span id="more"></span><br>在 <a href="gan/2019/07/23/GAN">GAN</a> 中我们知道 GAN 经过训练，生成器 G 可以根据一个随机噪声输入生成与训练集样本非常相似的样本（判别器 D 无法判别），但是 G 生成样本的标签是无法控制的，以 mnist 数据集为例，给 G 一个随机噪声输入，G 生成的样本图像可能表示数字 1，也可能是其他数字，GAN 无法控制，GAN 只能做到 G 生成样本图像很逼近真实样本图像。然而，使用额外信息来限制模型则可以控制数据生成过程，这个额外信息可以是分类标签或是其他形式的数据，于是本文的 CGAN 应运而生。</p><h2 id="Conditional-Adversarial-Nets"><a href="#Conditional-Adversarial-Nets" class="headerlink" title="Conditional Adversarial Nets"></a>Conditional Adversarial Nets</h2><p>GAN 中的 G 和 D 均使用额外信息 y 进行条件限制，则得到 CGAN。额外信息 y 可是是分类标签或者其他形式的数据。以 mnist 训练集为例，通常选择图像的分类标签作为额外信息 y。</p><p>预先已知的输入噪声 z 和 图像分类标签 y 合并一起作为 G 的输入（这是本文所用的最简单的方法，这种处理方式可以很容易地使用传统的 GAN 网络而不需要重新设计网络）。训练样本数据 x 以及对应的图像分类标签 y 合并到一起作为 D 的输入。（G 和 D 的结构可以与 GAN 中保持一致，也可以将部分 fc 替换为 conv/deconv）</p><p>训练目标函数为，</p><script type="math/tex; mode=display">\min_G \max_D V(D,G)=\Bbb E_{x \sim p_{data}(x)} [\log D(x|y)] + \Bbb E_{z \sim p_z(z)}[1-\log (1-D(G(z|y)))]</script><p>图 1 为 CGAN 过程示意图，<br><img src="/images/CGAN_fig1.png" alt=""></p><p><del>这里引用一个代码片段来进行说明</del> 请参考下方 PyTorch 实现代码。<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tfy_dim<span class="token operator">=</span><span class="token number">10</span>    <span class="token comment"># one-hot vector for mnist-label</span>z_dim<span class="token operator">=</span><span class="token number">100</span>   <span class="token comment"># length of noise input vector</span>y<span class="token operator">=</span>tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span>y_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'label'</span><span class="token punctuation">)</span>x<span class="token operator">=</span>tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'real_img'</span><span class="token punctuation">)</span>z<span class="token operator">=</span>tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span>z_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'noise'</span><span class="token punctuation">)</span><span class="token comment"># G 的输入由 noise 与 label 合并，单个输入 vector 长度由原来的 100 变成 110</span>x_for_g<span class="token operator">=</span>tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>z<span class="token punctuation">,</span>y<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># [batch_size, 100+10]</span><span class="token comment"># 然后与 GAN 中 G 的处理相同</span><span class="token comment"># D 的输入由 real_img 与 label 合并</span>new_y<span class="token operator">=</span>tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>y<span class="token punctuation">,</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>y_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>new_y<span class="token operator">=</span>new_y<span class="token operator">*</span>tf<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span>y_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># [batch_size,28,28,10]</span>x_for_d<span class="token operator">=</span>tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span>new_y<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># [batch_size,28,28,1+10]</span><span class="token comment"># 然后与 GAN 中 D 的处理相同</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="PyTorch-代码实现"><a href="#PyTorch-代码实现" class="headerlink" title="PyTorch 代码实现"></a>PyTorch 代码实现</h2><p>代码来自 <a href="https://github.com/eriklindernoren/PyTorch-GAN">eriklindernoren/PyTorch-GAN</a></p><p><strong>Generator</strong><br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 可学习的，将分类label 转换为 embedding vector，更好的与 img 数据融合</span>        self<span class="token punctuation">.</span>label_emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> layers        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token comment"># 不必过多考虑为何第一个 layer 不使用 BN，可能是因为浅层，网络 input</span>            <span class="token comment">#   已经经过 normalization。当然如果这里使用 BN，我觉得也可以</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span>latent_dim <span class="token operator">+</span> num_classes<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> noise<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        noise: (B, latent_dim)        labels: (B,)  -> label index        '''</span>        gen_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>label_emb<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">,</span> noise<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (B, latent_dim+num_classes)</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>gen_input<span class="token punctuation">)</span>        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> img      <span class="token comment"># (B, C, H, W)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>Discriminator</strong><br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>        <span class="token comment"># 不用考虑各 layer 的 output units 数量是否合适，这仅仅是使用</span>        <span class="token comment">#    mnist 的一个简单例子</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_classes <span class="token operator">+</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forwad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        img: 输入 image tensor，可以是真实 images，也可以是生成 images        labels: (B,)， label index        '''</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> img<span class="token punctuation">.</span>shape        d_in <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label_emb<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>d_in<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment"># (B,)</span>        <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>训练</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># (\hat p-p)^2  为什么不用交叉熵/NLL 损失？</span>adversarial_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span><span class="token punctuation">)</span>D <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_G <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>G<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> num_epochs<span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> imgs<span class="token punctuation">.</span>shape        valid <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>B<span class="token punctuation">)</span>        fake <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>B<span class="token punctuation">)</span>        <span class="token comment"># ==================== 训练 G ===================</span>        optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>B<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>        gen_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        gen_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>        validity <span class="token operator">=</span> D<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>        g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity<span class="token punctuation">,</span> valid<span class="token punctuation">)</span>        g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># ==================== 训练 D ===================</span>        optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        validity_real <span class="token operator">=</span> D<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        d_real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity_real<span class="token punctuation">,</span> valid<span class="token punctuation">)</span>        validity_fake <span class="token operator">=</span> D<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> gen_labels<span class="token punctuation">)</span>        d_fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>validity_fake<span class="token punctuation">,</span> fake<span class="token punctuation">)</span>        d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>d_real_loss <span class="token operator">+</span> d_fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>        d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="Unimodal"><a href="#Unimodal" class="headerlink" title="Unimodal"></a>Unimodal</h3><p>使用 mnist 数据集，分类标签 y 使用长度为 10 的 one-hot 向量。CGAN 的结构和训练方法介绍略，这部分可以查看原文。图 2 显示了生成样本，每一行使用一个标签作为模型的限制条件。<br><img src="/images/CGAN_fig2.png" alt=""></p><h3 id="Multimodal"><a href="#Multimodal" class="headerlink" title="Multimodal"></a>Multimodal</h3><p>对应一到多映射，即每个图像可以有多个不同的标签。例如 Flickr 数据集，包含图像和对应的 UGM（user-generated metadata）。UGM 通常更具有描述性，并且语义上与人类使用自然语言描述图像更为接近，而不仅仅是标记图中的目标。不同的用户可能使用不同的词汇来描述相同的概念，因此使用一个高效的方法来规范化这些标签显得尤其重要。概念词嵌入（word embedding）在此情况下非常有用，因为语义相似的词其词向量非常接近。</p><p>根据图像特征，我们可以使用 CGAN 生成 tag-vectors 以进行对图像自动打标签。使用 AlexNet 在 ImageNet 上训练网络，网络的最后一个 fc 层输出单元为 4096 个，这个输出作为最终的图像表示。为了得到词表示，我们从 YFCC100M 数据集的 metadata 中收集 user-tags，title 和 descriptions 作为文本预料，经过预处理和文本清洗，使用 skip-gram 模型进行训练，得到长度为 200 的词向量，我们忽略词频低于 200 的词，最终得到的词典大小为 247465。生成器 G 生成样本为 tag 特征向量，额外信息 y 为图像特征（上述的 4096 向量）。</p><p>实验使用 MIR Flickr 25000 数据集，使用上述卷积模型和语言模型（AlexNet，skip-gram）分布抽取图像特征和 tag 特征。数据集中前 15000 的样本作为训练集。训练阶段，数据集中没有 tag 的图像被忽略掉，而如果图像拥有多个 tag，那么对于每个 tag 均分别使用一次这个图像。</p><p>evaluation 阶段，对于每个图像生成 100 个样本（tag 特征向量），然后对每个生成样本，使用余弦相似度计算词典中与样本最接近的 20 个词，然后再所有 100 个样本中（我理解的是在 2000 个词中）选择 top 10 最常见的词作为图像的 tags。由于这部分实验没有看到源码，故其余部分的介绍略过，详情可参考原论文。</p><h1 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h1><p>论文 <a href="https://arxiv.org/abs/1511.06434">Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks</a></p><p>这篇文章主要是将卷积层、BN 以及 ReLU 引入 GAN 网络，解决以往 GAN 中使用 MLP 带来的训练不稳定，输出很奇怪的 image 等问题。</p><p><del>没有官方代码，但是 github 上有很多实现，都非常简单易懂，例如 <a href="https://github.com/carpedm20/DCGAN-tensorflow">DCGAN-tensorflow</a>。</del></p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p><img src="/images/gan/DCGAN1.png" alt=""><br>图 2. DCGAN 的生成器网络结构。</p><p>100 维度的均匀分布随机变量，通过 MLP 输出后 reshape 为 $(1024,4,4)$ tensor，然后经过 4 个 反卷积上采样，得到 $(3, H, W)$ 的 image 输出。</p><p>细节说明：</p><ol><li>将 pooling 替换为具有 stride 的卷积（在判别器 D 中）或反卷积（生成器 G 中）</li><li>G 和 D 均使用 BN</li><li>G 中使用 ReLU 代替 LeakyReLU，不过最后一层即输出层仍然使用 Tanh 激活</li><li>D 中全部使用 LeakyReLU</li><li>G 中，<code>latent_dim</code> 维度的噪声经过一个全卷积层线性变换为 <code>1024*4*4</code> 的 tensor，然后 reshape 为 <code>(1024, 4, 4)</code> 后作为全卷积网络的输入。</li></ol><h2 id="PyTorch-代码实现-1"><a href="#PyTorch-代码实现-1" class="headerlink" title="PyTorch 代码实现"></a>PyTorch 代码实现</h2><p><strong>Generator</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 由于 mnist 图片较小，整个上采样率为 4</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 这里 mnist 的 size 为 28*28，较小，如果较大图片，可以 img_size // 16</span>        self<span class="token punctuation">.</span>init_size <span class="token operator">=</span> opt<span class="token punctuation">.</span>img_size <span class="token operator">//</span> <span class="token number">4</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>init_size <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 上采样没有采用反卷积</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment"># opt.channels = 1，灰度图片， =3 为彩色图片</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>init_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>init_size<span class="token punctuation">)</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_blocks<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Discriminator</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 整个下采样为 16，对于 28*28 的 mnist image，最终输出的 spatial size 为 1*1</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">discriminator_block</span><span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># 下采样 =2</span>            <span class="token comment"># Conv + LeakyReLU + Dropout +? BN</span>            <span class="token comment"># 可以试试 Conv +? BN + LeakyReLU</span>            block <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_filters<span class="token punctuation">,</span> out_filters<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> bn<span class="token punctuation">:</span>                block<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_filters<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> block        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> bn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>discriminator_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token comment"># The height and width of downsampled image</span>        ds_size <span class="token operator">=</span> opt<span class="token punctuation">.</span>img_size <span class="token operator">//</span> <span class="token number">2</span> <span class="token operator">**</span> <span class="token number">4</span>        self<span class="token punctuation">.</span>adv_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span> <span class="token operator">*</span> ds_size <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>       <span class="token comment"># (B, 128, 1, 1)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>adv_layer<span class="token punctuation">(</span>out<span class="token punctuation">)</span>  <span class="token comment"># (B, 1)</span>        <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WGAN</title>
      <link href="/2019/07/25/gan/WGAN/"/>
      <url>/2019/07/25/gan/WGAN/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1701.07875">Wasserstein GAN</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN</title>
      <link href="/2019/07/23/gan/GAN/"/>
      <url>/2019/07/23/gan/GAN/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Nets</a><br><span id="more"></span></p><h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>生成对抗网络 GAN：一个生成模型 G 和一个判别模型 D，G 尽可能模拟真实的数据分布，D 尽可能的区分样本是模型生成的还是真实的。下文以图像数据为例说明。</p><p>定义一个输入噪声随机变量 z，其分布为 $p_z(z)$，G 根据 z 生成图像 $G(z;\theta_g)$，我们假设 G 是一个多层感知机 MLP 网络，网络参数为 $\theta_g$。D 也是一个 MLP $D(x;\theta_d)$ 输出是一个标量，表示 x 是真实图像的概率。训练 D 使其对输入 x 预测正确的概率最大化，即当 x 来自真实的训练数据时，$D(x)$ 尽可能大，当 x 来自 G 生成样本时，预测概率 $D(G(z))$ 尽可能小；而训练 G 目的是为了让 $D(G(x))$ 尽可能大，或者说让 $\log(1-D(G(z)))$ 尽可能小，于是目标函数为，</p><script type="math/tex; mode=display">\min_G \max_D V(D,G)=\Bbb E_{x \sim p_{data}(x)}[\log D(x)] + \Bbb E_{z \sim p_z(z)}[\log(1-D(G(z)))] \tag{1}</script><p>（对 D 而言，这是一个 log 似然函数，D 希望它越大越大，所以求最大值；而 G 却希望 D 的 log 似然函数越小越好，所以求最小值）</p><p>这是一个二人零和博弈。图 1 是训练过程示意图，训练使用迭代的，数值计算的方法。<br><img src="/images/GAN_fig1.png" alt=""></p><p>图 1 中 D 模型分布为蓝色虚线，数据 x 的分布 $p_x$ 为黑色点线，G 模型分布 $p_g$ 为绿色实线（黑绿曲线上某一点分别表示此 x 值处真实数据的概率密度和生成数据的概率密度）。下面的水平线为随机噪声变量 z 的定义域，在其上对 z 均匀采样，上面水平线是 x 的定义域，向上箭头表示映射过程 x=G(z) （G 生成过程）。<br>(a) 是收敛附近的对抗情况：此时 $p_g,\ p_{data}$ 两者相似，D 分类不完全准确。<br>(b) 在内层循环中，训练 D 判别样本，训练过程收敛于 $D^{\ast}(x)=\frac {p_{data}(x)}{p_{data}(x)+p_g(x)}$。<br>(c) D 的梯度可指引 G(z) 移动到更容易被分类为真实数据的区域，即，G 更新后，更加逼近真实数据分布。<br>(d) 经过几次训练，G 和 D 到达一个平衡点，此时 $p_g=p_{data}$，D 无法再区分这两个分布，即，$D(x)=1/2$。</p><p>训练算法如下，<br><img src="/images/GAN_alg1.png" alt=""></p><p>k 次 D 的优化与一次 G 的优化交替进行，这可以使得 G 变化缓慢，而 D 维持在最优解附近。</p><p>实际应用中，(1) 式可能无法提供足够的梯度来更新 G。训练初期，G 性能较差，生成样本与真实训练样本区别较大，所以 D 可以较高的置信度判别，此时，$\log (1-D(G(z)))$ 达到饱和（log 曲线右端较为平坦），于是我们改为训练 G 以最大化 $\log D(G(z))$，最终训练能到达相同的 G 和 D 的平衡点，但是训练初期的梯度较大（log 曲线的左端较为陡峭）。</p><h2 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h2><p>已知噪声随机变量 z 的分布 $p_z$ 时，可以获得 G 的模型分布，根据算法 1，如果 G 模型的假设空间和训练时间足够，G 可以拟合真实数据分布 $p_{data}$。现在我们来证明 $p_g=<br>p_{data}$ 是 (1) 式的全局最优解。</p><h3 id="全局最优解"><a href="#全局最优解" class="headerlink" title="全局最优解"></a>全局最优解</h3><p><strong>Proposition 1.</strong> 对于任意的 G，D 的最优解为</p><script type="math/tex; mode=display">D_G^{\ast}(x)=\frac {p_{data}(x)}{p_{data}(x)+p_g(x)} \qquad (2)</script><p><strong>证明：</strong>  给定任意 G，D 的训练准则是最大化 V(G,D)  </p><script type="math/tex; mode=display">\begin{aligned} V(G,D)&=\int_x p_{data}(x) \log D(x) dx+\int_z p_z(z) \log (1-D(g(z))) dz\\\\ &=\int_x p_{data}(x) \log D(x)+p_g(x) \log(1-D(x))dx \end{aligned}</script><p>$\forall (a,b) \in \Bbb R^2 \setminus \{0,0\}$，函数 $y \rightarrow a \log y+b \log(1-y)$ 在 (0,1) 区间上当 $y=\frac a {a+b}$ 时有最大值（梯度为 0 求解得到），所以要使得 V(G,D) 最大，那么对于每个 x 值，都要使 D(x) 达到最大，即 (2) 式。证毕。</p><p>D 的训练目标函数可以看作是条件概率 $P(Y=y|x)$ 的最大 log 似然函数（或者是最小化 binary cross-entropy），其中当 x 来自 $p_{data}$ 时 y=1，当 x 来自 $p_g$ 时 y=0。得到 D 的最优解 $D_G^{\ast}$ 后 (1) 式变为，  </p><script type="math/tex; mode=display">\begin{aligned} C(G)&=\max_D V(G,D)\\\\ &=\Bbb E_{x \sim p_{data}}[\log D_G^{\ast}(x)] + \Bbb E_{z \sim p_z} [\log(1-D_G^{\ast}(G(z)))]\\\\ &=\Bbb E_{x \sim p_{data}}[\log D_G^{\ast}(x)] + \Bbb E_{x \sim p_g} [\log(1-D_G^{\ast}(x))]\\\\ &=\Bbb E_{x \sim p_{data}} \left[\log \frac {P_{data}(x)} {p_{data}(x)+p_g(x)} \right]+\Bbb E_{x \sim p_g} \left[\log \frac {p_g(x)} {p_{data}(x)+p_g(x)}\right] \qquad(4) \end{aligned}</script><p><strong>Theorem 1.</strong> 当且仅当 $p_g=p_{data}$ 时， C(G) 有全局最优解 -log4。  </p><p><strong>证明：</strong> </p><ol><li>充分性<br>令 $p_g=p_{data}$，根据 (2) 式有 $D_G^{\ast}(x)=1/2$，然后根据 (4) 式有，<script type="math/tex; mode=display">C(G)=\Bbb E_{x \sim p_{data}}[-\log 2]+\Bbb E_{x \sim p_g}[-\log 2] \equiv -\log 4</script></li><li>必要性  <script type="math/tex; mode=display">\begin{aligned}C(G)&=C(G)+\Bbb E_{x \sim p_{data}}[\log 2]+\Bbb E_{x \sim p_g}[\log 2]  -\log 4 \\\\ &=-\log4 +\Bbb E_{x \sim p_{data}}\left[\log \frac {P_{data}(x)} {\frac {p_{data}(x)+p_g(x)} 2} \right]+\Bbb E_{x \sim p_g} \left[\log \frac {p_g(x)} {\frac {p_{data}(x)+p_g(x)} 2}\right] \\\\ &=-\log4+KL \left(p_{data} \| \frac {p_{data}+p_g} 2 \right)+KL \left(p_g \| \frac {p_{data}+p_g} 2 \right) \\\\ &=-\log4 + 2\cdot JSD(p_{data} \| p_g) \end{aligned}</script>其中 KL 表示 Kullback-Leibler 散度，JSD 表示 Jensen-Shannon 散度。由于 JSD 非负，且仅在 $p_g=p_{data}$ 时取得最小值 0，所以 C(G)=-log4 时，$p_g=p_{data}$。  </li></ol><p>证毕。</p><h3 id="算法-1-的收敛"><a href="#算法-1-的收敛" class="headerlink" title="算法 1 的收敛"></a>算法 1 的收敛</h3><p>上一小节我们分析了全局最优解是存在的，并且取得全局最优解的条件是 $p_g=p_{data}$。<strong>Proposition 2</strong> 表明基于算法 1 的更新是有效的，训练可以收敛到全局最优解。</p><p><strong>Proposition 2.</strong> 如果 G 和 D 有足够的模型空间，且在算法 1 每次迭代中给定 G 的情况下判别器可以达到最优解，且以调优（使更小） G 的训练标准 C(G) 更新 $p_g$ </p><script type="math/tex; mode=display">\Bbb E_{x \sim p_{data}}[\log D_G^{\ast}(x)] + \Bbb E_{x \sim p_g} [\log(1-D_G^{\ast}(x))] \qquad(5)</script><p>那么，$p_g$ 趋于 $p_{data}$。</p><p><strong>证明：</strong></p><p>考虑 $V(G,D)=U(p_g,D)$ 是 $p_g$ 的函数，$p_g$ 可根据 (5) 式标准进行优化。注意到 $U(p_g,D)$ 是 $p_g$ （定义域）上的凸函数，不同 D 形成的凸函数集合的上确界（它也是一个凸函数）的 <strong>次导数</strong> 包含了此凸函数集合在某个 D 值取得最大值所对应函数的导数，也就是说，给定任意 $p_g$（它是函数自变量），D 是可变参数，（在任意自变量 $p_g$ 处）上述结论均成立。用数学语言描述就是：</p><ul><li>如果 $f(x)=\sup_{\alpha \in \mathcal A} f_{\alpha}(x)$，且 $f_{\alpha}(x)$ 对任意 $\alpha$ 在 x 上均为凸，那么当 $\beta=\arg \sup_{\alpha \in \mathcal A} f_{\alpha}(x)$ 时有 $\partial f_{\beta}(x) \in \partial f(x)$。</li></ul><p>$V(G,D)=U(p_g,D)$ 相当于上述的上确界函数，不能保证在 $p_g$ 定义域上处处严格可导，但是这个上确界函数也是一个凸函数，保证了其具有全局唯一最优解。而上面这个结论 “在任意 $p_g$ 处，其次导数包含了在某个 D 值取得最大值所对应函数的导数”，即，“包含了在 D 取最优解 D* 时 V(G,D) 的导数”，而这个导数正是对 (5) 式求导，于是可以使用这个导数进行梯度上升/下降法更新 $p_g$，并且这个更新将会使得 $p_g$ 趋于 $p_{data}$（参考 Theorem 1）。证毕</p><p>对 (5) 式求导与算法 1 中的梯度本质相同，只是似然函数的期望改为批 SGD 中各样本损失的均值（没办法，数值计算使然），注意第一个期望在更新 $p_g$ 时不起作用，为什么这么讲？因为更新 $p_g$ 时，D 已经被固定，此时第一个期望与 $p_g$ 无关。</p><p>实际应用中，对抗网络使用 $G(z;\theta_g)$ 表示 $p_g$ 的分布，其中 $\theta_g$ 是 G 模型参数，在选定 G 的网络模型如 MLP 时，$\theta_g$ 就决定了 $p_g$ 的分布，故以上有所对 $p_g$ 的更新其实都转为对  $\theta_g$ 的更新，例如，使用 MLP 作为 G 的模型，目标函数 (1) 式中的 $p_g$ 分布替换为某个 batch 中的生成样本分布，$p_{data}$ 则替换为 batch 中的真实样本分布，简单点说，目标函数 (1) 变为 batch 中所有样本的 log-likelihood function 的均值，包含真实数据和生成数据两部分的log 似然函数，具体可参见下文的代码分析。</p><h2 id="PyTorch-代码分析"><a href="#PyTorch-代码分析" class="headerlink" title="PyTorch 代码分析"></a>PyTorch 代码分析</h2><p>代码来自 <a href="https://github.com/eriklindernoren/PyTorch-GAN">eriklindernoren/PyTorch-GAN</a></p><p><strong>Generator</strong></p><p>生成器就是一个简单的 MLP，将随机噪声 $(B, d)$ 转变为 $(B, C\times H \times W)$，其中 $B$ 表示 batch size，$d$ 表示噪声空间维度，手动设置，$C, H, W$ 为数据集中图片的 shape。<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token triple-quoted-string string">'''create a Conv+BN+ReLU layer'''</span>            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> layers                self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment"># latent_dim：噪声维度</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment"># 线性变换，输出 CxHxW</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''z is the noise, (B, latent_dim)'''</span>        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>     <span class="token comment"># (B, C*H*W)    对于 mnist，灰度图片，C=1</span>        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>        <span class="token keyword">return</span> img<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p><strong>Discriminator</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span>  nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''img: (B, C, H, W)，真实图片数据，或者 G 生成的图片数据'''</span>        <span class="token comment"># 将输入 flatten 为 (B, C*H*W)，然后通过 MLP，输出 (B, 1)</span>        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment"># 归一化，(B, 1) -> (B, )</span>        <span class="token keyword">return</span> validity<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>损失</strong></p><ol><li><p>训练判别器 D</p><p> 将公式 (1) 进行调整，对于一个 mini-batch，真实图片的 target 为 1，生成图片的 target 为 0，$D(x)$ 和 $D(G(z))$ 为各自的预测概率，于是公式 (1) 对判别器 D 而言可以看作是最大化似然函数，或者说是最小化交叉熵/NLL 损失，判别器的目标是能正确判别，故真实图片 <code>target=1</code>，生成图片 <code>target=0</code>，使用 <code>BCELoss</code> 损失函数。</p> <pre class="line-numbers language-python" data-language="python"><code class="language-python">adversarial_loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>训练生成器 G</p><p> 生成器 G 希望 D 将生成数据判别为 1，即，最大化预测概率 $D(G(z))$，这与公式 (1) 中最小化 $1-D(G(z))$ 是一致的。最大化预测概率 $D(G(z))$ 等价于最小化 NLL/交叉熵 损失，故训练 G 时，生成数据的 <code>target=1</code>，使用 <code>BCELoss</code> 损失函数。</p></li></ol><p><strong>训练</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">latent_dim <span class="token operator">=</span> <span class="token number">100</span>G <span class="token operator">=</span> Generator<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment"># 根据正态分布随机初始化模型参数：N(0, 0.02)</span>D <span class="token operator">=</span> Discriminator<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer_G <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>G<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>optimizer_D <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>D<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> epoch_num<span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token comment"># 批次取真实数据</span>        <span class="token comment"># imgs: ToTensor(), Normalize([0.5], [0.5])</span>        <span class="token comment"># ====================== 训练 G =========================</span>        B<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> img<span class="token punctuation">.</span>shape        target <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        fake_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>B<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>      <span class="token comment"># 噪声</span>        fake_imgs <span class="token operator">=</span> G<span class="token punctuation">(</span>z<span class="token punctuation">)</span>                    <span class="token comment"># 生成数据，(B, C, H, W)</span>        optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># G 希望 D 将生成数据预测为 1</span>        g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>D<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>        g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># ====================== 训练 D =========================</span>        optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>D<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>   <span class="token comment"># D(imgs): (B,)</span>        fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>D<span class="token punctuation">(</span>fake_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake_t<span class="token punctuation">)</span>        d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>        d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>生成 image</strong></p><p>生成器 G 输出的 image data 范围为 <code>[-1,1]</code>，所以还需要恢复到 <code>[0,255]</code>，可以直接使用 torchvision 中的 <code>save_image</code> 方法，可以帮我们实现 rescale 到 <code>[0,255]</code> 这个步骤，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image<span class="token comment"># 保存 5*5 个生成 images</span><span class="token comment"># 保存一个大的 image，由这 25 个 images 按 5x5 的 grid 排列</span>row <span class="token operator">=</span> <span class="token number">5</span><span class="token comment"># 指定 normalize，将最小值映射为 0， 最大值映射为 1， 然后乘以 255 取整，即可</span><span class="token comment"># 否则，img * 0.5 + 0.5，然后乘以 255，取整</span>save_image<span class="token punctuation">(</span>G<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>row<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">,</span> nrow<span class="token operator">=</span>row<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>由于原生实现所用到的库太古老，以下内容可以忽略。</p><p>实验介绍和结果分析略。在这里，我们重点看一下源码 <a href="http://www.github.com/goodfeli/adversarial">adversarial</a></p><blockquote><p>声明：本源码使用库 Theano 和 Pylearn2，而我从来没接触过这两个库，代码分析全凭函数名、变量名和类名等。github 上也有 GAN 的其他实现如 <a href="https://github.com/wiseodd/generative-models">generative-models</a>，代码通俗易懂，读者可自行查阅。</p></blockquote><p>从 github 上 clone 这个仓库，进入 adversarial 本项目的根目录。以 mnist 数据集为例说明。</p><p>首先看下 mnist.yaml 这个文件，<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token tag">!obj:pylearn2.train.Train</span> <span class="token punctuation">&#123;</span>         <span class="token comment"># 训练配置</span>    <span class="token key atrule">dataset</span><span class="token punctuation">:</span> <span class="token important">&amp;train</span> <span class="token tag">!obj:pylearn2.datasets.mnist.MNIST</span> <span class="token punctuation">&#123;</span>    <span class="token comment"># 训练使用 mnist 数据集</span>        <span class="token key atrule">which_set</span><span class="token punctuation">:</span> <span class="token string">'train'</span><span class="token punctuation">,</span>                                 <span class="token comment"># 使用 train 数据的前 50000 条</span>        <span class="token key atrule">start</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>        <span class="token key atrule">stop</span><span class="token punctuation">:</span> <span class="token number">50000</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token key atrule">model</span><span class="token punctuation">:</span> <span class="token tag">!obj:adversarial.AdversaryPair</span> <span class="token punctuation">&#123;</span>                 <span class="token comment"># GAN：G &amp; D</span>        <span class="token key atrule">generator</span><span class="token punctuation">:</span> <span class="token tag">!obj:adversarial.Generator</span> <span class="token punctuation">&#123;</span>             <span class="token comment"># G</span>            <span class="token key atrule">noise</span><span class="token punctuation">:</span> <span class="token string">'uniform'</span><span class="token punctuation">,</span>                               <span class="token comment"># noise 分布使用均匀分布</span>            <span class="token key atrule">monitor_ll</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>            <span class="token key atrule">mlp</span><span class="token punctuation">:</span> <span class="token tag">!obj:pylearn2.models.mlp.MLP</span> <span class="token punctuation">&#123;</span>            <span class="token key atrule">layers</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>                     <span class="token tag">!obj:pylearn2.models.mlp.RectifiedLinear</span> <span class="token punctuation">&#123;</span> <span class="token comment"># 带 ReLu 的 FC 层</span>                         <span class="token key atrule">layer_name</span><span class="token punctuation">:</span> <span class="token string">'h0'</span><span class="token punctuation">,</span>                         <span class="token key atrule">dim</span><span class="token punctuation">:</span> <span class="token number">1200</span><span class="token punctuation">,</span>                             <span class="token comment"># 本层 output units 数量</span>                         <span class="token key atrule">irange</span><span class="token punctuation">:</span> <span class="token number">.05</span><span class="token punctuation">,</span>                     <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                     <span class="token punctuation">...</span>                     <span class="token tag">!obj:pylearn2.models.mlp.Sigmoid</span> <span class="token punctuation">&#123;</span>     <span class="token comment"># FC 层后接 sigmoid</span>                         <span class="token key atrule">init_bias</span><span class="token punctuation">:</span> <span class="token tag">!obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals</span> <span class="token punctuation">&#123;</span> <span class="token key atrule">dataset</span><span class="token punctuation">:</span> <span class="token important">*train</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>                         <span class="token key atrule">layer_name</span><span class="token punctuation">:</span> <span class="token string">'y'</span><span class="token punctuation">,</span>                         <span class="token key atrule">irange</span><span class="token punctuation">:</span> <span class="token number">.05</span><span class="token punctuation">,</span>                         <span class="token key atrule">dim</span><span class="token punctuation">:</span> <span class="token number">784</span>                               <span class="token comment"># 784=28x28，为 mnist 单个样本大小</span>                     <span class="token punctuation">&#125;</span>                    <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token key atrule">nvis</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token punctuation">,</span>                                          <span class="token comment"># G 的噪声随机变量的向量维度</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>        <span class="token key atrule">discriminator</span><span class="token punctuation">:</span>                                          <span class="token comment"># D</span>            <span class="token tag">!obj:pylearn2.models.mlp.MLP</span> <span class="token punctuation">&#123;</span>            <span class="token key atrule">layers</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>                     <span class="token punctuation">...</span>                     <span class="token tag">!obj:pylearn2.models.mlp.Sigmoid</span> <span class="token punctuation">&#123;</span>                         <span class="token key atrule">layer_name</span><span class="token punctuation">:</span> <span class="token string">'y'</span><span class="token punctuation">,</span>                         <span class="token key atrule">dim</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>                                <span class="token comment"># 输出为标量</span>                         <span class="token key atrule">irange</span><span class="token punctuation">:</span> <span class="token number">.005</span>                     <span class="token punctuation">&#125;</span>                    <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token key atrule">nvis</span><span class="token punctuation">:</span> <span class="token number">784</span><span class="token punctuation">,</span>                                          <span class="token comment"># 输入向量维度</span>        <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token key atrule">algorithm</span><span class="token punctuation">:</span> <span class="token tag">!obj:pylearn2.training_algorithms.sgd.SGD</span> <span class="token punctuation">&#123;</span>      <span class="token comment"># 优化算法</span>        <span class="token punctuation">...</span>        <span class="token key atrule">cost</span><span class="token punctuation">:</span> <span class="token tag">!obj:adversarial.AdversaryCost2</span> <span class="token punctuation">&#123;</span>                 <span class="token comment"># 损失实现类</span>            <span class="token key atrule">scale_grads</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>            <span class="token comment">#target_scale: 1.,</span>            <span class="token key atrule">discriminator_default_input_include_prob</span><span class="token punctuation">:</span> <span class="token number">.5</span><span class="token punctuation">,</span>            <span class="token key atrule">discriminator_input_include_probs</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>                <span class="token key atrule">'h0'</span><span class="token punctuation">:</span> <span class="token number">.8</span>            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>            <span class="token key atrule">discriminator_default_input_scale</span><span class="token punctuation">:</span> <span class="token number">2.</span><span class="token punctuation">,</span>            <span class="token key atrule">discriminator_input_scales</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>                <span class="token key atrule">'h0'</span><span class="token punctuation">:</span> <span class="token number">1.25</span>               <span class="token punctuation">&#125;</span>            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>        <span class="token punctuation">...</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>    <span class="token punctuation">...</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>可以明显知道，训练使用 mnist 的 <code>train</code> 数据集中前 50000 个数据，模型类实现为 adversarial.AdversaryPair，生成器类为 adversarial.Generator，其内部封装了一个 MLP，判别器类直接使用 MLP。损失实现类为 adversarial.AdversaryCost2。这些类的实现均位于 <code>__init__.py</code> 中。这里主要分析一下 AdversaryCost2（其他类的实现均比较简单明了）。</p><p>首先看一下生成样本和目标函数 <code>get_samples_and_objectives</code>，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">g<span class="token operator">=</span>model<span class="token punctuation">.</span>generator       <span class="token comment"># model is an instance of AdversaryPair</span>d<span class="token operator">=</span>model<span class="token punctuation">.</span>discriminatorX<span class="token operator">=</span>data                  <span class="token comment"># 真实数据（来自训练样本）的 batch</span>m<span class="token operator">=</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span>space<span class="token punctuation">.</span>get_batch_axis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment"># 获取 batch 的大小，即批样本数量</span>y1<span class="token operator">=</span>T<span class="token punctuation">.</span>alloc<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>m<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>       <span class="token comment"># 长度为 m 的全 1 向量，代表真实数据的 label</span>y0<span class="token operator">=</span>T<span class="token punctuation">.</span>alloc<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>m<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>       <span class="token comment"># 长度为 m 的全 0 向量，代表生成数据的 label</span><span class="token comment"># 1. 生成 m 个噪声作为 G 模型的输入 z</span><span class="token comment"># 2. G 前向传播生成 m 个样本 S</span>S<span class="token punctuation">,</span>z<span class="token punctuation">,</span>other_layers<span class="token operator">=</span>g<span class="token punctuation">.</span>sample_and_noise<span class="token punctuation">(</span>m<span class="token punctuation">,</span>    default_input_include_prob<span class="token operator">=</span>self<span class="token punctuation">.</span>generator_default_input_include_prob<span class="token punctuation">,</span>   <span class="token comment"># 1</span>    default_input_scale<span class="token operator">=</span>self<span class="token punctuation">.</span>generator_default_input_scale<span class="token punctuation">,</span>                 <span class="token comment"># 1</span>    all_g_layers<span class="token operator">=</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>infer_layer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">)</span>                         <span class="token comment"># False</span><span class="token punctuation">)</span><span class="token keyword">if</span> self<span class="token punctuation">.</span>noise_both <span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">:</span>     <span class="token comment"># 真实数据和生成数据均添加一个噪声干扰</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token comment"># D 前向传播，分别得到真实数据的预测 label 和生成数据的预测 label</span>y_hat1 <span class="token operator">=</span> d<span class="token punctuation">.</span>dropout_fprop<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>       <span class="token comment"># 参数略</span>y_hat0 <span class="token operator">=</span> d<span class="token punctuation">.</span>dropout_fprop<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token comment"># D 的目标损失。d.layers[-1] 为 Sigmoid 层，其目标损失为 KL 散度</span>d_obj <span class="token operator">=</span> <span class="token number">0.5</span><span class="token operator">*</span><span class="token punctuation">(</span>d<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cost<span class="token punctuation">(</span>y1<span class="token punctuation">,</span>y_hat1<span class="token punctuation">)</span><span class="token operator">+</span>d<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cost<span class="token punctuation">(</span>y0<span class="token punctuation">,</span>y_hat0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># G 的目标损失。G 希望 D 的判别结果 y_hat0 与真实 label y1 越小越好  </span>g_obj <span class="token operator">=</span> d<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cost<span class="token punctuation">(</span>y1<span class="token punctuation">,</span>y_hat0<span class="token punctuation">)</span><span class="token keyword">if</span> model<span class="token punctuation">.</span>inferer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>       <span class="token comment"># 模型推断器</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">else</span><span class="token punctuation">:</span>    i_obj <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">return</span> S<span class="token punctuation">,</span> d_obj<span class="token punctuation">,</span> g_obj<span class="token punctuation">,</span> i_obj       <span class="token comment"># 返回生成样本，D 损失和 G 损失</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>再来看计算梯度函数 <code>get_gradients</code> 的实现部分，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python">g<span class="token operator">=</span>model<span class="token punctuation">.</span>generatord<span class="token operator">=</span>model<span class="token punctuation">.</span>generatorS<span class="token punctuation">,</span>d_obj<span class="token punctuation">,</span>g_obj<span class="token punctuation">,</span>i_obj <span class="token operator">=</span> self<span class="token punctuation">.</span>get_samples_and_objectives<span class="token punctuation">(</span>model<span class="token punctuation">,</span>data<span class="token punctuation">)</span>   <span class="token comment"># 调用上面分析的函数</span>g_params <span class="token operator">=</span> g<span class="token punctuation">.</span>get_params<span class="token punctuation">(</span><span class="token punctuation">)</span>d_params <span class="token operator">=</span> d<span class="token punctuation">.</span>get_params<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 计算损失对各参数的梯度</span>d_grads <span class="token operator">=</span> T<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>d_obj<span class="token punctuation">,</span>d_params<span class="token punctuation">)</span>g_grads <span class="token operator">=</span> T<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>g_obj<span class="token punctuation">,</span>g_params<span class="token punctuation">)</span><span class="token keyword">if</span> self<span class="token punctuation">.</span>scale_grads<span class="token punctuation">:</span>    <span class="token comment"># 缩小 g_grads</span>    S_grad <span class="token operator">=</span> T<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>g_obj<span class="token punctuation">,</span> S<span class="token punctuation">)</span>   <span class="token comment"># G 损失对生成样本（也就是 G 的输出）的梯度</span>    <span class="token comment"># S_grad 的平方和的平方根的倒数作为缩小比例</span>    scale <span class="token operator">=</span> T<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>target_scale<span class="token operator">/</span>T<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>T<span class="token punctuation">.</span>sqr<span class="token punctuation">(</span>S_grad<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 缩小 g_grads</span>    g_grads <span class="token operator">=</span> <span class="token punctuation">[</span>g_grad <span class="token operator">*</span> scale <span class="token keyword">for</span> g_grad <span class="token keyword">in</span> g_grads<span class="token punctuation">]</span><span class="token comment"># 保存各模型参数与其对应的梯度</span>rval <span class="token operator">=</span> OrderDict<span class="token punctuation">(</span><span class="token punctuation">)</span>rval<span class="token punctuation">.</span>update<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span>safe_zip<span class="token punctuation">(</span>d_params<span class="token punctuation">,</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>now_train_discriminator <span class="token operator">*</span> dg <span class="token keyword">for</span> dg <span class="token keyword">in</span> d_grads<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>rval<span class="token punctuation">.</span>update<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span>safe_zip<span class="token punctuation">(</span>g_params<span class="token punctuation">,</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>now_train_generator <span class="token operator">*</span> gg <span class="token keyword">for</span> gg <span class="token keyword">in</span> g_grads<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>updates <span class="token operator">=</span> OrderDict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> self<span class="token punctuation">.</span>alternate_g<span class="token punctuation">:</span>    updates<span class="token punctuation">[</span>self<span class="token punctuation">.</span>now_train_generator<span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>now_train_generator<span class="token keyword">return</span> rval<span class="token punctuation">,</span> updates<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>最终的更新操作由 Pylearn2/Theano 库完成。</p><p>以上代码片段中，目标函数为损失，与 log 似然函数相差一个负号，所以上文分析中某些求最大值的地方变为求最小值，然后使用随机梯度下降更新模型参数，这与算法 1 中的情况完成相同。另外，对 <code>g_grads</code> 进行 scale 缩小，一种可能的原因是，</p><p>生成样本 $S=\theta_g \cdot z$，损失对 $\theta_g$ 的梯度满足</p><script type="math/tex; mode=display">\nabla_{\theta_g}L=\nabla_S L \cdot \frac {\partial S}{\partial \theta_g}</script><p>记生成样本 S 经过 D 的输出为 y_0，即，$y_0=\theta_d \cdot S$，于是</p><script type="math/tex; mode=display">\nabla_S L=\frac {dL}{dy_0}\cdot \theta_d</script><p>可以看出在计算损失对 G 模型参数的梯度之前，$\nabla_S L$ 这个梯度已经经过 D 中各层的传播：</p><ol><li><p>如果其 L2 范数大于 1，那么再经过 G 中各层反向传播时，极有可能出现梯度爆炸，即 $\nabla_{\theta_g}L$ 很大， 导致训练不稳定，所以需要将其进行 scale 缩小，缩小的比例正好能使 $\nabla_S L$ 的 L2 范数为指定值 <code>self.target_scale</code>（默认为1）。<br>关于 G 模型参数的梯度过大导致训练不稳定，如下图，<br><img src="/images/GAN_fig2.png" alt=""><center>fig 2. 图来自于网络。左图表示 $G_0$ 时的 V(G,D) 曲线；右图表示 $G_1$ 时的 V(G,D) 曲线。（这个图我觉得有点奇怪，按道理不应该是凸函数吗，以及右图右边的红点不是说明存在合适的 $D_1^{\ast}$ 吗，用这个图能说明什么问题，我没有搞懂。相反，我倒觉得是用来说明不要更新 G 太多以便可以达到这个图中的效果。如我理解有误，恳请大佬指正~）</center></p><p>上图表示在 $D_0^{\ast}$ 取得最大值 $\max_D V(G_0,D_0)=V(G_0,D_0^{\ast})$，然后更新 $G_0$ 为 $G_1$后，由于 G 的更新会降低 V(G,D)，故 $V(G_1,D_0^{\ast}) &lt; V(G_0,D_0^{\ast})$，但是此时更新 D 以最大化 V(G,D)，可能会出现 $V(G_1,D_1^{\ast}) &lt; V(G_0,D_0^{\ast})$，这意味着判别器 $D_1^{\ast}$ 的判别能力比之前的 $D_0^{\ast}$ 的判别能力差，而 G 伪装能力的增强是建立在 D 判别能力的增强这个基础上，否则更新 G 就达不到应该有的效果，所以降低损失对 G 模型参数的梯度，以便不要更新 G 太多，或者多次更新 D 与一次更新 G 交替进行。</p></li><li>如果其 L2 范数小于等于1，则对梯度不做 scale 缩小操作。</li></ol><p>当然，还有其他损失实现类，具体请查阅源码，不再讨论。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>给定一个预先已知分布的噪声随机变量 z，G 根据 z 生成图像 G(z)，D 将 G(z) 与训练样本区分开来。训练过程根据 (1) 式交替优化 D 和 G，使得 G 尽可能拟合真实数据分布，而 D 提高判别能力，最终 G 分布与真实分布相同，D 无法判别模型分布和真实数据分布。</p><h1 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h1><p>源码：<a href="https://github.com/eriklindernoren/PyTorch-GAN">eriklindernoren/PyTorch-GAN</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Grid-RCNN</title>
      <link href="/2019/07/19/obj_det/Grid-RCNN/"/>
      <url>/2019/07/19/obj_det/Grid-RCNN/</url>
      
        <content type="html"><![CDATA[<h1 id="Grid-R-CNN"><a href="#Grid-R-CNN" class="headerlink" title="Grid R-CNN"></a>Grid R-CNN</h1><p>论文 <a href="https://arxiv.org/abs/1811.12030">Grid R-CNN</a></p><p>源码 <a href="https://github.com/STVIR/Grid-R-CNN">Grid R-CNN</a><br><span id="more"></span></p><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>目标检测器包含两个分支：分类和回归，其中回归分支通常由 conv 和 fc 层组成，因为最终的输出单元数量固定为 4，表示 x,y,w,h 的坐标偏差（或者固定为 4*(C+1)，表示坐标偏差的预测是分类相关的），而 fc 层适用输出单元数量固定的场景。<br><img src="/images/Grid-RCNN_fig1.png" alt=""></p><p>这篇文章介绍了 Grid R-CNN，主要是修改了类 R-CNN 目标检测器的回归分支，与传统类 R-CNN 的区别主要如图 1 所示，即，使用 grid points 表示目标定位：在得到 RoI 特征后，使用全卷积 FCN 得到特征图，然后再通过某种方法得到 grid points。此修改有如下优点：</p><ol><li>FCN 保留了 RoI 的空间信息，二维（显然，之前的方法都是展平成了一维向量），所以可准确的得到 grid points</li><li>根据 grid points 可以更加精确的获得目标定位。以前的方法都是通过左上角和右下角坐标确定目标 bbox，这种方法显然较为粗糙，因为目标形状的任意性，角点可能位于目标形状之外的背景上，角点处的局部特征并不能反映目标的特征（ExtremeNet 中也提过 CornerNet 的这个问题），而 grid points 采用 3x3 的点作为监督，由于点数增多，可以降低其中某些不准确点对位置预测的负面影响。如图 1(b)，右上角的坐标不准确，但是中上（top-middle）点可以帮助校正最终的目标位置。</li></ol><p>利用 grid points 数量多这个优势，文中还提出一种信息融合方法，为每个 grid point 设计独立的一组 feature maps：对某个 grid point，聚集其邻近 grid point 的 feature maps 并进行融合成，作为当前这个 grid point 的 feature map，这个合成的 feature map 则用于预测当前 grid point 的位置。这种空间信息互补的方法可以使得位置预测更加准确。</p><h2 id="2-Grid-R-CNN"><a href="#2-Grid-R-CNN" class="headerlink" title="2. Grid R-CNN"></a>2. Grid R-CNN</h2><p>网络的整体结构如图 2 所示，基于 region proposals，使用 RoIAlign 抽取出 RoI 特征，然后分为两支，其中一支用于目标分类预测，另一支经过 FCN 得到 feature maps，然后经过 sigmoid 得到概率热图（probability heatmap），注意不是传统的坐标偏差，heatmaps 可由 target map 监督，从这个概率热图上我们可以通过某种方法得到 grid points（下文 2.1 一节会介绍这种方法），再经过上述的空间信息融合方法（2.2 一节会介绍），最后得到准确的目标定位。接下来我们将整个问题分而治之进行介绍。<br><img src="/images/Grid-RCNN_fig2.png" alt=""></p><h3 id="2-1-Grid-Guided-Localization"><a href="#2-1-Grid-Guided-Localization" class="headerlink" title="2.1 Grid Guided Localization"></a>2.1 Grid Guided Localization</h3><p>一般地， NxN 的 grid points 位列 bbox 之上。以上文提到的 3x3 的 grid points 为例，共四个角点，四条边的中点，以及 bbox 的中心点。</p><p>我们简单地描述一下坐标预测分支：使用 RoIAlign 抽取 RoI 得到空间尺度固定为 14x14 的 feature，然后跟着是 8 个 3x3 的空洞卷积，目的是为了增大感受野，接着是两个 2x 反卷积，得到空间尺度为 56x56 的 feature，其通道数为 NxN，然后应用 pixel-wise 的 sigmoid 函数，得到 NxN 个概率热图 heatmap，注意 heatmap 与 feature map 两者是不同的，每个热图对应一个 grid point，且对应一个 supervision map，在这个 supervision map 上以 target grid point 为中心的可以组成十字型的 5 个像素点标记为正 $t_i=1$，其他像素位置处表示为负 $t_i=0$（target grid point 在 supervision map 上的位置在 2.3 一节介绍），然后使用 binary cross-entropy loss $CE=\sum_{i=1}^{56 \times 56} [-t_i\log p_i-(1-t_i)\log(1-p_i)]$进行优化，其中 $p_i$ 表示某个 pixel 处的概率。</p><p>Inference 阶段，在每个 heatmap 上选择最高置信度的点，记为 $(H_x,H_y)$，经过简单的映射计算可以得到其在原始 image 平面上的坐标，记为 $(I_x,I_y)$，</p><script type="math/tex; mode=display">I_x=P_x+ \frac {H_x}{w_o} w_p\\\\ I_y=P_y+ \frac {H_y}{h_o} h_p</script><p>其中 $(P_x,P_y)$ 为 region proposal 的左上角在原始 image 平面上的坐标，$(w_p,h_p)$ 表示 proposal 的宽高，$(w_o,h_o)$ 表示输出 heatmap 的宽高。 <strong>注意：</strong> heatmap 与 proposal 尺度不一定相同！！！<br>有了预测的 grid points 之后就可以得到目标 bbox 的四个边的坐标，记为 $B=(x_l,y_u,x_r,y_b)$。第 j 个 grid point 记为 $g_j$，其坐标为 $(x_j,y_j)$，其概率为 $p_j$（第 j 个 heatmap 上置信度最高值），定义 $E_i$ 为位于第 i 个边（左上右下，其中一个）上的 grid points 的下标集合，即，如果 $g_j$ 位于 第 i 个边上，那么 $j \in E_i$，于是根据 grid points 集合可以计算 B，采用加权平均，如下，</p><script type="math/tex; mode=display">x_l=\frac 1 N \sum_{j \in E_1} x_j p_j, \quad y_u=\frac 1 N \sum_{j \in E_2} y_j p_j\\\\ x_r=\frac 1 N \sum_{j \in E_3} x_j p_j, \quad y_b=\frac 1 N \sum_{j \in E_4} y_j p_j</script><h3 id="2-2-Grid-Points-Feature-Fusion"><a href="#2-2-Grid-Points-Feature-Fusion" class="headerlink" title="2.2 Grid Points Feature Fusion"></a>2.2 Grid Points Feature Fusion</h3><p>由 FCN 得到得 heatmap 保留了 RoI 的空间信息，所以 grid points 之间存在某种联系，他们之间可以互相校正位置，通过一种空间信息融合方法得以实现。以 3x3 grid points 为例，要校正左上角 point，我们可以利用其他 grid points 对应的 feature maps 上左上角区域的特征。</p><p>为了区分不同 grid points 的 feature maps，使用 NxN 不同的 filters 从最后的 feature map 上分别为这些 grid points 抽取特征，于是每个 feature map 与其对应的 grid point 有特殊的联系，称第 i 个 point 对应的 feature map 为 $F_i$。</p><p>对于每个 grid point，与其 L1 距离为 1 的其他 points 参与融合过程，称这些 points 为 source points，记为 $S_i$，对于 $S_i$ 中的 point j，其 feature maps $F_j$ 经过三个连续的 5x5 卷积，记此过程为 $T_{j \rightarrow i}$，$S_i$ 中所有 source points 经过此过程后得到的 features 再与 $F_i$ 进行融合得到 $F_i’$，融合采用简单的求和操作，</p><script type="math/tex; mode=display">F_i'=F_i + \sum_{j \in S_i} T_{j \rightarrow i} (F_j)</script><p><img src="/images/Grid-RCNN_fig3.png" alt=""></p><p>如图 3(a) 是左上角 point 的融合示意图。有了融合后的特征 $F_i’$ 后，还可进行二次融合，类似的，对 source point 的 $F_i’$ 特征应用变换函数 $T_{j \rightarrow i}^+$（几个连续的卷积），其参数不与第一个融合的过程共享，第二次融合后的特征记为 $F_i’’$，用于输出最终的 heatmap，并从中根据前述方法取最大置信度得到 grid point 位置预测。第二次融合使得 L1 距离小于等于 2 的 points 的 features 对当前 grid point 均有贡献，如图 3(b)。</p><p><strong>注意：</strong> 融合前后的两组 feature maps 均通过 sigmoid 计算得到两组 heatmaps，然后分别与 supervision maps 计算出前后两处 loss（作为位置预测损失），损失计算如上面所述均采用 Binary Cross-Entropy Loss。</p><h3 id="2-3-Extended-Region-Mapping"><a href="#2-3-Extended-Region-Mapping" class="headerlink" title="2.3 Extended Region Mapping"></a>2.3 Extended Region Mapping</h3><p>Grid 预测模块输出的 heatmap 是固定尺度的，各 pixel 位置处的概率表示可能是 grid point 的概率。对 RoI 特征应用的是全卷积 FCN，所以空间信息得以保留，输出 heatmap 自然就对应 region proposal 在原 image 上的空间区域，但是，region proposal 不一定完全包含目标，这意味着 gt grid point 可能位于 region proposal 之外，导致无法在 supervision map 上标记 target grid point，这种缺失造成训练阶段训练样本的利用率低的问题，同时在 inference 阶段，简单地在 heatmap 上选择置信度最大的 pixel 作为 grid point，由于 region proposal 没有完全包含目标，可能会选择出一个错误的 grid point 位置，从而导致预测存在偏差。很多场合下有超过一半的 gt grid points 都没有被 region proposals 覆盖到，如图 4，proposal（最小白框）比 gt box 小，9 个 grid points 中有 7 个将会位于输出 heatmap 之外。</p><p>解决上述问题的一个最自然的方法是增大 proposal，从而确保大部分 gt grid points 还是会被 proposal 包含进来，但是这同时也会包含 背景或其他目标 的特征，这些特征对于预测当前目标是冗余的，甚至是有害的。作者实验显示，简单的增大 proposal 确实没什么好处，在小目标检测上是有害的。作者采用的解决方法是修改输出 heatmap 和原 image 上 region 之间的关系：当给定 proposal 时，RoI 特征依然是从 feature map 上相同 region 中获取，此处不需要增大 proposal；但是重新定义输出 heatmap 所代表的区域为 region 的两倍大，这样大多数场合下，所有的 grid points 都被包含进来了，如图 4 中虚线框所示，但是 supervision map 与输出 heatmap 尺度相同的，这相当于将 gt box 缩小一倍然后映射到 supervision map 上从而进行标记，标记方法前文已经提到过，在以 gt grid point 为中心的十字型 pixels，即 gt grid point 和位于其上下左右四个最近邻 pixels，共 5 个 pixels 标记为正。<br><img src="/images/Grid-RCNN_fig4.png" alt=""></p><p>扩展的区域映射使用公式表达如下，</p><script type="math/tex; mode=display">I_x'=P_x+\frac {4H_x-w_o}{2w_o}w_p\\\\ I_y'=P_y+\frac {4H_y-h_o}{2h_o}h_p</script><p>以图 4 为例，推导一下上式的由来。<br>记 heatmap 对应到原 image 上两倍 region proposal 大小的区域为 R’，类似于 $(I_x,I_y)$ 地有，</p><script type="math/tex; mode=display">I_x'=P_x'+\frac {H_x}{w_o} 2 w_p, \quad I_y'=P_y'+\frac {H_y}{h_o} 2 h_p</script><p>其中 $(P_x’,P_y’)$ 是 R’ 的左上角在原 image 上的坐标，其与 proposal 的左上角坐标具有关系，</p><script type="math/tex; mode=display">2(x_c-P_x)=x_c-P_x'=w_p, \quad 2(y_c-P_y)=y_c-P_y'=h_p</script><p>其中 $(x_c,y_c)$ 是 proposal 与 R’ 共同的中心在原 image 上的坐标，综合上两式即可证明。</p><h3 id="2-4-Implementation-Details"><a href="#2-4-Implementation-Details" class="headerlink" title="2.4 Implementation Details"></a>2.4 Implementation Details</h3><p>实现细节和实验分析略，请阅读原文。</p><h1 id="Grid-R-CNN-Plus"><a href="#Grid-R-CNN-Plus" class="headerlink" title="Grid R-CNN Plus"></a>Grid R-CNN Plus</h1><p>论文 <a href="https://arxiv.org/abs/1906.05688">Grid R-CNN Plus: Faster and Better</a></p><p>前面讲到将 Grid R-CNN 模块引入到 two-stage 目标检测器中可以显著提升 mAP，然而 Grid R-CNN 的计算量较大导致 inference 时间较长，从而使其难以广泛应用，所以这篇文章提出 Grid R-CNN Plus，通过一些有效的改进使其成为更好更快的目标检测器。</p><p>大概介绍一下 Grid R-CNN Plus：对于每个 grid point，Grid R-CNN 均使用相同的表示区域来生成 supervision map，显然这是低效的，例如，左上 grid point 不会出现在其对应 supervision map 的右部和底部，所以在 Grid R-CNN Plus 中，仅监督最有可能的 1/4 区域，这样就降低了 grid 分支中 feature maps 的尺度。另外，特征融合阶段的卷积层数量也减少了。如此，降低计算损耗的同时，由于更加专注 grid point 的表示区域（原来区域中最有可能的 1/4），grid point 定位也更加准确。</p><p>在采用策略，归一化方法，NMS 策略和超参数上也进行了分析和优化。</p><h2 id="回顾-Grid-R-CNN"><a href="#回顾-Grid-R-CNN" class="headerlink" title="回顾 Grid R-CNN"></a>回顾 Grid R-CNN</h2><p>图 1 是 Grid R-CNN 的框架结构示意图。与一般 two-stage 检测器类似，Grid R-CNN 包含 RPN 和 R-CNN。基于 region propopsals，使用 RoIAlign 从 CNN backbone 的输出 feature maps 上 RoI 对应区域抽取特征，这个 RoI 特征用于预测分类和 bbox 定位。Grid R-CNN 与一般类 R-CNN 的不同之处在于使用 grid points 代替了坐标偏差。Grid 预测分支使用 FCN 结构输出保留空间信息的 heatmaps，从这些 heatmaps 中可以分别定位目标的 grid points。<br><img src="/images/Grid-RCNN-Plus_fig1.png" alt=""></p><p>Grid R-CNN 使用 8 个 3x3 的卷积和两个 2x 反卷积得到 heatmap，这种分支结构比较重量级。降低计算量的一种方法是：首先从 RPN 中选择 1000 的 proposals，然后送入分类分支得到分类得分后，进行 NMS 之后然后选择其中 top 100 的 proposals，然后再送入 grid 分支，以降低计算耗时。</p><p>为了提高准确性，还使用了特征融合机制和扩展区域映射，其中特征融合利用了 grid points 空间相关性互相进行校正，扩展区域映射则解决了 gt grid points 位于 proposal 之外的痛点。</p><h2 id="Grid-R-CNN-Plus-1"><a href="#Grid-R-CNN-Plus-1" class="headerlink" title="Grid R-CNN Plus"></a>Grid R-CNN Plus</h2><h3 id="Grid-Point-专用表示区域"><a href="#Grid-Point-专用表示区域" class="headerlink" title="Grid Point 专用表示区域"></a>Grid Point 专用表示区域</h3><p>因为只有 IoU &gt; 0.5 的 proposals（正例）才可能会被选择送入 Grid 分支，所以 supervision map 上 gt grid point 被限制在一个较小的区域，如图 2 所示是各个 grid point 的 gt label 分布，以 3x3 grid points 为例说明，左上角 point 的 gt label 只可能出现在 supervision map 的左上角区域，所以，如果所有 grid points 的表示区域均相同（相同的 scale 和 center），那么大多数 pixel 的输出均不会被激活，这是很低效的，于是就有了 grid point 专用表示区域。<br><img src="/images/Grid-RCNN-Plus_fig2.png" alt=""></p><p>原来每个 grid point 的表示区域的尺度是 56x56，现在降为 28x28，是原来区域中最有可能的 1/4，这样输出 heatmap 尺度降为一半。Grid point 专用表示区域也可以看作一种规范化过程，即，从原来的有偏分布到现在的规范化分布，如图 2 中，上左 point 和 中右 point 的 gt label 分布均以区域中心为中心。</p><h3 id="Light-Grid-Head"><a href="#Light-Grid-Head" class="headerlink" title="Light Grid Head"></a>Light Grid Head</h3><p>由于输出 heatmap 尺度变为一半，我们同时将 grid 分支中其中 features 的分辨率也降为一半（例如从 14x14 降为 7x7），这降低了计算损耗。具体而言，使用 RoIAlign 从 RoI 中抽取固定大小 14x14 的特征之后，使用一个 3x3 stride=2 的卷积层，使得特征 size 降为 7x7，在这之后，使用 7 个 3x3 stride=1 的卷积层，每层的输出特征大小均为 7x7，最终特征分为 N 组（默认为 9）每组特征对应一个 grid point。我们显式地将特征与 grid points 一一起来，然后使用 2 个 2x 反卷积生成 28x28 的 heatmaps。</p><p>grid point 专用表示区域使得不同的 grid points 的特征之间更加联系紧密，所以不需要很多的卷积层来弥补不同 grid points 特征之间的差异，所以 Grid R-CNN Plus 仅使用一个 5x5 depth-wise 的卷积，depth-wise 表示一个卷积核负责一个通道（二维平面上的卷积），而 Grid R-CNN 则使用三个 5x5 的普通卷积。这个改进也使得 grid 分支更加轻量。</p><h3 id="跨越图像的采样策略"><a href="#跨越图像的采样策略" class="headerlink" title="跨越图像的采样策略"></a>跨越图像的采样策略</h3><p>grid branch 仅使用正例（IoU &gt; 0.5 的 positive proposals）进行训练，那么不同训练批次如果具有不同数量的正例，会对最终性能产品影响，例如，某些图像只有极少数正例，而其他图像可能会包含成百上千的正例，这种情况会导致 grid 分支的特征分布不稳定。所以在 Grid R-CNN Plus 中采用跨越单个图像的采样策略：当某个图像中正例数量较小时，可以使用其他图像来填充正例的空缺。具体操作为，将原来单个图像采样 96 个正例改为每两个图像采样 192 个正例。这种改进使得训练更加稳定，性能也得到提升。</p><h3 id="仅一次-NMS"><a href="#仅一次-NMS" class="headerlink" title="仅一次 NMS"></a>仅一次 NMS</h3><p>Grid R-CNN 中，proposals 经过分类分支得到分类得分，然后使用 IoU 阈值 0.5 进行非极大抑制 NMS，之后取分类得分 top 125 的 proposals 送入 grid 分支进行定位预测，然后再次进行 NMS 以得到更加精确的结果。然而 NMS 是非常耗费计算量的，实验显示即使较少数量的 proposals，在 80 个分类（COCO 分类数量）上的 NMS 也很慢，所以 Grid R-CNN Plus 中移除了第二次 NMS。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验略。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RepPoints</title>
      <link href="/2019/07/17/obj_det/RepPoints/"/>
      <url>/2019/07/17/obj_det/RepPoints/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1904.11490">RepPoints: Point Set Representation for Object Detection</a><br><span id="more"></span><br>大多数目标检测器使用 bbox 表示目标的位置，但是本文认为 bbox 对目标的位置描述较为粗糙，所以提出了一种新型的更加精确的目标表示方法 RepPoints（representative points），RepPoints 使用一组采样点进行目标定位和识别。通过训练给定目标的 gt 位置和分类，RepPoints 可以学习自动排布这些点使得这些点能勾画出目标边缘并在语义上确定目标所在区域。这是一种 anchor-free 的目标检测器，避开了 anchor 导致的搜索空间大和 anchor 难于设计等缺点。</p><p>如图 1，<br><img src="/images/RepPoints_fig1.png" alt=""></p><p>RepPoints 使用一个点集，这个点集中各点位于目标边缘，并且语义上表明了目标所在的局部区域。<del>RepPoints 与其他非矩阵表示的目标检测器区别在于其他目标检测器采用 bottom-up 的方式确定一些独立的点（比如角点或极点），然后依靠手工设计的聚合方法聚合这些点以获得预测 box，而 RepPoints 则是 top-down 的方式从输入 image/目标特征中学习并且能够端到端的训练。</del></p><h1 id="RepPoints"><a href="#RepPoints" class="headerlink" title="RepPoints"></a>RepPoints</h1><h2 id="BBox-表示"><a href="#BBox-表示" class="headerlink" title="BBox 表示"></a>BBox 表示</h2><p>目标 bbox 可表示为 $\mathcal B=(x,y,w,h)$。我们回归一下 multi-stage 目标检测器，每经过一个 stage，目标定位都会得到调整，过程如下，</p><p>bbox anchors -(bbox reg)-&gt;  bbox proposals (S1)<br>             -(bbox reg)-&gt;  bbox proposals (S2)<br>             …<br>             -(bbox reg)-&gt;  bbox object targets</p><p>开始时使用多个具有不同 scale 和 aspect ratio 的 anchors。anchor 中心处的特征（向量）用于预测目标分类的得分（二值分类，前景/背景），以及预测坐标偏差。调整后的 bbox 称为 proposal (S1)。在第二 stage，从 S1 中继续抽取特征，通常是 RoIpooling/RoIAlign，对于 two-stage 目标检测器，S1 中抽取的特征将用于最终的 box 的分类预测和坐标偏差预测。对于 multi-stage 目标检测器，S1 中抽取的特征用于预测生成 S2，逐次进行此过程，直到最后一个 stage 用于预测最终的 bbox target。</p><p>坐标回归预测为一个 4-d 向量 $(\Delta x_p, \Delta y_p, \Delta w_p, \Delta h_p)$，再结合 bbox proposal 的坐标 $\mathcal B_p=(x_p,y_p,w_p,h_p)$ 可解码出调整后的预测 bbox，</p><script type="math/tex; mode=display">\mathcal B_r=(x_p+w_p \Delta x_p, \ y_p+h_p\Delta y_p, \ w_p e^{\Delta w_p}, \ h_p e^{\Delta h_p})</script><p>记目标的 gt 位置为 $\mathcal B_t=(x_t,y_t,w_t,h_t)$，gt 坐标偏差（gt target）为，</p><script type="math/tex; mode=display">\hat {\mathcal F}(\mathcal B_p, \mathcal B_t)=(\frac {x_t-x_p} {w_p},\ \frac {y_t-y_p} {h_p},\ \log \frac {w_t} {w_p}, \ \log \frac {h_t} {h_p})</script><p>回归损失使用 smooth L1 损失。</p><h2 id="RepPoints-1"><a href="#RepPoints-1" class="headerlink" title="RepPoints"></a>RepPoints</h2><p>前文提到，4-d bbox 是一种比较粗糙的目标位置表示，不能反映目标的性质、姿势以及语义上的区域。RepPoints 能够解决这些问题，使用一组自适应采样点，</p><script type="math/tex; mode=display">\mathcal R = \{(x_k,y_k)\}_{k=1}^n</script><p>其中 n 为采样点数量，本文设置为 9。</p><p>RepPoints 的坐标调整可表示为，</p><script type="math/tex; mode=display">\mathcal R_r = \{(x_k+\Delta x_k,\ y_k+\Delta y_k)\}_{k=1}^n \qquad (5)</script><p>其中 $\{(\Delta x_k,\ \Delta y_k)\}_{k=1}^n$ 表示新采样点与旧采样点之间的偏差，refine 旧采样点之后得到新采样点。</p><p><strong>RepPoints 变换到 gt box:</strong> $\mathcal {T: R}_P \rightarrow \mathcal B_P$，其中 $\mathcal R_P$ 表示目标 P 的 RepPoints，$\mathcal T(\mathcal R_p)$ 表示伪 box，变换函数考虑以下三种，</p><ol><li><p>Min-max function<br>$\mathcal {T=T_1}$：根据所有 RepPoints 确定横轴和纵轴上的最小最大值，以得到 $\mathcal B_p$</p></li><li><p>Partial min-max function<br>$\mathcal {T=T_2}$：根据部分 RepPoints 确定横轴和纵轴上的最小最大值，以得到 $\mathcal B_p$</p></li><li><p>Moment-based function<br>$\mathcal {T=T_3}$：使用 RepPoints 的期望值和二阶矩（方差）来计算 $\mathcal B_p$ 的中心和 scale，其中 scale 需要乘上全局共享的可学习系数 $\lambda_x, \ \lambda_y$。使用坐标的均值作为 box 的中心，这一点不难理解，RepPoints 为目标边缘的点，故目标越大，RepPoints 坐标的方差越大，两者应该成正比，所以将方差乘以系数可得到目标 size。考虑到任意目标的 RepPoint 都不是固定的，所以系数可以全局共享，并且可通过 point loss 学习得到。</p></li></ol><p><strong>RepPoints 的学习</strong> 学习过程由目标定位损失和目标分类损失驱动。对于定位损失，首先使用上述某个转换函数将 RepPoints 转换为 pseudo box，然后计算与 gt box 之间的距离，这里使用左上角和右下角的 smooth L1 距离作为定位损失。</p><h1 id="RPDet"><a href="#RPDet" class="headerlink" title="RPDet"></a>RPDet</h1><p>类似地，multi-stage 中使用 RepPoints 的目标表示演进过程为，</p><p>object centers -(RP refine)-&gt; RepPoints proposals(S1) -(RP refine)-&gt; RepPoints proposals(S2) … -(RP refine)-&gt; RepPoints object targets</p><p>RPDet (RepPoints Detector) 结构如图 2，<br><img src="/images/RepPoints_fig2.png" alt=""></p><p>其中 N 表示 RepPoints 的数量。</p><p>采用 FPN backbone，得到的 feature maps，一支经过 3x3 卷积得到 offset field，这是一个与输入 feature maps 相同 spatial size 的 2N-channel 的特征，每个空间位置的 feature vector 是 2N-d 的，表示这个位置处的 offsets，offsets 是用于 deformable conv，同时也是 RepPoints，相当于给 deformable conv 的 offsets 赋予了物理含义，变换这个 offsets 得到 pseudo box，与 gt box 之间的左上和右下两点的 point loss（smooth L1 损失）用于优化这一分支。</p><p>得到的 offsets 用于 deformable conv，然后再经过卷积得到第二组的 offsets，根据 (5) 式得到 refinement 之后的 RepPoints（也就是说第二组的 offsets 其实是 $\Delta x, \Delta y$？），表示最终的目标定位，另一分支经过卷积得到目标分类 score maps。</p><h2 id="与可变形-RoI-pooling-的关系"><a href="#与可变形-RoI-pooling-的关系" class="headerlink" title="与可变形 RoI pooling 的关系"></a>与可变形 RoI pooling 的关系</h2><p>可变形卷积和可变形 RoI pooling 用于改善特征抽取，而 RepPoints 是一种灵活的目标几何表示方式，可以抽取语义特征，从而准确地定位目标。作者认为，可变形 RoI pooling 无法学习到表示目标精确位置的采样点，原因为：假设可以学习到目标位置的几何表示，那么对于同一目标的两个靠的很近的 proposals，可变形 RoI pooling 将生成相同的特征，这表示目标检测器会失败；然而，可变形 RoI pooling 已经通过实验证明可以区分两个靠的很近的 proposals，这说明，可变形 RoI pooling 无法学习到目标的准确位置表示。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>略</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>本文比较晦涩难懂，需要多读几遍，并且期待作者放出源码。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DetNet</title>
      <link href="/2019/07/17/obj_det/DetNet/"/>
      <url>/2019/07/17/obj_det/DetNet/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1804.06215">DetNet: A Backbone network for Object Detection</a><br><span id="more"></span><br>本文创作动机是当前大多数的目标检测器都是在 ImageNet 上预训练后 finetune 到目标检测集，目标检测器的 backbone 原本是为了图像分类任务而设计的，这样的 backbone 显然不是最佳的，较大的下采样率带来较大的感受野 RF，这对图像分类是有益的，对目标检测尤其是小目标而言则是不利的，所以像 FPN 和 RetinaNet 就使用了额外的网络结构（extra stage）来处理目标的多尺度问题，但是这总归不是一个优雅的解决办法，所以本文提出了 DetNet，这是一个专为目标检测而设计的新型 backbone。</p><p>DetNet 保持了 FPN 中的额外网络结构（extra stage），毕竟是目标的多尺度问题的一个较为不错的解决方案。与 FPN 等基于 ImageNet 预训练的目标检测器不同的是，DetNet 的深层依然有较高的空间分辨率，不过考虑到高分辨率与计算资源的矛盾，我们采用了一种低复杂度的 dilated bottleneck 结构。</p><h1 id="DetNet"><a href="#DetNet" class="headerlink" title="DetNet"></a>DetNet</h1><p>如图 1(A) 是 FPN 的部分网络结构，图像分类任务和目标分类任务本身就存在很大的不同，并且基于此结构的模型训练还存在以下问题：<br><img src="/images/DetNet_fig1.png" alt=""><center>A. 具有传统的 backbone 的 FPN 结构；B. 图像分类中传统的 backbone；C. DetNet 的 backbone，比 FPN 的分辨率高</center></p><ol><li>网络 stage 的数量不同。图像分类的网络包含 5 个 stages，每个 stage 下采样率为 2，故输出分辨率为 32 倍的下采样，而 FPN 拥有更多的 stages，比如增加 P6 以处理更大的目标，在 RetinaNet 中也同样增加了 P6 和 P7。</li><li>大目标的可视性较差。具有 32 的步幅的 feature map 包含较强的语义信息，然而这对目标定位是不利的，FPN 中大目标是由较深 layer 进行预测，难以回归到准确的目标边界。</li><li>小目标的不可见性。大的步幅显然会导致小目标的丢失，所以 FPN 在较浅 layer 上预测小目标，然而浅 layer 只有很弱的语义信息，可能不足以预测目标分类，故为了加强浅 layer 的目标分类能力，将深 layer 的特征上采样后合并进浅层特征，如图 1 A 所示，只不过，如果小目标在较深 layer 中已经丢失，那么深层特征上就没有小目标的 context 信息，这样的深层特征合并进浅层特征并不会增强对小目标的分类能力。</li></ol><p>DetNet 经过如下设计可解决以上问题：</p><ol><li>直接为目标检测量身定制 stage 的数量</li><li>即使 stage 的数量很多，如 6~7 个 stage，对于 deep layer，在保持较大感受野（有利于分类）的同时有较大的分辨率（有利于目标定位）。</li></ol><h2 id="DetNet-设计"><a href="#DetNet-设计" class="headerlink" title="DetNet 设计"></a>DetNet 设计</h2><p>使用 ResNet-50 作为 baseline。在 ResNet-50 的基础之上构建 DetNet-59（类似地也可以在 ResNet-101 基础上构建 DetNet，在本文中这不是重点）。DetNet 的 stage 1,2,3,4 与 ResNet-50 的 stage 1,2,3,4 完全相同。这里给出 ResNet-50 前四个 stage 的结构描述，</p><div class="table-container"><table><thead><tr><th style="text-align:center">ResNet</th><th style="text-align:center">output size</th><th style="text-align:center">50-layer</th></tr></thead><tbody><tr><td style="text-align:center">conv1</td><td style="text-align:center">112x112</td><td style="text-align:center">7x7,64, stride 2</td></tr><tr><td style="text-align:center">maxpool</td><td style="text-align:center">56x56</td><td style="text-align:center">3x3, stride 2</td></tr><tr><td style="text-align:center">conv2_x</td><td style="text-align:center">56x56</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; 64 \\\\ 3 \times 3 &amp; 64 \\\\ 1 \times 1 &amp; 256\end{bmatrix} \times 3$</td></tr><tr><td style="text-align:center">conv3_x</td><td style="text-align:center">28x28</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; 128 \\\\ 3 \times 3 &amp; 128 \\\\ 1 \times 1 &amp; 512\end{bmatrix} \times 4$</td></tr><tr><td style="text-align:center">conv4_x</td><td style="text-align:center">14x14</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; 256 \\\\ 3 \times 3 &amp; 256 \\\\ 1 \times 1 &amp; 1024\end{bmatrix} \times 6$</td></tr></tbody></table></div><p>从第五个 stage 开始介绍 DetNet，如图 2 D 所示，DetNet-59 的设计细节如下：<br><img src="/images/DetNet_fig2.png" alt=""><center>fig 2. DetNet 的结构细节</center></p><ol><li>从上图中可见，我们在 backbone 中引入了 extra stage，即 P6，与 FPN 中一样，也是用于目标检测，只不过，从 stage 4 开始，我们就固定了步幅 16，即每个 stage 的输出空间大小。</li><li>从 stage 4 开始的空间大小就固定不变，本文引入一种 dilated bottleneck 和 1x1 卷积并列的结构，用于之后每个 stage 的最开始，如图 2 B。</li><li>bottleneck 中的 dilated conv 可以增大感受野。由于 dilated conv 较为耗时，所以 stage 5 和 6 的 channel 与 stage 4 保持相同（维持在256），这一点与传统 backbone 设计不一样，传统 backbone 的后一个 stage 的 channel 是前一个 stage 的两倍（如 ResNet-50 中的 64-&gt;128-&gt;256-&gt;512）。</li></ol><p>DetNet 作为 backbone 可以很方便地移植到（具有/不具有 feature pyramid 的）目标检测器中。不失代表性地，我们采用 FPN 作为主检测器，除了 backbone 不同，其他结构与原先 FPN 中保持相同。由于 stage 4 之后的 stage 输出大小不变，所以将 stage 4,5,6 的输出相加，如图 2 E。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验和结果分析，略</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>loss</title>
      <link href="/2019/07/16/dl/loss/"/>
      <url>/2019/07/16/dl/loss/</url>
      
        <content type="html"><![CDATA[<p>总结一些常见的损失（虽然我把本文归类到 CV，但实际上这些损失函数并不仅仅用于 CV 中，只是目前我只关注 CV 而已）<br><span id="more"></span></p><h1 id="Cross-Entropy-Loss"><a href="#Cross-Entropy-Loss" class="headerlink" title="Cross-Entropy Loss"></a>Cross-Entropy Loss</h1><p>交叉熵损失常用于分类任务中，比如共有 C 中可能的分类，（softmax 之后的）预测向量为 $P=(p_1,…,p_C)$，其中 $p_i$ 表示分类为 i 的概率，且有 $\sum_i^C p_i=1$，目标真实分类为 c，那么 gt target 为 $T=(t_1,…,t_C)$，其中</p><script type="math/tex; mode=display">t_i=\begin{cases} 1 & i=c \\\\ 0 & i\ne c \end{cases}</script><p>于是交叉熵损失为</p><script type="math/tex; mode=display">CE=-\sum_{i=1}^C t_i \log p_i</script><h2 id="Binary-Cross-Entropy-Loss"><a href="#Binary-Cross-Entropy-Loss" class="headerlink" title="Binary Cross-Entropy Loss"></a>Binary Cross-Entropy Loss</h2><p>特别地，当分类数量 C=2 时，目标为正的预测概率为 p，真实分类为 t，$t \in \{0,1\}$，</p><script type="math/tex; mode=display">CE=-t \log p - (1-t) \log (1-p)</script><p>为方便起见，记</p><script type="math/tex; mode=display">p_t=\begin{cases} p & t=1 \\\\ 1-p & t=0 \end{cases}</script><p>于是，</p><script type="math/tex; mode=display">CE=-\log p_t</script><h2 id="Balanced-Cross-Entropy-Loss"><a href="#Balanced-Cross-Entropy-Loss" class="headerlink" title="Balanced Cross-Entropy Loss"></a>Balanced Cross-Entropy Loss</h2><p>如果样本分类分布不均（long-tail distribution），即少数分类的占据了绝大多数样本，而其他分类的样本数量则非常少，比如二分类中，分类为 1 的样本很少而分类为 0 的样本很多，那么从分类为 1 的样本中学习到的信息就有限，或者说分类为 1 的样本对损失贡献较小从而对优化过程作用较弱，故引入权重因子，t=1 具有权重 $\alpha$，t=0 具有权重 $1-\alpha$，$\alpha \in [0,1]$。实际操作中，设置 $\alpha$ 反比例于分类样本频次，或将 $\alpha$ 作为超参数通过交叉验证设置其值（RetinaNet 中设置为 0.25）。于是平衡交叉熵损失为，</p><script type="math/tex; mode=display">CE=-\alpha_t \log p_t</script><h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>虽然 balanced cross-entropy loss 中 $\alpha$ 平衡了正负样本，但是并没有区分简单样本和困难样本，我们知道 $p_t \gg 0.5$ 属于简单样本，当简单样本数量很多时，其贡献的总损失不容忽视，显然，我们更应该重视困难样本，因为从困难样本中更能学习到有用（对模型至关重要的）信息，所以，降低简单样本的损失权重，比如这里的 Focal loss，</p><script type="math/tex; mode=display">FL=-(1-p_t)^{\gamma} \log p_t \ , \ \gamma \ge 0</script><p>其中 $(1-p_t)^{\gamma}$ 称为调节因子。</p><p>Focal loss 的性质：</p><ol><li>$p_t$ 较小，表示误分类，困难样本，此时 $(1-p_t)^{\gamma}$ 相对较大</li><li>$p_t$ 较大，表示分类正确，简单样本，此时 $(1-p_t)^{\gamma}$ 相对较小</li></ol><h1 id="MSE"><a href="#MSE" class="headerlink" title="MSE"></a>MSE</h1><p>均方误差为</p><script type="math/tex; mode=display">MSE = \frac 1 n \sum_{i=1}^n (Y_i-\hat Y_i)^2</script><p>表示 n 个样本的 L2 范数误差的平均，其中 $Y_i, \hat Y_i$ 分别表示第 i 个样本的真实值和预测值。</p><h2 id="L2-Loss"><a href="#L2-Loss" class="headerlink" title="L2 Loss"></a>L2 Loss</h2><script type="math/tex; mode=display">L_2=(Y_i-\hat Y_i)^2</script><p>缺点：当 $|Y_i-\hat Y_i|&gt;1$ 时，误差会被放大很多，导致模型训练不稳定。</p><h2 id="L1-Loss"><a href="#L1-Loss" class="headerlink" title="L1 Loss"></a>L1 Loss</h2><script type="math/tex; mode=display">L_1=|Y_i-\hat Y_i|</script><p>缺点：当 $|Y_i-\hat Y_i|&lt;1$ 时，梯度（的绝对值）不变，导致优化过程出现震荡。</p><h2 id="Smooth-L1-Loss"><a href="#Smooth-L1-Loss" class="headerlink" title="Smooth L1 Loss"></a>Smooth L1 Loss</h2><p>结合以上两点，得到 Smooth L1 损失，</p><script type="math/tex; mode=display">L=smooth_{L_1}(Y_i-\hat Y_i)\\\\ smooth_{L_1}(x)=\begin{cases} 0.5 x^2 & |x|<1\\\\ |x|-0.5 & otherwise \end{cases}</script><h2 id="Regularized-Loss"><a href="#Regularized-Loss" class="headerlink" title="Regularized Loss"></a>Regularized Loss</h2><p>机器学习中，为防止过拟合加入正则项损失，通常是参数的 L1 范数或 L2 范数，略。</p>]]></content>
      
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeRPN</title>
      <link href="/2019/07/15/obj_det/DeRPN/"/>
      <url>/2019/07/15/obj_det/DeRPN/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1811.06700">DeRPN: Taking a further step toward more general object detection</a><br><span id="more"></span><br>two-stage SOTA 目标检测器通常会使用 anchor，比如 Faster R-CNN 中的 RPN，但是对于不同的数据集，则需要重新设计超参数，如 anchor 的 scale 和 aspect ratio，并且一旦选定就固定了，这在被检测目标尺度变化较大时，检测性能往往不理想，当然，也有人尝试使用 K-means 聚类计算得到 anchor，但是对最终的检测性能的提升非常有限。本文提出 DeRPN 用于解决 RPN 的这一不足之处，如图 1(b)，<br><img src="/images/DeRPN_fig1.png" alt=""></p><p>DeRPN 通过分离宽度和高度来分解检测维度（维度分解）。利用灵活的 anchor strings（不理解这个概念没关系，阅读完下一节就理解了），使得可以选择最佳 anchor 来匹配目标。</p><h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><h2 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h2><p>我们知道目标检测网络通常都是一个 CNN 网络用于抽取特征，记抽取到的特征为 $\mathbf x$，然后经过两个并行的检测分支：回归和分类，其中回归是在 anchor box （$B_a$）基础上进行回归得到目标位置，而分类分支则在最后的预测值上应用 sigmoid（二分类）或 softmax（多分类），记此函数为 $\sigma$，从而得到 bbox 的分类置信度（概率），用数学语言描述则为：</p><script type="math/tex; mode=display">\mathbf t = \mathbf {W}_t \mathbf x+ \mathbf {b}_r\\\\ B(x,y,w,h)=\psi(\mathbf t, B_a(x_a,y_a,w_a,h_a))\\\\ P_B=\sigma (\mathbf {W}_c \mathbf x + \mathbf {b}_c)</script><p>其中 $\mathbf {W_r, b_r}$ 表示回归分支的权重和偏置，$\mathbf {W_c, b_c}$ 表示分类分支的权重和偏置，$\psi$ 表示预测 box 的位置解码，例如 Faster R-CNN 中根据位置偏差 $\mathbf t$ 和 region proposals 的坐标计算出预测 box 的坐标。</p><p>显然由于目标形状的多样性，anchor 的数量会非常大，这不利于训练，而且我们也很难设计出合适的 anchor 形状，所以当 anchor 严重偏离 gt box 时，检测性能下降! 目标检测的维度分解具体是指分离宽度和高度，以减轻目标不同尺度带来的影响。我们引入 anchor string，$(S_a^w(x_a,w_a), S_a^h(y_a,h_a))$，各自分别作为目标宽度和高度的回归参照，anchor string 分别独立预测 $(S_w(x,w), S_h(y,h))$ 以及对应的分类概率 $(P_s^w, P_s^h)$，此过程的数学语言描述为，</p><script type="math/tex; mode=display">\mathbf t^w=\mathbf {W_r}^w \mathbf {x+ b_r}^w \qquad S_w(x,w)=\psi(\mathbf t^w, S_a^w(x_a,w_a))\\\\ \mathbf t^h=\mathbf {W_r}^h \mathbf {x+ b_r}^h \qquad S_h(x,w)=\psi(\mathbf t^h, S_a^h(y_a,h_a))\\\\ P_s^w=\sigma (\mathbf {W_c}^w \mathbf {x+b_c}^w) \qquad P_s^h=\sigma (\mathbf {W_c}^h \mathbf {x+b_c}^h)</script><p>相比上一组计算式，容易看出确实是将宽度和高度分类开来（包括分类概率也分解为两个维度上各自独立的分类概率）。现在我们从分解开来的两个维度预测恢复出 bbox 的位置以及分类置信度，</p><script type="math/tex; mode=display">B(x,y,w,h)=f(S_w(x,w),S_h(y,h))\\\\ P_B=g(P_s^w, P_s^h)</script><p>其中，f 表示合并两个维度的一种策略函数，g 计算合并后 bbox 的分类置信度（可以是算术平均，或调和平均）。</p><h3 id="匹配复杂度"><a href="#匹配复杂度" class="headerlink" title="匹配复杂度"></a>匹配复杂度</h3><p>假设数据集中目标的宽度或高度共有 n 种情况，那么一共有 $n^2$ 种情况需要 anchor box 去匹配，即，匹配复杂度为 $O(n^2)$，而在维度分解下，n 种宽度和高度分别独立地由 anchor string 去匹配，匹配复杂度降为 $O(n)$。</p><h2 id="维度分解"><a href="#维度分解" class="headerlink" title="维度分解"></a>维度分解</h2><h3 id="Anchor-strings"><a href="#Anchor-strings" class="headerlink" title="Anchor strings"></a>Anchor strings</h3><p>RPN 以 anchor string 作为回归参照，DeRPN 则将二维 box 拆分为两个独立的一维部分作为回归参照，称为 anchor string。虽说 anchor string 可以匹配任意object 的宽度或高度，设置 anchor string 为一个等比数列 $\{a_n\}$，例如 (16,32,64,128,256,512,1024)，此时可用于匹配目标宽度或高度的范围为 $[8\sqrt 2,1024 \sqrt 2]$，通常这已经足够覆盖很多场景下的目标尺寸了。解释一下这个的 $\sqrt 2$，记一个 anchor string 长度值（等比数列中的一项）为 $a_i$，这个 anchor string 可匹配的目标边长范围为$[a_i/\sqrt 2, a_i\sqrt 2]$，由于等比数列中公比为2，此时这个等比数列中各项所匹配的目标边长范围无缝连接，形成一个大的范围 $[8\sqrt 2,1024 \sqrt 2]$。</p><p>图 2 为 DeRPN 网络，<br><img src="/images/DeRPN_fig2.png" alt=""> <center>(a) 目标宽度和高度分别独立使用 anchor string 匹配，粗线表示匹配较好的 anchor string；(b) 在 anchor string 上应用分类和回归，虚线表示置信度低的 anchor string；(c) 合并预测的宽度和高度生成 bbox；(d) 使用置信度阈值和 NMS 过滤得到 region proposals。</center></p><p>如何为目标选择最佳匹配的 anchor string？在 RPN 中，通过 anchor box 与 gt box 的 IoU 决定是否选择 anchor 参与训练。比如， anchor 的最大 IoU 超过 0.7，或者 gt 的最大 IoU 对应的 anchor 均可作为正例。在 DeRPN 中则基于长度将 anchor string 与目标进行匹配，评估最佳匹配 anchor string 的方法为，</p><script type="math/tex; mode=display">M_j=\{i|\arg \min_i |\log e_j - \log a_i|\} \cup \{i,i+1| \begin{vmatrix}\frac {e_j} {a_i} - \sqrt q \end{vmatrix} \le \beta\}, \ (i=1,...,N) \quad(9)</script><p>$M_j$ 表示与第 j 个目标匹配的 anchor string 的索引，$e_j$ 是目标边长（宽或高），N 是等比数列 $\{a_n\}$ 中的项数，q 是等比数列的公比（本文中设置为 2）。</p><p>上式中，第一项表示选择与目标边长最接近的 anchor string，这是一种很直观的选择策略，然而还有第二种选择策略，见上式第二项，我们将条件约束稍作变形得 $(\sqrt q-\beta)\times a_i \le e_j \le (\sqrt q+\beta)\times a_i$，范围 $[(\sqrt q-\beta)\times a_i, (\sqrt q+\beta)\times a_i]$ 称为 i 关联的转移区间，$\beta$ 控制区间长度，如果目标边长 $e_j$ 位于此范围内，那么选择 i 和 i+1 作为匹配的 anchor string 的索引。</p><p>上文我们说到 $a_i$ 可匹配的目标边长范围为 $[a_i/ \sqrt q,a_i\sqrt q]$，按道理说，如果 $e_j$ 落于这个区间，就选择 i 作为匹配的索引就好了鸭（不考虑边长等于区间端点值的情况，事实上这种情况的可能性为0），但是考虑到图像噪声和 gt 标记偏离正确位置等因素，按照这个选择策略选择的 i 不一定准确，而图像噪声和 gt 标记偏离正确位置等因素所带来的影响相对较小，所以我们选择连续的两个 anchor string 索引即可保证目标能落入这两个连续 anchor string 的可匹配范围，$a_i, a_{i+1}$ 的可匹配范围为 $[a_i/\sqrt q, a_i \sqrt q] \cup [a_i \sqrt q,qa_i\sqrt q]$，其（非几何）“中心”为 $a_i \sqrt q$，所以很自然地，如果目标边长 $e_j$ 在这个“中心”附近，就选择 i 和 i+1 作为匹配索引，判断是否在附近的条件不难理解，</p><script type="math/tex; mode=display">(\sqrt q-\beta)\times a_i \le e_j \le (\sqrt q+\beta)\times a_i</script><p>剩下的就不多说了。</p><p>忽略转移区间，可以知道 anchor string 与目标边长之间的最大偏移比例为 $\sqrt q$（如果考虑转移区间，最大偏移比例则为 $\max(\sqrt q + \beta, q/(\sqrt q-\beta))$，也就比 $\sqrt q$ 大一点点），这表示 DeRPN 中回归损失是有界的，而 RPN 中较小的 IoU 则会导致较大的回归损失，经验表明，如果 anchor box 严重偏离 gt，RPN 甚至无法收敛</p><h3 id="Label-assignment"><a href="#Label-assignment" class="headerlink" title="Label assignment"></a>Label assignment</h3><p>对齐的 anchor string 位于 feature map 上目标中心处，其中与目标匹配较好的（根据式 (9)）则标记为正。除了对齐的 anchor string，还使用了 observe-to-distribute 策略来选择其他 anchor string：1. 观察每个 anchor string 的回归结果，回归之后，结合宽度/高度的预测得到 region proposal，如果这个 region proposal 与某个 gt 的 IoU 大于一定阈值（0.6），那么就将正标签分发到对应的 anchor string 上。不满足以上任何条件的 anchor string 则标记为负。</p><h3 id="Consistent-network"><a href="#Consistent-network" class="headerlink" title="Consistent network"></a>Consistent network</h3><p>DeRPN 与 RPN 的网络结构是一致的，故可方便地移植到当前 two-stage 目标检测器中。如图 2 所示，由一个 3x3 的卷积层，后跟两个并列的 1x1 卷积层，分别用于分类和回归，组成了 DeRPN 网络。记 anchor string 长度的等比数列为 $\{a_n\}$，数量为 N，宽度和高度独立使用 anchor string，分类预测 $2\times 2N$ 个得分来估计 anchor string 是否匹配目标边长（二值分类置信度），anchor string 预测目标的宽需要两个值 $(x,w)$，同理对于目标的高也需要两个值 $(y,h)$，故回归一共预测 $2 \times 2N$ 个值。</p><h3 id="Scale-sensitive-loss-function"><a href="#Scale-sensitive-loss-function" class="headerlink" title="Scale-sensitive loss function"></a>Scale-sensitive loss function</h3><p>目标的尺度分布不是均匀的，大目标比小目标更多。如果简单地将目标混合起来计算损失，那么小目标对损失的影响将会被大目标带来的影响所淹没，本文提出一种新型的尺度敏感的损失函数，公平地对待不同尺度的目标，</p><script type="math/tex; mode=display">L(\{p_i\},\{t_i\})=\sum_{j=1}^N \sum_{i=1}^M \frac 1 {|R_j|} L_{cls}(p_i,p_i^*) \cdot \Bbb I\{i \in R_j\} + \lambda \sum_{j=1}^N \sum_{i=1}^M \frac 1 {|G_j|} L_{reg} (t_i,t_i^*)\cdot \Bbb I\{i \in G_j\} \quad (10)\\\\ R_j=\{k|s_k=a_j, k=1,...,M\} \quad (11)\\\\ G_j=\{k|s_k \in A, s_k=a_j, p_i^*=1, k=1,...,M\} \quad (12)</script><p>这里，N 是等比数列的项数，M 是 batch size，s 表示 anchor string，$p_i$ 表示一个批次中第 i 个 anchor string 的预测概率，$p_i^<em>$ 表示 gt label，当 anchor string 为正时等于 1， 否则等于 0。$t_i$ 表示参数化坐标的预测向量，$t_i^</em>$ 为相应的 gt 向量。A 表示对齐的 anchor string 集合。$R_j$ 这个索引集包含了具有相同尺度的 anchor string，其中 j 用于指示尺度 $a_j$。$G_j$ 这个索引集包含了具有相同尺度的对齐的正 anchor string，同样 j 用于指示尺度 $a_j$。上式表明每个尺度下的目标损失均根据这个尺度下的 anchor string 数量进行归一化，这可以有效地避免小目标优化作用被大目标淹没。分类损失使用交叉熵，回归损失使用 smooth L1 损失，</p><script type="math/tex; mode=display">L_{cls}(p_i,p_i^*)=- p_i^*\log p_i-(1-p_i^*)\log (1-p_i)\\\\ L_{reg}(t_i,t_i^*)=\sum_{j \in \{x,y,w,h\}} smooth_{L_1}(t_i^j,t_i^{j*})</script><p>预测值 t 表示坐标偏差，这一点与 Fast/Faster R-CNN 中完全一样，故可根据下式解码出预测 box 坐标，</p><script type="math/tex; mode=display">x=x_a+w_a \times t_x \quad (13)\\\\ y=y_a+h_a \times t_y \quad (14)\\\\ w=w_a \times e^{t_w} \qquad (15)\\\\ h=h_a \times e^{t_h} \qquad (16)</script><h1 id="维度合并"><a href="#维度合并" class="headerlink" title="维度合并"></a>维度合并</h1><p>DeRPN 使用维度分解来预测，然而最终的 region proposal 是二维的 bbox，故需要合并宽和高以恢复出 region proposal。</p><p><strong>像素级别的合并算法</strong> 根据预测坐标偏差 t 和 anchor string 可以解码出宽和高，记所有预测宽的集合为 W，根据预测宽的概率选择 top-N，记 $W_N$，对于这 top-N 中任意一个宽的预测 (x,w)（对应的概率为 $p^W$），我们在 (x,w) 所在的像素位置处选择 top-k 的目标高的预测 $(y^{(k)},h^{(k)})$，于是得到一系列的 bbox $B_w=\{(x,y^{(k)},w,h^{(k)}\}$，每个组合后的 bbox 的概率使用调和平均计算得到，</p><script type="math/tex; mode=display">p^B=2/ \left(\frac 1 {p^W}+\frac 1 {p^H}\right)</script><p>其中 $p^W$ 为 (x,w) 对应的预测概率，$p^H$ 为 $(y^{(k)},h^{(k)})$ 对应的预测概率。</p><p>类似地，对于 top-N 预测概率的目标高 $H_N$，按上面的策略选择得到 $B_h=\{(x^{(k)},y,w^{(k)},h\}$，对这两个集合的并 $B=B_w \cup B_h$ 使用 NMS，然后再选择 top-M 作为 region proposals。尽管这个合并过程引入了一些背景 bbox，但是第二 stage 的目标检测器可以通过分类分支抑制它们。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>请阅读原文，略。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><ol><li>介绍了 DeRPN，将目标的宽和高两个维度进行分解</li><li>使用了新型损失函数，避免了小目标（少数）的优化作用被大目标（多数）淹没</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpp-aux-tools</title>
      <link href="/2019/07/11/cpp/cpp-aux-tools/"/>
      <url>/2019/07/11/cpp/cpp-aux-tools/</url>
      
        <content type="html"><![CDATA[<p>来看一个 c++ 程序片段<br><span id="more"></span><br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; test.cppint f(int i) &#123; return 0; &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>编译<br><pre class="line-numbers language-none"><code class="language-none">gcc test.cpp -o test.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>查看 f 的 low-level assembler 名称（name mangling），<br><pre class="line-numbers language-none"><code class="language-none">nm test.o | grep f&#x2F;&#x2F; 输出&#x2F;&#x2F; 000000000000008b T _Z4fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>逆过程为<br><pre class="line-numbers language-none"><code class="language-none">c++filt -n _Z4fi&#x2F;&#x2F; 输出&#x2F;&#x2F; f(int)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><p>反汇编<br><pre class="line-numbers language-none"><code class="language-none">objdump -d test.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>更多 option 可查看 <code>objdump --help</code>。</p><p>查看头文件搜索路径<br><pre class="line-numbers language-none"><code class="language-none">gcc -xc++ -E -v -<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>查看链接库依赖<br><pre class="line-numbers language-none"><code class="language-none">ldd test.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>设置动态库、头文件搜索目录的相关环境变量<br><pre class="line-numbers language-none"><code class="language-none">export LD_LIBRARY_PATH&#x3D;&#x2F;xx&#x2F;xx:$LD_LIBRARY_PATHexport CPLUS_INCLUDE_PATH&#x3D;&#x2F;xx&#x2F;xx:$CPLUS_INCLUDE_PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><h2 id="生成静态库"><a href="#生成静态库" class="headerlink" title="生成静态库"></a>生成静态库</h2><pre class="line-numbers language-none"><code class="language-none">g++ -c x.cppar crv libx.a x.o<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="生成动态库"><a href="#生成动态库" class="headerlink" title="生成动态库"></a>生成动态库</h2><pre class="line-numbers language-none"><code class="language-none">g++ -shared -fPIC -o libx.so x.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mask-rcnn</title>
      <link href="/2019/07/08/obj_det/mask-rcnn/"/>
      <url>/2019/07/08/obj_det/mask-rcnn/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a><br><span id="more"></span></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这是一篇实例分割的文章。实例分割结合了目标检测和语义分割，这看似是需要一个复杂的模型才能完成的任务，实际上本文提出的 Mask R-CNN 出奇的简单灵活且高效。  </p><p>Mask R-CNN 是对 Faster R-CNN 的扩展，增加了一个分支用于预测每个 RoI 的分割掩模（segmentation masks），如图 1，这个分支与原先的分类和回归分支并列。mask 分支在 RoI 上以 pixel-to-pixel 方式预测得到一个 segmentation mask，有语义分割背景的话，不难想象 mask 分支应是一个全卷积网络 FCN。如何构建这个 mask 分支则至关重要。<br><img src="/images/mask-rcnn_fig1.png" alt=""></p><p>Faster R-CNN 的网络输入和输出之间不是点与点对齐，这是由于 RoIPool 层在抽取特征时使用了离散化空间坐标（坐标值必须为整数，RoI 坐标从输入 image 平面映射到 feature map 时，坐标变为原来的 1/16，并四舍五入取整），而 mask 分支是 pixel-wise 的，所以必须要解决这个不对齐问题，为此我们提出了 RoIAlign 层以保持准确的空间位置，这个改动虽小，但效果却十分明显：提高了大约 10%~50% 的 mask 准确度。  </p><p>另外，有必要将分类预测和 binary mask 预测解耦，每个分类独立进行 binary mask 预测，并根据 RoI 分类分支来确定目标分类。相反在语义分割 FCN 方法中，每个像素位置均进行多分类，这就耦合了分割和分类，如果用在实例分割任务中则表现较差。</p><h1 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h1><p>Faster R-CNN 中每个候选区域均对应两个输出：分类标签和坐标偏差。Mask R-CNN 则在此基础上增加第三个输出：目标 binary mask，与前两个输出不同的是，此输出需要非常精确的目标空间位置，这是 Mask R-CNN 的关键点之一。</p><p><strong>Faster R-CNN:</strong> 简单的回顾一下 Faster R-CNN，这是一个 two-stage 目标检测器，其中第一个 stage 为 RPN，用于生成 proposals，第二个 stage 其本质就是 Fast R-CNN，使用 RoIPooling 从每个 proposal 中提取固定长度的特征并进行分类和 bbox 回归。</p><p><strong>Mask R-CNN:</strong> 在 Faster R-CNN 基础上增加第二个 stage 的输出，即为每个 RoI 生成 binary mask。</p><p>训练时，每个 RoI 的损失为 $L=L_{cls}+L_{box}+L_{mask}$，其中分类损失 $L_{cls}$ 和回归损失 $L_{box}$ 均与 Fast/Faster R-CNN 中相同，</p><script type="math/tex; mode=display">L_{cls}=L_{cls}(p,u)=-\log p_u</script><p>上式为 log loss，proposal 对应的 gt 分类为 u，$p_u$ 为 proposal 分类为 u 对应的置信度（分类得分）。</p><script type="math/tex; mode=display">L_{loc}=L_{loc}(t^u,v)=\sum_{i \in \{x,y,w,h\}} smooth_{L_1}(t_i^u,v_i)</script><p>上式为 smooth L1 loss，$t_u$ 为在分类 u 下的 bbox 的四个偏移值，v 表示 gt box 相对 proposal 的偏移 target。<br><strong>mask 分支会为每个 RoI 生成 $Km^2$ 维输出向量</strong>，然后对这个输出向量应用 pixel-wise sigmoid，表示 K 个 binary mask，每个 mask 分辨率为 $m \times m$（m 值参见下文图 4），这里 K 表示所有分类数量，定义 $L_{mark}$ 为平均二值交叉熵损失，记 RoI 的 gt 分类为 k，$L_{mark}$ 仅由第 k 个 binary mask 计算得到，其他 K-1 个 binary mask 均不参与 $L_{mark}$ 的计算，</p><script type="math/tex; mode=display">L_{mark}=-\frac 1{m^2} \sum_{i=1}^{m^2} \sum_{j=0}^1 [t_i=j] \cdot \log f(s_i^j)=-\frac 1{m^2} \sum_{i=1}^{m^2} [t_i \cdot \log f(s_i) + (1-t_i) \cdot \log (1-f(s_i))]</script><p>其中 $f(\cdot)$ 表示 sigmoid。</p><p><strong>Mask Representation:</strong> 对单个 RoI 而言，无论其大小，对应的分类和 bbox 偏移这两个输出都是固定长度，可由 fc 层输出得到，而 mask 则以 pixel-to-pixel 方式表征 RoI 中目标的空间布局，所以适合使用卷积。事实上，我们正是使用了全卷积网络 FCN 来为每个 RoI 生成 $m \times m$ 空间尺寸的 mask。然而需要注意的是，pixel-to-pixel 的方式要求 RoI 特征能如实地保留每个像素的空间对应关系，于是我们提出 RoIAlign 来解决这个问题。</p><p><strong>RoIAlign:</strong> RoIPool 是从 RoI 中抽取固定长度特征（例如 $7\times 7$）的标准方法，首先将浮点数 RoI 量化成整数粒度的 feature map，然后将量化后的 RoI 切分得到一系列空间 bins ，每个空间 bin 的大小也是浮点数，所以每个空间 bin 的位置也需要量化，然后将其中的像素值聚合得到这个空间 bin 的值，一般使用最大值池化进行聚合。</p><p>可见前后有两次量化过程，第一次量化是在将 RoI 的坐标 x 从输入 image 平面上映射到特征平面上，在 Faster R-CNN 中，这个特征的 stride 为 16，所以 RoI 在特征平面上的坐标为 $[x/16]$，其中 $[\cdot]$ 表示四舍五入成整数；第二次量化是在计算空间 bin 位置时，假设 RoI 为 $(x_1,y_1,x_2,y_2)$（通常均为浮点数，因为 RPN 中对 anchor 位置进行偏移得到 RoI），一共将 RoI 划分为 7x7 个空间 bins，经过第一次量化后特征平面上 RoI 表示为，</p><script type="math/tex; mode=display">x_1'=[x_1/16] \quad y_1'=[y_1/16]\quad x_2'=[x_2/16]\quad y_2'=[y_2/16]</script><p>RoI 的大小 和 空间 bin 的大小分别为</p><script type="math/tex; mode=display">w'=x_2'-x_1'+1\quad h'=y_2'-y_1'+1\\\\ w^b=w'/7 \quad h^b=h'/7</script><p>对于第 (i,j) 个 bin，其位置为</p><script type="math/tex; mode=display">x_1^b=\lfloor j \cdot w^b\rfloor \quad y_1^b=\lfloor i \cdot h^b\rfloor \quad x_2^b=\lceil (j+1) \cdot w^b\rceil \quad y_1^b=\lceil (i+1) \cdot h^b\rceil</script><p>其中 $0 \le i&lt;7, \ 0\le j&lt;7$。（当然还需要对 bin 的位置十分越界进行检查，这里略）</p><p>两次量化使得 RoI 与抽取到的特征不对齐，这对 pixel-to-pixel 的 mask 而言是非常不利的，所幸 RoIAlign 可以解决这个问题。使用 RoIAlign 代替 RoIPool，避免量化操作，如图 3，<br><img src="/images/mask-rcnn_fig3.png" alt=""></p><center>图 3 RoIAlign 示意图，图中黑矩形框表示 backbone 输出 feature maps 上的一个 RoI，具有 2x2 个 bin，实际是 7x7 个 bin，这里仅作示例</center><p>特征平面上的 RoI 的位置为 $x/16$，其中每个 bin 采样 4 个位置点，采样位置处的值通过双线性插值计算得到，然后每个 bin 的值使用这四个采样位置的值进行聚合得到（max 或者 average 聚合）。整个过程 <strong>没有任何量化操作</strong>。实验的最终结果对采样位置不敏感，对采样位置的数量也不敏感。</p><p><strong>Network Architecture:</strong> Mask R-CNN 网络组成包括 1. 用于抽取特征的 backbone，2. network head，用于 bbox 分类和回归，以及 mask 预测。</p><p>Backbone 网络的命名法：我们使用了 ResNet 和 ResNeXt（深度为 50 或101）。Faster R-CNN 中使用 ResNet 的 4-th stage 的最后一个 conv 的输出作为特征，这里记为 C4。于是，当 ResNet 为 ResNet-50 时，我们称 backbone 为 ResNet-50-C4。</p><p>我们也研究了其他的 backbone 例如 FPN，FPN 使用 top-down 结构以及横向连接生成 feature pyramid。使用 ResNet-FPN 作为 backbone 时，Mask R-CNN 的准确率以及响应速度均有提升。</p><p>对于 Network head，如图 4，<br><img src="/images/mask-rcnn_fig4.png" alt=""></p><center>图 4. 检测 heads </center><p>ResNet-C4 作为 backbone 时，后面的 head 结构包含 ResNet 的 5-th stage（即，具有 9 个 conv 的 res5）。ResNet-FPN 作为 backbone 时，由于 backbone 已经包含了 res5，故后面的 head 结构较为简单高效。<br>图 4 左边部分，res5 表示 ResNet 的 5-th stage，为简单起见，作用到 $7x7$ 的 RoI feature maps 上的第一个 conv 的 stride 为 1，而原始 ResNet 中对应的这个 conv 由于作用在（conv4_x 输出的）$14x14$ feature maps 上，这个 conv 的 stride 为 2，这一点有所不同。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>实验部分略，请阅读原文。</p><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><p>有关 mask 分支，这里详细说明一下处理过程。如图 4，mask 分支输出大小为 $(R,K,m,m)$，根据 bbox 回归得到预测 box 的坐标数据，数据块大小为 $(R,4)$，其中 R 为检测到的所有预测 box 的数量，K 为目标分类数量，$mxm$ 为 mask 的空间大小。对于第 i 个 目标，$0 \le i &lt; R$，记预测 box 位置为 $(x_1,y_1,x_2,y_2)$，对于第 k 个分类，记对应的 mask map 为 $M_i^k$，</p><ol><li>计算第 i 个 box 的宽高<br>$w=x_2-x_1, \ h=y_2-y_1$</li><li>将 mask map resize 到 box 宽高的大小  <pre class="line-numbers language-python" data-language="python"><code class="language-python">mask<span class="token operator">=</span>cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>M_i_k<span class="token punctuation">,</span> <span class="token punctuation">(</span>w<span class="token punctuation">,</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>将 mask map 二值化，因为 mask 是 pixel-wise sigmoid 之后的值，介于 (0,1) 之间，所以需要二值化处理  <pre class="line-numbers language-python" data-language="python"><code class="language-python">mask<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>mask<span class="token operator">></span><span class="token number">0.5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>将 binary mask 映射到原始输入 image 平面。记原始输入 image 的宽高为 (W,H)，于是得到分割 mask  <pre class="line-numbers language-python" data-language="python"><code class="language-python">im_mask<span class="token operator">=</span>np<span class="token punctuation">.</span>zero<span class="token punctuation">(</span><span class="token punctuation">(</span>H<span class="token punctuation">,</span>W<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>im_mask<span class="token punctuation">[</span>y1<span class="token punctuation">:</span>y2<span class="token punctuation">,</span>x1<span class="token punctuation">:</span>x2<span class="token punctuation">]</span><span class="token operator">=</span>mask<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DSOD</title>
      <link href="/2019/07/08/obj_det/DSOD/"/>
      <url>/2019/07/08/obj_det/DSOD/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1708.01241">DSOD: Learning Deeply Supervised Object Detectors from Scratch</a><br><span id="more"></span></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>近几年来提出了很多新型 CNN 网络结构，如 Inception、ResNet 以及 DenseNet 等，带动了包括目标检测在内的诸多 CV 任务的发展。通常来讲，目标检测都是在 backbone 后增加检测子网络，backbone 在分类 benchmark 如 ImageNet 进行预训练，然后使用目标检测数据集对整个网络进行 fine-tune，也就是所谓的迁移学习。但是这种设计范式具有三个不足之处：</p><ol><li>有限的结构设计空间。基于 ImageNet 预训练的 backbone 通常是较为庞大的网络，参数量巨大，所以用在目标检测时，不容易调整网络结构。</li><li>学习偏向性。由于分类和目标检测任务两者的损失函数以及分类分布情况均不相同，导致不同的搜索/优化空间，对目标检测任务而言，模型学习可能偏向一个局部最优解。</li><li>领域不匹配。fine-tuning 虽然可以缓和不同数据集的不同分类分布，但是当源域（ImageNet）与目标域（深度图像，医学图像等）有着严重不匹配时，这依然是个问题。</li></ol><p>于是我们考虑两个问题：目标检测网络是否可以 train from scratch？如果可以，是否存在一些网络结构设计原则使得保持高检测准确率的同时让网络轻量？我们提出深度监督目标检测器 DSOD 以满足以上两个问题。</p><h1 id="DSOD"><a href="#DSOD" class="headerlink" title="DSOD"></a>DSOD</h1><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>DSOD 与 SSD 类似，是一个多尺度的无 proposal（one-stage）的目标检测网络。DSOD 结构分为两部分：用于抽取特征的 backbone 子网络，以及在多尺度响应图（response maps）上预测子网络（这里也称前端子网络）。backbone 是深度监督的 DenseNet 的变体（深度监督指的是对网络隐藏层和输出层直接使用目标检测数据集监督训练，而不是先使用 ImageNet 预训练，再使用目标检测数据集 fine-tune），这个 DenseNet 组成包括一个 stem block，四个 dense block，两个 transition layer 以及两个不带池化层的 transition layer。前端子网络使用一个dense结构融合了多尺度预测响应，如图 1 展示了 DSOD 前端子网络，以及 SSD 中使用的朴素多尺度预测 maps 结构。<br><img src="/images/DSOD_fig1.png" alt=""><center>Fig 1: 预测子网络。左边是 SSD 中所用的朴素结构；右边是 dense 结构</center></p><p>整个 DSOD 网络结构如表 1 所示。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Layers</th><th style="text-align:center">Output Size (Input 3x100x100)</th><th style="text-align:center">DSOD</th></tr></thead><tbody><tr><td style="text-align:center">Stem Convolution</td><td style="text-align:center">64x150x150</td><td style="text-align:center">3x3 conv, stride 2</td></tr><tr><td style="text-align:center">Stem Convolution</td><td style="text-align:center">64x150x150</td><td style="text-align:center">3x3 conv, stride 1</td></tr><tr><td style="text-align:center">Stem Convolution</td><td style="text-align:center">128x150x150</td><td style="text-align:center">3x3 conv, stride 1</td></tr><tr><td style="text-align:center">Stem Convolution</td><td style="text-align:center">128x75x75</td><td style="text-align:center">2x2 max pool, stride 2</td></tr><tr><td style="text-align:center">Dense Block (1)</td><td style="text-align:center">416x75x75</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; conv \\\\ 3 \times 3 &amp; conv\end{bmatrix} \times 6$</td></tr><tr><td style="text-align:center">Transition Layer (1)</td><td style="text-align:center">416x75x75 <br> 416x38x38</td><td style="text-align:center">1x1 conv <br> 2x2 max pool, stride 2</td></tr><tr><td style="text-align:center">Dense Block (2)</td><td style="text-align:center">800x38x38</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; conv \\\\ 3 \times 3 &amp; conv\end{bmatrix} \times 8$</td></tr><tr><td style="text-align:center">Transition Layer (2)</td><td style="text-align:center">800x38x38 <br> 800x19x19</td><td style="text-align:center">1x1 conv <br> 2x2 max pool, stride 2</td></tr><tr><td style="text-align:center">Dense Block (3)</td><td style="text-align:center">1184x19x19</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; conv \\\\ 3 \times 3 &amp; conv\end{bmatrix} \times 8$</td></tr><tr><td style="text-align:center">Transition w/o Pooling Layer (1)</td><td style="text-align:center">1184x19x19</td><td style="text-align:center">1x1 conv</td></tr><tr><td style="text-align:center">Dense Block (4)</td><td style="text-align:center">1568x19x19</td><td style="text-align:center">$\begin{bmatrix} 1 \times 1 &amp; conv \\\\ 3 \times 3 &amp; conv\end{bmatrix} \times 8$</td></tr><tr><td style="text-align:center">Transition w/o Pooling Layer (2)</td><td style="text-align:center">1568x19x19</td><td style="text-align:center">1x1 conv</td></tr><tr><td style="text-align:center">DSOD Prediction Layers</td><td style="text-align:center">-</td><td style="text-align:center">Plain/Dense</td></tr></tbody></table></div><center>Table 1: DSOD 结构 </center><p>DSOD 设计原则如下：</p><h3 id="无-Proposal"><a href="#无-Proposal" class="headerlink" title="无 Proposal"></a>无 Proposal</h3><p>我们调查了如下三类 SOTA 的目标检测器：</p><ol><li>R-CNN 和 Fast R-CNN，使用外部目标 proposal 生成器如 selective search。</li><li>Faster R-CNN 和 R-FCN 使用 RPN 生成 region proposals</li><li>YOLO 和 SSD，属于 single-shot 不生成 proposals（proposal-free），直接回归得到目标位置。</li></ol><p>发现仅第三类（proposal-free）方法可以在没有预训练模型的情况下收敛成功。我们猜测这是由于前两类方法中的 RoI pooling 从每个 region proposal 中生成特征，这个 pooling 阻碍了梯度从 region 到 conv feature 的平滑反向传播。基于 proposal 的方法在有预训练的情况下工作良好是因为 RoI pooling 之前的 layers 的参数初始化足够好，而在 train from scratch 时由于没有预训练，所以那些 layers 参数初始化不够好，并在训练过程中梯度无法平法的反向传播过去，导致无法很好的更新这部分 layers 的参数。</p><p>于是，第一个设计原则为：training from scratch 需要 proposal-free 网络。</p><h3 id="深度监督"><a href="#深度监督" class="headerlink" title="深度监督"></a>深度监督</h3><p>中心思想是使用统一的目标函数对网络最初的隐藏层进行直接监督。这里我们使用密集层间连接如同 DenseNets 中那样来增强深度监督，即在一个 block 中当前 layer 与前面所有 layers 均有直接连接（也称 dense block），DenseNet 中初始的 layers 可通过 skip connections 得到来自目标函数的额外监督，所以只需要一个位于网络顶层的目标函数即可实现深度监督，并且能缓和梯度消失的问题。在 DenseNet 中，每个 transition layer 均包含池化层，所以要维持相同尺度的输出并增加网络深度，那么只能在 dense block 内部增加 layers，而我们所用的 Transition w/o pooling layer 由于不带有池化层，故消除了这种限制。</p><h3 id="Stem-Block"><a href="#Stem-Block" class="headerlink" title="Stem Block"></a>Stem Block</h3><p>Stem block 包含三个 3x3 卷积以及一个 2x2 最大值池化，其中第一个卷积步幅为 2。这个 stem block 明显提高了我们实验性能，相比较于 DenseNet 中的原始设计（7x7 卷积步幅为 2，后跟一个步幅为 2 的 3x3 最大值池化），stem block 可以降低输入 image 中的信息损失。</p><h3 id="密集预测结构"><a href="#密集预测结构" class="headerlink" title="密集预测结构"></a>密集预测结构</h3><p>图 1 展示了两种预测子结构：1. 朴素结构（源于 SSD）以及 2. 我们提出的密集结构。输入 image 大小为 300x300，6 种不同尺度的 feature maps 用于预测目标，其中 Scale-1 feature maps 来自 backbone 中间层，此 feature maps 尺度最大，为 38x38，用于小目标预测，其余五个尺度的 feature maps 来自于 backbone 之后的子结构。这个子结构构造方法为：如图 1 右边仅靠中心竖线的虚线框，相邻两个尺度 feature maps 之间使用 transition layer 连接起来，这个 transition layer 具有 bottleneck 结构：一个 1x1 卷积用于降低 previous scale 的 feature maps 的通道数，以及一个 3x3 卷积下采样得到 next scale 的 feature maps。</p><p>在图 1 中所示的 SSD 原始预测子结构中，每个尺度的特征均由上一个尺度的特征直接转变而来。我们提出的预测子结构是一个密集结构，融合了多尺度特征。为简单起见，限制每个尺度输出相等通道的 feature maps 用于预测。在 DSOD 中，除 scale-1 之外的每个尺度中，feature maps 有一半是通过一系列的 conv 从上一尺度中学习而来，这一系列的 conv 即图 1 右边仅靠中心竖线的虚线框所标注，剩余的一半 feature maps 则直接从相邻的高分辨率的 feature maps 中降采样得到，图 1 中最右边的虚线框标注，这个降采样包含 2x2 步幅为 2 的 max pooling，以及一个 1x1 步幅为 1 的 conv，其中 max pooling 是为了两边的 feature maps 的分辨率匹配从而能够 concatenate 起来，而 1x1 conv 则是为了将 feature maps 的通道数降为一半。max pooling 层位于 1x1 conv 之前可以降低计算损害。对每个 scale 而言，仅学习一半的新 feature maps，并重新利用一半的 previous feature maps。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>实验部分略，可阅读原文以获取详细信息。</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>提出 DSOD 用于 training from scratch，而这总训练方式适合 single-shot 的目标检测器，在 SSD 基础上，使用 DenseNet 作为 backbone，同时预测子网络也采用类似 DenseNet 的密集连接网络，实现了深度监督。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>libra-rcnn</title>
      <link href="/2019/07/03/obj_det/libra-rcnn/"/>
      <url>/2019/07/03/obj_det/libra-rcnn/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1904.02701">Libra R-CNN: Towards Balanced Learning for Object Detection</a><br><span id="more"></span></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>当前大多数目标检测器无论是 one-stage 还是 two-stage，其训练范式都是 image 上区域选择（以下使用原英文单词 Region 表示），从 region 抽取特征，以及联合目标分类和定位的多任务目标函数优化。基于此训练范式，有如下三点关于训练是否成功：</p><ol><li>所选 region 是否具有代表性</li><li>抽取的特征是否被充分利用</li><li>设计的目标函数是否最优</li></ol><p>如图 1，很多训练过程均存在以上三点问题，<br><img src="/images/libra-rcnn_fig1.png" alt=""> <center> 不平衡包括 a. 样本级别；b. 特征级别；c. 目标函数级别 </center></p><p>由于以上三个不平衡问题的存在，即使一个设计良好的模型，也可能最终训练出来的性能不佳。以下我们具体讨论这三个不平衡问题：</p><h2 id="样本不平衡"><a href="#样本不平衡" class="headerlink" title="样本不平衡"></a>样本不平衡</h2><p>为了避免模型倾向于预测为负，很多训练过程设置了一个训练批次中正负样本的比例（如 1:3）。训练目标检测器时，困难样例更具有价值，可以加快训练收敛速度，有效提高检测性能，然而事实上随机选择的 region 主要都是简单负样例，这些简单负样例贡献不了什么有用的特征，于是有了在线难负例发掘方法 OHEM [1]，这个 OHEM 对于噪声标签非常敏感，因为噪声标签会使得误分类为负也就是难负例筛选不准确，此外 OHEM 显然提高了内存占用并增加了计算量。通过进一步降低分类正确的那部分损失，Focal loss 也可以缓和样本不平衡这个问题，但是 Focal loss 通常用在 one-stage 模型中，在 two-stage 模型中则作用不明显，因为大部分的简单负例在 first stage 已经被过滤掉了（正如前面所说的正负样本比例为 1:3），此时若再使用 Focal loss 则会使得正负例样本所产生的梯度不平衡，较小的梯度淹没在较大的梯度里，难以起到梯度优化指导作用。</p><h2 id="特征不平衡"><a href="#特征不平衡" class="headerlink" title="特征不平衡"></a>特征不平衡</h2><p>深度高层的特征具有更丰富的语义信息，而浅层特征则保留了更多的视觉内容描述（局部细节信息）。近年来，FPN 和 PANet 则通过 top-down 结构和 横向连接来进行特征整合，提高了目标检测性能，这说明高底层的特征对于目标检测的作用确实是互补的。但是，如何最佳地整合特征？前面提高的特征整合方法，feature pyramid 中每一层的特征整合更多的是关注邻近的特征（直接相连），而很少关注其他非邻近特征（非直接相连），非邻近特征需要经过一个或多个中间层才能到达本层特征，显然非近邻特征的语义信息被稀释的非常淡。如下图所示，<br><img src="/images/libra-rcnn_figa.png" alt=""><center>FPN</center></p><p>从上图可知，融合后的 a’ 特征，其来自于 b,c 层的特征信息不是均衡的。</p><h2 id="优化目标不平衡"><a href="#优化目标不平衡" class="headerlink" title="优化目标不平衡"></a>优化目标不平衡</h2><p>目标检测器是多任务的：分类和定位。两者的目标函数加起来作为最终的优化目标，如果这两者之间不均衡，会导致次优的结果，较小的梯度会淹没在较大的梯度里，起不到优化指导作用。这个情况与训练中样本导致的梯度不平衡的情况是相同的，均会限制模型进一步的性能调优。</p><p>我们提出 Libra R-CNN（天秤 R-CNN），以平衡以上三个问题，Libra R-CNN 框架包含三个创新组件：</p><ol><li>IoU 均衡采样，根据与 gt box 的 IoU 来挖掘难例</li><li>均衡的 feature pyramid，使用 <strong>相同深度</strong> 合并到一起的均衡语义特征进行强化</li><li>均衡的 L1 loss，提升关键的梯度从而平衡 1)分类 2) 大致定位 3) 准确定位 这三者</li></ol><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><p>Libra R-CNN 结构如图 2，<br><img src="/images/libra-rcnn_fig2.png" alt=""></p><p>其中所有组件的详细介绍如下。</p><h2 id="IoU-balanced-Sampling"><a href="#IoU-balanced-Sampling" class="headerlink" title="IoU-balanced Sampling"></a>IoU-balanced Sampling</h2><p>首先一个基本问题是：训练样本 region 和其对应的 gt box 之间的重合与此样本的难易程度是否有关联？图 3 显示了三种 region 采样的 IoU 分布，<br><img src="/images/libra-rcnn_fig3.png" alt=""></p><p>我们仅考虑难负例，因为难负例是上文我们分析的关键三点之一。从图 3 中可见超过 60% 的难负例有大于 0.05 的 IoU（因为图 3 中橙色部分 IoU 低于 0.05 的占比大约为 37%），而随机采样时仅仅有大约 30% 的训练样本其 IoU 大于 0.05，这意味着如果随机采样会得到很多 IoU 位于 [0,0.05) 区间的样本，而分布在这个区间的难负例样本较少，所以随机采样会得到很多简单样本。</p><p>受以上结论启发，我们提出 IoU-balanced 采样：既然难负例分布在各个 IoU 区间，那么我们就对各个 IoU 区间分别采样。假设从 M 个候选中选出 N 个负样本，随机采样下每个样本被选择的概率为</p><script type="math/tex; mode=display">p=\frac N M</script><p>为了提高选择难负例的概率，根据 IoU 将采样区间等分成 K 个桶，从每个桶中选择 N/K 个负样本，于是在 IoU-balanced sampling 下，第 k 个桶中每个样本被选择的概率为</p><script type="math/tex; mode=display">p_k=\frac N K \cdot \frac 1 {M_k}, \ k \in [0,K)</script><p>其中，$M_k$ 是第 k 个桶中的样例候选数量。实验中 K=3。</p><p>IoU-balanced sampling 结果如图 3，可以看到使用这种采样方式得到的训练样本分布与难负例的分布非常接近。采样候选数量不足，这种采样方法难以扩展到正例采样，为了得到均衡采样过程，使用一种替换方案：对每个 gt box 我们进行数量相等的采样。</p><h3 id="SOURCE-CODE"><a href="#SOURCE-CODE" class="headerlink" title="SOURCE CODE"></a>SOURCE CODE</h3><p>经过阅读源码，本人总结 IoU balanced sampling 负例采样过程为：</p><ol><li>获取所有 proposals 的最大 IoU，记为 <code>max_overlaps</code></li><li>获取所有 proposals 的最大 IoU 的最大值，<code>max_iou=max_overlaps.max()</code></li><li>设置阈值下限 <code>floor_thr</code>，对 <code>(floor_thr, max_iou)</code> 范围内的 proposals 进行 IoU balanced sampling</li><li>设置桶（bin）数量 K，假设所需要的负例数量为 N，对每个桶采样数量为 N/K，每个桶的 IoU 范围跨度为 <code>(max_iou-floor_thr)/K</code></li><li>对于第 k 个桶，计算对应的 IoU 范围，记为 <code>[sk,ek)</code></li><li>获取第 k 个桶内的 proposals 的 index<pre class="line-numbers language-python" data-language="python"><code class="language-python">tmp_set <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>np<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>max_overlaps<span class="token operator">>=</span>sk<span class="token punctuation">,</span> max_overlaps<span class="token operator">&lt;</span>ek<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>获取第 k 个桶内的负例的 index<pre class="line-numbers language-python" data-language="python"><code class="language-python">tmp_inds <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>tmp_set <span class="token operator">&amp;</span> full_set<span class="token punctuation">)</span> <span class="token comment"># full_set 为 floor_thr&lt;iou&lt;0.5  proposals 的 index</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>从第 7 步中得到的第 k 个桶中所有负例的 index，在随机抽取 N/K 个负例<pre class="line-numbers language-python" data-language="python"><code class="language-python">random_choice<span class="token punctuation">(</span>tmp_inds<span class="token punctuation">,</span> N<span class="token operator">/</span>K<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>IoU balanced sampling 正例采样过程：</li><li>获取正例 proposals 所对应的 gt 的 index，记为 <code>gt_inds</code></li><li><p>将第 1 步的结果去重，<code>unique_gt_inds=gt_inds.unique()</code>，得到所有 gt 的 index</p><p>为什么说是所有 gt 呢？因为所有 gt 均作为正例被添加到正例 proposals 中</p></li><li>所有 gt 的数量为 <code>num_gts=len(unique_gt_indx)</code>，假设总共要采样 N 个正例，以每个 gt 为中心，均需要采样 <code>num_per_gt=N/num_gts</code> 个正例</li><li>对于第 i 个 gt，获取与其匹配的所有正例，并从中随机选择 <code>num_per_gt</code> 个正例<pre class="line-numbers language-python" data-language="python"><code class="language-python">inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>assign_result<span class="token punctuation">.</span>gt_inds <span class="token operator">==</span> i<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>inds <span class="token operator">=</span> random_choice<span class="token punctuation">(</span>inds<span class="token punctuation">,</span> num_per_gt<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>以上采样过程均经过简化，如需彻底理解细节问题则直接阅读源码</li></ol><h2 id="Balanced-Feature-Pyramid"><a href="#Balanced-Feature-Pyramid" class="headerlink" title="Balanced Feature Pyramid"></a>Balanced Feature Pyramid</h2><p>使用 <strong>相同深度</strong> 合并到一起的均衡语义特征来加强 multi-level features，如图 4，特征经过四个步骤：尺度缩放、整合、精修和加强。<br><img src="/images/libra-rcnn_fig4.png" alt=""></p><h3 id="获取均衡语义特征"><a href="#获取均衡语义特征" class="headerlink" title="获取均衡语义特征"></a>获取均衡语义特征</h3><p>记 l 层级的特征为 $C_l$，层级数量为 L。最低层和最高层分别记为 $l_{min}, l_{max}$。如图 4，将所有层级的特征 $\{C_2,C_3,C_4,C_5\}$ resize 到一个中间大小即 $C_4$ 的大小，resize 操作使用插值或者最大值池化实现，所有特征经过尺度缩放后，均衡语义特征可由下式获得，</p><script type="math/tex; mode=display">C=\frac 1 L \sum_{l_{min}}^{l_{max}} C_l</script><p>这个均衡语义特征可经过相反的 rescale 操作来加强各自原始特征（图 4 中的 Identity）。</p><h3 id="精修均衡语义特征"><a href="#精修均衡语义特征" class="headerlink" title="精修均衡语义特征"></a>精修均衡语义特征</h3><p>进一步精修均衡语义特征使其更具判别力。使用嵌入的高斯 non-local 注意力机制[2]精修均衡语义特征。</p><p>Balanced feature pyramid $\{P_2,P_3,P_4,P_5\}$ 可用于目标检测，检测网络结构与 FPN 的一致。</p><h2 id="Balanced-L1-Loss"><a href="#Balanced-L1-Loss" class="headerlink" title="Balanced L1 Loss"></a>Balanced L1 Loss</h2><p>遵循 Fast R-CNN 中的分类和目标定位的损失，定义如下，</p><script type="math/tex; mode=display">L_{p,u,t^u,v}=L_{cls}(p,u) + \lambda [u\ge 1] L_{loc}(t^u,v)</script><p>上式为单个样本的损失，其中，预测和 target 分别记为 p 和 u。t<sup>u</sup> 表示回归预测，v 表示回归 target。$\lambda$ 为平衡系数。我们称损失大于等于 1.0 的样本为外点 outliers，损失小于 1.0 的样本为内点 inliers。</p><p>由于回归 target 值是无界的，如果直接增大 $\lambda$ 会使得模型对 outliers 更为敏感，outliers 可以视作困难样本（困难样本可以认为是误差较大的样本），由于较大的损失使得梯度也较大，这对训练过程是不利的。Inliers 可以看作简单样本，与 outliers 相比，其梯度贡献较小，具体而言，inliers 平均每个样本仅贡献了 30% 的梯度，基于这些考虑，我们提出均衡 L1 损失，从传统的 smooth L1 损失演变而来，记为 $L_b$。设置一个拐点分离 inliers 和 outliers，并使用最大值 1.0 来剃平 outliers 的较大梯度，如图 5(a) 所示,<br><img src="/images/libra-rcnn_fig5.png" alt=""><center>横坐标 regression error 为 |x|，参见下文中的说明</center></p><p>均衡 L1 损失的核心思想是提升关键的回归梯度，也就是来自 inliers 的梯度，使得所有样本的所有任务的梯度达到平衡。使用均衡 L1 损失的定位损失为，</p><script type="math/tex; mode=display">L_{loc}=\sum_{i \in \{x,y,w,h\}} L_b (t_i^u-v_i)</script><p>相关的梯度满足，</p><script type="math/tex; mode=display">\frac {\partial L_{loc}} {\partial w} \propto \frac {\partial L_b} {\partial t_i^u} \propto \frac {L_b} x</script><p>上式中，w 表示网络权重参数（我是这么认为的），x 表示 $t_i^u - v_i$，因为 smooth L1 损失就是这么表示的，回顾一下 smooth L1 损失，其定义如下，</p><script type="math/tex; mode=display">L_{loc}(t^u, v) = \sum_{x,y,w,h} smooth_{L_1} (t_i^u-v_i)</script><p>其中，</p><script type="math/tex; mode=display">smooth_{L_1}(x)=\begin{cases} 0.5 x^2 & |x|<1\\\\ |x|-0.5 & otherwise \end{cases}</script><p>于是 smooth L1 损失对应的梯度为，</p><script type="math/tex; mode=display">\frac {\partial L_1} {\partial |x|} = \begin{cases} |x| & |x|<1\\\\ 1 & |x| \ge 1 \end{cases}</script><p>我们将 |x| 看作是回归误差（regression error），显然误差总是非负的。现在，我们要想提升 inliers 的梯度，也就是 |x|&lt;1  的梯度（因为 |x|&lt;1 表示样本损失较小），首先对于 smooth L1 损失在 |x|&lt;1 范围内的梯度为 $\nabla_{|x|} L = |x|$ 也就是一条经过 (0,0) 和 (1,1) 的线段，要提高这个范围内的梯度，很自然的想法是位于直线 y=x 上方的曲线，当然曲线必须要经过原点(0,0)，表示预测与 target 相等即误差为零时损失也为零，为了与 $|x| \ge 1$ 的梯度保持连续，梯度曲线仍然经过 (1,1) 点，同时还要保持单调递增，这说明曲线是 <strong>上凹</strong> 的，满足这些特性的一组曲线其函数为，</p><script type="math/tex; mode=display">\frac {\partial L_b} {\partial x} = \begin{cases} \alpha \ln (b|x|+1) & |x|<1\\\\ \gamma & otherwise \end{cases}</script><p>其中 $\alpha$ 越小，对 inliers 的梯度提升越大，$\gamma$ 控制 outliers 的梯度，或者说整个梯度的上限，$\gamma$ 参数用于平衡回归损失和分类损失，平衡后的梯度曲线如图 5(a)所示。参数 b 则用于确保损失在 |x|=1 处连续，对梯度积分得到损失函数为，</p><script type="math/tex; mode=display">L_b(x)=\begin{cases} \frac \alpha b (b|x|+1) \ln (b|x|+1) - \alpha |x| & |x| < 1\\\\ \gamma |x| + C & otherwise \end{cases}</script><p>根据损失在 |x|=1 处连续，得到</p><script type="math/tex; mode=display">\frac \alpha b (b+1) \ln (b+1) - \alpha=(\alpha + \frac \alpha b) \ln(b+1) -\alpha = \gamma + C</script><p>由于 C 可以是任意常数，所以可令 $C=\frac \alpha b \ln(b+1) -\alpha$，于是有</p><script type="math/tex; mode=display">\alpha \ln (b+1)=\gamma</script><p>解得，</p><script type="math/tex; mode=display">b=e^{\gamma / \alpha} -1\\\\ C=\gamma/b-\alpha</script><p>损失函数曲线如图 5(b) 所示。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>实验部分略</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>提出了 Libra R-CNN，包含三点：</p><ol><li>IoU balanced sampling</li><li>balanced feature pyramid</li><li>balanced L1 loss</li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Training Region-based Object Detectors with Online Hard Example Mining. Abhinav Shrivastava</li><li>Non-local neural networks. Xiaolong Wang</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gcc-src</title>
      <link href="/2019/07/02/cpp/gcc-src/"/>
      <url>/2019/07/02/cpp/gcc-src/</url>
      
        <content type="html"><![CDATA[<p>多阅读 c++ 标准库源码，才能更好的理解 c++ 标准库。<br><span id="more"></span><br>以 ubuntu 为例，gcc 版本为 7.3.0，目录 /usr/include/c++/7/ 包含了大多数标准库（头）文件，标准库的大多数的实现逻辑也在这些头文件中，如要获取完整的源码，则可以去</p><ol><li><a href="https://github.com/gcc-mirror/gcc">gcc-mirror/gcc</a> clone 这个位于 github 的远程仓库</li><li><a href="http://www.gnu.org/prep/ftp.html">GNU Mirror List</a> 选择一个镜像网址，直接下载 gcc 源码</li></ol><p>C++ 标准模板库包含容器，以及容器相关的算法，涉及到的概念包括容器，算法，迭代器以及分配器等，各自功能从名称可窥见一二。</p><p>我们采用自底向上的方式来分析各类的实现，虽然自顶向下才是阅读这些源码的最自然的方式，不过阅读方式并不影响什么，待熟悉了这些类的各自功能后，反过来梳理一遍正好可以加深印象。</p><h1 id="Allocator"><a href="#Allocator" class="headerlink" title="Allocator"></a>Allocator</h1><p>我们以 <strong>allocator_traits_base 为例开始分析，此类位于 libstdc++-v3/include/bits/alloc_traits.h 头文件中，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">struct __allocator_traits_base&#123;    template&lt;typename _Tp, typename _Up, typename &#x3D; void&gt;    struct __rebind : __replace_first_arg&lt;_Tp, _Up&gt; &#123; &#125;;    template&lt;typename _Tp, typename _Up&gt;    struct __rebind&lt;_Tp, _Up, __void_t&lt;typename _Tp::template rebind&lt;_Up&gt;::other&gt;&gt;    &#123; using type &#x3D; typename _Tp::template rebind&lt;_Up&gt;::other; &#125;;    &#x2F;&#x2F; 定义一系列 _Tp 内部类型的别名protected:    template&lt;typename _Tp&gt;    using __pointer &#x3D; typename _Tp::pointer;    ...&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>类内部定义了模板类 </strong>rebind，对于类 __rebind，分以下几种情况讨论：</p><ol><li>提供三个模板参数，并且第三个模板参数不为 void，此时匹配最泛型模板类，即第一个 __rebind 定义 </li><li>提供三个模板参数并且第三个模板参数为 void，或者仅提供两个模板参数，此时再分两种情况：<ul><li>前两个模板参数满足 _Tp::template rebind<_Up>::other 为有效定义，那么匹配第二个 __rebind 定义</li><li>否则，匹配第一个 __rebind 定义</li></ul></li></ol><p>接着此文件定义了<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Alloc, typename _Up&gt;using __alloc_rebind &#x3D; typename __allocator_traits_base::template __rebind&lt;_Alloc, _Up&gt;::type;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>根据前面的分析，只有 _Alloc::template rebind<_Up>::other 这个类型存在时，这个别名才存在，并且就是这个类型的别名，否则的话，根据第一个 <strong>rebind 模板定义，当 _Alloc 是模板类时，</strong>alloc_rebind 为 _Alloc<_Up, ...>::type。</p><p>然后就是 allocator_traits 类，这个特性用于萃取分配器相关的类型，定义如下，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Alloc&gt;struct allocator_traits: _allocator_traits_base&#123;    typedef _Alloc allocator_type;    typedef type _Alloc::value_type value_type;    using pointer &#x3D; __detected_or_t&lt;value_type*, __pointer, _Alloc&gt;;    ...&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>类中 pointer 这个别名指的是 _Alloc::pointer 类型，如果这个类型存在的话，否则就是类型 value_type<em>。当然通常情况下，_Alloc::pointer 其实也就是 value_type</em> 类型。<strong>pointer 来自基类成员类型，是一个模板类。<br>在 std/type_traits 文件中可查看 </strong>detected_or_t 定义，与前文 __rebind 匹配规则类似，不再赘述。我们再继续看 allocator_traits 其他内部类，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;template&lt;typename&gt; class _Func, typename _Tp, typename &#x3D; void&gt;struct _Ptr&#123;    using type &#x3D; typename pointer_traits&lt;pointer&gt;::template rebind&lt;_Tp&gt;;&#125;;template&lt;template&lt;typename&gt; class _Func, typename _Tp&gt;struct _Ptr&lt;_Func, _Tp, __void_t&lt;_Func&lt;_Alloc&gt;&gt;&gt;&#123;    using type &#x3D; _Func&lt;_Alloc&gt;;&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>定义了模板类 _Ptr，具有内部类型 type 为 _Func<_Alloc>，当这个类型存在时，也就是说 _Func 是模板类型，否则 type 就是 <code>pointer_traits&lt;pointer&gt;::template rebind&lt;_Tp&gt;</code>，此时，假设 pointer 为 value_type<em> 类型（参见上文介绍），根据 bits/ptr_traits.h 中的 pointer_traits 定义，<br><pre class="line-numbers language-none"><code class="language-none">template&lt;typename _Tp&gt;struct pointer_traits&lt;_Tp*&gt;&#123;    ...    template&lt;typename _Up&gt;    using rebind &#x3D; _Up*;    ...&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>可知此时 _Ptr::type 为 _Tp</em> 类型。allocator_traits 内部还定义了很多模板类，比如 _Diff，其类型成员 type 表示指针位移类型（一般是有符号长整型），_Size 的类型成员 type 表示数量类型（一般是无符号长整型），对 _Ptr::type, _Diff::type 和 _Size::type 设置类型别名，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; 如果 _Alloc::const_pointer 存在，则为 _Alloc::const_pointer，否则为 const value_type*using const_pointer &#x3D; typename _Ptr&lt;__c_pointer, const value_type&gt;::type;&#x2F;&#x2F; 为 _Alloc::void_pointer 类型，如果这个类型存在的话，否则为 void*using void_pointer &#x3D; typename _Ptr&lt;__v_pointer, void&gt;::type;&#x2F;&#x2F; 为 _Alloc::difference_type 类型，如果它存在的话，否则为 pointer_traits&lt;pointer&gt;::difference_type，此时一般为（有符号长整型）using difference_type &#x3D; typename _Diff&lt;_Alloc, pointer&gt;::type;&#x2F;&#x2F; 为 _Alloc::size_type 类型，如果它存在的话，否则为 difference_type 的无符号版本类型using size_type &#x3D; typename _Size&lt;_Alloc, difference_type&gt;::type;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>篇幅有限，不一一介绍，后面的讨论中如果遇到，则根据需要再进行展开讨论。</p><p>我们再看一个类 <strong>alloc_traits，位于 ext/alloc_traits.h 中，看看它提供了哪些类型萃取，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Alloc, typename &#x3D; typename _Alloc::value_type&gt;struct __alloc_traits    : std::allocator_traits&lt;_Alloc&gt;     &#x2F;&#x2F; 假设 __cplusplus &gt;&#x3D; 201103L，其他情况这里不考虑&#123;    typedef _Alloc allocator_type;    &#x2F;&#x2F; std::allocator_traits 就是上面刚讨论的那个特性类    typedef std::allocator_traits&lt;_Alloc&gt;               _Base_type;    typedef typename _Base_type::value_type             value_type;    &#x2F;&#x2F; _Alloc::pointer or value_type*    typedef typename _Base_type::pointer                pointer;    typedef typename _Base_type::const_pointer          const_pointer;    typedef typename _Base_type::size_type              size_type;    typedef typename _Base_type::difference_type        difference_type;    typedef value_type&amp;                                 reference;    typedef const value_type&amp;                           const_reference;    &#x2F;&#x2F; 以上各类型含义已经非常明显易懂了，不再赘述。以下引入一组方法到当前域    using _Base_type::allocate;    using _Base_type::deallocate;    using _Base_type::construct;    using _Base_type::destroy;    using _Base_type::max_size;    ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>于是回到 std::allocator_traits 中查看例如 allocate 的定义，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">_GLIBCXX_NODISCARD static pointer       &#x2F;&#x2F; _GLIBCXX_NODISCARD 指示编译器，如果返回结果被抛弃，则编译器发出警告。显然这么做是应该的，否则动态申请的内存，将无法被释放，造成内存泄漏allocate(_Alloc&amp; __a, size_type __n)&#123; return __a.allocate(__n); &#125;_GLIBCXX_NODISCARD static pointerallocate(_Alloc&amp; __a, size_type __n, const_void_pointer __hint) &#123; return _S_allocate(__a, __n, __hint, 0); &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>上面代码片段中，_Alloc 表示分配器类型，第一个 allocate 模板直接调用分配器 </strong>a 分配 <strong>n 个元素的内存，第二个 allocate 模板增加了一个参数 </strong>hint 指向临近内存位置的指针，分配器会尝试尽可能分配靠近 __hint 的内存块。易知，分配器特性类的 allocate 方法实际上依赖具体分配器的 allocate 方法实现。实际上，不光是 allocate，deallocate, construct, destroy, max_size 也可能依赖于分配器的同名方法实现（当然，如果目标类型 _Tp 有相应方法实现，则依赖于 _Tp 的同名方法实现）。</p><p>由于 std::allocator_traits::construct 的方法参数为，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Tp, typename... _Args&gt;static auto construct(_Alloc&amp; __a, _Tp* __p, _Args&amp;&amp;... __args)...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>发现参数类型为 _Tp*，这是 _Tp 类型的标准内存指针，在 <strong>gnu_cxx::</strong>alloc_traits 中还实现了使用自定义指针类型作为参数的 construct 方法，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; 是否是自定义指针的判断template&lt;typename _Ptr&gt;using __is_custom_pointer&#x2F;&#x2F; 如果 _Ptr 与 pointer 相同，那么 _Ptr 不是指针时 &#x3D;&gt; __is_custom_pointer 为真&#x2F;&#x2F; 如果 _Ptr 与 pointer 不同，那么 __is_custom_pointer 为假&#x3D; std::__and_&lt;std::is_same&lt;pointer, _Ptr&gt;,        std::__not_&lt;std::is_pointer&lt;_Ptr&gt;&gt;&gt;;&#x2F;&#x2F; 重载非标准指针类型的 构造函数template&lt;typename _Ptr, typename... _Args&gt;&#x2F;&#x2F; 条件判断，当 __is_custom_pointer&lt;_Ptr&gt; 为真时，enable_if&lt;xx&gt;::type 才存在static typename std::enable_if&lt;__is_custom_pointer&lt;_Ptr&gt;::value&gt;::typeconstruct(_Alloc&amp; __a, _Ptr __p, _Args&amp;&amp;... __args)...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>我们阶段性地总结一下以上分配器特性类，主要提供了与分配器有关的类型萃取，如分配器类型，分配的目标对象类型（包含值类型，const 型，指针型），分配的目标对象数量类型（因为是用于容器/序列的分配，涉及到元素对象的数量），位移类型（常用于序列的迭代器）等。另外还提供了一些方法，比如 rebind，由于模板参数 _Alloc 可由调用者传入，假如传入的 _Alloc 其用于分配的模板对象类型 value_type 与当前分配器特性类 allocator_traits 的 value_type 不一致，那么 rebind 将重新绑定得到与 allocator_traits::value_type 一致的分配器类型 Allocator。</p><p>接下来则是分配器类，注意与分配器特性类区别开来，后者更注重与分配器有关的类型萃取，前者更注重完成分配器的如分配，反分配，对象构造/析构等实际工作。可能是故意分开成两个类，这种设计能提高自由度，当然，这是我个人理解。</p><p>std::allocator 类位于文件 bits/allocator.h 中，包含了分配器模板类定义和偏特化模板类定义，现在理解这些代码应该比较容易了，其中最泛化的模板类继承了 <strong>allocator_base，这个类为 </strong>gnu_cxx::new_allocator 的类型别名，在 new_allocator 中我们可以看到 allocate, deallocate, max_size, construct, destroy 等方法实现。读者可仔细阅读这些源码，这里不再一一分析。</p><h1 id="Iterator"><a href="#Iterator" class="headerlink" title="Iterator"></a>Iterator</h1><p>开门见山不绕弯子，位于 bit/stl_iterator_base_types.h 中，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; 定义一组 Iterator 标记，它们都是空类型，仅仅用于区分不同的迭代器&#x2F;&#x2F; 迭代器底层的算法会根据迭代器本身的类型标记来选择最优算法input_iterator_tagoutput_iterator_tagforward_iterator_tagbidirectional_iterator_tagrandom_access_iterator_tag<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>对于一个迭代器，需要指定迭代器自身的类型（上述某 iterator_tag 之一），迭代目标对象的值/指针/引用类型，迭代位移类型等，这正是 std::iterator 的定义，然后还需要一个相关的特性模板 iterator_traits 用于萃取其相关的类型。</p><p>在 bits/stl_iterator.h 中还提供了几个迭代器适配器，其本质也是一个迭代器，只不过是提供某些专有功能的迭代器。我们先阐述上面五种迭代器类型，然后再结合迭代器适配器理解更有心得，</p><ol><li>input 迭代器。看到 input 可以将容器类比标准输入，比如从屏幕读取输入，这里 input 迭代器类似，从容器读取元素，迭代器迭代器，说明是依次向前读取容器内的元素。<br>支持的操作：自增（向前），解引用（右值，取值），判断两个迭代器是否相等（是否迭代到头）</li><li>output 迭代器。与 input 迭代器相反，依次向容器写入元素。<br>支持的操作：自增（向前），解引用（左值，赋值）。</li><li>forward 迭代器。结合了 input 和 output 迭代器，解引用，既可作左值也可作右值。自增指向下一个元素。与 input/output 迭代器不同的是，forward 迭代器支持 multipass 算法。</li><li>bidirectional 迭代器。在 forword 迭代器的基础上增加了自减操作，指向上一个元素。</li><li>random-access 迭代器。在 bidirectional 迭代器基础上增加关系比较，算术运算等。</li></ol><p>也许上面的总结还不能完全理解，没关系，现在结合迭代器适配器的代码来综合理解。</p><h2 id="reverse-iterator"><a href="#reverse-iterator" class="headerlink" title="reverse_iterator"></a>reverse_iterator</h2><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Iterator&gt;class reverse_iterator      &#x2F;&#x2F; 首先是一个迭代器，其次是提供某些特殊功能的迭代器: public iterator&lt;typename iterator_traits&lt;_Iterator&gt;::iterator_category,                typename iterator_traits&lt;_Iterator&gt;::value_type,                typename iterator_traits&lt;_Iterator&gt;::difference_type,                typename iterator_traits&lt;_Iterator&gt;::pointer,                typename iterator_traits&lt;_Iterator&gt;::reference&gt;&#123;protected:    _Iterator current;  &#x2F;&#x2F; 声明所用迭代器类型的一个变量，反向迭代器正是在此迭代器之上进行构造得到public:    &#x2F;&#x2F; 构造函数略    ...    _GLIBCXX17_CONSTEXPR reference    operator*() const &#123;        _Iterator __tmp &#x3D; current;        return *--__tmp;&#x2F;&#x2F; 先自减，然后解引用，返回的是前一个元素值的引用，返回值只能用作右值                        &#x2F;&#x2F; 由于是在临时变量临时变量上自减，故当前迭代器所指位置不变    &#125;    _GLIBCXX17_CONSTEXPR reverse_iterator&amp;    operator++() &#123;        --current;      &#x2F;&#x2F; 反向迭代器表示从右往左，故自增表示正常迭代器的自减        return *this;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>记反向迭代器为 r，其内部迭代器为 i，那么 r 的所有操作均转换为 i 上的操作，并由 i 完成，如</p><ol><li>解引用: <em>r = </em>(i-1)</li><li>++r = —i, —r = ++i</li><li>r+n = i-n, r-n = i+n</li></ol><p>还有其他一些操作如关系比较，基本上，r 的操作与 i 的操作相反（除了等于，不等于操作）</p><h2 id="back-insert-iterator"><a href="#back-insert-iterator" class="headerlink" title="back_insert_iterator"></a>back_insert_iterator</h2><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Container&gt;class back_insert_iterator:public iterator&lt;output_iterator_tag, void, void, void, void&gt; &#x2F;&#x2F; 指定迭代器标签，其他相关类型则由容器决定&#123;protected:    _Container* container;  &#x2F;&#x2F; 构造此迭代器时，需要传入容器变量，此迭代器用于向这个容器末端插入元素public:    back_insert_iterator&amp;   &#x2F;&#x2F; 给此迭代器赋值就等于向容器末端插入元素    operator&#x3D;(const typename _Container::value_type&amp; __value)    &#123;        container-&gt;push_back(__value);        return *this;    &#125;    ...    back_insert_iterator&amp;    operator*() &#123; return *this; &#125;       &#x2F;&#x2F; 解引用不是取所指元素的值，因为是 output 迭代器    back_insert_iterator&amp;    operator++() &#123;return *this; &#125;       &#x2F;&#x2F; 自增也不是指向下一个元素，因为只能向容器末端插入值    back_insert_iterator&amp;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与此类似还有 front_insert_iterator, insert_iterator 分别表示像容器首端插入值和像容器插入值，插入操作的实现均依赖于容器自身的插入操作，你所能做的，就是给这些迭代赋值，除了赋值还是赋值。。。</p><h2 id="normal-iterator"><a href="#normal-iterator" class="headerlink" title="__normal_iterator"></a>__normal_iterator</h2><p>这是一个正常的迭代器模板，有两个模板参数 _Iterator, _Container，内部维持了一个迭代器对象，用于迭代操作，_Container 作用仅仅是用于生成不同的 __normal_iterator 类型，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Iterator, typename _Container&gt;class __normal_iterator&#123;protected:    _Iterator _M_current;   &#x2F;&#x2F; _normal_iterator 的迭代操作实际上由 _M_current 完成    ...public:    &#x2F;&#x2F; 构造函数略    ...    &#x2F;&#x2F; 迭代器的解引用，自增，自减，指针访问成员，位移等均由 _M_current 完成    &#x2F;&#x2F; 两个 __normal_iterator 的关系比较也由对应的两个 _M_current 的关系比较完成    &#x2F;&#x2F; 确实是再 normal 不过了&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h2 id="move-iterator"><a href="#move-iterator" class="headerlink" title="move_iterator"></a>move_iterator</h2><p>顾名思义就是提供 move 操作，其内部也有一个迭代器，move_iterator 的解引用就是将其内部解引用得到的值进行 move 从而转为右值引用，这用于某些泛型方法中，move 代替了 copy，提高了效率。<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Iterator&gt;class move_iterator&#123;protected:    _Iterator _M_current;    typedef iterator_traits&lt;_Iterator&gt;          __traits_type;  &#x2F;&#x2F; _Iterator 的特性类    typedef typename __traits_type::reference   __base_ref;     &#x2F;&#x2F; 萃取 _Iterator 相关的元素引用类型public:    ...    &#x2F;&#x2F; 如果__base_ref 是引用类型，将其转为右值引用，否则保持不变。通常来讲，__base_ref 都是引用类型    typedef typename conditional&lt;is_reference&lt;__base_ref&gt;::value,        typename remove_reference&lt;__base_ref&gt;::type&amp;&amp;,        __base_ref&gt;::type               reference;        _GLIBCXX17_CONSTEXPR reference    operator*() const    &#123; return static_cast&lt;reference&gt;(*_M_current); &#125; &#x2F;&#x2F; 将内部迭代器解引用得到的值转为右值引用    _GLIBCXX17_CONSTEXPR reference    operator[](difference_type __n) const    &#123; return std::move(_M_current[__n]); &#125;  &#x2F;&#x2F; 随机访问取值，也转为右值引用&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h1 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h1><h2 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h2><p>以 vector 为例，代码位于 bits/stl_vector.h 中，首先是基类 _Vector_base，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Tp, typename _Alloc&gt;struct _Vector_base&#123;    typedef typename __gnu_cxx::__alloc_traits&lt;_Alloc&gt;::template rebind&lt;_Tp&gt;::other _Tp_alloc_type;    typedef typename __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;::pointer pointer;    ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>模板参数 _Alloc 的 value_type 不一定是 _Tp，所以通过 rebind 得到 value_type 为 _Tp 的 alloctor（即 alloctor<_Tp>），设置其别名为 _Tp_alloc_type，然后设置其关联的 pointer，即 _Tp_alloc_type::pointer，如果它存在的话，否则为 _Tp<em>，然后根据 std::allocator 模板定义不难知道 _Tp_alloc_type::pointer 其实就是 _Tp</em>，所以 _Vector_base::pointer 就是 _Tp*。</p><p>接着 _Vector_base 中又定义了几个内部结构<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">struct _Vector_impl_data&#123;    pointer _M_start;   &#x2F;&#x2F; 指向 vector 中第一个元素的内存位置    pointer _M_finish;  &#x2F;&#x2F; 指向 vector 中 past-the-last-element 的内存位置    pointer _M_end_of_storage;  &#x2F;&#x2F; vector 分配 past-the-max-element 内存位置    &#x2F;&#x2F; 构造函数，拷贝函数，交换数据函数。比较简单，略    ...&#125;struct _Vector_impl : public _Tp_alloc_type, public _Vector_impl_data&#123;    &#x2F;&#x2F; 构造函数，略    &#x2F;&#x2F; vector 内存 overflow 检测，需要指定 _GLIBCXX_SANITIZE_VECTOR。参考 AddressSanitizer&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>回到 _Vector_base 中来，_Vector_base 定义了类型别名和一个变量，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Tp, typename _Alloc&gt;struct _Vector_base&#123;    ...public:    typedef _Alloc allocator_type;    _Vector_impl _M_impl;           &#x2F;&#x2F; 分配器变量    ...    &#x2F;&#x2F; 构造&#x2F;析构 函数    pointer _M_allocator(size_t __n) &#123;      &#x2F;&#x2F; 分配 n 个元素的内存，起始位置保存到 pointer 类型变量中        typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr;        &#x2F;&#x2F; 如 __n&#x3D;0，则返回 nullptr，否则使用分配器 _M_impl 分配内存        return __n !&#x3D; 0 ? _Tr::allocate(_M_impl, __n) : pointer();    &#125;protected:    void _M_create_storage(size_t __n) &#123;    &#x2F;&#x2F; 分配内存，并保存内存起始位置和截止位置        this-&gt;_M_impl._M_start &#x3D; this-&gt;_M_allocate(__n);        this-&gt;_M_impl._M_finish &#x3D; this-&gt;_M_impl._M_start;        this-&gt;_M_impl._M_end_of_storage &#x3D; this-&gt;_M_impl._M_start + __n;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>基类 _Vector_base 中仅仅做了内存分配和记录内存块位置的事情，其他 vector 相关的操作则放在 vector 类中，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; vector 模板参数指明了 vector 关联的元素类型 _Tp，以及 vector 的内存分配器类型 _Alloc，&#x2F;&#x2F;  默认 _Alloc 为 std::allocator&lt;_Tp&gt;，显然是于 _Tp 匹配的，&#x2F;&#x2F;  若提供的模板参数 _Alloc 与 _Tp 不匹配，那么也由 _Alloc::rebind 获取匹配的 alloctortemplate&lt;typename _Tp, typename _Alloc &#x3D; std::allocator&lt;_Tp&gt;&gt;class vector : protected _Vector_base&lt;_Tp, _Alloc&gt;&#123;    typedef _Vector_base&lt;_Tp, _Alloc&gt;               _Base;    typedef typename _Base::_Tp_alloc_type          _Tp_alloc_type;    typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;   _Alloc_traits;public:    typedef _Tp                             value_type;    typedef typename _Base::pointer         pointer;    typedef __gnu_cxx::__normal_iterator&lt;pointer, vector&gt;   iterator;    typedef std::reverse_iterator&lt;iterator&gt;                 reverse_iterator;    ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>事实上，指针包含解引用，自增和自减等操作，也可看作是一种特殊的迭代器，所以这里 vector 内部类型 iterator，使用 pointer 作为 <strong>gnu::cxx::</strong>normal_iterator 的模板参数 _Iterator。<br>然后是 vector 的各种构造函数，需要注意到 vector 在实际分配内存后，都会更新 _M_impl._M_finish 使其指向 past-the-last-element 的位置。我们来看一下 vector 获取迭代器的函数，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">iteratorbegin() _GLIBCXX_NOEXCEPT&#123; return iterator(this-&gt;_M_impl._M_start); &#125;iteratorend() _GLIBCXX_NOEXCEPT&#123; return iterator(this-&gt;_M_impl._M_finish); &#125;reverse_iteratorrbegin() _GLIBCXX_NOEXCEPT&#123; return reverse_iterator(end()); &#125;reverse_iteratorrend() _GLIBCXX_NOEXCEPT&#123; return reverse_iterator(begin()); &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>可见迭代器的自增自减解引用均转为指针的自增自减解引用操作。</p><p>其他的 vector 操作，resize 表示重置 vector 中有效元素的数量，重置后 new_size &gt; old_size，那么末尾多出来的元素使用默认值填充（如果 resize 提供了指定值，那么使用指定值填充），如果 new_size&lt;=old_size，则重置 _M_impl._M_finish 所指位置（[_M_start, _M_finish) 范围内的元素有效），_M_finish 之后的元素则根据元素类型决定是调用元素的析构函数还是放任不理，注意这一过程中内存占用没有改变。</p><p>来看 vector 的 push_back 函数实现，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">voidpush_back(const value_type&amp; __x)&#123;    if(this-&gt;_M_impl._M_finish !&#x3D; this-&gt;_M_impl._M_end_of_storage) &#123;        &#x2F;&#x2F; 当前分配的内存空间还足以存储新的元素 __x        ...    &#125; else        _M_realloc_insert(end(), __x);  &#x2F;&#x2F; 重新分配内存，并在 _M_finish 位置插入元素 __x，然后                                        &#x2F;&#x2F;  将 _M_finish 所指位置向前移动一个元素单位&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>在 bits/vector.tcc 中找到 _M_realloc_insert 的实现，<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">template&lt;typename _Tp, typename _Alloc&gt;template&lt;typename ..._Arg&gt;voidvector&lt;_Tp, _Alloc&gt;::_M_realloc_insert(iterator __position, _Args&amp;&amp;... _args)&#123;    &#x2F;&#x2F; 计算即将重新分配元素数量，这里重新分配的元素数量是原来元素数量的 2 倍，参见 _M_check_len    const size_type __len &#x3D; _M_check_len(size_type(1), &quot;vector::_M_realloc_insert&quot;);    pointer __old_start &#x3D; this-&gt;_M_impl._M_start;    pointer __old_finish &#x3D; this-&gt;_M_impl._M_finish; &#x2F;&#x2F; 原来的起始元素指针和 past-the-last 元素指针    const size_type __elems_before &#x3D; __position - begin();&#x2F;&#x2F; 插入位置之前的元素数量    pointer __new_start(this-&gt;_M_allocate(__len));   &#x2F;&#x2F; 重新分配内存，使得能容纳 __len 个元素    pointer __new_finish(__new_start);  &#x2F;&#x2F; 由于尚未填充元素，故此时 past-the-last 指针与起始指针相等    __try    &#123;        &#x2F;&#x2F; 在指定位置处插入目标对象        _Alloc_traits::construct(this-&gt;_M_impl,                     &#x2F;&#x2F; 使用此分配器                                 __new_start + __elems_before,      &#x2F;&#x2F; 在指定位置处                                 std::forward&lt;_Args&gt;(__args)...);   &#x2F;&#x2F; 根据此参数构造对象        &#x2F;&#x2F; 此时 vector 中有了元素，将 __new_finish 先置为 nullptr，等元素全部填充完毕，再更新其值        __new_finish &#x3D; pointer();        if _GLIBCXX17_CONSTEXPR (_S_use_relocate()) &#123;   &#x2F;&#x2F; 如果元素类型支持移动插入            &#x2F;&#x2F; 将原来起始位置到插入位置截止，之间的元素重定位到新的起始位置            __new_finish &#x3D; _S_relocate(__old_start, __position.base()                __new_start, _M_get_Tp_allocator());            &#x2F;&#x2F; 此时 __new_finish 所指位置就是新插入的元素，自增 1，移动新插入元素之后，将原来剩余的元素重定位到此位置处            ++__new_finish;            __new_finish &#x3D; _S_relocate(__position.base(), __old_finish,                __new_finish, _M_get_Tp_allocator());   &#x2F;&#x2F; 此时 __new_finish 就是新的 past-of-last 元素位置了        &#125;        ...        &#x2F;&#x2F; 失败处理，略        &#x2F;&#x2F; 析构原先内存上的对象，并释放内存，略        &#x2F;&#x2F; 更新元素起始和截止位置等，略    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>vector 类中还有很多其他方法，但是到了这一步，相信这些方法的代码实现不难理解了，由于篇幅有限，不对这些方法进行分析。</p><p>本文结束</p>]]></content>
      
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>M2Det</title>
      <link href="/2019/06/28/obj_det/M2Det/"/>
      <url>/2019/06/28/obj_det/M2Det/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1811.04533">M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</a><br><span id="more"></span></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>我们知道在目标检测任务中目标尺度的变化一直是一个具有挑战的问题，通常有两种解决思路：image pyramid 和 feature pyramid。前者在训练阶段其实可以看作是一种数据增强，优点是可以让网络学习到统一的特征表达能力，缺点是测试阶段计算量和内存占用均增大，因为不同 size 的 image 需要分别通过网络预测，然后再合并预测结果。后者是从输入 image 中抽取不同 level 的 feature （不同scale 的 feature maps）形成 feature pyramid，相比于前者，降低了计算量和内存占用，但是不足之处在于构造 feature pyramid 时使用 backbone 网络中固有的 multi-scale feature maps，虽然这些 feature maps 可以形成 feature pyramid，但是其本是为了分类任务而设计的。如图 1，<br><img src="/images/M2Det_fig1.png" alt=""></p><p>SSD 使用 backbone 的两个 layers，然后在此基础上再以步幅 2 连续构造 4 个卷积 layers，这 6 个 layers 的输出构成 feature pyramid；STDN 使用 DenseNet 的最后一个 block 并通过 pooling 和 scale-transfer 操作来构造出 feature pyramid；FPN 以 top-down 方式并增加一个横向连接，融合高层和底层特征，从而构造出 feature pyramid。通常来说，以上方法均存在以下两点不足：</p><ol><li>pyramid 中的 feature 用于目标检测的表征能力还不够，因为是从 backbone 中抽取出来的，而 backbone 是为分类任务设计的。</li><li>pyramid 中每个 level 的 feature 用于检测相应某个 scale 范围内的目标，而 feature 主要（FPN 这类）或者仅仅（除 FPN 这类以外的）由 backbone 的单一 layer 生成，故 feature 主要或仅仅包含单一 level 的信息。</li></ol><p>一般而言，高层特征由于包含更多的语义信息对于分类任务更具有判别力，而低层特征保持了局部信息所以更适合目标定位任务。并且，低层特征适合描述具有简单外观的目标，而高层特征则适合描述具有复杂外观的目标。实际上，size 相差无几的目标其外观很可能差别非常大，例如交通信号灯和一个远处的人，两者 size 差不多，但是人的外观显然更加复杂，因此，用同一 level 的 feature maps 预测这两者，检测性能不是最优。</p><p>本文构造出一个更加有效的 feature pyramid 用于检测不同 scale 的目标，并能解决上述问题。如图 2，<br><img src="/images/M2Det_fig2.png" alt=""></p><p>首先融合 backbone 的 multi-level features（来自于多 layers 输出）作为 base feature，将这个 base feature 喂给一个交替连接 Thinned U-shape Modules(TUM) 和 Feature Fusion Modules(FFM) 的 block（如图 2 中红色框），从而得到更具表征能力的 multi-level multi-scale features，multi-leve 是指 shallow, medium, deep 等 level，multi-scale 是指每个 level 均具有多尺度 features。值得注意的是，每个 U 型模块中的解码层深度相同，这是为了在下一步 Scale-wise Feature Aggregation Module（SFAM） 中，将每个 level 中 scale 相同的特征聚合起来构成最终的 feature pyramid，这个 SFAM 操作相当于将 multi-level multi-scale 变成 multi-scale multi-level，也就是说，用于检测每个 scale 范围目标的 feature 均包含浅层特征和深层特征。显然，用于生成最终 feature pyramid 的解码层特征比原先 backbone 中的 layers 更深，所以也就更具有表征能力。我们称此 feature pyramid 模块为 Multi-Level Feature Pyramid Network（MLFPN）。</p><p>为了评估 MLFPN 的有效性，我们设计并训练了一个端到端的 one-stage 目标检测器称为 M2Det，这是将 MLFPN 合并入 SSD 得到的检测器。M2Det 获得了新 SOTA 结果，使用单尺度 inference 时，FPS=11.8，AP=41.0，而使用多尺度 inference 时，AP 高达 44.2，超过 MS-COCO 上其他 one-stage 检测结果。</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><p>M2Det 网络结构如图 2，使用 backbone 和 MLFPN 得到 feature pyramid，其他网络部分与 SSD 类似，生成密集预测 bbox 以及分类得分，然后使用 NMS 得到最后的检测结果。MLFPN 包含：FFM, TUM 以及 SFAM。FFMv1 丰富了 base feature 中的语义信息，因为融合了 backbone 多级 feature maps。每个 TUM 均生成一组多尺度特征，每一个尺度用于检测对应尺度范围的目标。交替连接 TUM 和 FFMv2 以抽取 multi-level multi scale features。此外，SFAM 按 scale 聚合多个 level 的 features（concatenate features）。关于这三个核心模块的细节以及 M2Det 的配置介绍如下。</p><h2 id="MLFPN"><a href="#MLFPN" class="headerlink" title="MLFPN"></a>MLFPN</h2><p>如图 2，首先，FFMv1 融合了浅层和深层的特征得到 base feature，例如，融合 VGG 中 conv4_3 和 conv5_3 的特征。然后，交替连接 TUM 和 FFMv2，每个 TUM 生成不同 scale 的 feature maps，FFMv2 则融合 base feature 和上一 TUM 中最大 scale 的 feature，融合后的 feature maps 作为下一 TUM 的输入。注意第一个 TUM 仅从 base feature 中学习。输出的 multi-level multi-scale features 按如下方式计算：</p><script type="math/tex; mode=display">[x_1^l,...x_i^l]=\begin{cases} \mathbf T_l(\mathbf X_{base}) & l=1\\\\ \mathbf T_l(\mathbf F (\mathbf X_{base}, \mathbf x_i^{l-1})) & l=2,...L \end{cases}</script><p>其中，$\mathbf X_{base}$ 表示 base feature，$x_i^l$ 表示第 $l$ 个 TUM 中第 $i$ 个 scale 的 feature，L 表示 TUM 数量，$\mathbf T_l$ 表示 第 $l$ 个 TUM 处理，$\mathbf F$ 表示 FFMv2 融合过程。</p><h3 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h3><p>FFM 是如何融合多个 feature 的呢？使用 1x1 卷积压缩这些 features，然后使用 concatenation 操作聚合这些 features。由于 FFMv1 将 backbone 中不同 scale 的两个 features 作为输入，所以需要将其中深层特征 upsample 使得与浅层特征的 scale 相同，然后再执行 concatenation 操作。TUM 的网络结构是 <strong>对称</strong> 的，所以 FFMv2 的两个输入 base feature 与 上一 TUM 的最大的输出 feature 具有相同的 scale，故直接 concatenate 起来作为下一 TUM 的输入。FFMv1 和 FFMv2 的结构如图 4 (a)(b)。<br><img src="/images/M2Det_fig4.png" alt=""> <center>Fig 4 (a) FFMv1. (b) FFMv2. (c) TUM。每个 block 中数字分别表示：输入通道，卷积核 size，步幅，输出通道</center></p><h3 id="TUM"><a href="#TUM" class="headerlink" title="TUM"></a>TUM</h3><p>TUM 是一个 Thin U-shape 结构，如图 4(c)，encoder 是一系列的 stride=2 的 3x3 卷积，decoder 将这些卷积层的输出作为 feature maps 的参考集合，而 FPN 则使用 backbone 中的 layer 输出。此外，我们在 upsample 和 element-wise sum 操作之后增加了一个 1x1 卷积，以增强学习能力并保持特征的平滑。所有 TUM 的 decoder 输出形成 multi-level multi-scale features，其中，靠前的 TUM 生成浅层的 multi-scale features，中间的 TUM 生成中层的 multi-scale features，而靠后的 TUM 生成深层的 multi-scale features。</p><h3 id="SFAM"><a href="#SFAM" class="headerlink" title="SFAM"></a>SFAM</h3><p>SFAM 用于聚合所有 TUM 输出的 multi-level multi-scale features，如图 3，<br><img src="/images/M2Det_fig3.png" alt=""><center>Fig 3 SFAM 结构。第一阶段是按 scale 沿 channel 维度 concatenate 特征，第二阶段使用 SE attention 以适应的方式聚合特征</center></p><p>第一阶段是将 scale 相等的 features 沿通道方向 concatenate，聚合后的 feature pyramid 可表示为 </p><script type="math/tex; mode=display">\mathbf X=[\mathbf X_1,...,\mathbf X_i]</script><p>其中 $\mathbf X_i=Concat(x_i^1,…x_i^L) \in \mathcal R^{W_i \times H_i \times C}$ 表示第 $i$ 个 scale 的（由浅层到深层）特征，$W_i \times H_i$ 表示第 $i$ 个 scale 的 feature map 的 size，这里所有 scale 所有 level 的 feature maps 的通道 $C$ 均相等，如图 4 中 $C=128$。但是仅仅 concatenate 这些 features，其适应性还不足（有点生硬），所以第二阶段，我们采用了通道注意力模块使得 features 专注于那些能从中获得最大收益的通道。参考 SE block，在 squeeze 这一步，我们使用全局平均池化（global average pooling）按通道生成统计量 $\mathbf z \in \mathcal R^C$，然后再 excitation 这一步，使用两个 fc 层学习注意力机制以获得通道依赖性，</p><script type="math/tex; mode=display">\mathbf s = \mathbf F_{ex}(\mathbf {z,W})=\sigma (\mathbf W_2 \delta(\mathbf W_1 \mathbf z))</script><p>其中，$\sigma$ 表示 ReLu，$\delta$ 表示 sigmoid，$\mathbf W_1 \in \mathcal R^{\frac C r \times C}, \ \mathbf W_2 \in \mathcal R^{C \times \frac C r}$， r 是缩小比例（实验中 r=16），然后重新对特征按通道加权得到最终的特征，</p><script type="math/tex; mode=display">\tilde {\mathbf X_i^c}=\mathbf F_{scale}(\mathbf X_i^c, s_c)=s_c \cdot \mathbf X_i^c</script><p>最后的特征为 $\tilde {\mathbf X_i}=[\tilde {\mathbf X_i^1},…,\tilde {\mathbf X_i^C}]$。</p><h3 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h3><p>分别使用 VGG 和 ResNet 作为 M2Det 的 backbone，backbone 使用 ImageNet2012 进行预训练。MLFPN 包含 8 个 TUM，每个 TUM 包含 5 个 convs 和 5 个上采样操作，故共输出 6 个 scale 的 features。为了降低参数量，TUM 的每个 scale 的特征仅使用 256 个通道，参见图 4 (c) 中最上面一排。整个网络的输入大小遵循原始的 SSD, RefineDet 和 RetinaNet，分别为 320, 512 和 800。</p><p>MLFPN 之后，得到 6 组 pyramid features，scale 分别为 1x1，3x3，5x5，10x10，20x20，40x40，我们为每个 scale 的 pyramid features 分别增加两个卷积层，用于定位回归和分类。6 组 pyramid features 上 anchor(prior) box 的默认 scale （不考虑 aspect ratio）与原始 SSD 中保持一致，稍微回顾一下这一点，假设共 m 组 features（这里 m = 6），第 k 组 features 上的 anchor box 的默认 scale 为</p><script type="math/tex; mode=display">s_k=s_{min}+\frac {s_{max}-s_{min}} {m-1} (k-1)</script><p>其中，$s_{min}=0.2, \ s_{max}=0.9$（当然，还需要乘上每组 features 相对于输入 image 的步幅（下采样率）才是最终的 anchor 的默认 scale）。</p><p>在 pyramidal features 上每个像素点位置，设置 6 个 anchors，包含 3 个 aspect ratios（参考 SSD）。使用阈值 0.05 过滤掉较低得分的检测，然后使用线性核函数的 <a href="/2019/06/24/cv-mtds">soft-NMS</a> 进一步处理检测结果。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验略，请阅读原文以获取详细信息</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>提出了 MLFPN 以解决目标检测中 multi-scale 问题。构造 M2Det 目标检测器取得了 SOTA 的 one-stage 检测结果。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BBox-Reg-Uncertainty</title>
      <link href="/2019/06/28/obj_det/BBox-Reg-Uncertainty/"/>
      <url>/2019/06/28/obj_det/BBox-Reg-Uncertainty/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1809.08545">Bounding Box Regression with Uncertainty for Accurate Object Detection</a><br><span id="more"></span></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>大型目标检测集如 ImageNet，MS-COCO 和 CrowdHuman 等都致力于定义足够明确的 ground truth bounding box。但是有时候 gt bbox 的边界是不明确的，使得难以去打标签，也难以学习 bbox 回归函数（的参数），如图 1，<br><img src="/images/BBox-reg_fig1.png" alt=""> <center>Fig 1 MS-COCO 数据集中 gt bbox 不明确的情况。(a)(c) 标签不准确导致歧义；(b) 遮挡导致歧义；(d) 目标边界本身就不明确</center></p><p>当前 SOTA 目标检测器如 Faster R-CNN，Cascade R-CNN 和 Mask R-CNN 等均依赖于 bbox 回归来定位目标。传统的 bbox 回归损失如 smooth-L1 没有考虑到 gt box 的不明确性，所以损失较大，并且认为分类得分越高时 bbox 回归越准确（应该说的是 Inference 阶段），但事实不总是如此，如图 2，分类得分高的 bbox 但是回归不够准确，回归不准确还是说明 <strong>回归 loss 较大</strong>。<br><img src="/images/BBox-reg_fig2.png" alt=""> <center>Fig 2 MS-COCO 上使用 VGG-16 Faster R-CNN 的失败案例。(a) 两个预测框均不准确；(b) 高分类得分 bbox 的左边界不准确</center></p><p>为了解决以上问题，我们介绍一种新型 bbox 回归损失 KL loss，同时学习 bbox 回归和定位不确定性，从而使得 <strong>回归 loss 较小</strong>。学习 gt box 的不确定性肯定是针对整个数据集的，首先将预测 box 和 gt box 分别建模为 Gaussian 分布和 Dirac delta 函数。KL loss 定义为预测分布和 gt 分布之间的 KL 散度，我们知道 KL 散度用于衡量两个分布之间的距离（其实不满足距离的对称性，即不满足交换律）或者说差异，差异越大，KL 散度越大。假设目标分布为 P(x)，使用 Q(x) 去匹配目标分布，那么 KL 散度为</p><script type="math/tex; mode=display">D_{KL}(P||Q)=\sum_{i=1}^N P(x_i) \log \frac {P(x_i)} {Q(x_i)}</script><p>这是离散分布的情况，对于连续分布则为，</p><script type="math/tex; mode=display">D_{KL}(P||Q)=E_P \left[\log \frac {p(x)} {q(x)} \right]=\int p(x) \log \frac {p(x)} {q(x)} dx</script><p>注意，此时 p(x) 和 q(x) 表示概率密度而非概率。<br>显然如果 P,Q 完全匹配，那么 KL 散度达到最小值 0。</p><p>使用 KL loss 学习 bbox 回归有以下三个优点：</p><ol><li>可以成功捕获数据集中的不明确性，对于有歧义的 bbox，回归损失更小</li><li>学习到的方差在后续处理中非常有用。我们提出 var voting (variance voting)，通过使用附近 box 的位置和位置方差来票选（加权平均）出当前候选 box 的位置。这么做是为了解决 Fig 2 中的问题</li><li>学习到的概率分布是可解释的。由于分布反应的是预测 box 的不确定性，故在汽车自动驾驶或机器人等下游应用中非常有用</li></ol><p>我们提出了 KL loss 和 var voting，为了验证这两者的通用性，我们使用了 PASCAL VOC 2007 和 MS-COCO 两个 benchmark，多个目标检测器包括 VGG-CNN-M-1024, VGG-16, ResNet-5-FPN 以及 Mask R-CNN（前两者属于 Faster R-CNN），实验证明使用我们提出的方法均提升了目标定位的准确率。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="BBox-参数化"><a href="#BBox-参数化" class="headerlink" title="BBox 参数化"></a>BBox 参数化</h2><p>基于 Faster R-CNN 或 Mask R-CNN 如图 3，我们分别回归 bbx 的四条边坐标，即 Box 分支输出 shape 为 (N, 84)，其中 N 表示使用 proposals 的 batch size，84 是 21 个分类下 4 个坐标预测（这里以 PASCAL VOC 为例，共 21 个分类），Box std 分支输出 shape 也是 (N, 84)，表示 21 分类下 4 条边坐标分布的标准差 $\sigma$，坐标是分类相关的（not class-agnostic），前面简介部分所讲的将 box 建模为高斯分布，就是指四条边的坐标均为高斯分布，具体请往下看，<br><img src="/images/BBox-reg_fig3.png" alt=""></p><p>令 $(x_1,y_1,x_2,y_2) \in \mathcal R^4$ 表示预测 bbox，那么偏差 $\{t_i| i=x_1,y_1,x_2,y_2\}$ 为：</p><script type="math/tex; mode=display">t_{x_1}=\frac {x_1-x_{1a}} {w_a}, \quad t_{x_2}=\frac {x_2-x_{2a}} {w_a}\\\\ t_{y_1}=\frac {y_1-y_{1a}} {h_a}, \quad t_{y_2}=\frac {y_2-y_{2a}} {h_a}\\\\ t_{x_1}^{\ast}=\frac {x_1^{\ast}-x_{1a}} {w_a}, \quad t_{x_2}^{\ast}=\frac {x_2^{\ast}-x_{2a}} {w_a}\\\\ t_{y_1}^{\ast}=\frac {y_1^{\ast}-y_{1a}} {h_a}, \quad t_{y_2}^{\ast}=\frac {y_2^{\ast}-y_{2a}} {h_a}</script><p>其中带 <em> 的为 gt offset，不带 </em> 的为预测 offset，$(x_{1a},y_{1a},x_{2a},y_{2a})$ 为 anchor box。后面的讨论中，由于各坐标独立进行优化，故我们统一使用 x 表示这四个坐标，x 取值为$\{x_1,y_1,x_2,y_2\}$。</p><p>我们的网络不仅仅预测 bbox 的定位，还预测其概率分布。这种分布可以是复杂的如多变量高斯分布或混合高斯分布，但是本文为了简单起见，我们假定各坐标互相独立，故使用单变量高斯分布，</p><script type="math/tex; mode=display">P_{\Theta}(x)=\frac 1 {\sqrt {2 \pi \sigma^2}}e^{- \frac {(x-x_e)^2} {2 \sigma^2}}</script><p>其中 $\Theta$ 是可学习的参数，$x_e$ 是 bbox 位置估计，标准差 $\sigma$ 衡量位置估计的不确定性，越大越不确定。当 $\sigma \rightarrow 0$，表示网络对 bbox 位置估计非常十分自信。</p><p><del>（以 Faster R-CNN 为例说明，bbox 回归分支其实是两组输出 blob，分别使用两个全连接层得到，分别表示 4 个 坐标估计以及 4 个坐标分布的标准差，所以可以说，$\Theta$ 就是这两个全连接层的权重参数。这段话不一定准确，需要看源码待定）</del></p><p>gt box 也可以使用高斯分布，只是其中标准差无限趋于 0： $\sigma \rightarrow 0$，此时退化为 Dirac delta 函数，</p><script type="math/tex; mode=display">P_D(x)=\delta(x-x_g)</script><p>其中 $x_g$ 是 gt box 位置 x 坐标。</p><h2 id="使用-KL-Loss-的-BBox-回归"><a href="#使用-KL-Loss-的-BBox-回归" class="headerlink" title="使用 KL Loss 的 BBox 回归"></a>使用 KL Loss 的 BBox 回归</h2><p>最小化 $P_{\Theta}(x)$ 和 $P_D(x)$ 之间的 KL 散度来估计参数 $\hat \Theta$，即，使用 KL 损失优化网络参数，</p><script type="math/tex; mode=display">\hat \Theta = \arg \min_{\Theta} \frac 1 N \sum D_{KL}(P_D(x)||P_{\Theta}(x))</script><p>其中 N 表示样本数量，x 表示 4 个坐标中的一个。KL 散度作为回归损失，而分类损失维持原来不变。</p><script type="math/tex; mode=display">\begin{aligned} L_{reg} &=D_{KL}(P_D(x)||P_{\Theta}(x)) \\\\ &=\int P_D(x) \log P_D(x) dx - \int P_D(x) \log P_{\Theta}(x) dx\\\\ &=-H(P_D(x))-\int P_D(x) \log \frac 1 {\sqrt {2 \pi \sigma^2}}e^{- \frac {(x-x_e)^2} {2 \sigma^2}} dx\\\\ &=-H(P_D(x))+ \log \sqrt{2\pi \sigma^2}\int P_D(x) dx+\int P_D(x) \frac {(x-x_e)^2} {2 \sigma^2} dx\\\\ &=\frac {(x_g-x_e)^2}{2\sigma^2}+\frac {\log \sigma^2} 2 + \frac {\log 2\pi} 2 - H(P_D(x))\end{aligned}</script><p>其中，$H(P_D(x))$ 是 Dirac delta 分布的信息熵。</p><p>如图 4，<br><img src="/images/BBox-reg_fig4.png" alt=""></p><p>当 box 位置 $x_e$ 估计不正确时，我们希望方差 $\sigma^2$ 更大，从而降低回归损失 $L_{reg}$。由于 $H(P_D(x)), \log (2\pi)/2$ 均与估计参数 $\Theta$ 无关，故有，</p><script type="math/tex; mode=display">L_{reg} \propto \frac {(x_g-x_e)^2}{2\sigma^2}+\frac {\log \sigma^2} 2</script><p>当 $\sigma=1$，KL Loss 退化为标准的欧氏距离，</p><script type="math/tex; mode=display">L_{reg} \propto \frac {(x_g-x_e)^2} 2</script><p>损失关于估计位置 $x_e$ 和定位标准差 $\sigma$ 可导，</p><script type="math/tex; mode=display">\frac d {dx_e}L_{reg}=\frac {x_e-x_g} {\sigma^2}\\\\ \frac d {dx_e}L_{reg}=-\frac {(x_e-x_g)^2} {\sigma^3} + \frac 1 \sigma</script><p>由于 $\sigma$ 位于分母上，所以训练初期可能会出现梯度爆炸，为了避免这种现象，在训练阶段，使用 $\alpha=\log \sigma^2$ 代替 $\sigma$，即，图 3 中 Box std 输出为 $\alpha$，此时</p><script type="math/tex; mode=display">L_{reg} \propto \frac {e^{-\alpha}} 2 (x_g-x_e)^2+\frac \alpha 2</script><p>反向传播时使用 $L_{reg}$ 关于 $\alpha$ 的梯度。测试阶段，则将 $\alpha$ 转变为 $\sigma$，即测试阶段中，需要将 Box std 的输出经过 $\sigma=\sqrt{e^{\alpha}}$ 转换才能得到标准差。</p><p>当 $|x_g - x_e| &gt; 1$ 时，我们参考 smooth-L1 改写回归损失，这是为了避免 $x_g,x_e$ 相差太多时，损失过大造成训练不稳定，于是最终有，</p><script type="math/tex; mode=display">L_{reg} \begin {cases} \propto \frac {e^{-\alpha}} 2 (x_g-x_e)^2+\frac \alpha 2 & |x_g - x_e| \le 1\\\\ = e^{-\alpha} (|x_g-x_e|-\frac 1 2 )+\frac \alpha 2 & |x_g - x_e| > 1 \end{cases}</script><p>根据以上分析可见，网络 bbox 回归分支输出两组数据，分别是预测位置 offset 以及位置分布标准差 $\sigma$。训练阶段，将预测 $\sigma$ 改为预测 $\alpha$，$\alpha$ 预测的那个全连接层参数使用随机 Gaussian 初始化，这个 Gaussian 使用标准差 0.0001，期望 0。</p><h2 id="Variance-Voting"><a href="#Variance-Voting" class="headerlink" title="Variance Voting"></a>Variance Voting</h2><p>得到预测位置坐标的方差 $\sigma^2$ 后，根据附近 bbox 的位置方差票选出当前候选框的位置，这里附近是指与当前 box 有重叠（IoU&gt;0）的 box。使用 Variance Voting 是为了解决 Fig 2 中的问题。算法如下，</p><p><strong>Algorithm 1</strong> var voting</p><hr><p>$\mathcal B$ 是 Nx4 的矩阵，表示初始检测 boxes</p><p>$\mathcal S$ 为相应的检测得分，是长度为 N 的一维向量</p><p>$\mathcal C$ 是相应的方差，也是一个 Nx4 的矩阵</p><p>$\mathcal D$ 为最终的检测结果集，$\sigma_t$ 是 var voting 的一个参数，其值可调整</p><p>$\mathcal B=\{b_1,…,b_N\}, \ \mathcal S=\{s_1,…,s_N\}, \ \mathcal C=\{\sigma_1^2,…,\sigma_N^2\}$</p><p>$\mathcal D \leftarrow \{\}, \ \mathcal T \leftarrow \mathcal B$</p><p><strong>while</strong> $\mathcal T \ne \varnothing$ <strong>do</strong></p><ul><li>$m \leftarrow \arg\max \mathcal T$ （论文中为 $\arg \max \mathcal S$，但是我觉得不对）</li><li>$\mathcal T \leftarrow \mathcal T - b_m$</li><li><font color='cyan'>$\mathcal S \leftarrow \mathcal S f(IoU(b_m, \mathcal T)) \qquad \qquad \qquad \qquad \ \ \triangleright$ soft-NMS </font></li><li><font color='gree'>$idx \leftarrow IoU(b_m, B) > 0 \qquad \qquad \qquad \qquad \triangleright$    var voting </font></li><li><font color='gree'> $p \leftarrow exp(-(1-IoU(b_m, \mathcal B[idx]))^2/\sigma_t)$ </font></li><li><font color='gree'> $b_m \leftarrow p(\mathcal B[idx]/\mathcal C[idx])/p(1 / \mathcal C[idx])$</font></li><li>$\mathcal D \leftarrow \mathcal D \cup b_m$</li></ul><p><strong>end while</strong></p><p><strong>return</strong> $\mathcal {D, S}$</p><hr><p>我们已经知道，当前检测 box 的近邻 box 指与当前 box 的 IoU 超过一定阈值的 box。NMS 是移除得分较低的近邻预测 box ，soft-NMS 是 NMS 的修改版，将得分较低的近邻预测 box 重新修改为一个更低的得分，简单来讲就是得分低，则进一步抑制其得分，衰减因子为函数 $f(IoU(b_m,b_i))$ 的值，关于这两者的具体解释可参考 <a href="/2019/06/24/cv-mtds">CV 中的常用方法总结</a>。</p><p>算法 1 中，对于当前得分最高的检测 box，记为 b， $\{x_1,y_1,x_2,y_2,s,\sigma_{x1},\sigma_{y1},\sigma_{x2},\sigma_{y2}\}$，先使用 soft-NMS 衰减其近邻 boxes 的得分，然后获取其附近（IoU&gt;0） boxes，根据附近 boxes $\sigma$ 的加权来计算当前 box 的新位置，这里加权是基于这样一个认识：某个附近 box 如果越靠近当前 box，那么用它的值来计算当前 box 就越有把握，不确定性越低。用 x 表示坐标（例如 x<sub>1</sub> 坐标），x<sub>i</sub> 表示第 i 个 box 的坐标，坐标新值按如下计算：</p><script type="math/tex; mode=display">p_i = e^{-(1-IoU(b_i,b))^2/\sigma_t}\\\\ x=\frac {\sum_i p_i x_i/\sigma_{x,i}^2} {\sum_i p_i / \sigma_{x,i}^2}\\\\ \text{s.t.  IoU}(b_i, b) >0</script><p>上面两式非常明显了，我们不直接使用检测 box 的初始预测位置值，而是通过附近 boxes 的位置和位置方差加权平均值作为当前 box 的位置坐标值。当附近 box 与当前 box 靠的越近，IoU 越大，然后 p<sub>i</sub> 越大，然后 voting 当前 box 的坐标时，权值越大，即贡献越大。另外，上两式也表明附近 box 的方差也影响权值， 当 $\sigma^2$ 越小，权值越大，贡献也越大。以上 voting 过程没有考虑分类得分值，因为低得分的 box 其定位置信度可能还更高，所以让分类得分影响权值，也许会降低准确性。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验介绍及结果分析略，请阅读原文以获得更详细的信息。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>大型数据集中 gt box 的不确定性会阻碍 SOTA 检测器性能的提升。分类置信度与定位置信度不是强相关的。本文提出新型 bbox 回归损失用于学习目标的准确定位。使用 KL Loss 训练网络学习预测每个坐标的分布方差。预测的方差用在 var voting 中，从而改良 box 的坐标。</p><p>从网络结构上来看，在 Faster R-CNN/Mask R-CNN 基础上修改回归预测分支，使用 KL Loss 替换 smooth L1 Loss，并使用 var voting 得到坐标新值，其中坐标初始预测值（也就是算法 1 中的输入 $\mathcal B$）与 Faster R-CNN 中相同。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FSAF</title>
      <link href="/2019/06/27/obj_det/FSAF/"/>
      <url>/2019/06/27/obj_det/FSAF/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1903.00621">Feature Selective Anchor-Free Module for Single-Shot Object Detection</a><br><span id="more"></span><br>目标检测中一个具有挑战性的问题是目标尺度的变化，即，在检测极小目标或极大目标时，往往检测性能不够好。为了达到尺度不变性，SOTA 检测器使用 feature pyramid 或 image pyramid。比如使用 feature pyramid 时，高 level 的 feature 对应大 anchor，低 level 的 feature 对应小 anchor，如图 2，高 level 的 feature 拥有更多的语义信息，适合检测大目标，而低 level 的 feature 由于保持了细粒度的信息，所以适合检测小目标。但是这种网络设计有两个局限：</p><ol><li>启发式导向的特征选择</li><li>基于 overlap 选取 anchor </li></ol><p>第 1 点是指对某个目标的检测选择哪个 level 的 feature 是启发式的，或者说是通过不断的实验、试错从而找到这个问题的解，这就导致为某个目标所选的 feature level 可能不是最优的。第 2 点则指出每个目标总是需要根据 IoU 去匹配到最近的 anchor 上去。</p><p><img src="/images/FSAF_fig2.png" alt=""></p><p>本文则提出一个简单而有效的方法同时解决以上两个局限，此方法名为 feature selective anchor-free (FSAF)，目的是为了让每个目标实例选择最佳 feature level。如图 3，</p><p><img src="/images/FSAF_fig3.png" alt=""> <center>Fig 3 FSAF 插入到传统基于 anchor 的检测模块中。训练阶段，根据特征选择将每个目标实例分配到一个pyramid level上</center></p><p>对 feature pyramid 的每个 level 均使用一个 anchor-free 分支，此分支与 anchor-based 分支类似，包含一个分类子网络和回归子网络（图 3 中没有展示出来）。目标实例可被分配到任意 level 的 anchor-free 分支。训练阶段，基于实例内容而不仅仅是实例 box 为每个目标实例动态选择最佳 feature level。这个 feature level 负责学习并检测这个被分配过来的目标实例。Inference 阶段，可以单独使用 FSAF 模块或者将其与 anchor-based 分支结合使用。此外，anchor-free 分支和在线特征选择可以使用复杂的结构，但是在我们的实验中，我们选择简单的 FSAF 模块结构，所以 FSAF 模块的计算量与整个网络相比是很小的。</p><h1 id="FSAF-模块"><a href="#FSAF-模块" class="headerlink" title="FSAF 模块"></a>FSAF 模块</h1><p>我们来看下如何实现 FSAF 模块以及如何将其整合到具有 feature pyramid 的 single-shot 检测器（如 SSD, DSSD, RetinaNet）中。不失一般性，我们将 FSAF 应用到 SOTA 的 RetinaNet。从以下几个方面来说明我们的设计：</p><ol><li>如何创建 anchor-free 分支</li><li>如何生成 anchor-free 分支的监督信号（GT target）</li><li>如何为每个实例动态选择 feature level</li><li>如何联合训练/测试 anchor-free 分支和 anchor-based 分支</li></ol><h2 id="网络框架"><a href="#网络框架" class="headerlink" title="网络框架"></a>网络框架</h2><p>图 4 是将 FSAF 应用到 RetinaNet 的网络结构。简单而言，Retina 由一个 backbone 网络以及两个特定任务的子网络组成。从 backbone 网络中构建 feature pyramid，其 level 为 $\{P_l|l\in [3,7]\}$，$P_l$ 分辨率为输入 image 的 $1/2^l$ 倍。图 4 中为了简单起见仅显示了三个 level 的 feature pyramid，每个 level 负责检测一定 scale 范围的目标，每个 feature level 后接分类子网络和回归子网络，这俩子网络均为小型全卷积网络。</p><p>基于 RetinaNet，FSAF 仅在每个 feature level 增加两个卷积层，如图 4，</p><p><img src="/images/FSAF_fig4.png" alt=""><center>Fig 4 具有 FSAF 的 RetinaNet 框架</center></p><p>这两个卷积层分别负责 anchor-free 分支的分类预测和回归预测。具体地，具有 3x3 大小的 K 个卷积核的卷积层附在分类子网络上，这个卷积层后跟一个 sigmoid 函数用于将分类得分归一化，与 anchor-based 的分类卷积层并列，用于预测空间每个位置点的 K 个分类的得分（置信度）。回归子网络则类似的使用 3x3 大小的 4 个卷积核的卷积层后跟一个 ReLu 函数，用于预测 anchor-free 方式的 box 偏差。anchor-free 分支和 anchor-based 分支以多任务方式联合运作并共享所属 level 的 feature。</p><h2 id="Ground-truth-and-Loss"><a href="#Ground-truth-and-Loss" class="headerlink" title="Ground-truth and Loss"></a>Ground-truth and Loss</h2><p>给定一个目标，我们知道其分类 k 和 bbox 坐标 b=[x,y,w,h]。此目标可被分配到任意 feature level，定义此目标映射到 $P_l$ 的 box 为 $b_p^l=[x_p^l,y_p^l,w_p^l,h_p^l]$，由于 $P_l$ 分辨率是输入 image 的 $1/2^l$，故 $b_p^l=b/2^l$。定义一个有效 box $b_e^l=[x_e^l,y_e^l,w_e^l,h_e^l]$ 和一个 ignore box $b_i^l=[x_i^l,y_i^l,w_i^l,h_i^l]$，均为 $b_p^l$ 的线性缩放，比例分别为 $\epsilon_e, \ \epsilon_i$，于是有</p><script type="math/tex; mode=display">x_e^l=x_p^l, \ y_e^l=y_p^l, \ w_e^l=\epsilon_e w_p^l, \ h_e^l=\epsilon_e h_p^l\\\\x_i^l=x_p^l, \ y_i^l=y_p^l, \ w_i^l=\epsilon_i w_p^l, \ h_i^l=\epsilon_i h_p^l</script><p>（到这里就发现与 <a href="/2019/06/25/GA-RPN">GA-RPN</a> 中完全一样有木有，所以 anchor-free 到底是什么，是不是也突然明白了什么，如果与 GA-RPN 中一样的话，那么 anchor-free 就是指没有预设 scale 和 aspect ratio 生成的均匀密集分布的 anchor，也就是说 anchor-free 还是有 anchor 的，只不过其 shape 是任意的、动态生成的，而不是 anchor-based 那样固定的 scale 和 aspect ratio。好的，先不管是不是这样，我们继续往下讨论。）</p><p>图 5 是一个 car 实例的 GT 生成（GT target）的例子</p><p><img src="/images/FSAF_fig5.png" alt=""></p><p><strong>分类输出：</strong> 分类的 GT output 是 K-channel maps，每个 map 对应一个分类。假设目标分类为 k，那么对第 k 个 GT map 有：</p><ul><li>位于 $b_e^l$ 内的为正例，值为 1，如图 5 中白色区域</li><li>位于 $b_i^l - b_e^l$ 内的点忽略，此区域的梯度不进行反向传播，如图 5 中灰色区域</li><li>如果存在邻近 feature level，那么其上的 $b_i^{l-1}, b_i^{l+1}$ 区域也被忽略</li></ul><p>这里需要注意的是，由于在线特征选择模块，单个实例最终只用在最佳的某个 feature level 上。</p><p>如果两个实例的有效 box 重叠了，较小尺度的实例优先权更高。gt map 的剩余区域则是负例，值为 0，如图 5 中黑色区域。分类损失使用 Focal loss，</p><script type="math/tex; mode=display">FL(p_t)=-\alpha_t (1-p_t)^{\gamma} \log p_t\\\\p_t=\begin{cases} p & y=1 \\\\1-p & y=0 \end{cases}\\\\\alpha_t=\begin{cases} \alpha & y=1 \\\\1-\alpha & y=0 \end{cases}</script><p>anchor-free 的总分类损失为除 ignore box 之外的区域内所有点的 focal loss 之和，并除以有效 box 内点的数量进行归一化。</p><p><strong>Box 回归输出：</strong> 回归输出的 gt 为 4-channal maps，表示 4 个偏差值（与分类无关，否则就是 4K-channel 了）。实例仅影响 gt maps 上 $b_e^l$ 区域的值，对 $b_e^l$ 内某一像素点位置 (i,j)，我们使用一个 4-d 向量来表示 $b_p^l$：</p><script type="math/tex; mode=display">\mathbf d_{i,j}^l=[d_{t_{i,j}}^l,d_{l_{i,j}}^l,d_{b_{i,j}}^l,d_{r_{i,j}}^l]</script><p>其中 $d_t^l,d_l^l,d_b^l,d_r^l$ 分别为当前位置点 (i,j) 到 $b_p^l$ 的 top,left,bottom,right 四条边的距离。这个与 <a href="FCOS">FCOS</a> 是差不多的，毕竟都是 anchor-free 的。然后点 (i,j) 处的 4-d 向量归一化为 $\mathbf d_{i,j}^l/S$，根据经验 S=4（可能是训练过程中发现这样归一化后不容易出现梯度饱和的现象，或者是训练更加稳定）。有效 box 之外的区域的梯度全部忽略。采用 IoU 损失来优化此分支参数。anchor-free 的总回归损失为所有有效 box 区域的 IoU 损失的平均（损失之和对有效 box 内点的数量取平均），其中单点 IoU 损失为</p><script type="math/tex; mode=display">L_{IoU}=-\log IoU\\\\ IoU = \frac {I(b_p,b_{gt})} {U(b_p,b_{gt})}</script><p>具体可参考 UnitBox。</p><p>Inference 阶段，从分类输出和回归输出中解码出预测 box。在位置 (i,j)，假设预测偏差输出为 $[\hat o_{t_{i,j}},\hat o_{l_{i,j}},\hat o_{b_{i,j}},\hat o_{r_{i,j}}]$，那么预测距离为 $[S\hat o_{t_{i,j}},S\hat o_{l_{i,j}},S\hat o_{b_{i,j}},S\hat o_{r_{i,j}}]$，于是左上角和右下角坐标分别为 $(i-S\hat o_{t_{i,j}},j-S\hat o_{l_{i,j}}), \ (i+\hat o_{b_{i,j}},j+\hat o_{r_{i,j}})$，最后再乘以 $2^l$ 就恢复到输入 image 上的预测框，其置信度得分和分类则可以根据分类输出 maps 上 (i,j) 处的 K-d 向量决定。</p><h2 id="在线特征选择"><a href="#在线特征选择" class="headerlink" title="在线特征选择"></a>在线特征选择</h2><p>FSAF 模块为每个实例选择最佳 level 的 feature $P_l$，这种选择是基于实例的内容，而 anchor-based 中则是基于实例 box 大小，显然基于实例内容更加合理。</p><p>给力实例 $I$，定义其在 $P_l$ 上的分类损失和回归损失分别为 $L_{FL}^I(l), \ L_{IoU}^I(l)$，计算式如下</p><script type="math/tex; mode=display">L_{FL}^I(l)=\frac 1 {N(b_e^l)} \sum_{i,j \in b_e^l} FL(l,i,j)\\\\L_{IoU}^I(l)=\frac 1 {N(b_e^l)} \sum_{i,j \in b_e^l} IoU(l,i,j)</script><p>其中，$N(b_e^l)$ 为有效 box 内点的数量。注意因为只考虑实例 $I$ 的损失，故分类损失只考虑了正例损失的那部分。</p><p>图 6 显示了在线特征选择的过程。</p><p><img src="/images/FSAF_fig6.png" alt=""> <center>Fig 6 在线特征选择机制。每个实例通过所有level的anchor-free分支以相应的计算平均分类损失和平均回归损失，然后具有最小两种损失之和的分支为最佳分支，在此分支上设立此实例的监督信号（gt target）</center></p><p>首先实例 $I$ 前向传播到 feature pyramid，然后计算每个 anchor-free 分支的 $L_{FL}^I(l) + L_{IoU}^I(l)$ 的和，最后根据最小损失之和选择最佳 feature pyramid leve $P_l$，</p><script type="math/tex; mode=display">l^*=\arg \min_l L_{FL}^I(l) + L_{IoU}^I(l)</script><p>对于一个训练批次，更新某 level 的特征仅使用分配到此 level 上的实例。直觉上，根据这种方法选择的特征最适合对实例进行建模，因为此时的损失在特征空间构成损失下限，而经过训练又进一步地拉低损失下限。Inference 阶段，我们不需要手动选择使用哪个特征，在线选择的最适合的特征将会输出高置信度得分。</p><p>我们比较了启发式特征选择和在线特征选择。启发式特征选择仅依赖于 box size，例如在 FPN 检测器中，实例 $I$ 将被分配到 $P_{l’}$，其中</p><script type="math/tex; mode=display">l' = \lfloor l_0+\log_2(\sqrt{wh}/224) \rfloor</script><p>其中，(w,h) 是实例 size，224 是典型的 ImageNet 预训练尺寸，224x224 应该映射到 $l_0$ 这个 target level 上。如何理解上式？首先 $P_l$ 的分辨率是原始输入 image 的 $1/2^l$，然后将上式变形如下就能理解了，</p><script type="math/tex; mode=display">\sqrt{wh}/2^{l'} \approx 224/2^{l_0}</script><p>可见是将一个 scale 范围按 $1/2^l$ 的比例分配。我们这里选择 $l_0=5$，因为 ResNet 使用 conv5_x 卷积组的 feature map 进行分类预测。</p><h2 id="Joint-Inference-and-Training"><a href="#Joint-Inference-and-Training" class="headerlink" title="Joint Inference and Training"></a>Joint Inference and Training</h2><p>当 FSAF 模块插入到 RetinaNet 中时，如图 4，我们保持原来的 anchor-based 分支不变，所有的超参也不变。</p><p><strong>Inference:</strong> FSAF 仅增加少量的卷积层。对于 anchor-free 分支，我们对每个 pyramid level 的分类输出使用置信度阈值 0.05 进行过滤，然后分别选取 top 1k 得分的位置点，从这些位置解码出预测 box，所有 level 的预测 box 与 anchor-based 分支的预测 box 合并起来，并使用非极大抑制 NMS，NMS 阈值为 0.5，得到最后的检测结果。</p><p><strong>初始化：</strong> backbone 网络使用 ImageNet1k 预训练。RetinaNet 中的 layers 与原始 RetinaNet 中 layers 的初始化相同。FSAF 中的 分类分支的 layers 初始化所用的高斯分布权值 $\sigma=0.01$，偏置 bias 为 $-\log((1-\pi)/\pi)$，其中 $\pi$ 指明训练初始时各像素点输出是否存在目标的得分值在 $\pi$ 上下。我们遵循原始 RetineNet 中的设置 $\pi=0.01$。所有回归分支的 layers 初始化使用偏置 b=0.1，高斯权值 $\sigma=0.01$。以上初始化过程由于避免生成较大的损失，从而有助于训练初期过程的稳定。</p><p><strong>优化：</strong> 整个网络的损失来自于 anchor-free 分支和 anchor-based 分支。记原始 RetinaNet 的总损失为 $L^{ab}$，而 $L_{cls}^{af}, \ L_{reg}^{af}$ 分布为 anchor-free 分支的分类损失和回归损失。那么，整个网络的总损失为 $L=L^{ab}+\lambda (L_{cls}^{af} + L_{reg}^{af})$，其中 $\lambda$ 用于平衡两者，实验中设置 $\lambda=0.5$。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验介绍以及结果分析略，请阅读原文以获取详细信息。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文指出了具有 feature pyramid 的 anchor-based single-shot 目标检测器中启发式选择特征的不足之处，并提出 FSAF 模块以解决这个问题，FSAF 使用了 anchor-free 分支以及在线特征选择，显著提高了检测性能，inference 的耗费增加较少，但是性能超过最近的 SOTA single-shot 检测器。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GA-RPN</title>
      <link href="/2019/06/25/obj_det/GA-RPN/"/>
      <url>/2019/06/25/obj_det/GA-RPN/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1901.03278">Region Proposal by Guided Anchoring</a><br><span id="more"></span><br>目标检测中，通常使用 anchor 来生成 proposal（two-stage）或者直接对 anchor 进行分类和回归（one-stage）。以 two-stage 的 Faster R-CNN 为例，先在 feature map 上生成密集均匀分布的 anchors，然后对其进行二分类预测及坐标回归得到 proposals，最后再对 proposals 进行分类和坐标回归微调。</p><p>合理的 anchor 设计遵循两个通用规则：alignment 和 consistency：</p><ol><li>anchor 中心应与 feature map 的像素点对准</li><li>感受野 RF 和语义范围应与 anchor 的尺度和形状保持一致</li></ol><p>滑窗就是一种简单且被广泛采用的 anchor 生成机制，大多数目标检测方法均采用滑窗来生成均匀密集的 anchors，即，在 feature map 上每个像素点位置按预先设置的 scale 和 aspect ratio 生成 k 个 anchors。然而，这种 anchor 生成机制的困难在于：</p><ol><li>对不同的检测问题，需要预先精心设计适合的 scale 和 aspect ratio，否则会影响检测性能指标。</li><li>为了得到高的 recall，需要生成大量的 anchors，这导致大部分 anchors 为负例（non-object），同时，大量的 anchors 增加计算量</li></ol><p>本文提出一个有效的 anchor 生成方法，此方法受以下观点启发：</p><ol><li>根据观察，image 中的目标位置不是均匀分布的</li><li>目标的 scale 与目标位置和 image 内容相关</li></ol><p>于是我们的稀疏非均匀 anchor 生成方法步骤为（guided anchoring）：</p><ol><li>确定可能包含目标的子区域</li><li>根据子区域位置确定其 shape</li></ol><p>可学习的 anchor shape 虽然合理，但是打破了前述的 consistency 规则，即，学习到（动态生成）的 anchor shape 可能与 RF 和 语义 scope 不一致。由于现在的 scale 和 aspect ratio 是可变的而非固定的，所以 feature map 上不同的像素点的 anchor shape 也不尽相同，需要学习适配 anchor shape 的表征以维持 consistency 原则。为了解决此问题，我们介绍了一个有效的模块：基于 anchor shape 来修改 features 使其适配，此即 feature adaptation 机制。</p><p>使用前述的 guided anchoring 和 feature adaptation 机制，我们制定了 Guided Anchoring Region Proposal Network （GP-RPN）。由于动态预测 anchors，recall 值比常规 RPN（baseline，使用滑窗生成密集均匀分布的 anchor）高了 9.1%，而 anchors 数量下降了 90%。通过预测得到 scale 和 aspect ratio 而非固定的预设值，我们的检测方法能更加有效地处理 aspect ratio 小于 1/2 或 大于 2 的宽/高目标。除了用于生成 region proposals， guided anchoring 方法可集成到任何依赖 anchor 的检测器中（比如 SSD，直接拿 anchor 分类和回归得到最终的预测 box）。guided anchoring 机制能使得各种目标检测器获得一致的性能提升，比如在 COCO 数据集上， GA-Fast-RCNN，GA-Faster-RCNN 和 GA-RetinaNet 的 mAP 比相应的使用滑窗的 baseline 分别提升了 2.2%, 2.7% 和 1.2%。</p><h1 id="Guided-Anchoring"><a href="#Guided-Anchoring" class="headerlink" title="Guided Anchoring"></a>Guided Anchoring</h1><p>目标的 location 和 shape 可以使用 (x,y,w,h) 来刻画，其中 (x,y) 是中心点的坐标，(w,h) 表示宽高。给定一个 image $I$，那么目标 location 和 shape 遵循如下分布：</p><script type="math/tex; mode=display">p(x,y,w,h|I)=p(x,y|I)p(w,h|x,y,I)</script><p>这种因式分解基于如下两点：</p><ol><li>给定 image，目标仅位于某些特定区域</li><li>shape 即 scale 和 aspect ratio 与 anchor 的位置有关</li></ol><p>根据以上公式，我们的 anchor 生成模块如图 1，</p><p><img src="/images/GA-RPN_fig1.png" alt=""> <center>Fig 1 框架结构。每个feature map 均使用 anchor 生成模块，模块中有两个分支，分别预测 anchor 位置和 shape。应用 feature 适配模块到 feature map 上得到新的 feature map，使其注意到 anchor</center></p><p>给定 image $I$，首先得到 feature map $F_I$，在 $F_I$ 上 位置预测分支生成一个概率 map，表示每个位置处存在目标的概率，shape 预测分支生成位置相关的 shape，即预测每个位置的 w,h。使用一个概率阈值，选择大于阈值的位置，以及这些位置上最有可能的 shape，从而生成 anchor。考虑到 anchor 的 shape 可变，不同位置处的 feature 应该捕获不同范围内的视觉内容，所以我们进一步引入了特征适配模块，根据 anchor 的shape 使 feature 适配。</p><p>由于最近的研究表面，使用不同 leve 的 feature maps 有助于目标检测，如 FPN 和 RetinaNet，所以如图 1，我们也使用了多 level 的 anchor 生成机制，需要注意的是，不同 level 的 anchor 生成分支所用的参数是相同的。</p><h2 id="Anchor-位置预测"><a href="#Anchor-位置预测" class="headerlink" title="Anchor 位置预测"></a>Anchor 位置预测</h2><p>anchor 位置预测分支生成的概率 map $p(\cdot|F_I)$ 与 feature map $F_I$ 大小相同，其上每点位置的概率值 $p(i,j|F_I)$ 对应原输入 image $I$ 上位置 $((i+\frac 1 2)s,(j+\frac 1 2)s)$，其中 s 是  $F_I$ 相对于 $I$ 的步幅，即两个相邻 anchor 中心点的距离，$p(i,j|F_I)$ 表示在 $F_I$ 位置 (i,j) 处是某个目标中心的概率。</p><p>使用一个子网络 $\mathcal N_L$ 来预测得到 $p(i,j|F_I)$，$\mathcal N_L$ 组成包括一个 1x1 的卷积和一个 element-wise 的 sigmoid 函数。当然更复杂的 $\mathcal N_L$ 可以使得预测更加准确，但是为了平衡计算效率和准确性，我们仍然采用当前 $\mathcal N_L$ 的组成。</p><p>预定义一个概率阈值 $\epsilon_L$，概率 map 上小于阈值的位置均被过滤掉，也就是说，过滤掉以这些位置为中心的 region（由于当前只考虑了 anchor 中心，尚未考虑 shape，所以此时称 region），这可以过滤掉 90% 的 region 且能同时维持相同的 recall（与普通的 RPN 相比）。如图 4(b)，像天空和大海所在的 region 均被排除，而集中于人和冲浪板。由于不需要考虑那些排除掉的 region，我们将卷积替换为 masked convolution 使推断过程更加高效。</p><h2 id="Anchor-shape-预测"><a href="#Anchor-shape-预测" class="headerlink" title="Anchor shape 预测"></a>Anchor shape 预测</h2><p>确定了 anchor 位置之后，下一步就是确定 anchor 的 shape。如图 1，此预测分支与传统的 bbox 回归预测不同，因为此分支不改变 anchor 的位置，所以不会打破前述 alignment 原则。给定 $F_I$，此分支预测每个位置上的最佳 shape (w,h)，这个最佳 shape 是指 anchor 与最近的 gt box 有最高覆盖度。</p><p>由于 w,h 的范围较大，直接预测这两个值不稳定，故做如下转换将输出值域控制在 [-1,1] 这样一个较小的范围内，</p><script type="math/tex; mode=display">w=\sigma \cdot s \cdot e^{dw}, \quad h = \sigma \cdot s \cdot e^{dh}</script><p>于是 shape 分支预测输出为 (dw,dh)，其中 s 为 $F_I$ 相对于 $I$ 的步幅，$\sigma$ 为经验尺度因子，我们实验中 $\sigma=8$。使用子网络 $\mathcal N_S$ 得到 shape 预测，$\mathcal N_S$ 组成包含一个 1x1 卷积核输出通道为 2 的卷积层，以及一个 element-wise 转换层，前者生成的 2 通道分别对应 dw map 和 dh map，后者实现上式转换得到 w map 和 h map。</p><p>以上 anchor 生成模块的设计与传统的 anchor 生成机制（滑窗）有本质不同，使用我们这里的 anchor 生成机制，每个位置仅一个 anchor，其 shape 动态预测得到，而传统的滑窗根据不同 scale 和 aspect ratio 每个位置生成 k 个 anchor。实验证明，由于我们的 anchor 生成机制中，shape 与 location 有密切关联，所以可以获取更高的 recall，且由于不是预设固定的 aspect ratio 而是动态预测 shape，我们的 anchor 机制可以捕获那些极高或者极宽的目标。</p><h2 id="Anchor-Guided-特征适配"><a href="#Anchor-Guided-特征适配" class="headerlink" title="Anchor-Guided 特征适配"></a>Anchor-Guided 特征适配</h2><p>传统的 RPN 或者 one-stage 检测器采用滑窗机制生成 anchors 均匀分布在 feature map 上，每个位置处 anchor 的 shape/scale 均相同，所以 feature map 能学习到一致的表征。但是在我们的 anchor 机制中，由于 shape 任意可变的，所以不适合像传统方法那样在 feature map 上使用全卷积分类器对 anchor 进行分类（例如 RPN 的二分类或者 one-stage 的前景分类）。最好的做法是，大 anchor 的 feature 应该使用大 region 的内容，小 anchor 的 feature 则使用小范围内容。于是我们进一步提出 anchor-guided 特征适配模块，根据 anchor shape 对 feature 进行转换以使其适配，如下，</p><script type="math/tex; mode=display">\mathbf f_i'= \mathcal N_T(\mathbf f_i, w_i,h_i)</script><p>其中，$\mathbf f_i$ 是 位置 i 处的 feature，$(w_i,h_i)$ 是此处的 anchor shape。由于此特征转换是位置相关的，所以我们采用 3x3 的可变形卷积来实现 $\mathcal N_T$，如图 1，首先根据 anchor shape 分支的输出预测 offset，然后应用可变形卷积到原始 feature map 上，在转换后的 feature map 上，我们可以按传统方法进行分类和 bbox 回归。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="联合目标函数"><a href="#联合目标函数" class="headerlink" title="联合目标函数"></a>联合目标函数</h3><p>本文提出的网络框架使用多任务损失进行端到端优化，除了传统的分类损失和回归损失，还包括 anchor 的位置损失和 shape 损失，目标函数的优化使用如下联合损失：</p><script type="math/tex; mode=display">\mathcal L=\lambda_1 \mathcal L_{loc}+ \lambda_2 \mathcal L_{shape} + \mathcal L_{cls} + \mathcal L_{reg}</script><h3 id="Anchor-location-targets"><a href="#Anchor-location-targets" class="headerlink" title="Anchor location targets"></a>Anchor location targets</h3><p>为了训练 anchor 位置分支，对每个 image 我们需要一个 二值 label map，每个像素点值 1 表示有效位置，0 表示无效位置。这个二值 label map 根据 gt box 得到。我们希望在目标中心的周围附近放置较多的 anchor，而远离目标中心的位置则放置较少的 anchor。首先，将 gt box $(x_g,y_g,w_g,h_g)$ 映射到 feature map $F_I$上得到 $(x_g’,y_g’,w_g’,h_g’)$，然后使用 $\mathcal R(x,y,w,h)$ 表示一个矩形区域。Anchors 将被放置到 gt box 中心的附近以得到较大的 IOU，对每个 gt box 定义如下三种类型的矩形区域：</p><ol><li><p>中心区域 </p><p>$CR=\mathcal R(x_g’,y_g’,\sigma_1 w_g’, \sigma_1 h_g’)$，此区域中心与 gt box 中心重合，宽高分别是 gt box 宽高的 $\sigma_1$ 倍。CR 内像素点值为 1（positive）</p></li><li><p>忽略区域</p><p>$IR=\mathcal R(x_g’,y_g’,\sigma_2 w_g’, \sigma_2 h_g’) \setminus CR$，其中$\sigma_2 &gt; \sigma_1$，IR 内的像素点被标记为 <code>ignore</code>，不参与训练，这一点类似于 Faster R-CNN 中训练 RPN，anchor 与 gt box 的 IOU 大于 0.7 时为标记为 1 positive，小于 0.3 时标记为 0 negative，而位于 <code>[0.3,0.7]</code> 范围则标记为 -1，标记为 -1 的 anchor 不参与训练</p></li><li><p>外围区域</p><p>$OR=F_I \setminus IR$，OR 内的像素点值为 0（negative）</p></li></ol><p>由于我们使用多 level features，每个 level 的 feature map 应该仅瞄准特定 scale 范围的目标，故对某个 feature map 匹配的 scale 范围内的目标，我们设置相应（这些目标）的 CR，对 IR 也是同样处理，如图 2。如果多个目标重叠，那么 CR 抑制 IR， IR 抑制 OR，显然这是合理的，因为 CR, IR, OR 优先级应该逐步下降，才能保证 recall。由于 CR 只占 feature map 中的一小部分，所以我们采用 Focal Loss 平衡正负例来训练 anchor 位置分支。<br><img src="/images/GA-RPN_fig2.png" alt=""></p><h3 id="Anchor-shape-targets"><a href="#Anchor-shape-targets" class="headerlink" title="Anchor shape targets"></a>Anchor shape targets</h3><p>分两步来决定最佳 shape target：</p><ol><li>将 anchor 与某个 gt box 匹配起来</li><li>预测 anchor 的宽高，使其最佳覆盖所匹配的 gt box</li></ol><p>Faster R-CNN 为 anchor 选定一个具有最大 IOU 的 gt box，然后根据 anchor 和 gt box 计算 $(t_x,t_y,t_w,t_h)$ 作为回归 target，这里的 anchor 其 $(x,y,w,h)$ 是已知的预设值。</p><p>但是这种方法不适合我们的 anchor 生成机制，因为 anchor 的 w,h 不再是固定的预设值，而是变化的，也就是说，我们 shape 分支预测得到某位置的 $(w_p,h_p)$ 值，但是我们怎么确定该位置处的回归 target $(t_w,t_h)$ 呢？为了解决此问题，我们定义一个 anchor 变量 $a_{\mathbf {wh}}=\{(x_0,y_0,w,h)|w&gt;0,h&gt;0\}$ 与一个 gt box $gt=(x_g,y_g,w_g,h_g)$ 之间的 IoU （记作 vIoU）为，</p><script type="math/tex; mode=display">\text{vIoU}(a_{\mathbf {wh}},gt)=\max_{w>0,h>0} IoU_{normal}(a_{wh},gt)</script><p>对于任意给定的 anchor 位置 $(x_0,y_0)$ 和 gt box $gt$，上式的解析解是非常复杂的，在一个端到端的网络中很难去实现这个计算，因此使用一个替代方法得到近似解。给定位置 $(x_0,y_0)$，我们取一些 w 和 h 的常见值来模拟所有 w 和 h 的枚举，然后计算所取（这些常见 w 和 h）的 anchor 与某个 gt box 的 IoU，其中最大 IoU 作为 $\text{vIoU}(a_{\mathbf {wh}}, gt)$ 的近似。在我们的实验中，我们选取了 9 组 (w,h) 来估算 vIoU。这 9 组 (w,h) 使用 RetinaNet 中的 scales 和 aspect ratios 生成。理论而言，使用越多的 (w,h) 那么 vIoU 的近似越准确，当然计算量也跟着增加。我们采用 bounded iou loss 的变体来优化 shape 预测分支，这个损失如下：</p><script type="math/tex; mode=display">\mathcal L_{shape}=\mathcal L_1(1-\min(\frac w {w_g}, \frac {w_g} w)) + \mathcal L_1 (1-\min(\frac h {h_g}, \frac {h_g} h))</script><p>其中 (w,h) 是预测 anchor shape，(w<sub>g</sub>,h<sub>g</sub>) 是与 anchor 有着最大 vIoU 的那个 gt box 的 shape。从上式损失函数中可见，我们希望 $\min(\frac w {w_g}, \frac {w_g} w)$ 和 $\min(\frac h {h_g}, \frac {h_g} h)$ 越大越好，也就是说，w 越接近 w<sub>g</sub>，h 越接近 h<sub>g</sub>，就越好。</p><p>总结一下以上过程：</p><ol><li>选择 9 组 (w,h)</li><li>给定位置 (x<sub>0</sub>,y<sub>0</sub>)，计算 anchor 与所有 gt box 的 vIoU，每个 vIoU 的计算均使用 9 组 (w,h)</li><li>最大 vIoU 的那个 gt box 与此位置 anchor 相匹配</li><li>shape 预测分支在此位置预测的 (w,h) 与此位置 anchor 匹配的 gt box 的 (w<sub>g</sub>,h<sub>g</sub>) 一起计算得到此处的 shape 损失</li></ol><p>那么，为何不直接用 shape 分支预测的 (w,h) 与所有 gt box 计算 IoU，然后选择最大 IoU 的那个 gt box 作为该位置 anchor 所匹配的 gt box 呢？</p><p>当然不行，由于 shape 分支预测的 (w,h) 在每次训练迭代过程中均会变化，如果使用上述方法求匹配的 gt box，那么该位置 anchor 所匹配的 gt box 在每次迭代时都有可能不一样，如果 anchor 训练回归的 target 都一直会变化，那就没法训练了。</p><h2 id="使用高质量-proposals"><a href="#使用高质量-proposals" class="headerlink" title="使用高质量 proposals"></a>使用高质量 proposals</h2><p>得到 guided anchoring 加强的 RPN（GA-RPN）可以生成更高质量的 proposals。通过使用这些高质量的 proposals，我们探索了如何提高传统的 two-stage 目标检测器的性能。首先，研究了 RPN 和 GA-RPN 生成的 proposals 的 IoU 分布，如图 3，<br><img src="/images/GA-RPN_fig3.png" alt=""> <center>Fig 3 不同 IoU 下的 proposals 数量</center></p><p>比起 RPN，GA-RPN 有如下两个明显优点：</p><ol><li>正例 proposals 数量更多</li><li>高 IoU 处两者的 proposals 数量比例更明显</li></ol><p>在现有模型下将 RPN 直接替换为 GA-RPN 然后端到端训练（从头开始训练），然而，如果采用相同的训练设置，性能指标提升会非常有限（不到 1 一个点）。通过我们的观察发现使用高质量 proposals 的前提条件是训练样本的分布需要与 proposal 分布一致。因此，设置一个更高的正负例阈值，从而使用更少的样本去训练。</p><p>除了端到端训练，GA-RPN 还可以通过微调提升一个训练好的 two-stage 检测器的性能。具体而言，给定一个训练好的模型，我们舍弃其中的 proposal 生成模块，例如舍弃 RPN，然后使用预先计算好的 GA-RPN proposals 来微调这个模型，仅需要几个 epochs（默认是 3 个 epochs）即可。GA-RPN proposals 还可以用于 inference。这种简单的微调机制因为只需要少数 epochs，所以可以大大提高性能。</p><p><img src="/images/GA-RPN_fig4.png" alt=""></p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验参数、实现细节以及结果分析这里不展开讨论，直接阅读原文。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>提出了 Guided Anchoring 机制，利用语义特征生成位置非均匀且 shape 任意的 anchor。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CV 中的常用方法总结</title>
      <link href="/2019/06/24/cv/cv-mtds/"/>
      <url>/2019/06/24/cv/cv-mtds/</url>
      
        <content type="html"><![CDATA[<p>总结 CV 中的一些概念和操作（并不局限于 CV）。<br><span id="more"></span></p><h1 id="RF"><a href="#RF" class="headerlink" title="RF"></a>RF</h1><p>第 k layer 上的感受野大小为</p><script type="math/tex; mode=display">l_k=l_{k-1}+[(f_k-1)\prod_{i=0}^{k-1}s_i]</script><p>其中，$s_i$ 为第 i layer 上卷积的步幅，$f_k$ 为第 k layer 上卷积核大小，$l_0=1, \ s_0=1$。</p><h1 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h1><p>以 Faster R-CNN 为例，Test 阶段时，ProposalLayer 生成密集均匀分布的 anchors，RPN 得到所有 anchors 的得分（置信度）以及偏差回归值，根据偏差值对 anchors 进行坐标转换得到 proposals，proposals 的得分就是对应 anchors 的得分，然后经过如下处理：</p><ol><li>proposal 的坐标不能超过输入 image 的范围 [0,w-1], [0,h-1]，故需要对超过范围的 proposal 进行 clip 以使得 proposal 坐标位于范围内</li><li>过滤极小尺度的 proposal，proposal 对应在原始 image 上的 box 尺度必须大于 16（配置值）</li><li>按 proposals 得分倒排，保留 top N1 的 proposals（N1 为配置值）</li><li>非极大抑制 NMS</li><li>按 proposals 得分倒排，保留 top N2 的 proposals（N2 为配置值）</li></ol><p>NMS 过程如下：</p><ol><li>对于所有的 proposals 列表 P，计算其面积列表 A，根据 proposals 的得分倒排得到其列表下标 I。最终要保留的 proposals 的列表下标将被保存到 K 中</li><li>找到当前得分最高的 proposal，其列表下标为 I[0]，将其添加到最终需要保留的 K 中，<code>K.append(I[0])</code>。计算当前 I 中与此最高得分的 proposal 的 IOUs，从 I 列表中移除 IOU 大于阈值（配置值）的那些 proposals 的下标值（注意，包括 I[0] 处的 proposal 也被移除，因为 I[0] 已经添加到 K 中）</li><li>重复过程 2，直到当前 I 为空 </li><li>K 中保存了 NMS 之后的 proposals 的列表下标值</li></ol><h1 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h1><p>NMS会过滤到两个靠的很近的 boxes 中得分较低的那个 box，但是有时候确实是存在两个靠的很近的 gt boxes，强行过滤到得分较低的 box 会导致 recall 较低，所以此时可改用 soft-NMS，源于论文 <a href="https://arxiv.org/pdf/1704.04503.pdf">Improving Object Detection With One Line of Code</a></p><p>Soft-NMS 与 NMS 的最主要区别是 NMS 将近邻低得分 box 重置其得分为 0，而 Soft-NMS 则是根据一个函数降低其得分，使得近邻 box 的置信度更低，但仍然在检测 rank list 中。算法如下：</p><p><strong>Input</strong></p><ul><li>$\mathcal B=\{b_1,…,b_N\}, \mathcal S = \{s_1,…,S_N\}, N_t, m$</li><li>分别表示初始检测 boxes，相应的 scores，NMS 阈值（0.7）， $m=1 \rightarrow \text{NMS}; \ m=2\rightarrow \text{Soft-NMS}$</li></ul><p>$\mathcal D \leftarrow \{\}$</p><p><strong>while</strong> $\mathcal B \ne \varnothing$ <strong>do</strong></p><p>&emsp; &emsp; $m \leftarrow \arg \max \mathcal S$</p><p>&emsp; &emsp; $\mathcal M \leftarrow b_m$</p><p>&emsp; &emsp; $\mathcal D \leftarrow \mathcal {D \cup M}; \mathcal B \leftarrow \mathcal{B-M}$</p><p>&emsp; &emsp; <strong>for</strong> $b_i \in \mathcal B$ <strong>do</strong></p><p>&emsp; &emsp; &emsp; &emsp; <strong>if</strong> $iou(\mathcal M, b_i) &gt; N_t$ <strong>then</strong></p><p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>if</strong> $m=1$ <strong>then</strong></p><p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $\mathcal {B \leftarrow B} - b_i; \mathcal {S \leftarrow S} - s_i$</p><p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>else if</strong> $m=2$</p><p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $s_i \leftarrow s_i f[iou(\mathcal M, b_i)]$</p><p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>end</strong></p><p>&emsp; &emsp; &emsp; &emsp; <strong>end</strong></p><p>&emsp; &emsp; <strong>end</strong></p><p><strong>end</strong></p><p><strong>return</strong> $\mathcal {D,S}$</p><p>现在来看 Soft-NMS 中的得分衰减因子 f 函数，首先无论 NMS 还是 Soft-NMS，我们都可以统一可将 box 的得分修改为 $s_i=s_i f(i)$，其中 f 函数为，</p><ol><li><p>NMS</p><script type="math/tex; mode=display">f(i) = \begin{cases} 1 & iou(\mathcal M, b_i) < N_t \\ 0 & iou(\mathcal M, b_i) \ge N_t\end{cases}</script></li><li><p>Soft-NMS</p><script type="math/tex; mode=display">f(i) = \begin{cases} 1 & iou(\mathcal M, b_i) < N_t \\ 1-iou(\mathcal M, b_i) & iou(\mathcal M, b_i) \ge N_t \end{cases}</script><p>可见，靠的越近 iou 越大，得分衰减的越厉害。但是这个式子中函数值在 iou=N<sub>t</sub> 处附近不连续，可使用高斯惩罚函数，</p><script type="math/tex; mode=display">f(i)=e^{-\frac {iou(\mathcal M, b_i)^2} \sigma}, \ \forall b_i \notin \mathcal D</script><p>在 iou=0 时取得最大值，参数 $\sigma$ 控制衰减速度，$\sigma$ 越小表示得分随 iou 增大而衰减越快。</p></li></ol><h1 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h1><p>在很多 CV 任务例如 semantic segmentation 中，需要上采样，简单的上采样可以使用 bilinear interpolation，但有时为了得到更好的上采样结果会使用反卷积。<br>(to be continued…)</p>]]></content>
      
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TridentNet</title>
      <link href="/2019/06/21/obj_det/TridentNet/"/>
      <url>/2019/06/21/obj_det/TridentNet/</url>
      
        <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1901.01892">Scale-Aware Trident Networks for Object Detection</a><br><span id="more"></span><br>代码：<a href="https://github.com/TuSimple/simpledet">TuSimple/simpledet</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>目标检测通常分为：</p><ol><li>one stage，如 YOLO, SSD</li><li>two stage，如 Faster R-CNN, R-FCN</li></ol><p>这些方法在目标尺度变化范围较大时，均存在问题，尤其在目标尺度很小或很大时，性能较差。为了解决目标尺寸多变性的问题，有如下方法：</p><ol><li>生成多尺度 image pyramids 作为网络输入，如图 1(a)，缺点是计算量大，耗时</li><li>利用网络中的不同分辨率的 feature maps，不同分辨率的 feature maps 负责检测不同尺度的目标，如 SSD</li><li>2 方法中 low level 的 feature 注重于局部细节，而 high level 的 feature 因为感受野 RF 更大，则注重于整体（语义）为了补偿 low level 的 feature 所缺失的语义，FPN 在原有 bottom-up 的基础上增加 top-down pathway 和 径向连接，如图 1(b)。但是由于不同分辨率 features 来自网络不同的 layers，所以对不同尺度的目标的表征能力差异较大，所以 feature pyramids 不能认为是 image pyramids 的替代。</li></ol><p><img src="/images/TridentNet_fig1(a" alt="">.png) <center> fig1(a)</center><br><img src="/images/TridentNet_fig1(b" alt="">.png) <center> fig1(b)</center><br><img src="/images/TridentNet_fig1(c" alt="fig1(c)">.png) <center> fig1(c)</center></p><p>本文提出的新网络结构能适应不同的目标尺度，如图 1(c)，使用 trident 块生成多个尺度相关的 feature maps。trident 块的各个分支结构相同，且共享权重参数，但是由于使用了空洞卷积（膨胀系数不同），所以具有不同的 RF，每个分支负责处理一定尺度范围的目标。由于参数共享，所以 inference 阶段，可以使用一个主分支来近似 TridentNet 。</p><h1 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h1><p>backbone 中的影响最终目标检测的几个设计因素为：下采样率、网络深度和感受野。更深的网络和更低的下采样率会增加网络的复杂度，但往往也有益于检测。为了研究 RF 在检测中的作用，可以将 backbone 的一些卷积层的卷积改为空洞卷积。</p><p>假设膨胀率为 $d_s$，那么一个膨胀后的 3x3 卷积的 RF 与 kernel size 为 $3+2(d_s-1)$ 卷积核的 RF 相当。记当前 feature map 相对于输入 image 的下采样率为 s，那么此时膨胀率为 $d_s$ 的卷积相较于普通卷积，其 RF 将增加 $2(d_s-1)s$，因此，如果将 n 个卷积改为空洞卷积，那么 RF 将增加 $2(d_s-1)sn$，其中，这 n 个卷积所作用的 feature map 相对于输入 image 的下采样率均为 s。</p><p>实验基于 COCO benchmark 使用 Faster R-CNN，backbone 分别使用 ResNet-50 和 ResNet-101，在 _conv4_ stage 的 residual block 上 3x3 卷积层使用空洞卷积，膨胀率在 1-3 之间。测试结果指标 AP 分别基于： a. 所有目标；b. 小目标；c. 中等目标；d. 大目标，结果如表 1，</p><div class="table-container"><table><thead><tr><th>Backbone</th><th>Dilation</th><th style="text-align:center">AP</th><th style="text-align:center">AP<sub>s</sub></th><th style="text-align:center">AP<sub>m</sub></th><th style="text-align:center">AP<sub>l</sub></th></tr></thead><tbody><tr><td>ResNet-50</td><td>1</td><td style="text-align:center">0.332</td><td style="text-align:center"><strong>0.174</strong></td><td style="text-align:center">0.384</td><td style="text-align:center">0.464</td></tr><tr><td>ResNet-50</td><td>2</td><td style="text-align:center">0.342</td><td style="text-align:center">0.168</td><td style="text-align:center"><strong>0.386</strong></td><td style="text-align:center">0.486</td></tr><tr><td>ResNet-50</td><td>3</td><td style="text-align:center">0.341</td><td style="text-align:center">0.162</td><td style="text-align:center">0.383</td><td style="text-align:center"><strong>0.492</strong></td></tr><tr><td>ResNet-101</td><td>1</td><td style="text-align:center">0.372</td><td style="text-align:center"><strong>0.200</strong></td><td style="text-align:center"><strong>0.430</strong></td><td style="text-align:center">0.528</td></tr><tr><td>ResNet-101</td><td>2</td><td style="text-align:center">0.380</td><td style="text-align:center">0.191</td><td style="text-align:center">0.427</td><td style="text-align:center"><strong>0.538</strong></td></tr><tr><td>ResNet-101</td><td>3</td><td style="text-align:center">0.371</td><td style="text-align:center">0.181</td><td style="text-align:center">0.410</td><td style="text-align:center"><strong>0.538</strong></td></tr></tbody></table></div><font size=2> Table 1 COCO 数据集上具有不同 RF 的 Faster R-CNN 的检测结果</font><p>从表中可见，当 RF 增加时，ResNet-50 和 ResNet-101 上的小目标的检测性能持续下降，而大目标的检测性能则越来越好。不难发现：</p><ol><li>网络的 RF 能影响不同尺度的目标上的检测性能。一个合适的 RF 是与目标尺度强相关的</li><li>尽管 ResNet-101 拥有足够大的理论 RF 以覆盖大尺度（大于 96x96）的目标，但是当增大膨胀率，仍能提高大目标上的性能。这说明实际上有效 RF 比理论 RF 要小</li></ol><h1 id="Trident-网络"><a href="#Trident-网络" class="headerlink" title="Trident 网络"></a>Trident 网络</h1><p>TridentNet 包括共享权重参数的 trident 块，以及一个精心设计的与 scale-aware 训练机制。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>如图 2，<br><img src="/images/TridentNet_fig2.png" alt=""></p><p>网络输入为一个单尺度的 image，然后通过并行的分支生成不同尺度的 feature maps，这些并行分支共享权重参数，但是其卷积层的空洞卷积具有不同的膨胀率。</p><p><strong>多分支块</strong> 在目标检测器的 backbone 中，使用 trident 块代替普通卷积。trident 块包含多个并行的分支，这些分支结构与原先普通卷积相同，只是膨胀率不同（普通卷积可以看作是膨胀率为 1 的空洞卷积）。</p><p>以 ResNet 为例作为 backbone，bottleneck 风格（ResNet-50, ResNet=101 等）的 residual 块包含三个卷积：1x1，3x3，1x1。trident 块则基于 residual 块构建，即，将单个 residual 块改为并行的多个 residual 块，其中每个块中 3x3 的空洞卷积的膨胀率不同。通过堆叠多个 trident 块我们可以有效的调整不同分支上的感受野 RF。通常将 backbone 中最后一个 stage 中的 residual 块替换为 trident 块，这是因为靠后的 stage 其 stride 较大，所以并行分支中的 RF 差距较大。</p><p><strong>分支间共享权重</strong> 多分支的一个显著问题是参数数量成倍增加，可能会导致过拟合，故分支间除了空洞卷积的膨胀不同，结构和参数均相同，包括每个分支的 RPN 和 Fast R-CNN head（分类预测和回归预测）。<br>参数共享优点有三：</p><ol><li>降低参数数量。相比于常规目标检测器，TridentNet 不需要额外的参数</li><li>对不同尺度的目标，输入均通过统一的转换得到 feature maps，具有相同的表征能力。（这是与 feature pyramid 的区别）</li><li>因为是多分支，相当于增加了训练参数的样本。换句话说，在不同的 RF 下，训练同样的参数以应对不同的尺度范围。</li></ol><h2 id="scale-aware-训练机制"><a href="#scale-aware-训练机制" class="headerlink" title="scale-aware 训练机制"></a>scale-aware 训练机制</h2><p>根据预先定义好的膨胀率，trident 框架将生成尺度相关的 feature maps。但是尺度不匹配可能会导致性能降级，例如表 1 中具有大膨胀率的分支检测小目标。因此，很自然地做法就是不同分支负责检测不同尺度的目标。我们提出了 scale-aware 训练机制，加强各分支对尺度认识，从而避免在不匹配的分支上训练具有极端尺度的目标（极大 or 极小）。</p><p>每个分支定义一个有效范围 $[l_i,u_i]$。训练时，某个分支上训练所使用的 proposal 和 gt box 其尺度应该落入此分支的有效范围。具体而言，某个 ROI 大小为 <code>(w,h)</code>，如果 $l_i \le \sqrt{wh} \le u_i$，那么这个 ROI 适合在分支 i 上训练。</p><p>scale-aware 训练机制可以应用于 RPN 和 Fast R-CNN 上。原先 RPN 用于判断 anchors 目标/非目标 的二值分类，以及 box 回归。在 scale-aware 训练机制下，根据 gt box 尺度决定其用在哪个分支上，然后判断这个分支上的 anchor 是否是目标或非目标。训练 Fast R-CNN head 时，每个分支根据其有效范围筛选出有效的 proposal。</p><h2 id="Inference-和近似"><a href="#Inference-和近似" class="headerlink" title="Inference 和近似"></a>Inference 和近似</h2><p>Inference 阶段，所有分支均生成检测结果，然后根据分支的有效范围筛选出有效的检测结果。然后使用 NMS 或 soft-NMS 合并多个分支的检测结果。</p><p><strong>快速推断近似</strong> 为了进一步提高速度，在 inference 阶段我们可以仅使用一个主分支来近似 TridentNet。具体来说，设置主分支的有效范围为 [0,&infin;] 以预测所有尺度的目标。例如图 2 中的三分支网络，我们使用中间分支作为主分支，因为中间分支的有效范围覆盖了大目标和小目标。使用主分支近似 TridentNet 时，没有额外的计算和参数，故与原先的 Faster R-CNN 检测时间相当，与 TridentNet 相比，性能下降较小。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验采用 COCO 数据集，模型训练使用 80k 训练图片和 35k 的验证图片子集（_trainval35k_），模型评估使用 5k 验证图片子集（_minival_）。</p><h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p>使用 Faster R-CNN 的 MXNet 版本作为 baseline。网络 backbone 使用 ImageNet 进行预训练，然后迁移网络到检测数据集上微调。resize 输入 image，使得短边为 800 像素。Baseline 和 TridentNet 均进行 end-to-end 训练。我们在 8 块 GPU 上训练，batch size 为16。总共训练了 12 epochs，学习率初始值为 0.02，在第 8 个 和 第 10 个 epoch 之后分别下降 10%。使用 ResNet 的 conv4 stage 的输出作为 backbone 的 feature maps，而 conv5 stage 作为 baseline 和 TridentNet 的 rcnn head。对 TridentNet 的每个分支， 从每个 image 中采样 128 个 ROIs。若无特别说明，我们使用三分支结构作为默认 TridentNet 结构，膨胀率分别为 1，2，3.采用 scale-aware 训练机制时，设置三个分支的有效范围为 [0,90]，[30,160]，[90,&infin;]。</p><p>性能评估时采用 COCO 标准评估指标 AP，和 $AP_{50}/AP_{75}$，以及 $AP_s, AP_m, AP_l$，目标尺度范围分别为 小于 32x32, 32x32 ~ 96x96, 大于 96x96。</p><h2 id="消融学习"><a href="#消融学习" class="headerlink" title="消融学习"></a>消融学习</h2><p><strong>TridentNet 组件</strong> Baseline (Table 2(a)) 的评估结果分别使用 ResNet-101 和 ResNet-101-Deformable 作为 backbone。然后我们逐步在 Baseline 上应用 多分支、权重共享和 scale-aware 训练机制。<br><img src="/images/TridentNet_fig3.png" alt=""></p><ol><li><strong>Multi-branch</strong><br>如 Table 2(b)，多分支版本比 baseline 的性能有所提升，尤其在大目标检测上，这种提升更加明显。这说明即使只应用最简单的多分支结构，也能受益于不同的 RF。</li><li><strong>Scale-aware</strong><br>Table 2(d) 显示了在 Table 2(b) 多分支版本上增加 scale-aware 训练机制后的结果。在小目标检测上性能有所提升，但是在大目标检测上 $AP_s$ 值掉了。我们猜测，scale-sware 训练机制虽然能阻止分支去训练极端尺寸的目标，但也可能引入过拟合问题，因为每个分支上训练的有效样本数量减少。</li><li><strong>Weight-sharing</strong><br>Table 2(c) 为在 多分支版本 Table 2(b) 基础上增加权重共享这一设计，Table 2(e) TridentNet 为在 Baseline 上应用以上三个设计。这两个网络的性能均得到提升，这证实权重共享是有效的。由于分支共享权重参数，所以参数的训练利用了所有尺度的目标，从而降低了 scale-aware 训练中的过拟合问题。</li></ol><p><strong>分支数量</strong> Table 3 显示了使用 1-4 个分支时的评估结果。这里没有增加 scale-aware 训练，这是为了避免精心地调整不同分支的有效范围。Table 3 说明 TridentNet 比单分支结构（baseline）方法的评估指标高。可以注意到，四分支结构比三分支结构没有带来提升效果，所以我们选择三分支结构作为默认 TridentNet。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Branches</th><th style="text-align:center">AP</th><th style="text-align:center">AP<sub>50</sub></th><th style="text-align:center">AP<sub>s</sub></th><th style="text-align:center">AP<sub>m</sub></th><th style="text-align:center">AP<sub>l</sub></th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">33.2</td><td style="text-align:center">53.8</td><td style="text-align:center">17.4</td><td style="text-align:center">38.4</td><td style="text-align:center">46.4</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">35.9</td><td style="text-align:center">56.7</td><td style="text-align:center"><strong>19.0</strong></td><td style="text-align:center">40.6</td><td style="text-align:center">51.2</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center"><strong>36.6</strong></td><td style="text-align:center"><strong>57.3</strong></td><td style="text-align:center">18.3</td><td style="text-align:center"><strong>41.4</strong></td><td style="text-align:center"><strong>52.3</strong></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">36.5</td><td style="text-align:center"><strong>57.3</strong></td><td style="text-align:center">18.8</td><td style="text-align:center"><strong>41.4</strong></td><td style="text-align:center">51.9</td></tr></tbody></table></div><font size=2> Table 3 COCO _minival_ 目标检测结果。ResNet-50，使用不同分支数量</font><p>其他的消融学习，如在哪个 conv stage 上使用 trident 块，和 trident 块的数量等等，以及 TridentNet 与其他 SOTA 目标检测器的结果对比，可参考原文的实验结果及说明。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>提出了 TridentNet 网络，可以生成具有相同表征能力的 scale 相关的 feature maps。提出 scale-aware 训练机制，使得不同的分支善于处理不同尺度范围的目标。快速 inference 方法使用一个主分支来近似 TridentNet，提高了检测效果（相比于 baseline），并且不引入额外的参数和计算量。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch-3</title>
      <link href="/2019/06/18/pytorch/PyTorch-3/"/>
      <url>/2019/06/18/pytorch/PyTorch-3/</url>
      
        <content type="html"><![CDATA[<p>在 <a href="PyTorch-2">PyTorch-2</a> 我们已经了解了 torch 包的初始化过程，接下来便可以愉快查看这个 package 包含哪些字段（包含函数和类）了，再参照 PyTorch 的<a href="https://pytorch.org/docs/stable/torch.html">官方文档</a>，了解其中各个函数的具体实现。<br><span id="more"></span></p><h1 id="torch-包"><a href="#torch-包" class="headerlink" title="torch 包"></a>torch 包</h1><p>从 <code>torch/__init__.py</code> 中可以查看所有的 torch 包的所有字段，包括：</p><ol><li>直接在此文件中定义的函数/字段，如 typename, is_tensor, is_storage, _storage_classes 等</li><li>从 torch 包的模块中导入的函数/类，如<pre class="line-numbers language-none"><code class="language-none">from .random import set_rng_state, get_rng_state, manual_seed, initial_seed...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>从 torch._C 中导入的字段/函数/类</li><li>从 torch._C._VariableFunctions 导入的字段/函数</li></ol><p>PyTorch 官方文档中 torch 包有很多函数。这里举几个例子进行说明。</p><h2 id="torch-empty"><a href="#torch-empty" class="headerlink" title="torch.empty"></a>torch.empty</h2><p>这个函数实际上来自于 torch._C._VariableFunctions 这个类。文件 torch/csrc/Module.cpp 中调用函数 THPVariable_initModule，跳转到 torch/csrc/autograd/python_variable.cpp 查看函数定义，其定义体中调用 torch::autograd::initTorchFunctions，而这个函数定义位于 torch/csrc/autograd/generated/python_torch_functions.cpp，这个文件是安装 PyTorch 过程中生成的，按以下步骤查看这个文件的生成过程：</p><ol><li>caffe2/CMakeLists.txt 中的文件生成语句为<pre class="line-numbers language-none"><code class="language-none">set(GENERATED_CXX_PYTHON  ...  &quot;$&#123;TORCH_SRC_DIR&#125;&#x2F;csrc&#x2F;autograd&#x2F;generated&#x2F;python_torch_functions.cpp&quot;  ...)...add_custom_command(    OUTPUT    $&#123;TORCH_GENERATED_CODE&#125;    COMMAND    &quot;$&#123;PYTHON_EXECUTABLE&#125;&quot; tools&#x2F;setup_helpers&#x2F;generate_code.py     ...    DEPENDS    ...)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>执行 tools/setup_helpers/generate_code.py。在函数 generate_code 中调用了以下四个函数生成文件，<pre class="line-numbers language-none"><code class="language-none">generate_nn_wrappersgen_autograd_pythongen_autogradgen_jit_dispatch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>这四个函数的实现都是非常繁琐的，这里以生成 torch/csrc/autograd/generated/python_torch_functions.cpp 为例，实际上是将模板文件 tools/autograd/templates/python_torch_functions.cpp 中的 ${py_methods} 和 ${py_method_defs} 分别替换为对应的方法实现和方法签名，这些方法来自于 torch/share/ATen/Declarations.yaml, tools/autograd/deprecated.yaml, tools/autograd/derivatives.yaml，其中第一个文件又需要动态生成，过程为：</li><li>在 caffe2/CMakeLists.txt 中有语句<pre class="line-numbers language-none"><code class="language-none">include(..&#x2F;cmake&#x2F;Codegen.cmake)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>在文件 cmake/Codegen.cmake 中调用 <code>gen.py</code><pre class="line-numbers language-none"><code class="language-none">SET(GEN_COMMAND    &quot;$&#123;PYTHON_EXECUTABLE&#125;&quot; $&#123;CMAKE_CURRENT_LIST_DIR&#125;&#x2F;..&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;gen.py    --source-path $&#123;CMAKE_CURRENT_LIST_DIR&#125;&#x2F;..&#x2F;aten&#x2F;src&#x2F;ATen    --install_dir $&#123;CMAKE_BINARY_DIR&#125;&#x2F;aten&#x2F;src&#x2F;ATen    $&#123;GEN_ROCM_FLAG&#125;    $&#123;cwrap_files&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>（在 aten/src/ATen/native/native_functions.yaml 找到 <code>empty</code> 的函数签名）</li><li>aten/src/ATen/gen.py 中的 generate_outputs 函数生成 Declarations.yaml 文件<pre class="line-numbers language-none"><code class="language-none">file_manager.write(&quot;Declarations.yaml&quot;, format_yaml(output_declarations))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>根据第 2 点，install_dir 为 build/aten/src/ATen，所以 Declarations.yaml 生成路径此时为 build/aten/src/ATen，根据以下步骤安装此文件<ul><li>CMakeLists.txt 中的 add_subdirectory(caffe2)</li><li>caffe2/CMakeLists.txt 中的 add_subdirectory(../aten aten)</li><li>aten/CMakeLists.txt 中的 add_subdirectory(src/ATen)</li><li>aten/src/ATen/CMakeLists.txt 中有，<pre class="line-numbers language-none"><code class="language-none">INSTALL(FILES $&#123;CMAKE_BINARY_DIR&#125;&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;Declarations.yaml  DESTINATION $&#123;AT_INSTALL_SHARE_DIR&#125;&#x2F;ATen)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>事实上，除了这里的 Declarations.yaml，在 aten/src/ATen/CMakeLists.txt 中还安装了很多头文件，其中就包括下文将提到的 build/aten/src/ATen/Functions.h，具体参见 aten/src/ATen/CMakeLists.txt 中其他 INSTALL 指令调用。</li></ul></li></ol><p>找到这些函数来源后，通过 tools/autograd/gen_python_functions.py 中的函数 create_python_bindings 生成 ${py_methods} 和 ${py_method_defs} 的内容，<br><pre class="line-numbers language-none"><code class="language-none">PY_VARIABLE_METHOD_VARARGS &#x3D; CodeTemplate(&quot;&quot;&quot;\static PyObject * $&#123;pycname&#125;(PyObject* self_, PyObject* args, PyObject* kwargs)&#123;    HANDLE_TH_ERRORS    static PythonArgsParser parser(&#123;        $&#123;signatures&#125;    &#125;, &#x2F;*traceable&#x3D;*&#x2F;$&#123;traceable&#125;);    $&#123;unpack_self&#125;    ParserArgs&lt;$&#123;max_args&#125;&gt; parsed_args;    auto r &#x3D; parser.parse(args, kwargs, parsed_args);    $&#123;declare_namedtuple_return_types&#125;    $&#123;dispatch&#125;    Py_RETURN_NONE;    END_HANDLE_TH_ERRORS&#125;&quot;&quot;&quot;)...def create_python_bindings(python_functions, has_self, is_module&#x3D;False):    def process_function(name, declarations):        ...        env &#x3D; &#123;            &#39;name&#39;: name,            &#39;dispatch_name&#39;: &#39;dispatch_&#123;&#125;&#39;.format(name),            &#39;pycname&#39;: &#39;THPVariable_&#123;&#125;&#39;.format(name),            &#39;signature&#39;: [],            &#39;max_args&#39;: max(len(o[&#39;arguments&#39;])+len(o[&#39;python_binding_arguments&#39;]) for o in declarations),            &#39;unpack_self&#39;: [],            &#39;dispatch&#39;: [],            &#39;declare_namedtuple_return_types&#39;: &#39;&#39;,        &#125;        ... &#x2F;&#x2F; 向 env 增加 key-value pair or 更新 env 中已有 key 的 value        if len(declarations) &#x3D;&#x3D; 1 and len(declarations[0][&#39;args&#39;]) &#x3D;&#x3D; 1 and has_self:            ...        else:            tmpl &#x3D; PY_VARIABLE_METHOD_VARARGS            env[&#39;flags&#39;] &#x3D; &#39;METH_VARARGS | METH_KEYWORDS&#39;        if not is_module and not has_self:            env[&#39;flags&#39;] +&#x3D; &#39; | METH_STATIC&#39;                py_methods.append(tmpl.substitute(env))        py_methods_defs.append(PY_VARIABLE_METHOD_DEF.substitute(env))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>通过以上代码片段可知，对于函数定义的生成，使用一个函数定义模板 PY_VARIABLE_METHOD_VARARGS，然后对每个函数，来自于 Declarations.yaml, deprecated.yaml, derivatives.yaml，抽取有关字段的值存储到 env 字典中，然后将 PY_VARIABLE_METHOD_VARARGS 中的占位符使用 env 中相应 key 的值替换，就得到这个函数的定义。</p><h2 id="empty-定义"><a href="#empty-定义" class="headerlink" title="empty 定义"></a>empty 定义</h2><p>我们看生成后的 empty 函数定义（位于文件 torch/csrc/autograd/generated/python_torch_function.cpp）<br><pre class="line-numbers language-none"><code class="language-none">static PyObject * THPVariable_empty(PyObject* self_, PyObject* args, PyObject* kwargs)&#123;    HANDLE_TH_ERRORS    static PythonArgParser parser(&#123;        &quot;empty(IntList size, *, Tensor out&#x3D;None, ScalarType dtype&#x3D;None, Layout layout&#x3D;torch.strided, Device device&#x3D;None, bool requires_grad&#x3D;False)&quot;,    &#125;, &#x2F;*tracebalbe*&#x2F;true); &#x2F;&#x2F; 大括号初始化器，得到函数签名的vector    ParseArgs&lt;6&gt; parsed_args;    auto r &#x3D; parser.parse(args, kwargs, parseed_args);    if (r.idx &#x3D;&#x3D; 0) &#123;       &#x2F;&#x2F; 函数签名在vector中的下标        if (r.isNone(1)) &#123;  &#x2F;&#x2F; parameter &#39;out&#39; is None            auto size &#x3D; r.intlist(0);            auto dtype &#x3D; r.scalartype(2);            auto device &#x3D; r.device(4);            const auto options &#x3D; TensorOptions()                .dtype(dtype)                .device(device)                .layout(r.layout(3).layout)                .requires_grad(r.toBool(5));            return wrap(dispatch_empty(size, options));        &#125; else &#123;            check_out_type_matches(r.tensor(1), r.scalartype(2), r.isNone(2),                                   r.layout(3), r.isNone(3),                                   r.device(4), r.isNone(4));            return wrap(dispatch_empty(r.intlist(0), r.tensor(1)).set_requires_grad(r.toBool(5)));        &#125;    &#125;    Py_RETURN_NONE;    END_HANDLE_TH_ERRORS&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>从以上代码中可见，要创建一个 empty 的 Tensor，首先检查调用者是否提供了一个 Tensor，如未提供，则先创建一个 Tensor：</p><ol><li><code>out</code> 参数为None，则需要根据参数 dtype, device, layout 和 requires_grad 创建 Tensor</li><li><code>out</code> 参数不为None, 则检查 <code>out</code> 这个 Tensor 与参数 dtype, layout, device 是否匹配，如果匹配，还需要将 <code>out</code> 的 requires_grad 属性重置为参数 requires_grad</li></ol><p>然后调用函数 dispatch_empty，这个函数总共有两个重载版本，位于 torch/csrc/autograd/generated/python_torch_functions_dispatch.h，这个文件与同目录下的 python_torch_function.cpp 一样也是动态生成的，生成逻辑也是一样的，将 tools/autograd/templates/python_torch_functions_dispatch.h 中的占位符替换掉，不再具体展开，可参见 tools/autograd/gen_python_functions.py 中的函数 gen_py_torch_functions。dispatch_empty 的两个重载版本为，<br><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; empty 函数调用者提供了 Tensor &#39;out&#39;inline Tensor dispatch_empty(IntList size, Tensor result) &#123;    AutoNoGIL no_gil;    return at::empty_out(result, size);&#125;&#x2F;&#x2F; empty 函数调用者未提供 Tensor &#39;out&#39;，需要根据参数 options 创建inline Tensor dispatch_empty(IntList size, const TensorOptions &amp; options) &#123;    maybe_initialize_cuda(options);    AutoNoGIL no_gil;    return torch::empty(size, options);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h3 id="有输出-Tensor"><a href="#有输出-Tensor" class="headerlink" title="有输出 Tensor"></a>有输出 Tensor</h3><p>我们看第一个重置版本的定义体，即，调用者提供了输出 Tensor，首先构造一个结构实例 AutoNoGIL，这个结构的构造函数为<br><pre class="line-numbers language-none"><code class="language-none">AutoNoGIL() : save(PyEval_SaveThread()) &#123;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>可以看出，先释放 GIL，因为下一句执行的 at::empty_out 可能会慢很多，为了防止程序使用多线程，但仍然被阻塞在这里，所以释放 GIL，待 at::empty_out 执行完毕，再重新获取 GIL，<br><pre class="line-numbers language-none"><code class="language-none">~AutoNoGIL() &#123;    PyEval_RestoreThread(save);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>然后 at::empty_out 函数位于 torch/lib/include/Aten/Functions.h，<br><pre class="line-numbers language-none"><code class="language-none">static inline Tensor &amp; empty_out(Tensor &amp; result, IntList size) &#123;    return detail::infer_type(result).empty_out(result, size);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>在分析 at::empty_out 函数之前，我们需要知道这里的 Functions.h 也是动态生成的，在项目源码中稍作查询便知，在 aten/src/ATen/gen.py 中的 generate_outputs 函数中使用如下语句生成（与前面的 Declarations.yaml 文件的生成在同一处地方），<br><pre class="line-numbers language-none"><code class="language-none">file_manager.write(&#39;Functions.h&#39;, FUNCTIONS_H, top_env)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>现在回到 at::empty_out 函数定义上来，首先 detail::infer_type(result) 根据调用用传入的 Tensor 实例 result 得到 TypeExtendedInference 类型实例，然后调用实例函数 empty_out。这里相关的结构、类为 TypeExtendedInferface，TypeDefault，位于文件 torch/lib/include/ATen/TypeExtendedInferface.h， torch/lib/include/ATen/TypeDefault.h，此外，TypeDefault类方法实现源文件为 build/aten/src/ATen/TypeDefault.cpp，接口方法 empty_out 的实现正是位于此文件中，<br><pre class="line-numbers language-none"><code class="language-none">Tensor &amp; TypeDefault::empty_out(Tensor &amp; result, IntList size) const &#123;    return at::native::empty_out(&#x2F;* native_actuals *&#x2F; result, size);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>首先这三个文件是动态生成的（与 Declarations.yaml 相同）。然后我们看方法定义体中，直接调用另一个同名函数 at::native::empty_out 下，函数声明位于文件 torch/lib/include/ATen/NativeFunctions.h，此文件动态生成（与 Declarations.yaml 相同），函数实现位于 aten/src/ATen/native/TensorFactories.cpp，这个文件不是动态生成的（终于来了一个非动态生成的了），在此文件中查看函数定义，<br><pre class="line-numbers language-none"><code class="language-none">namespace at &#123;namespace native &#123;...Tensor&amp; empty_out(Tensor&amp; result, IntList size) &#123;    if (result.is_sparse()) &#123;        result.sparse_resize_and_clear_(size, size.size(), 0);    &#125; else &#123;        result.resize_(size);    &#125;    return result;&#125;...&#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>显然，根据输出 Tensor 是否是稀疏的进行不同的处理。</p><ol><li><p>输出 Tensor 是稀疏的</p><p>对输出 Tensor 调用方法 sparse_resize_and_clear_，声明位于 torch/lib/include/ATen/core/Tensor.h，此文件动态生成，与 Declarations.yaml 相同，见于 aten/src/ATen/gen.py，但是实际上源码中存在 aten/src/ATen/core/Tensor.h，并且这俩文件完全一样，还有 TensorMethods.h 和 Type.h 均存在这个现象，这里暂时不清楚为啥会这样。sparse_resize_and_clear_ 的函数实现位于 torch/lib/include/ATen/core/TensorMethods.h，</p><pre class="line-numbers language-none"><code class="language-none">inline Tensor &amp; Tensor::sparse_resize_and_clear_(IntList size, int64_t sparse_dim, int64_t dense_dim) &#123;    return type().sparse_resize_and_clear_(*this, size, sparse_dim, dense_dim);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>先根据当前 Tensor 获取对应的 Type，然后调用 Type 类型的 sparse_resize_and_clear_ 方法，Type 这个结构是一个接口，其接口函数的具体实现见各个具体 Type 的 .cpp 文件，Type 是由数值类型（如 int,float,double 等）和 Backend（CPU,CUDA,SparseCPU, SparseCUDA 等）组合而成，比如 SparseCPUByteType.h 和 SparseCPUByteType.cpp，此函数的的定义为</p><pre class="line-numbers language-none"><code class="language-none">Tensor &amp; SparseCPUByteType::sparse_resize_and_clear_(Tensor &amp; self, IntList size, int64_t sparse_dim, int64_t dense_dim) const &#123;    const OptionalDeviceGuard device_guard(device_of(self));    return at::native::sparse_resize_and_clear_(&#x2F;* actuals *&#x2F; self, size, sparse_dim, dense_dim);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>其中 at::native::sparse_resize_and_clear_ 函数声明位于 torch/lib/include/ATen/NativeFunctions.h，函数实现位于 aten/src/ATen/native/sparse/SparseTensor.cpp，</p><pre class="line-numbers language-none"><code class="language-none">SparseTensor&amp; sparse_resize_and_clear_(SparseTensor&amp; self, ArrayRef&lt;int64_t&gt; size, int64_t sparse_dim, int64_t dense_dim) &#123;    get_sparse_impl(self)-&gt;resize_and_clear_(sparse_dim, dense_dim, size);    return self;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>根据 Tensor 获取其底层实现 SparseTensorImpl 类对象，然后调用 SparseTensorImpl 的方法 resize_and_clear_。</p></li><li><p>输出 Tensor 是密集的</p><p>Tensor 的 resize_ 方法定义见 TensorMethods.h，为</p><pre class="line-numbers language-none"><code class="language-none">inline Tensor &amp; Tensor::resize_(IntList size) &#123;    return type().resize_(*this, size);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>调用这个 Tensor 的类型方法 resize_，以 CPUByteType.cpp 为例，定义如下</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">Tensor &amp; CPUByteType::resize_(Tensor &amp; self, IntList size) const &#123;    return at::native::resize_cpu_(&#x2F;* actuals *&#x2F; self, size);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可见，对 Tensor 按给定 size 进行 resize 操作，这个位于 aten/src/ATen/native/Resize.cpp 中的 resize_cpu_ 方法定义为，</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">Tensor&amp; resize_cpu_(Tensor&amp; self, IntList size) &#123;    auto* self &#x3D; self.unsafeGetTensorImpl();         &#x2F;&#x2F; 获取 Tensor 的底层实现类对象    &#x2F;&#x2F; 按给定 size 大小对 Tensor 进行 resize，当 size 大小比 Tensor size 大时，才分配一个更大的内存块    resize_impl_cpu_(self_, size, c10::nullopt);         self_-&gt;maybe_zero_dim(size.size()&#x3D;&#x3D;0);    return self;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面这个代码片段中，resize_impl_cpu_ 表示以 cpu 实现方式进行内存 resize 操作，此函数定义位于 aten/src/ATen/native/Resize.h 下，</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">inline TensorImpl* resize_impl_cpu_(    TensorImpl* self,    IntList size,    c10::optional&lt;IntList&gt; stride) &#123;    if (self-&gt;sizes() &#x3D;&#x3D; size &amp;&amp; (!stride || self-&gt;strides() &#x3D;&#x3D; stride)) &#123;        &#x2F;&#x2F; 如果当前 size 与将要重新分配 size 相等，且未指定新的步幅，或者当前数据步幅与新的步幅相等，那么无需重新分配内存        &#x2F;&#x2F; size 是整型列表，size 相等意味着列表元素数量相等，且对应位置的元素均相等        return self;    &#125;    int64_t storage_size &#x3D; 1;    ...    if(!stride)&#123;     &#x2F;&#x2F; 未指定步幅，则数据布局是近邻的，连续的，即，stride&#x3D;1        self-&gt;set_sizes_contiguous(size);    &#x2F;&#x2F; 设置当前 size 为新的 size        storage_size &#x3D; self-&gt;numel();        &#x2F;&#x2F; 设置 size 之后，计算元素数量，例如 size 为 (n1,n2,n3)，那么元素数量为 n1 * n2 * n3    &#125;    maybe_resize_storage_cpu(self, storage_size);    &#x2F;&#x2F; resize 操作&#125;static inline void maybe_resize_storage_cpu(TensorImpl* self, int64_t new_size) &#123;    ...    if (new_size+self-&gt;storage_offset() &gt; self-&gt;storage().numel()) &#123;        &#x2F;&#x2F; self-&gt;storage_offset() 通常返回 0        &#x2F;&#x2F; 只有需要更多的元素数量时，才重新分配内存        THStorage_resize(THTensor_getStoragePtr(self), new_size+self-&gt;storage_offset());    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们再来看位于 aten/src/TH/THStorageFunctions.cpp 中的 THStorage_resize 函数定义，</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">void THStorage_resize(THStorage* storage, ptrdiff_t size) &#123;    if (storage-&gt;resizable()) &#123;        at::DataPtr new_data;        if (size !&#x3D; 0) &#123;            new_data &#x3D; storage-&gt;allocator()-&gt;allocate(storage-&gt;itemsize()*size);        &#125;        &#x2F;&#x2F; 旧数据为 Tensor 已经存储的数据，新数据为上一步新分配的内存        &#x2F;&#x2F; 设置 Tensor 内部存储指向新数据，同时返回旧数据        at::DataPtr old_data &#x3D; storage-&gt;set_data_ptr(std::move(new_data));        ptrdiff_t old_size &#x3D; storage-&gt;numel();   &#x2F;&#x2F; 旧数据 size，元素数量        storage-&gt;set_numel(size);                &#x2F;&#x2F; 设置新的元素熟路        if (old_data !&#x3D; nullptr) &#123;            ptrdiff_t copy_size &#x3D; old_size;            if (storage-&gt;numel() &lt; copy_size) &#123;                copy_size &#x3D; storage_numel();            &#125;            if (copy_size &gt; 0) &#123;                 &#x2F;&#x2F; 内存数据考虑                memcpy(                    storage-&gt;data(),                    old_data.get(),                    storage-&gt;itemsize() * copy_size);            &#125;        &#125;    &#125;    ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从上面的代码片段可见整个 resize 过程，假设原先元素数量为 N1，resize 后的元素数量为 N2，那么</p><ol><li>N1 &gt;= N2，不重新分配内存，仅仅设置新的 size，标记原来 N1 个元素中前 N2 个元素处于当前使用中</li><li>N1 &lt; N2，重新分配内存，并将原来 N1 个元素值拷贝到新内存中前 N1 个位置上，剩余的元素值由 Tensor 内部存储的内存分配器 allocator 决定。</li></ol></li></ol><p>实验验证上述 torch.empty 过程，代码如下，<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchx<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span>out<span class="token operator">=</span>x<span class="token punctuation">)</span>  <span class="token comment"># resize 到一个较大的 size</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>out<span class="token operator">=</span>x<span class="token punctuation">)</span>  <span class="token comment"># resize 到一个较小的 size</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>out<span class="token operator">=</span>x<span class="token punctuation">)</span>  <span class="token comment"># 再次 resize 到一个较大的 size</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>本次输出如下，从以下结果可以看出是符合上述过程的。<br><pre class="line-numbers language-none"><code class="language-none">tensor([[0.0446, 0.1545, 0.5059, 0.6027],        [0.4872, 0.4557, 0.1010, 0.2962],        [0.0576, 0.1087, 0.3033, 0.4694]])tensor([[4.4638e-02, 1.5454e-01, 5.0591e-01, 6.0266e-01, 4.8720e-01],        [4.5573e-01, 1.0103e-01, 2.9619e-01, 5.7569e-02, 1.0874e-01],        [3.0331e-01, 4.6944e-01, 0.0000e+00, 0.0000e+00,        nan],        [0.0000e+00, 1.4013e-45, 0.0000e+00, 1.4013e-45, 0.0000e+00]])tensor([[0.0446, 0.1545]])tensor([[0.0446, 0.1545, 0.5059, 0.6027],        [0.4872, 0.4557, 0.1010, 0.2962],        [0.0576, 0.1087, 0.3033, 0.4694],        [0.0000, 0.0000,    nan, 0.0000]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><h3 id="无输出-Tensor"><a href="#无输出-Tensor" class="headerlink" title="无输出 Tensor"></a>无输出 Tensor</h3><p>回到 torch/csrc/autograd/generated/python_torch_functions_dispatch.h 这个文件，无输出 tensor 的 dispatch_empty 函数直接调用 torch::empty，此函数位于 torch/csrc/autograd/generated/variable_factories.h，在此函数定义中，我们暂且忽略 jit 跟踪部分的代码（用于跟踪记录有关 Tensor 的操作），核心的实现代码为<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">inline at::Tensor empty(at::IntList size, const at::TensorOptions &amp; options&#x3D;&#123;&#125;) &#123;    ...     &#x2F;&#x2F; jit tracing    at::Tensor tensor &#x3D; at::empty(size, at::TensorOptions(options).is_variable(false));    auto result &#x3D; autograd::make_variable(tensor, options.requires_grad()); &#x2F;&#x2F; 将 Tensor 转为 Variable    ...     &#x2F;&#x2F; jit tracing    return result&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>其中 at::empty 位于安装时动态生成的源文件 Functions.h（见上文分析），这个函数定义为<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">static inline Tensor empty(IntList size, const TensorOptions &amp; options) &#123;    return at::getType(options).empty(size, options);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>与有输出 Tensor 的 empty 函数实现逻辑类似，这里 at::getType(options) 根据给定的 options 构造出 TypeExtendedInterface 接口的具体实现类的 instance，具体而言，根据 options.backend(), options.dtype() 和 options.is_variable() 获取具体类型实例，而类型实例是事先注册好的，以 CPU 为 backend 为例说明，在 aten/src/ATen/Context.cpp 中 Context 的构造函数中，执行函数 register_cpu_types(this) 进行注册，而 register_cpu_type(Context* context) 函数位于 build/aten/src/ATen/RegisterCPU.cpp 文件，此文件由 aten/src/ATen/gen.py 中的 generate_outputs 函数生成（关于 gen.py 文件，上文也有介绍），现在我们来看看 register_cpu_types 中注册哪些类型<br><pre class="line-numbers language-none"><code class="language-none">CPUByteTypeCPUCharTypeCPUDoubleTypeCPUFloatTypeCPUIntTypeCPULongTypeCPUShortType...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>我们随便选择一个类型，比如 CPUByteType，查看其中 empty 函数实现，<br><pre class="line-numbers language-none"><code class="language-none">Tensor CPUByteType::empty(IntList size, const TensorOptions &amp; options) const &#123;    const DeviceGuard device_guard(options.device());   &#x2F;&#x2F; 准备在指定 device 上构造 Tensor    return at::native::empty_cpu(size, options);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>以上 at::native::empty_cpu 函数位于 aten/src/ATen/native/TensorFactories.cpp 中，函数实现体的部分为<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">auto* allocator &#x3D; at::getCPUAllocator();int64_t nelements &#x3D; prod_intlist(size); &#x2F;&#x2F; 连乘（各维度值），得到总元素数量auto dtype &#x3D; options.dtype();auto storage_impl &#x3D; c10::make_intrusive&lt;StorageImpl&gt;(    dtype,    nelements,    allocator-&gt;allocate(nelements*dtype.itemsize()),    allocator,    &#x2F;*resizeable&#x3D;*&#x2F;true);auto tensor &#x3D; detail::make_tensor&lt;TensorImpl&gt;(storage_impl, at::CPUTensorId(), false);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>继续查看 c10::make_intrusive<StorageImpl> 函数定义，不难得知先进行 new StorageImpl(…)，然后 wrap 为 intrusive_ptr，在 <a href="2019/06/13/PyTorch-2">PyTorch-2</a> 中，我们讨论过各种 Tensor 的底层实现都是 StorageImpl，所以 StorageImpl 对象可以通过 detail::make_tensor 转为对应的 Tensor。根据 at::getCPUAllocator 查看其定义得知获得的是 THDefaultAllocator 实例，其 allocate 方法调用 THAlloc 分配内存，THAlloc 内部调用 THAllocInternal 分配内存，而这个函数又使用 malloc（某些情况下也会使用 posix_memalign 申请对齐内存） 申请一块未初始化的内存。</p><p>示例：<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>结果为（每次执行结果可能不同，不固定）<br><pre class="line-numbers language-none"><code class="language-none">tensor([[1.6504e-12,3.0637e-41,1.6588e-12],        [3.0637e-41,4.4842e-44,0.0000e+00]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><h3 id="Tensor-的由来"><a href="#Tensor-的由来" class="headerlink" title="Tensor 的由来"></a>Tensor 的由来</h3><p>这里我们讨论 torch.empty 函数是如何返回得到 torch.Tensor 对象的。一开始，在 <code>torch/__init__.py</code> 中 <code>import autograd</code>，继而查看 <code>torch/autograd/__init__.py</code>，发现如下调用<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>_autograd_init<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>_autograd_init 这个 python 函数在 torch/csrc/Module.cpp 中注册，其底层实现是由 THPAutograd_initExtension 完成，这个 c++ 函数声明位于头文件 torch/csrc/autograd/autograd.h 中，函数实现位于 torch/csrc/autograd/init.cpp 中，看下这个函数的部分定义<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; 加载 torch&#x2F;tensor.py 模块auto tensor_module &#x3D; THPObjectPtr(PyImport_ImportModule(&quot;torch.tensor&quot;));&#x2F;&#x2F; 获取 torch&#x2F;tensor.py 中的 Tensor 类型THPVariableClass &#x3D; PyObject_GetAttrString(tensor_module, &quot;Tensor&quot;);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>要知道 <code>THPVariableClass</code> 这个类型对象声明位于 torch/csrc/autograd/python_variable.h 中<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">THP_API PyObject *THPVariableClass;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>嗯，这是一个 extern 声明，其原本定义位于 torch/csrc/autograd/python_variable.cpp 中。好，现在回到 torch.empty 的底层 c++ 实现部分，即上文 THPVariable_empty 函数定义，在 dispatch_empty 返回一个 Variable 对象后，经过 wrap 包装为 PyObject，来看 wrap 的定义，位于 torch/csrc/autograd/utils/wrap_outputs.h 中，其内部调用 THPVariable_Wrap，这个函数也位于 torch/csrc/autograd/python_variable.cpp，与 THPVariableClass 定义在同一个文件中，前面我们已经知道 THPVariableClass 就是 torch/tensor.py 中的 Tensor 类型，而这里 THPVariable_Wrap 通过调用 THPVariable_NewWithVar 将 Variable 对象包装为 THPVariableClass 对象，即 Tensor 实例。THPVariable_NewWithVar 函数定义的部分代码为<br><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">static PyObject* THPVariable_NewWithVar(PyTypeObject* type, Variable var) &#123;PyObject *obj&#x3D;type-&gt;tp_alloc(type, 0);      &#x2F;&#x2F; 申请 torch.Tensor 所需要的内存if(obj) &#123;    auto v &#x3D; (THPVariable*)obj; &#x2F;&#x2F; cast 为 THPVariable 类型指针，即 torch.Tensor 的基类 torch._C._TensorBase 的指针    new(&amp;v-&gt;cdata) Variable(std::move(var));    &#x2F;&#x2F; 指定内存中，移动构造 Variable（C++ 版本的 Tensor）    v-&gt;cdata.set_pyobj(obj);    ...&#125;return obj;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p><p>示例<br><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'torch.Tensor'</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></p><h1 id="PS"><a href="#PS" class="headerlink" title="PS"></a>PS</h1><p>好吧，主要是因为内容太多了，樯橹灰飞烟灭，先到此为止吧，就当是梳理了一下方法调用过程，等以后熟悉了整个代码框架，再回头重新整理一番。</p>]]></content>
      
      
      <categories>
          
          <category> DL Framework </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mAP</title>
      <link href="/2019/06/16/obj_det/mAP/"/>
      <url>/2019/06/16/obj_det/mAP/</url>
      
        <content type="html"><![CDATA[<h1 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h1><p>目标检测中，不同比赛的评估指标通常也不相同，我们先以 PASCAL VOC 为例进行说明。<br>-目标检测中常用的评价标准是 mAP（mean Average Precision），入坑目标检测的应该都知道 mAP 是 AP 的平均，即每个分类单独计算出一个 AP 值，然后对所有分类的 AP 值求平均就得到 mAP。<br><span id="more"></span></p><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><ol><li>Positive 表示检测结果</li><li>True Positive (TP): IoU 大于等于阈值的检测 box</li><li>False Positive (FP): IoU 小于阈值的检测 box</li><li>Precision = TP/(TP+FP) = TP/(所有检测)</li><li>Recall = TP/(TP+FN) = TP/(所有gt)</li></ol><p>由于现在我们专注于目标检测这个场景，所以首先需要弄清楚目标检测中 TP,FP,TN,FN 这四个基本概念。（以下4点均基于个人理解，如有错误，请及时通知本人修改，若博客不支持评论，可在<a href="https://github.io/shajian/shajian.github.io">项目</a>提 issue）：</p><ol><li><p>TP</p><p>检测结果为P (Positive)，其中与 gt box 最大 IoU 超过阈值（$Threshold_{VOC}=0.5$）的检测为 TP</p></li><li><p>FP</p><p>检测结果为P (Positive)，其中与 gt box 最大 IoU 低于阈值的检测为 FP。如果某个检测与某 gt box 有最大 IoU 且超过阈值，但是这个 gt box 已被另一个检测匹配（match），且另一个检测的 confidence 更高，则当前检测也被认为是 FP。用数学语言描述为：</p><script type="math/tex; mode=display">\left. \begin{array}{} GT_1=\underset{GT_i} {\text{argmax}} \quad \text{IoU}(Det_a, GT_i) \\\\GT_1=\underset{GT_i} {\text{argmax}} \quad \text{IoU}(Det_b, GT_i) \\\\\text{Conf}_a > \text{Conf}_b \end{array} \right] \Rightarrow Det_b \in FP</script></li><li><p>FN</p><p>如果某个 gt box 未被检测到，即没有检测结果与这个 gt box 的 IoU 大于0，则认为这个 gt box 为 FN</p></li><li><p>TN</p><p>目标检测中没有阴性预测，TN = 0。以二分类问题为例，则分类判断不是 Positive 就是 Negative，TN 表示判断为 Negative，而实际是 Positive。</p></li></ol><p>VOC 使用阈值 <code>0.5</code>。</p><h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><h3 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h3><p>每个预测 box 均有一个 score 表示 confidence，对这个 confidence 设置阈值，仅考虑大于等于这个阈值的预测 box，小于这个阈值的检测结果则忽略，于是每个不同的 confidence 阈值均对应一对 PR（Precision x Recall）值。实际计算中，按 confidence 降序排列，将预测数量从 1 增加到全部预测数量（从 rank=1 到全部预测数量），每次计算一对 PR 值，于是得到原始的 PR 曲线，对于召回率 R’ &gt;= R 选取最大的 P 值则得到插值 PR 曲线。我们使用一个例子予以说明（搬运自<a href="https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge">stackexchange</a>）。</p><p>给定目标分类 “Aeroplane”，假设检测结果如下,<br><pre class="line-numbers language-none"><code class="language-none">BB  | confidence | GT----------------------BB1 |  0.9       | 1----------------------BB2 |  0.9       | 1----------------------BB3 |  0.7       | 0----------------------BB4 |  0.7       | 0----------------------BB5 |  0.7       | 1----------------------BB6 |  0.7       | 0----------------------BB7 |  0.7       | 0----------------------BB8 |  0.7       | 1----------------------BB9 |  0.7       | 1----------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>（BB 表示检测结果所匹配 “match” 的 GT box）</p><p>以上表格中已经按 confidence 降序排列，GT=1 表示 TP，GT=0 表示 FP。 BB 那一列的 <code>BBi</code> 表示 GT box 编号。预测 box 总共有 10 个，上表中列出了 9 个，还有一个 预测 box，gt boxes 中与这个预测 box 有最大 IOU 的是 <code>BB1</code>，不过其相应的 confidence 比上表中第一行的预测 box （与 <code>BB1</code> ) 的 confidence （值为 0.9）小（注意，这里是 confidence 比较，不是 IOU 比较，所以不知道这两个预测 box 哪个与 <code>BB1</code> 的 IOU 更大），所以这个预测 box 被第一行的预测 box 抑制，故认为此检测是 FP。除了此外，还有两个未检测到的 BBox 未在上表中列出， FN=2。</p><p>TP=5 (对应的匹配 gt box 为 BB1,BB2,BB5,BB8,BB9)，FP=5 ，其中 4 个在上表中列出，还有一个是上面所说的被第一行的 TP 预测 box 所抑制的预测 box，这个被抑制的 box 对应如下的 rank=3 这个 case，舍弃这个检测。这一点在 PASCAL VOC 主页的 Detection Task 的 <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/devkit_doc.html#SECTION00054000000000000000">Evaluation</a> 一节也进行了说明。</p><p>GT box 数量为 TP+FN=5+2=7。计算所有点的 PR 值如下，<br><pre class="line-numbers language-none"><code class="language-none">rank&#x3D;1  precision&#x3D;1.00 and recall&#x3D;0.14----------rank&#x3D;2  precision&#x3D;1.00 and recall&#x3D;0.29----------(被第一行预测 box 所抑制的预测box，其 confidence &lt;0.9，例如可取 0.8，它们两个都匹配 BB1)rank&#x3D;3  precision&#x3D;0.66 and recall&#x3D;0.29----------rank&#x3D;4  precision&#x3D;0.50 and recall&#x3D;0.29----------rank&#x3D;5  precision&#x3D;0.40 and recall&#x3D;0.29----------rank&#x3D;6  precision&#x3D;0.50 and recall&#x3D;0.43----------rank&#x3D;7  precision&#x3D;0.43 and recall&#x3D;0.43----------rank&#x3D;8  precision&#x3D;0.38 and recall&#x3D;0.43----------rank&#x3D;9  precision&#x3D;0.44 and recall&#x3D;0.57----------rank&#x3D;10 precision&#x3D;0.50 and recall&#x3D;0.71----------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>稍作解释：（使用所匹配的 GT box 编号进行说明）</p><ol><li>rank=1，检测数量为 1（此时其他检测结果均被舍弃），TP 仅 BB1 一个，没有 FP，故 P=1，R=1/7=0.14</li><li>rank=2，检测数量为 2，TP 包括 BB1,BB2，没有 FP，故 P=1，R=2/7=0.29</li><li>rank=3，检测数量为 3，TP 包括 BB1,BB2，FP 为 BB1，故 P=2/3=0.66，R=2/7=0.29</li><li>…</li></ol><h3 id="AP"><a href="#AP" class="headerlink" title="AP"></a>AP</h3><p>VOC 在 2010 之前，选择固定的 11 个 R 值 等分点，即 R={0,0.1,…,1}，然后对 R’ &gt;= R 选择最大 P 值得到插值 PR 曲线。 AP 则是每个 R 阈值处的平均正确率（average precision）。VOC 2010 之后，仍然是对 R’ &gt;= R 选择最大 P 值，但是 R 是 [0,1] 之间的所有值（参考上一节内容 <strong>PR 曲线</strong> 中的计算过程），此时 AP 为 PR 曲线下方的面积 AUC （area under the curve）。两种计算方法如下：</p><h4 id="11-点插值"><a href="#11-点插值" class="headerlink" title="11-点插值"></a>11-点插值</h4><p>取11个 R 值的 [0,1] 区间等分点计算平均正确率：</p><script type="math/tex; mode=display">AP=\frac 1 {11} \sum_{r \in {0,0.1,...,1}} \rho_{interp(r)} \tag(1)</script><script type="math/tex; mode=display">\rho_{interp(r)}=\max_{\tilde r:\tilde r \ge r} \rho(\tilde r) \tag(2)</script><p>其中，$\rho(\tilde r)$ 为计算得到的正确率。<br>举个例子如图（完整例子请参考<a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">这里</a>），<br><img src="/images/mAP_fig1.png" alt=""></p><p>（上图中的 PR 数据与上面表格的数据无关，它们来自不同的例子）</p><p>蓝色折线的 <strong>上顶点</strong> 为根据预测结果计算得到的 PR 值，即，每一个竖直线段的上端点为 PR 值。红色点则是根据11个固定的 R 值进行插值得到的 PR 值，比如计算阈值 R=0.2 处的插值，根据式 (2)，大于等于 0.2 的 $\tilde r$ 值可取 {0.2,0.2666,0.3333,0.4,0.4666}，当 $\tilde r=0.4$ 时，显然 P 有最大值为 0.4285。根据 11-点插值，计算 AP：</p><p>$AP=\frac 1 {11} \sum_{r \in {0,0.1,…,1}} \rho_{interp(r)}$</p><p>$AP=\frac 1 {11}(1+0.6666+0.4285+0.4285+0.4285+0+0+0+0+0+0)$</p><p>$AP=26.84\%$</p><h4 id="所有点插值"><a href="#所有点插值" class="headerlink" title="所有点插值"></a>所有点插值</h4><p>AP 计算式为，</p><script type="math/tex; mode=display">AP=\sum_{r=0}^1(r_{n+1}-r_n) \rho_{interp}(r_{n+1}) \qquad(3) \\\\\rho_{interp}(r_{n+1})=\max_{\tilde r: \tilde r \ge r_{n+1}} \rho(\tilde r) \qquad(4)</script><p>其中，$\rho (\tilde r)$ 为 Recall $\tilde r$ 处的正确率。这种 AP 计算方法首先插值得到每个召回率值的正确率，然后计算插值后 PR 曲线下的面积 AUC。<br>如下图，<br><img src="/images/mAP_fig2.png" alt=""></p><p>蓝色折线顶点表示根据检测结果计算出来的 PR 值，红色虚线表示插值后的 RP 值，可将 AUC 划为 4 个区域，如下图，<br><img src="/images/mAP_fig3.png" alt=""></p><p>于是计算 AP 为，</p><p>$AP=A_1+A_2+A_3+A_4=(0.0666-0) \times 1+(0.1333-0.0666) \times 0.6666 \\\\ +(0.4-0.1333) \times 0.4285+(0.4666-0.4) \times 0.3043=24.56\%$</p><h1 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h1><h2 id="相关概念-1"><a href="#相关概念-1" class="headerlink" title="相关概念"></a>相关概念</h2><ol><li>TPR (true positive rate)，又称灵敏度 (sensitivity)、召回率 (recall)：TPR = TP/(TP+FN)</li><li>TNR (true negative rate)，又称特异度 (specificity): TNR = TN/(FP+TN)</li><li>FNR (false negative rate)，又称漏诊率: FNR = 1 - TPR = FN/(TP+FN)</li><li>FPR (false positive rate)，又称误诊率: FPR = 1 - TNR = FP/(FP+TN)</li><li><p>LR+ (positive likelihood ratio):</p><p>$LR^+=\frac {TPR} {FPR} = \frac {Sensitivily} {1-Specificity}$</p></li><li><p>LR- (negative likelihood ratio):</p><p>$LR^-=\frac {FNR} {TNR} = \frac {1-Sensitivity} {Specificity}$</p></li><li>Youden index: Youden index = Sensitivity + Specificity - 1 = TPR - FPR</li></ol><h2 id="ROC-曲线-1"><a href="#ROC-曲线-1" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>ROC 是常见的评价分类器的指标。</p><p>ROC 全称 <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">receiver operating characteristic</a>（以下很多内容均来自于这个维基百科词条）。</p><p>根据不同的判别阈值（大于等于阈值为正，否则为负），得到一组 TPR-FPR 值，所画曲线就是 ROC 曲线。<br>如下图所示，<br><img src="/images/mAP_fig4.png" alt=""></p><p>图中 (0,0) 和 (1,1) 两点分别对应：</p><ol><li>当阈值为 1 时，全部判断为 Negative，故 TP=FP=0，所以 TPR=FPR=0</li><li>当阈值为 0 时，全部判断为 Positive，故 TN=FN=0，所以 TPR=FPR=1</li></ol><p>实际上，阈值可以位于范围 $(-\infty,0) \cup (1,+\infty)$，位于 $(-\infty,0)$ 是与第 2 点相同，位于 $(1,+\infty)$ 是与第 1 点相同。</p><p>一个好的分类器其 ROC 曲线应该位于直线 y=x 的上方，直线 y=x 对应随机猜测的分类器，也就是说，不管选择什么阈值，都应该让真阳性率大于误诊率。理想情况下，TPR 接近 1，FPR 接近 0，故 ROC 曲线越接近 (0,1)，越偏离直线 y=x，就越好。</p><h2 id="ROC-空间"><a href="#ROC-空间" class="headerlink" title="ROC 空间"></a>ROC 空间</h2><p>二分类中，每个实例的分类预测均基于一个连续随机变量 X，即实例对应的得分 score，例如逻辑回归中的概率。给定阈值 T，如果 X&gt;T，为正例，否则为负例。如果实例属于正例，那么 X 的概率密度为 $f_1(x)$，如果实例属于负例，那么 X 的概率密度为 $f_0(x)$。因此,</p><script type="math/tex; mode=display">TPR=\int_T^{\infty} f_1(x)dx \\FPR = \int_T^{\infty} f_0(x)dx</script><p>两者均为阈值 T 的函数。</p><ol><li>TPR(T) 表示在该阈值下随机选择一个正例，判断该正例为正例的概率</li><li>FPR(T) 表示在该阈值下随机选择一个负例，判断该负例为正例的概率。</li></ol><p>下图表示某分类器的分类情况，<br><img src="/images/mAP_fig5.png" alt="图 5"></p><p>横轴为随机变量 X 的取值（表示计算得分 score），与纵轴的交点处为判断阈值，纵轴表示概率密度，越大则表示此 score 对应的实例越多。两个曲线相聚越远，则表示越容易区分正负例。</p><h2 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h2><p>通常使用 ROC 曲线下方的面积 AUC 来评价一个分类器的好坏。</p><p>AUC 等于一个概率值：当随机选择一个正例和随机选择一个负例时，分类器计算正例的 Score 大于计算负例的 Score 的概率。根据ROC 曲线，可以将 TPR 看作是 FPR 的函数，而实际上这两者均是判断阈值 T 的函数，所以有</p><script type="math/tex; mode=display">TPR(T): T \rightarrow y(x) \\\\FPR(T): T \rightarrow x</script><p>于是，</p><script type="math/tex; mode=display">A =\int_0^1 y(x) \ dx  =\int_0^1 TPR[FPR^{-1}(x)] \ dx \\\\ \stackrel{x=FPR(T)} =\int_{-\infty}^{+\infty} TPR(T) \ d[FPR(T)] =\int_{-\infty}^{+\infty} TPR(T) \cdot FPR \ '(T) \ dT \\\\ = \int_{-\infty}^{+\infty} \left( \int_T^{+\infty}  f_1(T') \ dT' \right) f_0(T) \ dT \\\\ =\int_{-\infty}^{+\infty}\int_T^{+\infty}  f_1(T')f_0(T) \ dT' dT \\\\ = P(X_1>X_0)</script><p>其中，$X_1$ 表示正例的得分，$X_0$表示负例的得分。</p><p>最后一个等号可能不容易理解，我们将 $X_1$ 和 $X_0$ 均看作随机变量，其分布函数为:</p><script type="math/tex; mode=display">F_1(x)=\int_{-\infty}^{x} f_1(x) dx \\\\F_0(x)=\int_{-\infty}^{x} f_1(x) dx</script><p>概率密度分别为 $f_1,f_0$。</p><p>由于$X_1, X_0$ 互相独立，二维随机变量 $(X_1,X_0)$ 的联合概率密度为 $f(x_1,x_0)=f_1(x_1) f_0(x_0)$，于是 $X_0 &lt; X_1$ 的概率为：</p><script type="math/tex; mode=display">P(X_1>X_0)=\iint_{G} f(x_1,x_0) dx_1 dx_0=\int_{-\infty}^{+\infty}\int_{x_0}^{+\infty}f_1(x_1) f_0(x_0) \ dx_1 dx_0</script><p>与上面的计算式形式完全一样，证毕。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GIoU</title>
      <link href="/2019/06/13/obj_det/GIoU/"/>
      <url>/2019/06/13/obj_det/GIoU/</url>
      
        <content type="html"><![CDATA[<p>论文 <a href="https://arxiv.org/abs/1902.09630">Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression</a><br><span id="more"></span></p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>IoU 是目标检测benchmarks中使用最广的评估指标，然而，优化回归bbox参数的距离损失并不等价于最大化IoU指标。对于轴对齐的2D bbox（bbox 旋转一个角度就非轴对齐了），IoU 可直接用作回归损失，但是 IoU 无法优化无重叠的bbox，所以本文提出一种泛化版的Iou，名为 GIou。结合 GIoU 和 sota 目标检测框架，在流行的目标检测benchmarks例如 PASCAL VOC 和 MS COCO中，分别使用标准 IoU 和 GIoU 损失，我们发现性能一致得到提升。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在很多2D/3D 计算机视觉任务中，bbox 回归是最基本的组成之一。例如目标定位，多目标检测，目标跟踪以及实例分割，均依赖准确的bbox回归。提升性能的主流趋势是使用深度神经网络，然而，还有一种提升方法被广泛忽略，那就是使用基于 IoU 的指标损失来代替传统的回归损失如 $l_1, l_2$ 等。</p><p>IoU 将要比较的目标的形状属性例如 bbox 的宽、高和位置等信息编码成区域属性，并基于面积（体积）计算出一个归一化的值。语义分割、目标检测和跟踪等任务中的性能测量均采用IoU作为测量指标。</p><p>然而，最小化损失如$l_n$范数与提高IoU并不是强相关。考虑一个2D场景，如图1(a)，<br><img src="/images/GIoU_fig1.png" alt=""></p><!--  --><p>预测box（黑矩形）和gt box（绿矩形）均由左下角和右上角坐标表示$(x_1,y_1,x_2,y_2)$，为简单起见，我们令两个box的其中一个corner 左下角的距离（例如$l_2$范数）固定，于是，以 gt box 另一个 corner 为圆心，某半径长的圆，无论预测 box 的另一个 corner 的坐标，只要其位于这个圆上，其 $l_2$ 距离均保持不变；然而IoU却不同。这个问题可以延伸到其他损失和bbox表示上，例如图1(b)。</p><p>直觉而言，这些类型的损失的一个较好的局部最优解可能并非 IoU 的局部最优解。而且，与 IoU 不同的是，$l_n$ 不具有尺度不变性，相同重叠程度的几对 bbox，其损失值各不相同。另外，一些 bbox 的表示方法，由于没有对不同类型的表示参数进行正则处理，使得这个问题更加严重。例如在 center+size 表示法中，$(x_c,y_c)$ 是中心坐标，$(w,h)$ 是 box size。当表示参数变多时，如旋转度，复杂度继续上升。</p><p>为了解决这些问题，sota 检测器引入了 anchor 的概念，并使用了非线性表示方法简单地处理尺度问题（例如，faster-rcnn中坐标偏差的计算）。但即使使用了这些手工设计，优化回归损失和IoU值依然存在偏差。</p><p>本文探索了轴对齐矩形之间的IoU计算，以及轴对齐超矩形（$ndim \ge 2$）之间的IoU计算，此时IoU 有解析解，并且可反向传播，也就是说，IoU 可以直接用作目标函数进行优化，而优化Iou目标函数与优化某个损失函数之间，显然选择优化IoU目标函数，能与提高Iou指标强相关，但是这也导致一个问题：如果两个目标没有重叠，IoU则为0，无法知道两个目标距离有多远，IoU为0，其梯度也将为0，导致无法优化。</p><p>我们将IoU这一概念延伸到无重叠情况下来解决上述问题。这种泛化：(a) 沿袭 IoU 能将被比较的目标的形状属性编码进区域属性；(b) 维持 IoU 的尺度不变性；(c) 在目标有重叠情况下与IoU强相关。这个泛化版的IoU，我们称为GIoU，将GIoU引入到 sota 目标检测框架，在流行的目标检测的benchmarks上，比较标准的IoU和GIoU，发现性能一致均得到提升。</p><p>主要贡献如下：</p><ul><li>介绍了GIoU，作为比较两个任意形状差距的指标</li><li>以GIoU作为轴对齐矩形或超矩形的损失时，使用解析解</li><li>将GIoU引入sota 检测器如Faster R-CNN，Mask R-CNN和YOLO v3，并在标准目标检测benchmark上验证性能得到提升</li></ul><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p><strong>目标检测准确性测量：</strong> IoU作为评估指标在目标检测任务中广为使用，常用于确定预测box是真阳性还是假阳性。使用IoU时需要选择一个阈值。在PASCAL VOC上，计算mAP时选择 IoU阈值=0.5，但是随意选择的IoU阈值不能完全反映定位性能，所有定位准确性大于这个阈值的检测结果认为是真阳性，从而参与mAP的计算，IoU阈值的选择将直接影响mAP值。为了是性能测量对IoU阈值不敏感，MS COCO benchmark 则选择不同的IoU阈值计算多个mAP然后取平均。</p><p><strong>bbox表示和损失：</strong> 2D目标检测中，bbox参数非常重要。最近的文献提出多种不同bbox表示和损失：</p><ol><li><p>YOLO v1</p><p>YOLO v1 直接回归 bbox 参数$(x_c,y_c,w,h)$，坐标损失使用平方差。计算损失时，为了降低目标scale对(w,h)损失项的影响，将这一损失项由$(w-\hat w)^2+(h-\hat h)^2$ 改为 $(\sqrt w - \sqrt {\hat w})^2+(\sqrt h - \sqrt {\hat h})^2$。</p></li><li><p>R-CNN</p><p>R-CNN使用selective search先获得候选boxes，然后回归bbox中心点偏差（求差）和size的偏差（求商），为了降低scale敏感度，将size 偏差转换到对数空间（求log），然会对偏差使用$l_2$范数（最小均方差MSE）作为目标函数进行优化。</p></li><li><p>Fast R-CNN</p><p>Fast R-CNN对坐标偏差使用 $l_1$-smooth 损失，使得模型即使在异常值情况下也具有较好的鲁棒性（异常值情况一般指偏差非常大的情况，此时若使用 $l_2$ 范数的目标函数，其梯度比较大，使得模型训练初期非常不稳定）。</p></li><li><p>Faster R-CNN</p><p>Faster R-CNN使用密集anchor boxes，然后对其中心坐标和size的偏差进行回归，根据anchor boxes的得分（分类置信度）按正负例的一定比例（1:3）得到一个batch （数量为128）的proposals，然后再使用Fast R-CNN的分类和回归两个分支进行最终的预测。为了进一步解决正负例不平衡问题，RetinaNet 使用 focal loss。</p></li></ol><p>大部分目标检测器都是结合以上某种bbox表示和某种损失。这些努力推动目标检测有了明显的发展。我们的工作表明，使用GIoU 损失可以进一步提高目标定位，因为如前面所分析的那样 bbox 回归损失并不能够直接反映检测评估指标IoU。 </p><p><strong>使用近似或替代函数优化IoU：</strong> 在语义分割任务种，曾使用近似函数或替代损失优化IoU。类似地，目标检测任务中，最近的一些研究工作也尝试直接或间接利用IoU以更好地进行bbox回归，然而却在非重叠情况下优化IoU时遇到近似或梯度平坦问题。本文我们通过引入GIoU解决IoU在非重叠情况下的问题。</p><h1 id="泛化IoU"><a href="#泛化IoU" class="headerlink" title="泛化IoU"></a>泛化IoU</h1><p>用于比较两个任意形状 $A,B \subseteq S \in \mathbb{R}^n$ 的 IoU 计算方法为：</p><script type="math/tex; mode=display">IoU = \frac {|A \cap B|} {|A \cup B|}</script><p>两个显著特性使得这种相似性测量方法流行于评估2D/3D计算机视觉任务中：</p><ul><li><p>IoU作为距离同时也作为评估指标。</p><p>IoU距离即 $\mathcal L_{IoU}=1-IoU$，这意味着 $\mathcal L_{IoU}$ 满足 IoU 指标的所有性质，例如非负性，不可区分的同一性，对称性和三角不等式</p></li><li>IoU具有尺度不变性。这意味着，两个任意形状A B的相似度与它们在 S 空间的尺度无关</li></ul><p>但是，IoU的主要问题是：</p><ul><li>$|A \cap B|=0 \Rightarrow IoU(A,B)=0$，此时，IoU无法分辨两个形状A B是靠的非常近还是非常远</li></ul><p>为了解决这个问题，我们提出了泛化版IoU，即 GIoU。</p><p>两个任意的凸形 $A, B \subseteq S \in \mathbb S^n$，首先在 S 空间中寻找包含 A 和 B 的最小凸形 C。如果比较两个具体类型的几何图形，C 可以也是这个具体类型，例如比较两个椭圆形，C 则是包含这两个椭圆形的最小椭圆形。然后我们计算 C 中扣掉 A 和 B 剩余部分的面积（体积）与 C 自身的面积（体积）的比例，这个比例代表了一种归一化的且注重 A 和 B 之间的空白部分面积（体积）的测量方法，然后，从 IoU 中减去这个比例就得到 GIoU。（面积/体积对应 2D/3D）</p><p>整个计算过程总结如下算法1：</p><hr><p>算法1：GIoU</p><hr><p>输入： 两个任意凸形 $A,B \subseteq S \in \mathbb S^n$</p><p>输出： GIoU</p><ul><li>在 S 空间中寻找包含 A B 的最小凸形 C</li><li><p>计算 IoU</p><p>$IoU=\frac {|A \cap B|} {|A \cup B|}$</p></li><li><p>计算 GIoU</p><p>$GIoU = IoU - \frac {|C \setminus (A \cup B)|} {|C|}$</p></li></ul><hr><p>作为新的指标，GIoU 具有性质：</p><ul><li><p>与 IoU 类似，GIoU 作为距离具有指标的所有性质：非负性，不可区分的同一性，对称性和三角不等式</p><p>IoU 距离即 $\mathcal L_{GIoU} = 1-GIoU$。</p></li><li>与 IoU 类似，GIoU 具有尺度不变性。</li><li><p>GIoU 上限为 IoU</p><p>$\forall A,B \subseteq \mathbb S, GIoU(A,B) \le IoU(A,B)$，当 A B越靠近且形状越相似，则 GIoU 越接近 IoU，即 $\lim_{A \rightarrow B} GIoU(A,B)=IoU(A,B)$。</p></li><li><p>IoU 和 GIoU 的值域</p><p>$\forall A,B \subseteq \mathbb S, 0 \le IoU(A,B) \le 1$，但是 GIoU 的值域则关于零点对称，$-1 \le GIoU(A,B) \le 1$。</p><p>我们看下如何获得边界值：</p><ul><li>与 IoU 相同，只有当 A B 完全重合的时候，即$|A \cup B|=|A \cap B|$，此时$GIoU =IoU=1$</li><li>当 A B 两个形所占面积（体积）与 C 所在面积（体积）之比趋于 0，GIoU 趋于 -1，即$\lim_{\frac{|A \cup B|}{|C|}\rightarrow 0} GIoU(A,B)=-1$</li></ul></li></ul><p>综上，GIoU 保持了 IoU 的主要性质并避免了 IoU 的缺点，所以在2D/3D计算机视觉任务的性能测试中可以使用 GIoU 代替 IoU。本文我们侧重于 2D 目标检测，推导 GIoU 的解析解，GIoU 同时担当性能指标和损失。在非轴对齐 3D 场景下的 GIoU 则待以后的工作去研究。</p><h2 id="GIoU用作BBox回归损失"><a href="#GIoU用作BBox回归损失" class="headerlink" title="GIoU用作BBox回归损失"></a>GIoU用作BBox回归损失</h2><p>我们已经介绍了 GIoU 可以作为任意两个形状的距离测量指标，但是与 IoU 一样，没有解析解计算两个任意形状的交，也没有解析解可以计算包含这俩形状的最小凸形。</p><p>好在2D 目标检测任务中，bbox 是轴对齐的，此时 GIoU 有解析解。两个形状 A B 的交，以及包含 A B 的最小凸形均具为矩形，对 A B 的顶点坐标使用 min 或 max 操作可以求得它们的顶点坐标。为了确定 A B 是否重叠，还需要进行条件检查，比如 A B 的交，作为矩形，其左上顶点的 x 坐标必然比右下顶点的 x 坐标小即 $x^{tl} &lt; x^{br}$，而 $x^{tl}=\max (x_A^{tl}, x_B^{tl}), \ x^{br}=\min (x_A^{br},x_B^{br})$，所以有 $x_B^{tl} \le x_A^{tl}&lt;x_B^{br}$ 或 $x_A^{tl} \le x_B^{tl}&lt;x_A^{br}$。</p><p>反向传播中，min、max和按位计算的线性函数如 ReLU 的梯度计算均是可行的，算法2 中每个部分均可以求导，故 IoU 和 GIoU 均可以直接用作损失即 $\mathcal L_{IoU}, \mathcal L_{GIoU}$ 来优化基于深度神经网络的目标检测器。</p><hr><p>算法2：IoU和GIoU用作BBox回归损失</p><hr><p>输入：预测框 $B^p$ 和 GT 框 $B^g$ 的坐标，$B^p=(x_1^p,y_1^p,x_2^p,y_2^p), \quad B^g=(x_1^g,y_1^g,x_2^g,y_2^g)$</p><p>输出：$\mathcal L_{IoU}, \ \mathcal L_{GIoU}$</p><ol><li><p>因为预测框各个坐标是独立预测出来的，所以需要确保 预测 box 坐标有效即，</p><p>$x_2^p&gt;x_1^p, \ y_2^p&gt;y_1^p$，故进行如下转换：</p><ul><li>$\hat x_1^p=\min(x_1^p,x_2^p), \ \hat x_2^p=\max(x_1^p,x_2^p)$</li><li>$\hat y_1^p=\min(y_1^p,y_2^p), \ \hat y_2^p=\max(y_1^p,y_2^p)$</li></ul></li><li><p>计算 GT box 面积：</p><p>$A^g=(x_2^g-x_1^g)\times (y_2^g-y_1^g)$</p></li><li><p>计算预测 box 面积：</p><p>$A^p=(x_2^p-x_1^p)\times (y_2^p-y_1^p)$</p></li><li><p>计算交：</p><ul><li>$x_1^{\mathcal I}=\max(\hat x_1^p, x_1^g), \ x_2^{\mathcal I}=\min(\hat x_2^p,x_2^p)$</li><li>$y_1^{\mathcal I}=\max(\hat y_1^p, y_1^g), \ y_2^{\mathcal I}=\min(\hat y_2^p,y_2^p)$</li><li>$\mathcal I=\begin{cases} (x_2^{\mathcal I}-x_1^{\mathcal I})\times (y_2^{\mathcal I}-y_1^{\mathcal I}) &amp; x_2^{\mathcal I} &gt; x_1^{\mathcal I}, y_2^{\mathcal I} &gt; y_1^{\mathcal I} \\ 0 &amp; \text{otherwise} \end{cases}$</li></ul></li><li><p>计算最小包含凸形 c：</p><ul><li>$x_1^c=\min(\hat x_1^p, x_1^g), \ \max(\hat x_2^p, x_2^g)$</li><li>$y_1^c=\min(\hat y_1^p, y_1^g), \ \max(\hat y_2^p, y_2^g)$</li></ul></li><li><p>计算 c 的面积：</p><p>$A^c=(x_2^c-x_1^c)\times (y_2^c-y_1^c)$</p></li><li><p>计算 IoU：</p><p>$IoU = \frac {\mathcal I}{\mathcal U}$，其中 $\mathcal U = A^p+A^g-\mathcal I$</p></li><li><p>计算 GIoU：</p><p>$GIoU = IoU - \frac {A^c-\mathcal U} {A^c}$</p></li><li><p>计算 GIoU 损失：</p><p>$\mathcal L_{IoU}=1-IoU, \ \mathcal L_{GIoU}=1-GIoU$</p></li></ol><hr><p>根据指标检测性能时，以指标本身作为损失来优化显然是最佳选择，但是在bbox非重叠场景下，IoU=0，其梯度也为0，影响训练质量和收敛速度，相反，GIoU 则一直有有效梯度指导如何优化模型。另外，根据性质3，GIoU 与 IoU 强相关，在 IoU 较大时，这种强相关更加显著。图2 定性的分析了这种相关性，</p><p><img src="/images/GIoU_fig2.png" alt=""></p><p>图2中，随机选择了1万组 2D 矩形pair，计算其 IoU 和 GIoU，观察发现，在重叠较小时，例如 $IoU \le 0.2, \ GIoU \le 0.2$，GIoU 可以比 IoU 变化更显著，而且在任何情况下，GIoU 的梯度都可以很陡，所以将 GIoU 作为损失$\mathcal L_{GIoU}$，比使用 IoU 作为损失$\mathcal L_{IoU}$，更有利于优化，并且最终的性能测量指标只要是基于IoU，无论使用哪种指标均可。</p><h3 id="损失稳定性"><a href="#损失稳定性" class="headerlink" title="损失稳定性"></a>损失稳定性</h3><p>我们也考察了预测值为任意的情况下，损失是否会不稳定或者出现未定义情况（比如除数为0）。</p><p>假设 GT box 是矩形，且面积大于0即，$A^g &gt; 0$，算法2中第1点和第4点分别确保了预测框和两个bbox的交均非负即，$A^p \ge 0, \ \mathcal I \ge 0, \forall B^p \in \mathbb R^4$，又根据$\mathcal U \ge A^g$，故 $\mathcal U &gt; 0$，所以 IoU 的分母为正非零。又 $\mathcal U \ge \mathcal I$，故 $0 \le IoU \le 1$，于是 IoU 损失范围为 $0 \le \mathcal L_{IoU} \le 1$</p><p>检查 GIoU 的稳定性，需要考察项 $\frac {A^c-\mathcal U} {A^c}$，显然包含 A B 的最小凸形不小于 A B 的并，即 $A^c \ge \mathcal U &gt; 0$，所以 $\frac {A^c-\mathcal U} {A^c} \ge 0$。理论上来讲，$\frac {A^c-\mathcal U} {A^c} &lt;1$，且当 A B 中心点的几何距离比 A B 的 size 大很多时，即 A B 离得很远，此时 $\frac {A^c-\mathcal U} {A^c} \rightarrow 1$，故 $-1 &lt; GIoU \le 1$，为了对称，改写为 $-1 \le GIoU \le 1$。</p><h3 id="IoU-0时-mathcal-L-GIoU-的行为"><a href="#IoU-0时-mathcal-L-GIoU-的行为" class="headerlink" title="IoU=0时$\mathcal L_{GIoU}$的行为"></a>IoU=0时$\mathcal L_{GIoU}$的行为</h3><p>GIoU 损失 $\mathcal L_{GIoU}=1-GIoU=1+\frac {A^c-\mathcal U} {A^c} - IoU$，当 $B^p$ 和 $B^g$ 不相交，即 $\mathcal I=0, IoU=0$，此时 GIoU 损失简化为 $\mathcal L_{GIoU}=1+\frac{A^c-\mathcal U}{A^c}=2-\frac {\mathcal U}{A^c}$，最小化 GIoU 损失则需要最大化 $\frac {\mathcal U}{A^c}$，这一项已经是归一化的，即 $0\le \frac {\mathcal U}{A^c} \le 1$，并且最大化这一项则需要最小化 $A^c$，同时最大化 $\mathcal U$，因为 $\mathcal I=0$，故此时 $\mathcal U=A^p+A^g$，由于 $A^g$ 已知且固定，所以需要最大化 $A^p$，也就是说，最小化 $A^c$ 且同时最大化 $A^p$，显然，这就使得 $B^p$ 趋于与 $B^g$ 重合。</p><h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p>引入 bbox 回归损失 $\mathcal L_{GIoU}$ 到2D目标检测器中如 Faster R-CNN、Mask R-CNN 和 YOLO v3，即，将原来 Faster R-CNN/Mask R-CNN 中的 $l_1$-smooth 损失和 YOLO v3 中的 MSE 损失替换为 $\mathcal L_{GIoU}$，并且我们还对比了 baseline 和使用 $\mathcal L_{IoU}$ 损失时的结果。记使用目标检测器原先的损失为 baseline。（具体实验数据和结果分析请参考原论文，这里省略）</p><p><strong>数据集</strong> 使用PASCAL VOC 和 MS COCO 数据集，训练方案的细节和对应的评估见下文。</p><p><strong>评估方案</strong> 本文采取 MS COCO 的性能测试方法，在所有分类上计算 mAP，计算在不同 IoU 阈值下的 mAP 值，IoU 阈值用于判断正负例（因为计算mAP需要知道正例数量），取阈值 $IoU=\{.5,.55,…,.95\}$，计算这些 IoU 阈值下 mAP 值的平均，记为 <strong>AP</strong>，然后使用 GIoU 代替 IoU 来判断正负例，同样取阈值 $GIoU=\{.5,.55,…,.95\}$，计算这些阈值下 mAP 的平均，<strong>AP</strong>，特别地，文中还报导了当 IoU 和 GIoU 阈值为 0.75 时的 mAP，记为 <strong>AP75</strong>。</p><h2 id="YOLO-v3"><a href="#YOLO-v3" class="headerlink" title="YOLO v3"></a>YOLO v3</h2><p><strong>训练方案</strong> 使用 YOLO v3 的 Darknet 使用版本。为了得到 Baseline 结果（使用 MSE 损失），我们使用 DarkNet-608 作为 backbone，训练所使用的参数与 YOLO v3 中一致。使用 IoU 和 GIoU 损失训练 YOLO v3 时，我们仅仅将原先的 MSE 损失替换为 $\mathcal L_{IoU}, \mathcal L_{GIoU}$，考虑到 MSE 损失无边界，我们的新损失则是有边界的，而 YOLO v3 损失还包含了分类损失，所以需要针对分类损失将 bbox 回归损失进行正则处理。当然，我们做了一个极小的努力来进行正则处理。</p><h2 id="Faster-R-CNN-和-Mask-R-CNN"><a href="#Faster-R-CNN-和-Mask-R-CNN" class="headerlink" title="Faster R-CNN 和 Mask R-CNN"></a>Faster R-CNN 和 Mask R-CNN</h2><p><strong>训练方案</strong> 使用最新的 Faster R-CNN/Mask R-CNN 的 PyTorch 实现。为了得到baseline结果（使用$l_1$-smooth损失），我们使用 ResNet-50 作为 backbone，其他训练所使用的参数与原先保持一致。当使用 IoU 和 GIoU 损失时，在最后的坐标改进阶段（而不是RPN阶段）使用 $\mathcal L_{IoU}, \mathcal L_{GIoU}$，与 YOLO v3 的情况一样，我们进行了极小的努力来进行正则处理。所有的实验中，简单的将 $\mathcal L_{IoU}, \mathcal L_{GIoU}$ 均乘以 10。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>介绍了 GIoU 作为新的指标来测量两个任意形状的距离。GIoU 继承了 IoU 的优秀特性且避免了 IoU 的缺点（非重叠情况），所以在基于 IoU 作为指标的 2D/3D 的计算机视觉任务中，GIoU 是一个很好的选择。</p><p>我们也提供了轴对齐的两个矩形之间 GIoU 的解析解。 GIoU 作为距离其导数/梯度可计算，故可以使用 GIoU 作为 bbox 回归损失。将 GIoU 损失结合进 sota 目标检测器，其检测性能在多个数据集上均一致得到提升。我们认为，指标自身就是针对指标的最优损失，GIoU 可以作为最佳 bbox 回归损失用于需要 2D bbox 回归的所有计算机视觉任务中。</p><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>这篇文章主要是提出了一个新的损失来优化模型，文章通俗易懂，实在没什么可分析的，于是就写成了翻译，也算是一种阅读记录吧。</p>]]></content>
      
      
      
        <tags>
            
            <tag> object detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch-2</title>
      <link href="/2019/06/13/pytorch/PyTorch-2/"/>
      <url>/2019/06/13/pytorch/PyTorch-2/</url>
      
        <content type="html"><![CDATA[<h1 id="torch-installization"><a href="#torch-installization" class="headerlink" title="torch installization"></a>torch installization</h1><span id="more"></span><p>依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是<br><pre class="line-numbers language-none"><code class="language-none">import torch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>于是阅读 <code>torch/__init__.py</code>，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，<br><pre class="line-numbers language-none"><code class="language-none">old_flags&#x3D;sys.getdlopenflags()sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)from torch._C import *__all__ +&#x3D; [name for name in dir(_C)            if name[0] !&#x3D; &#39;_&#39; and            not name.endswith(&#39;Base&#39;)]sys.setdlopenflags(old_flags)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><strong>将torch._C中（不包括_开头和Base结尾）的属性导出到当前域。</strong></p><p><code>__init__.py</code>除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，<br><pre class="line-numbers language-none"><code class="language-none">extern PyObject* initModule();PyMODINIT_FUNC PyInit__C()   &#x2F;&#x2F; 在python脚本中，import _C 时调用&#123;  return initModule();&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>根据python3扩展库的规则可知，<code>import torch._C</code> ，调用PyInit__C函数（调用名为PyInit_&lt;package&gt;的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。</p><p>shm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，<br><pre class="line-numbers language-none"><code class="language-none">set(LIBSHM_SUBDIR libshm)set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;&#x2F;lib&#x2F;$&#123;LIBSHM_SUBDIR&#125;)add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现<br><pre class="line-numbers language-none"><code class="language-none">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>TORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。</p><p>initModule方法定义在torch/csrc/Module.cpp，<br><pre class="line-numbers language-none"><code class="language-none">#ifdef USE_CUDAnamespace torch &#123; namespace cuda &#123;void initModule(PyObject* module);       &#x2F;&#x2F; 模块中有关cuda部分的初始化函数声明&#125;&#125;#endifstatic std::vector&lt;PyMethodDef&gt; methods;PyObject* module;PyObject* initModule() &#123;                 &#x2F;&#x2F; 声明并定义模块初始化函数  &#x2F;&#x2F; 向methods中添加方法定义  THPUtils_addPyMethodDefs(methods, TorchMethods);  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);  ...  &#x2F;&#x2F; 真正的扩展模块定义  static struct PyModuleDef torchmodule &#x3D; &#123;    PyModuleDef_HEAD_INIT,    &quot;torch._C&quot;,                          &#x2F;&#x2F; 扩展模块名    nullptr,                               -1,    methods.data()                       &#x2F;&#x2F; 模块中的方法定义  &#125;;  ASSERT_TRUE(module &#x3D; PyModule_Create(&amp;torchmodule)); &#x2F;&#x2F; 创建模块并确保创建成功  &#x2F;&#x2F; 对模块进行各种初始化#ifdef USE_CUDA  torch::cuda::initModule(module);       &#x2F;&#x2F; 执行cuda相关的初始化#endif  ...  &#x2F;&#x2F; 定义模块的属性设置函数，setter  &#x2F;&#x2F; 属性名为name，值为v，incref表示是否对值对象增加引用计数  &#x2F;&#x2F; 设置成功返回1，否则返回0  auto set_module_attr &#x3D; [&amp;](const char* name, PyObject* v, bool incref &#x3D; true)   &#123;    if(incref) &#123;      Py_INCREF(v);    &#125;    return PyModule_AddObject(module, name, v) &#x3D;&#x3D; 0;  &#125;  &#x2F;&#x2F; 设置模块属性  ...  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));  &#x2F;&#x2F; 向模块添加方法  auto py_module &#x3D; py::reinterpret_borrow&lt;py::module&gt;(module);  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);  ...    &#x2F;&#x2F; 设置模块其他属性  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;,         (PyObject*)THPDefaultGenerator, false));  torch::nn::init__THNN(module);  &#x2F;&#x2F; 增加 _THNN 属性#ifdef USE_CUDA  torch::nn::init_THCUDD(module);#endif  return module;  ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。</p><h1 id="methods-members-in-torch-C"><a href="#methods-members-in-torch-C" class="headerlink" title="methods/members in torch._C"></a>methods/members in torch._C</h1><ul><li>使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括<pre class="line-numbers language-none"><code class="language-none"># TorchMethods _initExtension_autograd_init...# DataLoaderMethods _set_worker_signal_handlers_set_worker_pids...# torch::autograd::python_functions(), torch&#x2F;csrc&#x2F;autograd&#x2F;init.cppset_grad_enabledis_grad_enabledset_anomaly_enabledis_anomaly_enabled# torch::multiprocessing::python_functions(), torch&#x2F;csrc&#x2F;multiprocessing&#x2F;init.cpp_multiprocessing_init# torch::distributed::c10d::python_functions()  同上类似...# THCPModule_method(), torch&#x2F;csrc&#x2F;cuda&#x2F;Module.cpp_cuda_init_cuda_setDevice..._nccl_version...# THCUDNN_method()_cudnn_version# THDPModule_methods(), torch&#x2F;csrc&#x2F;distributed&#x2F;Module.cpp_dist_init_extension_dist_init_process_group...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>生成模块torch._C 后再向其添加如下成员：</p><ul><li><p>向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。</p><p>  torch._C._TensorBase这个类型具有属性</p>  <pre class="line-numbers language-none"><code class="language-none">_cdata_versiongrad_fn_grad_fnis_leafdata_gradgrad...devicendim<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  并且具有以下方法</p>  <pre class="line-numbers language-none"><code class="language-none"># variable_methods, torch&#x2F;csrc&#x2F;autograd&#x2F;generated&#x2F;python_variable_methods.cpp__add____radd__...apply_bytecharcontiguous...wherezero_# extra_method_make_subclass<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  类型torch._C._FunctionBase， 这个类型具有方法和属性为</p>  <pre class="line-numbers language-none"><code class="language-none"># methodapply_do_forward_do_backward_register_hook_dictregister_hook# propertysaved_tensorssaved_variables...requires_gradmetadata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  类型 torch._C._VariableFunctions 包含方法</p>  <pre class="line-numbers language-python" data-language="python"><code class="language-python">arangeas_tensor<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>empty       <span class="token comment"># 出现我们这里所讨论的 torch.empty</span>empty_like<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。</p></li><li><p>向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。</p></li><li><p>向torch._C添加模块， _nn，cpp，_onnx。</p></li><li><p>向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。</p></li></ul></li></ul><h1 id="some-installization-w-r-t-torch-C"><a href="#some-installization-w-r-t-torch-C" class="headerlink" title="some installization w.r.t. torch._C"></a>some installization w.r.t. torch._C</h1><h3 id="THPxxxStorage-init"><a href="#THPxxxStorage-init" class="headerlink" title="THPxxxStorage_init"></a>THPxxxStorage_init</h3><p>torch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。</p><p>注意到从Module.cpp文件中头文件引用：<br><pre class="line-numbers language-none"><code class="language-none">#include &lt;TH&#x2F;TH.h&gt;               &#x2F;&#x2F; TH&#x3D;TorcH#include &lt;c10&#x2F;util&#x2F;Logging.h&gt;#include &lt;ATen&#x2F;ATen.h&gt;...#include &lt;torch&#x2F;csrc&#x2F;THP.h&gt;      &#x2F;&#x2F; THP&#x3D;TorcH Python...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。</p><p>一方面，头文件 TH/TH.h 中引用了#include <TH/THGeneral.h>，在aten/src/TH目录下的CMakeLists.txt中有这么一行<br><pre class="line-numbers language-none"><code class="language-none">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;&#x2F;THGeneral.h&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>在THGeneral.h中有如下宏定义<br><pre class="line-numbers language-none"><code class="language-none">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>另一方面，torch/csrc/THP.h 中引用了#include <torch/src/Storage.h>，在这个Storage.h中有如下语句<br><pre class="line-numbers language-none"><code class="language-none">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)...#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;#include &lt;TH&#x2F;THGenerateAllType.h&gt;#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;#include &lt;TH&#x2F;THGenerateHalfType.h&gt;#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;#include &lt;TH&#x2F;THGenerateBoolType.h&gt;#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;#include &lt;TH&#x2F;THGenerateQTypes.h&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句<br><pre class="line-numbers language-none"><code class="language-none">#ifndef TH_GENERIC_FILE#define TH_GENERIC_FILE &quot;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&quot;         &#x2F;&#x2F; (0)#else...bool THPStorage_(init)(PyObject *module);                      &#x2F;&#x2F; (1)...#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>而文件TH/THGenerateAllType.h则包含语句<br><pre class="line-numbers language-none"><code class="language-none">#include &lt;TH&#x2F;THGenerateFloatTypes.h&gt;#include &lt;TH&#x2F;THGenerateIntTypes.h&gt;...#undef TH_GENERIC_FILE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有<br><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 此时 TH_GENERIC_FILE是已定义的#include &lt;TH&#x2F;THGenerateFloatType.h&gt;#include &lt;TH&#x2F;THGenerateDoubleType.h&gt;#undef TH_GENERIC_FILE     &#x2F;&#x2F; 这里将TH_GENERIC_FILE 设为未定义<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>以TH/THGenerateFloatType.h为例说明，此文件中有语句<br><pre class="line-numbers language-none"><code class="language-none">#define Real Float...#line 1 TH_GENERIC_FILE#include TH_GENERIC_FILE         &#x2F;&#x2F; (2)...#undef Real<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换<br><pre class="line-numbers language-none"><code class="language-none">bool THPStorage_(init)(PyObject *module);  -&gt;bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;bool THPFloatStorage_init(PyObject *module);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>类似地，#include <TH/THGenerateDoubleType.h>，则得到THPDoubleStorage_init，</p><h1 id="include-得到"><a href="#include-得到" class="headerlink" title="include  得到"></a>include <TH/THGenerateIntTypes.h> 得到</h1><pre class="line-numbers language-none"><code class="language-none">THPByteStorage_initTHPCharStorage_initTHPShortStorage_initTHPIntStorage_initTHPLongStorage_init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对4组include中的其他三组，则得到<br><pre class="line-numbers language-none"><code class="language-none">THPHalfStorage_initTHPBoolStorage_initTHPQUInt8Storage_initTHPQInt8Storage_initTHPQInt32Storage_init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含<br><pre class="line-numbers language-none"><code class="language-none">#include &lt;TH&#x2F;THStorageFunctions.hpp&gt;#include &lt;torch&#x2F;csrc&#x2F;THP.h&gt;                   &#x2F;&#x2F; include THPxxxStorage_init 函数声明...#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;#include &lt;TH&#x2F;THGenerateAllTypes.h&gt;#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;#include &lt;TH&#x2F;THGenerateHalfType.h&gt;#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;#include &lt;TH&#x2F;THGenerateBoolType.h&gt;#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;#include &lt;TH&#x2F;THGenerateQTypes.h&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，<br><pre class="line-numbers language-none"><code class="language-none">#ifndef TH_GENERIC_FILE#define TH_GENERIC_FILE &quot;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&quot;              &#x2F;&#x2F; (11)#else...                                                                   &#x2F;&#x2F; (12)bool THPStorage_(init)(PyObject *module)&#123;  static std::vector&lt;PyMethodDef&gt; methods;  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));#ifndef THD_GENERIC_FILE  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);#endif    THPStorageType.tp_methods &#x3D; methods.data();  THPStorageType.tp_members &#x3D; THPStorage_(members);  THPStorageType.tp_getset &#x3D; THPStorage_(properties);  if (PyType_Ready(&amp;THPStorageType) &lt; 0)    return false;  Py_INCREF(&amp;THPStorageType);  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);  THPStorage_(initCopyMethods)();  return true;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏<br><pre class="line-numbers language-none"><code class="language-none">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>在TH/THGeneral.h中存在宏定义<br><pre class="line-numbers language-none"><code class="language-none">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为”FloatStorageBase”，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。</p><p>以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据<br><pre class="line-numbers language-none"><code class="language-none">#define Real Float...#include TH_GENERIC_FILE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。</p><p>其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。</p><p>torch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。</p><p>现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，<br><pre class="line-numbers language-none"><code class="language-none">PyTypeObject THPStorageType &#x3D; &#123;  PyVarObject_HEAD_INIT(nullptr, 0)  &quot;torch._C.&quot; THPStorageBaseStr,               &#x2F;* tp_name *&#x2F;  sizeof(THPStorage),                          &#x2F;* tp_basicsize *&#x2F;  ...  THPStorage_(pynew),                          &#x2F;* tp_new *&#x2F;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义<br><pre class="line-numbers language-none"><code class="language-none">struct THPStorage &#123;  PyObject_HEAD  THWStorage *cdata;&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）</p><p>然后查看类创建 THPStorage_(pynew) 的定义<br><pre class="line-numbers language-none"><code class="language-none">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)&#123;  Py_ssize_t num_args &#x3D; args ? PyTuple_Size(args) : 0;   &#x2F;&#x2F; 可变长度参数的个数  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); &#x2F;&#x2F; 分配内存，让self指向这个内存块  ...  c10::Allocator * allocator &#x3D; nullptr;  if (kwargs !&#x3D; nullptr) &#123;                               &#x2F;&#x2F; named arguments    PyObject *allocator_ptr &#x3D; PyDict_GetItemString(kwargs, &quot;allocator&quot;); &#x2F;&#x2F; 获取参数allocator的值    if (allocator_ptr) &#123;      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);      &#x2F;&#x2F; 转为 c10::Allocator 指针      allocator &#x3D; static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));      PyDict_DelItemString(kwargs, &quot;allocator&quot;);    &#125;    Py_ssize_t num_kwargs &#x3D; PyDict_Size(kwargs);    if (num_args &#x3D;&#x3D; 0) &#123;      PyObject *cdata_ptr &#x3D; PyDict_GetItemString(kwargs, &quot;cdata&quot;);      if (num_kwargs&#x3D;&#x3D;1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   &#x2F;&#x2F; 提供了cdata值        THWStorage *ptr &#x3D; (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);        self-&gt;cdata &#x3D; ptr;        return (PyObject*)self.release();       &#x2F;&#x2F; 返回THPStorage指针      &#125;    &#125;    THPUtils_assert(num_kwargs &#x3D;&#x3D; 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);  &#125;  if (num_args &#x3D;&#x3D; 0) &#123;    if (allocator) &#123;                            &#x2F;&#x2F; 未提供cdata值，则需要创建THWStorage类型实例      self-&gt;cdata &#x3D; THPStorage_(newWithAllocator)(0, allocator);    &#125; else &#123;      self-&gt;cdata &#x3D; THWStorage_(new)(LIBRARY_STATE_NOARGS);    &#125;    return (PyObject*)self.release();  &#125;  ...     &#x2F;&#x2F; 使用其他方法设置 self-&gt;cdata&#125;   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义<br><pre class="line-numbers language-none"><code class="language-none">#define THWStorage THStorage<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，<br><pre class="line-numbers language-none"><code class="language-none">Storage.cpp                 -&gt;#include &lt;TH&#x2F;TH.h&gt;          -&gt;#include &lt;TH&#x2F;THStorageFunction.h&gt;   -&gt;#include &lt;TH&#x2F;generic&#x2F;THStorage.h&gt;   -&gt;#include &lt;c10&#x2F;core&#x2F;StorageImpl.h&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>在 TH/generic/THStorage.h 中找到宏定义<br><pre class="line-numbers language-none"><code class="language-none">#define THStorage at::StorageImpl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>在 c10/core/StorageImpl.h 中找到结构定义<br><pre class="line-numbers language-none"><code class="language-none">namespace c10 &#123;struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;...private:  caffe2::TypeMeta  data_type_;  &#x2F;&#x2F; 数据类型  DataPtr data_ptr_;             &#x2F;&#x2F; 数据指针  int64_t numel_;                &#x2F;&#x2F; 数据数量  bool resizable_;  bool received_cuda_;  Allocator* allocator_;         &#x2F;&#x2F; 数据的内存分配器&#125;;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为<br><pre class="line-numbers language-none"><code class="language-none">new                &#x2F;&#x2F; 新建THStorage，未指定 size，即size&#x3D;0，使用默认AllocatorfreesizegetsetdatanewWithSize        &#x2F;&#x2F; 新建THStorage，指定 size，使用默认AllocatornewWithAllocator   &#x2F;&#x2F; 新建THStorage，指定 size 和 Allocatorcopy_functionscopyByte...copyCudaByte...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>此外有宏定义<br><pre class="line-numbers language-none"><code class="language-none">#define THWStorage_(NAME) THStorage_(NAME)     &#x2F;&#x2F; torch&#x2F;csrc&#x2F;THP.h#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   &#x2F;&#x2F; TH&#x2F;THStorageFunctions.h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。</p><p>（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）</p><p>以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义<br><pre class="line-numbers language-none"><code class="language-none">THStorage* THStorage_(newWithSize)(ptrdiff_t size)&#123;  THStorage* storage &#x3D; c10::make_instrusive&lt;at::StorageImpl&gt;(#ifdef THQUANTIZED    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),#else    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        &#x2F;&#x2F; 新建scalar_t 类型#endif    size,    getTHDefaultAllocator(),    true).release();  return storage;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，<br><pre class="line-numbers language-none"><code class="language-none">StorageImpl(    caffe2::TypeMeta data_type,    int64_4 numel,    at::Allocator* allocator,    bool resizable)...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>我们看上上个代码片段中StorageImpl构造函数的实参，</p><p>首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）<br><pre class="line-numbers language-none"><code class="language-none">#define scalar_t float<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>于是，<br><pre class="line-numbers language-none"><code class="language-none">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    &#x2F;&#x2F; 假设 THQUANTIZED 未定义<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>caffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，<br><pre class="line-numbers language-none"><code class="language-none">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \  namespace detail &#123;                                                       \  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) &#x3D;    \    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \  &#125;                                                                        \  template&lt;&gt;                                                               \  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \  &#125;  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)#define C10_CONCATENATE_IMPL(s1,s2) s1##s2#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>经过宏替换，得到 _typeMetaDataInstance的模板函数定义<br><pre class="line-numbers language-none"><code class="language-none">template&lt;&gt;const detail::TypeMetaData*TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>还有一组宏，用于生成模板特例化，<br><pre class="line-numbers language-none"><code class="language-none">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \  template&lt;&gt;                                                           \  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \    return TypeIdentifier(PreallocatedId);                             \  &#125;                                                                    \  namespace detail &#123;                                                   \  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \    _typeMetaDataInstance_preallocated_,                               \    PreallocatedId);                                                   \  &#125;                                                                    \  template&lt;&gt;                                                           \  inline const detail::TypeMetaData*                                   \  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \    return &amp;C10_CONCATENATE(                                           \      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \  &#125;                                                                    \#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \  namespace detail &#123;                                                 \  const TypeMetaData C10_CONCATENATE(                                \    _typeMetaDataInstance_preallocated_,                             \    PreallocatedId) &#x3D; _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\  &#125;                                                                  &#x2F;&#x2F; 调用CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>对于系统内部变量如 float，得到函数模板特例化的定义<br><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 函数声明namespace detail &#123;__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData_typeMetaDataInstance_preallocated_Preallocated;&#125;template&lt;&gt;inline const detail::TypeMetaData*TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>另外，在c10/util/typeid.cpp中有如下调用<br><pre class="line-numbers language-none"><code class="language-none">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>经过宏替换得到<br><pre class="line-numbers language-none"><code class="language-none">namespace detail &#123;                                                   const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId    &#x3D; _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));&#125;   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>于是函数模板特例化最终形式为，<br><pre class="line-numbers language-none"><code class="language-none">template&lt;&gt;inline const detail::TypeMetaData*TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>detail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，<br><pre class="line-numbers language-none"><code class="language-none">struct TypeMetaData final &#123;&#x2F;&#x2F; 函数类型的别名using New &#x3D; void*();                            &#x2F;&#x2F; newusing PlacementNew &#x3D; void(void*, size_t);       &#x2F;&#x2F; 占位newusing Copy &#x3D; void(const void*, void*, size_t);  &#x2F;&#x2F; 类型数组拷贝using PlacementDelete &#x3D; void(void*, size_t);using Delete &#x3D; void(void*);... &#x2F;&#x2F;构造函数size_t itemsize_;  &#x2F;&#x2F; 类型占多少字节New* new_;PlacementNew* placementNew_;   &#x2F;&#x2F; 定位放置 newCopy* copy_;        &#x2F;&#x2F; 类型拷贝Delete* delete_;    &#x2F;&#x2F; 类型析构TypeIdentifier id_; &#x2F;&#x2F; 类型全局唯一idconst char* name_;  &#x2F;&#x2F; 类型名称&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义<br><pre class="line-numbers language-none"><code class="language-none">template &lt;class T&gt;inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;  return &#123;sizeof(T),                 &#x2F;&#x2F; 类型T占多少字节          _PickNew&lt;T&gt;(),             &#x2F;&#x2F; 通过 new T          _PickPlacementNew&lt;T&gt;(),          _PickCopy&lt;T&gt;(),                _PickPlacementDelete&lt;T&gt;(),          _PickDelete&lt;T&gt;(),          TypeIdentifier::Get&lt;T&gt;(),  &#x2F;&#x2F; 获取类型的全局唯一id，          typeName&#125;;                 &#x2F;&#x2F; 类型名称，例如float的名称为&quot;float&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用<br><pre class="line-numbers language-none"><code class="language-none">TypeIdentifier::Get&lt;T&gt;()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。</p><p>对于其他类型如 int，double，int64_t等类似处理。</p><p>PyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。</p><p>至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为<br><pre class="line-numbers language-none"><code class="language-none">size,             &#x2F;&#x2F; 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）getTHDefaultAllocator(),  &#x2F;&#x2F; 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配true                      &#x2F;&#x2F; 被构造的StorageImpl可以resize<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase</p><p>记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。</p><p>FloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。</p><p>类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，<br><pre class="line-numbers language-none"><code class="language-none">  torch::nn::init_THNN(module);#ifdef USE_CUDA  torch::nn::init_THCUNN(module);#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。</p><p><code>torch._C</code>模块初始化过程到这里就完成了。回到 <code>torch/__init__.py</code>，继续看看 import torch时接下来做了哪些事情：</p><ol><li>定义了模块函数 typename，is_tensor，is_storage等</li><li>导入torch下其他子模块</li><li>调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理</li><li>调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：<ul><li>初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；</li><li>初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；</li><li>初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；</li><li>初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor</li><li>共享内存管理初始化，设置文件路径；</li><li>执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），  <pre class="line-numbers language-none"><code class="language-none">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, TH_CONCAT_2(at::k, Real));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>  其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，  <pre class="line-numbers language-none"><code class="language-none">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>  这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。</li></ul></li></ol><p>到这里，import torch 的工作全部完成。</p><h1 id="后记："><a href="#后记：" class="headerlink" title="后记："></a>后记：</h1><p>初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。</p>]]></content>
      
      
      <categories>
          
          <category> DL Framework </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Sync</title>
      <link href="/2019/06/13/tools/Hexo-Sync/"/>
      <url>/2019/06/13/tools/Hexo-Sync/</url>
      
        <content type="html"><![CDATA[<p>场景：<br><pre class="line-numbers language-none"><code class="language-none">在A, B两台电脑上同步Hexo博客<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br><span id="more"></span><br>假设在 computer B 上已经初次建立hexo博客 <a href="https://shajian.github.io，">https://shajian.github.io，</a> computer B 本地的文件夹（hexo部署环境目录）为 path/to/myblog，其内部文件/目录如下：<br><pre class="line-numbers language-none"><code class="language-none">_config.ymldb.jsonnode_modulespackage.jsonpackage-lock.jsonpublicscaffoldssourcethemes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>在github仓库 shajian.github.io 上新建branch，比如”hexo”，这样，”mater”主分支用于维护hexo生成的静态博客文件/目录，”hexo”分支用于维护hexo部署环境下的所有文件/目录。</p><p>在 computer A 上 clone 这个仓库，并切换到 hexo 分支，<br><pre class="line-numbers language-none"><code class="language-none">$ git clone https:&#x2F;&#x2F;github&#x2F;shajian&#x2F;shajian.github.io.git$ cd shajian.github.io$ git checkout hexo$ git branch* hexo  master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>将目录 shajian.github.io 内的所有文件/目录全部删除，然后将 path/to/myblog内的全部内容复制过来，<br><pre class="line-numbers language-none"><code class="language-none">$ rm -rf .# do not use &quot;cp -R path&#x2F;to&#x2F;myblog&#x2F;* .&#x2F;&quot; which ignores hidden files&#x2F;directories$ cp -R path&#x2F;to&#x2F;myblog&#x2F;. .&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>然后可在使用<br><pre class="line-numbers language-none"><code class="language-none">hexo new &quot;&lt;title&gt;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>写新文章或直接去source/_posts下修改已有文章，<br>部署<br><pre class="line-numbers language-none"><code class="language-none">hexo g -d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>上面这个命令将文章更新到远程网站上，我这里配置为 github 上 master 分支，</p><p>然后提交到仓库的hexo分支，进行备份，注意最后一个命令中 <code>hexo</code> 必须要带上，<br><pre class="line-numbers language-none"><code class="language-none">$ git add .$ git commit -m &quot;new post &#39;title&#39;&quot;$ git push origin hexo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></p><p>然后就可以去 <a href="https://shajian.github.io">https://shajian.github.io</a> 浏览本地新增/修改文章内容了。</p><p>通常，个人都是一直保持在 <code>hexo</code> 这个 git 分支下操作，包括 <code>hexo g -d</code> 部署到远程网站，以及上面三个命令将源码提交到远程 <code>hexo</code> 分支下。</p><p>在 computer B 上删除 path/to/myblog 目录，然后重新 clone 仓库，并切换到 hexo 分支，<br><pre class="line-numbers language-none"><code class="language-none">$ git clone https:&#x2F;&#x2F;github&#x2F;shajian&#x2F;shajian.github.io.git$ cd shajian.github.io$ git checkout hexo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>如果仓库有 .gitignore 文件且包含 node_modules 目录，则执行<br><pre class="line-numbers language-none"><code class="language-none">$ npm install<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>此时，要修改还是新增文章，步骤均与上面 computer A上的操作一致。</p><p>computer A 和 B 本地均有仓库后，以后每次修改还是新增文章，首先需要将仓库更新到最新<br><pre class="line-numbers language-none"><code class="language-none">$ git checkout master$ git pull origin master$ git checkout hexo$ git pull origin hexo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>切换到 hexo 分支后，可以进行修改和新增文章了。</p><p>由于 .depoly_git 下其实就是对应 master 主分支的内容，这也是一个git 仓库目录，内含 .git 文件夹，所以提交的时候无法提交 .deploy_git 内部的文件/目录，不过这个没关系，例如前面，在 computer B 上 clone 仓库后，执行<br><pre class="line-numbers language-none"><code class="language-none">hexo g -d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>由 hexo 向 .deploy_git 填充生成的文件/目录，而不需要在 hexo 分支上备份这些内容。</p><h3 id="在本地环境中预览主题"><a href="#在本地环境中预览主题" class="headerlink" title="在本地环境中预览主题"></a>在本地环境中预览主题</h3><pre class="line-numbers language-none"><code class="language-none">hexo s<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="hexo-新建自定义路径的文章"><a href="#hexo-新建自定义路径的文章" class="headerlink" title="hexo 新建自定义路径的文章"></a>hexo 新建自定义路径的文章</h2><p>有时候为了方便管理文章，需要将文章归入不同的子目录下。例如，<br><pre class="line-numbers language-none"><code class="language-none">hexo new -p pytorch&#x2F;optim_Adadelta &quot;PyTorch.optim.Adadelta&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>表示新建文章，标题为 <code>PyTorch.optim.Adadelta</code>，文章所在文件位于 <code>source/_posts/pytorch/optim_Adadelta.md</code>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch-1</title>
      <link href="/2019/06/12/pytorch/PyTorch-1/"/>
      <url>/2019/06/12/pytorch/PyTorch-1/</url>
      
        <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>一直以来就对深度学习的框架源码有着浓厚兴趣，但是由于涉及到的领域较多，C++，python，CUDA，数学等，加上时间也比较零碎，就耽搁至今，后来意识到我不可能等完全弄明白之后再来写博客记录，毕竟能力不足，所以还是边看源码边记录，不求完全搞明白，但求能从整体上有个大致的理解，如果还能整明白一些数学计算上的代码实现，那就再好不过了。<br><span id="more"></span><br>当前最流行的深度学习框架就是tensorflow和pytorch了，但是tensorflow据说代码工业化程度非常高，我等菜鸡先避其锋芒，来分析pytorch，希望能给自己带来点信心。</p><p>下载源码<br><pre class="line-numbers language-none"><code class="language-none">git clone --recursive https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><p>由于使用了子模块所以增加—recursive选项，记pytorch的root dir为$ROOT_DIR。</p><p>根据安装步骤进行自上而下的阅读。Linux下安装使用命令<br><pre class="line-numbers language-none"><code class="language-none">cd pytorchpython setup.py install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>pytorch底层计算使用C++实现，并提供了python调用接口，所以这一命令就是使用setuptools安装python包，安装依赖库及修改配置项这里均跳过，故直接看$ROOT_DIR/setup.py中的setup()方法，但是在这个方法之前先执行了build_deps()用于生成有关 caffe2 的依赖库</p><h3 id="build-deps"><a href="#build-deps" class="headerlink" title="build_deps()"></a>build_deps()</h3><p>这个方法内部关键的一步为<br><pre class="line-numbers language-none"><code class="language-none">build_caffe2(...)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>查看这个方法的定义，发现build_caffe2做了如下几件事：</p><ol><li>run_cmake。执行cmake，这个命令的选项这里省略不展开，注意执行cmake这个命令的工作目录为<code>$ROOD_DIR/build</code>， cmake的Source Tree为$ROOD_DIR，这个 目录下存在top level的CMakeLists.txt</li><li>在$ROOT_DIR/build下编译并安装，使用make install或者 ninja install（cmake生成的Makefile中install这个target包含了build这个步骤）</li><li>将build/caffe2/proto下的所有.py文件 拷贝到caffe2/proto/下，这些.py文件是根据caffe2/proto/下的.proto文件生成</li></ol><p>这其中最复杂的部分就是run_cmake了，先是使用cmake的-D option设置一些cmake的变量，然后对source tree应用cmake， 查看top level的CMakeLists.txt，这个文件看着好像特别庞大，实际上做的事情也就那么几种：1)设置变量，根据不同操作系统设置或修改变量；2)设置include dir以及lib dir；3）加载.cmake文件以使用其中自定义的cmake函数；4）设置C++文件编译选项；5）安装配置文件/目录到指定位置等；我们注意比较关键的语句如下：<br><pre class="line-numbers language-none"><code class="language-none">add_subdirectory(c10)add_subdirectory(caffe2)add_subdirectory(modules)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>这表明将c10,caffe2,modules等目录添加进build tree，这些目录下必定也有相应的CMakeLists.txt， 所以需要继续查看这些CMakeLists.txt中定义了哪些生成规则。</p><p>另外，top level 中CMakeLists.txt中有这么一行<br><pre class="line-numbers language-none"><code class="language-none">include(cmake&#x2F;Dependencies.cmake)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>这个Dependencies.cmake指明安装Caffe2所依赖的各种库，其中一些库位于本项目中如<code>$ROOT_DIR/third_party</code>或$ROOT_DIR/caffe2，还有一些库则是需要预先手动安装的，举个例子：</p><ol><li>非本项目的公共库，比如添加BLAS库依赖，假设最开始设置了环境变量BLAS=OpenBLAS（环境变量的设置可参考setup.py文件头部注释）, 那么选择添加OpenBLAS库依赖，在Dependencies.cmake中代码为<pre class="line-numbers language-none"><code class="language-none">...elseif(BLAS STREQUAL &quot;OpenBLAS&quot;)  find_package(OpenBLAS REQUIRED)  include_directories(SYSTEM $&#123;OpenBLAS_INCLUDE_DIR&#125;)  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS $&#123;OpenBLAS_LIB&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>这个find_package告诉我们去查看<code>$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake</code>，好的我们跳过去看一下这个.cmake文件，发现其定义了OpenBLAS的头文件和库文件的搜索路径，然后根据这些搜索路径分别搜索头文件cblas.h所在目录以及库名openblas， 分别使用变量OpenBLAS_INCLUDE_DIR和OpenBLAS_LIB保存，从上面的代码片段，我们知道搜索到的库名被添加到Caffe2_PUBLIC_DEPENDENCY_LIBS中，而我们再跳至$ROOT_DIR/caffe2/CMakeLists.txt发现其中有<pre class="line-numbers language-none"><code class="language-none">target_link_libraries(caffe2 PUBLIC $&#123;Caffe2_PUBLIC_DEPENDENCY_LIBS&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>这就相当于能生成-lopenblas这样的链接选项。</li></ol><p>我们直接再看另一个库caffe2_pybind11_state的生成，因为下文会提到它，查看$ROOT_DIR/caffe2/CMakeLists.txt发现<br><pre class="line-numbers language-none"><code class="language-none">add_subdirectory(python)...add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)install(TARGETS caffe2_pybind11_state DESTINATION &quot;$&#123;PYTHON_LIB_REL_PATH&#125;&#x2F;caffe2&#x2F;python&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>其中Caffe2_CPU_PYTHON_SRCS在$ROOT_DIR/caffe2/python/CMakeLists.txt中设置， 类似地，还根据是否使用CUDA或者ROCM , 生成caffe2_pybind11_state_gpu或caffe2_pybind11_state_hip。生成这些库文件后，直接install到python的site-packages目录下的caffe2/python目录中</p><p>以上就是build_dep()这个方法介绍，接着看$ROOT_DIR/setup.py中的setup方法。</p><h3 id="setup"><a href="#setup" class="headerlink" title="setup()"></a>setup()</h3><p>setup方法（可以参考<a href="https://docs.python.org/3/distutils/apiref.html">setup()</a>），其中几个值得说明的参数：</p><ol><li>ext_modules 有5个扩展库分别如下：</li></ol><ul><li>torch._C 指定了C++源文件，链接库，编译选项，链接选项和头文件/库dir</li><li>torch._dl 非WINDOWS平台下才有，指定了C源文件</li><li>caffe2.python.caffe2_pybind11_state</li><li>caffe2.python.caffe2_pybind11_state_gpu</li><li>caffe2.python.caffe2_pybind11_state_hip</li></ul><p>后三个库在上一步中其实已经生成好了，其中caffe2.python前缀表示两级目录（package），可以在$ROOT_DIR/build/caffe2/python目录下查看。扩展模块ext_modules在build_ext这个动作中生成。</p><ol><li>cmdclass，重写了build_ext, clean, install这几个action，这个action用在python setup.py <action> 命令中。install动作跟默认一致。 clean是清除编译过程中产生的临时文件，这些临时文件的pattern在.gitignore中给定。我们重点看一下build_ext这个动作对应的类build_ext，其中方法包含</li></ol><ul><li>create_compile_commands这是一个自定义方法，用于将compile_commands.json中的gcc编译器改为g++，修改原因代码注释写的很清楚，使用gcc编译s时不会include c++的头文件目录。 文件compile_commands.json是根据<code>$ROOT_DIR/CMakeLists.txt中的set(CMAKE_EXPORT_COMPILE_COMMAND ON)</code>这句代码而生成，所以位于$ROOT_DIR/build目录下，这个json文件中指明了编译各个文件时的工作路径（working directory），编译指令（command）以及被编译的原文件，格式如下<pre class="line-numbers language-none"><code class="language-none">[&#123;  &quot;directory&quot;:&quot;&lt;path&#x2F;to&#x2F;root&gt;build&#x2F;third_party&#x2F;protobuf&#x2F;cmake&quot;,  &quot;command&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;c++ ... -I&lt;path&#x2F;to&#x2F;root&gt;&#x2F;third_party&#x2F;protobuf&#x2F;src ...                 -o CMakeFiles&#x2F;libprotobuf.dir&#x2F;__&#x2F;src&#x2F;google&#x2F;protobuf&#x2F;arena.cc.o ...&quot;,  &quot;file&quot;: &quot;&lt;path&#x2F;to&#x2F;root&gt;&#x2F;third_party&#x2F;protobuf&#x2F;src&#x2F;google&#x2F;protobuf&#x2F;arena.cc&quot;&#125;,...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>其中每个{…}块表示编译一个源文件到目标文件 .o。 将文件中gcc改为g++后重新保存为$ROOT_DIR/compile_commands.json。</li><li>run打印各library（比如 CUDA, CUDNN, NUMPY等）的使用情况，然后执行基类同名方法的逻辑</li><li>build_extensions 生成由ext_modules指定的python扩展库所用的方法</li></ul><p>ext_modules中添加了5个扩展，后三个扩展在build_deps()中已经生成并安装，当然，caffe2_pybind11_state_gpu和caffe2_pybind11_state_hip是根据配置决定是否生成，配置了CUDA则生成前者，配置了ROCM则生成后者，如果均未配置，则这两个扩展均不生成。既然在build_deps()中已经生成并安装，所以这里将其从ext_modules中删除，于是build_extensions实际上只生成torch._C, torch._dl这两个扩展库。</p><p>然而，除了build_deps()方法还有其他方法可用于生成ext_modules中 的后三个扩展库，生成路径为<code>$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/</code>，所以需要判断在这个路径下是否存在后三个扩展库，若不在（此时就是前面所说的使用build_deps()生成），则将扩展库名称从ext_modules中予以删除， 若存在，则还需则将其拷贝到生成目录<code>$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/</code>下，并修改拷贝后的文件名称，以caffe2.python.caffe2_pybind11_state为例说明，两级前缀表示目录所以最终的目录为<code>$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/</code>，剩余的caffe2_pybind11_state表示扩展库的文件名，还需要添加后缀名，这个后缀名由系统平台和python版本，我这里是.cpython-37m-x86_64-linux-gnu.so，于是拷贝后得到文件$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so ，这样使用基类的build_extensions()方法才能将其进一步安装到 python的site-packages目录下，我这里是…/miniconda3/lib/python3.7/site-packages/caffe2/python/目录。</p><ol><li>packages 指定安装到python 的site-packages下的包<pre class="line-numbers language-none"><code class="language-none">packages &#x3D; find_packages(exclude&#x3D;[&#39;tools&#39;, &#39;tools.*&#39;])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p>由于PyTorch项目中除tools之外，只有caffe2和torch两个目录包含<strong>init</strong>.py，所以将caffe2和torch两个包安装到site-packages下。</p><p>现在再回头看看ext_modules中指定的5个扩展，不难得知，其中torch._C, torch._dl这两个扩展安装到site-packages/torch下，扩展包名称分别为_C, _dl（省略了文件ext后缀），而另外三个caffe2有关的扩展则根据名称（.号切分，前面都是目录名，最后一个是文件名）知道其安装在site-packages/caffe2/python下。</p><h3 id="整理"><a href="#整理" class="headerlink" title="整理"></a>整理</h3><p>以上就是pytorch安装过程，主要分为两部分:</p><ol><li>使用CMake生成c++库，对应build_deps()这个方法执行</li><li>使用python的setup方法生成扩展库，主要是build_ext。</li></ol><p>根据上面两点，重新整理一遍。<br><pre class="line-numbers language-none"><code class="language-none">top-level的CMakeLists.txt中add_subdirectory(c10)add_subdirectory(caffe2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>于是先看caffe2这个目录下的CMakeLists.txt， 寻找其中的关键语句，<br><pre class="line-numbers language-none"><code class="language-none">add_library(caffe2_proto STATIC $&lt;TARGET_OBJECTS:Caffe2_PROTO&gt;add_library(thnvrtc SHARED $&#123;TORCH_SRC_DIR&#125;&#x2F;csrc&#x2F;jit&#x2F;fuser&#x2F;cuda&#x2F;thnvrtc.cpp&gt;add_library(caffe2 $&#123;Caffe2_CPU_SRCS&#125;)if (TORCH_STATIC)  add_library(torch STATIC $&#123;DUMMY_EMPTY_FILE&#125;)else()  add_library(torch SHARED $&#123;DUMMY_EMPTY_FILE&#125;)endif()torch_cuda_based_add_library(caffe2_gpu $&#123;Caffe2_GPU_SRCS&#125;)hip_add_library(caffe2_hip $&#123;Caffe2_HIP_SRCS&#125;)add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)add_library(caffe2_pybind11_state_gpu MODULE $&#123;Caffe2_GPU_PYTHON_SRCS&#125;)add_library(caffe2_pybind11_state_hip MODULE $&#123;Caffe2_HIP_PYTHON_SRCS&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>安装目录则寻找对应的install语句。此外，文件中还有一句<br><pre class="line-numbers language-none"><code class="language-none">add_subdirectory(..&#x2F;torch torch)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>（实际上caffe2目录下CMakeLists.txt中存在很多add_subdirectory，但是都是类似的处理过程，所以不一一说明，仅以torch这个目录进行说明）</p><p>于是查看torch目录下的CMakeLists.txt， 其中生成的库为<br><pre class="line-numbers language-none"><code class="language-none">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>然后根据其中的<br><pre class="line-numbers language-none"><code class="language-none">set(LIBSHM libshm)set(LIBSHM_SRCDIR $&#123;TORCH_SRC_DIR&#125;&#x2F;lib&#x2F;$&#123;LIBSHM_SUBDIR&#125;)add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>继续查看torch/lib/libshm下的CMakeLists.txt，其中生成的库为<br><pre class="line-numbers language-none"><code class="language-none">ADD_LIBRARY(shm SHARED core.cpp)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>有关的库依赖，分为预装库和本项目（pytorch）内包含的库，CMake生成规则位于cmake/Dependencies.cmake文件中，仔细查看该文件发现：</p><ul><li>预先装的库依赖，这些库名存在Caffe2_PUBLIC_DEPENDENCY_LIBS中。如上文所举例子OpenBLAS 那样添加g++的链接flag和 <code>-I&lt;include dir&gt;flag</code>。</li><li>本项目内包含的库。包括：<br>(1) tbb<pre class="line-numbers language-none"><code class="language-none">add_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;cpu&#x2F;tbb)    # 添加tbb库<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>(2) qnnpack<pre class="line-numbers language-none"><code class="language-none"># 添加 qnnpack 库# source directory为$&#123;PROJECT_SOURCE_DIR&#125;&#x2F;third_party&#x2F;QNNPACK# output directory为$&#123;PROJECT_BINARY_DIR&#125;&#x2F;confu-deps&#x2F;QNNPACKadd_subdirectory(&quot;$&#123;QNNPACK_SOURCE_DIR&#125;&quot; &quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;&#x2F;QNNPACK&quot;)list(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>最后一行指引CMake去QNNPACK的目录（位于third_party下）去生成qnnpack库，然后回到Dependencies.cmake中添加到Caffe2_DEPENDENCY_LIBS中。<br>(3) nnpack<pre class="line-numbers language-none"><code class="language-none"># 添加 nnpackinclude($&#123;CMAKE_CURRENT_LIST_DIR&#125;&#x2F;External&#x2F;nnpack.cmake)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>跳至nnpack.cmake文件，发现其中包含<pre class="line-numbers language-none"><code class="language-none">add_subdirectory($&#123;NNPACK_SOURCE_DIR&#125; $&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;&#x2F;NNPACK)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>找到包含NNPACK的代码目录位于third_party下，显然这个NNPACK也应该包含CMakeLists.txt文件指示CMake 生成nnpack库，然后回到Dependencies.cmake中将nnpack添加到Caffe2_DEPENDENCY_LIBS。</li></ul><p>(4) 类似地，还添加了 cpuinfo，gflag，glog::glog，googletest，fbgemm，fp16等。这些也不一定全部使用，是否使用还得看相应配置</p><p>(5) LMDB。使用如下语句<br><pre class="line-numbers language-none"><code class="language-none">find_package(LMDB)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>所以去cmake/Modules目录下寻找FindLMDB.cmake， 在这个.cmake文件中寻找lmdb库以及lmdb.h头文件（linux中已经安装，分别位于/usr/lib/x86_64-linux-gnu和/usr/include）, 将库名称和头文件目录分别保存于变量LMDB_LIBRARIES和LMDB_INCLUDE_DIR，然后回到Dependencies.cmake，照例执行<br><pre class="line-numbers language-none"><code class="language-none">include_directories(SYSTEM $&#123;LMDB_INCLUDE_DIR&#125;)list(APPEND Caffe2_DEPENDENCY_LIBS $&#123;LMDB_LIBRARIES&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>类似的，还可以添加OPENCL，LEVELDB，NUMA，ZMQ，REDIS，OPENCV，FFMPEG，Python，MPI等。</p><p>(6) pybind11。在Dependencies.cmake添加pybind11依赖，<br><pre class="line-numbers language-none"><code class="language-none">find_package(pybind11 CONFIG)# 配置模式下寻找，然而没有$&#123;pybind11_DIR&#125;，也没有pybind11Config.cmakeif(NOT pybind11_FOUND)  find_package(pybind11)     # 继续module模式下寻找endif()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>虽然存在cmake/Modules/Findpybind11.cmake，然而其中find_path并没有找到pybind11/pybind11.h这个头文件，因为我没有预先安装pybind11，CMake自然是找不到的，于是在Dependencies.cmake中直接添加<br><pre class="line-numbers language-none"><code class="language-none">include_directories(SYSTEM $&#123;CMAKE_CURRENT_LIST_DIR&#125;&#x2F;..&#x2F;third_party&#x2F;pybind11&#x2F;include)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>(7) OPENMP<br><pre class="line-numbers language-none"><code class="language-none">FIND_PACKAGE(OpenMP QUIET)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>如果找到OpenMP，那么${OpenMP_CXX_FLAGS} 和 ${OpenMP_CXX_LIBRARIES}分别存储头文件搜索路径和库文件链接flag，生成caffe2时可以用到OpenMP，用法是在caffe2/CMakeLists.txt中，<br><pre class="line-numbers language-none"><code class="language-none">target_compile_options(caffe2 INTERFACE $&#123;OpenMP_CXX_FLAGS&#125;)target_link_libraries(caffe2 PRIVATE $&#123;OpenMP_CXX_LIBRARIES&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>(8) CUDA。在Dependencies.cmake中有<br><pre class="line-numbers language-none"><code class="language-none">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;&#x2F;public&#x2F;cuda.cmake)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>在这个cuda.cmake中，使用 find_library寻找cuda相关的库，找到后作为IMPORTED target进行库的添加，<br><pre class="line-numbers language-none"><code class="language-none">add_library(caffe2::cuda UNKNOWN IMPORTED)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>其他cuda有关的库类似的进行添加，包括caffe2::cudart，caffe2::cudnn，caffe2::curand，caffe2::cufft，caffe2::tensorrt， caffe2::cublas，caffe2::nvrtc，当然这些库不一定全部添加，根据配置决定添加哪些库，然后回到Dependencies.cmake中，<br><pre class="line-numbers language-none"><code class="language-none">list(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>保存到Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS，将来在caffe2/CMakeLists.txt用于链接。</p><p>(9) 其他的依赖库如NCCL，CUB，GLOO等与上述某一点说明类似，不再一一罗列。</p><p>Dependencies.cmake中有很多库是作为生成caffe2库的依赖，比如QNNPACK，对这部分库添加到Caffe2_DEPENDENCY_LIBS（或Caffe2_PUBLIC_DEPENDENCY_LIBS，Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS），这个使用下面语句（位于caffe2/CMakeLists.txt）得到链接flag<br><pre class="line-numbers language-none"><code class="language-none">target_link_libraries(caffe2 PRIVATE $&#123;Caffe2_DEPENDENCY_LIBS&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p><ol><li>生成python的扩展库。首先后三个有关caffe2的扩展已经在上一步中生成并安装，所以对于剩下的两个扩展予以说明。</li></ol><ul><li>torch._C 链接的两个库为<pre class="line-numbers language-none"><code class="language-none">main_libraries&#x3D;[&#39;shm&#39;, &#39;torch_python&#39;]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>显然前面已经生成了这两个库。而使用的源文件则为<pre class="line-numbers language-none"><code class="language-none">main_sources&#x3D;[&quot;torch&#x2F;csrc&#x2F;stub.cpp&quot;]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>torch._dl此扩展使用源文件torch/csrc/dl.c生成 。查看这个文件，发现就是添加了<dlfcn.h>中的三个常量到torch._dl库中，如下<pre class="line-numbers language-none"><code class="language-none">RTLD_GLOBAL&#x3D;0x100RTLD_NOW   &#x3D;0x2RTLD_LAZY  &#x3D;0x1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>这三个常量指示动态加载（比如加载torch._C）的模式，用于dlopen()方法中，增加这三个常量是为了防止python 的os 模块中没有这些flag，并且也没有python的DLFCN模块，此时可以从torch._dl中得到这些flag。相当于把torch._dl当作备胎。</li></ul><h3 id="还有…"><a href="#还有…" class="headerlink" title="还有…"></a>还有…</h3><p>可能，大概了解清楚PyTorch的安装过程了，毕竟安装过程我也没试过（只试过较老版本的安装），没有看到最终生成的各种文件，仅供参考吧。</p>]]></content>
      
      
      <categories>
          
          <category> DL Framework </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
