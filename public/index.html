<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>SJJ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="SJJ">
<meta property="og:url" content="https://shajianjian.github.io/index.html">
<meta property="og:site_name" content="SJJ">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SJJ">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans+KR:100,300,400,700&amp;subset=korean" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <!--<div id="banner"></div>-->
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        <a href="/" id="main-nav-title" class="main-nav-link">SJJ</a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives/">Archives</a>
        
          <a class="main-nav-link" href="/about/">about</a>
        
      </nav>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-PyTorch-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DL-Framework/">DL Framework</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/13/PyTorch-2/">PyTorch-2</a>
    </h1>
  

        <a href="/2019/06/13/PyTorch-2/" class="article-date">
  <time datetime="2019-06-13T02:19:52.000Z" itemprop="datePublished">2019-06-13</time>
</a>
      </header>
    
    <div class="article-entry-abstract" itemprop="articleBody">
      
        <!--<h1 id="torch-installization"><a href="#torch-installization" class="headerlink" title="torch installization"></a>torch installization</h1><p>依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br></pre></td></tr></table></figure>

<p>于是阅读torch/<strong>init</strong>.py，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">old_flags=sys.getdlopenflags()</span><br><span class="line">sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)</span><br><span class="line">from torch._C import *</span><br><span class="line">__all__ += [name for name in dir(_C)</span><br><span class="line">            if name[0] != &apos;_&apos; and</span><br><span class="line">            not name.endswith(&apos;Base&apos;)]</span><br><span class="line">sys.setdlopenflags(old_flags)</span><br></pre></td></tr></table></figure>

<p><b>将torch._C中（不包括_开头和Base结尾）的属性导出到当前域。</b></p>
<p><strong>init</strong>.py除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">extern PyObject* initModule();</span><br><span class="line">PyMODINIT_FUNC PyInit__C()   // 在python脚本中，import _C 时调用</span><br><span class="line">&#123;</span><br><span class="line">  return initModule();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>根据python3扩展库的规则可知，<code>import torch._C</code> ，调用PyInit__C函数（调用名为PyInit_&lt;package&gt;的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。</p>
<p>shm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set(LIBSHM_SUBDIR libshm)</span><br><span class="line">set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class="line">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure>

<p>从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>

<p>TORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。</p>
<p>initModule方法定义在torch/csrc/Module.cpp，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">#ifdef USE_CUDA</span><br><span class="line">namespace torch &#123; namespace cuda &#123;</span><br><span class="line">void initModule(PyObject* module);       // 模块中有关cuda部分的初始化函数声明</span><br><span class="line">&#125;&#125;</span><br><span class="line">#endif</span><br><span class="line"></span><br><span class="line">static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class="line"></span><br><span class="line">PyObject* module;</span><br><span class="line">PyObject* initModule() &#123;                 // 声明并定义模块初始化函数</span><br><span class="line">  // 向methods中添加方法定义</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class="line">  ...</span><br><span class="line">  // 真正的扩展模块定义</span><br><span class="line">  static struct PyModuleDef torchmodule = &#123;</span><br><span class="line">    PyModuleDef_HEAD_INIT,</span><br><span class="line">    &quot;torch._C&quot;,                          // 扩展模块名</span><br><span class="line">    nullptr,                           </span><br><span class="line">    -1,</span><br><span class="line">    methods.data()                       // 模块中的方法定义</span><br><span class="line">  &#125;;</span><br><span class="line">  ASSERT_TRUE(module = PyModule_Create(&amp;torchmodule)); // 创建模块并确保创建成功</span><br><span class="line">  // 对模块进行各种初始化</span><br><span class="line">#ifdef USE_CUDA</span><br><span class="line">  torch::cuda::initModule(module);       // 执行cuda相关的初始化</span><br><span class="line">#endif</span><br><span class="line">  ...</span><br><span class="line">  // 定义模块的属性设置函数，setter</span><br><span class="line">  // 属性名为name，值为v，incref表示是否对值对象增加引用计数</span><br><span class="line">  // 设置成功返回1，否则返回0</span><br><span class="line">  auto set_module_attr = [&amp;](const char* name, PyObject* v, bool incref = true) </span><br><span class="line">  &#123;</span><br><span class="line">    if(incref) &#123;</span><br><span class="line">      Py_INCREF(v);</span><br><span class="line">    &#125;</span><br><span class="line">    return PyModule_AddObject(module, name, v) == 0;</span><br><span class="line">  &#125;</span><br><span class="line">  // 设置模块属性</span><br><span class="line">  ...</span><br><span class="line">  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));</span><br><span class="line">  // 向模块添加方法</span><br><span class="line">  auto py_module = py::reinterpret_borrow&lt;py::module&gt;(module);</span><br><span class="line">  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);</span><br><span class="line">  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);</span><br><span class="line">  ...    // 设置模块其他属性</span><br><span class="line">  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;, </span><br><span class="line">        (PyObject*)THPDefaultGenerator, false));</span><br><span class="line">  torch::nn::init__THNN(module);  // 增加 _THNN 属性</span><br><span class="line">#ifdef USE_CUDA</span><br><span class="line">  torch::nn::init_THCUDD(module);</span><br><span class="line">#endif</span><br><span class="line">  return module;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。</p>
<h1 id="methods-members-in-torch-C"><a href="#methods-members-in-torch-C" class="headerlink" title="methods/members in torch._C"></a>methods/members in torch._C</h1><ul>
<li><p>使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># TorchMethods </span><br><span class="line">_initExtension</span><br><span class="line">_autograd_init</span><br><span class="line">...</span><br><span class="line"># DataLoaderMethods </span><br><span class="line">_set_worker_signal_handlers</span><br><span class="line">_set_worker_pids</span><br><span class="line">...</span><br><span class="line"># torch::autograd::python_functions(), torch/csrc/autograd/init.cpp</span><br><span class="line">set_grad_enabled</span><br><span class="line">is_grad_enabled</span><br><span class="line">set_anomaly_enabled</span><br><span class="line">is_anomaly_enabled</span><br><span class="line"># torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp</span><br><span class="line">_multiprocessing_init</span><br><span class="line"># torch::distributed::c10d::python_functions()  同上类似</span><br><span class="line">...</span><br><span class="line"># THCPModule_method(), torch/csrc/cuda/Module.cpp</span><br><span class="line">_cuda_init</span><br><span class="line">_cuda_setDevice</span><br><span class="line">...</span><br><span class="line">_nccl_version</span><br><span class="line">...</span><br><span class="line"># THCUDNN_method()</span><br><span class="line">_cudnn_version</span><br><span class="line"># THDPModule_methods(), torch/csrc/distributed/Module.cpp</span><br><span class="line">_dist_init_extension</span><br><span class="line">_dist_init_process_group</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>生成模块torch._C 后再向其添加如下成员：</p>
<ul>
<li><p>向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。</p>
<p>  torch._C._TensorBase这个类型具有属性</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">_cdata</span><br><span class="line">_version</span><br><span class="line">grad_fn</span><br><span class="line">_grad_fn</span><br><span class="line">is_leaf</span><br><span class="line">data</span><br><span class="line">_grad</span><br><span class="line">grad</span><br><span class="line">...</span><br><span class="line">device</span><br><span class="line">ndim</span><br></pre></td></tr></table></figure>

<p>  并且具有以下方法</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp</span><br><span class="line">__add__</span><br><span class="line">__radd__</span><br><span class="line">...</span><br><span class="line">apply_</span><br><span class="line">byte</span><br><span class="line">char</span><br><span class="line">contiguous</span><br><span class="line">...</span><br><span class="line">where</span><br><span class="line">zero_</span><br><span class="line"># extra_method</span><br><span class="line">_make_subclass</span><br></pre></td></tr></table></figure>

<p>  类型torch._C._FunctionBase， 这个类型具有方法和属性为</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># method</span><br><span class="line">apply</span><br><span class="line">_do_forward</span><br><span class="line">_do_backward</span><br><span class="line">_register_hook_dict</span><br><span class="line">register_hook</span><br><span class="line"># property</span><br><span class="line">saved_tensors</span><br><span class="line">saved_variables</span><br><span class="line">...</span><br><span class="line">requires_grad</span><br><span class="line">metadata</span><br></pre></td></tr></table></figure>

<p>  不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。</p>
</li>
<li><p>向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。</p>
</li>
<li><p>向torch._C添加模块， _nn，cpp，_onnx。</p>
</li>
<li><p>向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。</p>
</li>
</ul>
</li>
</ul>
<h1 id="some-installization-w-r-t-torch-C"><a href="#some-installization-w-r-t-torch-C" class="headerlink" title="some installization w.r.t. torch._C"></a>some installization w.r.t. torch._C</h1><h3 id="THPxxxStorage-init"><a href="#THPxxxStorage-init" class="headerlink" title="THPxxxStorage_init"></a>THPxxxStorage_init</h3><p>torch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。</p>
<p>注意到从Module.cpp文件中头文件引用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;TH/TH.h&gt;               // TH=TorcH</span><br><span class="line">#include &lt;c10/util/Logging.h&gt;</span><br><span class="line">#include &lt;ATen/ATen.h&gt;</span><br><span class="line">...</span><br><span class="line">#include &lt;torch/csrc/THP.h&gt;      // THP=TorcH Python</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。</p>
<p>一方面，头文件 TH/TH.h 中引用了#include &lt;TH/THGeneral.h&gt;，在aten/src/TH目录下的CMakeLists.txt中有这么一行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/THGeneral.h&quot;)</span><br></pre></td></tr></table></figure>

<p>在THGeneral.h中有如下宏定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w</span><br><span class="line">#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND</span><br></pre></td></tr></table></figure>

<p>另一方面，torch/csrc/THP.h 中引用了#include &lt;torch/src/Storage.h&gt;，在这个Storage.h中有如下语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)</span><br><span class="line">...</span><br><span class="line">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class="line">#include &lt;TH/THGenerateAllType.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class="line">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class="line">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class="line">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure>

<p>上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#ifndef TH_GENERIC_FILE</span><br><span class="line">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.h&quot;         // (0)</span><br><span class="line">#else</span><br><span class="line">...</span><br><span class="line">bool THPStorage_(init)(PyObject *module);                      // (1)</span><br><span class="line">...</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>

<p>而文件TH/THGenerateAllType.h则包含语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;TH/THGenerateFloatTypes.h&gt;</span><br><span class="line">#include &lt;TH/THGenerateIntTypes.h&gt;</span><br><span class="line">...</span><br><span class="line">#undef TH_GENERIC_FILE</span><br></pre></td></tr></table></figure>

<p>4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 此时 TH_GENERIC_FILE是已定义的</span><br><span class="line">#include &lt;TH/THGenerateFloatType.h&gt;</span><br><span class="line">#include &lt;TH/THGenerateDoubleType.h&gt;</span><br><span class="line">#undef TH_GENERIC_FILE     // 这里将TH_GENERIC_FILE 设为未定义</span><br></pre></td></tr></table></figure>

<p>以TH/THGenerateFloatType.h为例说明，此文件中有语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#define Real Float</span><br><span class="line">...</span><br><span class="line">#line 1 TH_GENERIC_FILE</span><br><span class="line">#include TH_GENERIC_FILE         // (2)</span><br><span class="line">...</span><br><span class="line">#undef Real</span><br></pre></td></tr></table></figure>

<p>注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bool THPStorage_(init)(PyObject *module);  -&gt;</span><br><span class="line">bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;</span><br><span class="line">bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;</span><br><span class="line">bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;</span><br><span class="line">bool THPFloatStorage_init(PyObject *module);</span><br></pre></td></tr></table></figure>

<p>类似地，#include &lt;TH/THGenerateDoubleType.h&gt;，则得到THPDoubleStorage_init，</p>
<p>#include &lt;TH/THGenerateIntTypes.h&gt; 得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">THPByteStorage_init</span><br><span class="line">THPCharStorage_init</span><br><span class="line">THPShortStorage_init</span><br><span class="line">THPIntStorage_init</span><br><span class="line">THPLongStorage_init</span><br></pre></td></tr></table></figure>

<p>对4组include中的其他三组，则得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">THPHalfStorage_init</span><br><span class="line">THPBoolStorage_init</span><br><span class="line">THPQUInt8Storage_init</span><br><span class="line">THPQInt8Storage_init</span><br><span class="line">THPQInt32Storage_init</span><br></pre></td></tr></table></figure>

<p>以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;TH/THStorageFunctions.hpp&gt;</span><br><span class="line">#include &lt;torch/csrc/THP.h&gt;                   // include THPxxxStorage_init 函数声明</span><br><span class="line">...</span><br><span class="line">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class="line">#include &lt;TH/THGenerateAllTypes.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class="line">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class="line">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class="line">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure>

<p>又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#ifndef TH_GENERIC_FILE</span><br><span class="line">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.cpp&quot;              // (11)</span><br><span class="line">#else</span><br><span class="line">...                                                                   // (12)</span><br><span class="line">bool THPStorage_(init)(PyObject *module)</span><br><span class="line">&#123;</span><br><span class="line">  static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class="line">#ifndef THD_GENERIC_FILE</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);</span><br><span class="line">#endif</span><br><span class="line">  </span><br><span class="line">  THPStorageType.tp_methods = methods.data();</span><br><span class="line">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class="line">  THPStorageType.tp_getset = THPStorage_(properties);</span><br><span class="line">  if (PyType_Ready(&amp;THPStorageType) &lt; 0)</span><br><span class="line">    return false;</span><br><span class="line">  Py_INCREF(&amp;THPStorageType);</span><br><span class="line">  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);</span><br><span class="line">  THPStorage_(initCopyMethods)();</span><br><span class="line">  return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)</span><br></pre></td></tr></table></figure>

<p>在TH/THGeneral.h中存在宏定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)</span><br><span class="line">#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y</span><br></pre></td></tr></table></figure>

<p>由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为”FloatStorageBase”，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。</p>
<p>以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#define Real Float</span><br><span class="line">...</span><br><span class="line">#include TH_GENERIC_FILE</span><br></pre></td></tr></table></figure>

<p>即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。</p>
<p>其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。</p>
<p>torch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。</p>
<p>现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PyTypeObject THPStorageType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(nullptr, 0)</span><br><span class="line">  &quot;torch._C.&quot; THPStorageBaseStr,               /* tp_name */</span><br><span class="line">  sizeof(THPStorage),                          /* tp_basicsize */</span><br><span class="line">  ...</span><br><span class="line">  THPStorage_(pynew),                          /* tp_new */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct THPStorage &#123;</span><br><span class="line">  PyObject_HEAD</span><br><span class="line">  THWStorage *cdata;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）</p>
<p>然后查看类创建 THPStorage_(pynew) 的定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)</span><br><span class="line">&#123;</span><br><span class="line">  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // 可变长度参数的个数</span><br><span class="line"></span><br><span class="line">  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); // 分配内存，让self指向这个内存块</span><br><span class="line">  ...</span><br><span class="line">  c10::Allocator * allocator = nullptr;</span><br><span class="line"></span><br><span class="line">  if (kwargs != nullptr) &#123;                               // named arguments</span><br><span class="line">    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, &quot;allocator&quot;); // 获取参数allocator的值</span><br><span class="line">    if (allocator_ptr) &#123;</span><br><span class="line">      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);</span><br><span class="line">      // 转为 c10::Allocator 指针</span><br><span class="line">      allocator = static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));</span><br><span class="line">      PyDict_DelItemString(kwargs, &quot;allocator&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    Py_ssize_t num_kwargs = PyDict_Size(kwargs);</span><br><span class="line">    if (num_args == 0) &#123;</span><br><span class="line">      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, &quot;cdata&quot;);</span><br><span class="line">      if (num_kwargs==1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   // 提供了cdata值</span><br><span class="line">        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);</span><br><span class="line">        self-&gt;cdata = ptr;</span><br><span class="line">        return (PyObject*)self.release();       // 返回THPStorage指针</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    THPUtils_assert(num_kwargs == 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  if (num_args == 0) &#123;</span><br><span class="line">    if (allocator) &#123;                            // 未提供cdata值，则需要创建THWStorage类型实例</span><br><span class="line">      self-&gt;cdata = THPStorage_(newWithAllocator)(0, allocator);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      self-&gt;cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);</span><br><span class="line">    &#125;</span><br><span class="line">    return (PyObject*)self.release();</span><br><span class="line">  &#125;</span><br><span class="line">  ...     // 使用其他方法设置 self-&gt;cdata</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define THWStorage THStorage</span><br></pre></td></tr></table></figure>

<p>转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Storage.cpp                 -&gt;</span><br><span class="line">#include &lt;TH/TH.h&gt;          -&gt;</span><br><span class="line">#include &lt;TH/THStorageFunction.h&gt;   -&gt;</span><br><span class="line">#include &lt;TH/generic/THStorage.h&gt;   -&gt;</span><br><span class="line">#include &lt;c10/core/StorageImpl.h&gt;</span><br></pre></td></tr></table></figure>

<p>在 TH/generic/THStorage.h 中找到宏定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define THStorage at::StorageImpl</span><br></pre></td></tr></table></figure>

<p>在 c10/core/StorageImpl.h 中找到结构定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">namespace c10 &#123;</span><br><span class="line">struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;</span><br><span class="line">...</span><br><span class="line">private:</span><br><span class="line">  caffe2::TypeMeta  data_type_;  // 数据类型</span><br><span class="line">  DataPtr data_ptr_;             // 数据指针</span><br><span class="line">  int64_t numel_;                // 数据数量</span><br><span class="line">  bool resizable_;</span><br><span class="line">  bool received_cuda_;</span><br><span class="line">  Allocator* allocator_;         // 数据的内存分配器</span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">new                // 新建THStorage，未指定 size，即size=0，使用默认Allocator</span><br><span class="line">free</span><br><span class="line">size</span><br><span class="line">get</span><br><span class="line">set</span><br><span class="line">data</span><br><span class="line">newWithSize        // 新建THStorage，指定 size，使用默认Allocator</span><br><span class="line">newWithAllocator   // 新建THStorage，指定 size 和 Allocator</span><br><span class="line">copy_functions</span><br><span class="line">copyByte</span><br><span class="line">...</span><br><span class="line">copyCudaByte</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>此外有宏定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h</span><br><span class="line">#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h</span><br></pre></td></tr></table></figure>

<p>函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。</p>
<p>（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）</p>
<p>以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">THStorage* THStorage_(newWithSize)(ptrdiff_t size)</span><br><span class="line">&#123;</span><br><span class="line">  THStorage* storage = c10::make_instrusive&lt;at::StorageImpl&gt;(</span><br><span class="line">#ifdef THQUANTIZED</span><br><span class="line">    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),</span><br><span class="line">#else</span><br><span class="line">    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        // 新建scalar_t 类型</span><br><span class="line">#endif</span><br><span class="line">    size,</span><br><span class="line">    getTHDefaultAllocator(),</span><br><span class="line">    true).release();</span><br><span class="line">  return storage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">StorageImpl(</span><br><span class="line">    caffe2::TypeMeta data_type,</span><br><span class="line">    int64_4 numel,</span><br><span class="line">    at::Allocator* allocator,</span><br><span class="line">    bool resizable)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>我们看上上个代码片段中StorageImpl构造函数的实参，</p>
<p>首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define scalar_t float</span><br></pre></td></tr></table></figure>

<p>于是，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    // 假设 THQUANTIZED 未定义</span><br></pre></td></tr></table></figure>

<p>caffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \</span><br><span class="line">  namespace detail &#123;                                                       \</span><br><span class="line">  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \</span><br><span class="line">    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \</span><br><span class="line">  &#125;                                                                        \</span><br><span class="line">  template&lt;&gt;                                                               \</span><br><span class="line">  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \</span><br><span class="line">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \</span><br><span class="line">    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \</span><br><span class="line">  &#125;</span><br><span class="line">  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)</span><br><span class="line"></span><br><span class="line">#define C10_CONCATENATE_IMPL(s1,s2) s1##s2</span><br><span class="line">#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)</span><br></pre></td></tr></table></figure>

<p>经过宏替换，得到 _typeMetaDataInstance的模板函数定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">template&lt;&gt;</span><br><span class="line">const detail::TypeMetaData*</span><br><span class="line">TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;</span><br><span class="line">  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>还有一组宏，用于生成模板特例化，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \</span><br><span class="line">  template&lt;&gt;                                                           \</span><br><span class="line">  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \</span><br><span class="line">    return TypeIdentifier(PreallocatedId);                             \</span><br><span class="line">  &#125;                                                                    \</span><br><span class="line">  namespace detail &#123;                                                   \</span><br><span class="line">  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \</span><br><span class="line">    _typeMetaDataInstance_preallocated_,                               \</span><br><span class="line">    PreallocatedId);                                                   \</span><br><span class="line">  &#125;                                                                    \</span><br><span class="line">  template&lt;&gt;                                                           \</span><br><span class="line">  inline const detail::TypeMetaData*                                   \</span><br><span class="line">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \</span><br><span class="line">    return &amp;C10_CONCATENATE(                                           \</span><br><span class="line">      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \</span><br><span class="line">  &#125;                                                                    \</span><br><span class="line">#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \</span><br><span class="line">  namespace detail &#123;                                                 \</span><br><span class="line">  const TypeMetaData C10_CONCATENATE(                                \</span><br><span class="line">    _typeMetaDataInstance_preallocated_,                             \</span><br><span class="line">    PreallocatedId) = _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\</span><br><span class="line">  &#125;                                                                  </span><br><span class="line">// 调用</span><br><span class="line">CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)</span><br></pre></td></tr></table></figure>

<p>对于系统内部变量如 float，得到函数模板特例化的定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 函数声明</span><br><span class="line">namespace detail &#123;</span><br><span class="line">__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData</span><br><span class="line">_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">template&lt;&gt;</span><br><span class="line">inline const detail::TypeMetaData*</span><br><span class="line">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class="line">  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>另外，在c10/util/typeid.cpp中有如下调用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)</span><br></pre></td></tr></table></figure>

<p>经过宏替换得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">namespace detail &#123;                                                 </span><br><span class="line">  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId</span><br><span class="line">    = _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>于是函数模板特例化最终形式为，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">template&lt;&gt;</span><br><span class="line">inline const detail::TypeMetaData*</span><br><span class="line">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class="line">  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>detail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">struct TypeMetaData final &#123;</span><br><span class="line">// 函数类型的别名</span><br><span class="line">using New = void*();                            // new</span><br><span class="line">using PlacementNew = void(void*, size_t);       // 占位new</span><br><span class="line">using Copy = void(const void*, void*, size_t);  // 类型数组拷贝</span><br><span class="line">using PlacementDelete = void(void*, size_t);</span><br><span class="line">using Delete = void(void*);</span><br><span class="line">... //构造函数</span><br><span class="line"></span><br><span class="line">size_t itemsize_;  // 类型占多少字节</span><br><span class="line">New* new_;</span><br><span class="line">PlacementNew* placementNew_;   // 定位放置 new</span><br><span class="line">Copy* copy_;        // 类型拷贝</span><br><span class="line">Delete* delete_;    // 类型析构</span><br><span class="line">TypeIdentifier id_; // 类型全局唯一id</span><br><span class="line">const char* name_;  // 类型名称</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">template &lt;class T&gt;</span><br><span class="line">inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;</span><br><span class="line">  return &#123;sizeof(T),                 // 类型T占多少字节</span><br><span class="line">          _PickNew&lt;T&gt;(),             // 通过 new T</span><br><span class="line">          _PickPlacementNew&lt;T&gt;(),</span><br><span class="line">          _PickCopy&lt;T&gt;(),      </span><br><span class="line">          _PickPlacementDelete&lt;T&gt;(),</span><br><span class="line">          _PickDelete&lt;T&gt;(),</span><br><span class="line">          TypeIdentifier::Get&lt;T&gt;(),  // 获取类型的全局唯一id，</span><br><span class="line">          typeName&#125;;                 // 类型名称，例如float的名称为&quot;float&quot;</span><br></pre></td></tr></table></figure>

<p>构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeIdentifier::Get&lt;T&gt;()</span><br></pre></td></tr></table></figure>

<p>在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。</p>
<p>对于其他类型如 int，double，int64_t等类似处理。</p>
<p>PyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。</p>
<p>至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">size,             // 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）</span><br><span class="line">getTHDefaultAllocator(),  // 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配</span><br><span class="line">true                      // 被构造的StorageImpl可以resize</span><br></pre></td></tr></table></figure>

<p>创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase</p>
<p>记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。</p>
<p>FloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。</p>
<p>类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  torch::nn::init_THNN(module);</span><br><span class="line">#ifdef USE_CUDA</span><br><span class="line">  torch::nn::init_THCUNN(module);</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>

<p>函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。</p>
<p><code>torch._C</code>模块初始化过程到这里就完成了。回到 <code>torch/__init__.py</code>，继续看看 import torch时接下来做了哪些事情：</p>
<ol>
<li><p>定义了模块函数 typename，is_tensor，is_storage等</p>
</li>
<li><p>导入torch下其他子模块</p>
</li>
<li><p>调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理</p>
</li>
<li><p>调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：</p>
<ul>
<li><p>初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；</p>
</li>
<li><p>初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；</p>
</li>
<li><p>初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；</p>
</li>
<li><p>初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor</p>
</li>
<li><p>共享内存管理初始化，设置文件路径；</p>
</li>
<li><p>执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, </span><br><span class="line">TH_CONCAT_2(at::k, Real));</span><br></pre></td></tr></table></figure>

<p>  其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`</span><br></pre></td></tr></table></figure>

<p>  这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。</p>
</li>
</ul>
</li>
</ol>
<p>到这里，import torch 的工作全部完成。</p>
<h1 id="后记："><a href="#后记：" class="headerlink" title="后记："></a>后记：</h1><p>初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。</p>
-->
      
    </div>
    <footer class="article-footer">
      <!--<a data-url="https://shajianjian.github.io/2019/06/13/PyTorch-2/" data-id="cjwu48imc00087wvc6n4olv9i" class="article-share-link">Share</a>-->
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/">PyTorch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Hexo-Sync" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/13/Hexo-Sync/">Hexo Sync</a>
    </h1>
  

        <a href="/2019/06/13/Hexo-Sync/" class="article-date">
  <time datetime="2019-06-13T01:57:11.000Z" itemprop="datePublished">2019-06-13</time>
</a>
      </header>
    
    <div class="article-entry-abstract" itemprop="articleBody">
      
        <!--<p>场景：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在A, B两台电脑上同步Hexo博客</span><br></pre></td></tr></table></figure>

<p>假设在 computer B 上已经初次建立hexo博客 <a href="https://shajian.github.io，" target="_blank" rel="noopener">https://shajian.github.io，</a> computer B 本地的文件夹（hexo部署环境目录）为 path/to/myblog，其内部文件/目录如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">_config.yml</span><br><span class="line">db.json</span><br><span class="line">node_modules</span><br><span class="line">package.json</span><br><span class="line">package-lock.json</span><br><span class="line">public</span><br><span class="line">scaffolds</span><br><span class="line">source</span><br><span class="line">themes</span><br></pre></td></tr></table></figure>

<p>在github仓库 shajian.github.io 上新建branch，比如”hexo”，这样，”mater”主分支用于维护hexo生成的静态博客文件/目录，”hexo”分支用于维护hexo部署环境下的所有文件/目录。</p>
<p>在 computer A 上 clone 这个仓库，并切换到 hexo 分支，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class="line">$ cd shajian.github.io</span><br><span class="line">$ git checkout hexo</span><br><span class="line">$ git branch</span><br><span class="line">* hexo</span><br><span class="line">  master</span><br></pre></td></tr></table></figure>

<p>将目录 shajian.github.io 内的所有文件/目录全部删除，然后将 path/to/myblog内的全部内容复制过来，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ rm -rf .</span><br><span class="line"># do not use &quot;cp -R path/to/myblog/* ./&quot; which ignores hidden files/directories</span><br><span class="line">$ cp -R path/to/myblog/. ./</span><br></pre></td></tr></table></figure>

<p>然后可在使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new &quot;&lt;title&gt;&quot;</span><br></pre></td></tr></table></figure>

<p>写新文章或直接去source/_posts下修改已有文章，<br>部署</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>

<p>然后提交到仓库的hexo分支，进行备份</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git add .</span><br><span class="line">$ git commit -m &quot;new post &apos;title&apos;&quot;</span><br><span class="line">$ git push origin hexo</span><br></pre></td></tr></table></figure>

<p>然后就可以去 <a href="https://shajian.github.io" target="_blank" rel="noopener">https://shajian.github.io</a> 浏览本地新增/修改文章内容了。</p>
<p>在 computer B 上删除 path/to/myblog 目录，然后重新 clone 仓库，并切换到 hexo 分支，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class="line">$ cd shajian.github.io</span><br><span class="line">$ git checkout hexo</span><br></pre></td></tr></table></figure>

<p>如果仓库有 .gitignore 文件且包含 node_modules 目录，则执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install</span><br></pre></td></tr></table></figure>

<p>此时，要修改还是新增文章，步骤均与上面 computer A上的操作一致。</p>
<p>computer A 和 B 本地均有仓库后，以后每次修改还是新增文章，首先需要将仓库更新到最新</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">$ git pull origin master</span><br><span class="line">$ git checkout hexo</span><br><span class="line">$ git pull origin hexo</span><br></pre></td></tr></table></figure>

<p>切换到 hexo 分支后，可以进行修改和新增文章了。</p>
<p>由于 .depoly_git 下其实就是对应 master 主分支的内容，这也是一个git 仓库目录，内含 .git 文件夹，所以提交的时候无法提交 .deploy_git 内部的文件/目录，不过这个没关系，例如前面，在 computer B 上 clone 仓库后，执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>

<p>由 hexo 向 .deploy_git 填充生成的文件/目录，而不需要在 hexo 分支上备份这些内容。</p>
-->
      
    </div>
    <footer class="article-footer">
      <!--<a data-url="https://shajianjian.github.io/2019/06/13/Hexo-Sync/" data-id="cjwu48ila00007wvclssm6cxn" class="article-share-link">Share</a>-->
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tool/">tool</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-PyTorch-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DL-Framework/">DL Framework</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/12/PyTorch-1/">PyTorch_1</a>
    </h1>
  

        <a href="/2019/06/12/PyTorch-1/" class="article-date">
  <time datetime="2019-06-12T11:17:11.000Z" itemprop="datePublished">2019-06-12</time>
</a>
      </header>
    
    <div class="article-entry-abstract" itemprop="articleBody">
      
        <!--<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>一直以来就对深度学习的框架源码有着浓厚兴趣，但是由于涉及到的领域较多，C++，python，CUDA，数学等，加上时间也比较零碎，就耽搁至今，后来意识到我不可能等完全弄明白之后再来写博客记录，毕竟能力不足，所以还是边看源码边记录，不求完全搞明白，但求能从整体上有个大致的理解，如果还能整明白一些数学计算上的代码实现，那就再好不过了。</p>
<p>当前最流行的深度学习框架就是tensorflow和pytorch了，但是tensorflow据说代码工业化程度非常高，我等菜鸡先避其锋芒，来分析pytorch，希望能给自己带来点信心。</p>
<p>下载源码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https://github.com/pytorch/pytorch</span><br></pre></td></tr></table></figure>

<p>由于使用了子模块所以增加–recursive选项，记pytorch的root dir为$ROOT_DIR。</p>
<p>根据安装步骤进行自上而下的阅读。Linux下安装使用命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd pytorch</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

<p>pytorch底层计算使用C++实现，并提供了python调用接口，所以这一命令就是使用setuptools安装python包，安装依赖库及修改配置项这里均跳过，故直接看$ROOT_DIR/setup.py中的setup()方法，但是在这个方法之前先执行了build_deps()用于生成有关 caffe2 的依赖库</p>
<h3 id="build-deps"><a href="#build-deps" class="headerlink" title="build_deps()"></a>build_deps()</h3><p>这个方法内部关键的一步为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">build_caffe2(...)</span><br></pre></td></tr></table></figure>

<p>查看这个方法的定义，发现build_caffe2做了如下几件事：</p>
<ol>
<li>run_cmake。执行cmake，这个命令的选项这里省略不展开，注意执行cmake这个命令的工作目录为$ROOD_DIR/build， cmake的Source Tree为$ROOD_DIR，这个 目录下存在top level的CMakeLists.txt</li>
<li>在$ROOT_DIR/build下编译并安装，使用make install或者 ninja install（cmake生成的Makefile中install这个target包含了build这个步骤）</li>
<li>将build/caffe2/proto下的所有.py文件 拷贝到caffe2/proto/下，这些.py文件是根据caffe2/proto/下的.proto文件生成</li>
</ol>
<p>这其中最复杂的部分就是run_cmake了，先是使用cmake的-D option设置一些cmake的变量，然后对source tree应用cmake， 查看top level的CMakeLists.txt，这个文件看着好像特别庞大，实际上做的事情也就那么几种：1)设置变量，根据不同操作系统设置或修改变量；2)设置include dir以及lib dir；3）加载.cmake文件以使用其中自定义的cmake函数；4）设置C++文件编译选项；5）安装配置文件/目录到指定位置等；我们注意比较关键的语句如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">add_subdirectory(c10)</span><br><span class="line">add_subdirectory(caffe2)</span><br><span class="line">add_subdirectory(modules)</span><br></pre></td></tr></table></figure>

<p>这表明将c10,caffe2,modules等目录添加进build tree，这些目录下必定也有相应的CMakeLists.txt， 所以需要继续查看这些CMakeLists.txt中定义了哪些生成规则。</p>
<p>另外，top level 中CMakeLists.txt中有这么一行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include(cmake/Dependencies.cmake)</span><br></pre></td></tr></table></figure>

<p>这个Dependencies.cmake指明安装Caffe2所依赖的各种库，其中一些库位于本项目中如$ROOT_DIR/third_party或$ROOT_DIR/caffe2，还有一些库则是需要预先手动安装的，举个例子：</p>
<ol>
<li>非本项目的公共库，比如添加BLAS库依赖，假设最开始设置了环境变量BLAS=OpenBLAS（环境变量的设置可参考setup.py文件头部注释）, 那么选择添加OpenBLAS库依赖，在Dependencies.cmake中代码为<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">elseif(BLAS STREQUAL &quot;OpenBLAS&quot;)</span><br><span class="line">  find_package(OpenBLAS REQUIRED)</span><br><span class="line">  include_directories(SYSTEM $&#123;OpenBLAS_INCLUDE_DIR&#125;)</span><br><span class="line">  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS $&#123;OpenBLAS_LIB&#125;)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>这个find_package告诉我们去查看$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake，好的我们跳过去看一下这个.cmake文件，发现其定义了OpenBLAS的头文件和库文件的搜索路径，然后根据这些搜索路径分别搜索头文件cblas.h所在目录以及库名openblas， 分别使用变量OpenBLAS_INCLUDE_DIR和OpenBLAS_LIB保存，从上面的代码片段，我们知道搜索到的库名被添加到Caffe2_PUBLIC_DEPENDENCY_LIBS中，而我们再跳至$ROOT_DIR/caffe2/CMakeLists.txt发现其中有</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">target_link_libraries(caffe2 PUBLIC $&#123;Caffe2_PUBLIC_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>

<p>这就相当于能生成-lopenblas这样的链接选项。</p>
<p>我们直接再看另一个库caffe2_pybind11_state的生成，因为下文会提到它，查看$ROOT_DIR/caffe2/CMakeLists.txt发现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">add_subdirectory(python)</span><br><span class="line">...</span><br><span class="line">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class="line">install(TARGETS caffe2_pybind11_state DESTINATION &quot;$&#123;PYTHON_LIB_REL_PATH&#125;/caffe2/python&quot;)</span><br></pre></td></tr></table></figure>

<p>其中Caffe2_CPU_PYTHON_SRCS在$ROOT_DIR/caffe2/python/CMakeLists.txt中设置， 类似地，还根据是否使用CUDA或者ROCM , 生成caffe2_pybind11_state_gpu或caffe2_pybind11_state_hip。生成这些库文件后，直接install到python的site-packages目录下的caffe2/python目录中</p>
<p>以上就是build_dep()这个方法介绍，接着看$ROOT_DIR/setup.py中的setup方法。</p>
<h3 id="setup"><a href="#setup" class="headerlink" title="setup()"></a>setup()</h3><p>setup方法（可以参考<a href="https://docs.python.org/3/distutils/apiref.html" target="_blank" rel="noopener">setup()</a>），其中几个值得说明的参数：</p>
<ol>
<li>ext_modules 有5个扩展库分别如下：</li>
</ol>
<ul>
<li>torch._C 指定了C++源文件，链接库，编译选项，链接选项和头文件/库dir</li>
<li>torch._dl 非WINDOWS平台下才有，指定了C源文件</li>
<li>caffe2.python.caffe2_pybind11_state</li>
<li>caffe2.python.caffe2_pybind11_state_gpu</li>
<li>caffe2.python.caffe2_pybind11_state_hip</li>
</ul>
<p>后三个库在上一步中其实已经生成好了，其中caffe2.python前缀表示两级目录（package），可以在$ROOT_DIR/build/caffe2/python目录下查看。扩展模块ext_modules在build_ext这个动作中生成。</p>
<ol start="2">
<li>cmdclass，重写了build_ext, clean, install这几个action，这个action用在python setup.py <action> 命令中。install动作跟默认一致。 clean是清除编译过程中产生的临时文件，这些临时文件的pattern在.gitignore中给定。我们重点看一下build_ext这个动作对应的类build_ext，其中方法包含</action></li>
</ol>
<ul>
<li>create_compile_commands这是一个自定义方法，用于将compile_commands.json中的gcc编译器改为g++，修改原因代码注释写的很清楚，使用gcc编译s时不会include c++的头文件目录。 文件compile_commands.json是根据$ROOT_DIR/CMakeLists.txt中的set(CMAKE_EXPORT_COMPILE_COMMAND ON)这句代码而生成，所以位于$ROOT_DIR/build目录下，这个json文件中指明了编译各个文件时的工作路径（working directory），编译指令（command）以及被编译的原文件，格式如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">&#123;</span><br><span class="line">  &quot;directory&quot;:&quot;&lt;path/to/root&gt;build/third_party/protobuf/cmake&quot;,</span><br><span class="line">  &quot;command&quot;: &quot;/usr/bin/c++ ... -I&lt;path/to/root&gt;/third_party/protobuf/src ... </span><br><span class="line">                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...&quot;,</span><br><span class="line">  &quot;file&quot;: &quot;&lt;path/to/root&gt;/third_party/protobuf/src/google/protobuf/arena.cc&quot;</span><br><span class="line">&#125;,</span><br><span class="line">...</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>其中每个{…}块表示编译一个源文件到目标文件 .o。 将文件中gcc改为g++后重新保存为$ROOT_DIR/compile_commands.json。</p>
<ul>
<li>run打印各library（比如 CUDA, CUDNN, NUMPY等）的使用情况，然后执行基类同名方法的逻辑</li>
<li>build_extensions 生成由ext_modules指定的python扩展库所用的方法</li>
</ul>
<p>ext_modules中添加了5个扩展，后三个扩展在build_deps()中已经生成并安装，当然，caffe2_pybind11_state_gpu和caffe2_pybind11_state_hip是根据配置决定是否生成，配置了CUDA则生成前者，配置了ROCM则生成后者，如果均未配置，则这两个扩展均不生成。既然在build_deps()中已经生成并安装，所以这里将其从ext_modules中删除，于是build_extensions实际上只生成torch._C, torch._dl这两个扩展库。</p>
<p>然而，除了build_deps()方法还有其他方法可用于生成ext_modules中 的后三个扩展库，生成路径为$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/，所以需要判断在这个路径下是否存在后三个扩展库，若不在（此时就是前面所说的使用build_deps()生成），则将扩展库名称从ext_modules中予以删除， 若存在，则还需则将其拷贝到生成目录$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/下，并修改拷贝后的文件名称，以caffe2.python.caffe2_pybind11_state为例说明，两级前缀表示目录所以最终的目录为$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/，剩余的caffe2_pybind11_state表示扩展库的文件名，还需要添加后缀名，这个后缀名由系统平台和python版本，我这里是.cpython-37m-x86_64-linux-gnu.so，于是拷贝后得到文件$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so ，这样使用基类的build_extensions()方法才能将其进一步安装到 python的site-packages目录下，我这里是…/miniconda3/lib/python3.7/site-packages/caffe2/python/目录。</p>
<ol start="3">
<li>packages 指定安装到python 的site-packages下的包<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">packages = find_packages(exclude=[&apos;tools&apos;, &apos;tools.*&apos;])</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>由于PyTorch项目中除tools之外，只有caffe2和torch两个目录包含<strong>init</strong>.py，所以将caffe2和torch两个包安装到site-packages下。</p>
<p>现在再回头看看ext_modules中指定的5个扩展，不难得知，其中torch._C, torch._dl这两个扩展安装到site-packages/torch下，扩展包名称分别为_C, _dl（省略了文件ext后缀），而另外三个caffe2有关的扩展则根据名称（.号切分，前面都是目录名，最后一个是文件名）知道其安装在site-packages/caffe2/python下。</p>
<h3 id="整理"><a href="#整理" class="headerlink" title="整理"></a>整理</h3><p>以上就是pytorch安装过程，主要分为两部分:</p>
<ol>
<li>使用CMake生成c++库，对应build_deps()这个方法执行</li>
<li>使用python的setup方法生成扩展库，主要是build_ext。</li>
</ol>
<p>根据上面两点，重新整理一遍。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">top-level的CMakeLists.txt中</span><br><span class="line">add_subdirectory(c10)</span><br><span class="line">add_subdirectory(caffe2)</span><br></pre></td></tr></table></figure>

<p>于是先看caffe2这个目录下的CMakeLists.txt， 寻找其中的关键语句，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">add_library(caffe2_proto STATIC $&lt;TARGET_OBJECTS:Caffe2_PROTO&gt;</span><br><span class="line">add_library(thnvrtc SHARED $&#123;TORCH_SRC_DIR&#125;/csrc/jit/fuser/cuda/thnvrtc.cpp&gt;</span><br><span class="line">add_library(caffe2 $&#123;Caffe2_CPU_SRCS&#125;)</span><br><span class="line">if (TORCH_STATIC)</span><br><span class="line">  add_library(torch STATIC $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class="line">else()</span><br><span class="line">  add_library(torch SHARED $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class="line">endif()</span><br><span class="line">torch_cuda_based_add_library(caffe2_gpu $&#123;Caffe2_GPU_SRCS&#125;)</span><br><span class="line">hip_add_library(caffe2_hip $&#123;Caffe2_HIP_SRCS&#125;)</span><br><span class="line">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class="line">add_library(caffe2_pybind11_state_gpu MODULE $&#123;Caffe2_GPU_PYTHON_SRCS&#125;)</span><br><span class="line">add_library(caffe2_pybind11_state_hip MODULE $&#123;Caffe2_HIP_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>

<p>安装目录则寻找对应的install语句。此外，文件中还有一句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_subdirectory(../torch torch)</span><br></pre></td></tr></table></figure>

<p>（实际上caffe2目录下CMakeLists.txt中存在很多add_subdirectory，但是都是类似的处理过程，所以不一一说明，仅以torch这个目录进行说明）</p>
<p>于是查看torch目录下的CMakeLists.txt， 其中生成的库为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>

<p>然后根据其中的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set(LIBSHM libshm)</span><br><span class="line">set(LIBSHM_SRCDIR $&#123;TORCH_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class="line">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure>

<p>继续查看torch/lib/libshm下的CMakeLists.txt，其中生成的库为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD_LIBRARY(shm SHARED core.cpp)</span><br></pre></td></tr></table></figure>

<p>有关的库依赖，分为预装库和本项目（pytorch）内包含的库，CMake生成规则位于cmake/Dependencies.cmake文件中，仔细查看该文件发现：</p>
<ul>
<li>预先装的库依赖，这些库名存在Caffe2_PUBLIC_DEPENDENCY_LIBS中。如上文所举例子OpenBLAS 那样添加g++的链接flag和 -I<include dir>flag。</include></li>
<li>本项目内包含的库。包括：<br>(1) tbb<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;/aten/src/ATen/cpu/tbb)    # 添加tbb库</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>(2) qnnpack</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 添加 qnnpack 库</span><br><span class="line"># source directory为$&#123;PROJECT_SOURCE_DIR&#125;/third_party/QNNPACK</span><br><span class="line"># output directory为$&#123;PROJECT_BINARY_DIR&#125;/confu-deps/QNNPACK</span><br><span class="line">add_subdirectory(&quot;$&#123;QNNPACK_SOURCE_DIR&#125;&quot; &quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/QNNPACK&quot;)</span><br><span class="line">list(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)</span><br></pre></td></tr></table></figure>

<p>最后一行指引CMake去QNNPACK的目录（位于third_party下）去生成qnnpack库，然后回到Dependencies.cmake中添加到Caffe2_DEPENDENCY_LIBS中。<br>(3) nnpack</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 添加 nnpack</span><br><span class="line">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/External/nnpack.cmake)</span><br></pre></td></tr></table></figure>

<p>跳至nnpack.cmake文件，发现其中包含</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_subdirectory($&#123;NNPACK_SOURCE_DIR&#125; $&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/NNPACK)</span><br></pre></td></tr></table></figure>

<p>找到包含NNPACK的代码目录位于third_party下，显然这个NNPACK也应该包含CMakeLists.txt文件指示CMake 生成nnpack库，然后回到Dependencies.cmake中将nnpack添加到Caffe2_DEPENDENCY_LIBS。</p>
<p>(4) 类似地，还添加了 cpuinfo，gflag，glog::glog，googletest，fbgemm，fp16等。这些也不一定全部使用，是否使用还得看相应配置</p>
<p>(5) LMDB。使用如下语句</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_package(LMDB)</span><br></pre></td></tr></table></figure>

<p>所以去cmake/Modules目录下寻找FindLMDB.cmake， 在这个.cmake文件中寻找lmdb库以及lmdb.h头文件（linux中已经安装，分别位于/usr/lib/x86_64-linux-gnu和/usr/include）, 将库名称和头文件目录分别保存于变量LMDB_LIBRARIES和LMDB_INCLUDE_DIR，然后回到Dependencies.cmake，照例执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">include_directories(SYSTEM $&#123;LMDB_INCLUDE_DIR&#125;)</span><br><span class="line">list(APPEND Caffe2_DEPENDENCY_LIBS $&#123;LMDB_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>

<p>类似的，还可以添加OPENCL，LEVELDB，NUMA，ZMQ，REDIS，OPENCV，FFMPEG，Python，MPI等。</p>
<p>(6) pybind11。在Dependencies.cmake添加pybind11依赖，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">find_package(pybind11 CONFIG)# 配置模式下寻找，然而没有$&#123;pybind11_DIR&#125;，也没有pybind11Config.cmake</span><br><span class="line">if(NOT pybind11_FOUND)</span><br><span class="line">  find_package(pybind11)     # 继续module模式下寻找</span><br><span class="line">endif()</span><br></pre></td></tr></table></figure>

<p>虽然存在cmake/Modules/Findpybind11.cmake，然而其中find_path并没有找到pybind11/pybind11.h这个头文件，因为我没有预先安装pybind11，CMake自然是找不到的，于是在Dependencies.cmake中直接添加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include_directories(SYSTEM $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../third_party/pybind11/include)</span><br></pre></td></tr></table></figure>

<p>(7) OPENMP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FIND_PACKAGE(OpenMP QUIET)</span><br></pre></td></tr></table></figure>

<p>如果找到OpenMP，那么${OpenMP_CXX_FLAGS} 和 ${OpenMP_CXX_LIBRARIES}分别存储头文件搜索路径和库文件链接flag，生成caffe2时可以用到OpenMP，用法是在caffe2/CMakeLists.txt中，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target_compile_options(caffe2 INTERFACE $&#123;OpenMP_CXX_FLAGS&#125;)</span><br><span class="line">target_link_libraries(caffe2 PRIVATE $&#123;OpenMP_CXX_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>

<p>(8) CUDA。在Dependencies.cmake中有</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/public/cuda.cmake)</span><br></pre></td></tr></table></figure>

<p>在这个cuda.cmake中，使用 find_library寻找cuda相关的库，找到后作为IMPORTED target进行库的添加，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_library(caffe2::cuda UNKNOWN IMPORTED)</span><br></pre></td></tr></table></figure>

<p>其他cuda有关的库类似的进行添加，包括caffe2::cudart，caffe2::cudnn，caffe2::curand，caffe2::cufft，caffe2::tensorrt， caffe2::cublas，caffe2::nvrtc，当然这些库不一定全部添加，根据配置决定添加哪些库，然后回到Dependencies.cmake中，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)</span><br></pre></td></tr></table></figure>

<p>保存到Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS，将来在caffe2/CMakeLists.txt用于链接。</p>
<p>(9) 其他的依赖库如NCCL，CUB，GLOO等与上述某一点说明类似，不再一一罗列。</p>
<p>Dependencies.cmake中有很多库是作为生成caffe2库的依赖，比如QNNPACK，对这部分库添加到Caffe2_DEPENDENCY_LIBS（或Caffe2_PUBLIC_DEPENDENCY_LIBS，Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS），这个使用下面语句（位于caffe2/CMakeLists.txt）得到链接flag</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">target_link_libraries(caffe2 PRIVATE $&#123;Caffe2_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>生成python的扩展库。首先后三个有关caffe2的扩展已经在上一步中生成并安装，所以对于剩下的两个扩展予以说明。</li>
</ol>
<ul>
<li>torch._C 链接的两个库为<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main_libraries=[&apos;shm&apos;, &apos;torch_python&apos;]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>显然前面已经生成了这两个库。而使用的源文件则为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">main_sources=[&quot;torch/csrc/stub.cpp&quot;]</span><br></pre></td></tr></table></figure>

<ul>
<li>torch._dl此扩展使用源文件torch/csrc/dl.c生成 。查看这个文件，发现就是添加了&lt;dlfcn.h&gt;中的三个常量到torch._dl库中，如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RTLD_GLOBAL=0x100</span><br><span class="line">RTLD_NOW   =0x2</span><br><span class="line">RTLD_LAZY  =0x1</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>这三个常量指示动态加载（比如加载torch._C）的模式，用于dlopen()方法中，增加这三个常量是为了防止python 的os 模块中没有这些flag，并且也没有python的DLFCN模块，此时可以从torch._dl中得到这些flag。相当于把torch._dl当作备胎。</p>
<h3 id="还有…"><a href="#还有…" class="headerlink" title="还有…"></a>还有…</h3><p>可能，大概了解清楚PyTorch的安装过程了，毕竟安装过程我也没试过（只试过较老版本的安装），没有看到最终生成的各种文件，仅供参考吧。</p>
-->
      
    </div>
    <footer class="article-footer">
      <!--<a data-url="https://shajianjian.github.io/2019/06/12/PyTorch-1/" data-id="cjwu48im400037wvcek39ab0p" class="article-share-link">Share</a>-->
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/">PyTorch</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 shajianjian<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> with 
      theme_by <a href="http://hexo.io/" target="_blank">mango</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives/" class="mobile-nav-link">Archives</a>
  
    <a href="/about/" class="mobile-nav-link">about</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>