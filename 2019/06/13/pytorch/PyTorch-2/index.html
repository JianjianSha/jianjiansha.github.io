<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="PyTorch-2, SJJ">
    <meta name="description" content="torch installization

依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是
import torch
于是阅读 torch/__init__.py，发现需要加载torc">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>PyTorch-2 | SJJ</title>
    <link rel="icon" type="image/png" href="/medias/logo.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">SJJ</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/resume" class="waves-effect waves-light">
      
      <i class="fas fa-file" style="zoom: 0.6;"></i>
      
      <span>简历（英）</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/jianli" class="waves-effect waves-light">
      
      <i class="fas fa-file" style="zoom: 0.6;"></i>
      
      <span>简历（中）</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">SJJ</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/resume" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-file"></i>
			
			简历（英）
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/jianli" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-file"></i>
			
			简历（中）
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/jianjiansha/jianjiansha.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/jianjiansha/jianjiansha.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">PyTorch-2</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/PyTorch/">
                                <span class="chip bg-color">PyTorch</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/DL-Framework/" class="post-category">
                                DL Framework
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-06-13
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1>torch installization</h1>
<span id="more"></span>
<p>依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是</p>
<pre class="line-numbers language-none"><code class="language-none">import torch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>于是阅读 <code>torch/__init__.py</code>，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，</p>
<pre class="line-numbers language-none"><code class="language-none">old_flags&#x3D;sys.getdlopenflags()
sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)
from torch._C import *
__all__ +&#x3D; [name for name in dir(_C)
            if name[0] !&#x3D; &#39;_&#39; and
            not name.endswith(&#39;Base&#39;)]
sys.setdlopenflags(old_flags)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>_<em>将torch.<em>C中（不包括_开头和Base结尾）的属性导出到当前域。</em></em></p>
<p><code>__init__.py</code>除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，</p>
<pre class="line-numbers language-none"><code class="language-none">extern PyObject* initModule();
PyMODINIT_FUNC PyInit__C()   &#x2F;&#x2F; 在python脚本中，import _C 时调用
&#123;
  return initModule();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>根据python3扩展库的规则可知，<code>import torch._C</code> ，调用PyInit__C函数（调用名为PyInit_&lt;package&gt;的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。</p>
<p>shm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，</p>
<pre class="line-numbers language-none"><code class="language-none">set(LIBSHM_SUBDIR libshm)
set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;&#x2F;lib&#x2F;$&#123;LIBSHM_SUBDIR&#125;)
add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现</p>
<pre class="line-numbers language-none"><code class="language-none">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>TORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。</p>
<p>initModule方法定义在torch/csrc/Module.cpp，</p>
<pre class="line-numbers language-none"><code class="language-none">#ifdef USE_CUDA
namespace torch &#123; namespace cuda &#123;
void initModule(PyObject* module);       &#x2F;&#x2F; 模块中有关cuda部分的初始化函数声明
&#125;&#125;
#endif

static std::vector&lt;PyMethodDef&gt; methods;

PyObject* module;
PyObject* initModule() &#123;                 &#x2F;&#x2F; 声明并定义模块初始化函数
  &#x2F;&#x2F; 向methods中添加方法定义
  THPUtils_addPyMethodDefs(methods, TorchMethods);
  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);
  ...
  &#x2F;&#x2F; 真正的扩展模块定义
  static struct PyModuleDef torchmodule &#x3D; &#123;
    PyModuleDef_HEAD_INIT,
    &quot;torch._C&quot;,                          &#x2F;&#x2F; 扩展模块名
    nullptr,                           
    -1,
    methods.data()                       &#x2F;&#x2F; 模块中的方法定义
  &#125;;
  ASSERT_TRUE(module &#x3D; PyModule_Create(&amp;torchmodule)); &#x2F;&#x2F; 创建模块并确保创建成功
  &#x2F;&#x2F; 对模块进行各种初始化
#ifdef USE_CUDA
  torch::cuda::initModule(module);       &#x2F;&#x2F; 执行cuda相关的初始化
#endif
  ...
  &#x2F;&#x2F; 定义模块的属性设置函数，setter
  &#x2F;&#x2F; 属性名为name，值为v，incref表示是否对值对象增加引用计数
  &#x2F;&#x2F; 设置成功返回1，否则返回0
  auto set_module_attr &#x3D; [&amp;](const char* name, PyObject* v, bool incref &#x3D; true) 
  &#123;
    if(incref) &#123;
      Py_INCREF(v);
    &#125;
    return PyModule_AddObject(module, name, v) &#x3D;&#x3D; 0;
  &#125;
  &#x2F;&#x2F; 设置模块属性
  ...
  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));
  &#x2F;&#x2F; 向模块添加方法
  auto py_module &#x3D; py::reinterpret_borrow&lt;py::module&gt;(module);
  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);
  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);
  ...    &#x2F;&#x2F; 设置模块其他属性
  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;, 
        (PyObject*)THPDefaultGenerator, false));
  torch::nn::init__THNN(module);  &#x2F;&#x2F; 增加 _THNN 属性
#ifdef USE_CUDA
  torch::nn::init_THCUDD(module);
#endif
  return module;
  ...
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。</p>
<h1>methods/members in torch._C</h1>
<ul>
<li>使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># TorchMethods 
_initExtension
_autograd_init
...
# DataLoaderMethods 
_set_worker_signal_handlers
_set_worker_pids
...
# torch::autograd::python_functions(), torch&#x2F;csrc&#x2F;autograd&#x2F;init.cpp
set_grad_enabled
is_grad_enabled
set_anomaly_enabled
is_anomaly_enabled
# torch::multiprocessing::python_functions(), torch&#x2F;csrc&#x2F;multiprocessing&#x2F;init.cpp
_multiprocessing_init
# torch::distributed::c10d::python_functions()  同上类似
...
# THCPModule_method(), torch&#x2F;csrc&#x2F;cuda&#x2F;Module.cpp
_cuda_init
_cuda_setDevice
...
_nccl_version
...
# THCUDNN_method()
_cudnn_version
# THDPModule_methods(), torch&#x2F;csrc&#x2F;distributed&#x2F;Module.cpp
_dist_init_extension
_dist_init_process_group
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>
<p>生成模块torch._C 后再向其添加如下成员：</p>
<ul>
<li>
<p>向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。</p>
<p>torch._C._TensorBase这个类型具有属性</p>
  <pre class="line-numbers language-none"><code class="language-none">_cdata
_version
grad_fn
_grad_fn
is_leaf
data
_grad
grad
...
device
ndim<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>并且具有以下方法</p>
  <pre class="line-numbers language-none"><code class="language-none"># variable_methods, torch&#x2F;csrc&#x2F;autograd&#x2F;generated&#x2F;python_variable_methods.cpp
__add__
__radd__
...
apply_
byte
char
contiguous
...
where
zero_
# extra_method
_make_subclass<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>类型torch._C._FunctionBase， 这个类型具有方法和属性为</p>
  <pre class="line-numbers language-none"><code class="language-none"># method
apply
_do_forward
_do_backward
_register_hook_dict
register_hook
# property
saved_tensors
saved_variables
...
requires_grad
metadata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>类型 torch._C._VariableFunctions 包含方法</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">arange
as_tensor
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
empty       <span class="token comment"># 出现我们这里所讨论的 torch.empty</span>
empty_like
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。</p>
</li>
<li>
<p>向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。</p>
</li>
<li>
<p>向torch._C添加模块， _nn，cpp，_onnx。</p>
</li>
<li>
<p>向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。</p>
</li>
</ul>
</li>
</ul>
<h1>some installization w.r.t. torch._C</h1>
<h3 id="THPxxxStorage-init">THPxxxStorage_init</h3>
<p>torch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。</p>
<p>注意到从Module.cpp文件中头文件引用：</p>
<pre class="line-numbers language-none"><code class="language-none">#include &lt;TH&#x2F;TH.h&gt;               &#x2F;&#x2F; TH&#x3D;TorcH
#include &lt;c10&#x2F;util&#x2F;Logging.h&gt;
#include &lt;ATen&#x2F;ATen.h&gt;
...
#include &lt;torch&#x2F;csrc&#x2F;THP.h&gt;      &#x2F;&#x2F; THP&#x3D;TorcH Python
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。</p>
<p>一方面，头文件 TH/TH.h 中引用了#include &lt;TH/THGeneral.h&gt;，在aten/src/TH目录下的CMakeLists.txt中有这么一行</p>
<pre class="line-numbers language-none"><code class="language-none">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;&#x2F;THGeneral.h&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在THGeneral.h中有如下宏定义</p>
<pre class="line-numbers language-none"><code class="language-none">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w
#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>另一方面，torch/csrc/THP.h 中引用了#include &lt;torch/src/Storage.h&gt;，在这个Storage.h中有如下语句</p>
<pre class="line-numbers language-none"><code class="language-none">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)
...
#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;
#include &lt;TH&#x2F;THGenerateAllType.h&gt;

#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;
#include &lt;TH&#x2F;THGenerateHalfType.h&gt;

#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;
#include &lt;TH&#x2F;THGenerateBoolType.h&gt;

#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&gt;
#include &lt;TH&#x2F;THGenerateQTypes.h&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句</p>
<pre class="line-numbers language-none"><code class="language-none">#ifndef TH_GENERIC_FILE
#define TH_GENERIC_FILE &quot;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.h&quot;         &#x2F;&#x2F; (0)
#else
...
bool THPStorage_(init)(PyObject *module);                      &#x2F;&#x2F; (1)
...
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>而文件TH/THGenerateAllType.h则包含语句</p>
<pre class="line-numbers language-none"><code class="language-none">#include &lt;TH&#x2F;THGenerateFloatTypes.h&gt;
#include &lt;TH&#x2F;THGenerateIntTypes.h&gt;
...
#undef TH_GENERIC_FILE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 此时 TH_GENERIC_FILE是已定义的
#include &lt;TH&#x2F;THGenerateFloatType.h&gt;
#include &lt;TH&#x2F;THGenerateDoubleType.h&gt;
#undef TH_GENERIC_FILE     &#x2F;&#x2F; 这里将TH_GENERIC_FILE 设为未定义<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>以TH/THGenerateFloatType.h为例说明，此文件中有语句</p>
<pre class="line-numbers language-none"><code class="language-none">#define Real Float
...
#line 1 TH_GENERIC_FILE
#include TH_GENERIC_FILE         &#x2F;&#x2F; (2)
...
#undef Real<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换</p>
<pre class="line-numbers language-none"><code class="language-none">bool THPStorage_(init)(PyObject *module);  -&gt;
bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;
bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;
bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;
bool THPFloatStorage_init(PyObject *module);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>类似地，#include &lt;TH/THGenerateDoubleType.h&gt;，则得到THPDoubleStorage_init，</p>
<p>#include &lt;TH/THGenerateIntTypes.h&gt; 得到</p>
<pre class="line-numbers language-none"><code class="language-none">THPByteStorage_init
THPCharStorage_init
THPShortStorage_init
THPIntStorage_init
THPLongStorage_init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>对4组include中的其他三组，则得到</p>
<pre class="line-numbers language-none"><code class="language-none">THPHalfStorage_init
THPBoolStorage_init
THPQUInt8Storage_init
THPQInt8Storage_init
THPQInt32Storage_init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含</p>
<pre class="line-numbers language-none"><code class="language-none">#include &lt;TH&#x2F;THStorageFunctions.hpp&gt;
#include &lt;torch&#x2F;csrc&#x2F;THP.h&gt;                   &#x2F;&#x2F; include THPxxxStorage_init 函数声明
...
#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;
#include &lt;TH&#x2F;THGenerateAllTypes.h&gt;

#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;
#include &lt;TH&#x2F;THGenerateHalfType.h&gt;

#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;
#include &lt;TH&#x2F;THGenerateBoolType.h&gt;

#include &lt;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&gt;
#include &lt;TH&#x2F;THGenerateQTypes.h&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，</p>
<pre class="line-numbers language-none"><code class="language-none">#ifndef TH_GENERIC_FILE
#define TH_GENERIC_FILE &quot;torch&#x2F;csrc&#x2F;generic&#x2F;Storage.cpp&quot;              &#x2F;&#x2F; (11)
#else
...                                                                   &#x2F;&#x2F; (12)
bool THPStorage_(init)(PyObject *module)
&#123;
  static std::vector&lt;PyMethodDef&gt; methods;
  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));
#ifndef THD_GENERIC_FILE
  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);
#endif
  
  THPStorageType.tp_methods &#x3D; methods.data();
  THPStorageType.tp_members &#x3D; THPStorage_(members);
  THPStorageType.tp_getset &#x3D; THPStorage_(properties);
  if (PyType_Ready(&amp;THPStorageType) &lt; 0)
    return false;
  Py_INCREF(&amp;THPStorageType);
  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);
  THPStorage_(initCopyMethods)();
  return true;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏</p>
<pre class="line-numbers language-none"><code class="language-none">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在TH/THGeneral.h中存在宏定义</p>
<pre class="line-numbers language-none"><code class="language-none">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)
#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为&quot;FloatStorageBase&quot;，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。</p>
<p>以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据</p>
<pre class="line-numbers language-none"><code class="language-none">#define Real Float
...
#include TH_GENERIC_FILE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。</p>
<p>其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。</p>
<p>torch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。</p>
<p>现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，</p>
<pre class="line-numbers language-none"><code class="language-none">PyTypeObject THPStorageType &#x3D; &#123;
  PyVarObject_HEAD_INIT(nullptr, 0)
  &quot;torch._C.&quot; THPStorageBaseStr,               &#x2F;* tp_name *&#x2F;
  sizeof(THPStorage),                          &#x2F;* tp_basicsize *&#x2F;
  ...
  THPStorage_(pynew),                          &#x2F;* tp_new *&#x2F;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义</p>
<pre class="line-numbers language-none"><code class="language-none">struct THPStorage &#123;
  PyObject_HEAD
  THWStorage *cdata;
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）</p>
<p>然后查看类创建 THPStorage_(pynew) 的定义</p>
<pre class="line-numbers language-none"><code class="language-none">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)
&#123;
  Py_ssize_t num_args &#x3D; args ? PyTuple_Size(args) : 0;   &#x2F;&#x2F; 可变长度参数的个数

  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); &#x2F;&#x2F; 分配内存，让self指向这个内存块
  ...
  c10::Allocator * allocator &#x3D; nullptr;

  if (kwargs !&#x3D; nullptr) &#123;                               &#x2F;&#x2F; named arguments
    PyObject *allocator_ptr &#x3D; PyDict_GetItemString(kwargs, &quot;allocator&quot;); &#x2F;&#x2F; 获取参数allocator的值
    if (allocator_ptr) &#123;
      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);
      &#x2F;&#x2F; 转为 c10::Allocator 指针
      allocator &#x3D; static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));
      PyDict_DelItemString(kwargs, &quot;allocator&quot;);
    &#125;
    Py_ssize_t num_kwargs &#x3D; PyDict_Size(kwargs);
    if (num_args &#x3D;&#x3D; 0) &#123;
      PyObject *cdata_ptr &#x3D; PyDict_GetItemString(kwargs, &quot;cdata&quot;);
      if (num_kwargs&#x3D;&#x3D;1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   &#x2F;&#x2F; 提供了cdata值
        THWStorage *ptr &#x3D; (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);
        self-&gt;cdata &#x3D; ptr;
        return (PyObject*)self.release();       &#x2F;&#x2F; 返回THPStorage指针
      &#125;
    &#125;
    THPUtils_assert(num_kwargs &#x3D;&#x3D; 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);
  &#125;

  if (num_args &#x3D;&#x3D; 0) &#123;
    if (allocator) &#123;                            &#x2F;&#x2F; 未提供cdata值，则需要创建THWStorage类型实例
      self-&gt;cdata &#x3D; THPStorage_(newWithAllocator)(0, allocator);
    &#125; else &#123;
      self-&gt;cdata &#x3D; THWStorage_(new)(LIBRARY_STATE_NOARGS);
    &#125;
    return (PyObject*)self.release();
  &#125;
  ...     &#x2F;&#x2F; 使用其他方法设置 self-&gt;cdata
&#125;   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义</p>
<pre class="line-numbers language-none"><code class="language-none">#define THWStorage THStorage<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，</p>
<pre class="line-numbers language-none"><code class="language-none">Storage.cpp                 -&gt;
#include &lt;TH&#x2F;TH.h&gt;          -&gt;
#include &lt;TH&#x2F;THStorageFunction.h&gt;   -&gt;
#include &lt;TH&#x2F;generic&#x2F;THStorage.h&gt;   -&gt;
#include &lt;c10&#x2F;core&#x2F;StorageImpl.h&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在 TH/generic/THStorage.h 中找到宏定义</p>
<pre class="line-numbers language-none"><code class="language-none">#define THStorage at::StorageImpl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在 c10/core/StorageImpl.h 中找到结构定义</p>
<pre class="line-numbers language-none"><code class="language-none">namespace c10 &#123;
struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;
...
private:
  caffe2::TypeMeta  data_type_;  &#x2F;&#x2F; 数据类型
  DataPtr data_ptr_;             &#x2F;&#x2F; 数据指针
  int64_t numel_;                &#x2F;&#x2F; 数据数量
  bool resizable_;
  bool received_cuda_;
  Allocator* allocator_;         &#x2F;&#x2F; 数据的内存分配器
&#125;;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为</p>
<pre class="line-numbers language-none"><code class="language-none">new                &#x2F;&#x2F; 新建THStorage，未指定 size，即size&#x3D;0，使用默认Allocator
free
size
get
set
data
newWithSize        &#x2F;&#x2F; 新建THStorage，指定 size，使用默认Allocator
newWithAllocator   &#x2F;&#x2F; 新建THStorage，指定 size 和 Allocator
copy_functions
copyByte
...
copyCudaByte
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>此外有宏定义</p>
<pre class="line-numbers language-none"><code class="language-none">#define THWStorage_(NAME) THStorage_(NAME)     &#x2F;&#x2F; torch&#x2F;csrc&#x2F;THP.h
#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   &#x2F;&#x2F; TH&#x2F;THStorageFunctions.h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。</p>
<p>（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）</p>
<p>以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义</p>
<pre class="line-numbers language-none"><code class="language-none">THStorage* THStorage_(newWithSize)(ptrdiff_t size)
&#123;
  THStorage* storage &#x3D; c10::make_instrusive&lt;at::StorageImpl&gt;(
#ifdef THQUANTIZED
    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),
#else
    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        &#x2F;&#x2F; 新建scalar_t 类型
#endif
    size,
    getTHDefaultAllocator(),
    true).release();
  return storage;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，</p>
<pre class="line-numbers language-none"><code class="language-none">StorageImpl(
    caffe2::TypeMeta data_type,
    int64_4 numel,
    at::Allocator* allocator,
    bool resizable)
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>我们看上上个代码片段中StorageImpl构造函数的实参，</p>
<p>首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）</p>
<pre class="line-numbers language-none"><code class="language-none">#define scalar_t float<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>于是，</p>
<pre class="line-numbers language-none"><code class="language-none">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    &#x2F;&#x2F; 假设 THQUANTIZED 未定义<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>caffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，</p>
<pre class="line-numbers language-none"><code class="language-none">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \
  namespace detail &#123;                                                       \
  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) &#x3D;    \
    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \
  &#125;                                                                        \
  template&lt;&gt;                                                               \
  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \
  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \
    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \
  &#125;
  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)

#define C10_CONCATENATE_IMPL(s1,s2) s1##s2
#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>经过宏替换，得到 _typeMetaDataInstance的模板函数定义</p>
<pre class="line-numbers language-none"><code class="language-none">template&lt;&gt;
const detail::TypeMetaData*
TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;
  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>还有一组宏，用于生成模板特例化，</p>
<pre class="line-numbers language-none"><code class="language-none">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \
  template&lt;&gt;                                                           \
  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \
    return TypeIdentifier(PreallocatedId);                             \
  &#125;                                                                    \
  namespace detail &#123;                                                   \
  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \
    _typeMetaDataInstance_preallocated_,                               \
    PreallocatedId);                                                   \
  &#125;                                                                    \
  template&lt;&gt;                                                           \
  inline const detail::TypeMetaData*                                   \
  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \
    return &amp;C10_CONCATENATE(                                           \
      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \
  &#125;                                                                    \
#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \
  namespace detail &#123;                                                 \
  const TypeMetaData C10_CONCATENATE(                                \
    _typeMetaDataInstance_preallocated_,                             \
    PreallocatedId) &#x3D; _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\
  &#125;                                                                  
&#x2F;&#x2F; 调用
CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>对于系统内部变量如 float，得到函数模板特例化的定义</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 函数声明
namespace detail &#123;
__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData
_typeMetaDataInstance_preallocated_Preallocated;
&#125;

template&lt;&gt;
inline const detail::TypeMetaData*
TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;
  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>另外，在c10/util/typeid.cpp中有如下调用</p>
<pre class="line-numbers language-none"><code class="language-none">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>经过宏替换得到</p>
<pre class="line-numbers language-none"><code class="language-none">namespace detail &#123;                                                 
  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId
    &#x3D; _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));
&#125;   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>于是函数模板特例化最终形式为，</p>
<pre class="line-numbers language-none"><code class="language-none">template&lt;&gt;
inline const detail::TypeMetaData*
TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;
  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>detail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，</p>
<pre class="line-numbers language-none"><code class="language-none">struct TypeMetaData final &#123;
&#x2F;&#x2F; 函数类型的别名
using New &#x3D; void*();                            &#x2F;&#x2F; new
using PlacementNew &#x3D; void(void*, size_t);       &#x2F;&#x2F; 占位new
using Copy &#x3D; void(const void*, void*, size_t);  &#x2F;&#x2F; 类型数组拷贝
using PlacementDelete &#x3D; void(void*, size_t);
using Delete &#x3D; void(void*);
... &#x2F;&#x2F;构造函数

size_t itemsize_;  &#x2F;&#x2F; 类型占多少字节
New* new_;
PlacementNew* placementNew_;   &#x2F;&#x2F; 定位放置 new
Copy* copy_;        &#x2F;&#x2F; 类型拷贝
Delete* delete_;    &#x2F;&#x2F; 类型析构
TypeIdentifier id_; &#x2F;&#x2F; 类型全局唯一id
const char* name_;  &#x2F;&#x2F; 类型名称
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义</p>
<pre class="line-numbers language-none"><code class="language-none">template &lt;class T&gt;
inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;
  return &#123;sizeof(T),                 &#x2F;&#x2F; 类型T占多少字节
          _PickNew&lt;T&gt;(),             &#x2F;&#x2F; 通过 new T
          _PickPlacementNew&lt;T&gt;(),
          _PickCopy&lt;T&gt;(),      
          _PickPlacementDelete&lt;T&gt;(),
          _PickDelete&lt;T&gt;(),
          TypeIdentifier::Get&lt;T&gt;(),  &#x2F;&#x2F; 获取类型的全局唯一id，
          typeName&#125;;                 &#x2F;&#x2F; 类型名称，例如float的名称为&quot;float&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用</p>
<pre class="line-numbers language-none"><code class="language-none">TypeIdentifier::Get&lt;T&gt;()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。</p>
<p>对于其他类型如 int，double，int64_t等类似处理。</p>
<p>PyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。</p>
<p>至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为</p>
<pre class="line-numbers language-none"><code class="language-none">size,             &#x2F;&#x2F; 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）
getTHDefaultAllocator(),  &#x2F;&#x2F; 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配
true                      &#x2F;&#x2F; 被构造的StorageImpl可以resize<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase</p>
<p>记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。</p>
<p>FloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。</p>
<p>类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，</p>
<pre class="line-numbers language-none"><code class="language-none">  torch::nn::init_THNN(module);
#ifdef USE_CUDA
  torch::nn::init_THCUNN(module);
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。</p>
<p><code>torch._C</code>模块初始化过程到这里就完成了。回到 <code>torch/__init__.py</code>，继续看看 import torch时接下来做了哪些事情：</p>
<ol>
<li>定义了模块函数 typename，is_tensor，is_storage等</li>
<li>导入torch下其他子模块</li>
<li>调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理</li>
<li>调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：
<ul>
<li>初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；</li>
<li>初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；</li>
<li>初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；</li>
<li>初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor</li>
<li>共享内存管理初始化，设置文件路径；</li>
<li>执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），  <pre class="line-numbers language-none"><code class="language-none">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, 
TH_CONCAT_2(at::k, Real));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，  <pre class="line-numbers language-none"><code class="language-none">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。</li>
</ul>
</li>
</ol>
<p>到这里，import torch 的工作全部完成。</p>
<h1>后记：</h1>
<p>初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">shajianjian</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jianjiansha.github.io/2019/06/13/pytorch/PyTorch-2/">https://jianjiansha.github.io/2019/06/13/pytorch/PyTorch-2/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">shajianjian</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/PyTorch/">
                                    <span class="chip bg-color">PyTorch</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2019/06/13/obj_det/GIoU/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/16.jpg" class="responsive-img" alt="GIoU">
                        
                        <span class="card-title">GIoU</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            论文 Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2019-06-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            shajianjian
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/object-detection/">
                        <span class="chip bg-color">object detection</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/06/13/tools/Hexo-Sync/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="Hexo Sync">
                        
                        <span class="card-title">Hexo Sync</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            场景：
在A, B两台电脑上同步Hexo博客
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2019-06-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            shajianjian
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/tool/">
                        <span class="chip bg-color">tool</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2024</span>
            
            <a href="/about" target="_blank">shajianjian</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/jianjiansha" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:501834524@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=501834524" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 501834524" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    
        <!-- <script src='https://unpkg.com/mermaid@latest/dist/mermaid.min.js'></script> -->
        <script src='/libs/mermaid/mermaid.min.js'></script>
        <script>
          if (window.mermaid) {
            mermaid.initialize({theme: 'forest'});
          }
        </script>
    

    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
