---
title: Dynamic Programming (1)
date: 2019-08-07 17:29:56
tags: math, DP
category: math
mathjax: true
---
我计划开启一系列动态规划的方法介绍，主要参考 《Dynamic Programming · A Computational Tool》这本书。

# 简介

动态规划用于解决一类优化问题，顺序地做出决策，每一次决策使得问题转变为对一个子问题的优化，直到问题解决，这个决策序列就是原始问题的最优解。我们也可以将 问题/子问题 看作状态，决策就是状态间的转移，问题得到解决就对应着`结束状态`。

## 优化原理

> 一个最优决策满足：无论问题初始状态和初始决策是什么，剩余的决策序列构成做出初始决策之后问题状态的最优解。

以最短路径问题为例说明：在一个指定了起点和终点的有权路径图中，无论之前选择了什么路径，我们必须保证从当前节点起，剩余的路径选择必须是最优的。~~这是一种递归的处理方式，要解这个问题，直觉告诉我们似乎可以采用逆推法（隐马尔可夫预测问题的求解），这个直觉很重要，因为下文将会用到它。~~

### 顺序决策过程
考虑具有如下形式的优化问题：$opt_{d \in \Delta} \{H(d)\}$，其中 d 为决策，决策空间为 $\Delta$，H 为目标函数，H(d) 的最优解记为 $d^{\ast}$：$d^{\ast}=\arg opt_d \{H(d)\}$。动态规划问题则要求寻找有序决策集 $\{d_1,...,d_n\}$，使得目标函数 $h(d_1,...,h_n)$ 取得最优 $H^{\ast}$。

我们可以枚举 $\{d_1,...,d_n\}$ 所有可能的取值，然后代入目标函数进行计算，这就是 “暴力” 解法，但是这只在决策空间较小时有效，在决策空间很大时，这种方法效率非常低不可取，所以此时我们需要按顺序做出决策 $d_1,...,d_n$，使得
$$\begin{aligned}H^{\ast}&=opt_{(d_1,...,d_n)\in \Delta} \{h(d_1,...,d_n)\}
\\\\ &=opt_{d_1 \in D_1} \{opt_{d_2 \in D_2}\{...\{opt_{d_n \in D_n}\{h(d_1,...,d_n)\}\}...\}\} \quad(1.1)\end{aligned}$$

其中 $(d_1,...,d_n) \in \Delta=D_1 \times ... \times D_n$。通常，第 i 个决策空间依赖于前面所有的决策：$d_i \in D_i(d_1,...,d_{i-1})$，于是式 (1.1) 可改写为
$$\begin{aligned}H^{\ast}&=opt_{(d_1,...,d_n)\in \Delta} \{h(d_1,...,d_n)\}
\\\\ &=opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{h(d_1,...,d_n)\}\}...\}\} \quad(1.2)\end{aligned}$$

式 (1.2) 的优化操作是一个嵌套结构，可以由内向外解决问题，解最内层的优化问题，此时前序所有决策均看作已知，可得到最优 $d_n$，记作 $d_n^{\ast}(d_1,...,d_{n-1})$，可以将 $d_n^{\ast}$ 看作是其前序决策的函数。向外逆推，直到解出最外层优化问题 $opt_{d_1 \in D_1} \{h(d_1,d_2^{\ast},...,d_n^{\ast} \}$ 的解 $d_1^{\ast}$。

如果改变决策顺序目标函数的最优解相同，如
$$\begin{aligned} &opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)} \{... \{opt_{d_n \in D_n(d_1,...,d_{n-1})} \{h(d_1,...,d_n)\}\}...\}\}
\\\\ = \ & opt_{d_n \in D_n} \{opt_{d_{n-1} \in D_{n-1}(d_n)} \{... \{opt_{d_1 \in D_n(d_2,...,d_n)} \{h(d_1,...,d_n)\}\}...\}\} \quad(1.3) \end{aligned}$$

那么决策空间 $D_i$ 可能会跟之前有所不同，因为此时 $D_i$ 依赖于 $(d_{i+1},...,d_n)$，所以问题求解的效率会随着决策顺序的变化而有所改变。

回到前面式 (1.2)，假设我们暂时做出最外层决策 $d_1$，此时 $d_1$ 是否是最优决策还尚未可知，但是根据前面所说的优化原理，无论之前做出什么决策，之后的决策需要保证是最优的，所以有
$$\begin{aligned}H^{\ast}&=opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{h(d_1,...,d_n)\}\}...\}\}
\\\\ &=opt_{d_1 \in D_1}\{h(d_1,d_2^{\ast}(d_1),...,d_n^{\ast}(d_1)\} \qquad \qquad(1.4) \end{aligned}$$

其中 $d_i^{\ast}(d_1), \ i>1$ 可以看作是输入参数 $d_1$ 的偏函数（partial function）。最外层决策的最优解则为 $d_1^{\ast}=\arg opt_{d_1 \in D_1} \{h(d_1,d_2^{\ast}(d_1),...,d_n^{\ast}(d_1))\}$，可以看出，$d_1$ 与其后序的决策互相耦合，要解这样的问题还是有点棘手。

#### 目标函数可分
一种方法是将 $d_1$ 决策与 $d_2,...,d_n$ 决策独立开来，也就是说通过解决形如 $opt_{d_1 \in D_1}\{H'(d_1)\}$ 问题的最优解以得到 $d_1$ 的最佳决策，这是一种贪心算法，这种算法在局部最优 $opt_{d_1}\{H'(d_1)\}$ 与全局最优 $H^{\ast}$ 一致的情况下是有效的。我们先分析这种特殊情况，因为它足够简单：假设目标函数 h 强可分，即
$$h(d_1,...,d_n)=C_1(d_1) \circ C_2(d_2) \circ ... \circ C_n(d_n) \qquad (1.5)$$
其中 $C_i$ 是决策 $d_i$ 关联的决策损失函数，$\circ$ 是某种关联二元操作（例如 加 或 乘）并具有属性 
$$opt_d\{a \circ C(d)\}=a \circ opt_d\{C(d)\}$$
其中 a 不依赖于决策 d。在序列决策过程中，损失 $C_n$ 不仅依赖于 $d_n$，还依赖于当前问题所处的状态 $(d_1,d_2,...,d_{n-1})$，所以改写上式为
$$h(d_1,...,d_n)=C_1(d_1|\emptyset) \circ C_2(d_2|d_1) \circ ... \circ C_n(d_n|d_1,...,d_{n-1}) \qquad(1.6)$$

定义如果目标函数 h 满足
$$h(d_1,...,d_n)=C_1(d_1) \circ C_2(d_1,d_2) \circ ... \circ C_n(d_1,...,d_n) \qquad(1.7)$$
那么称其弱可分（强可分是弱可分的一种特殊情况），此时有
$$\begin{aligned} & opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{h(d_1,...,d_n)\}\}...\}\}
\\\\ = \ & opt_{d_1 \in D_1} \{opt_{d_2 \in D_2(d_1)}\{...\{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{C_1(d_1) \circ C_2(d_1,d_2) \circ ... \circ C_n(d_1,...,d_n)\}\}...\}\}
\\\\ = \ & opt_{d_1 \in D_1} \{C_1(d_1|\emptyset) \circ opt_{d_2 \in D_2(d_1)}\{C_2(d_1,d_2) \circ ... \circ \{opt_{d_n \in D_n(d_1,...,d_{n-1})}\{C_n(d_1,...,d_n)\}...\}\} \qquad(1.8) \end{aligned}$$
最后一个等式根据 $\circ$ 操作的属性推导。

令 $f(d_1,...,d_n)$ 表示序列决策过程在已经做出决策 $d_1,...,d_{i-1}$ 时的最优解，即
$$f(d_1,...,d_{i-1})=opt_{d_i}\{opt_{d_{i+1}}\{... \{opt_{d_n} \{C_i(d_i|d_1,...,d_{i-1}) \circ C_{i+1}(d_{i+1}|d_1,...,d_i) \circ ... \circ C_n(d_n|d_1,...,d_{n-1}) \}\}...\}\} \ (1.9)$$
其中因为篇幅起见省略了每个决策的取值空间 $D_i$。现在序列决策过程可表示为
$$\begin{aligned}f(\emptyset)&=opt_{d_1}\{opt_{d_2}\{...\{opt_{d_n}\{C(d_1|\emptyset) \circ C_2(d_2|d_1) \circ ... \circ C_n(d_n|d_1,...,d_{n-1})\}\}...\}\}
\\\\ &opt_{d_1}\{C_1(d_1|\emptyset) \circ opt_{d_2}\{C(d_2|d_1) \circ...\circ opt_{d_n}\{C_n(d_n|d_1,...,d_{n-1})\}...\}\}
\\\\ &opt_{d_1}\{C_1(d_1|\emptyset) \circ f(d_1)\}  \qquad \quad (1.10) \end{aligned}$$
一般地，我们有
$$f(d_1,...,d_{i-1})=opt_{d_i \in D_i(d_1,...,d_{i-1})}\{C_i(d_i|d_1,...,d_{i-1})\circ f(d_1,...,d_i)\} \qquad(1.11)$$

于是我们得到问题的递归函数形式，这就是优化问题的动态规划函数方程（DPFE）。

### DPFE
求解 DPFE 中的 $f(d_1,...,d_{i-1})$，定义状态 $S=(d_1,...,d_{i-1})$，那么 $i=|S|+1=|\{d_1,...,d_{i-1}\}|+1$，于是可以改写 DPFE 为以下形式，
$$f(S)=opt_{d_i \in D_i(S)}\{C_i(d_i|S) \circ f(S')\} \qquad (1.12)$$
其中 $S'=(d_1,...,d_i)$ 是下一状态，$\emptyset$ 是初始状态。记状态空间为 $\mathcal S$，由于 DPFE 是递归的，要终止递归，则要求具备一些基本情况（或称边界条件），例如 $f(S_0)=b, \ S_0 \in \mathcal S_{base}$，对于某个基本（终止）态 $S_0$，$f(S_0)$ 不使用 DPFE 计算其值，而是有一个给定的常数值 b，这就表示到达基本态时，递归结束。

值得注意的是决策序列的长度 n 并非固定，当决策使得目标到达基本态时结束决策过程。前面我们定义状态 S 表示已经做过的决策，下一决策 d 则从 D(S) 中进行选择，但实际上为了表示方便，直接定义状态 S 为下一决策 d 的可选决策空间，即 $d \in S$，于是 DPFE 变为
$$f(S)=opt_{d \in S} \{C(d|S) \circ f(S')\} \qquad (1.13)$$

我们可以使用状态转移系统或者有向图对简单序列决策过程进行建模，状态 S 为节点，决策 d 使得状态从 S 转移到 S'，D(S) 表示处于状态 S 时的决策空间。考虑使用有向图建模，节点表示 DPFE 的状态，边表示状态间的转移，转移对应着决策，边标记为 b(S,S')，表示决策 d 的损失 C(d|S)，其中下一状态 $S'=T(S,d), \ T: \mathcal S \times D \rightarrow \mathcal S$，T 是转移函数，于是 DPFE 转变为
$$f(S)=opt_S\{b(S,S') \circ f(S')\} \qquad(1.14) $$

DPFE 的反转形式为
$$f'(S)=opt_{S'}\{f'(S') \circ b(S',S)\} \qquad(1.15) $$
其中 f'(S) 表示从基本态 $S_0$ 到状态 S 的最优解，注意与前面 f(S) 表示从状态 S 到基本态 $S_0$ 的最优解区分开来。式 (1.14) 为后向形式（backward），式 (1.15) 为前向形式（forward）。

### 动态规划的基本要素
动态规划的基本形式为
$$f(S)=opt_{d \in D(S)} \{R(S,d) \circ f(T(S,d))\}  \quad (1.16)$$
其中，S 表示状态空间 $\mathcal S$ 中的某个状态，d 是决策空间 D(S) 中的某个决策，R(S,d) 是收益函数（或称损失函数，记为 C(d|S)，收益对应最大化，损失对应最小化），T(S,d) 是转移函数，$\circ$ 是二元操作符。为简单起见，我们只考虑离散情况。

### 线性搜索
现在我们来看一个实际例子。问题是需要排列一个长度为 N 的数组 A 中的元素，元素 x 具有概率 $p_x$，通过最小化排列的损失来优化线性搜索过程，例如 A={a,b,c}，且 $p_a=0.2,p_b=0.5,p_c=0.3$，于是共有 6 中排列方式 abc,acb,bac,bca,cab,cba（注意：每个排列均代表一种决策序列），其中 bca 排列的损失为 1.7，计算如下：
1. Strong separable，方法 S  
   $1p_b+2p_c+3p_a$
2. Weak separable，方法 W  
   $(p_a+p_b+p_c)+(p_a+p_c)+(p_a)$

最优排列问题可看作是序列决策过程，每个决策用于决定将 A 的元素置于排列后 A' 的哪个位置上。决策的损失可互相独立（强可分），即方法 S 损失定义为：元素 x 的损失为 $ip_x$，其中 i 为 x 在 A' 中位置；对于 W 方法，决策的损失依赖于决策的顺序，或者说依赖于决策空间，如果以从 A' 的开始到最后这样的顺序进行决策，还以 bca 排列为例说明，第一次决策的空间为 {a,b,c}，第一次决策选择 b 置于 A' 第一个位置，然后第二次决策空间为 {a,c}... 依次类推，决策损失与决策空间相关，定义为决策空间中各元素概率之和 $\sum_{x\in D_i} p_x$。

假设决策顺序为 i=1,2,3，那么对应的决策空间为 $D_1=A,D_2=A-\{d_1\},D_3=A-\{d_1,d_2\}$，方法 S 的目标函数为 $h(d_1,d_2,d_3)=1p_{d_1}+2p_{d_2}+3p_{d_3}$，于是有
$$\begin{aligned}f(\emptyset)&=\min_{d_1\in A}\{\min_{d_2\in A-\{d_1\}}\{\min_{d_3\in A-\{d_1,d_2\}}\{1p_{d_1}+2p_{d_2}+3p_{d_3}\}\}\}
\\\\ &=\min_{d_1\in A}\{1p_{d_1}+\min_{d_2 \in A-\{d_1\}}\{2p_{d_2}+\min_{d_3\in A-\{d_1,d_2\}}\{3p_{d_3}\}\}\} \end{aligned}$$

方法 W 的目标函数为 $h(d_1,d_2,d_3)=\sum_{x \in A}p_x+\sum_{x\in A-\{d_1\}}p_x+\sum_{x \in A-\{d_1,d_2\}}p_x$，于是有
$$\begin{aligned}f(\emptyset)&=\min_{d_1\in A}\{\min_{d_2\in A-\{d_1\}}\{\min_{d_3\in A-\{d_1,d_2\}}\{\sum_{x \in A}p_x+\sum_{x\in A-\{d_1\}}p_x+\sum_{x \in A-\{d_1,d_2\}}p_x\}\}\}
\\\\ &=\min_{d_1\in A}\{\sum_{x \in A}p_x+\min_{d_2 \in A-\{d_1\}}\{\sum_{x\in A-\{d_1\}}p_x+\min_{d_3\in A-\{d_1,d_2\}}\{\sum_{x \in A-\{d_1,d_2\}}p_x\}\}\} \end{aligned}$$

有了损失的计算方法之后，__线性搜索__ 就是依次计算并比较所有排列的损失，具有最小损失的就是最优排列。经过计算发现，bca 就是最佳排列。

### 问题的表示和解
上一小节中的例子可以使用 DP 求解。定义状态 S 为元素的集合，可从中选择决策来确定哪个元素应该放置在 A' 中的哪个位置。DPFE 的形式如下
$$f(S)=\min_{x \in S} \{C(x|S)+f(S-\{x\})\}     \quad(1.17)$$
其中 $S \in 2^A$，$2^A$ 是 A 的幂集。基本态 $f(\emptyset)=0$，我们目标是要求出 $f(A)$。

注意这是前向形式的 DPFE。要写成这是后向形式的 DPFE，则根据式 (1.15) 改写如下
$$f(S)=\min_{S'} \{C(x|S')+f(S')\}     \quad(1.18)$$
其中 $S \in 2^A$，此时我们目标是求 $f(\emptyset)$，基本态 $f(A)=0$。S' 是 S 的前导状态，从前导状态 S' 经过决策 x 到达状态 S。

基于方法 W，损失函数为
$$C_W(x|S)=\sum_{y\in S}p_y$$
基于上一小节的讨论可知，当前的损失与当前决策 x 无关，而依赖于临决策之前的状态 S 有关，即 S 中各元素的概率和。

基于方法 S，那么损失函数为
$$C_S(x|S)=(N+1-|S|)p_x$$
可见此时损失只与当前决策 x 以及决策的序号有关，其中与序号有关是假定了第一个决策确定某元素置于 A' 的第一个位置，第二个决策确定 A' 第二个位置上的元素...依次类推。如果决策顺序反过来，即第一个决策确定 A' 最后一个位置上的元素，那么损失函数需要修改为 $C_S'(x|S)=|S|p_x$。如果将 S 中元素按概率降序排列，事实表明第一个元素（具有最大概率值）将会最小化 $C(x|S)+f(S-\{x\})$，这是一种贪心策略，即只求当前状态下的最优解。事实上确实存在一类 DP 问题用贪心策略也可解决，这个我们暂时不讨论。

现在我们来看下如何解 DP 问题，以式 (1.17) 表示的 DPFE 为例进行说明：
$$\begin{aligned} f(\{a,b,c\}) &= \min\{C(a|\{a,b,c\})+f(\{b,c\}), C(b|\{a,b,c\})+f(\{a,c\}), C(c|\{a,b,c\})+f(\{a,b\})\}
\\\\ f(\{b,c\}) &= \min\{C(b|\{b,c\}+f(\{c\}),C(c|\{b,c\}+f(\{b\})\}
\\\\ f(\{a,c\}) &= \min\{C(a|\{a,c\}+f(\{c\}),C(c|\{a,c\}+f(\{a\})\}
\\\\ f(\{a,b\}) &= \min\{C(a|\{a,b\}+f(\{b\}),C(c|\{a,b\}+f(\{a\})\}
\\\\ f(\{c\}) &= \min \{C(c|\{c\})+f(\emptyset)\}
\\\\ f(\{b\}) &= \min \{C(b|\{b\})+f(\emptyset)\}
\\\\ f(\{a\}) &= \min \{C(a|\{a\})+f(\emptyset)\} 
\\\\ f(\emptyset) &= 0 \end{aligned}$$
其中损失函数可以分别使用方法 S 和方法 W 进行代入计算，这里略。

再以式 (1.18) 表示的 DPFE 进行说明：
$$\begin{aligned} f(\{a,b,c\}) &= 0
\\\\ f(\{b,c\}) &= \min\{C(a|\{a,b,c\}+f(\{a,b,c\})\}\stackrel W=\min \{1.0+0\}=1.0 
\\\\ f(\{a,c\}) &= \min\{C(b|\{a,a,c\}+f(\{a,b,c\})\}\stackrel W=\min \{1.0+0\}=1.0
\\\\ f(\{a,b\}) &= \min\{C(c|\{a,b,c\}+f(\{a,b,c\})\}\stackrel W=\min \{1.0+0\}=1.0
\\\\ f(\{c\}) &= \min \{C(a|\{a,c\})+f(\{a,c\}), C(b|\{b,c\})+f(\{b,c\})\}\stackrel W = \min \{0.5+1.0,0.8+1.0\}=1.5
\\\\ f(\{b\}) &= \min \{C(a|\{a,b\})+f(\{a,b\}), C(c|\{b,c\})+f(\{b,c\})\}\stackrel W = \min \{0.7+1.0,0.8+1.0\}=1.7
\\\\ f(\{a\}) &= \min \{C(b|\{a,b\})+f(\{a,b\}), C(c|\{a,c\})+f(\{a,c\})\}\stackrel W = \min \{0.7+1.0,0.5+1.0\}=1.5
\\\\ f(\emptyset) &= \min \{C(a|a)+f(\{a\}), C(b|b)+f(\{b\}), C(c|c)+f(\{c\})\}\stackrel W = \min \{0.2+1.5,0.5+1.7,0.3+1.5\}=1.7 \end{aligned}$$
以上式中 $\stackrel W=$ 之后部分均表示使用方法 W 进行计算，这是为了演示，方法 S 的代入计算略。

### 带阶决策
第一次决策记为阶 1，第二次决策记为阶 2... 依次类推。将阶号包含进状态 S 的定义中有时候会带来方便甚至是非常有必要的。还以前面的例子进行说明，DPFE 形式 (1.17) 可改写为
$$f(k,S)=\min_{x \in S} \{C(x|k,S)+f(k+1,S-\{x\})\} \quad(1.19)$$

### Path-States
状态 S 可以定义为当前已经做过的决策 $(d_1,...,d_{i-1})$，在有向图中用节点表示状态，状态 S 与初始态 $\emptyset$ 到状态 S 之间的路径有关联（其实这个路径也可以表示为 $(d_1,...,d_{i-1})$），需要特别注意的是，前面的状态 S 是无序的，比如 S={a,b}，表示当前已经做出了决策 a 和 b（或者说做出决策选择了 a 和 b，读者根据具体语境进行调整理解），至于决策 a 和 b 的顺序则未定义，而这里 Path-States 中的状态是有序的，S=(a,b)，表示当前已经做出两个决策，第一个决策是 a 且第二个决策是 b。于是此时 DPFE 的形式可写为
$$f(S)=\min_{x \notin S} \{C(x|S)+f(S + (x))\} \qquad(1.20)$$

前面线性搜索一节中的例子计算过程为
$$\begin{aligned} f(\emptyset) &= \min \{C(a|\emptyset)+f(a),C(b|\emptyset)+f(b),C(c|\emptyset)+f(c)\}\stackrel S= \min\{0.2+1.9,0.5+1.2,0.3+1.6\}=1.7
\\\\ f(a) &= \min \{C(b|a)+f(ab), C(c|a)+f(ac)\}\stackrel S= \min\{2*0.5+0.9,2*0.3+1.5\}=1.9
\\\\ f(b) &= \min \{C(a|b)+f(ba), C(c|b)+f(bc)\}\stackrel S= \min\{2*0.2+0.9,2*0.3+0.6\}=1.2
\\\\ f(c) &= \min \{C(a|c)+f(ca), C(b|c)+f(cb)\}\stackrel S= \min\{2*0.2+1.5,2*0.5+0.6\}=1.6
\\\\ f(ab) &= \min \{C(c|ab)+f(abc)\}\stackrel S= 3*0.3=0.9
\\\\ f(ac) &= \min \{C(b|ac)+f(acb)\}\stackrel S= 3*0.5=1.5
\\\\ f(ba) &= \min \{C(c|ba)+f(bac)\}\stackrel S= 3*0.3=0.9
\\\\ f(bc) &= \min \{C(a|bc)+f(bca)\}\stackrel S= 3*0.2=0.6
\\\\ f(ca) &= \min \{C(b|ca)+f(cab)\}\stackrel S= 3*0.5=1.5
\\\\ f(cb) &= \min \{C(a|cb)+f(cba)\} \stackrel S= 3*0.2=0.6
\\\\ f(abc) &= f(acb)=f(bac)=f(bca)=f(cab)=f(cba)=0 \end{aligned}$$
由于状态是有序的，所以共有 $N!$ 个基本态，损失函数依然可以使用方法 S 和方法 W 计算，例如使用方法 S，损失 $C(c|ab)$ 表示第三次决策使用 c，那么根据方法 S 的定义有 $C(c|ab)=3p_c=3*0.3=0.9$。上面计算中 $\stackrel S=$ 之后部分均表示使用方法 S 进行计算。方法 W 的计算略。

### 松弛 Relaxation
松弛在数学中指通过某种迭代方法逐步得到更好的近似解。考虑一个有限集合 $\{a_1,...,a_N\}$，其最小值可以通过计算结对元素最小化来求解
$$x^{\ast}=\min\{\min\{...\{\min\{a_1,a_2\},a_3\},...\},a_N\}$$
偏最小化序列为 $x_1=a_1, x_2=\min\{x_1,a_2\},...$，为了表示的统一，可以令 $x_1=\min\{x_0,a_1\}, x_0=\infty$。序列 $x_1,x_2,...$ 逐步逼近并最终达到 $x^{\ast}$。松弛就是刻画这种逐步逼近的特性。借助松弛的思想，动态规划问题的 DPFE 可表示为
$$\begin{aligned} f(S)&=\min_{x \in S} \{C(x|S)+f(S_x')\}
\\\\ &=\min\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}'),...,C(x_m|S)+f(S_{x_m}')\} \end{aligned}$$
其中 $S=\{x_1,x_2,...,x_m\}$，$S_x'$ 是选择 x 之后的下一状态，与其计算所有的 $C(x|S)+f(S_x')$ 值，我们不如逐步逼近最终值
$$f(S)=\min\{\min\{...\min\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}')\},...\},C(x_m|S)+f(S_{x_m}')\} \quad (1.21)$$
注意 $C(x_i|S)$ 中状态全部是 S，并且所有的 $f(S_{x_i}')$ 需要提前全部计算出来。

带阶形式的 DPFE 为
$$f(k,S)=\min_x \{C(x|k,S) + f(k-1,S_x')\} \qquad(1.22)$$
其中 k 表示阶段，这里 k 可能不太好理解，我们可以想象从状态 S 经过恰好 k 次变换到达终止态 T，下文最短路径问题中会借鉴式 (1.22)，彼时再回过头来理解可能更加容易些。序列 $f(0,S),f(1,S),...$ 近似于 $f(S)$，序列最小值为 $f(S)$，但这个序列不保证单调性（比如振荡逼近），所以 $f(S)=\min_k \{f(k,S)\}$，注意 $f(k,S)$ 不是 $f(k-1,S)$ 的函数，而是 $f(k-1,S_x')$ 的函数。既然 $f(k,S)$ 序列不一定单调，我们定义一个新的序列 $F(k,S)$ 来保证单调性，
$$F(k,S)=\min\{F(k-1,S), \min_x \{C(x|k,S)+F(k-1,S_x')\}\} \quad(1.23)$$
这里我们可以将 $F(k,S)$ 理解为从状态 S 到终止态 T 最多变换 k 次的损失，与式 (1.22) 中恰好变换 k 次是有区别的。 

### 最短路径问题
在解决前述的线性搜索问题中，我们使用了状态转换图模型，不难发现解决这种线性搜索问题等价于在图中搜索最短路径。

考虑到有环图的复杂性，我们先讨论无环图。对于一个无环图，从起点 s 到终点 t 的最短路径使用 DPFE 可表示为
$$f(p)=\min_q \{b(p,q)+f(q)\} \qquad(1.24)$$
其中 b(p,q) 表示从 p 到 q 的距离，q 是 p 的直接邻点，f(p) 表示从 p 到 t 的最短路径，基本态条件为 f(t)=0。如果 q 不是 p 的直接邻点，那么可以认为 $b(p,q)=\infty$。无环图中，要计算 f(p) 则需要先计算 f(q)。采用自底向上的方式计算，具体不展开。

在有环图中，p 和 q 可能互为后继节点，f(p) 和 f(q) 互相依赖。为了方便，我们假定有环图中没有自环，这样假设是有原因的，如果有自环，即一条从 p 到 p 的分支，考虑以下三种情况：
1. b(p,p) > 0，这条分支会被忽略，因为会增加距离
2. b(p,p) < 0，问题本身不是定义良好的，可以不断的向路径中添加这条分支，从而一直缩短距离
3. b(p,p) = 0，问题本身不是定义良好的，可以不断的向路径中添加这条分支，却不改变距离

所以可以忽略掉自环，以下所讨论的有环图中均没有自环。对于一个有环图，DPFE 为
$$f(p) = \min_q \{b(p,q)+f(q)\} \qquad(1.25)$$
其中 f(q) 可能依赖于 f(p)，做特殊处理：初始时令 $f(p)=\infty, \forall p \ne t; \ f(t)=0$。式 (1.25) 与 (1.24) 一样，因为都是解最短路径模型，只是有环图中进行求解的时候需要做特殊处理。

举例说明，如图 1.2，
![](/images/DP1_fig1.png)

根据式 (1.25) 计算过程如下
$$\begin{aligned}f(s)&=\min \{b(s,x)+f(x),b(s,y)+f(y),b(s,t)+f(t)\}=\min \{3+f(x),5+f(y),\infty+f(t)\}
\\\\f(x)&=\min \{b(x,y)+f(y),b(x,t)+f(t)\}=\min \{1+f(y),8+f(t)\}
\\\\f(y)&=\min \{b(y,x)+f(x),b(y,t)+f(t)\}=\min \{2+f(x),5+f(t)\}
\\\\f(t)&=0 \end{aligned}$$
显然 f(x) 与 f(y) 互相依赖。

初始化时假设 $f(s)=f(x)=f(y)=\infty$，第一次迭代，
$$\begin{aligned}f(s)&=\min \{3+\infty,5+\infty,\infty+f(t)\}=\infty
\\\\f(x)&=\min \{1+\infty,8+0\}=8
\\\\f(y)&=\min \{2+\infty,5+0\}=5
\\\\f(t)&=0 \end{aligned}$$

第二次迭代，
$$\begin{aligned}f(s)&=\min \{3+8,5+5,\infty+0\}=10
\\\\f(x)&=\min \{1+5,8+0\}=6
\\\\f(y)&=\min \{2+8,5+0\}=5
\\\\f(t)&=0 \end{aligned}$$
第三次迭代，
$$\begin{aligned}f(s)&=\min \{3+6,5+5,\infty+0\}=9
\\\\f(x)&=\min \{1+5,8+0\}=6
\\\\f(y)&=\min \{2+6,5+0\}=5
\\\\f(t)&=0 \end{aligned}$$
由于第三次迭代 $f(x),f(y),f(t)$ 均未改变，故第三次迭代后计算到的 f(s) 就是最终 f(s)。

还可以利用带阶 Relaxation 解决有环图问题，仿照式 (1.22)，我们针对最短路径模型改为 DPFE 为
$$f(k,p)=\min_q \{b(p,q)+f(k-1,q)\} \qquad(1.26)$$
其中 f(k,p) 表示从 p 到 t 的最短距离，k 表示 p 到 t 的某个路径需要走恰好 k 步。于是基本条件为： $f(0,t)=0;f(k,t)=\infty, k>0;f(0,p)=\infty, \forall p \ne t$，这表示 t 到 t 走 0 步，代价为 0，走大于 0 步，代价为 $\infty$，因为既然到了 t 点，我们不希望再继续走下去。p 到 t 走 0 步，代价为 $\infty$，这驱使我们从 p 点走出去。还以上面的例子说明，根据式 (1.26) 计算过程为
$$\begin{aligned}f(k,s)&=\min \{b(s,x)+f(k-1,x),b(s,y)+f(k-1,y),b(s,t)+f(k-1,t)\}
\\\\f(k,x)&=\min \{b(x,y)+f(k-1,y),b(x,t)+f(k-1,t)\}
\\\\f(k,y)&=\min \{b(y,x)+f(k-1,x),b(y,t)+f(k-1,t)\}
\\\\f(k,t) \end{aligned}$$
根据基本条件，也就是 k=0 的初始条件，第一次迭代，
$$\begin{aligned}f(1,s)&=\min \{3+f(0,x),5+f(0,y),\infty+f(0,t)\}=\infty
\\\\f(1,x)&=\min \{1+f(0,y),8+f(0,t)\}=8
\\\\f(1,y)&=\min \{2+f(0,x),5+f(0,t)\}=5
\\\\f(1,t)&=\infty \end{aligned}$$
第二次迭代，
$$\begin{aligned}f(2,s)&=\min \{3+f(1,x),5+f(1,y),\infty+f(1,t)\}=10
\\\\f(2,x)&=\min \{1+f(1,y),8+f(1,t)\}=6
\\\\f(2,y)&=\min \{2+f(1,x),5+f(1,t)\}=10
\\\\f(2,t)&=\infty \end{aligned}$$
第三次迭代，
$$\begin{aligned}f(3,s)&=\min \{3+f(2,x),5+f(2,y),\infty+f(2,t)\}=9
\\\\f(3,x)&=\min \{1+f(2,y),8+f(2,t)\}=11
\\\\f(3,y)&=\min \{2+f(1,x),5+f(2,t)\}=8
\\\\f(3,t)&=\infty \end{aligned}$$
假设图中总共有 N 个节点，那么从任意一点 p 到 t 可以走恰好 k 步，k 取值为 {0,1,...,N-1}，k 不能大于等于 N，否则就存在某个节点经过两次，从而路径中存在环 circle，在任意两点路径均大于 0 的情况下，显然有环的路径不可能是最短路径。这里的例子中，N=4，所以 k 最大为 3，经过三次迭代后，就没必要再迭代下去了，否则路径中存在环，迭代下去的 f 值只会越来越大。于是根据 $f(p)=\min_k \{f(k,p)\}$ 得
$$\begin{aligned}f(s)&=\min \{\infty,\infty,10,9\}=9
\\\\f(x)&=\min \{\infty,8,6,11\}=6
\\\\f(y)&=\min \{\infty,5,10,8\}=5
\\\\f(t)&=\min \{0,\infty,\infty,\infty\}=0 \end{aligned}$$
从以上求解过程不难发现，迭代计算结果序列并不收敛，这也说明了式 (1.22) 中 $f(k,S)$ 序列不单调性。

既然 $f(k,S)$ 序列不单调，我们参考式 (1.23) 为最短路径问题改写合适的 DPFE，如下
$$F(k,p)=\min \{F(k-1,p), \ \min_q \{b(p,q)+F(k-1,q)\}\} \qquad(1.27)$$

其中 $F(k,p)$ 表示从 p 到 t 最多走 k 步的最短路径。显然要获得全局最短路径，我们必须考虑从 p 到 t 最多走 $N-1$ 步的最短路径，即目标是计算 $F(N-1,s)$，k 最大为 $N-1$，超过则路径出现环。基本条件不难得知为 $F(k,t)=0,k\ge 0; F(0,p)=\infty, p \ne t$，这个不用过多解释了，相信现在大家都能理解。


还有其他形式的 DPFE，由于篇幅有限就不一一介绍，待后面分析具体例子的时候再穿插说明。