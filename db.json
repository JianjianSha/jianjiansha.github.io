{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":1,"renderable":1},{"_id":"source/images/BBox-reg_fig1.png","path":"images/BBox-reg_fig1.png","modified":1,"renderable":0},{"_id":"source/images/BBox-reg_fig2.png","path":"images/BBox-reg_fig2.png","modified":1,"renderable":0},{"_id":"source/images/BBox-reg_fig3.png","path":"images/BBox-reg_fig3.png","modified":1,"renderable":0},{"_id":"source/images/BBox-reg_fig4.png","path":"images/BBox-reg_fig4.png","modified":1,"renderable":0},{"_id":"source/images/CGAN_fig1.png","path":"images/CGAN_fig1.png","modified":1,"renderable":0},{"_id":"source/images/CGAN_fig2.png","path":"images/CGAN_fig2.png","modified":1,"renderable":0},{"_id":"source/images/DP1_fig1.png","path":"images/DP1_fig1.png","modified":1,"renderable":0},{"_id":"source/images/DP2_fig1.png","path":"images/DP2_fig1.png","modified":1,"renderable":0},{"_id":"source/images/DSOD_fig1.png","path":"images/DSOD_fig1.png","modified":1,"renderable":0},{"_id":"source/images/DeRPN_fig1.png","path":"images/DeRPN_fig1.png","modified":1,"renderable":0},{"_id":"source/images/DeRPN_fig2.png","path":"images/DeRPN_fig2.png","modified":1,"renderable":0},{"_id":"source/images/DetNet_fig1.png","path":"images/DetNet_fig1.png","modified":1,"renderable":0},{"_id":"source/images/DetNet_fig2.png","path":"images/DetNet_fig2.png","modified":1,"renderable":0},{"_id":"source/images/FSAF_fig2.png","path":"images/FSAF_fig2.png","modified":1,"renderable":0},{"_id":"source/images/FSAF_fig3.png","path":"images/FSAF_fig3.png","modified":1,"renderable":0},{"_id":"source/images/FSAF_fig4.png","path":"images/FSAF_fig4.png","modified":1,"renderable":0},{"_id":"source/images/FSAF_fig5.png","path":"images/FSAF_fig5.png","modified":1,"renderable":0},{"_id":"source/images/FSAF_fig6.png","path":"images/FSAF_fig6.png","modified":1,"renderable":0},{"_id":"source/images/GA-RPN_fig1.png","path":"images/GA-RPN_fig1.png","modified":1,"renderable":0},{"_id":"source/images/GA-RPN_fig2.png","path":"images/GA-RPN_fig2.png","modified":1,"renderable":0},{"_id":"source/images/GA-RPN_fig3.png","path":"images/GA-RPN_fig3.png","modified":1,"renderable":0},{"_id":"source/images/GA-RPN_fig4.png","path":"images/GA-RPN_fig4.png","modified":1,"renderable":0},{"_id":"source/images/GAN_alg1.png","path":"images/GAN_alg1.png","modified":1,"renderable":0},{"_id":"source/images/GAN_fig1.png","path":"images/GAN_fig1.png","modified":1,"renderable":0},{"_id":"source/images/GAN_fig2.png","path":"images/GAN_fig2.png","modified":1,"renderable":0},{"_id":"source/images/GIoU_fig1.png","path":"images/GIoU_fig1.png","modified":1,"renderable":0},{"_id":"source/images/Grid-RCNN-Plus_fig1.png","path":"images/Grid-RCNN-Plus_fig1.png","modified":1,"renderable":0},{"_id":"source/images/GIoU_fig2.png","path":"images/GIoU_fig2.png","modified":1,"renderable":0},{"_id":"source/images/Grid-RCNN-Plus_fig2.png","path":"images/Grid-RCNN-Plus_fig2.png","modified":1,"renderable":0},{"_id":"source/images/Grid-RCNN_fig1.png","path":"images/Grid-RCNN_fig1.png","modified":1,"renderable":0},{"_id":"source/images/Grid-RCNN_fig2.png","path":"images/Grid-RCNN_fig2.png","modified":1,"renderable":0},{"_id":"source/images/Grid-RCNN_fig3.png","path":"images/Grid-RCNN_fig3.png","modified":1,"renderable":0},{"_id":"source/images/Grid-RCNN_fig4.png","path":"images/Grid-RCNN_fig4.png","modified":1,"renderable":0},{"_id":"source/images/ImprovedGAN_fig1.png","path":"images/ImprovedGAN_fig1.png","modified":1,"renderable":0},{"_id":"source/images/M2Det_fig1.png","path":"images/M2Det_fig1.png","modified":1,"renderable":0},{"_id":"source/images/M2Det_fig2.png","path":"images/M2Det_fig2.png","modified":1,"renderable":0},{"_id":"source/images/M2Det_fig4.png","path":"images/M2Det_fig4.png","modified":1,"renderable":0},{"_id":"source/images/M2Det_fig3.png","path":"images/M2Det_fig3.png","modified":1,"renderable":0},{"_id":"source/images/RepPoints_fig1.png","path":"images/RepPoints_fig1.png","modified":1,"renderable":0},{"_id":"source/images/TridentNet_fig1(a).png","path":"images/TridentNet_fig1(a).png","modified":1,"renderable":0},{"_id":"source/images/TridentNet_fig1(b).png","path":"images/TridentNet_fig1(b).png","modified":1,"renderable":0},{"_id":"source/images/RepPoints_fig2.png","path":"images/RepPoints_fig2.png","modified":1,"renderable":0},{"_id":"source/images/TridentNet_fig1(c).png","path":"images/TridentNet_fig1(c).png","modified":1,"renderable":0},{"_id":"source/images/TridentNet_fig2.png","path":"images/TridentNet_fig2.png","modified":1,"renderable":0},{"_id":"source/images/TridentNet_fig3.png","path":"images/TridentNet_fig3.png","modified":1,"renderable":0},{"_id":"source/images/libra-rcnn_fig1.png","path":"images/libra-rcnn_fig1.png","modified":1,"renderable":0},{"_id":"source/images/libra-rcnn_fig2.png","path":"images/libra-rcnn_fig2.png","modified":1,"renderable":0},{"_id":"source/images/libra-rcnn_fig3.png","path":"images/libra-rcnn_fig3.png","modified":1,"renderable":0},{"_id":"source/images/libra-rcnn_fig4.png","path":"images/libra-rcnn_fig4.png","modified":1,"renderable":0},{"_id":"source/images/libra-rcnn_fig5.png","path":"images/libra-rcnn_fig5.png","modified":1,"renderable":0},{"_id":"source/images/libra-rcnn_figa.png","path":"images/libra-rcnn_figa.png","modified":1,"renderable":0},{"_id":"source/images/mAP_fig1.png","path":"images/mAP_fig1.png","modified":1,"renderable":0},{"_id":"source/images/mAP_fig2.png","path":"images/mAP_fig2.png","modified":1,"renderable":0},{"_id":"source/images/mAP_fig3.png","path":"images/mAP_fig3.png","modified":1,"renderable":0},{"_id":"source/images/mAP_fig4.png","path":"images/mAP_fig4.png","modified":1,"renderable":0},{"_id":"source/images/mAP_fig5.png","path":"images/mAP_fig5.png","modified":1,"renderable":0},{"_id":"source/images/mask-rcnn_fig1.png","path":"images/mask-rcnn_fig1.png","modified":1,"renderable":0},{"_id":"source/images/mask-rcnn_fig4.png","path":"images/mask-rcnn_fig4.png","modified":1,"renderable":0},{"_id":"source/images/mask-rcnn_fig3.png","path":"images/mask-rcnn_fig3.png","modified":1,"renderable":0},{"_id":"source/images/pytorch_mtd_aligncorners.png","path":"images/pytorch_mtd_aligncorners.png","modified":1,"renderable":0},{"_id":"source/images/pytorch_mtd_conv_t.png","path":"images/pytorch_mtd_conv_t.png","modified":1,"renderable":0},{"_id":"source/images/pytorch_mtd_conv_t_1.png","path":"images/pytorch_mtd_conv_t_1.png","modified":1,"renderable":0},{"_id":"source/images/pytorch_mth_conv.png","path":"images/pytorch_mth_conv.png","modified":1,"renderable":0},{"_id":"source/images/cpp/C_linking_process.png","path":"images/cpp/C_linking_process.png","modified":1,"renderable":0},{"_id":"source/images/cpp/string1.png","path":"images/cpp/string1.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/densenet_1.png","path":"images/img_cls/densenet_1.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/densenet_2.png","path":"images/img_cls/densenet_2.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/densenet_3.png","path":"images/img_cls/densenet_3.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/resnet_1.png","path":"images/img_cls/resnet_1.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/resnet_2.png","path":"images/img_cls/resnet_2.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/resnet_3.png","path":"images/img_cls/resnet_3.png","modified":1,"renderable":0},{"_id":"source/images/img_cls/resnet_4.png","path":"images/img_cls/resnet_4.png","modified":1,"renderable":0},{"_id":"source/images/ml/multiclass_fig1.png","path":"images/ml/multiclass_fig1.png","modified":1,"renderable":0},{"_id":"source/images/ml/multiclass_fig2.png","path":"images/ml/multiclass_fig2.png","modified":1,"renderable":0},{"_id":"source/images/ml/multiclass_fig3.png","path":"images/ml/multiclass_fig3.png","modified":1,"renderable":0},{"_id":"source/images/pytorch/NAG.png","path":"images/pytorch/NAG.png","modified":1,"renderable":0},{"_id":"source/images/pytorch/NAG_0.png","path":"images/pytorch/NAG_0.png","modified":1,"renderable":0},{"_id":"source/images/pytorch/momentum.png","path":"images/pytorch/momentum.png","modified":1,"renderable":0},{"_id":"source/images/pytorch/overfitting.png","path":"images/pytorch/overfitting.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/YOLOv1_fig1.jpg","path":"images/obj_det/YOLOv1_fig1.jpg","modified":1,"renderable":0},{"_id":"source/images/obj_det/YOLOv2_fig2.png","path":"images/obj_det/YOLOv2_fig2.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/anchor_free_fig1.png","path":"images/obj_det/anchor_free_fig1.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/anchor_free_fig2.png","path":"images/obj_det/anchor_free_fig2.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/courgette.log","path":"images/obj_det/courgette.log","modified":1,"renderable":0},{"_id":"source/images/obj_det/lightweight_fig1.png","path":"images/obj_det/lightweight_fig1.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/lightweight_fig2.png","path":"images/obj_det/lightweight_fig2.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/two_stage_fig1.png","path":"images/obj_det/two_stage_fig1.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/two_stage_fig2.png","path":"images/obj_det/two_stage_fig2.png","modified":1,"renderable":0},{"_id":"source/images/obj_det/two_stage_fig3.png","path":"images/obj_det/two_stage_fig3.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/images/obj_det/courgette.log","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1616519679929},{"_id":"source/_posts/BBox-Reg-Uncertainty.md","hash":"7e629be404c79ac1d8b63dc6478f75aa49503a35","modified":1587724517063},{"_id":"source/_posts/CGAN.md","hash":"f10bb3f69d370244bc8ffb0d6f5f0fcc84494550","modified":1587724547246},{"_id":"source/_posts/DIP-1.md","hash":"4900be1b46bf1738dd1b559d7d7b9dc4839150a0","modified":1587724616327},{"_id":"source/_posts/DIP-2.md","hash":"b613e3d6c3f72e4604b6e768c833d7a33644f1eb","modified":1587724624704},{"_id":"source/_posts/DSOD.md","hash":"216a994cfac7b88cd2edfe0863296025e8a772ee","modified":1587724653289},{"_id":"source/_posts/DeRPN.md","hash":"f1b4cefe1c47859626259b55d21d824ba90bc201","modified":1587724549189},{"_id":"source/_posts/DetNet.md","hash":"b40dfc488d450dc059f422ef20174378d9acce22","modified":1587724608330},{"_id":"source/_posts/FSAF.md","hash":"19f76265e71a60fc5c2c422884d65c43e3410791","modified":1587724658161},{"_id":"source/_posts/GA-RPN.md","hash":"0661834aa008c32e80c2e43f782b0f6eaacd3683","modified":1587724662094},{"_id":"source/_posts/GAN.md","hash":"b212be2661b6c61aafca80c68c17d25e4438bf30","modified":1587724666726},{"_id":"source/_posts/GIoU.md","hash":"3e70d0daed924dc871987f2c6ab00f101249ded3","modified":1589505889573},{"_id":"source/_posts/Grid-RCNN.md","hash":"d5b1989b6bb93edf7ee4585e1c67b62250c17dab","modified":1587724683391},{"_id":"source/_posts/ImprovedGAN.md","hash":"885776b42fa49975e90131418d8852306c1bc9ba","modified":1587724698844},{"_id":"source/_posts/M2Det.md","hash":"defe534aa5fc8e2729c43e6424b230fb469be7ed","modified":1587724591648},{"_id":"source/_posts/RepPoints.md","hash":"48a1a1d93224a738c7f7eee6660523998589407c","modified":1587724577184},{"_id":"source/_posts/TODO.md","hash":"8bbf8547be7d27a6d05f2b5ea7108d041d079112","modified":1612245762916},{"_id":"source/_posts/TridentNet.md","hash":"bb01d8181a5e4846d95911432cc4895b6eda5f39","modified":1587724572120},{"_id":"source/_posts/WGAN.md","hash":"d087dd74799c6606f923850d7dee077ba74d3fca","modified":1587720342769},{"_id":"source/_posts/cv-mtds.md","hash":"c0b6021c9c650f83a0a23abfe92a9685244c71f0","modified":1587724535883},{"_id":"source/_posts/gcc-src.md","hash":"3a0169396aec02a7ac32af85d7d990444fc96068","modified":1587724673028},{"_id":"source/_posts/libra-rcnn.md","hash":"e30150614c37fe490fa8b5f840bdd0ca1b410714","modified":1587724601422},{"_id":"source/_posts/loss.md","hash":"1a30c6f947cc8a0b711294c5ac7098b3086c61f0","modified":1587724596189},{"_id":"source/_posts/mAP.md","hash":"9e2b742de01933583676c894d34704a3c0484964","modified":1587724587200},{"_id":"source/_posts/mask-rcnn.md","hash":"e86c7e2564b2b4415cf4010822eed40f8b93534f","modified":1587724581610},{"_id":"source/categories/index.md","hash":"f543c292a5425d3bdeeb4eb223c39d17b75c3296","modified":1587720342848},{"_id":"source/about/index.md","hash":"a4051fc00d169485d93ddb50967415343e1b0075","modified":1587720342847},{"_id":"source/images/BBox-reg_fig3.png","hash":"941dbd9edad7d9e4961866872d93c87f35ae1c40","modified":1587720342850},{"_id":"source/images/BBox-reg_fig4.png","hash":"651ed85e9511c2ea9ff0c9c76248e71a950c41d4","modified":1587720342851},{"_id":"source/images/CGAN_fig1.png","hash":"94d2eb94087c072188200f54dfccb665a4bb0bc3","modified":1587720342852},{"_id":"source/images/DP1_fig1.png","hash":"ed9dd7cbecff94be6778831a494b1295482bfe3e","modified":1587720342854},{"_id":"source/images/DP2_fig1.png","hash":"a90b55aa55d0cfdd147c5b00feaf432300f2854b","modified":1587720342854},{"_id":"source/images/DetNet_fig1.png","hash":"0be4e55fcb24f78c0ae7e0abd848c863858c907e","modified":1587720342858},{"_id":"source/images/DetNet_fig2.png","hash":"dffd982d9558203676d5df62ded8eb2f4fa314d1","modified":1587720342859},{"_id":"source/images/FSAF_fig2.png","hash":"5980bbb5993d141c28aecc700f01bdbaf793d018","modified":1587720342860},{"_id":"source/images/FSAF_fig3.png","hash":"c792cc01936994074b8e6fce3b9884801d7e9f4b","modified":1587720342861},{"_id":"source/images/FSAF_fig4.png","hash":"a7fd53318b0879dba659aa13e5bb8e87ddaa57f3","modified":1587720342861},{"_id":"source/images/FSAF_fig5.png","hash":"afd140d4277cdf34e02d9607a950e805c33398e8","modified":1587720342862},{"_id":"source/images/FSAF_fig6.png","hash":"6d4ddfb5ca31af495ad5ba5f80d66f8cb0c5e79b","modified":1587720342863},{"_id":"source/images/GA-RPN_fig3.png","hash":"12f2d60e449b7213de492d18a2b0ada527788d94","modified":1587720342865},{"_id":"source/images/GAN_fig1.png","hash":"c6f2c668d1b4d98d4bd7fdc27851faed5c7ffe9c","modified":1587720342867},{"_id":"source/images/GIoU_fig2.png","hash":"874dbb5acd431fd27c0be189513190d30449b57c","modified":1587720342870},{"_id":"source/images/Grid-RCNN_fig1.png","hash":"4c257e0b6f9f569b1a60ac27af54ca440812bc9c","modified":1587720342873},{"_id":"source/images/ImprovedGAN_fig1.png","hash":"9496ef5958922774f45112291e76fc421ba33ad5","modified":1587720342876},{"_id":"source/images/M2Det_fig3.png","hash":"1a1f004e3ae0786c11e9ae915a229b41634e7e9f","modified":1587720342879},{"_id":"source/images/TridentNet_fig1(b).png","hash":"03489e4b700364b62b4693418137113f38f03c82","modified":1587720342883},{"_id":"source/images/TridentNet_fig1(c).png","hash":"3c3ec6c57f7ebb7180af2c2dc0649857ac37ad9b","modified":1587720342883},{"_id":"source/images/libra-rcnn_fig3.png","hash":"29973e85ddcc86bea3fb84d725471e061a479e75","modified":1587720342891},{"_id":"source/images/libra-rcnn_figa.png","hash":"761b2d9d6c57c8279ee717b4b011a19c987e5259","modified":1587720342893},{"_id":"source/images/mAP_fig1.png","hash":"e1e227bb2bf05159c46b812d4acb9683631e8aba","modified":1587720342894},{"_id":"source/images/mAP_fig2.png","hash":"6fe61598c855d8086c10c04187c9956d7b14b5be","modified":1587720342894},{"_id":"source/images/mAP_fig3.png","hash":"5289afe8e4ec978a94571d7d001563713404155f","modified":1587720342895},{"_id":"source/images/mAP_fig4.png","hash":"a13992fc8671dd3c1f5a44a9cd714176f580681d","modified":1587720342896},{"_id":"source/images/mAP_fig5.png","hash":"8727119e5d2a352699c59a7ef5429a2d30b3cef9","modified":1587720342896},{"_id":"source/images/mask-rcnn_fig3.png","hash":"593aa6f15b90d819e5690a2cd8befa3ba24ebccf","modified":1587720342897},{"_id":"source/images/pytorch_mtd_aligncorners.png","hash":"8e1fff6ffbefc3b3bfb3fabbb2aa34c035b922a4","modified":1587720342901},{"_id":"source/images/pytorch_mtd_conv_t_1.png","hash":"68104100110da86678ff50bbc0d7418946c68f10","modified":1587720342903},{"_id":"source/images/pytorch_mth_conv.png","hash":"789dc01b7cd1d19267d690b001bf45582d720085","modified":1587720342903},{"_id":"source/tags/index.md","hash":"187b2cc91b3f34577e2b97e1e10051a0eb5a0854","modified":1587720342904},{"_id":"source/_posts/cpp/cmake_1.md","hash":"8be563a17b8434740c38dc575e96749eef97e4a5","modified":1631671688960},{"_id":"source/_posts/cpp/cmake_cmds_1.md","hash":"026a9b5f7024a44f7ed9605cad74ec2def7101af","modified":1631671714168},{"_id":"source/_posts/cpp/cmake_find.md","hash":"fed56e66ac51bdc3e76fa455819895481a95a794","modified":1631671660330},{"_id":"source/_posts/cpp/cmake_im_ex.md","hash":"da9301e02b696eadf425c9d99532ccee4801cff2","modified":1631671727772},{"_id":"source/_posts/cpp/cmake_target.md","hash":"01020494588d1f879c503afd15c595b4a6e6e47b","modified":1631671744213},{"_id":"source/_posts/cpp/constructor.md","hash":"093f538f993d6ac379875f61283cace6d6f91231","modified":1624877265725},{"_id":"source/_posts/cpp/cpp-aux-tools.md","hash":"90fb8be93cd4cac11a250bdc5642b81c09358786","modified":1623492301775},{"_id":"source/_posts/cpp/gcc_common_usages.md","hash":"2820a35177913ffe4c17afe996b21279f184af11","modified":1628237907572},{"_id":"source/_posts/cpp/link.md","hash":"3c590dfc64b10d081b73072f815f505988ee79ad","modified":1628663527229},{"_id":"source/_posts/cpp/string.md","hash":"4a834d7418520fd73771bf5e96cf698d2897ac1b","modified":1631671470045},{"_id":"source/_posts/cpp/type_declare.md","hash":"4fba24da8678c4a4ea192ef94d8ebf3841d80681","modified":1625533380164},{"_id":"source/_posts/cv/methods.md","hash":"6231f507b1abb19b237e97eb10f700a7dde66be4","modified":1610953444578},{"_id":"source/_posts/dip/hist_equal.md","hash":"a9f0baf96144bfc1ba7b2eb6e9e60160c6702179","modified":1592906820778},{"_id":"source/_posts/dl/Metrics.md","hash":"ce3b692a8eb80915574858c5ec3a9ca00fc92525","modified":1613793861462},{"_id":"source/_posts/dl/Training-Operations.md","hash":"e1ea0015b04ae3b76ccf523fce1ad395c6c2e1a0","modified":1613715521500},{"_id":"source/_posts/dl/conv.md","hash":"83962525a9e96d35385c2dc2928f9fbd03eb50c1","modified":1615026219491},{"_id":"source/_posts/dl/norm.md","hash":"63c2c22fed177d6f117cebf752577cba4d4f94d4","modified":1615534788056},{"_id":"source/_posts/dl/receptive_field.md","hash":"978ea27e7345a1a9a6c3040f6f0c3b487a792831","modified":1613701138909},{"_id":"source/_posts/dl/tricks_1.md","hash":"4c919d9ba90cbf8015fd380364e0fd04ca103a20","modified":1610104264076},{"_id":"source/_posts/dl/x_ent_loss.md","hash":"f5f90c92361d932a64dc5289a6604260bd17b911","modified":1610443992331},{"_id":"source/_posts/dp/DP1.md","hash":"f4240b4eba164b3597345db784af0bc301ae5d39","modified":1587724265843},{"_id":"source/_posts/dp/DP2.md","hash":"1464a94ecdc9376dde946b7193db04d19a127969","modified":1587724274130},{"_id":"source/_posts/dp/DP3.md","hash":"1c572021c6c6fc05f735e640fa0aa105576b41b0","modified":1587724378204},{"_id":"source/_posts/dp/DP4.md","hash":"528ab635d06ad098842cdb57abcefb16be935c88","modified":1587724386640},{"_id":"source/_posts/img_cls/densenet.md","hash":"a6553202edceb6945135f85c018d82187f0a8527","modified":1587724395098},{"_id":"source/_posts/img_cls/resnet.md","hash":"a0ac8f32dc5d2e21f91e626288f5e68d2c9e0301","modified":1611821556889},{"_id":"source/_posts/ml/halfspace.md","hash":"8ec0ec5a30dc19e051e7f5c2dbb01caca34ae400","modified":1632479238518},{"_id":"source/_posts/ml/k_fold.md","hash":"1bdc9d88521b547d23212bf153fce90b0d2f36a7","modified":1632623581992},{"_id":"source/_posts/ml/kernel.md","hash":"1dbf15c331111cddcb857d6fd35fbd409df7ac5b","modified":1632731410250},{"_id":"source/_posts/ml/linear.md","hash":"6cb29cbeb334545dd4e69c7560fe7b809072a943","modified":1632479220353},{"_id":"source/_posts/ml/multiclass_algo.md","hash":"b3f8205406a60571c756030eb10b020345241158","modified":1632990012381},{"_id":"source/_posts/ml/multiclass.md","hash":"1534315d0f311e31e727089ff0c8fbe7392bd0ac","modified":1632989598030},{"_id":"source/_posts/ml/svm.md","hash":"0ab1e5c3d7ac1f0bc82da368ee88ee8e874de193","modified":1632989748519},{"_id":"source/_posts/obj_det/YOLO.md","hash":"61fc87d9410cc91ff5f17c6c21340123c4ad28cd","modified":1614068071583},{"_id":"source/_posts/obj_det/anchor_free.md","hash":"d9849b08956a158e5700b8cad88d83c9a82297f1","modified":1615015087937},{"_id":"source/_posts/obj_det/lightweight.md","hash":"111ed0b50faa4360d68f0494cc79e3de2c4b4fd2","modified":1615012692633},{"_id":"source/_posts/obj_det/one_stage.md","hash":"75b2d5d22e803faa442e18a4a8a6cda455c4856c","modified":1614325280627},{"_id":"source/_posts/obj_det/two_stage.md","hash":"3bccf893736e896d6df99d117ee351e6a080f319","modified":1614942019491},{"_id":"source/_posts/python/ext1.md","hash":"fb19abf391eb2f08bf5b9f11040e63581c647fca","modified":1631671545827},{"_id":"source/_posts/python/ext2.md","hash":"73fe970b1c4b4d2e71dd18ee9b2bdf4c1e5f8f98","modified":1631671558273},{"_id":"source/_posts/python/ext3.md","hash":"f815e97633748438ec094529a3835717b8e1a051","modified":1631671581724},{"_id":"source/_posts/python/setup.md","hash":"f84253444ffee774bf48658939650061a5953f2d","modified":1631671600634},{"_id":"source/_posts/pytorch/DL-env.md","hash":"b04e6156d52bb9933207b3c378f3c49198d12de2","modified":1612833755061},{"_id":"source/_posts/pytorch/PyTorch-2.md","hash":"270fee7d66050bf260227f129ec131c3158e6ac0","modified":1587724468998},{"_id":"source/_posts/pytorch/PyTorch-1.md","hash":"7642eced7556a6d93fa5330590b5af2dbceaf556","modified":1587724458685},{"_id":"source/_posts/pytorch/PyTorch-3.md","hash":"5d3e2de7b67f4f7a9fb1f2c2e833ee78e95a43f3","modified":1587724475902},{"_id":"source/_posts/pytorch/PyTorch-4.md","hash":"007fddc258aca5bf032a67e74c121c372d9cf958","modified":1587724485043},{"_id":"source/_posts/pytorch/PyTorch-5.md","hash":"6eb3f62ee09e3798539c0a5e90847aedd13baa64","modified":1587724491985},{"_id":"source/_posts/pytorch/PyTorch-mtd.md","hash":"c9f79f0b9d62ddf876b2b5d7a3df0f3b4e25671d","modified":1587724509355},{"_id":"source/_posts/pytorch/loss_1.md","hash":"f4a0f9b0cd71fce68c3ee614ed6f0bcbc02d252c","modified":1610683175833},{"_id":"source/_posts/pytorch/loss_2.md","hash":"785349448098fa76b3e729e00b5d6981904e2138","modified":1610694731771},{"_id":"source/_posts/pytorch/optim-1.md","hash":"e271d1277ed7b149a569704e551b5b222b461044","modified":1587724445306},{"_id":"source/_posts/pytorch/optim-2.md","hash":"f6bd0b830be2b4f1e1a6ce38badc0cf9e19636e7","modified":1587724453810},{"_id":"source/_posts/pytorch/optim_SGD.md","hash":"48612c41c9cb8297c361a446b1222e47aafe8153","modified":1587724415048},{"_id":"source/_posts/pytorch/tricks_1.md","hash":"91b028b768243c380c1cc37347e64f8b067e1d0c","modified":1610090539103},{"_id":"source/_posts/tools/Hexo-Sync.md","hash":"fad02ee4a81ffb7adf9bb96fd7caf0e5d974823d","modified":1631672298552},{"_id":"source/_posts/tools/jupyter-book.md","hash":"7fba9e2d3b4082643c604635e655b90920f53379","modified":1631671902428},{"_id":"source/_posts/tools/shell.md","hash":"30fec86374be420afcf82c01a98f3a430cc43546","modified":1629170253668},{"_id":"source/images/cpp/C_linking_process.png","hash":"92e289dd530f7964acd73cc16663ec3d37e7d4d4","modified":1628220192696},{"_id":"source/images/cpp/string1.png","hash":"1e5c94ee90e25254fac96fe3ce0caa9debca38c3","modified":1624618977161},{"_id":"source/images/img_cls/densenet_2.png","hash":"0d027c4897b024f9b9d20b21b5d3afaf1dd6e70c","modified":1587720342888},{"_id":"source/images/img_cls/resnet_2.png","hash":"533b0bfdf322cb80e914589bae69b20e98f25dcd","modified":1611192784028},{"_id":"source/images/img_cls/resnet_4.png","hash":"853e6a7da14895d60a5d894abf4f081730b5a927","modified":1611196664381},{"_id":"source/images/ml/multiclass_fig1.png","hash":"0062099b37effc625caf8e05e0555fadb87f4bb6","modified":1632814891680},{"_id":"source/images/ml/multiclass_fig2.png","hash":"3c383d90410947e1d5b57264225049218bb30f04","modified":1632821202181},{"_id":"source/images/ml/multiclass_fig3.png","hash":"85e436595fb14125c40cd0dbfe74370c2acff230","modified":1632881978721},{"_id":"source/images/pytorch/NAG.png","hash":"54fcfa655d287fe22d00a6b60f216dafd628b71e","modified":1587720342899},{"_id":"source/images/pytorch/NAG_0.png","hash":"95aa0c0197c730db1bda3ffffe8895287826132e","modified":1587720342899},{"_id":"source/images/pytorch/momentum.png","hash":"0b274a844e87ac5c878a8e5b66848288d36d1aea","modified":1587720342900},{"_id":"source/images/pytorch/overfitting.png","hash":"65c45d4a6a92b9664ab1454535350c1bb8423083","modified":1587720342900},{"_id":"source/images/obj_det/YOLOv1_fig1.jpg","hash":"7da82e62769ef15baafce9848f5164c00fab3b1b","modified":1587720375210},{"_id":"source/images/obj_det/YOLOv2_fig2.png","hash":"5c64920430b221ffaee62e991ae509c2410babb6","modified":1587720375210},{"_id":"source/images/obj_det/anchor_free_fig2.png","hash":"c8e0cd9eb5cc4add2339e639a225655543dd5b26","modified":1614909870453},{"_id":"source/images/obj_det/lightweight_fig1.png","hash":"b635af22f951130e6c16bbb71684892513bd3475","modified":1615012583265},{"_id":"source/images/obj_det/two_stage_fig1.png","hash":"113acd4ea03918c0b8f9f38ea446c6d8dde8ada7","modified":1614585491044},{"_id":"source/_posts/cpp/cmake/func_macro.md","hash":"5a5d4632f08cac07bb5a26d9b23090d0c089f2e6","modified":1628663515604},{"_id":"source/images/DeRPN_fig1.png","hash":"09d707a0fd6534c106e4f503c104c36aed31293e","modified":1587720342857},{"_id":"source/images/BBox-reg_fig2.png","hash":"645d710112f0a5b25f1d34020c1f7e56cfc2ad62","modified":1587720342850},{"_id":"source/images/GA-RPN_fig2.png","hash":"fb3585918ffff3813d462bd78799b847989598c7","modified":1587720342864},{"_id":"source/images/GA-RPN_fig4.png","hash":"7d7c11a72c263bdc87e8898b4018d3a96e6f7f1b","modified":1587720342866},{"_id":"source/images/GAN_alg1.png","hash":"d535c3b65a4c0c8eb331c79dc5032bf754e7084a","modified":1587720342867},{"_id":"source/images/GAN_fig2.png","hash":"86a432fab3c2df0b7e84f789971e5ced612cc2aa","modified":1587720342868},{"_id":"source/images/GIoU_fig1.png","hash":"8b5d938397e94b905245363c4dee5f4266e734b9","modified":1587720342869},{"_id":"source/images/GA-RPN_fig1.png","hash":"3879e968e038df6b23ad8793a1dc5933b14454ac","modified":1587720342863},{"_id":"source/images/Grid-RCNN_fig3.png","hash":"b5e40a1ca3df03b69c06e573086ce5af7f91eec1","modified":1587720342874},{"_id":"source/images/Grid-RCNN_fig4.png","hash":"f06e5e1250a7e59b4d04fbe316592745e65b6650","modified":1587720342875},{"_id":"source/images/M2Det_fig1.png","hash":"002f75d4ab7fa714afbf0f8d64fadb7ec1799775","modified":1587720342877},{"_id":"source/images/M2Det_fig4.png","hash":"27227839728d56d5c61c57629546b8b7e4d0fb00","modified":1587720342880},{"_id":"source/images/TridentNet_fig1(a).png","hash":"89a0e081b4dba10cbeca8e1af76d23cfa203eb72","modified":1587720342882},{"_id":"source/images/RepPoints_fig2.png","hash":"ef1068b6bf393ea829f199e37e5f14edc70641c3","modified":1587720342881},{"_id":"source/images/TridentNet_fig2.png","hash":"e186f0cd983d28f81df120a01c8611e8f9accdaa","modified":1587720342884},{"_id":"source/images/libra-rcnn_fig1.png","hash":"4150832cd9a4c2f9532ad0309e299154fd581d87","modified":1587720342890},{"_id":"source/images/libra-rcnn_fig2.png","hash":"be628467551b790e0cd0e9e3cdd1f041548f60db","modified":1587720342891},{"_id":"source/images/TridentNet_fig3.png","hash":"52502eade50078f68ca751915681e536a96094b4","modified":1587720342885},{"_id":"source/images/libra-rcnn_fig4.png","hash":"cc0dafa1503dad25981ed08a5f33431a5ce40e93","modified":1587720342892},{"_id":"source/images/mask-rcnn_fig1.png","hash":"6ee2989bcd121be915722f0d7ae9ba97039681b6","modified":1587720342897},{"_id":"source/images/mask-rcnn_fig4.png","hash":"a6000ce7a01688cefdd8af1d3c1bab492954320c","modified":1587720342898},{"_id":"source/images/Grid-RCNN-Plus_fig1.png","hash":"7255da83a2dadae1b8832adf87b3f60e6ed211d5","modified":1587720342871},{"_id":"source/images/img_cls/densenet_3.png","hash":"b456a005625516ce3e9acf66011d5fd4d9723e7a","modified":1587720342889},{"_id":"source/images/img_cls/resnet_1.png","hash":"5454e8ca5934d124bc10177771e1ad55999ac973","modified":1611192807710},{"_id":"source/images/libra-rcnn_fig5.png","hash":"33795e57abe6b93ce0e70a46dbb37c6348308c2e","modified":1587720342893},{"_id":"source/images/obj_det/anchor_free_fig1.png","hash":"ddd42dfa97ce4d60c680b60f3ff81a42263f623a","modified":1614828633807},{"_id":"source/images/pytorch_mtd_conv_t.png","hash":"158a3311f03a494bb7bd1a81a5712cab7aa1c37b","modified":1587720342902},{"_id":"source/images/obj_det/two_stage_fig3.png","hash":"f9c1d3141ae50cc9c84ad4469d885876a626ced6","modified":1614939723388},{"_id":"source/images/obj_det/two_stage_fig2.png","hash":"037ec47ff1ae7cf16f0cf2a122a9a0e0d21e4ac9","modified":1614764996317},{"_id":"source/images/Grid-RCNN-Plus_fig2.png","hash":"801abc90e532b83bc123e58df681d79b9fc8ad4b","modified":1587720342872},{"_id":"source/images/RepPoints_fig1.png","hash":"132a00a2205e81d684269a7a89ff3f61ac520217","modified":1587720342881},{"_id":"source/images/img_cls/densenet_1.png","hash":"f33ee6bfa0d34b8f14aaf6881ae878b9503d7cd4","modified":1587720342887},{"_id":"themes/next/.editorconfig","hash":"731c650ddad6eb0fc7c3d4a91cad1698fe7ad311","modified":1587722949386},{"_id":"themes/next/.eslintrc.json","hash":"d3c11de434171d55d70daadd3914bc33544b74b8","modified":1587722949386},{"_id":"themes/next/.gitattributes","hash":"3e00e1fb043438cd820d94ee3dc9ffb6718996f3","modified":1587722949386},{"_id":"themes/next/.gitignore","hash":"83418530da80e6a78501e1d62a89c3bf5cbaec3d","modified":1587722949391},{"_id":"themes/next/.stylintrc","hash":"6259e2a0b65d46865ab89564b88fc67638668295","modified":1587722949392},{"_id":"themes/next/.travis.yml","hash":"379f31a140ce41e441442add6f673bf397d863ea","modified":1587722949392},{"_id":"themes/next/LICENSE.md","hash":"0a9c7399f102b4eb0a6950dd31264be421557c7d","modified":1587722949392},{"_id":"themes/next/README.md","hash":"7d56751b580d042559b2acf904fca4b42bcb30a7","modified":1587722949393},{"_id":"themes/next/_config.yml","hash":"ad947b4a5bc64bee8aceaed79f47f0e5bfefded3","modified":1587723680740},{"_id":"themes/next/crowdin.yml","hash":"4a53f5985e545c635cb56b2a57ed290cb8cf8942","modified":1587722949393},{"_id":"themes/next/gulpfile.js","hash":"0c76a1ac610ee8cbe8e2cc9cca1c925ffd0edf98","modified":1587722949402},{"_id":"themes/next/package.json","hash":"b099e7cea4406e209130410d13de87988ba37b2a","modified":1587722949427},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"778b7e052993ed59f21ed266ba7119ee2e5253fb","modified":1587722949387},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ddde54fb50d11dc08cec899a3588addb56aa386","modified":1587722949387},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"d2f8e6b65783e31787feb05d2ccea86151f53f35","modified":1587722949389},{"_id":"themes/next/.github/config.yml","hash":"df3d970700e6b409edc3d23be8d553db78d5ba3f","modified":1587722949389},{"_id":"themes/next/.github/issue-close-app.yml","hash":"b14756e65546eb9ecc9d4393f0c9a84a3dac1824","modified":1587722949390},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"533fbe6b2f87d7e7ec6949063bb7ea7eb4fbe52d","modified":1587722949390},{"_id":"themes/next/.github/lock.yml","hash":"3ce3d0a26030a1cd52b273cc6a6d444d7c8d85c2","modified":1587722949390},{"_id":"themes/next/.github/mergeable.yml","hash":"1c1cb77a62df1e3654b151c2da34b4a10d351170","modified":1587722949390},{"_id":"themes/next/.github/release-drafter.yml","hash":"09c3352b2d643acdc6839601ceb38abc38ab97c5","modified":1587722949391},{"_id":"themes/next/.github/stale.yml","hash":"590b65aca710e0fba75d3cf5361a64d13b6b0f63","modified":1587722949391},{"_id":"themes/next/.github/support.yml","hash":"7ce2722d6904c31a086444c422dc49b6aa310651","modified":1587722949391},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"60c7e9ef0c578deebad43e9395c958fa61096baf","modified":1587722949394},{"_id":"themes/next/docs/AGPL3.md","hash":"f463f95b169d64983f59fa6f3e4b6760290a0e6b","modified":1587722949394},{"_id":"themes/next/docs/AUTHORS.md","hash":"cde7cc095ac31b421a573042cf61060f90d9ad0d","modified":1587722949395},{"_id":"themes/next/docs/DATA-FILES.md","hash":"980fb8d37701f7fd96b30bb911519de3bbb473d1","modified":1587722949395},{"_id":"themes/next/docs/INSTALLATION.md","hash":"07ea00bee149a1bdc9073e903ee6b411e9f2f818","modified":1587722949395},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"6cc663db5e99fd86bb993c10d446ad26ada88e58","modified":1587722949396},{"_id":"themes/next/docs/LICENSE.txt","hash":"ae5ad07e4f4106bad55535dba042221539e6c7f9","modified":1587722949396},{"_id":"themes/next/docs/MATH.md","hash":"f56946053ade0915ff7efa74d43c38b8dd9e63bb","modified":1587722949396},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"1e86d32063b490d204baa9d45d8d3cb22c24a37d","modified":1587722949397},{"_id":"themes/next/languages/ar.yml","hash":"abcf220bd615cec0dd50e4d98da56580169d77e1","modified":1587722949402},{"_id":"themes/next/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1587722949402},{"_id":"themes/next/languages/de.yml","hash":"15078b7ede1b084e8a6a15d271f0db9c325bd698","modified":1587722949402},{"_id":"themes/next/languages/en.yml","hash":"dbb64776f9c001c54d0058256c415a9a0724ed5d","modified":1587722949403},{"_id":"themes/next/languages/fa.yml","hash":"6c0a7d5bcc26eb45a9f3e02f13117c668e77fffd","modified":1587722949403},{"_id":"themes/next/languages/es.yml","hash":"f064c793d56a5e0f20cda93b6f0e355044efc7d8","modified":1587722949403},{"_id":"themes/next/languages/fr.yml","hash":"3e2f89d4bb4441d33ecc7b5a4ee114f627603391","modified":1587722949404},{"_id":"themes/next/languages/hu.yml","hash":"0ea89ffaefd02a10494995f05a2a59d5e5679a28","modified":1587722949404},{"_id":"themes/next/languages/id.yml","hash":"7599bb0ecf278beb8fde3d17bfc148a3241aef82","modified":1587722949404},{"_id":"themes/next/languages/it.yml","hash":"46222f468e66789e9ba13095809eb5e5b63edf30","modified":1587722949405},{"_id":"themes/next/languages/ja.yml","hash":"bf279d0eb1911806d01a12f27261fbc76a3bb3f9","modified":1587722949405},{"_id":"themes/next/languages/ko.yml","hash":"af4be6cb394abd4e2e9a728418897d2ed4cc5315","modified":1587722949405},{"_id":"themes/next/languages/nl.yml","hash":"9749cf90b250e631dd550a4f32ada3bb20f66dd0","modified":1587722949405},{"_id":"themes/next/languages/pt-BR.yml","hash":"69aa3bef5710b61dc9a0f3b3a8f52f88c4d08c00","modified":1587722949406},{"_id":"themes/next/languages/pt.yml","hash":"f6606dd0b916a465c233f24bd9a70adce34dc8d6","modified":1587722949406},{"_id":"themes/next/languages/ru.yml","hash":"012abc694cf9de281a0610f95f79c594f0a16562","modified":1587722949406},{"_id":"themes/next/languages/tr.yml","hash":"46e09f2119cbfbcf93fb8dbd267dccabeb8b0cda","modified":1587722949406},{"_id":"themes/next/languages/uk.yml","hash":"69ef00b1b8225920fcefff6a6b6f2f3aad00b4ce","modified":1587722949407},{"_id":"themes/next/languages/vi.yml","hash":"6a578cc28773bd764f4418110500478f185d6efa","modified":1587722949407},{"_id":"themes/next/languages/zh-CN.yml","hash":"81d73e21402dad729053a3041390435f43136a68","modified":1587722949407},{"_id":"themes/next/languages/zh-HK.yml","hash":"92ccee40c234626bf0142152949811ebe39fcef2","modified":1587722949407},{"_id":"themes/next/languages/zh-TW.yml","hash":"cf0740648725983fb88409d6501876f8b79db41d","modified":1587722949407},{"_id":"themes/next/layout/_layout.swig","hash":"9554bd0f5c5a0438aa7b64065be5561c374d260e","modified":1587722949408},{"_id":"themes/next/layout/archive.swig","hash":"d9bca77f6dcfef71e300a294f731bead11ce199f","modified":1587722949425},{"_id":"themes/next/layout/category.swig","hash":"c546b017a956faaa5f5643c7c8a363af7ac9d6b9","modified":1587722949426},{"_id":"themes/next/layout/index.swig","hash":"8dfd96fb6f833dd5d037de800813105654e8e8e6","modified":1587722949426},{"_id":"themes/next/layout/page.swig","hash":"357d916694d4c9a0fd1140fa56d3d17e067d8b52","modified":1587722949426},{"_id":"themes/next/layout/post.swig","hash":"5f0b5ba2e0a5b763be5e7e96611865e33bba24d7","modified":1587722949426},{"_id":"themes/next/layout/tag.swig","hash":"d44ff8755727f6532e86fc9fc8dc631200ffe161","modified":1587722949426},{"_id":"themes/next/scripts/renderer.js","hash":"e3658eea97b1183ee2e9f676231e53f7994741f6","modified":1587722949433},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"e67146befddec3a0dc47dc80d1109070c71d5d04","modified":1587722949387},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"6beeca0f45a429cd932b6e648617f548ff64c27c","modified":1587722949388},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d5aa1a3323639a36bcd9a401484b67537043cd3c","modified":1587722949388},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"59275aa0582f793fee7be67904dcf52ad33a7181","modified":1587722949388},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"a9cfe5ac9ef727a8650b2b6584482751a26b1460","modified":1587722949398},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"54e6a067ed95268eab6be2ba040a7e9b1907928e","modified":1587722949397},{"_id":"themes/next/docs/ru/README.md","hash":"1e5ddb26ad6f931f8c06ce2120f257ff38b74fdf","modified":1587722949398},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"cb8e39c377fc4a14aaf133b4d1338a48560e9e65","modified":1587722949398},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"3202be9a8d31986caac640e7a4c7ce22e99917eb","modified":1587722949399},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7e6f227f2aaf30f400d4c065650a4e3d0d61b9e1","modified":1587722949399},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"2d868cd271d78b08775e28c5b976de8836da4455","modified":1587722949399},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"611f2930c2b281b80543531b1bf33d082531456a","modified":1587722949399},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"716111dd36d276f463c707dfcc9937fea2a1cf7a","modified":1587722949400},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"50ab381c27611d5bf97bb3907b5ca9998f28187d","modified":1587722949400},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"0d46f9f50cf2e4183970adce705d1041155b0d37","modified":1587722949401},{"_id":"themes/next/docs/zh-CN/README.md","hash":"8f7c0d0b766024152591d4ccfac715c8e18b37f3","modified":1587722949401},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"b3201934b966bc731eaf8a4dad4ba4bdcd300c10","modified":1587722949401},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"30ade8c806d7826cc50a4a3e46a9e6213fddf333","modified":1587722949408},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"5bffdb1448caca7db7b1f84e1693e6657a106d50","modified":1587722949409},{"_id":"themes/next/layout/_macro/post.swig","hash":"c3fd56bac90ce45a0c79ddfe68beb223ad0d72b4","modified":1587722949408},{"_id":"themes/next/layout/_partials/comments.swig","hash":"142efb4c6b73d8f736f6784804b40d5871333172","modified":1587722949409},{"_id":"themes/next/layout/_partials/footer.swig","hash":"0e650e97d5fadc4b8a9a0fec00fe7db642dc3f76","modified":1587722949409},{"_id":"themes/next/layout/_partials/languages.swig","hash":"c3ea82604a5853fb44c5f4e4663cbe912aa5dcf8","modified":1587722949411},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"2de77d533c91532a8a4052000244d0c1693370df","modified":1587722949412},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"5392dcbb504266f0f61d5b8219914068ef9cdc25","modified":1587722949415},{"_id":"themes/next/layout/_scripts/index.swig","hash":"1822eaf55bbb4bec88871c324fc18ad95580ccb4","modified":1587722949415},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"7b9e0f776a5be6c3f95bc7f394e1424ba02ba93b","modified":1587722949415},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"ccff5a773644d33ff22f6b45b6734f52b048f22b","modified":1587722949416},{"_id":"themes/next/layout/_scripts/three.swig","hash":"6b092c6d882b2dfa5273e1b3f60b244cb7c29fcd","modified":1587722949417},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"244ca2d74ee0d497c87572c6a26b43c62a952673","modified":1587722949418},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"bd9ba0bf60cc3008ee14339fa395ee6af188e879","modified":1587722949419},{"_id":"themes/next/layout/_third-party/index.swig","hash":"c6b63cbc80938e6e09578b8c67e01adf13a9e3bd","modified":1587722949421},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"5ae5adcd6f63ed98b2071e4f7e5e38c4d7d24e1b","modified":1587722949422},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"269102fc5e46bd1ce75abdcce161f0570ae70e2f","modified":1587722949422},{"_id":"themes/next/scripts/events/index.js","hash":"7baf362743b3d30626066614d877891fc140c502","modified":1587722949427},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"ad321db012cea520066deb0639335e9bc0dcc343","modified":1587722949431},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"305d03c1e45782988809298c3e3b3c5d5ee438aa","modified":1587722949431},{"_id":"themes/next/scripts/filters/locals.js","hash":"a5e7d05d3bd2ae6dcffad5a8ea0f72c6e55dbd02","modified":1587722949431},{"_id":"themes/next/scripts/filters/minify.js","hash":"21196a48cb127bf476ce598f25f24e8a53ef50c2","modified":1587722949432},{"_id":"themes/next/scripts/filters/post.js","hash":"57f2d817578dd97e206942604365e936a49854de","modified":1587722949432},{"_id":"themes/next/scripts/helpers/engine.js","hash":"eb6b8bbc1dce4846cd5e0fac0452dbff56d07b5d","modified":1587722949432},{"_id":"themes/next/scripts/helpers/font.js","hash":"8fb1c0fc745df28e20b96222974402aab6d13a79","modified":1587722949432},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"b8d7ddfa4baa9b8d6b9066a634aa81c6243beec9","modified":1587722949433},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"4044129368d0e2811859a9661cad8ab47118bc32","modified":1587722949433},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"840536754121e0da5968f5ad235f29200fc5d769","modified":1587722949433},{"_id":"themes/next/scripts/tags/button.js","hash":"bb0e8abbc0a6d5b3a1a75a23976f2ac3075aab31","modified":1587722949433},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"e2d0184bc4a557e1017395b80ff46880078d8537","modified":1587722949434},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"93ccd3f99d3cb42674f29183c756df63acb5d7f8","modified":1587722949434},{"_id":"themes/next/scripts/tags/label.js","hash":"fc83f4e1be2c34e81cb79938f4f99973eba1ea60","modified":1587722949434},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"81134494ff0134c0dae1b3815caf6606fccd4e46","modified":1587722949434},{"_id":"themes/next/scripts/tags/note.js","hash":"1fdf4f95810fdb983bfd5ad4c4f13fedd4ea2f8d","modified":1587722949435},{"_id":"themes/next/scripts/tags/pdf.js","hash":"37b53661ad00a01a2ca7d2e4a5ad3a926073f8e2","modified":1587722949435},{"_id":"themes/next/scripts/tags/tabs.js","hash":"c70a4a66fd0c28c98ccb6c5d5f398972e5574d28","modified":1587722949435},{"_id":"themes/next/scripts/tags/video.js","hash":"944293fec96e568d9b09bc1280d5dbc9ee1bbd17","modified":1587722949435},{"_id":"themes/next/source/css/_colors.styl","hash":"11aef31a8e76f0f332a274a8bfd4537b73d4f88f","modified":1587722949436},{"_id":"themes/next/source/css/_mixins.styl","hash":"072a3fa473c19b20ccd7536a656cda044dbdae0a","modified":1587722949455},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1587722949460},{"_id":"themes/next/source/css/main.styl","hash":"815ef30987d02f3d76dbe4b5ee3a72135a152678","modified":1587722949460},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1587722949460},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1587722949461},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1587722949461},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1587722949461},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1587722949462},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1587722949462},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1587722949462},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1587722949463},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1587722949463},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1587722949463},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1587722949464},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1587722949464},{"_id":"themes/next/source/js/algolia-search.js","hash":"f0cee802b4d48d5e78ba88d77d4257cb8a88dd6e","modified":1587722949464},{"_id":"themes/next/source/js/bookmark.js","hash":"2268bfcab8cf9019e590e2d356b08a3d4a0cf791","modified":1587722949464},{"_id":"themes/next/source/js/local-search.js","hash":"f43b891fcd55b8153a8999a39d801c74ef5da0f7","modified":1587722949465},{"_id":"themes/next/source/js/motion.js","hash":"d5aa1a08cdf3c8d1d8d550fb1801274cc41e5874","modified":1587722949465},{"_id":"themes/next/source/js/next-boot.js","hash":"509c5b02446d4989a6ef3081cafeb9497cdde4e5","modified":1587722949465},{"_id":"themes/next/source/lib/anime.min.js","hash":"960be51132134acd65c2017cc8a5d69cb419a0cd","modified":1587722949467},{"_id":"themes/next/source/js/utils.js","hash":"2c5bc91559a19a5d1c9e691a46f472fe82fdcc4e","modified":1587722949466},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"7d638e413f2548fc990c4a467dd03de6c81fc960","modified":1587722949409},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"90cce9f407e9490756ba99580e3eb09f55b05eaa","modified":1587722949410},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"91056a6c98cca63ff8cc6956e531ee3faf4b8ad9","modified":1587722949410},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"0dd316f153c492c0a03bd0273d50fa322bc81f11","modified":1587722949410},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"90d3eaba6fbe69bee465ddd67c467fd2c0239dc4","modified":1587722949411},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"4baa86ca631168fc6388d27f4b1b501b40c877a8","modified":1587722949410},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"bed6cc2b48cf2655036ba39c9bae73a295228a4d","modified":1587722949411},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"91c0addb33006619faa4c32e5d66874e25f1e9b3","modified":1587722949411},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"8d4e3dd0d3631ce0b21bc15c259f6ac886de631d","modified":1587722949412},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"f2eb455c8bf13533427254f0c9b4b17b2498168b","modified":1587722949413},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"d8f785c062c6b0763a778bd4a252e6f5fee0e432","modified":1587722949413},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"ce712c110b5ce8aacba7a86b0558ff89700675c9","modified":1587722949413},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"bc7b047a6246df07767373644b1637d91c3a88b1","modified":1587722949413},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"f349a226e5370075bb6924e60da8b0170c7cfcc1","modified":1587722949413},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"98fd1f5df044f4534e1d4ca9ab092ba5761739a9","modified":1587722949414},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"a6c761d5193cb6f22e9422dbbcf209e05471b0ed","modified":1587722949414},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"128f7d679bb4d53b29203d598d217f029a66dee7","modified":1587722949414},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"7b2ef5db9615267a24b884388925de1e9b447c1f","modified":1587722949415},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"34495d408e8467555afee489500b8aad98c52079","modified":1587722949416},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"0b44f400ec00d2b5add5ee96c11d22465c432376","modified":1587722949416},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"34c05e9d73b0f081db70990c296b6d6a0f8ea2ca","modified":1587722949416},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"0b44f400ec00d2b5add5ee96c11d22465c432376","modified":1587722949417},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"34495d408e8467555afee489500b8aad98c52079","modified":1587722949417},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"84adaadd83ce447fa9da2cff19006334c9fcbff9","modified":1587722949418},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b8819bd056f8a580c5556d4415836a906ed5d7a4","modified":1587722949419},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"91c2cb900c76224c5814eeb842d1d5f517f9bf05","modified":1587722949419},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"85b60e222712ca3b2c4dc2039de2dc36b8d82940","modified":1587722949419},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"2642e8aef5afbe23a2a76efdc955dab2ee04ed48","modified":1587722949419},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"fb94ee487d75e484e59b7fba96e989f699ff8a83","modified":1587722949420},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"9298e6d6c4a62a0862fc0f4060ed99779d7b68cb","modified":1587722949420},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"1b29b99fa921f12c25d3dc95facdf84ef7bb1b5c","modified":1587722949420},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"a42f97eda3748583bac2253c47fe5dfa54f07b8f","modified":1587722949420},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"606ad14a29320157df9b8f33738282c51bb393d9","modified":1587722949420},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"3d91899ca079e84d95087b882526d291e6f53918","modified":1587722949420},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"ae2707d6e47582bb470c075649ec7bad86a6d5a9","modified":1587722949421},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"59df21fcfe9d0ada8cee3188cb1075529c1c3eb8","modified":1587722949421},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"276f523e414d4aa7f350a8f2fd3df8a3d8ea9656","modified":1587722949421},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"1f34b2d3c753a3589ab6c462880bd4eb7df09914","modified":1587722949421},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"58296a5c1883f26464c2a5ccf734c19f5fbf395a","modified":1587722949423},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"fd726aad77a57b288f07d6998ec29291c67c7cbb","modified":1587722949423},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"aa6ab95b8b76611694613defb4bf25003d1b927f","modified":1587722949423},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"d2f0e4c598410ec33785abe302c7ea7492bb791a","modified":1587722949424},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"53a0760c75d5aaabb3ce8e8aa8e003510d59807f","modified":1587722949424},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"01d94354d07e72cad47100482068b6be69fcc033","modified":1587722949424},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"c171ea94e9afbba97f06856904264da331559463","modified":1587722949424},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"619338ddacf01e3df812e66a997e778f672f4726","modified":1587722949425},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"964cd6bac668cf6d211a2624fbef3948cfdece55","modified":1587722949424},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"5a223b60406cee7438cfe3a5e41d1284425aa7a5","modified":1587722949425},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"08496b71c9939718e7955704d219e44d7109247b","modified":1587722949428},{"_id":"themes/next/scripts/events/lib/config.js","hash":"aefe3b38a22bc155d485e39187f23e4f2ee5680a","modified":1587722949428},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"e73f697bb160b223fdde783237148be5f41c1d78","modified":1587722949428},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"2f22f48f7370470cef78561a47c2a47c78035385","modified":1587722949429},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"713056d33dbcd8e9748205c5680b456c21174f4e","modified":1587722949429},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"0c3bea89d64bc12c1bbe6f208a83773c6fb5375a","modified":1587722949429},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"3a80559df0b670ccb065ea9d3bb587d0b61be3a4","modified":1587722949429},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"67cf90d9a2428c14eb113a64bdd213c22a019aef","modified":1587722949429},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"323a47df6ded894944a2647db44556d6163e67c4","modified":1587722949430},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"a4f3153ac76a7ffdf6cc70f52f1b2cc218ed393e","modified":1587722949430},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"851359f5ff90f733a9bd7fe677edbee8b8ac714c","modified":1587722949431},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"583ff1e7a2ca889f1f54eb0ca793894466823c7c","modified":1587722949459},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"5980abbbbeacd8541121f436fa414d24ad5e97c2","modified":1587722949459},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"c22b58af3327236ec54d5706501aa5a20e15012e","modified":1587722949459},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4e33774b1fe6d0a51f3a428c54c5e600e83bf154","modified":1587722949459},{"_id":"themes/next/source/css/_variables/base.styl","hash":"ad680efdfb2f86546182bf3f59886efbcf3c1b2d","modified":1587722949460},{"_id":"themes/next/source/js/schemes/muse.js","hash":"78c77614b9fe0d7d97aa08468c6cffbcbda96b75","modified":1587722949466},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"1a9741145938e2c754a808381350723cbebf43c5","modified":1587722949466},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1587722949470},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1587722949470},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"510a6f0ba7485dd54ce347cca890ab52c4957081","modified":1587722949436},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"0534b329d279a6f255112b3305ff92c810f31724","modified":1587722949437},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"d17236df3b4d6def1e4e81133ef4729c390de3ac","modified":1587722949437},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"c52648a7b09f9fe37858f5694fcc1ffc709ad147","modified":1587722949441},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"a2ee16cac29a82cfce26804c160286fcbee94161","modified":1587722949446},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"7a95c27762e1303bf06ee808c63f616cb192fcaf","modified":1587722949446},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5540c9259cb7895a5f10a289c7937e5470a7c134","modified":1587722949449},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"45f4badac6ec45cf24355f6157aece1d4d3f1134","modified":1587722949450},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"4b068d0d898f4e624937503f0e1428993050bd65","modified":1587722949450},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"6d740699fb6a7640647a8fd77c4ea4992d8d6437","modified":1587722949451},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"b619f39e18398422e0ac4999d8f042a5eaebe9cd","modified":1587722949451},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"43045d115f8fe95732c446aa45bf1c97609ff2a5","modified":1587722949452},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"7ed4733240206d1aa729c835e69a85f8f3c73cd6","modified":1587722949452},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"20e0e3e3eba384930c022e21511214d244b4c9e7","modified":1587722949454},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"e342b8f8e11a3a6aa5a029912c9778c25bf5d135","modified":1587722949455},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"b9e87d32da24264bda247c1526afe140c858b0ef","modified":1587722949456},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"12b265f82840f27112ca2b1be497677f20f87545","modified":1587722949456},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"716e8b0f056bf6393e6bc6969ac84598ab8e7a6f","modified":1587722949456},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"e1c29b81a32273a0dedd926cda199a71aea72624","modified":1587722949456},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"c5142739e01e9f25c8b32b2209af85c787bb2b42","modified":1587722949456},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"8674bd88df076a1dfe4023ed6750ded1f5b00223","modified":1587722949456},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"49c76bc723d3952abb613d9d68398ed7305da999","modified":1587722949457},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4b7f057dbb53efd7cbe7eac7835a793ab3cbb135","modified":1587722949457},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"9898323ee5a7ac2a5d4f633c653112280beb2643","modified":1587722949457},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"2d3e05015796a790abd9d68957a5c698c0c9f9b6","modified":1587722949457},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1587722949457},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"558794fced306339b98dc2b0ee7f0576802f1355","modified":1587722949458},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5de34e1d8a290751641ae456c942410852d5e809","modified":1587722949458},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"0a9f0d9eb042595502d200fb8c65efb0e6c89aa9","modified":1587722949458},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"dc9318992ce2eb086ebaa2fe56b325e56d24098b","modified":1587722949458},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b69ac38b9da8c9c1b7de696fdeea7f9d7705213a","modified":1587722949458},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1587722949459},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"82e34d28f8a1169b20b60101d5bb0446deba3514","modified":1587722949468},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1587722949469},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"236a039b0900f4267de566b46f62314ad967d30f","modified":1587722949437},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"18edddb2ffb3f85a68e4367f81e06c461e07bc25","modified":1587722949437},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"6cf78a379bb656cc0abb4ab80fcae60152ce41ad","modified":1587722949437},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"f6f05f02d50f742c84ee5122016c0563a8bb2cf9","modified":1587722949437},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"97974c231b4659b8aa5e9321c4d54db5c816d0db","modified":1587722949438},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"a52f8cae599099231866298ed831fdf76c9b6717","modified":1587722949438},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"9af620eba5ccceea21a0e3bc69f6f1fa7637c2f3","modified":1587722949438},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"70b3eb9d36543ab92796ac163544e9cf51b7c1e6","modified":1587722949438},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"97dec98d0403097d66822f1c90b50b2890c84698","modified":1587722949438},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"57b9a179675f1536e017cba457b6ac575e397c4f","modified":1587722949439},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"0dfb97703a519d9438f64f9e41ab1dd37381f733","modified":1587722949439},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"93ba8172c0d2c37d738e6dbd44fcd5a2e23b92f3","modified":1587722949440},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"2c24829d95c742eb9e8316ebf2fbe9f2c168b59a","modified":1587722949440},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"09dda2667628d1f91b2e37d8fc6df1413f961b64","modified":1587722949440},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"82a275ca74086a46b8e82d5ebf78c7a807cd9c8b","modified":1587722949440},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5cc9e7394c927065c688cba5edd6e0a27587f1d8","modified":1587722949440},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"b266d2ce5e2b117be01537889e839a69004dc0bb","modified":1587722949441},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"fcd64c23d17775b3635325f6758b648d932e79b5","modified":1587722949441},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"b87f4a06c0db893df4f756f24be182e1a4751f24","modified":1587722949442},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"d83102771df652769e51ddfd041cf5f4ca1a041d","modified":1587722949442},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"bad99f4cccb93b3cefe990a2c85124e60698d32e","modified":1587722949443},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"8ed7a9d5dfac592de703421b543978095129aa5b","modified":1587722949443},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1f6b0d3ab227697ca115e57fd61122ea7950e19d","modified":1587722949443},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"b4f4bae437d4f994af93cf142494ffcd86bae46b","modified":1587722949444},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"b31c86d1a4f89837f9187bed646bda96b2cd286c","modified":1587722949444},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"300058ca12e81013e77ba01fe66ac210525768b6","modified":1587722949444},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"7a3a56b10ab714c0e2ed240d0939deeecdcad167","modified":1587722949445},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"6d5f26646e2914474f295de8bf6dc327d4acd529","modified":1587722949444},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"3d16ac0f4ccaeed868c246d4d49bde543d1f62cb","modified":1587722949445},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b8c816fba0a9b4a35fbae03ba5b1b2da96ba2687","modified":1587722949446},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"7eeb22c5696f8e0c95161dc57703973cf81c8c12","modified":1587722949443},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"49722d555a2edb18094bb2cb3d7336dd72051b93","modified":1587722949447},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"357f825f0a649b2e28cba1481d4c9a0cb402e43a","modified":1587722949447},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"096f908c08ce553e482aadfd3e767a0145191093","modified":1587722949447},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"525242ce9e912c4adfe5134347c67dbdb9e98e3d","modified":1587722949447},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"12f7eaf6b56624cbc411528562d6bb848ff97039","modified":1587722949447},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"b11b04737a1a0fea3bd9f0081d96ee6c015358d4","modified":1587722949448},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"fa0a2ea57b7b4ce75b5d18c264af2d92ea3192f9","modified":1587722949448},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"098b4bdf49c7300490f959386d5d1185a32543f6","modified":1587722949448},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"5d540f683018745a5ed1d6f635df28ea610c1244","modified":1587722949449},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"67a1fcb33535122d41acd24f1f49cf02c89b88fa","modified":1587722949449},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"4079e616fbf36112dec0674c1e0713d1d9769068","modified":1587722949450},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"83bd737f663a8461e66985af8ddbfc0a731fc939","modified":1587722949450},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"80488259271bcfe38031f4c2e902463daba9336b","modified":1587722949451},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"c911045b2ce9a66e38d9dd30c7ed078abbc10cbf","modified":1587722949451},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"ceacfa6218f6084c71a230b086e5d2708d29927e","modified":1587722949453},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"aca7bb220fc14ef2a8f96282d2a95a96a9238d46","modified":1587722949453},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"8b7aafb911850c73074cdb6cc87abe4ac8c12e99","modified":1587722949453},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"adaf0f580fccf4158169eeaf534a18005b39a760","modified":1587722949453},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"03a5bcecc0b12231462ef6ffe432fa77ee71beff","modified":1587722949453},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"3256e39f281f06751a1c0145d9806a0e56d68170","modified":1587722949454},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"51d46fa3c7c6b691c61a2c2b0ac005c97cfbf72b","modified":1587722949454},{"_id":"source/images/DeRPN_fig2.png","hash":"30ef45adc8c9335bc896b5e2ec09b4096d17ec67","modified":1587720342858},{"_id":"source/images/M2Det_fig2.png","hash":"335a17497636d7b03535a133a982f2e89266cea7","modified":1587720342878},{"_id":"source/images/Grid-RCNN_fig2.png","hash":"65e1e9f69e1d3e7b1b7b8b95d5cbb1859a99e897","modified":1587720342874},{"_id":"source/images/obj_det/lightweight_fig2.png","hash":"641dbf830e3798478e25c3b49737cdc6ea33e473","modified":1614998381741},{"_id":"source/images/DSOD_fig1.png","hash":"19c19bc5ee6dadb3498de545b5eae190a17309ba","modified":1587720342856},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1587722949469},{"_id":"source/images/BBox-reg_fig1.png","hash":"1458cac1708ced6ad430da020ae1c4c84a0ddc6e","modified":1587720342849},{"_id":"source/images/CGAN_fig2.png","hash":"d690cf996f276f489982f47ed689683d1c48de1a","modified":1587720342853},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1587722949469},{"_id":"source/images/img_cls/resnet_3.png","hash":"d8b027e159cacbf69af5f6829dea83fb1641af3e","modified":1611192738286},{"_id":"public/categories/index.html","hash":"56e868494f915053f3cf3c3fc734e177f3909d0d","modified":1632991130380},{"_id":"public/about/index.html","hash":"7678294360bbf8abb5f41ff3d6fdef81980dbd98","modified":1632991130380},{"_id":"public/tags/index.html","hash":"9b63b6fe50ba8ba2f21e67e33a592d08ef3a51f5","modified":1632991130380},{"_id":"public/2021/09/19/ml/k_fold/index.html","hash":"56379e0a9176462974bc2b1e5fddd7f1a8e15112","modified":1632991130380},{"_id":"public/2021/08/10/cpp/cmake/func_macro/index.html","hash":"354bceb741d9d11d248644bd8f2bb7a8d4ba7588","modified":1632991130380},{"_id":"public/2021/06/28/cpp/constructor/index.html","hash":"c527e30a34f818c58340a4766700d7c991e7e091","modified":1632991130380},{"_id":"public/2021/03/08/dl/norm/index.html","hash":"e3aff533d4f58b053d4d83eb5828cbf4294d45c6","modified":1632991130380},{"_id":"public/2021/02/20/dl/Metrics/index.html","hash":"e186f1f11c3ccee06006622de08528c077a2ecdf","modified":1632991130380},{"_id":"public/2021/02/19/dl/Training-Operations/index.html","hash":"6c7af38c94aebc28d92b5ac879b2965123b10c58","modified":1632991130380},{"_id":"public/2021/02/02/TODO/index.html","hash":"284f12b2b275e50fd80f19855cdbdc36fe3dde32","modified":1632991130380},{"_id":"public/2021/01/23/tools/shell/index.html","hash":"dbe84c88ac20e6ff8ac7f602369b3799cfc67b52","modified":1632991130380},{"_id":"public/2021/01/08/dl/tricks_1/index.html","hash":"07e121bb6b724ce5d315b32f498f595db41ffee1","modified":1632991130380},{"_id":"public/2021/01/08/pytorch/tricks_1/index.html","hash":"2c028cbb57abc14fbe4b41ea7be4059ccefea53b","modified":1632991130380},{"_id":"public/2020/06/23/dip/hist_equal/index.html","hash":"a4d112fb0dafbe0717a5921c9a53c5537252d7a2","modified":1632991130380},{"_id":"public/2020/05/27/cv/methods/index.html","hash":"d3fc616b3c89b9b4eae90737ab8db79a4adedb5d","modified":1632991130380},{"_id":"public/2019/12/20/dp/DP4/index.html","hash":"22236949b6fd95e775e5dca546c1ce68c3919d66","modified":1632991130380},{"_id":"public/2019/07/25/WGAN/index.html","hash":"5d0a29acd94a583e525bc1956a4e0da2ee8b4017","modified":1632991130380},{"_id":"public/2019/07/11/cpp/cpp-aux-tools/index.html","hash":"9ab3f29da4cc7151ffa2acc4f3bf5d3c3a9c7fd2","modified":1632991130380},{"_id":"public/archives/page/5/index.html","hash":"067a3c5c5f7857994f703213a3ec138c0bfa7492","modified":1632991130380},{"_id":"public/archives/2019/06/index.html","hash":"4ace31c213d41a0008fccfe8a8e98e4970bb2ddb","modified":1632991130380},{"_id":"public/archives/2019/07/index.html","hash":"d9f7cbd181ae13026fcd5c85f2311d09bd846e26","modified":1632991130380},{"_id":"public/archives/2019/08/index.html","hash":"6e381d485150d933a8ef4a7fd0235c4eaa18904c","modified":1632991130380},{"_id":"public/archives/2019/09/index.html","hash":"3598132bece656a734f3207d9cc7582ed55ce813","modified":1632991130380},{"_id":"public/archives/2019/11/index.html","hash":"6fe8370496b37c8c1dc2100826c49b662090036e","modified":1632991130380},{"_id":"public/archives/2019/12/index.html","hash":"06e56bb320460a0728d068d27f09444ed462a4a5","modified":1632991130380},{"_id":"public/archives/2020/index.html","hash":"25291c951a0f4d695e9940fefa6575c880d54a5a","modified":1632991130380},{"_id":"public/archives/2020/01/index.html","hash":"e7d7a2443fd3ee3bbe6af08e55a29b2502de0f5c","modified":1632991130380},{"_id":"public/archives/2020/04/index.html","hash":"3f755746ace291ee2aadda4e28a31b97679639d4","modified":1632991130380},{"_id":"public/archives/2020/05/index.html","hash":"c94717b858a791aa19bbc240c076106305617f30","modified":1632991130380},{"_id":"public/archives/2020/06/index.html","hash":"79c5794b4d53bf90851b23d92aa96a71bd592056","modified":1632991130380},{"_id":"public/archives/2021/01/index.html","hash":"c1383177b01fe1b2555fc329e2ea3f2474f0004a","modified":1632991130380},{"_id":"public/archives/2021/02/index.html","hash":"d9f23f0e76fa64e9d076f557b4662d64a0e626cd","modified":1632991130380},{"_id":"public/archives/2021/03/index.html","hash":"e02dbf0e50776ccee682155ad1044140df1cb8b8","modified":1632991130380},{"_id":"public/archives/2021/06/index.html","hash":"f211fc34ef6892455899a570a421a13352257b43","modified":1632991130380},{"_id":"public/archives/2021/07/index.html","hash":"604bca4984fcf3bf5ea8bf3530fe060e48ce3983","modified":1632991130380},{"_id":"public/archives/2021/08/index.html","hash":"640e29d1abbbb7142e1c2cddb516a5802eff8ec8","modified":1632991130380},{"_id":"public/archives/2021/09/index.html","hash":"b594185040eff13d16a2c97c19fa2917f7bfb75c","modified":1632991130380},{"_id":"public/tags/object-detection/index.html","hash":"a6a8032bd0966b6dfc6f9fc01b88cd046e2e3ef7","modified":1632991130380},{"_id":"public/tags/object-detection/page/2/index.html","hash":"2c85456284d3c5dffdb645abf5bca70af2a8aed0","modified":1632991130380},{"_id":"public/tags/GAN/index.html","hash":"13bf8065672408656e84dab983e321b4fa1808a8","modified":1632991130380},{"_id":"public/tags/DIP/index.html","hash":"53f9602c461d24f92614c99de19155051c955d0d","modified":1632991130380},{"_id":"public/tags/CV/index.html","hash":"80ce1797e10bd03aa14b2c90ca0bc6f902b69d95","modified":1632991130380},{"_id":"public/tags/cmake/index.html","hash":"117e6527f5ec8cea53994a65f61ef1e30aa50d22","modified":1632991130380},{"_id":"public/tags/c/index.html","hash":"391e54d92f72399632386a2386302fc7bd66ac30","modified":1632991130380},{"_id":"public/tags/C/index.html","hash":"079a7155ba0592e0c5662d2dc678be7c6b3a3e48","modified":1632991130380},{"_id":"public/tags/CNN-Deep-Learning/index.html","hash":"c26254663eae80ad42176d3c591dd604c963a07e","modified":1632991130380},{"_id":"public/tags/Deep-Learning-CNN/index.html","hash":"056e70c8a97fcb8c5143958de96f4ff139c892e8","modified":1632991130380},{"_id":"public/tags/Deep-Learning/index.html","hash":"6351bf204460bcc56149338a394413ed22d47a1c","modified":1632991130380},{"_id":"public/tags/math/index.html","hash":"12d3b0d6a144796406ef4401eac96eeee9898616","modified":1632991130380},{"_id":"public/tags/DP/index.html","hash":"69acc742f6dd9aaa0303ecf044991bf48f883339","modified":1632991130380},{"_id":"public/tags/image-classification/index.html","hash":"18f77102616795b0152c8400b2017f01439b1514","modified":1632991130380},{"_id":"public/tags/img-cls/index.html","hash":"54ce73e485d470d62b7186023678911a444c4c49","modified":1632991130380},{"_id":"public/tags/machine-learning/index.html","hash":"16a27b445703b4cd965c4f89fe07eb25b62d1474","modified":1632991130380},{"_id":"public/tags/Object-Detection/index.html","hash":"ad681e732bd1f2c0ce09aa1c7b285fc3745dd2dd","modified":1632991130380},{"_id":"public/tags/cmake-C/index.html","hash":"9f530bfb12b19814c6c302169544b0bb515e5f60","modified":1632991130380},{"_id":"public/tags/DL/index.html","hash":"976b7c6a153fb822f8be65162a643c76ead740e5","modified":1632991130380},{"_id":"public/tags/PyTorch/index.html","hash":"582892a50f26c0d6b2075b2f9c9c09cb3a8d95b6","modified":1632991130380},{"_id":"public/tags/PyTorch/page/2/index.html","hash":"56b2b956071366c2b6165f00c642f5d19f7d5735","modified":1632991130380},{"_id":"public/tags/tool/index.html","hash":"53246ad4f1dde3eaa34b89e2b914b5fbee7c64ed","modified":1632991130380},{"_id":"public/tags/cmake-c/index.html","hash":"436ce61b38197f1b38246236d0c6d21f0fefb188","modified":1632991130380},{"_id":"public/categories/DL-Framework/index.html","hash":"2f80bea58e3513202058029eea22cfc9414e3b41","modified":1632991130380},{"_id":"public/categories/math/index.html","hash":"bdcca60936e16fbe9f2cced14b5e46d392eba2ab","modified":1632991130380},{"_id":"public/2021/09/29/ml/multiclass_algo/index.html","hash":"d90f4b24441c07451d4de9450496bbac1ddbcece","modified":1632991130380},{"_id":"public/2021/09/28/ml/multiclass/index.html","hash":"d8aa8764c19ad1e17ef94f37e03e6fe1a87e6a62","modified":1632991130380},{"_id":"public/2021/09/26/ml/kernel/index.html","hash":"865df30e042c5bf92b1a7e39d9db8b8b578d854a","modified":1632991130380},{"_id":"public/2021/09/22/ml/svm/index.html","hash":"069327ee2102dd2e992c823839286d1671b909e2","modified":1632991130380},{"_id":"public/2021/09/17/ml/linear/index.html","hash":"546a0db6f08c86f038b2d1af1d3bf27dfb8738b7","modified":1632991130380},{"_id":"public/2021/09/15/ml/halfspace/index.html","hash":"a716b0bf134bb1c74da36b3e1520aa82fab8c900","modified":1632991130380},{"_id":"public/2021/08/24/tools/jupyter-book/index.html","hash":"d02a32771234855bf6e58be3e929532011f9170f","modified":1632991130380},{"_id":"public/2021/08/06/cpp/gcc_common_usages/index.html","hash":"ee4c51d8177b2491787fece13bc264bb4de4d6a6","modified":1632991130380},{"_id":"public/2021/07/05/cpp/type_declare/index.html","hash":"6ea4efc452d67d1ec8e772334bdbce99b21d71b9","modified":1632991130380},{"_id":"public/2021/06/25/cpp/string/index.html","hash":"c2b6c24e8a45266f6509d8f243a6ebffdea30e75","modified":1632991130380},{"_id":"public/2021/06/16/python/ext3/index.html","hash":"9b57440e2d60cfa5bf4328247304c6f9ab8e2a01","modified":1632991130380},{"_id":"public/2021/06/16/python/ext2/index.html","hash":"cc0f8881296b597a665a8fed783918b36fe8e5ab","modified":1632991130380},{"_id":"public/2021/06/15/python/ext1/index.html","hash":"629e5d4a367982214f04fe3658da8fbf5025c132","modified":1632991130380},{"_id":"public/2021/06/12/python/setup/index.html","hash":"9d1b0c9f4cd18e9d1e98e2f0ddad9615334d5e62","modified":1632991130380},{"_id":"public/2021/06/08/cpp/cmake_target/index.html","hash":"a57b0036db31eb4f19b423960b5ac7dce19f9ce0","modified":1632991130380},{"_id":"public/2021/06/08/cpp/cmake_find/index.html","hash":"8dcf511cbfd3a021b9b7a91a41078f51b98d21f3","modified":1632991130380},{"_id":"public/2021/06/08/cpp/link/index.html","hash":"8ab7afa334ceca6fb697387b944c5bac74ad46ac","modified":1632991130380},{"_id":"public/2021/06/04/cpp/cmake_cmds_1/index.html","hash":"249812b248f90b2f178e0904925c355577951b60","modified":1632991130380},{"_id":"public/2021/06/03/cpp/cmake_im_ex/index.html","hash":"af7272881de52d824ffd3a3d1d883263bd0f48b4","modified":1632991130380},{"_id":"public/2021/06/02/cpp/cmake_1/index.html","hash":"a04eb5633738f173d5a8e3bb47a7c38d17cc3c33","modified":1632991130380},{"_id":"public/2021/03/05/obj_det/lightweight/index.html","hash":"ca98ffbe1a749beb372a8ca8d4c9971c3de19188","modified":1632991130380},{"_id":"public/2021/02/25/obj_det/anchor_free/index.html","hash":"066bf6327d783f3d93f6bce4ff87d20701cfbd5c","modified":1632991130380},{"_id":"public/2021/02/23/obj_det/one_stage/index.html","hash":"d15012b5a8db4edb4050d84204fa2960223e830b","modified":1632991130380},{"_id":"public/2021/02/20/obj_det/two_stage/index.html","hash":"06e621f5a6b2cbf09961c936b0fc0ccbad9f2494","modified":1632991130380},{"_id":"public/2021/02/19/dl/conv/index.html","hash":"f47ffbd630e9fa0b7b7da282eafe744cc04afb4d","modified":1632991130380},{"_id":"public/2021/02/18/dl/receptive_field/index.html","hash":"be6b9b3bcbe1a628ded217fdd4a6aa8d225b94e7","modified":1632991130380},{"_id":"public/2021/01/19/img_cls/resnet/index.html","hash":"ad2a05e514f674de5c15b843dfb5a23a10c4a054","modified":1632991130380},{"_id":"public/2021/01/13/pytorch/loss_2/index.html","hash":"e7fb11dd11d1b962c7267ed7879e2e3ca34e89d5","modified":1632991130380},{"_id":"public/2021/01/12/pytorch/loss_1/index.html","hash":"9f281abb019102b262d86fdbe5391c33fbdf1c64","modified":1632991130380},{"_id":"public/2021/01/12/dl/x_ent_loss/index.html","hash":"3464d052b2254aff0afe8bb4d71c2b4b3019ec87","modified":1632991130380},{"_id":"public/2020/04/20/obj_det/YOLO/index.html","hash":"cc8cecb9519c36ded98322cc73704be777bcaaab","modified":1632991130380},{"_id":"public/2020/01/08/pytorch/optim-2/index.html","hash":"bf3408c51c254e647f267efc26d7b405b1207f3a","modified":1632991130380},{"_id":"public/2020/01/06/pytorch/optim-1/index.html","hash":"9986660d05d2c6f82c3e2d70ff5d71ebf02185bb","modified":1632991130380},{"_id":"public/2020/01/02/pytorch/optim_SGD/index.html","hash":"1bc3a3341fef8fe5820615a46bfa871ad86dc999","modified":1632991130380},{"_id":"public/2019/12/31/img_cls/densenet/index.html","hash":"ab75c3aad72de07290ca19cd93a38802f0281de8","modified":1632991130380},{"_id":"public/2019/12/07/DIP-2/index.html","hash":"ab893bb403a287afb130f3c6e650553189cd427b","modified":1632991130380},{"_id":"public/2019/12/05/DIP-1/index.html","hash":"98f381645e3ef5d4a572346f8f0c6285f1769484","modified":1632991130380},{"_id":"public/2019/11/01/pytorch/PyTorch-mtd/index.html","hash":"5784352ab5f28df5be7b2c9cf9f8add9c6753eee","modified":1632991130380},{"_id":"public/2019/09/09/pytorch/DL-env/index.html","hash":"d8da2d236b80300134d0d7ed09e9ea6bb50698a6","modified":1632991130380},{"_id":"public/2019/08/27/dp/DP3/index.html","hash":"92105a405a935a49f7322b9c72d6fbece13efabb","modified":1632991130380},{"_id":"public/2019/08/27/pytorch/PyTorch-5/index.html","hash":"94be4d72f5165392d434a806cc239c6cbeea945f","modified":1632991130380},{"_id":"public/2019/08/22/pytorch/PyTorch-4/index.html","hash":"bb2097b05d29c3cb62bfb6bbde8e889e07438fa8","modified":1632991130380},{"_id":"public/2019/08/14/dp/DP2/index.html","hash":"479af56108d45ad27122a2c7810b5fe2a29af5f7","modified":1632991130380},{"_id":"public/2019/08/07/dp/DP1/index.html","hash":"becd5c6c7bf01b13c885515c04affdd8ded84629","modified":1632991130380},{"_id":"public/2019/08/01/ImprovedGAN/index.html","hash":"7284bfa6d5d28b4d7dab4ae8e44006576fea9a71","modified":1632991130380},{"_id":"public/2019/07/29/CGAN/index.html","hash":"a17a3ee13482583adbde26ef5e98cad9b559a76b","modified":1632991130380},{"_id":"public/2019/07/23/GAN/index.html","hash":"cbc0524d2b8e801d61db670fee4c430b3426f902","modified":1632991130380},{"_id":"public/2019/07/19/Grid-RCNN/index.html","hash":"d9fb20150cff08271746b3ee74c394933b6e08cf","modified":1632991130380},{"_id":"public/2019/07/17/RepPoints/index.html","hash":"f793a0a39fdbe05bff3b52cd6a4c77bab84b3829","modified":1632991130380},{"_id":"public/2019/07/17/DetNet/index.html","hash":"77ca417482e7412cc1609a3aa018597de62d5725","modified":1632991130380},{"_id":"public/2019/07/16/loss/index.html","hash":"474ad5a6c8faf12fb265aa92dd38790098729b4b","modified":1632991130380},{"_id":"public/2019/07/15/DeRPN/index.html","hash":"156ceb473d5b087ce844294063819121f9ca5514","modified":1632991130380},{"_id":"public/2019/07/08/mask-rcnn/index.html","hash":"9e9d50937231a621230a310054837a76b9114527","modified":1632991130380},{"_id":"public/2019/07/08/DSOD/index.html","hash":"36a950f8a1602bba4941e4d879c6f63ba50a145b","modified":1632991130380},{"_id":"public/2019/07/03/libra-rcnn/index.html","hash":"127eece5c92d275925ba518e009385b28efcbb34","modified":1632991130380},{"_id":"public/2019/07/02/gcc-src/index.html","hash":"47bcbcf9fbe9a71745272e25e0476339c9044475","modified":1632991130380},{"_id":"public/2019/06/28/M2Det/index.html","hash":"1a006db31133208c43419e96d1780b824828a1df","modified":1632991130380},{"_id":"public/2019/06/28/BBox-Reg-Uncertainty/index.html","hash":"cd45b903f1e12f44a48cc4734cf5616efab44a56","modified":1632991130380},{"_id":"public/2019/06/27/FSAF/index.html","hash":"6efc2352a76c637b4459bd00cf202893b2e69e6b","modified":1632991130380},{"_id":"public/2019/06/25/GA-RPN/index.html","hash":"afbbdf0f50f169e3ca1d230482f10bf873e836df","modified":1632991130380},{"_id":"public/2019/06/24/cv-mtds/index.html","hash":"c915376bcd11bcebe073ba014772cc5570cd90fe","modified":1632991130380},{"_id":"public/2019/06/21/TridentNet/index.html","hash":"9b8a0f0774f045b0854f5ec94d03a7389db25728","modified":1632991130380},{"_id":"public/2019/06/18/pytorch/PyTorch-3/index.html","hash":"b475b0ba0c5a4fa50bac062ec938a2286f072f04","modified":1632991130380},{"_id":"public/2019/06/16/mAP/index.html","hash":"014eaffcebd81d3e71cbeece51a0b7b7b0f9817f","modified":1632991130380},{"_id":"public/2019/06/13/GIoU/index.html","hash":"e08c5a7172722a7a41b3352a24c185d0b4954a2c","modified":1632991130380},{"_id":"public/2019/06/13/pytorch/PyTorch-2/index.html","hash":"3eaf414a6a820fd71a7eb45a570d84ac2d3deecc","modified":1632991130380},{"_id":"public/2019/06/13/tools/Hexo-Sync/index.html","hash":"955ba8ae7f80c1fd5f7344c43ca1c2e97f58adbc","modified":1632991130380},{"_id":"public/2019/06/12/pytorch/PyTorch-1/index.html","hash":"79e35ffb191b7378deb57927c0d4f53c0d06f2cb","modified":1632991130380},{"_id":"public/archives/index.html","hash":"8a6609fe26aa8e9b459a33c85a3d34ddf1204d00","modified":1632991130380},{"_id":"public/archives/page/2/index.html","hash":"ca5aab25175f6793c02b494a166f8245174e5f4a","modified":1632991130380},{"_id":"public/archives/page/3/index.html","hash":"5e0e64a53692c85aa88d722eb5860daedabc6076","modified":1632991130380},{"_id":"public/archives/page/4/index.html","hash":"e3d020b45480d10dfa52ac8f14cc1b8a79bca173","modified":1632991130380},{"_id":"public/archives/2019/index.html","hash":"8683f343029ba1b1af044d47e6517b5394ac411c","modified":1632991130380},{"_id":"public/archives/2019/page/2/index.html","hash":"0f2f0a5948882647ddb7e52c4e8a28e5e0be52e6","modified":1632991130380},{"_id":"public/archives/2021/index.html","hash":"05ef16db2ed3627b21319c6d68fbaf4213155dbe","modified":1632991130380},{"_id":"public/archives/2021/page/2/index.html","hash":"ad61a91491f437995faee5c1424e469db8976a0f","modified":1632991130380},{"_id":"public/index.html","hash":"2da9c20cce5ffc03b79b92e2a498b02a4425b8c6","modified":1632991130380},{"_id":"public/page/2/index.html","hash":"612efa0c77ca630e00bab1f9998d70fd9cc98f14","modified":1632991130380},{"_id":"public/page/3/index.html","hash":"0bb9fdb46bf0a63a3cebcaf000e2a53a553fbd75","modified":1632991130380},{"_id":"public/page/4/index.html","hash":"04776789358f96843111266a49f231f9e8b11181","modified":1632991130380},{"_id":"public/page/5/index.html","hash":"dce2ce6205a1def2b723c25dd1fb7c79d046f61a","modified":1632991130380},{"_id":"public/page/6/index.html","hash":"509afe3e8fe51a261cfd76d1d228dff318fa6451","modified":1632991130380},{"_id":"public/page/7/index.html","hash":"3e4cbd0da70b2cc1fb1ad987cf04e5762707ecb1","modified":1632991130380},{"_id":"public/page/8/index.html","hash":"f80415a28866e36631fb140b96fd87f4acfb9212","modified":1632991130380},{"_id":"public/page/9/index.html","hash":"29181a4d332902bd44a814a1871a7af554c8afec","modified":1632991130380},{"_id":"public/images/obj_det/courgette.log","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1632991130380},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1632991130380},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1632991130380},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1632991130380},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1632991130380},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1632991130380},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1632991130380},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1632991130380},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1632991130380},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1632991130380},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1632991130380},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1632991130380},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1632991130380},{"_id":"public/images/BBox-reg_fig4.png","hash":"651ed85e9511c2ea9ff0c9c76248e71a950c41d4","modified":1632991130380},{"_id":"public/images/BBox-reg_fig3.png","hash":"941dbd9edad7d9e4961866872d93c87f35ae1c40","modified":1632991130380},{"_id":"public/images/CGAN_fig1.png","hash":"94d2eb94087c072188200f54dfccb665a4bb0bc3","modified":1632991130380},{"_id":"public/images/DP1_fig1.png","hash":"ed9dd7cbecff94be6778831a494b1295482bfe3e","modified":1632991130380},{"_id":"public/images/DP2_fig1.png","hash":"a90b55aa55d0cfdd147c5b00feaf432300f2854b","modified":1632991130380},{"_id":"public/images/DetNet_fig1.png","hash":"0be4e55fcb24f78c0ae7e0abd848c863858c907e","modified":1632991130380},{"_id":"public/images/DetNet_fig2.png","hash":"dffd982d9558203676d5df62ded8eb2f4fa314d1","modified":1632991130380},{"_id":"public/images/FSAF_fig2.png","hash":"5980bbb5993d141c28aecc700f01bdbaf793d018","modified":1632991130380},{"_id":"public/images/FSAF_fig3.png","hash":"c792cc01936994074b8e6fce3b9884801d7e9f4b","modified":1632991130380},{"_id":"public/images/FSAF_fig5.png","hash":"afd140d4277cdf34e02d9607a950e805c33398e8","modified":1632991130380},{"_id":"public/images/FSAF_fig4.png","hash":"a7fd53318b0879dba659aa13e5bb8e87ddaa57f3","modified":1632991130380},{"_id":"public/images/FSAF_fig6.png","hash":"6d4ddfb5ca31af495ad5ba5f80d66f8cb0c5e79b","modified":1632991130380},{"_id":"public/images/GA-RPN_fig3.png","hash":"12f2d60e449b7213de492d18a2b0ada527788d94","modified":1632991130380},{"_id":"public/images/GAN_fig1.png","hash":"c6f2c668d1b4d98d4bd7fdc27851faed5c7ffe9c","modified":1632991130380},{"_id":"public/images/GIoU_fig2.png","hash":"874dbb5acd431fd27c0be189513190d30449b57c","modified":1632991130380},{"_id":"public/images/Grid-RCNN_fig1.png","hash":"4c257e0b6f9f569b1a60ac27af54ca440812bc9c","modified":1632991130380},{"_id":"public/images/ImprovedGAN_fig1.png","hash":"9496ef5958922774f45112291e76fc421ba33ad5","modified":1632991130380},{"_id":"public/images/M2Det_fig3.png","hash":"1a1f004e3ae0786c11e9ae915a229b41634e7e9f","modified":1632991130380},{"_id":"public/images/TridentNet_fig1(b).png","hash":"03489e4b700364b62b4693418137113f38f03c82","modified":1632991130380},{"_id":"public/images/TridentNet_fig1(c).png","hash":"3c3ec6c57f7ebb7180af2c2dc0649857ac37ad9b","modified":1632991130380},{"_id":"public/images/libra-rcnn_figa.png","hash":"761b2d9d6c57c8279ee717b4b011a19c987e5259","modified":1632991130380},{"_id":"public/images/mAP_fig1.png","hash":"e1e227bb2bf05159c46b812d4acb9683631e8aba","modified":1632991130380},{"_id":"public/images/mAP_fig3.png","hash":"5289afe8e4ec978a94571d7d001563713404155f","modified":1632991130380},{"_id":"public/images/mAP_fig2.png","hash":"6fe61598c855d8086c10c04187c9956d7b14b5be","modified":1632991130380},{"_id":"public/images/mAP_fig4.png","hash":"a13992fc8671dd3c1f5a44a9cd714176f580681d","modified":1632991130380},{"_id":"public/images/mAP_fig5.png","hash":"8727119e5d2a352699c59a7ef5429a2d30b3cef9","modified":1632991130380},{"_id":"public/images/pytorch_mtd_aligncorners.png","hash":"8e1fff6ffbefc3b3bfb3fabbb2aa34c035b922a4","modified":1632991130380},{"_id":"public/images/pytorch_mtd_conv_t_1.png","hash":"68104100110da86678ff50bbc0d7418946c68f10","modified":1632991130380},{"_id":"public/images/mask-rcnn_fig3.png","hash":"593aa6f15b90d819e5690a2cd8befa3ba24ebccf","modified":1632991130380},{"_id":"public/images/cpp/C_linking_process.png","hash":"92e289dd530f7964acd73cc16663ec3d37e7d4d4","modified":1632991130380},{"_id":"public/images/pytorch_mth_conv.png","hash":"789dc01b7cd1d19267d690b001bf45582d720085","modified":1632991130380},{"_id":"public/images/cpp/string1.png","hash":"1e5c94ee90e25254fac96fe3ce0caa9debca38c3","modified":1632991130380},{"_id":"public/images/img_cls/densenet_2.png","hash":"0d027c4897b024f9b9d20b21b5d3afaf1dd6e70c","modified":1632991130380},{"_id":"public/images/img_cls/resnet_2.png","hash":"533b0bfdf322cb80e914589bae69b20e98f25dcd","modified":1632991130380},{"_id":"public/images/ml/multiclass_fig2.png","hash":"3c383d90410947e1d5b57264225049218bb30f04","modified":1632991130380},{"_id":"public/images/img_cls/resnet_4.png","hash":"853e6a7da14895d60a5d894abf4f081730b5a927","modified":1632991130380},{"_id":"public/images/ml/multiclass_fig1.png","hash":"0062099b37effc625caf8e05e0555fadb87f4bb6","modified":1632991130380},{"_id":"public/images/pytorch/NAG.png","hash":"54fcfa655d287fe22d00a6b60f216dafd628b71e","modified":1632991130380},{"_id":"public/images/ml/multiclass_fig3.png","hash":"85e436595fb14125c40cd0dbfe74370c2acff230","modified":1632991130380},{"_id":"public/images/pytorch/NAG_0.png","hash":"95aa0c0197c730db1bda3ffffe8895287826132e","modified":1632991130380},{"_id":"public/images/obj_det/YOLOv1_fig1.jpg","hash":"7da82e62769ef15baafce9848f5164c00fab3b1b","modified":1632991130380},{"_id":"public/images/pytorch/overfitting.png","hash":"65c45d4a6a92b9664ab1454535350c1bb8423083","modified":1632991130380},{"_id":"public/images/pytorch/momentum.png","hash":"0b274a844e87ac5c878a8e5b66848288d36d1aea","modified":1632991130380},{"_id":"public/images/obj_det/YOLOv2_fig2.png","hash":"5c64920430b221ffaee62e991ae509c2410babb6","modified":1632991130380},{"_id":"public/images/obj_det/two_stage_fig1.png","hash":"113acd4ea03918c0b8f9f38ea446c6d8dde8ada7","modified":1632991130380},{"_id":"public/images/obj_det/lightweight_fig1.png","hash":"b635af22f951130e6c16bbb71684892513bd3475","modified":1632991130380},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1632991130380},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1632991130380},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1632991130380},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1632991130380},{"_id":"public/images/BBox-reg_fig2.png","hash":"645d710112f0a5b25f1d34020c1f7e56cfc2ad62","modified":1632991130380},{"_id":"public/images/CGAN_fig2.png","hash":"d690cf996f276f489982f47ed689683d1c48de1a","modified":1632991130380},{"_id":"public/images/DeRPN_fig1.png","hash":"09d707a0fd6534c106e4f503c104c36aed31293e","modified":1632991130380},{"_id":"public/images/GA-RPN_fig1.png","hash":"3879e968e038df6b23ad8793a1dc5933b14454ac","modified":1632991130380},{"_id":"public/images/GA-RPN_fig2.png","hash":"fb3585918ffff3813d462bd78799b847989598c7","modified":1632991130380},{"_id":"public/images/GAN_alg1.png","hash":"d535c3b65a4c0c8eb331c79dc5032bf754e7084a","modified":1632991130380},{"_id":"public/images/GAN_fig2.png","hash":"86a432fab3c2df0b7e84f789971e5ced612cc2aa","modified":1632991130380},{"_id":"public/images/GA-RPN_fig4.png","hash":"7d7c11a72c263bdc87e8898b4018d3a96e6f7f1b","modified":1632991130380},{"_id":"public/images/GIoU_fig1.png","hash":"8b5d938397e94b905245363c4dee5f4266e734b9","modified":1632991130380},{"_id":"public/images/Grid-RCNN-Plus_fig1.png","hash":"7255da83a2dadae1b8832adf87b3f60e6ed211d5","modified":1632991130380},{"_id":"public/images/Grid-RCNN_fig4.png","hash":"f06e5e1250a7e59b4d04fbe316592745e65b6650","modified":1632991130380},{"_id":"public/images/Grid-RCNN_fig3.png","hash":"b5e40a1ca3df03b69c06e573086ce5af7f91eec1","modified":1632991130380},{"_id":"public/images/M2Det_fig1.png","hash":"002f75d4ab7fa714afbf0f8d64fadb7ec1799775","modified":1632991130380},{"_id":"public/images/M2Det_fig4.png","hash":"27227839728d56d5c61c57629546b8b7e4d0fb00","modified":1632991130380},{"_id":"public/images/TridentNet_fig1(a).png","hash":"89a0e081b4dba10cbeca8e1af76d23cfa203eb72","modified":1632991130380},{"_id":"public/images/RepPoints_fig2.png","hash":"ef1068b6bf393ea829f199e37e5f14edc70641c3","modified":1632991130380},{"_id":"public/images/TridentNet_fig2.png","hash":"e186f0cd983d28f81df120a01c8611e8f9accdaa","modified":1632991130380},{"_id":"public/images/TridentNet_fig3.png","hash":"52502eade50078f68ca751915681e536a96094b4","modified":1632991130380},{"_id":"public/images/libra-rcnn_fig1.png","hash":"4150832cd9a4c2f9532ad0309e299154fd581d87","modified":1632991130380},{"_id":"public/images/libra-rcnn_fig2.png","hash":"be628467551b790e0cd0e9e3cdd1f041548f60db","modified":1632991130380},{"_id":"public/images/libra-rcnn_fig3.png","hash":"29973e85ddcc86bea3fb84d725471e061a479e75","modified":1632991130380},{"_id":"public/images/libra-rcnn_fig4.png","hash":"cc0dafa1503dad25981ed08a5f33431a5ce40e93","modified":1632991130380},{"_id":"public/images/libra-rcnn_fig5.png","hash":"33795e57abe6b93ce0e70a46dbb37c6348308c2e","modified":1632991130380},{"_id":"public/images/mask-rcnn_fig4.png","hash":"a6000ce7a01688cefdd8af1d3c1bab492954320c","modified":1632991130380},{"_id":"public/images/mask-rcnn_fig1.png","hash":"6ee2989bcd121be915722f0d7ae9ba97039681b6","modified":1632991130380},{"_id":"public/images/pytorch_mtd_conv_t.png","hash":"158a3311f03a494bb7bd1a81a5712cab7aa1c37b","modified":1632991130380},{"_id":"public/images/img_cls/densenet_3.png","hash":"b456a005625516ce3e9acf66011d5fd4d9723e7a","modified":1632991130380},{"_id":"public/images/img_cls/resnet_1.png","hash":"5454e8ca5934d124bc10177771e1ad55999ac973","modified":1632991130380},{"_id":"public/images/img_cls/resnet_3.png","hash":"d8b027e159cacbf69af5f6829dea83fb1641af3e","modified":1632991130380},{"_id":"public/images/obj_det/anchor_free_fig1.png","hash":"ddd42dfa97ce4d60c680b60f3ff81a42263f623a","modified":1632991130380},{"_id":"public/images/obj_det/anchor_free_fig2.png","hash":"c8e0cd9eb5cc4add2339e639a225655543dd5b26","modified":1632991130380},{"_id":"public/images/obj_det/two_stage_fig3.png","hash":"f9c1d3141ae50cc9c84ad4469d885876a626ced6","modified":1632991130380},{"_id":"public/images/obj_det/two_stage_fig2.png","hash":"037ec47ff1ae7cf16f0cf2a122a9a0e0d21e4ac9","modified":1632991130380},{"_id":"public/images/Grid-RCNN-Plus_fig2.png","hash":"801abc90e532b83bc123e58df681d79b9fc8ad4b","modified":1632991130380},{"_id":"public/images/RepPoints_fig1.png","hash":"132a00a2205e81d684269a7a89ff3f61ac520217","modified":1632991130380},{"_id":"public/images/img_cls/densenet_1.png","hash":"f33ee6bfa0d34b8f14aaf6881ae878b9503d7cd4","modified":1632991130380},{"_id":"public/js/bookmark.js","hash":"a00945ff886e9f6f835731cdaf29a3a3727c8877","modified":1632991130380},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1632991130380},{"_id":"public/js/schemes/muse.js","hash":"47c4f60eb7f7dc3303e84914b611dc34827069e1","modified":1632991130380},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1632991130380},{"_id":"public/js/schemes/pisces.js","hash":"3d9d3c14b77044d66be1898a9a934696e9127c82","modified":1632991130380},{"_id":"public/js/local-search.js","hash":"d6673063958127a03881dab2f0376a47f5e08a88","modified":1632991130380},{"_id":"public/js/algolia-search.js","hash":"23cc3c013185eb97ef347c3b4c92d928f2f3398f","modified":1632991130380},{"_id":"public/js/next-boot.js","hash":"a22eeb6048ddd6b9224c8a671cbcfa303a2f7a1a","modified":1632991130380},{"_id":"public/css/main.css","hash":"9fcff6e10e099f1d9d9f96e20d53e04916d8b381","modified":1632991130380},{"_id":"public/images/DeRPN_fig2.png","hash":"30ef45adc8c9335bc896b5e2ec09b4096d17ec67","modified":1632991130380},{"_id":"public/images/Grid-RCNN_fig2.png","hash":"65e1e9f69e1d3e7b1b7b8b95d5cbb1859a99e897","modified":1632991130380},{"_id":"public/images/M2Det_fig2.png","hash":"335a17497636d7b03535a133a982f2e89266cea7","modified":1632991130380},{"_id":"public/images/obj_det/lightweight_fig2.png","hash":"641dbf830e3798478e25c3b49737cdc6ea33e473","modified":1632991130380},{"_id":"public/js/utils.js","hash":"91d174e12c61c332f3b06085d635c2b0f686a758","modified":1632991130380},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1632991130380},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1632991130380},{"_id":"public/images/BBox-reg_fig1.png","hash":"1458cac1708ced6ad430da020ae1c4c84a0ddc6e","modified":1632991130380},{"_id":"public/images/DSOD_fig1.png","hash":"19c19bc5ee6dadb3498de545b5eae190a17309ba","modified":1632991130380},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1632991130380}],"Category":[{"name":"DL Framework","_id":"cku6or91n003ip0djgg456cxz"},{"name":"math","_id":"cku6or92d0056p0djbvxa3mfi"}],"Data":[],"Page":[{"title":"","date":"2019-06-14T13:23:43.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: \ndate: 2019-06-14 21:23:43\ntype: categories\n---\n","updated":"2020-04-24T09:25:42.848Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cku6or8zp0000p0djaoqg4usq","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","date":"2019-07-23T07:12:21.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-07-23 15:12:21\n---\n","updated":"2020-04-24T09:25:42.847Z","path":"about/index.html","comments":1,"layout":"page","_id":"cku6or8zy0002p0dj3b9477cy","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"","date":"2019-06-14T13:23:22.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: \ndate: 2019-06-14 21:23:22\ntype: tags\n---\n","updated":"2020-04-24T09:25:42.904Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cku6or9020005p0dj7d4lbvny","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"BBox-Reg-Uncertainty","date":"2019-06-28T01:23:16.000Z","mathjax":true,"_content":"[Bounding Box Regression with Uncertainty for Accurate Object Detection](https://arxiv.org/abs/1809.08545)\n<!-- more -->\n# \n ImageNetMS-COCO  CrowdHuman  ground truth bounding box gt bbox  bbox  1\n![](/images/BBox-reg_fig1.png) <center>Fig 1 MS-COCO  gt bbox (a)(c) (b) (d) </center>\n\n SOTA  Faster R-CNNCascade R-CNN  Mask R-CNN  bbox  bbox  smooth-L1  gt box  bbox  Inference  2 bbox  __ loss __\n![](/images/BBox-reg_fig2.png) <center>Fig 2 MS-COCO  VGG-16 Faster R-CNN (a) (b)  bbox </center>\n\n bbox  KL loss bbox  __ loss __ gt box  box  gt box  Gaussian  Dirac delta KL loss  gt  KL  KL KL  P(x) Q(x)  KL \n$$D_{KL}(P||Q)=\\sum_{i=1}^N P(x_i) \\log \\frac {P(x_i)} {Q(x_i)}$$\n\n$$D_{KL}(P||Q)=E_P \\left[\\log \\frac {p(x)} {q(x)} \\right]=\\int p(x) \\log \\frac {p(x)} {q(x)} dx$$\n p(x)  q(x) \n P,Q  KL  0\n\n KL loss  bbox \n1.  bbox\n2.  var voting (variance voting) box  box  Fig 2 \n3.  box \n\n\n\n KL loss  var voting PASCAL VOC 2007  MS-COCO  benchmark VGG-CNN-M-1024, VGG-16, ResNet-5-FPN  Mask R-CNN Faster R-CNN\n\n# \n## BBox \n Faster R-CNN  Mask R-CNN  3 bbx  Box  shape  (N, 84) N  proposals  batch size84  21  4  PASCAL VOC  21 Box std  shape  (N, 84) 21  4  $\\sigma$not class-agnostic box \n![](/images/BBox-reg_fig3.png)\n\n $(x_1,y_1,x_2,y_2) \\in \\mathcal R^4$  bbox $\\{t_i| i=x_1,y_1,x_2,y_2\\}$ \n\n$$t_{x_1}=\\frac {x_1-x_{1a}} {w_a}, \\quad t_{x_2}=\\frac {x_2-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}=\\frac {y_1-y_{1a}} {h_a}, \\quad t_{y_2}=\\frac {y_2-y_{2a}} {h_a}\n\\\\\\\\ t_{x_1}^{\\ast}=\\frac {x_1^{\\ast}-x_{1a}} {w_a}, \\quad t_{x_2}^{\\ast}=\\frac {x_2^{\\ast}-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}^{\\ast}=\\frac {y_1^{\\ast}-y_{1a}} {h_a}, \\quad t_{y_2}^{\\ast}=\\frac {y_2^{\\ast}-y_{2a}} {h_a}$$\n\n *  gt offset *  offset$(x_{1a},y_{1a},x_{2a},y_{2a})$  anchor box x x $\\{x_1,y_1,x_2,y_2\\}$\n\n bbox \n$$P_{\\Theta}(x)=\\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}}$$\n $\\Theta$ $x_e$  bbox  $\\sigma$  $\\sigma \\rightarrow 0$ bbox \n\n~~ Faster R-CNN bbox  blob 4   4 $\\Theta$ ~~\n\ngt box  0 $\\sigma \\rightarrow 0$ Dirac delta \n$$P_D(x)=\\delta(x-x_g)$$\n $x_g$  gt box  x \n\n##  KL Loss  BBox \n $P_{\\Theta}(x)$  $P_D(x)$  KL  $\\hat \\Theta$ KL \n$$\\hat \\Theta = \\arg \\min_{\\Theta} \\frac 1 N \\sum D_{KL}(P_D(x)||P_{\\Theta}(x))$$\n N x  4 KL \n$$\\begin{aligned} L_{reg} &=D_{KL}(P_D(x)||P_{\\Theta}(x)) \n\\\\\\\\ &=\\int P_D(x) \\log P_D(x) dx - \\int P_D(x) \\log P_{\\Theta}(x) dx\n\\\\\\\\ &=-H(P_D(x))-\\int P_D(x) \\log \\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}} dx\n\\\\\\\\ &=-H(P_D(x))+ \\log \\sqrt{2\\pi \\sigma^2}\\int P_D(x) dx+\\int P_D(x) \\frac {(x-x_e)^2} {2 \\sigma^2} dx\n\\\\\\\\ &=\\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2 + \\frac {\\log 2\\pi} 2 - H(P_D(x))\n\\end{aligned}$$\n\n$H(P_D(x))$  Dirac delta \n\n 4\n![](/images/BBox-reg_fig4.png)\n\n box  $x_e$  $\\sigma^2$  $L_{reg}$ $H(P_D(x)), \\log (2\\pi)/2$  $\\Theta$ \n$$L_{reg} \\propto \\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2$$\n $\\sigma=1$KL Loss \n$$L_{reg} \\propto \\frac {(x_g-x_e)^2} 2$$\n $x_e$  $\\sigma$ \n$$\\frac d {dx_e}L_{reg}=\\frac {x_e-x_g} {\\sigma^2}\n\\\\\\\\ \\frac d {dx_e}L_{reg}=-\\frac {(x_e-x_g)^2} {\\sigma^3} + \\frac 1 \\sigma$$\n\n $\\sigma$  $\\alpha=\\log \\sigma^2$  $\\sigma$ 3  Box std  $\\alpha$\n$$L_{reg} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2$$\n $L_{reg}$  $\\alpha$  $\\alpha$  $\\sigma$ Box std  $\\sigma=\\sqrt{e^{\\alpha}}$ \n\n $|x_g - x_e| > 1$  smooth-L1  $x_g,x_e$ \n$$L_{reg} \\begin {cases} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2 & |x_g - x_e| \\le 1\n\\\\\\\\ = e^{-\\alpha} (|x_g-x_e|-\\frac 1 2 )+\\frac \\alpha 2 & |x_g - x_e| > 1 \\end{cases}$$\n\n bbox  offset  $\\sigma$ $\\sigma$  $\\alpha$$\\alpha$  Gaussian  Gaussian  0.0001 0\n\n## Variance Voting\n $\\sigma^2$  bbox  box IoU>0 box Variance Voting  Fig 2 \n\n__Algorithm 1__ var voting\n*****\n$\\mathcal B$  Nx4  boxes\n\n$\\mathcal S$  N \n\n$\\mathcal C$  Nx4 \n\n$\\mathcal D$ $\\sigma_t$  var voting \n\n$\\mathcal B=\\{b_1,...,b_N\\}, \\ \\mathcal S=\\{s_1,...,s_N\\}, \\ \\mathcal C=\\{\\sigma_1^2,...,\\sigma_N^2\\}$\n\n$\\mathcal D \\leftarrow \\{\\}, \\ \\mathcal T \\leftarrow \\mathcal B$\n\n__while__ $\\mathcal T \\ne \\varnothing$ __do__\n\n- $m \\leftarrow \\arg\\max \\mathcal T$  $\\arg \\max \\mathcal S$\n- $\\mathcal T \\leftarrow \\mathcal T - b_m$\n- <font color='cyan'>$\\mathcal S \\leftarrow \\mathcal S f(IoU(b_m, \\mathcal T)) \\qquad \\qquad \\qquad \\qquad \\ \\ \\triangleright$ soft-NMS </font>\n- <font color='gree'>$idx \\leftarrow IoU(b_m, B) > 0 \\qquad \\qquad \\qquad \\qquad \\triangleright$    var voting </font>\n- <font color='gree'> $p \\leftarrow exp(-(1-IoU(b_m, \\mathcal B[idx]))^2/\\sigma_t)$ </font>\n- <font color='gree'> $b_m \\leftarrow p(\\mathcal B[idx]/\\mathcal C[idx])/p(1 / \\mathcal C[idx])$</font>\n- $\\mathcal D \\leftarrow \\mathcal D \\cup b_m$\n \n__end while__\n\n__return__ $\\mathcal {D, S}$\n***\n\n box  box  box  IoU  boxNMS  box soft-NMS  NMS  box  $f(IoU(b_m,b_i))$  [CV ](/2019/06/24/cv-mtds)\n\n 1  box b $\\{x_1,y_1,x_2,y_2,s,\\sigma_{x1},\\sigma_{y1},\\sigma_{x2},\\sigma_{y2}\\}$ soft-NMS  boxes IoU>0 boxes boxes $\\sigma$  box  box  box box  x  x<sub>1</sub> x<sub>i</sub>  i  box \n$$p_i = e^{-(1-IoU(b_i,b))^2/\\sigma_t}\n\\\\\\\\ x=\\frac {\\sum_i p_i x_i/\\sigma_{x,i}^2} {\\sum_i p_i / \\sigma_{x,i}^2}\n\\\\\\\\ \\text{s.t.  IoU}(b_i, b) >0$$\n box  boxes  box  box  box IoU  p<sub>i</sub>  voting  box  box   $\\sigma^2$  voting  box \n\n# \n\n\n# \n gt box  SOTA  bbox  KL Loss  var voting  box \n\n Faster R-CNN/Mask R-CNN  KL Loss  smooth L1 Loss var voting  1  $\\mathcal B$ Faster R-CNN ","source":"_posts/BBox-Reg-Uncertainty.md","raw":"---\ntitle: BBox-Reg-Uncertainty\ndate: 2019-06-28 09:23:16\ntags: object detection\nmathjax: true\n---\n[Bounding Box Regression with Uncertainty for Accurate Object Detection](https://arxiv.org/abs/1809.08545)\n<!-- more -->\n# \n ImageNetMS-COCO  CrowdHuman  ground truth bounding box gt bbox  bbox  1\n![](/images/BBox-reg_fig1.png) <center>Fig 1 MS-COCO  gt bbox (a)(c) (b) (d) </center>\n\n SOTA  Faster R-CNNCascade R-CNN  Mask R-CNN  bbox  bbox  smooth-L1  gt box  bbox  Inference  2 bbox  __ loss __\n![](/images/BBox-reg_fig2.png) <center>Fig 2 MS-COCO  VGG-16 Faster R-CNN (a) (b)  bbox </center>\n\n bbox  KL loss bbox  __ loss __ gt box  box  gt box  Gaussian  Dirac delta KL loss  gt  KL  KL KL  P(x) Q(x)  KL \n$$D_{KL}(P||Q)=\\sum_{i=1}^N P(x_i) \\log \\frac {P(x_i)} {Q(x_i)}$$\n\n$$D_{KL}(P||Q)=E_P \\left[\\log \\frac {p(x)} {q(x)} \\right]=\\int p(x) \\log \\frac {p(x)} {q(x)} dx$$\n p(x)  q(x) \n P,Q  KL  0\n\n KL loss  bbox \n1.  bbox\n2.  var voting (variance voting) box  box  Fig 2 \n3.  box \n\n\n\n KL loss  var voting PASCAL VOC 2007  MS-COCO  benchmark VGG-CNN-M-1024, VGG-16, ResNet-5-FPN  Mask R-CNN Faster R-CNN\n\n# \n## BBox \n Faster R-CNN  Mask R-CNN  3 bbx  Box  shape  (N, 84) N  proposals  batch size84  21  4  PASCAL VOC  21 Box std  shape  (N, 84) 21  4  $\\sigma$not class-agnostic box \n![](/images/BBox-reg_fig3.png)\n\n $(x_1,y_1,x_2,y_2) \\in \\mathcal R^4$  bbox $\\{t_i| i=x_1,y_1,x_2,y_2\\}$ \n\n$$t_{x_1}=\\frac {x_1-x_{1a}} {w_a}, \\quad t_{x_2}=\\frac {x_2-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}=\\frac {y_1-y_{1a}} {h_a}, \\quad t_{y_2}=\\frac {y_2-y_{2a}} {h_a}\n\\\\\\\\ t_{x_1}^{\\ast}=\\frac {x_1^{\\ast}-x_{1a}} {w_a}, \\quad t_{x_2}^{\\ast}=\\frac {x_2^{\\ast}-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}^{\\ast}=\\frac {y_1^{\\ast}-y_{1a}} {h_a}, \\quad t_{y_2}^{\\ast}=\\frac {y_2^{\\ast}-y_{2a}} {h_a}$$\n\n *  gt offset *  offset$(x_{1a},y_{1a},x_{2a},y_{2a})$  anchor box x x $\\{x_1,y_1,x_2,y_2\\}$\n\n bbox \n$$P_{\\Theta}(x)=\\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}}$$\n $\\Theta$ $x_e$  bbox  $\\sigma$  $\\sigma \\rightarrow 0$ bbox \n\n~~ Faster R-CNN bbox  blob 4   4 $\\Theta$ ~~\n\ngt box  0 $\\sigma \\rightarrow 0$ Dirac delta \n$$P_D(x)=\\delta(x-x_g)$$\n $x_g$  gt box  x \n\n##  KL Loss  BBox \n $P_{\\Theta}(x)$  $P_D(x)$  KL  $\\hat \\Theta$ KL \n$$\\hat \\Theta = \\arg \\min_{\\Theta} \\frac 1 N \\sum D_{KL}(P_D(x)||P_{\\Theta}(x))$$\n N x  4 KL \n$$\\begin{aligned} L_{reg} &=D_{KL}(P_D(x)||P_{\\Theta}(x)) \n\\\\\\\\ &=\\int P_D(x) \\log P_D(x) dx - \\int P_D(x) \\log P_{\\Theta}(x) dx\n\\\\\\\\ &=-H(P_D(x))-\\int P_D(x) \\log \\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}} dx\n\\\\\\\\ &=-H(P_D(x))+ \\log \\sqrt{2\\pi \\sigma^2}\\int P_D(x) dx+\\int P_D(x) \\frac {(x-x_e)^2} {2 \\sigma^2} dx\n\\\\\\\\ &=\\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2 + \\frac {\\log 2\\pi} 2 - H(P_D(x))\n\\end{aligned}$$\n\n$H(P_D(x))$  Dirac delta \n\n 4\n![](/images/BBox-reg_fig4.png)\n\n box  $x_e$  $\\sigma^2$  $L_{reg}$ $H(P_D(x)), \\log (2\\pi)/2$  $\\Theta$ \n$$L_{reg} \\propto \\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2$$\n $\\sigma=1$KL Loss \n$$L_{reg} \\propto \\frac {(x_g-x_e)^2} 2$$\n $x_e$  $\\sigma$ \n$$\\frac d {dx_e}L_{reg}=\\frac {x_e-x_g} {\\sigma^2}\n\\\\\\\\ \\frac d {dx_e}L_{reg}=-\\frac {(x_e-x_g)^2} {\\sigma^3} + \\frac 1 \\sigma$$\n\n $\\sigma$  $\\alpha=\\log \\sigma^2$  $\\sigma$ 3  Box std  $\\alpha$\n$$L_{reg} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2$$\n $L_{reg}$  $\\alpha$  $\\alpha$  $\\sigma$ Box std  $\\sigma=\\sqrt{e^{\\alpha}}$ \n\n $|x_g - x_e| > 1$  smooth-L1  $x_g,x_e$ \n$$L_{reg} \\begin {cases} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2 & |x_g - x_e| \\le 1\n\\\\\\\\ = e^{-\\alpha} (|x_g-x_e|-\\frac 1 2 )+\\frac \\alpha 2 & |x_g - x_e| > 1 \\end{cases}$$\n\n bbox  offset  $\\sigma$ $\\sigma$  $\\alpha$$\\alpha$  Gaussian  Gaussian  0.0001 0\n\n## Variance Voting\n $\\sigma^2$  bbox  box IoU>0 box Variance Voting  Fig 2 \n\n__Algorithm 1__ var voting\n*****\n$\\mathcal B$  Nx4  boxes\n\n$\\mathcal S$  N \n\n$\\mathcal C$  Nx4 \n\n$\\mathcal D$ $\\sigma_t$  var voting \n\n$\\mathcal B=\\{b_1,...,b_N\\}, \\ \\mathcal S=\\{s_1,...,s_N\\}, \\ \\mathcal C=\\{\\sigma_1^2,...,\\sigma_N^2\\}$\n\n$\\mathcal D \\leftarrow \\{\\}, \\ \\mathcal T \\leftarrow \\mathcal B$\n\n__while__ $\\mathcal T \\ne \\varnothing$ __do__\n\n- $m \\leftarrow \\arg\\max \\mathcal T$  $\\arg \\max \\mathcal S$\n- $\\mathcal T \\leftarrow \\mathcal T - b_m$\n- <font color='cyan'>$\\mathcal S \\leftarrow \\mathcal S f(IoU(b_m, \\mathcal T)) \\qquad \\qquad \\qquad \\qquad \\ \\ \\triangleright$ soft-NMS </font>\n- <font color='gree'>$idx \\leftarrow IoU(b_m, B) > 0 \\qquad \\qquad \\qquad \\qquad \\triangleright$    var voting </font>\n- <font color='gree'> $p \\leftarrow exp(-(1-IoU(b_m, \\mathcal B[idx]))^2/\\sigma_t)$ </font>\n- <font color='gree'> $b_m \\leftarrow p(\\mathcal B[idx]/\\mathcal C[idx])/p(1 / \\mathcal C[idx])$</font>\n- $\\mathcal D \\leftarrow \\mathcal D \\cup b_m$\n \n__end while__\n\n__return__ $\\mathcal {D, S}$\n***\n\n box  box  box  IoU  boxNMS  box soft-NMS  NMS  box  $f(IoU(b_m,b_i))$  [CV ](/2019/06/24/cv-mtds)\n\n 1  box b $\\{x_1,y_1,x_2,y_2,s,\\sigma_{x1},\\sigma_{y1},\\sigma_{x2},\\sigma_{y2}\\}$ soft-NMS  boxes IoU>0 boxes boxes $\\sigma$  box  box  box box  x  x<sub>1</sub> x<sub>i</sub>  i  box \n$$p_i = e^{-(1-IoU(b_i,b))^2/\\sigma_t}\n\\\\\\\\ x=\\frac {\\sum_i p_i x_i/\\sigma_{x,i}^2} {\\sum_i p_i / \\sigma_{x,i}^2}\n\\\\\\\\ \\text{s.t.  IoU}(b_i, b) >0$$\n box  boxes  box  box  box IoU  p<sub>i</sub>  voting  box  box   $\\sigma^2$  voting  box \n\n# \n\n\n# \n gt box  SOTA  bbox  KL Loss  var voting  box \n\n Faster R-CNN/Mask R-CNN  KL Loss  smooth L1 Loss var voting  1  $\\mathcal B$ Faster R-CNN ","slug":"BBox-Reg-Uncertainty","published":1,"updated":"2020-04-24T10:35:17.063Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or8zt0001p0dj8eu0876c","content":"<p><a href=\"https://arxiv.org/abs/1809.08545\">Bounding Box Regression with Uncertainty for Accurate Object Detection</a><br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> ImageNetMS-COCO  CrowdHuman  ground truth bounding box gt bbox  bbox  1<br><img src=\"/images/BBox-reg_fig1.png\" alt=\"\"> <center>Fig 1 MS-COCO  gt bbox (a)(c) (b) (d) </center></p>\n<p> SOTA  Faster R-CNNCascade R-CNN  Mask R-CNN  bbox  bbox  smooth-L1  gt box  bbox  Inference  2 bbox  <strong> loss </strong><br><img src=\"/images/BBox-reg_fig2.png\" alt=\"\"> <center>Fig 2 MS-COCO  VGG-16 Faster R-CNN (a) (b)  bbox </center></p>\n<p> bbox  KL loss bbox  <strong> loss </strong> gt box  box  gt box  Gaussian  Dirac delta KL loss  gt  KL  KL KL  P(x) Q(x)  KL </p>\n<script type=\"math/tex; mode=display\">D_{KL}(P||Q)=\\sum_{i=1}^N P(x_i) \\log \\frac {P(x_i)} {Q(x_i)}</script><p></p>\n<script type=\"math/tex; mode=display\">D_{KL}(P||Q)=E_P \\left[\\log \\frac {p(x)} {q(x)} \\right]=\\int p(x) \\log \\frac {p(x)} {q(x)} dx</script><p> p(x)  q(x) <br> P,Q  KL  0</p>\n<p> KL loss  bbox </p>\n<ol>\n<li> bbox</li>\n<li> var voting (variance voting) box  box  Fig 2 </li>\n<li> box </li>\n</ol>\n<p> KL loss  var voting PASCAL VOC 2007  MS-COCO  benchmark VGG-CNN-M-1024, VGG-16, ResNet-5-FPN  Mask R-CNN Faster R-CNN</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"BBox-\"><a href=\"#BBox-\" class=\"headerlink\" title=\"BBox \"></a>BBox </h2><p> Faster R-CNN  Mask R-CNN  3 bbx  Box  shape  (N, 84) N  proposals  batch size84  21  4  PASCAL VOC  21 Box std  shape  (N, 84) 21  4  $\\sigma$not class-agnostic box <br><img src=\"/images/BBox-reg_fig3.png\" alt=\"\"></p>\n<p> $(x_1,y_1,x_2,y_2) \\in \\mathcal R^4$  bbox $\\{t_i| i=x_1,y_1,x_2,y_2\\}$ </p>\n<script type=\"math/tex; mode=display\">t_{x_1}=\\frac {x_1-x_{1a}} {w_a}, \\quad t_{x_2}=\\frac {x_2-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}=\\frac {y_1-y_{1a}} {h_a}, \\quad t_{y_2}=\\frac {y_2-y_{2a}} {h_a}\n\\\\\\\\ t_{x_1}^{\\ast}=\\frac {x_1^{\\ast}-x_{1a}} {w_a}, \\quad t_{x_2}^{\\ast}=\\frac {x_2^{\\ast}-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}^{\\ast}=\\frac {y_1^{\\ast}-y_{1a}} {h_a}, \\quad t_{y_2}^{\\ast}=\\frac {y_2^{\\ast}-y_{2a}} {h_a}</script><p> <em>  gt offset </em>  offset$(x_{1a},y_{1a},x_{2a},y_{2a})$  anchor box x x $\\{x_1,y_1,x_2,y_2\\}$</p>\n<p> bbox </p>\n<script type=\"math/tex; mode=display\">P_{\\Theta}(x)=\\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}}</script><p> $\\Theta$ $x_e$  bbox  $\\sigma$  $\\sigma \\rightarrow 0$ bbox </p>\n<p><del> Faster R-CNN bbox  blob 4   4 $\\Theta$ </del></p>\n<p>gt box  0 $\\sigma \\rightarrow 0$ Dirac delta </p>\n<script type=\"math/tex; mode=display\">P_D(x)=\\delta(x-x_g)</script><p> $x_g$  gt box  x </p>\n<h2 id=\"-KL-Loss--BBox-\"><a href=\"#-KL-Loss--BBox-\" class=\"headerlink\" title=\" KL Loss  BBox \"></a> KL Loss  BBox </h2><p> $P_{\\Theta}(x)$  $P_D(x)$  KL  $\\hat \\Theta$ KL </p>\n<script type=\"math/tex; mode=display\">\\hat \\Theta = \\arg \\min_{\\Theta} \\frac 1 N \\sum D_{KL}(P_D(x)||P_{\\Theta}(x))</script><p> N x  4 KL </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} L_{reg} &=D_{KL}(P_D(x)||P_{\\Theta}(x)) \n\\\\\\\\ &=\\int P_D(x) \\log P_D(x) dx - \\int P_D(x) \\log P_{\\Theta}(x) dx\n\\\\\\\\ &=-H(P_D(x))-\\int P_D(x) \\log \\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}} dx\n\\\\\\\\ &=-H(P_D(x))+ \\log \\sqrt{2\\pi \\sigma^2}\\int P_D(x) dx+\\int P_D(x) \\frac {(x-x_e)^2} {2 \\sigma^2} dx\n\\\\\\\\ &=\\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2 + \\frac {\\log 2\\pi} 2 - H(P_D(x))\n\\end{aligned}</script><p>$H(P_D(x))$  Dirac delta </p>\n<p> 4<br><img src=\"/images/BBox-reg_fig4.png\" alt=\"\"></p>\n<p> box  $x_e$  $\\sigma^2$  $L_{reg}$ $H(P_D(x)), \\log (2\\pi)/2$  $\\Theta$ </p>\n<script type=\"math/tex; mode=display\">L_{reg} \\propto \\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2</script><p> $\\sigma=1$KL Loss </p>\n<script type=\"math/tex; mode=display\">L_{reg} \\propto \\frac {(x_g-x_e)^2} 2</script><p> $x_e$  $\\sigma$ </p>\n<script type=\"math/tex; mode=display\">\\frac d {dx_e}L_{reg}=\\frac {x_e-x_g} {\\sigma^2}\n\\\\\\\\ \\frac d {dx_e}L_{reg}=-\\frac {(x_e-x_g)^2} {\\sigma^3} + \\frac 1 \\sigma</script><p> $\\sigma$  $\\alpha=\\log \\sigma^2$  $\\sigma$ 3  Box std  $\\alpha$</p>\n<script type=\"math/tex; mode=display\">L_{reg} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2</script><p> $L_{reg}$  $\\alpha$  $\\alpha$  $\\sigma$ Box std  $\\sigma=\\sqrt{e^{\\alpha}}$ </p>\n<p> $|x_g - x_e| &gt; 1$  smooth-L1  $x_g,x_e$ </p>\n<script type=\"math/tex; mode=display\">L_{reg} \\begin {cases} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2 & |x_g - x_e| \\le 1\n\\\\\\\\ = e^{-\\alpha} (|x_g-x_e|-\\frac 1 2 )+\\frac \\alpha 2 & |x_g - x_e| > 1 \\end{cases}</script><p> bbox  offset  $\\sigma$ $\\sigma$  $\\alpha$$\\alpha$  Gaussian  Gaussian  0.0001 0</p>\n<h2 id=\"Variance-Voting\"><a href=\"#Variance-Voting\" class=\"headerlink\" title=\"Variance Voting\"></a>Variance Voting</h2><p> $\\sigma^2$  bbox  box IoU&gt;0 box Variance Voting  Fig 2 </p>\n<p><strong>Algorithm 1</strong> var voting</p>\n<hr>\n<p>$\\mathcal B$  Nx4  boxes</p>\n<p>$\\mathcal S$  N </p>\n<p>$\\mathcal C$  Nx4 </p>\n<p>$\\mathcal D$ $\\sigma_t$  var voting </p>\n<p>$\\mathcal B=\\{b_1,,b_N\\}, \\ \\mathcal S=\\{s_1,,s_N\\}, \\ \\mathcal C=\\{\\sigma_1^2,,\\sigma_N^2\\}$</p>\n<p>$\\mathcal D \\leftarrow \\{\\}, \\ \\mathcal T \\leftarrow \\mathcal B$</p>\n<p><strong>while</strong> $\\mathcal T \\ne \\varnothing$ <strong>do</strong></p>\n<ul>\n<li>$m \\leftarrow \\arg\\max \\mathcal T$  $\\arg \\max \\mathcal S$</li>\n<li>$\\mathcal T \\leftarrow \\mathcal T - b_m$</li>\n<li><font color='cyan'>$\\mathcal S \\leftarrow \\mathcal S f(IoU(b_m, \\mathcal T)) \\qquad \\qquad \\qquad \\qquad \\ \\ \\triangleright$ soft-NMS </font></li>\n<li><font color='gree'>$idx \\leftarrow IoU(b_m, B) > 0 \\qquad \\qquad \\qquad \\qquad \\triangleright$    var voting </font></li>\n<li><font color='gree'> $p \\leftarrow exp(-(1-IoU(b_m, \\mathcal B[idx]))^2/\\sigma_t)$ </font></li>\n<li><font color='gree'> $b_m \\leftarrow p(\\mathcal B[idx]/\\mathcal C[idx])/p(1 / \\mathcal C[idx])$</font></li>\n<li>$\\mathcal D \\leftarrow \\mathcal D \\cup b_m$</li>\n</ul>\n<p><strong>end while</strong></p>\n<p><strong>return</strong> $\\mathcal {D, S}$</p>\n<hr>\n<p> box  box  box  IoU  boxNMS  box soft-NMS  NMS  box  $f(IoU(b_m,b_i))$  <a href=\"/2019/06/24/cv-mtds\">CV </a></p>\n<p> 1  box b $\\{x_1,y_1,x_2,y_2,s,\\sigma_{x1},\\sigma_{y1},\\sigma_{x2},\\sigma_{y2}\\}$ soft-NMS  boxes IoU&gt;0 boxes boxes $\\sigma$  box  box  box box  x  x<sub>1</sub> x<sub>i</sub>  i  box </p>\n<script type=\"math/tex; mode=display\">p_i = e^{-(1-IoU(b_i,b))^2/\\sigma_t}\n\\\\\\\\ x=\\frac {\\sum_i p_i x_i/\\sigma_{x,i}^2} {\\sum_i p_i / \\sigma_{x,i}^2}\n\\\\\\\\ \\text{s.t.  IoU}(b_i, b) >0</script><p> box  boxes  box  box  box IoU  p<sub>i</sub>  voting  box  box   $\\sigma^2$  voting  box </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> gt box  SOTA  bbox  KL Loss  var voting  box </p>\n<p> Faster R-CNN/Mask R-CNN  KL Loss  smooth L1 Loss var voting  1  $\\mathcal B$ Faster R-CNN </p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://arxiv.org/abs/1809.08545\">Bounding Box Regression with Uncertainty for Accurate Object Detection</a><br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> ImageNetMS-COCO  CrowdHuman  ground truth bounding box gt bbox  bbox  1<br><img src=\"/images/BBox-reg_fig1.png\" alt=\"\"> <center>Fig 1 MS-COCO  gt bbox (a)(c) (b) (d) </center></p>\n<p> SOTA  Faster R-CNNCascade R-CNN  Mask R-CNN  bbox  bbox  smooth-L1  gt box  bbox  Inference  2 bbox  <strong> loss </strong><br><img src=\"/images/BBox-reg_fig2.png\" alt=\"\"> <center>Fig 2 MS-COCO  VGG-16 Faster R-CNN (a) (b)  bbox </center></p>\n<p> bbox  KL loss bbox  <strong> loss </strong> gt box  box  gt box  Gaussian  Dirac delta KL loss  gt  KL  KL KL  P(x) Q(x)  KL </p>\n<script type=\"math/tex; mode=display\">D_{KL}(P||Q)=\\sum_{i=1}^N P(x_i) \\log \\frac {P(x_i)} {Q(x_i)}</script><p></p>\n<script type=\"math/tex; mode=display\">D_{KL}(P||Q)=E_P \\left[\\log \\frac {p(x)} {q(x)} \\right]=\\int p(x) \\log \\frac {p(x)} {q(x)} dx</script><p> p(x)  q(x) <br> P,Q  KL  0</p>\n<p> KL loss  bbox </p>\n<ol>\n<li> bbox</li>\n<li> var voting (variance voting) box  box  Fig 2 </li>\n<li> box </li>\n</ol>\n<p> KL loss  var voting PASCAL VOC 2007  MS-COCO  benchmark VGG-CNN-M-1024, VGG-16, ResNet-5-FPN  Mask R-CNN Faster R-CNN</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"BBox-\"><a href=\"#BBox-\" class=\"headerlink\" title=\"BBox \"></a>BBox </h2><p> Faster R-CNN  Mask R-CNN  3 bbx  Box  shape  (N, 84) N  proposals  batch size84  21  4  PASCAL VOC  21 Box std  shape  (N, 84) 21  4  $\\sigma$not class-agnostic box <br><img src=\"/images/BBox-reg_fig3.png\" alt=\"\"></p>\n<p> $(x_1,y_1,x_2,y_2) \\in \\mathcal R^4$  bbox $\\{t_i| i=x_1,y_1,x_2,y_2\\}$ </p>\n<script type=\"math/tex; mode=display\">t_{x_1}=\\frac {x_1-x_{1a}} {w_a}, \\quad t_{x_2}=\\frac {x_2-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}=\\frac {y_1-y_{1a}} {h_a}, \\quad t_{y_2}=\\frac {y_2-y_{2a}} {h_a}\n\\\\\\\\ t_{x_1}^{\\ast}=\\frac {x_1^{\\ast}-x_{1a}} {w_a}, \\quad t_{x_2}^{\\ast}=\\frac {x_2^{\\ast}-x_{2a}} {w_a}\n\\\\\\\\ t_{y_1}^{\\ast}=\\frac {y_1^{\\ast}-y_{1a}} {h_a}, \\quad t_{y_2}^{\\ast}=\\frac {y_2^{\\ast}-y_{2a}} {h_a}</script><p> <em>  gt offset </em>  offset$(x_{1a},y_{1a},x_{2a},y_{2a})$  anchor box x x $\\{x_1,y_1,x_2,y_2\\}$</p>\n<p> bbox </p>\n<script type=\"math/tex; mode=display\">P_{\\Theta}(x)=\\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}}</script><p> $\\Theta$ $x_e$  bbox  $\\sigma$  $\\sigma \\rightarrow 0$ bbox </p>\n<p><del> Faster R-CNN bbox  blob 4   4 $\\Theta$ </del></p>\n<p>gt box  0 $\\sigma \\rightarrow 0$ Dirac delta </p>\n<script type=\"math/tex; mode=display\">P_D(x)=\\delta(x-x_g)</script><p> $x_g$  gt box  x </p>\n<h2 id=\"-KL-Loss--BBox-\"><a href=\"#-KL-Loss--BBox-\" class=\"headerlink\" title=\" KL Loss  BBox \"></a> KL Loss  BBox </h2><p> $P_{\\Theta}(x)$  $P_D(x)$  KL  $\\hat \\Theta$ KL </p>\n<script type=\"math/tex; mode=display\">\\hat \\Theta = \\arg \\min_{\\Theta} \\frac 1 N \\sum D_{KL}(P_D(x)||P_{\\Theta}(x))</script><p> N x  4 KL </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} L_{reg} &=D_{KL}(P_D(x)||P_{\\Theta}(x)) \n\\\\\\\\ &=\\int P_D(x) \\log P_D(x) dx - \\int P_D(x) \\log P_{\\Theta}(x) dx\n\\\\\\\\ &=-H(P_D(x))-\\int P_D(x) \\log \\frac 1 {\\sqrt {2 \\pi \\sigma^2}}e^{- \\frac {(x-x_e)^2} {2 \\sigma^2}} dx\n\\\\\\\\ &=-H(P_D(x))+ \\log \\sqrt{2\\pi \\sigma^2}\\int P_D(x) dx+\\int P_D(x) \\frac {(x-x_e)^2} {2 \\sigma^2} dx\n\\\\\\\\ &=\\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2 + \\frac {\\log 2\\pi} 2 - H(P_D(x))\n\\end{aligned}</script><p>$H(P_D(x))$  Dirac delta </p>\n<p> 4<br><img src=\"/images/BBox-reg_fig4.png\" alt=\"\"></p>\n<p> box  $x_e$  $\\sigma^2$  $L_{reg}$ $H(P_D(x)), \\log (2\\pi)/2$  $\\Theta$ </p>\n<script type=\"math/tex; mode=display\">L_{reg} \\propto \\frac {(x_g-x_e)^2}{2\\sigma^2}+\\frac {\\log \\sigma^2} 2</script><p> $\\sigma=1$KL Loss </p>\n<script type=\"math/tex; mode=display\">L_{reg} \\propto \\frac {(x_g-x_e)^2} 2</script><p> $x_e$  $\\sigma$ </p>\n<script type=\"math/tex; mode=display\">\\frac d {dx_e}L_{reg}=\\frac {x_e-x_g} {\\sigma^2}\n\\\\\\\\ \\frac d {dx_e}L_{reg}=-\\frac {(x_e-x_g)^2} {\\sigma^3} + \\frac 1 \\sigma</script><p> $\\sigma$  $\\alpha=\\log \\sigma^2$  $\\sigma$ 3  Box std  $\\alpha$</p>\n<script type=\"math/tex; mode=display\">L_{reg} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2</script><p> $L_{reg}$  $\\alpha$  $\\alpha$  $\\sigma$ Box std  $\\sigma=\\sqrt{e^{\\alpha}}$ </p>\n<p> $|x_g - x_e| &gt; 1$  smooth-L1  $x_g,x_e$ </p>\n<script type=\"math/tex; mode=display\">L_{reg} \\begin {cases} \\propto \\frac {e^{-\\alpha}} 2 (x_g-x_e)^2+\\frac \\alpha 2 & |x_g - x_e| \\le 1\n\\\\\\\\ = e^{-\\alpha} (|x_g-x_e|-\\frac 1 2 )+\\frac \\alpha 2 & |x_g - x_e| > 1 \\end{cases}</script><p> bbox  offset  $\\sigma$ $\\sigma$  $\\alpha$$\\alpha$  Gaussian  Gaussian  0.0001 0</p>\n<h2 id=\"Variance-Voting\"><a href=\"#Variance-Voting\" class=\"headerlink\" title=\"Variance Voting\"></a>Variance Voting</h2><p> $\\sigma^2$  bbox  box IoU&gt;0 box Variance Voting  Fig 2 </p>\n<p><strong>Algorithm 1</strong> var voting</p>\n<hr>\n<p>$\\mathcal B$  Nx4  boxes</p>\n<p>$\\mathcal S$  N </p>\n<p>$\\mathcal C$  Nx4 </p>\n<p>$\\mathcal D$ $\\sigma_t$  var voting </p>\n<p>$\\mathcal B=\\{b_1,,b_N\\}, \\ \\mathcal S=\\{s_1,,s_N\\}, \\ \\mathcal C=\\{\\sigma_1^2,,\\sigma_N^2\\}$</p>\n<p>$\\mathcal D \\leftarrow \\{\\}, \\ \\mathcal T \\leftarrow \\mathcal B$</p>\n<p><strong>while</strong> $\\mathcal T \\ne \\varnothing$ <strong>do</strong></p>\n<ul>\n<li>$m \\leftarrow \\arg\\max \\mathcal T$  $\\arg \\max \\mathcal S$</li>\n<li>$\\mathcal T \\leftarrow \\mathcal T - b_m$</li>\n<li><font color='cyan'>$\\mathcal S \\leftarrow \\mathcal S f(IoU(b_m, \\mathcal T)) \\qquad \\qquad \\qquad \\qquad \\ \\ \\triangleright$ soft-NMS </font></li>\n<li><font color='gree'>$idx \\leftarrow IoU(b_m, B) > 0 \\qquad \\qquad \\qquad \\qquad \\triangleright$    var voting </font></li>\n<li><font color='gree'> $p \\leftarrow exp(-(1-IoU(b_m, \\mathcal B[idx]))^2/\\sigma_t)$ </font></li>\n<li><font color='gree'> $b_m \\leftarrow p(\\mathcal B[idx]/\\mathcal C[idx])/p(1 / \\mathcal C[idx])$</font></li>\n<li>$\\mathcal D \\leftarrow \\mathcal D \\cup b_m$</li>\n</ul>\n<p><strong>end while</strong></p>\n<p><strong>return</strong> $\\mathcal {D, S}$</p>\n<hr>\n<p> box  box  box  IoU  boxNMS  box soft-NMS  NMS  box  $f(IoU(b_m,b_i))$  <a href=\"/2019/06/24/cv-mtds\">CV </a></p>\n<p> 1  box b $\\{x_1,y_1,x_2,y_2,s,\\sigma_{x1},\\sigma_{y1},\\sigma_{x2},\\sigma_{y2}\\}$ soft-NMS  boxes IoU&gt;0 boxes boxes $\\sigma$  box  box  box box  x  x<sub>1</sub> x<sub>i</sub>  i  box </p>\n<script type=\"math/tex; mode=display\">p_i = e^{-(1-IoU(b_i,b))^2/\\sigma_t}\n\\\\\\\\ x=\\frac {\\sum_i p_i x_i/\\sigma_{x,i}^2} {\\sum_i p_i / \\sigma_{x,i}^2}\n\\\\\\\\ \\text{s.t.  IoU}(b_i, b) >0</script><p> box  boxes  box  box  box IoU  p<sub>i</sub>  voting  box  box   $\\sigma^2$  voting  box </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> gt box  SOTA  bbox  KL Loss  var voting  box </p>\n<p> Faster R-CNN/Mask R-CNN  KL Loss  smooth L1 Loss var voting  1  $\\mathcal B$ Faster R-CNN </p>"},{"title":"CGAN/DCGAN","date":"2019-07-29T09:00:43.000Z","mathjax":true,"_content":"# CGAN\n [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)\n<!-- more -->\n [GAN](2019/07/23/GAN)  GAN  G  D  G  mnist  G G  1GAN GAN  G  CGAN \n\n## Conditional Adversarial Nets\nGAN  G  D  y  CGAN y  mnist  y\n\n z   y  G  GAN  x  y  D G  D  GAN  fc  conv/deconv\n\n\n$$\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)} [\\log D(x|y)] + \\Bbb E_{z \\sim p_z(z)}[1-\\log (1-D(G(z|y)))]$$\n\n 1  CGAN \n![](/images/CGAN_fig1.png)\n\n\n```python\nimport tensorflow as tf\ny_dim=10    # one-hot vector for mnist-label\nz_dim=100   # length of noise input vector\ny=tf.placeholder(tf.float32, shape=[None,y_dim], name='label')\nx=tf.placeholder(tf.float32, shape=[None,28,28,1], name='real_img')\nz=tf.placeholder(tf.float32, shape=[None,z_dim], name='noise')\n\n# G  noise  label  vector  100  110\nx_for_g=tf.concat([z,y], axis=1)    # [batch_size, 100+10]\n#  GAN  G \n\n# D  real_img  label \nnew_y=tf.reshape(y,[batch_size,1,1,y_dim])\nnew_y=new_y*tf.ones([batch_size,28,28,y_dim])   # [batch_size,28,28,10]\nx_for_d=tf.concat([x,new_y],axis=-1)    # [batch_size,28,28,1+10]\n#  GAN  D \n```\n\n## \n### Unimodal\n mnist  y  10  one-hot CGAN  2 \n![](/images/CGAN_fig2.png)\n\n### Multimodal\n Flickr  UGMuser-generated metadataUGM word embedding\n\n CGAN  tag-vectors  AlexNet  ImageNet  fc  4096  YFCC100M  metadata  user-tagstitle  descriptions  skip-gram  200  200  247465 G  tag  y  4096 \n\n MIR Flickr 25000 AlexNetskip-gram tag  15000  tag  tag tag \n\nevaluation  100 tag  20  100  2000  top 10  tags\n\n# DCGAN\n [Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n\nBN  ReLU  GAN  github  [DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)","source":"_posts/CGAN.md","raw":"---\ntitle: CGAN/DCGAN\ndate: 2019-07-29 17:00:43\ntags: GAN\nmathjax: true\n---\n# CGAN\n [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)\n<!-- more -->\n [GAN](2019/07/23/GAN)  GAN  G  D  G  mnist  G G  1GAN GAN  G  CGAN \n\n## Conditional Adversarial Nets\nGAN  G  D  y  CGAN y  mnist  y\n\n z   y  G  GAN  x  y  D G  D  GAN  fc  conv/deconv\n\n\n$$\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)} [\\log D(x|y)] + \\Bbb E_{z \\sim p_z(z)}[1-\\log (1-D(G(z|y)))]$$\n\n 1  CGAN \n![](/images/CGAN_fig1.png)\n\n\n```python\nimport tensorflow as tf\ny_dim=10    # one-hot vector for mnist-label\nz_dim=100   # length of noise input vector\ny=tf.placeholder(tf.float32, shape=[None,y_dim], name='label')\nx=tf.placeholder(tf.float32, shape=[None,28,28,1], name='real_img')\nz=tf.placeholder(tf.float32, shape=[None,z_dim], name='noise')\n\n# G  noise  label  vector  100  110\nx_for_g=tf.concat([z,y], axis=1)    # [batch_size, 100+10]\n#  GAN  G \n\n# D  real_img  label \nnew_y=tf.reshape(y,[batch_size,1,1,y_dim])\nnew_y=new_y*tf.ones([batch_size,28,28,y_dim])   # [batch_size,28,28,10]\nx_for_d=tf.concat([x,new_y],axis=-1)    # [batch_size,28,28,1+10]\n#  GAN  D \n```\n\n## \n### Unimodal\n mnist  y  10  one-hot CGAN  2 \n![](/images/CGAN_fig2.png)\n\n### Multimodal\n Flickr  UGMuser-generated metadataUGM word embedding\n\n CGAN  tag-vectors  AlexNet  ImageNet  fc  4096  YFCC100M  metadata  user-tagstitle  descriptions  skip-gram  200  200  247465 G  tag  y  4096 \n\n MIR Flickr 25000 AlexNetskip-gram tag  15000  tag  tag tag \n\nevaluation  100 tag  20  100  2000  top 10  tags\n\n# DCGAN\n [Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n\nBN  ReLU  GAN  github  [DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)","slug":"CGAN","published":1,"updated":"2020-04-24T10:35:47.246Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or8zy0003p0dj7os1hhn1","content":"<h1 id=\"CGAN\"><a href=\"#CGAN\" class=\"headerlink\" title=\"CGAN\"></a>CGAN</h1><p> <a href=\"https://arxiv.org/abs/1411.1784\">Conditional Generative Adversarial Nets</a><br><span id=\"more\"></span><br> <a href=\"2019/07/23/GAN\">GAN</a>  GAN  G  D  G  mnist  G G  1GAN GAN  G  CGAN </p>\n<h2 id=\"Conditional-Adversarial-Nets\"><a href=\"#Conditional-Adversarial-Nets\" class=\"headerlink\" title=\"Conditional Adversarial Nets\"></a>Conditional Adversarial Nets</h2><p>GAN  G  D  y  CGAN y  mnist  y</p>\n<p> z   y  G  GAN  x  y  D G  D  GAN  fc  conv/deconv</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)} [\\log D(x|y)] + \\Bbb E_{z \\sim p_z(z)}[1-\\log (1-D(G(z|y)))]</script><p> 1  CGAN <br><img src=\"/images/CGAN_fig1.png\" alt=\"\"></p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\">y_dim=<span class=\"number\">10</span>    <span class=\"comment\"># one-hot vector for mnist-label</span></span><br><span class=\"line\">z_dim=<span class=\"number\">100</span>   <span class=\"comment\"># length of noise input vector</span></span><br><span class=\"line\">y=tf.placeholder(tf.float32, shape=[<span class=\"literal\">None</span>,y_dim], name=<span class=\"string\">&#x27;label&#x27;</span>)</span><br><span class=\"line\">x=tf.placeholder(tf.float32, shape=[<span class=\"literal\">None</span>,<span class=\"number\">28</span>,<span class=\"number\">28</span>,<span class=\"number\">1</span>], name=<span class=\"string\">&#x27;real_img&#x27;</span>)</span><br><span class=\"line\">z=tf.placeholder(tf.float32, shape=[<span class=\"literal\">None</span>,z_dim], name=<span class=\"string\">&#x27;noise&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># G  noise  label  vector  100  110</span></span><br><span class=\"line\">x_for_g=tf.concat([z,y], axis=<span class=\"number\">1</span>)    <span class=\"comment\"># [batch_size, 100+10]</span></span><br><span class=\"line\"><span class=\"comment\">#  GAN  G </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># D  real_img  label </span></span><br><span class=\"line\">new_y=tf.reshape(y,[batch_size,<span class=\"number\">1</span>,<span class=\"number\">1</span>,y_dim])</span><br><span class=\"line\">new_y=new_y*tf.ones([batch_size,<span class=\"number\">28</span>,<span class=\"number\">28</span>,y_dim])   <span class=\"comment\"># [batch_size,28,28,10]</span></span><br><span class=\"line\">x_for_d=tf.concat([x,new_y],axis=-<span class=\"number\">1</span>)    <span class=\"comment\"># [batch_size,28,28,1+10]</span></span><br><span class=\"line\"><span class=\"comment\">#  GAN  D </span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Unimodal\"><a href=\"#Unimodal\" class=\"headerlink\" title=\"Unimodal\"></a>Unimodal</h3><p> mnist  y  10  one-hot CGAN  2 <br><img src=\"/images/CGAN_fig2.png\" alt=\"\"></p>\n<h3 id=\"Multimodal\"><a href=\"#Multimodal\" class=\"headerlink\" title=\"Multimodal\"></a>Multimodal</h3><p> Flickr  UGMuser-generated metadataUGM word embedding</p>\n<p> CGAN  tag-vectors  AlexNet  ImageNet  fc  4096  YFCC100M  metadata  user-tagstitle  descriptions  skip-gram  200  200  247465 G  tag  y  4096 </p>\n<p> MIR Flickr 25000 AlexNetskip-gram tag  15000  tag  tag tag </p>\n<p>evaluation  100 tag  20  100  2000  top 10  tags</p>\n<h1 id=\"DCGAN\"><a href=\"#DCGAN\" class=\"headerlink\" title=\"DCGAN\"></a>DCGAN</h1><p> <a href=\"https://arxiv.org/abs/1511.06434\">Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks</a></p>\n<p>BN  ReLU  GAN  github  <a href=\"https://github.com/carpedm20/DCGAN-tensorflow\">DCGAN-tensorflow</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"CGAN\"><a href=\"#CGAN\" class=\"headerlink\" title=\"CGAN\"></a>CGAN</h1><p> <a href=\"https://arxiv.org/abs/1411.1784\">Conditional Generative Adversarial Nets</a><br>","more":"<br> <a href=\"2019/07/23/GAN\">GAN</a>  GAN  G  D  G  mnist  G G  1GAN GAN  G  CGAN </p>\n<h2 id=\"Conditional-Adversarial-Nets\"><a href=\"#Conditional-Adversarial-Nets\" class=\"headerlink\" title=\"Conditional Adversarial Nets\"></a>Conditional Adversarial Nets</h2><p>GAN  G  D  y  CGAN y  mnist  y</p>\n<p> z   y  G  GAN  x  y  D G  D  GAN  fc  conv/deconv</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)} [\\log D(x|y)] + \\Bbb E_{z \\sim p_z(z)}[1-\\log (1-D(G(z|y)))]</script><p> 1  CGAN <br><img src=\"/images/CGAN_fig1.png\" alt=\"\"></p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\">y_dim=<span class=\"number\">10</span>    <span class=\"comment\"># one-hot vector for mnist-label</span></span><br><span class=\"line\">z_dim=<span class=\"number\">100</span>   <span class=\"comment\"># length of noise input vector</span></span><br><span class=\"line\">y=tf.placeholder(tf.float32, shape=[<span class=\"literal\">None</span>,y_dim], name=<span class=\"string\">&#x27;label&#x27;</span>)</span><br><span class=\"line\">x=tf.placeholder(tf.float32, shape=[<span class=\"literal\">None</span>,<span class=\"number\">28</span>,<span class=\"number\">28</span>,<span class=\"number\">1</span>], name=<span class=\"string\">&#x27;real_img&#x27;</span>)</span><br><span class=\"line\">z=tf.placeholder(tf.float32, shape=[<span class=\"literal\">None</span>,z_dim], name=<span class=\"string\">&#x27;noise&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># G  noise  label  vector  100  110</span></span><br><span class=\"line\">x_for_g=tf.concat([z,y], axis=<span class=\"number\">1</span>)    <span class=\"comment\"># [batch_size, 100+10]</span></span><br><span class=\"line\"><span class=\"comment\">#  GAN  G </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># D  real_img  label </span></span><br><span class=\"line\">new_y=tf.reshape(y,[batch_size,<span class=\"number\">1</span>,<span class=\"number\">1</span>,y_dim])</span><br><span class=\"line\">new_y=new_y*tf.ones([batch_size,<span class=\"number\">28</span>,<span class=\"number\">28</span>,y_dim])   <span class=\"comment\"># [batch_size,28,28,10]</span></span><br><span class=\"line\">x_for_d=tf.concat([x,new_y],axis=-<span class=\"number\">1</span>)    <span class=\"comment\"># [batch_size,28,28,1+10]</span></span><br><span class=\"line\"><span class=\"comment\">#  GAN  D </span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Unimodal\"><a href=\"#Unimodal\" class=\"headerlink\" title=\"Unimodal\"></a>Unimodal</h3><p> mnist  y  10  one-hot CGAN  2 <br><img src=\"/images/CGAN_fig2.png\" alt=\"\"></p>\n<h3 id=\"Multimodal\"><a href=\"#Multimodal\" class=\"headerlink\" title=\"Multimodal\"></a>Multimodal</h3><p> Flickr  UGMuser-generated metadataUGM word embedding</p>\n<p> CGAN  tag-vectors  AlexNet  ImageNet  fc  4096  YFCC100M  metadata  user-tagstitle  descriptions  skip-gram  200  200  247465 G  tag  y  4096 </p>\n<p> MIR Flickr 25000 AlexNetskip-gram tag  15000  tag  tag tag </p>\n<p>evaluation  100 tag  20  100  2000  top 10  tags</p>\n<h1 id=\"DCGAN\"><a href=\"#DCGAN\" class=\"headerlink\" title=\"DCGAN\"></a>DCGAN</h1><p> <a href=\"https://arxiv.org/abs/1511.06434\">Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks</a></p>\n<p>BN  ReLU  GAN  github  <a href=\"https://github.com/carpedm20/DCGAN-tensorflow\">DCGAN-tensorflow</a></p>"},{"title":"","date":"2019-12-05T03:37:39.000Z","mathjax":true,"_content":"\n> (Gonzalez)\n# 1. \n## 1.1 \n\n1. \n2. \n<!-- more -->   \n\n$$(x,y)=\\mathbf T[(v,w)]$$\n $(v,w)$ $(x,y)$ \n$$\\begin{bmatrix}x & y & 1 \\end{bmatrix}=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\mathbf T=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\begin{bmatrix}t_{11} & t_{12} & 0 \\\\ t_{21} & t_{22} & 0 \\\\ t_{31} & t_{32} & 1\\end{bmatrix}$$\n\n$$\\begin{cases}x=t_{11} v + t_{21} w + t_{31} \\\\\ny=t_{12} v + t_{22} w + t_{32} \\end{cases} \\qquad(1)$$\n\n\n$$(v,w)=\\mathbf T^{-1} [(x,y)]$$\n\n### 1.1.1 \n$$\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ 0&0&1\\end{bmatrix}$$\n### 1.1.2 \n$$\\mathbf T = \\begin{bmatrix} c_x & 0 & 0 \\\\ 0& c_y&0 \\\\ 0&0&1\\end{bmatrix}$$\nx  $c_x$ y  $c_y$ \n### 1.1.3 \n$$\\mathbf T = \\begin{bmatrix} cos \\theta & sin \\theta & 0 \\\\ -sin \\theta& cos \\theta&0 \\\\ 0&0&1\\end{bmatrix}$$\n $\\theta$ \n### 1.1.4 \n$$\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ t_x&t_y&1\\end{bmatrix}$$\n### 1.1.5 \nshear\n$$(v,w) \\rightarrow (v+mw,w)$$\n$m>0$ $m<0$ \n\n$$(v,w) \\rightarrow (v, vn+w)$$\n\n$$\\mathbf T=\\begin{bmatrix} 1 & n & 0 \\\\ m & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}$$\n\n## 1.2 \n $(x,y)$  $(x,y,z)$ $(x',y')$ \n\n $(x,y,1)$ $(x,y,1)$  $3 \\times 3$  $(x',y',1)$ $(x',y',1)$\n$$[x,y,1]=[v,w,1]T=[v,w,1]\\begin{bmatrix} t_{11} & t_{12} & t_{13} \\\\t_{21} & t_{22} & t_{23} \\\\t_{31} & t_{32} & t_{33} \\end{bmatrix}$$\n $t_{13}v+t_{23}w+t_{33}=1$\n\n 4  4  8  9  9  opencv  python [](https://docs.opencv.org/4.1.2/da/d6e/tutorial_py_geometric_transformations.html)\n\n\n# 2. \n n  3 66 $(1)$ \n$$x=c_1v+ c_2w+c_3vw + c_4 \\\\ y=c_5v+c_6w+c_7vw+c_8$$\n 4 \n\n\n\n# 3. \n $(x,y)$  $(i+u,j+v)$+$0\\le u,v < 1$\n## 3.1 \n $u,v$  $(\\lfloor i+u+\\frac 1 2\\rfloor,\\lfloor j+v+\\frac 1 2 \\rfloor)$\n## 3.2 \n 4  $(i,j), (i+1,j),(i,j+1),(i+1,j+1)$ \n$$f(i+u,j+v)=(1-u)(1-v)f(i,j)+(1-u)v f(i,j+1)+u(1-v)f(i+1,j)+uvf(i+1,j+1)$$\n\n## 3.2 \n 16  BiCubic \n$$W(x)=\\begin{cases} (a+2)|x|^3 - (a+3)|x|^2+1 & |x| \\le 1 \\\\ a|x|^3-5a|x|^2+8a|x|-4a & 1 <|x|<2 \\\\ 0 & \\text{otherwise} \\end{cases}$$\n $x$ a  $a=-0.5$\n\n $(x,y)$  $(i,j)$  $(x,y)$  $4\\times4$  $(x_i,y_j), \\ i,j=0,1,2,3$\n$$f(x,y)=\\sum_{i=0}^3\\sum_{j=0}^3 f(x_i,y_j) W(x-x_i) W(y-y_j)$$\n\n# 4. \n\n## 4.1 \n $[0,L-1]$\n$$s=T(r)$$\n `r`  `s`\n\n\n `r` `s`  $p_r(r), \\ p_s(s)$  `r`  `s` \n$$p_s(s)=p_r(r) \\frac {dr} {ds} \\qquad(2)$$\n\n $T(r)=s, \\ r_1 \\le r \\le r_2$ $r_1<r_2$ $r_1=r_2$\n\n\n$$s=T(r)=(L-1)\\int_0^r p_r(w) dw \\qquad(3)$$\n  $(L-1)$ \n\n (3) \n$$\\frac {ds} {dr} = \\frac {dT(r)} {dr} = (L-1) \\frac d {dr} \\left[\\int_0^r p_r(w)dw \\right] = (L-1)p_r(r) \\qquad(4)$$\n\n (4)  (2) \n$$p_s(s)=p_r(r) \\frac {dr} {ds} = \\frac 1 {L-1} \\qquad(5)$$\n\n  `s` \n\n\n$$s=T(r)=(L-1) \\sum_{0}^r p_r(r) \\qquad(3')$$\n $p_r(r)=n_r/N$$n_r$  `r` `N` \n \n$$1=s - (s-1) = (L-1)\\sum_0^{r_2}p_r(r) - (L-1)\\sum_0^{r_1}p_r(r)=(L-1)\\sum_{r_1}^{r_2}p_r(r)$$\n\n$$p_s(s) = \\sum_{r_1}^{r_2}p_r(r)=\\frac 1 {L-1}$$\n $r$  $r_1$ $1/(L-1)$\n\n## 4.2 \n `r`   `z` `s` \n$$s=T(r)=(L-1)\\int_0^r p_r(r) dw \\qquad(6)\n\\\\\\\\ s=G(z)=(L-1)\\int_0^z p_z(t) dt \\qquad(7)$$\n\n\n$$z=G^{-1}(s)$$\n $G$ \n\n $p_r(r)$ $p_z(z)$  (7)  $G$ z  s \n1.  $p_r(r)$ `s`\n2.  (7)  $G(z)$\n3.  $G^{-1}(s)$ `s`  `z`\n\n `s`  $z=G^{-1}(s)$s  z \n\n## 4.3 \n\n\n## 4.4 \n `r`  $p(r)$`r`  n \n$$\\mu_n(r)=\\sum_{i=0}^{L-1} (r_i-m)^n p(r_i)$$\n `m` $m=\\sum_0^{L-1} r_i p(r_i)$\n\n\n$$u_2(r)=\\sum_{i=0}^{L-1}(r_i-m)^2 p(r_i)$$\n $\\sigma^2$ \n\n\n$$m=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} f(x,y)\n\\\\\\\\ \\sigma^2=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} [f(x,y)-m]^2$$\n $MN-1$  $MN$ \n\n $(x,y)$  $S_{xy}$\n$$m_{s_{xy}}=\\sum_{i=0}^{L-1}r_i p_{s_{xy}} (r_i)\n\\\\\\\\ \\sigma_{s_{xy}}^2 = \\sum _{i=0}^{L-1} (r_i - m_{S_{xy}})^2 p_{s_{xy}}(r_i)$$\n\n $m_G$ $m_{s_{xy}} \\le k_0 m_G$ $0< k_0 < 1.0$\n\n $\\sigma_{s_{xy}} \\le k_2 \\sigma_G$ 0  $k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G$ `E` \n\n\n$$g(x,y)=\\begin{cases} E \\cdot f(x,y) & m_{s_{xy}} \\le k_0 m_G, \\ k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G \n\\\\\\\\ f(x,y) & \\text{otherwise} \\end{cases}$$","source":"_posts/DIP-1.md","raw":"---\ntitle: \ndate: 2019-12-05 11:37:39\ntags: DIP\nmathjax: true\n---\n\n> (Gonzalez)\n# 1. \n## 1.1 \n\n1. \n2. \n<!-- more -->   \n\n$$(x,y)=\\mathbf T[(v,w)]$$\n $(v,w)$ $(x,y)$ \n$$\\begin{bmatrix}x & y & 1 \\end{bmatrix}=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\mathbf T=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\begin{bmatrix}t_{11} & t_{12} & 0 \\\\ t_{21} & t_{22} & 0 \\\\ t_{31} & t_{32} & 1\\end{bmatrix}$$\n\n$$\\begin{cases}x=t_{11} v + t_{21} w + t_{31} \\\\\ny=t_{12} v + t_{22} w + t_{32} \\end{cases} \\qquad(1)$$\n\n\n$$(v,w)=\\mathbf T^{-1} [(x,y)]$$\n\n### 1.1.1 \n$$\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ 0&0&1\\end{bmatrix}$$\n### 1.1.2 \n$$\\mathbf T = \\begin{bmatrix} c_x & 0 & 0 \\\\ 0& c_y&0 \\\\ 0&0&1\\end{bmatrix}$$\nx  $c_x$ y  $c_y$ \n### 1.1.3 \n$$\\mathbf T = \\begin{bmatrix} cos \\theta & sin \\theta & 0 \\\\ -sin \\theta& cos \\theta&0 \\\\ 0&0&1\\end{bmatrix}$$\n $\\theta$ \n### 1.1.4 \n$$\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ t_x&t_y&1\\end{bmatrix}$$\n### 1.1.5 \nshear\n$$(v,w) \\rightarrow (v+mw,w)$$\n$m>0$ $m<0$ \n\n$$(v,w) \\rightarrow (v, vn+w)$$\n\n$$\\mathbf T=\\begin{bmatrix} 1 & n & 0 \\\\ m & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}$$\n\n## 1.2 \n $(x,y)$  $(x,y,z)$ $(x',y')$ \n\n $(x,y,1)$ $(x,y,1)$  $3 \\times 3$  $(x',y',1)$ $(x',y',1)$\n$$[x,y,1]=[v,w,1]T=[v,w,1]\\begin{bmatrix} t_{11} & t_{12} & t_{13} \\\\t_{21} & t_{22} & t_{23} \\\\t_{31} & t_{32} & t_{33} \\end{bmatrix}$$\n $t_{13}v+t_{23}w+t_{33}=1$\n\n 4  4  8  9  9  opencv  python [](https://docs.opencv.org/4.1.2/da/d6e/tutorial_py_geometric_transformations.html)\n\n\n# 2. \n n  3 66 $(1)$ \n$$x=c_1v+ c_2w+c_3vw + c_4 \\\\ y=c_5v+c_6w+c_7vw+c_8$$\n 4 \n\n\n\n# 3. \n $(x,y)$  $(i+u,j+v)$+$0\\le u,v < 1$\n## 3.1 \n $u,v$  $(\\lfloor i+u+\\frac 1 2\\rfloor,\\lfloor j+v+\\frac 1 2 \\rfloor)$\n## 3.2 \n 4  $(i,j), (i+1,j),(i,j+1),(i+1,j+1)$ \n$$f(i+u,j+v)=(1-u)(1-v)f(i,j)+(1-u)v f(i,j+1)+u(1-v)f(i+1,j)+uvf(i+1,j+1)$$\n\n## 3.2 \n 16  BiCubic \n$$W(x)=\\begin{cases} (a+2)|x|^3 - (a+3)|x|^2+1 & |x| \\le 1 \\\\ a|x|^3-5a|x|^2+8a|x|-4a & 1 <|x|<2 \\\\ 0 & \\text{otherwise} \\end{cases}$$\n $x$ a  $a=-0.5$\n\n $(x,y)$  $(i,j)$  $(x,y)$  $4\\times4$  $(x_i,y_j), \\ i,j=0,1,2,3$\n$$f(x,y)=\\sum_{i=0}^3\\sum_{j=0}^3 f(x_i,y_j) W(x-x_i) W(y-y_j)$$\n\n# 4. \n\n## 4.1 \n $[0,L-1]$\n$$s=T(r)$$\n `r`  `s`\n\n\n `r` `s`  $p_r(r), \\ p_s(s)$  `r`  `s` \n$$p_s(s)=p_r(r) \\frac {dr} {ds} \\qquad(2)$$\n\n $T(r)=s, \\ r_1 \\le r \\le r_2$ $r_1<r_2$ $r_1=r_2$\n\n\n$$s=T(r)=(L-1)\\int_0^r p_r(w) dw \\qquad(3)$$\n  $(L-1)$ \n\n (3) \n$$\\frac {ds} {dr} = \\frac {dT(r)} {dr} = (L-1) \\frac d {dr} \\left[\\int_0^r p_r(w)dw \\right] = (L-1)p_r(r) \\qquad(4)$$\n\n (4)  (2) \n$$p_s(s)=p_r(r) \\frac {dr} {ds} = \\frac 1 {L-1} \\qquad(5)$$\n\n  `s` \n\n\n$$s=T(r)=(L-1) \\sum_{0}^r p_r(r) \\qquad(3')$$\n $p_r(r)=n_r/N$$n_r$  `r` `N` \n \n$$1=s - (s-1) = (L-1)\\sum_0^{r_2}p_r(r) - (L-1)\\sum_0^{r_1}p_r(r)=(L-1)\\sum_{r_1}^{r_2}p_r(r)$$\n\n$$p_s(s) = \\sum_{r_1}^{r_2}p_r(r)=\\frac 1 {L-1}$$\n $r$  $r_1$ $1/(L-1)$\n\n## 4.2 \n `r`   `z` `s` \n$$s=T(r)=(L-1)\\int_0^r p_r(r) dw \\qquad(6)\n\\\\\\\\ s=G(z)=(L-1)\\int_0^z p_z(t) dt \\qquad(7)$$\n\n\n$$z=G^{-1}(s)$$\n $G$ \n\n $p_r(r)$ $p_z(z)$  (7)  $G$ z  s \n1.  $p_r(r)$ `s`\n2.  (7)  $G(z)$\n3.  $G^{-1}(s)$ `s`  `z`\n\n `s`  $z=G^{-1}(s)$s  z \n\n## 4.3 \n\n\n## 4.4 \n `r`  $p(r)$`r`  n \n$$\\mu_n(r)=\\sum_{i=0}^{L-1} (r_i-m)^n p(r_i)$$\n `m` $m=\\sum_0^{L-1} r_i p(r_i)$\n\n\n$$u_2(r)=\\sum_{i=0}^{L-1}(r_i-m)^2 p(r_i)$$\n $\\sigma^2$ \n\n\n$$m=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} f(x,y)\n\\\\\\\\ \\sigma^2=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} [f(x,y)-m]^2$$\n $MN-1$  $MN$ \n\n $(x,y)$  $S_{xy}$\n$$m_{s_{xy}}=\\sum_{i=0}^{L-1}r_i p_{s_{xy}} (r_i)\n\\\\\\\\ \\sigma_{s_{xy}}^2 = \\sum _{i=0}^{L-1} (r_i - m_{S_{xy}})^2 p_{s_{xy}}(r_i)$$\n\n $m_G$ $m_{s_{xy}} \\le k_0 m_G$ $0< k_0 < 1.0$\n\n $\\sigma_{s_{xy}} \\le k_2 \\sigma_G$ 0  $k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G$ `E` \n\n\n$$g(x,y)=\\begin{cases} E \\cdot f(x,y) & m_{s_{xy}} \\le k_0 m_G, \\ k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G \n\\\\\\\\ f(x,y) & \\text{otherwise} \\end{cases}$$","slug":"DIP-1","published":1,"updated":"2020-04-24T10:36:56.327Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or9020006p0dje1967ydw","content":"<blockquote>\n<p>(Gonzalez)</p>\n<h1 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h1><h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p></p>\n<ol>\n<li></li>\n<li><span id=\"more\"></span>   \n<script type=\"math/tex; mode=display\">(x,y)=\\mathbf T[(v,w)]</script> $(v,w)$ $(x,y)$ <script type=\"math/tex; mode=display\">\\begin{bmatrix}x & y & 1 \\end{bmatrix}=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\mathbf T=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\begin{bmatrix}t_{11} & t_{12} & 0 \\\\ t_{21} & t_{22} & 0 \\\\ t_{31} & t_{32} & 1\\end{bmatrix}</script></li>\n</ol>\n</blockquote>\n<script type=\"math/tex; mode=display\">\\begin{cases}x=t_{11} v + t_{21} w + t_{31} \\\\\ny=t_{12} v + t_{22} w + t_{32} \\end{cases} \\qquad(1)</script><p></p>\n<script type=\"math/tex; mode=display\">(v,w)=\\mathbf T^{-1} [(x,y)]</script><h3 id=\"1-1-1-\"><a href=\"#1-1-1-\" class=\"headerlink\" title=\"1.1.1 \"></a>1.1.1 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ 0&0&1\\end{bmatrix}</script><h3 id=\"1-1-2-\"><a href=\"#1-1-2-\" class=\"headerlink\" title=\"1.1.2 \"></a>1.1.2 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} c_x & 0 & 0 \\\\ 0& c_y&0 \\\\ 0&0&1\\end{bmatrix}</script><p>x  $c_x$ y  $c_y$ </p>\n<h3 id=\"1-1-3-\"><a href=\"#1-1-3-\" class=\"headerlink\" title=\"1.1.3 \"></a>1.1.3 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} cos \\theta & sin \\theta & 0 \\\\ -sin \\theta& cos \\theta&0 \\\\ 0&0&1\\end{bmatrix}</script><p> $\\theta$ </p>\n<h3 id=\"1-1-4-\"><a href=\"#1-1-4-\" class=\"headerlink\" title=\"1.1.4 \"></a>1.1.4 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ t_x&t_y&1\\end{bmatrix}</script><h3 id=\"1-1-5-\"><a href=\"#1-1-5-\" class=\"headerlink\" title=\"1.1.5 \"></a>1.1.5 </h3><p>shear</p>\n<script type=\"math/tex; mode=display\">(v,w) \\rightarrow (v+mw,w)</script><p>$m&gt;0$ $m&lt;0$ <br></p>\n<script type=\"math/tex; mode=display\">(v,w) \\rightarrow (v, vn+w)</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf T=\\begin{bmatrix} 1 & n & 0 \\\\ m & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}</script><h2 id=\"1-2-\"><a href=\"#1-2-\" class=\"headerlink\" title=\"1.2 \"></a>1.2 </h2><p> $(x,y)$  $(x,y,z)$ $(x,y)$ </p>\n<p> $(x,y,1)$ $(x,y,1)$  $3 \\times 3$  $(x,y,1)$ $(x,y,1)$</p>\n<script type=\"math/tex; mode=display\">[x,y,1]=[v,w,1]T=[v,w,1]\\begin{bmatrix} t_{11} & t_{12} & t_{13} \\\\t_{21} & t_{22} & t_{23} \\\\t_{31} & t_{32} & t_{33} \\end{bmatrix}</script><p> $t_{13}v+t_{23}w+t_{33}=1$</p>\n<p> 4  4  8  9  9  opencv  python <a href=\"https://docs.opencv.org/4.1.2/da/d6e/tutorial_py_geometric_transformations.html\"></a></p>\n<h1 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h1><p> n  3 66 $(1)$ </p>\n<script type=\"math/tex; mode=display\">x=c_1v+ c_2w+c_3vw + c_4 \\\\ y=c_5v+c_6w+c_7vw+c_8</script><p> 4 </p>\n<p></p>\n<h1 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h1><p> $(x,y)$  $(i+u,j+v)$+$0\\le u,v &lt; 1$</p>\n<h2 id=\"3-1-\"><a href=\"#3-1-\" class=\"headerlink\" title=\"3.1 \"></a>3.1 </h2><p> $u,v$  $(\\lfloor i+u+\\frac 1 2\\rfloor,\\lfloor j+v+\\frac 1 2 \\rfloor)$</p>\n<h2 id=\"3-2-\"><a href=\"#3-2-\" class=\"headerlink\" title=\"3.2 \"></a>3.2 </h2><p> 4  $(i,j), (i+1,j),(i,j+1),(i+1,j+1)$ </p>\n<script type=\"math/tex; mode=display\">f(i+u,j+v)=(1-u)(1-v)f(i,j)+(1-u)v f(i,j+1)+u(1-v)f(i+1,j)+uvf(i+1,j+1)</script><h2 id=\"3-2-\"><a href=\"#3-2-\" class=\"headerlink\" title=\"3.2 \"></a>3.2 </h2><p> 16  BiCubic </p>\n<script type=\"math/tex; mode=display\">W(x)=\\begin{cases} (a+2)|x|^3 - (a+3)|x|^2+1 & |x| \\le 1 \\\\ a|x|^3-5a|x|^2+8a|x|-4a & 1 <|x|<2 \\\\ 0 & \\text{otherwise} \\end{cases}</script><p> $x$ a  $a=-0.5$</p>\n<p> $(x,y)$  $(i,j)$  $(x,y)$  $4\\times4$  $(x_i,y_j), \\ i,j=0,1,2,3$</p>\n<script type=\"math/tex; mode=display\">f(x,y)=\\sum_{i=0}^3\\sum_{j=0}^3 f(x_i,y_j) W(x-x_i) W(y-y_j)</script><h1 id=\"4-\"><a href=\"#4-\" class=\"headerlink\" title=\"4. \"></a>4. </h1><p></p>\n<h2 id=\"4-1-\"><a href=\"#4-1-\" class=\"headerlink\" title=\"4.1 \"></a>4.1 </h2><p> $[0,L-1]$</p>\n<script type=\"math/tex; mode=display\">s=T(r)</script><p> <code>r</code>  <code>s</code><br></p>\n<p> <code>r</code> <code>s</code>  $p_r(r), \\ p_s(s)$  <code>r</code>  <code>s</code> </p>\n<script type=\"math/tex; mode=display\">p_s(s)=p_r(r) \\frac {dr} {ds} \\qquad(2)</script><p> $T(r)=s, \\ r_1 \\le r \\le r_2$ $r_1&lt;r_2$ $r_1=r_2$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">s=T(r)=(L-1)\\int_0^r p_r(w) dw \\qquad(3)</script><p>  $(L-1)$ </p>\n<p> (3) </p>\n<script type=\"math/tex; mode=display\">\\frac {ds} {dr} = \\frac {dT(r)} {dr} = (L-1) \\frac d {dr} \\left[\\int_0^r p_r(w)dw \\right] = (L-1)p_r(r) \\qquad(4)</script><p> (4)  (2) </p>\n<script type=\"math/tex; mode=display\">p_s(s)=p_r(r) \\frac {dr} {ds} = \\frac 1 {L-1} \\qquad(5)</script><p>  <code>s</code> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">s=T(r)=(L-1) \\sum_{0}^r p_r(r) \\qquad(3')</script><p> $p_r(r)=n_r/N$$n_r$  <code>r</code> <code>N</code> <br> </p>\n<script type=\"math/tex; mode=display\">1=s - (s-1) = (L-1)\\sum_0^{r_2}p_r(r) - (L-1)\\sum_0^{r_1}p_r(r)=(L-1)\\sum_{r_1}^{r_2}p_r(r)</script><p></p>\n<script type=\"math/tex; mode=display\">p_s(s) = \\sum_{r_1}^{r_2}p_r(r)=\\frac 1 {L-1}</script><p> $r$  $r_1$ $1/(L-1)$</p>\n<h2 id=\"4-2-\"><a href=\"#4-2-\" class=\"headerlink\" title=\"4.2 \"></a>4.2 </h2><p> <code>r</code>   <code>z</code> <code>s</code> </p>\n<script type=\"math/tex; mode=display\">s=T(r)=(L-1)\\int_0^r p_r(r) dw \\qquad(6)\n\\\\\\\\ s=G(z)=(L-1)\\int_0^z p_z(t) dt \\qquad(7)</script><p></p>\n<script type=\"math/tex; mode=display\">z=G^{-1}(s)</script><p> $G$ </p>\n<p> $p_r(r)$ $p_z(z)$  (7)  $G$ z  s </p>\n<ol>\n<li> $p_r(r)$ <code>s</code></li>\n<li> (7)  $G(z)$</li>\n<li> $G^{-1}(s)$ <code>s</code>  <code>z</code></li>\n</ol>\n<p> <code>s</code>  $z=G^{-1}(s)$s  z </p>\n<h2 id=\"4-3-\"><a href=\"#4-3-\" class=\"headerlink\" title=\"4.3 \"></a>4.3 </h2><p></p>\n<h2 id=\"4-4-\"><a href=\"#4-4-\" class=\"headerlink\" title=\"4.4 \"></a>4.4 </h2><p> <code>r</code>  $p(r)$<code>r</code>  n </p>\n<script type=\"math/tex; mode=display\">\\mu_n(r)=\\sum_{i=0}^{L-1} (r_i-m)^n p(r_i)</script><p> <code>m</code> $m=\\sum_0^{L-1} r_i p(r_i)$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">u_2(r)=\\sum_{i=0}^{L-1}(r_i-m)^2 p(r_i)</script><p> $\\sigma^2$ </p>\n<p></p>\n<script type=\"math/tex; mode=display\">m=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} f(x,y)\n\\\\\\\\ \\sigma^2=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} [f(x,y)-m]^2</script><p> $MN-1$  $MN$ </p>\n<p> $(x,y)$  $S_{xy}$</p>\n<script type=\"math/tex; mode=display\">m_{s_{xy}}=\\sum_{i=0}^{L-1}r_i p_{s_{xy}} (r_i)\n\\\\\\\\ \\sigma_{s_{xy}}^2 = \\sum _{i=0}^{L-1} (r_i - m_{S_{xy}})^2 p_{s_{xy}}(r_i)</script><p> $m_G$ $m_{s_{xy}} \\le k_0 m_G$ $0&lt; k_0 &lt; 1.0$</p>\n<p> $\\sigma_{s_{xy}} \\le k_2 \\sigma_G$ 0  $k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G$ <code>E</code> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">g(x,y)=\\begin{cases} E \\cdot f(x,y) & m_{s_{xy}} \\le k_0 m_G, \\ k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G \n\\\\\\\\ f(x,y) & \\text{otherwise} \\end{cases}</script>","site":{"data":{}},"excerpt":"<blockquote>\n<p>(Gonzalez)</p>\n<h1 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h1><h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p></p>\n<ol>\n<li></li>\n<li>","more":"<script type=\"math/tex; mode=display\">(x,y)=\\mathbf T[(v,w)]</script> $(v,w)$ $(x,y)$ <script type=\"math/tex; mode=display\">\\begin{bmatrix}x & y & 1 \\end{bmatrix}=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\mathbf T=\\begin{bmatrix}v & w & 1 \\end{bmatrix}\\begin{bmatrix}t_{11} & t_{12} & 0 \\\\ t_{21} & t_{22} & 0 \\\\ t_{31} & t_{32} & 1\\end{bmatrix}</script></li>\n</ol>\n</blockquote>\n<script type=\"math/tex; mode=display\">\\begin{cases}x=t_{11} v + t_{21} w + t_{31} \\\\\ny=t_{12} v + t_{22} w + t_{32} \\end{cases} \\qquad(1)</script><p></p>\n<script type=\"math/tex; mode=display\">(v,w)=\\mathbf T^{-1} [(x,y)]</script><h3 id=\"1-1-1-\"><a href=\"#1-1-1-\" class=\"headerlink\" title=\"1.1.1 \"></a>1.1.1 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ 0&0&1\\end{bmatrix}</script><h3 id=\"1-1-2-\"><a href=\"#1-1-2-\" class=\"headerlink\" title=\"1.1.2 \"></a>1.1.2 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} c_x & 0 & 0 \\\\ 0& c_y&0 \\\\ 0&0&1\\end{bmatrix}</script><p>x  $c_x$ y  $c_y$ </p>\n<h3 id=\"1-1-3-\"><a href=\"#1-1-3-\" class=\"headerlink\" title=\"1.1.3 \"></a>1.1.3 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} cos \\theta & sin \\theta & 0 \\\\ -sin \\theta& cos \\theta&0 \\\\ 0&0&1\\end{bmatrix}</script><p> $\\theta$ </p>\n<h3 id=\"1-1-4-\"><a href=\"#1-1-4-\" class=\"headerlink\" title=\"1.1.4 \"></a>1.1.4 </h3><script type=\"math/tex; mode=display\">\\mathbf T = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0& 1&0 \\\\ t_x&t_y&1\\end{bmatrix}</script><h3 id=\"1-1-5-\"><a href=\"#1-1-5-\" class=\"headerlink\" title=\"1.1.5 \"></a>1.1.5 </h3><p>shear</p>\n<script type=\"math/tex; mode=display\">(v,w) \\rightarrow (v+mw,w)</script><p>$m&gt;0$ $m&lt;0$ <br></p>\n<script type=\"math/tex; mode=display\">(v,w) \\rightarrow (v, vn+w)</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf T=\\begin{bmatrix} 1 & n & 0 \\\\ m & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}</script><h2 id=\"1-2-\"><a href=\"#1-2-\" class=\"headerlink\" title=\"1.2 \"></a>1.2 </h2><p> $(x,y)$  $(x,y,z)$ $(x,y)$ </p>\n<p> $(x,y,1)$ $(x,y,1)$  $3 \\times 3$  $(x,y,1)$ $(x,y,1)$</p>\n<script type=\"math/tex; mode=display\">[x,y,1]=[v,w,1]T=[v,w,1]\\begin{bmatrix} t_{11} & t_{12} & t_{13} \\\\t_{21} & t_{22} & t_{23} \\\\t_{31} & t_{32} & t_{33} \\end{bmatrix}</script><p> $t_{13}v+t_{23}w+t_{33}=1$</p>\n<p> 4  4  8  9  9  opencv  python <a href=\"https://docs.opencv.org/4.1.2/da/d6e/tutorial_py_geometric_transformations.html\"></a></p>\n<h1 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h1><p> n  3 66 $(1)$ </p>\n<script type=\"math/tex; mode=display\">x=c_1v+ c_2w+c_3vw + c_4 \\\\ y=c_5v+c_6w+c_7vw+c_8</script><p> 4 </p>\n<p></p>\n<h1 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h1><p> $(x,y)$  $(i+u,j+v)$+$0\\le u,v &lt; 1$</p>\n<h2 id=\"3-1-\"><a href=\"#3-1-\" class=\"headerlink\" title=\"3.1 \"></a>3.1 </h2><p> $u,v$  $(\\lfloor i+u+\\frac 1 2\\rfloor,\\lfloor j+v+\\frac 1 2 \\rfloor)$</p>\n<h2 id=\"3-2-\"><a href=\"#3-2-\" class=\"headerlink\" title=\"3.2 \"></a>3.2 </h2><p> 4  $(i,j), (i+1,j),(i,j+1),(i+1,j+1)$ </p>\n<script type=\"math/tex; mode=display\">f(i+u,j+v)=(1-u)(1-v)f(i,j)+(1-u)v f(i,j+1)+u(1-v)f(i+1,j)+uvf(i+1,j+1)</script><h2 id=\"3-2-\"><a href=\"#3-2-\" class=\"headerlink\" title=\"3.2 \"></a>3.2 </h2><p> 16  BiCubic </p>\n<script type=\"math/tex; mode=display\">W(x)=\\begin{cases} (a+2)|x|^3 - (a+3)|x|^2+1 & |x| \\le 1 \\\\ a|x|^3-5a|x|^2+8a|x|-4a & 1 <|x|<2 \\\\ 0 & \\text{otherwise} \\end{cases}</script><p> $x$ a  $a=-0.5$</p>\n<p> $(x,y)$  $(i,j)$  $(x,y)$  $4\\times4$  $(x_i,y_j), \\ i,j=0,1,2,3$</p>\n<script type=\"math/tex; mode=display\">f(x,y)=\\sum_{i=0}^3\\sum_{j=0}^3 f(x_i,y_j) W(x-x_i) W(y-y_j)</script><h1 id=\"4-\"><a href=\"#4-\" class=\"headerlink\" title=\"4. \"></a>4. </h1><p></p>\n<h2 id=\"4-1-\"><a href=\"#4-1-\" class=\"headerlink\" title=\"4.1 \"></a>4.1 </h2><p> $[0,L-1]$</p>\n<script type=\"math/tex; mode=display\">s=T(r)</script><p> <code>r</code>  <code>s</code><br></p>\n<p> <code>r</code> <code>s</code>  $p_r(r), \\ p_s(s)$  <code>r</code>  <code>s</code> </p>\n<script type=\"math/tex; mode=display\">p_s(s)=p_r(r) \\frac {dr} {ds} \\qquad(2)</script><p> $T(r)=s, \\ r_1 \\le r \\le r_2$ $r_1&lt;r_2$ $r_1=r_2$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">s=T(r)=(L-1)\\int_0^r p_r(w) dw \\qquad(3)</script><p>  $(L-1)$ </p>\n<p> (3) </p>\n<script type=\"math/tex; mode=display\">\\frac {ds} {dr} = \\frac {dT(r)} {dr} = (L-1) \\frac d {dr} \\left[\\int_0^r p_r(w)dw \\right] = (L-1)p_r(r) \\qquad(4)</script><p> (4)  (2) </p>\n<script type=\"math/tex; mode=display\">p_s(s)=p_r(r) \\frac {dr} {ds} = \\frac 1 {L-1} \\qquad(5)</script><p>  <code>s</code> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">s=T(r)=(L-1) \\sum_{0}^r p_r(r) \\qquad(3')</script><p> $p_r(r)=n_r/N$$n_r$  <code>r</code> <code>N</code> <br> </p>\n<script type=\"math/tex; mode=display\">1=s - (s-1) = (L-1)\\sum_0^{r_2}p_r(r) - (L-1)\\sum_0^{r_1}p_r(r)=(L-1)\\sum_{r_1}^{r_2}p_r(r)</script><p></p>\n<script type=\"math/tex; mode=display\">p_s(s) = \\sum_{r_1}^{r_2}p_r(r)=\\frac 1 {L-1}</script><p> $r$  $r_1$ $1/(L-1)$</p>\n<h2 id=\"4-2-\"><a href=\"#4-2-\" class=\"headerlink\" title=\"4.2 \"></a>4.2 </h2><p> <code>r</code>   <code>z</code> <code>s</code> </p>\n<script type=\"math/tex; mode=display\">s=T(r)=(L-1)\\int_0^r p_r(r) dw \\qquad(6)\n\\\\\\\\ s=G(z)=(L-1)\\int_0^z p_z(t) dt \\qquad(7)</script><p></p>\n<script type=\"math/tex; mode=display\">z=G^{-1}(s)</script><p> $G$ </p>\n<p> $p_r(r)$ $p_z(z)$  (7)  $G$ z  s </p>\n<ol>\n<li> $p_r(r)$ <code>s</code></li>\n<li> (7)  $G(z)$</li>\n<li> $G^{-1}(s)$ <code>s</code>  <code>z</code></li>\n</ol>\n<p> <code>s</code>  $z=G^{-1}(s)$s  z </p>\n<h2 id=\"4-3-\"><a href=\"#4-3-\" class=\"headerlink\" title=\"4.3 \"></a>4.3 </h2><p></p>\n<h2 id=\"4-4-\"><a href=\"#4-4-\" class=\"headerlink\" title=\"4.4 \"></a>4.4 </h2><p> <code>r</code>  $p(r)$<code>r</code>  n </p>\n<script type=\"math/tex; mode=display\">\\mu_n(r)=\\sum_{i=0}^{L-1} (r_i-m)^n p(r_i)</script><p> <code>m</code> $m=\\sum_0^{L-1} r_i p(r_i)$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">u_2(r)=\\sum_{i=0}^{L-1}(r_i-m)^2 p(r_i)</script><p> $\\sigma^2$ </p>\n<p></p>\n<script type=\"math/tex; mode=display\">m=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} f(x,y)\n\\\\\\\\ \\sigma^2=\\frac 1 {MN} \\sum_{x=0}^{M-1} \\sum_{y=0}^{N-1} [f(x,y)-m]^2</script><p> $MN-1$  $MN$ </p>\n<p> $(x,y)$  $S_{xy}$</p>\n<script type=\"math/tex; mode=display\">m_{s_{xy}}=\\sum_{i=0}^{L-1}r_i p_{s_{xy}} (r_i)\n\\\\\\\\ \\sigma_{s_{xy}}^2 = \\sum _{i=0}^{L-1} (r_i - m_{S_{xy}})^2 p_{s_{xy}}(r_i)</script><p> $m_G$ $m_{s_{xy}} \\le k_0 m_G$ $0&lt; k_0 &lt; 1.0$</p>\n<p> $\\sigma_{s_{xy}} \\le k_2 \\sigma_G$ 0  $k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G$ <code>E</code> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">g(x,y)=\\begin{cases} E \\cdot f(x,y) & m_{s_{xy}} \\le k_0 m_G, \\ k_1 \\sigma_G \\le \\sigma_{s_{xy}} \\le k_2 \\sigma_G \n\\\\\\\\ f(x,y) & \\text{otherwise} \\end{cases}</script>"},{"title":"","date":"2019-12-07T03:08:24.000Z","mathjax":true,"_content":"\n> (Gonzalez)\n\n# 1. \n\n<!-- more -->\n## 1.1 \n\n1. \n2. \n\n\n1. \n   \n   \n\n## 1.2 \n\n $f(x)$\n$$\\frac {\\partial f} {\\partial x} = f(x+1) - f(x)$$\n $f(x,y)$ \n$$\\frac {\\partial^2 f} {\\partial x^2} = f'(x) - f'(x-1) = f(x+1) + f(x-1) - 2f(x)$$\n\n\n### 1.2.1 \n$$\\nabla^2 f = \\frac {\\partial^2 f} {\\partial x^2} + \\frac {\\partial^2 f} {\\partial y^2} $$\n\n\n$$\\frac {\\partial^2 f} {\\partial x^2} = f(x+1,y)+f(x-1,y) - 2f(x,y)\n\\\\\\\\ \\frac {\\partial^2 f} {\\partial y^2} = f(x,y+1)+f(x,y-1) - 2f(x,y)$$\n\n$$\\nabla^2 f = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$\n\n$f(x \\pm 1,y \\pm 1)$ 4  $-f(x,y)$\n\n -1\n\n\n$$g(x,y)=f(x,y)+c\\left[ \\nabla^2 f(x,y) \\right]$$\n\n 0 255  255 8 bit  `f`\n$$f_m = f-\\min(f)\n\\\\\\\\ f_s=(L-1)[f_m/\\max(f_m)]$$\n $[0,L-1]$ \n\n\n### 1.2.2 \n\n1. \n2. \n3. \n   \n$$g_{mask}(x,y) = f(x,y) - \\overline f(x,y)\n\\\\\\\\ g(x,y)=f(x,y) + k \\cdot g_{mask}(x,y)$$\n\n### 1.2.3 \n $f(x,y)$ \n$$\\nabla f =\\begin{bmatrix} g_x \\\\\\\\ g_y \\end{bmatrix}= \\begin{bmatrix} \\frac {\\partial f} {\\partial x} \\\\\\\\ \\frac {\\partial f} {\\partial x} \\end{bmatrix}$$\n\n$$M(x,y) = \\sqrt {g_x^2 + g_y^2}$$\n\n\n$$M(x,y)=|g_x|+|g_y|$$\n\n $3 \\times 3$  $3 \\times 3$ \n$$\\mathbf z=\\begin{bmatrix} z_1 & z_2 & z_3 \\\\ z_4 & z_5 & z_6 \\\\z_7 & z_8 & z_9 \\end{bmatrix}$$\n $z_5$\n$$g_x=z_8-z_5, \\quad g_y = z_6-z_5$$\n\n Roberts \n$$g_x=z_9- z_5, \\quad g_y = z_8-z_6$$\n\n `x,y`  90 \n\n__sobel __\n\n$\\mathbf w_x=\\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}$,  $\\mathbf w_y=\\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}$\n\n\n\n~~$$g_x = \\mathbf w_x \\ast \\mathbf z, \\qquad g_x = \\mathbf w_x \\ast \\mathbf z$$~~\n$$g_x = \\mathbf w_x \\odot \\mathbf z, \\qquad g_x = \\mathbf w_x \\odot \\mathbf z$$\n\nsobel \n\n## 1.3 \n\n\n## 1.4 \n\n `z` \n$$A = \\{z, \\mu_A(z)|z \\in Z, \\ \\mu_A(z) \\in (0,1]\\}$$\n $Z$  `z`  $[0,1]$\n\n____ $\\mu_A(z) = 0$\n\n____ $\\mu_A(z) = \\mu_B(z), \\ \\forall z$\n\n____ $\\mu_{\\overline A}(z) = 1- \\mu_A(z)$\n\n____ $\\mu_A(z) \\le \\mu_B(z) \\Rightarrow A \\subseteq B$\n\n____ $\\mu_U(z)=\\max [\\mu_A(z), \\mu_B(z)]$\n\n____ $\\mu_I(z) = \\min [\\mu_A(z), \\mu_B(z)]$\n\n","source":"_posts/DIP-2.md","raw":"---\ntitle: \ndate: 2019-12-07 11:08:24\ntags: DIP\nmathjax: true\n---\n\n> (Gonzalez)\n\n# 1. \n\n<!-- more -->\n## 1.1 \n\n1. \n2. \n\n\n1. \n   \n   \n\n## 1.2 \n\n $f(x)$\n$$\\frac {\\partial f} {\\partial x} = f(x+1) - f(x)$$\n $f(x,y)$ \n$$\\frac {\\partial^2 f} {\\partial x^2} = f'(x) - f'(x-1) = f(x+1) + f(x-1) - 2f(x)$$\n\n\n### 1.2.1 \n$$\\nabla^2 f = \\frac {\\partial^2 f} {\\partial x^2} + \\frac {\\partial^2 f} {\\partial y^2} $$\n\n\n$$\\frac {\\partial^2 f} {\\partial x^2} = f(x+1,y)+f(x-1,y) - 2f(x,y)\n\\\\\\\\ \\frac {\\partial^2 f} {\\partial y^2} = f(x,y+1)+f(x,y-1) - 2f(x,y)$$\n\n$$\\nabla^2 f = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$\n\n$f(x \\pm 1,y \\pm 1)$ 4  $-f(x,y)$\n\n -1\n\n\n$$g(x,y)=f(x,y)+c\\left[ \\nabla^2 f(x,y) \\right]$$\n\n 0 255  255 8 bit  `f`\n$$f_m = f-\\min(f)\n\\\\\\\\ f_s=(L-1)[f_m/\\max(f_m)]$$\n $[0,L-1]$ \n\n\n### 1.2.2 \n\n1. \n2. \n3. \n   \n$$g_{mask}(x,y) = f(x,y) - \\overline f(x,y)\n\\\\\\\\ g(x,y)=f(x,y) + k \\cdot g_{mask}(x,y)$$\n\n### 1.2.3 \n $f(x,y)$ \n$$\\nabla f =\\begin{bmatrix} g_x \\\\\\\\ g_y \\end{bmatrix}= \\begin{bmatrix} \\frac {\\partial f} {\\partial x} \\\\\\\\ \\frac {\\partial f} {\\partial x} \\end{bmatrix}$$\n\n$$M(x,y) = \\sqrt {g_x^2 + g_y^2}$$\n\n\n$$M(x,y)=|g_x|+|g_y|$$\n\n $3 \\times 3$  $3 \\times 3$ \n$$\\mathbf z=\\begin{bmatrix} z_1 & z_2 & z_3 \\\\ z_4 & z_5 & z_6 \\\\z_7 & z_8 & z_9 \\end{bmatrix}$$\n $z_5$\n$$g_x=z_8-z_5, \\quad g_y = z_6-z_5$$\n\n Roberts \n$$g_x=z_9- z_5, \\quad g_y = z_8-z_6$$\n\n `x,y`  90 \n\n__sobel __\n\n$\\mathbf w_x=\\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}$,  $\\mathbf w_y=\\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}$\n\n\n\n~~$$g_x = \\mathbf w_x \\ast \\mathbf z, \\qquad g_x = \\mathbf w_x \\ast \\mathbf z$$~~\n$$g_x = \\mathbf w_x \\odot \\mathbf z, \\qquad g_x = \\mathbf w_x \\odot \\mathbf z$$\n\nsobel \n\n## 1.3 \n\n\n## 1.4 \n\n `z` \n$$A = \\{z, \\mu_A(z)|z \\in Z, \\ \\mu_A(z) \\in (0,1]\\}$$\n $Z$  `z`  $[0,1]$\n\n____ $\\mu_A(z) = 0$\n\n____ $\\mu_A(z) = \\mu_B(z), \\ \\forall z$\n\n____ $\\mu_{\\overline A}(z) = 1- \\mu_A(z)$\n\n____ $\\mu_A(z) \\le \\mu_B(z) \\Rightarrow A \\subseteq B$\n\n____ $\\mu_U(z)=\\max [\\mu_A(z), \\mu_B(z)]$\n\n____ $\\mu_I(z) = \\min [\\mu_A(z), \\mu_B(z)]$\n\n","slug":"DIP-2","published":1,"updated":"2020-04-24T10:37:04.704Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or9030007p0djdv3sg6h1","content":"<blockquote>\n<p>(Gonzalez)</p>\n</blockquote>\n<h1 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h1><p><br><span id=\"more\"></span></p>\n<h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p></p>\n<ol>\n<li></li>\n<li></li>\n</ol>\n<p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n</ol>\n<h2 id=\"1-2-\"><a href=\"#1-2-\" class=\"headerlink\" title=\"1.2 \"></a>1.2 </h2><p><br> $f(x)$</p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial f} {\\partial x} = f(x+1) - f(x)</script><p> $f(x,y)$ </p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial^2 f} {\\partial x^2} = f'(x) - f'(x-1) = f(x+1) + f(x-1) - 2f(x)</script><p></p>\n<h3 id=\"1-2-1-\"><a href=\"#1-2-1-\" class=\"headerlink\" title=\"1.2.1 \"></a>1.2.1 </h3><script type=\"math/tex; mode=display\">\\nabla^2 f = \\frac {\\partial^2 f} {\\partial x^2} + \\frac {\\partial^2 f} {\\partial y^2}</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial^2 f} {\\partial x^2} = f(x+1,y)+f(x-1,y) - 2f(x,y)\n\\\\\\\\ \\frac {\\partial^2 f} {\\partial y^2} = f(x,y+1)+f(x,y-1) - 2f(x,y)</script><p></p>\n<script type=\"math/tex; mode=display\">\\nabla^2 f = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)</script><p>$f(x \\pm 1,y \\pm 1)$ 4  $-f(x,y)$</p>\n<p> -1</p>\n<p></p>\n<script type=\"math/tex; mode=display\">g(x,y)=f(x,y)+c\\left[ \\nabla^2 f(x,y) \\right]</script><p> 0 255  255 8 bit  <code>f</code></p>\n<script type=\"math/tex; mode=display\">f_m = f-\\min(f)\n\\\\\\\\ f_s=(L-1)[f_m/\\max(f_m)]</script><p> $[0,L-1]$ </p>\n<h3 id=\"1-2-2-\"><a href=\"#1-2-2-\" class=\"headerlink\" title=\"1.2.2 \"></a>1.2.2 </h3><p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<script type=\"math/tex; mode=display\">g_{mask}(x,y) = f(x,y) - \\overline f(x,y)\n\\\\\\\\ g(x,y)=f(x,y) + k \\cdot g_{mask}(x,y)</script><h3 id=\"1-2-3-\"><a href=\"#1-2-3-\" class=\"headerlink\" title=\"1.2.3 \"></a>1.2.3 </h3><p> $f(x,y)$ </p>\n<script type=\"math/tex; mode=display\">\\nabla f =\\begin{bmatrix} g_x \\\\\\\\ g_y \\end{bmatrix}= \\begin{bmatrix} \\frac {\\partial f} {\\partial x} \\\\\\\\ \\frac {\\partial f} {\\partial x} \\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">M(x,y) = \\sqrt {g_x^2 + g_y^2}</script><p></p>\n<script type=\"math/tex; mode=display\">M(x,y)=|g_x|+|g_y|</script><p> $3 \\times 3$  $3 \\times 3$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf z=\\begin{bmatrix} z_1 & z_2 & z_3 \\\\ z_4 & z_5 & z_6 \\\\z_7 & z_8 & z_9 \\end{bmatrix}</script><p> $z_5$</p>\n<script type=\"math/tex; mode=display\">g_x=z_8-z_5, \\quad g_y = z_6-z_5</script><p> Roberts </p>\n<script type=\"math/tex; mode=display\">g_x=z_9- z_5, \\quad g_y = z_8-z_6</script><p> <code>x,y</code>  90 </p>\n<p><strong>sobel </strong></p>\n<p>$\\mathbf w_x=\\begin{bmatrix} -1 &amp; -2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix}$,  $\\mathbf w_y=\\begin{bmatrix} -1 &amp; 0 &amp; 1 \\\\ -2 &amp; 0 &amp; 2 \\\\ -1 &amp; 0 &amp; 1 \\end{bmatrix}$</p>\n<p></p>\n<p><del><script type=\"math/tex\">g_x = \\mathbf w_x \\ast \\mathbf z, \\qquad g_x = \\mathbf w_x \\ast \\mathbf z</script></del></p>\n<script type=\"math/tex; mode=display\">g_x = \\mathbf w_x \\odot \\mathbf z, \\qquad g_x = \\mathbf w_x \\odot \\mathbf z</script><p>sobel </p>\n<h2 id=\"1-3-\"><a href=\"#1-3-\" class=\"headerlink\" title=\"1.3 \"></a>1.3 </h2><p></p>\n<h2 id=\"1-4-\"><a href=\"#1-4-\" class=\"headerlink\" title=\"1.4 \"></a>1.4 </h2><p> <code>z</code> </p>\n<script type=\"math/tex; mode=display\">A = \\{z, \\mu_A(z)|z \\in Z, \\ \\mu_A(z) \\in (0,1]\\}</script><p> $Z$  <code>z</code>  $[0,1]$</p>\n<p><strong></strong> $\\mu_A(z) = 0$</p>\n<p><strong></strong> $\\mu_A(z) = \\mu_B(z), \\ \\forall z$</p>\n<p><strong></strong> $\\mu_{\\overline A}(z) = 1- \\mu_A(z)$</p>\n<p><strong></strong> $\\mu_A(z) \\le \\mu_B(z) \\Rightarrow A \\subseteq B$</p>\n<p><strong></strong> $\\mu_U(z)=\\max [\\mu_A(z), \\mu_B(z)]$</p>\n<p><strong></strong> $\\mu_I(z) = \\min [\\mu_A(z), \\mu_B(z)]$</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>(Gonzalez)</p>\n</blockquote>\n<h1 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h1><p><br>","more":"</p>\n<h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p></p>\n<ol>\n<li></li>\n<li></li>\n</ol>\n<p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n</ol>\n<h2 id=\"1-2-\"><a href=\"#1-2-\" class=\"headerlink\" title=\"1.2 \"></a>1.2 </h2><p><br> $f(x)$</p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial f} {\\partial x} = f(x+1) - f(x)</script><p> $f(x,y)$ </p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial^2 f} {\\partial x^2} = f'(x) - f'(x-1) = f(x+1) + f(x-1) - 2f(x)</script><p></p>\n<h3 id=\"1-2-1-\"><a href=\"#1-2-1-\" class=\"headerlink\" title=\"1.2.1 \"></a>1.2.1 </h3><script type=\"math/tex; mode=display\">\\nabla^2 f = \\frac {\\partial^2 f} {\\partial x^2} + \\frac {\\partial^2 f} {\\partial y^2}</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial^2 f} {\\partial x^2} = f(x+1,y)+f(x-1,y) - 2f(x,y)\n\\\\\\\\ \\frac {\\partial^2 f} {\\partial y^2} = f(x,y+1)+f(x,y-1) - 2f(x,y)</script><p></p>\n<script type=\"math/tex; mode=display\">\\nabla^2 f = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)</script><p>$f(x \\pm 1,y \\pm 1)$ 4  $-f(x,y)$</p>\n<p> -1</p>\n<p></p>\n<script type=\"math/tex; mode=display\">g(x,y)=f(x,y)+c\\left[ \\nabla^2 f(x,y) \\right]</script><p> 0 255  255 8 bit  <code>f</code></p>\n<script type=\"math/tex; mode=display\">f_m = f-\\min(f)\n\\\\\\\\ f_s=(L-1)[f_m/\\max(f_m)]</script><p> $[0,L-1]$ </p>\n<h3 id=\"1-2-2-\"><a href=\"#1-2-2-\" class=\"headerlink\" title=\"1.2.2 \"></a>1.2.2 </h3><p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<script type=\"math/tex; mode=display\">g_{mask}(x,y) = f(x,y) - \\overline f(x,y)\n\\\\\\\\ g(x,y)=f(x,y) + k \\cdot g_{mask}(x,y)</script><h3 id=\"1-2-3-\"><a href=\"#1-2-3-\" class=\"headerlink\" title=\"1.2.3 \"></a>1.2.3 </h3><p> $f(x,y)$ </p>\n<script type=\"math/tex; mode=display\">\\nabla f =\\begin{bmatrix} g_x \\\\\\\\ g_y \\end{bmatrix}= \\begin{bmatrix} \\frac {\\partial f} {\\partial x} \\\\\\\\ \\frac {\\partial f} {\\partial x} \\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">M(x,y) = \\sqrt {g_x^2 + g_y^2}</script><p></p>\n<script type=\"math/tex; mode=display\">M(x,y)=|g_x|+|g_y|</script><p> $3 \\times 3$  $3 \\times 3$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf z=\\begin{bmatrix} z_1 & z_2 & z_3 \\\\ z_4 & z_5 & z_6 \\\\z_7 & z_8 & z_9 \\end{bmatrix}</script><p> $z_5$</p>\n<script type=\"math/tex; mode=display\">g_x=z_8-z_5, \\quad g_y = z_6-z_5</script><p> Roberts </p>\n<script type=\"math/tex; mode=display\">g_x=z_9- z_5, \\quad g_y = z_8-z_6</script><p> <code>x,y</code>  90 </p>\n<p><strong>sobel </strong></p>\n<p>$\\mathbf w_x=\\begin{bmatrix} -1 &amp; -2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix}$,  $\\mathbf w_y=\\begin{bmatrix} -1 &amp; 0 &amp; 1 \\\\ -2 &amp; 0 &amp; 2 \\\\ -1 &amp; 0 &amp; 1 \\end{bmatrix}$</p>\n<p></p>\n<p><del><script type=\"math/tex\">g_x = \\mathbf w_x \\ast \\mathbf z, \\qquad g_x = \\mathbf w_x \\ast \\mathbf z</script></del></p>\n<script type=\"math/tex; mode=display\">g_x = \\mathbf w_x \\odot \\mathbf z, \\qquad g_x = \\mathbf w_x \\odot \\mathbf z</script><p>sobel </p>\n<h2 id=\"1-3-\"><a href=\"#1-3-\" class=\"headerlink\" title=\"1.3 \"></a>1.3 </h2><p></p>\n<h2 id=\"1-4-\"><a href=\"#1-4-\" class=\"headerlink\" title=\"1.4 \"></a>1.4 </h2><p> <code>z</code> </p>\n<script type=\"math/tex; mode=display\">A = \\{z, \\mu_A(z)|z \\in Z, \\ \\mu_A(z) \\in (0,1]\\}</script><p> $Z$  <code>z</code>  $[0,1]$</p>\n<p><strong></strong> $\\mu_A(z) = 0$</p>\n<p><strong></strong> $\\mu_A(z) = \\mu_B(z), \\ \\forall z$</p>\n<p><strong></strong> $\\mu_{\\overline A}(z) = 1- \\mu_A(z)$</p>\n<p><strong></strong> $\\mu_A(z) \\le \\mu_B(z) \\Rightarrow A \\subseteq B$</p>\n<p><strong></strong> $\\mu_U(z)=\\max [\\mu_A(z), \\mu_B(z)]$</p>\n<p><strong></strong> $\\mu_I(z) = \\min [\\mu_A(z), \\mu_B(z)]$</p>"},{"title":"DSOD","date":"2019-07-08T01:14:40.000Z","mathjax":true,"_content":" [DSOD: Learning Deeply Supervised Object Detectors from Scratch](https://arxiv.org/abs/1708.01241)\n<!-- more -->\n# Introduction\n CNN  InceptionResNet  DenseNet  CV  backbone backbone  benchmark  ImageNet  fine-tune\n1.  ImageNet  backbone \n2. /\n3. fine-tuning ImageNet\n\n train from scratch DSOD \n\n# DSOD\n## \nDSOD  SSD  proposalone-stageDSOD  backbone response mapsbackbone  DenseNet  ImageNet  fine-tune DenseNet  stem block dense block transition layer  transition layerdense 1  DSOD  SSD  maps \n![](/images/DSOD_fig1.png)<center>Fig 1:  SSD  dense </center>\n\n DSOD  1 \n\n|      Layers      | Output Size (Input 3x100x100) |       DSOD        |\n|      :----:      |  :--------:                   |     :-----:       |\n| Stem Convolution | 64x150x150                    | 3x3 conv, stride 2|\n| Stem Convolution | 64x150x150                    | 3x3 conv, stride 1|\n| Stem Convolution | 128x150x150                   | 3x3 conv, stride 1|\n| Stem Convolution | 128x75x75                     | 2x2 max pool, stride 2|\n| Dense Block (1)  | 416x75x75                     | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 6$|\n| Transition Layer (1)| 416x75x75 <br> 416x38x38   | 1x1 conv <br> 2x2 max pool, stride 2|\n| Dense Block (2)  | 800x38x38                     | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 8$|\n| Transition Layer (2)| 800x38x38 <br> 800x19x19   | 1x1 conv <br> 2x2 max pool, stride 2|\n| Dense Block (3)  | 1184x19x19                    | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 8$|\n| Transition w/o Pooling Layer (1)| 1184x19x19     | 1x1 conv          |\n| Dense Block (4)  | 1568x19x19                    | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 8$|\n| Transition w/o Pooling Layer (2)| 1568x19x19     | 1x1 conv          |\n| DSOD Prediction Layers | -                       | Plain/Dense       |\n\n<center>Table 1: DSOD  </center>\n\nDSOD \n###  Proposal\n SOTA \n1. R-CNN  Fast R-CNN proposal  selective search\n2. Faster R-CNN  R-FCN  RPN  region proposals\n3. YOLO  SSD single-shot  proposalsproposal-free\n\nproposal-free RoI pooling  region proposal  pooling  region  conv feature  proposal  RoI pooling  layers  train from scratch  layers  layers \n\ntraining from scratch  proposal-free \n\n### \n DenseNets  block  layer  layers  dense blockDenseNet  layers  skip connections  DenseNet  transition layer  dense block  layers Transition w/o pooling layer \n\n### Stem Block\nStem block  3x3  2x2  2 stem block  DenseNet 7x7  2 2  3x3 stem block  image \n\n### \n 1 1.  SSD 2.  image  300x3006  feature maps  Scale-1 feature maps  backbone  feature maps  38x38 feature maps  backbone  1  feature maps  transition layer  transition layer  bottleneck  1x1  previous scale  feature maps  3x3  next scale  feature maps\n\n 1  SSD  feature maps  DSOD  scale-1 feature maps  conv  conv  1  feature maps  feature maps  1  2x2  2  max pooling 1x1  1  conv max pooling  feature maps  concatenate  1x1 conv  feature maps max pooling  1x1 conv  scale  feature maps previous feature maps\n\n# Experiments\n\n\n# Conclusion\n DSOD  training from scratch single-shot  SSD  DenseNet  backbone DenseNet ","source":"_posts/DSOD.md","raw":"---\ntitle: DSOD\ndate: 2019-07-08 09:14:40\ntags: object detection\nmathjax: true\n---\n [DSOD: Learning Deeply Supervised Object Detectors from Scratch](https://arxiv.org/abs/1708.01241)\n<!-- more -->\n# Introduction\n CNN  InceptionResNet  DenseNet  CV  backbone backbone  benchmark  ImageNet  fine-tune\n1.  ImageNet  backbone \n2. /\n3. fine-tuning ImageNet\n\n train from scratch DSOD \n\n# DSOD\n## \nDSOD  SSD  proposalone-stageDSOD  backbone response mapsbackbone  DenseNet  ImageNet  fine-tune DenseNet  stem block dense block transition layer  transition layerdense 1  DSOD  SSD  maps \n![](/images/DSOD_fig1.png)<center>Fig 1:  SSD  dense </center>\n\n DSOD  1 \n\n|      Layers      | Output Size (Input 3x100x100) |       DSOD        |\n|      :----:      |  :--------:                   |     :-----:       |\n| Stem Convolution | 64x150x150                    | 3x3 conv, stride 2|\n| Stem Convolution | 64x150x150                    | 3x3 conv, stride 1|\n| Stem Convolution | 128x150x150                   | 3x3 conv, stride 1|\n| Stem Convolution | 128x75x75                     | 2x2 max pool, stride 2|\n| Dense Block (1)  | 416x75x75                     | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 6$|\n| Transition Layer (1)| 416x75x75 <br> 416x38x38   | 1x1 conv <br> 2x2 max pool, stride 2|\n| Dense Block (2)  | 800x38x38                     | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 8$|\n| Transition Layer (2)| 800x38x38 <br> 800x19x19   | 1x1 conv <br> 2x2 max pool, stride 2|\n| Dense Block (3)  | 1184x19x19                    | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 8$|\n| Transition w/o Pooling Layer (1)| 1184x19x19     | 1x1 conv          |\n| Dense Block (4)  | 1568x19x19                    | $\\begin{bmatrix} 1 \\times 1 & conv \\\\\\\\ 3 \\times 3 & conv\\end{bmatrix} \\times 8$|\n| Transition w/o Pooling Layer (2)| 1568x19x19     | 1x1 conv          |\n| DSOD Prediction Layers | -                       | Plain/Dense       |\n\n<center>Table 1: DSOD  </center>\n\nDSOD \n###  Proposal\n SOTA \n1. R-CNN  Fast R-CNN proposal  selective search\n2. Faster R-CNN  R-FCN  RPN  region proposals\n3. YOLO  SSD single-shot  proposalsproposal-free\n\nproposal-free RoI pooling  region proposal  pooling  region  conv feature  proposal  RoI pooling  layers  train from scratch  layers  layers \n\ntraining from scratch  proposal-free \n\n### \n DenseNets  block  layer  layers  dense blockDenseNet  layers  skip connections  DenseNet  transition layer  dense block  layers Transition w/o pooling layer \n\n### Stem Block\nStem block  3x3  2x2  2 stem block  DenseNet 7x7  2 2  3x3 stem block  image \n\n### \n 1 1.  SSD 2.  image  300x3006  feature maps  Scale-1 feature maps  backbone  feature maps  38x38 feature maps  backbone  1  feature maps  transition layer  transition layer  bottleneck  1x1  previous scale  feature maps  3x3  next scale  feature maps\n\n 1  SSD  feature maps  DSOD  scale-1 feature maps  conv  conv  1  feature maps  feature maps  1  2x2  2  max pooling 1x1  1  conv max pooling  feature maps  concatenate  1x1 conv  feature maps max pooling  1x1 conv  scale  feature maps previous feature maps\n\n# Experiments\n\n\n# Conclusion\n DSOD  training from scratch single-shot  SSD  DenseNet  backbone DenseNet ","slug":"DSOD","published":1,"updated":"2020-04-24T10:37:33.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or9040008p0dje4ma96kl","content":"<p> <a href=\"https://arxiv.org/abs/1708.01241\">DSOD: Learning Deeply Supervised Object Detectors from Scratch</a><br><span id=\"more\"></span></p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p> CNN  InceptionResNet  DenseNet  CV  backbone backbone  benchmark  ImageNet  fine-tune</p>\n<ol>\n<li> ImageNet  backbone </li>\n<li>/</li>\n<li>fine-tuning ImageNet</li>\n</ol>\n<p> train from scratch DSOD </p>\n<h1 id=\"DSOD\"><a href=\"#DSOD\" class=\"headerlink\" title=\"DSOD\"></a>DSOD</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DSOD  SSD  proposalone-stageDSOD  backbone response mapsbackbone  DenseNet  ImageNet  fine-tune DenseNet  stem block dense block transition layer  transition layerdense 1  DSOD  SSD  maps <br><img src=\"/images/DSOD_fig1.png\" alt=\"\"><center>Fig 1:  SSD  dense </center></p>\n<p> DSOD  1 </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Layers</th>\n<th style=\"text-align:center\">Output Size (Input 3x100x100)</th>\n<th style=\"text-align:center\">DSOD</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">64x150x150</td>\n<td style=\"text-align:center\">3x3 conv, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">64x150x150</td>\n<td style=\"text-align:center\">3x3 conv, stride 1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">128x150x150</td>\n<td style=\"text-align:center\">3x3 conv, stride 1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">128x75x75</td>\n<td style=\"text-align:center\">2x2 max pool, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (1)</td>\n<td style=\"text-align:center\">416x75x75</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 6$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition Layer (1)</td>\n<td style=\"text-align:center\">416x75x75 <br> 416x38x38</td>\n<td style=\"text-align:center\">1x1 conv <br> 2x2 max pool, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (2)</td>\n<td style=\"text-align:center\">800x38x38</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 8$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition Layer (2)</td>\n<td style=\"text-align:center\">800x38x38 <br> 800x19x19</td>\n<td style=\"text-align:center\">1x1 conv <br> 2x2 max pool, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (3)</td>\n<td style=\"text-align:center\">1184x19x19</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 8$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition w/o Pooling Layer (1)</td>\n<td style=\"text-align:center\">1184x19x19</td>\n<td style=\"text-align:center\">1x1 conv</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (4)</td>\n<td style=\"text-align:center\">1568x19x19</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 8$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition w/o Pooling Layer (2)</td>\n<td style=\"text-align:center\">1568x19x19</td>\n<td style=\"text-align:center\">1x1 conv</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DSOD Prediction Layers</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">Plain/Dense</td>\n</tr>\n</tbody>\n</table>\n</div>\n<center>Table 1: DSOD  </center>\n\n<p>DSOD </p>\n<h3 id=\"-Proposal\"><a href=\"#-Proposal\" class=\"headerlink\" title=\" Proposal\"></a> Proposal</h3><p> SOTA </p>\n<ol>\n<li>R-CNN  Fast R-CNN proposal  selective search</li>\n<li>Faster R-CNN  R-FCN  RPN  region proposals</li>\n<li>YOLO  SSD single-shot  proposalsproposal-free</li>\n</ol>\n<p>proposal-free RoI pooling  region proposal  pooling  region  conv feature  proposal  RoI pooling  layers  train from scratch  layers  layers </p>\n<p>training from scratch  proposal-free </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> DenseNets  block  layer  layers  dense blockDenseNet  layers  skip connections  DenseNet  transition layer  dense block  layers Transition w/o pooling layer </p>\n<h3 id=\"Stem-Block\"><a href=\"#Stem-Block\" class=\"headerlink\" title=\"Stem Block\"></a>Stem Block</h3><p>Stem block  3x3  2x2  2 stem block  DenseNet 7x7  2 2  3x3 stem block  image </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 1 1.  SSD 2.  image  300x3006  feature maps  Scale-1 feature maps  backbone  feature maps  38x38 feature maps  backbone  1  feature maps  transition layer  transition layer  bottleneck  1x1  previous scale  feature maps  3x3  next scale  feature maps</p>\n<p> 1  SSD  feature maps  DSOD  scale-1 feature maps  conv  conv  1  feature maps  feature maps  1  2x2  2  max pooling 1x1  1  conv max pooling  feature maps  concatenate  1x1 conv  feature maps max pooling  1x1 conv  scale  feature maps previous feature maps</p>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p></p>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p> DSOD  training from scratch single-shot  SSD  DenseNet  backbone DenseNet </p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1708.01241\">DSOD: Learning Deeply Supervised Object Detectors from Scratch</a><br>","more":"</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p> CNN  InceptionResNet  DenseNet  CV  backbone backbone  benchmark  ImageNet  fine-tune</p>\n<ol>\n<li> ImageNet  backbone </li>\n<li>/</li>\n<li>fine-tuning ImageNet</li>\n</ol>\n<p> train from scratch DSOD </p>\n<h1 id=\"DSOD\"><a href=\"#DSOD\" class=\"headerlink\" title=\"DSOD\"></a>DSOD</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DSOD  SSD  proposalone-stageDSOD  backbone response mapsbackbone  DenseNet  ImageNet  fine-tune DenseNet  stem block dense block transition layer  transition layerdense 1  DSOD  SSD  maps <br><img src=\"/images/DSOD_fig1.png\" alt=\"\"><center>Fig 1:  SSD  dense </center></p>\n<p> DSOD  1 </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Layers</th>\n<th style=\"text-align:center\">Output Size (Input 3x100x100)</th>\n<th style=\"text-align:center\">DSOD</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">64x150x150</td>\n<td style=\"text-align:center\">3x3 conv, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">64x150x150</td>\n<td style=\"text-align:center\">3x3 conv, stride 1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">128x150x150</td>\n<td style=\"text-align:center\">3x3 conv, stride 1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Stem Convolution</td>\n<td style=\"text-align:center\">128x75x75</td>\n<td style=\"text-align:center\">2x2 max pool, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (1)</td>\n<td style=\"text-align:center\">416x75x75</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 6$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition Layer (1)</td>\n<td style=\"text-align:center\">416x75x75 <br> 416x38x38</td>\n<td style=\"text-align:center\">1x1 conv <br> 2x2 max pool, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (2)</td>\n<td style=\"text-align:center\">800x38x38</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 8$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition Layer (2)</td>\n<td style=\"text-align:center\">800x38x38 <br> 800x19x19</td>\n<td style=\"text-align:center\">1x1 conv <br> 2x2 max pool, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (3)</td>\n<td style=\"text-align:center\">1184x19x19</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 8$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition w/o Pooling Layer (1)</td>\n<td style=\"text-align:center\">1184x19x19</td>\n<td style=\"text-align:center\">1x1 conv</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Dense Block (4)</td>\n<td style=\"text-align:center\">1568x19x19</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; conv \\\\\\\\ 3 \\times 3 &amp; conv\\end{bmatrix} \\times 8$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Transition w/o Pooling Layer (2)</td>\n<td style=\"text-align:center\">1568x19x19</td>\n<td style=\"text-align:center\">1x1 conv</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DSOD Prediction Layers</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">Plain/Dense</td>\n</tr>\n</tbody>\n</table>\n</div>\n<center>Table 1: DSOD  </center>\n\n<p>DSOD </p>\n<h3 id=\"-Proposal\"><a href=\"#-Proposal\" class=\"headerlink\" title=\" Proposal\"></a> Proposal</h3><p> SOTA </p>\n<ol>\n<li>R-CNN  Fast R-CNN proposal  selective search</li>\n<li>Faster R-CNN  R-FCN  RPN  region proposals</li>\n<li>YOLO  SSD single-shot  proposalsproposal-free</li>\n</ol>\n<p>proposal-free RoI pooling  region proposal  pooling  region  conv feature  proposal  RoI pooling  layers  train from scratch  layers  layers </p>\n<p>training from scratch  proposal-free </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> DenseNets  block  layer  layers  dense blockDenseNet  layers  skip connections  DenseNet  transition layer  dense block  layers Transition w/o pooling layer </p>\n<h3 id=\"Stem-Block\"><a href=\"#Stem-Block\" class=\"headerlink\" title=\"Stem Block\"></a>Stem Block</h3><p>Stem block  3x3  2x2  2 stem block  DenseNet 7x7  2 2  3x3 stem block  image </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 1 1.  SSD 2.  image  300x3006  feature maps  Scale-1 feature maps  backbone  feature maps  38x38 feature maps  backbone  1  feature maps  transition layer  transition layer  bottleneck  1x1  previous scale  feature maps  3x3  next scale  feature maps</p>\n<p> 1  SSD  feature maps  DSOD  scale-1 feature maps  conv  conv  1  feature maps  feature maps  1  2x2  2  max pooling 1x1  1  conv max pooling  feature maps  concatenate  1x1 conv  feature maps max pooling  1x1 conv  scale  feature maps previous feature maps</p>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p></p>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p> DSOD  training from scratch single-shot  SSD  DenseNet  backbone DenseNet </p>"},{"title":"DeRPN","date":"2019-07-15T07:04:18.000Z","mathjax":true,"_content":" [DeRPN: Taking a further step toward more general object detection](https://arxiv.org/abs/1811.06700)\n<!-- more -->\ntwo-stage SOTA  anchor Faster R-CNN  RPN anchor  scale  aspect ratio K-means  anchor DeRPN  RPN  1(b)\n![](/images/DeRPN_fig1.png)\n\nDeRPN  anchor strings anchor \n\n# \n## \n CNN  $\\mathbf x$ anchor box $B_a$ sigmoid softmax $\\sigma$ bbox \n$$\\mathbf t = \\mathbf {W}_t \\mathbf x+ \\mathbf {b}_r\n\\\\\\\\ B(x,y,w,h)=\\psi(\\mathbf t, B_a(x_a,y_a,w_a,h_a))\n\\\\\\\\ P_B=\\sigma (\\mathbf {W}_c \\mathbf x + \\mathbf {b}_c)$$\n $\\mathbf {W_r, b_r}$ $\\mathbf {W_c, b_c}$ $\\psi$  box  Faster R-CNN  $\\mathbf t$  region proposals  box \n\nanchor  anchor  anchor  gt box !  anchor string$(S_a^w(x_a,w_a), S_a^h(y_a,h_a))$anchor string  $(S_w(x,w), S_h(y,h))$  $(P_s^w, P_s^h)$\n$$\\mathbf t^w=\\mathbf {W_r}^w \\mathbf {x+ b_r}^w \\qquad S_w(x,w)=\\psi(\\mathbf t^w, S_a^w(x_a,w_a))\n\\\\\\\\ \\mathbf t^h=\\mathbf {W_r}^h \\mathbf {x+ b_r}^h \\qquad S_h(x,w)=\\psi(\\mathbf t^h, S_a^h(y_a,h_a))\n\\\\\\\\ P_s^w=\\sigma (\\mathbf {W_c}^w \\mathbf {x+b_c}^w) \\qquad P_s^h=\\sigma (\\mathbf {W_c}^h \\mathbf {x+b_c}^h)$$\n bbox \n$$B(x,y,w,h)=f(S_w(x,w),S_h(y,h))\n\\\\\\\\ P_B=g(P_s^w, P_s^h)$$\nf g  bbox \n### \n n  $n^2$  anchor box  $O(n^2)$n  anchor string  $O(n)$\n\n## \n### Anchor strings\nRPN  anchor string DeRPN  box  anchor string anchor string object  anchor string  $\\{a_n\\}$ (16,32,64,128,256,512,1024) $[8\\sqrt 2,1024 \\sqrt 2]$ $\\sqrt 2$ anchor string  $a_i$ anchor string $[a_i/\\sqrt 2, a_i\\sqrt 2]$2 $[8\\sqrt 2,1024 \\sqrt 2]$\n\n 2  DeRPN \n![](/images/DeRPN_fig2.png) <center>(a)  anchor string  anchor string(b)  anchor string  anchor string(c)  bbox(d)  NMS  region proposals</center>\n\n anchor string RPN  anchor box  gt box  IoU  anchor  anchor  IoU  0.7 gt  IoU  anchor  DeRPN  anchor string  anchor string \n$$M_j=\\{i|\\arg \\min_i |\\log e_j - \\log a_i|\\} \\cup \\{i,i+1| \\begin{vmatrix}\\frac {e_j} {a_i} - \\sqrt q \\end{vmatrix} \\le \\beta\\}, \\ (i=1,...,N) \\quad(9)$$\n$M_j$  j  anchor string $e_j$ N  $\\{a_n\\}$ q  2\n\n anchor string $(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i$ $[(\\sqrt q-\\beta)\\times a_i, (\\sqrt q+\\beta)\\times a_i]$  i $\\beta$  $e_j$  i  i+1  anchor string \n\n $a_i$  $[a_i/ \\sqrt q,a_i\\sqrt q]$ $e_j$  i 0 gt  i  gt  anchor string  anchor string $a_i, a_{i+1}$  $[a_i/\\sqrt q, a_i \\sqrt q] \\cup [a_i \\sqrt q,qa_i\\sqrt q]$ $a_i \\sqrt q$ $e_j$  i  i+1 \n$$(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i$$\n\n\n anchor string  $\\sqrt q$ $\\max(\\sqrt q + \\beta, q/(\\sqrt q-\\beta))$ $\\sqrt q$  DeRPN  RPN  IoU  anchor box  gtRPN \n\n### Label assignment\n anchor string  feature map  (9) anchor string observe-to-distribute  anchor string1.  anchor string / region proposal region proposal  gt  IoU 0.6 anchor string  anchor string \n\n### Consistent network\nDeRPN  RPN  two-stage  2  3x3  1x1  DeRPN  anchor string  $\\{a_n\\}$ N anchor string $2\\times 2N$  anchor string anchor string  $(x,w)$ $(y,h)$ $2 \\times 2N$ \n\n### Scale-sensitive loss function\n\n$$L(\\{p_i\\},\\{t_i\\})=\\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|R_j|} L_{cls}(p_i,p_i^*) \\cdot \\Bbb I\\{i \\in R_j\\} + \\lambda \\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|G_j|} L_{reg} (t_i,t_i^*)\\cdot \\Bbb I\\{i \\in G_j\\} \\quad (10)\n\\\\\\\\ R_j=\\{k|s_k=a_j, k=1,...,M\\} \\quad (11)\n\\\\\\\\ G_j=\\{k|s_k \\in A, s_k=a_j, p_i^*=1, k=1,...,M\\} \\quad (12)$$\n\nN M  batch sizes  anchor string$p_i$  i  anchor string $p_i^*$  gt label anchor string  1  0$t_i$ $t_i^*$  gt A  anchor string $R_j$  anchor string j  $a_j$$G_j$  anchor string j  $a_j$ anchor string  smooth L1 \n$$L_{cls}(p_i,p_i^*)=- p_i^*\\log p_i-(1-p_i^*)\\log (1-p_i)\n\\\\\\\\ L_{reg}(t_i,t_i^*)=\\sum_{j \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^j,t_i^{j*})$$\n\n t  Fast/Faster R-CNN  box \n$$x=x_a+w_a \\times t_x \\quad (13)\n\\\\\\\\ y=y_a+h_a \\times t_y \\quad (14)\n\\\\\\\\ w=w_a \\times e^{t_w} \\qquad (15)\n\\\\\\\\ h=h_a \\times e^{t_h} \\qquad (16)$$\n\n# \nDeRPN  region proposal  bbox region proposal\n\n____  t  anchor string  W top-N $W_N$ top-N  (x,w) $p^W$ (x,w)  top-k  $(y^{(k)},h^{(k)})$ bbox $B_w=\\{(x,y^{(k)},w,h^{(k)}\\}$ bbox \n$$p^B=2/ \\left(\\frac 1 {p^W}+\\frac 1 {p^H}\\right)$$\n $p^W$  (x,w) $p^H$  $(y^{(k)},h^{(k)})$ \n\n top-N  $H_N$ $B_h=\\{(x^{(k)},y,w^{(k)},h\\}$ $B=B_w \\cup B_h$  NMS top-M  region proposals bbox stage \n\n# \n\n\n# \n1.  DeRPN\n2. ","source":"_posts/DeRPN.md","raw":"---\ntitle: DeRPN\ndate: 2019-07-15 15:04:18\ntags: object detection\nmathjax: true\n---\n [DeRPN: Taking a further step toward more general object detection](https://arxiv.org/abs/1811.06700)\n<!-- more -->\ntwo-stage SOTA  anchor Faster R-CNN  RPN anchor  scale  aspect ratio K-means  anchor DeRPN  RPN  1(b)\n![](/images/DeRPN_fig1.png)\n\nDeRPN  anchor strings anchor \n\n# \n## \n CNN  $\\mathbf x$ anchor box $B_a$ sigmoid softmax $\\sigma$ bbox \n$$\\mathbf t = \\mathbf {W}_t \\mathbf x+ \\mathbf {b}_r\n\\\\\\\\ B(x,y,w,h)=\\psi(\\mathbf t, B_a(x_a,y_a,w_a,h_a))\n\\\\\\\\ P_B=\\sigma (\\mathbf {W}_c \\mathbf x + \\mathbf {b}_c)$$\n $\\mathbf {W_r, b_r}$ $\\mathbf {W_c, b_c}$ $\\psi$  box  Faster R-CNN  $\\mathbf t$  region proposals  box \n\nanchor  anchor  anchor  gt box !  anchor string$(S_a^w(x_a,w_a), S_a^h(y_a,h_a))$anchor string  $(S_w(x,w), S_h(y,h))$  $(P_s^w, P_s^h)$\n$$\\mathbf t^w=\\mathbf {W_r}^w \\mathbf {x+ b_r}^w \\qquad S_w(x,w)=\\psi(\\mathbf t^w, S_a^w(x_a,w_a))\n\\\\\\\\ \\mathbf t^h=\\mathbf {W_r}^h \\mathbf {x+ b_r}^h \\qquad S_h(x,w)=\\psi(\\mathbf t^h, S_a^h(y_a,h_a))\n\\\\\\\\ P_s^w=\\sigma (\\mathbf {W_c}^w \\mathbf {x+b_c}^w) \\qquad P_s^h=\\sigma (\\mathbf {W_c}^h \\mathbf {x+b_c}^h)$$\n bbox \n$$B(x,y,w,h)=f(S_w(x,w),S_h(y,h))\n\\\\\\\\ P_B=g(P_s^w, P_s^h)$$\nf g  bbox \n### \n n  $n^2$  anchor box  $O(n^2)$n  anchor string  $O(n)$\n\n## \n### Anchor strings\nRPN  anchor string DeRPN  box  anchor string anchor string object  anchor string  $\\{a_n\\}$ (16,32,64,128,256,512,1024) $[8\\sqrt 2,1024 \\sqrt 2]$ $\\sqrt 2$ anchor string  $a_i$ anchor string $[a_i/\\sqrt 2, a_i\\sqrt 2]$2 $[8\\sqrt 2,1024 \\sqrt 2]$\n\n 2  DeRPN \n![](/images/DeRPN_fig2.png) <center>(a)  anchor string  anchor string(b)  anchor string  anchor string(c)  bbox(d)  NMS  region proposals</center>\n\n anchor string RPN  anchor box  gt box  IoU  anchor  anchor  IoU  0.7 gt  IoU  anchor  DeRPN  anchor string  anchor string \n$$M_j=\\{i|\\arg \\min_i |\\log e_j - \\log a_i|\\} \\cup \\{i,i+1| \\begin{vmatrix}\\frac {e_j} {a_i} - \\sqrt q \\end{vmatrix} \\le \\beta\\}, \\ (i=1,...,N) \\quad(9)$$\n$M_j$  j  anchor string $e_j$ N  $\\{a_n\\}$ q  2\n\n anchor string $(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i$ $[(\\sqrt q-\\beta)\\times a_i, (\\sqrt q+\\beta)\\times a_i]$  i $\\beta$  $e_j$  i  i+1  anchor string \n\n $a_i$  $[a_i/ \\sqrt q,a_i\\sqrt q]$ $e_j$  i 0 gt  i  gt  anchor string  anchor string $a_i, a_{i+1}$  $[a_i/\\sqrt q, a_i \\sqrt q] \\cup [a_i \\sqrt q,qa_i\\sqrt q]$ $a_i \\sqrt q$ $e_j$  i  i+1 \n$$(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i$$\n\n\n anchor string  $\\sqrt q$ $\\max(\\sqrt q + \\beta, q/(\\sqrt q-\\beta))$ $\\sqrt q$  DeRPN  RPN  IoU  anchor box  gtRPN \n\n### Label assignment\n anchor string  feature map  (9) anchor string observe-to-distribute  anchor string1.  anchor string / region proposal region proposal  gt  IoU 0.6 anchor string  anchor string \n\n### Consistent network\nDeRPN  RPN  two-stage  2  3x3  1x1  DeRPN  anchor string  $\\{a_n\\}$ N anchor string $2\\times 2N$  anchor string anchor string  $(x,w)$ $(y,h)$ $2 \\times 2N$ \n\n### Scale-sensitive loss function\n\n$$L(\\{p_i\\},\\{t_i\\})=\\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|R_j|} L_{cls}(p_i,p_i^*) \\cdot \\Bbb I\\{i \\in R_j\\} + \\lambda \\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|G_j|} L_{reg} (t_i,t_i^*)\\cdot \\Bbb I\\{i \\in G_j\\} \\quad (10)\n\\\\\\\\ R_j=\\{k|s_k=a_j, k=1,...,M\\} \\quad (11)\n\\\\\\\\ G_j=\\{k|s_k \\in A, s_k=a_j, p_i^*=1, k=1,...,M\\} \\quad (12)$$\n\nN M  batch sizes  anchor string$p_i$  i  anchor string $p_i^*$  gt label anchor string  1  0$t_i$ $t_i^*$  gt A  anchor string $R_j$  anchor string j  $a_j$$G_j$  anchor string j  $a_j$ anchor string  smooth L1 \n$$L_{cls}(p_i,p_i^*)=- p_i^*\\log p_i-(1-p_i^*)\\log (1-p_i)\n\\\\\\\\ L_{reg}(t_i,t_i^*)=\\sum_{j \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^j,t_i^{j*})$$\n\n t  Fast/Faster R-CNN  box \n$$x=x_a+w_a \\times t_x \\quad (13)\n\\\\\\\\ y=y_a+h_a \\times t_y \\quad (14)\n\\\\\\\\ w=w_a \\times e^{t_w} \\qquad (15)\n\\\\\\\\ h=h_a \\times e^{t_h} \\qquad (16)$$\n\n# \nDeRPN  region proposal  bbox region proposal\n\n____  t  anchor string  W top-N $W_N$ top-N  (x,w) $p^W$ (x,w)  top-k  $(y^{(k)},h^{(k)})$ bbox $B_w=\\{(x,y^{(k)},w,h^{(k)}\\}$ bbox \n$$p^B=2/ \\left(\\frac 1 {p^W}+\\frac 1 {p^H}\\right)$$\n $p^W$  (x,w) $p^H$  $(y^{(k)},h^{(k)})$ \n\n top-N  $H_N$ $B_h=\\{(x^{(k)},y,w^{(k)},h\\}$ $B=B_w \\cup B_h$  NMS top-M  region proposals bbox stage \n\n# \n\n\n# \n1.  DeRPN\n2. ","slug":"DeRPN","published":1,"updated":"2020-04-24T10:35:49.189Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or905000bp0dj3u3rhgci","content":"<p> <a href=\"https://arxiv.org/abs/1811.06700\">DeRPN: Taking a further step toward more general object detection</a><br><span id=\"more\"></span><br>two-stage SOTA  anchor Faster R-CNN  RPN anchor  scale  aspect ratio K-means  anchor DeRPN  RPN  1(b)<br><img src=\"/images/DeRPN_fig1.png\" alt=\"\"></p>\n<p>DeRPN  anchor strings anchor </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> CNN  $\\mathbf x$ anchor box $B_a$ sigmoid softmax $\\sigma$ bbox </p>\n<script type=\"math/tex; mode=display\">\\mathbf t = \\mathbf {W}_t \\mathbf x+ \\mathbf {b}_r\n\\\\\\\\ B(x,y,w,h)=\\psi(\\mathbf t, B_a(x_a,y_a,w_a,h_a))\n\\\\\\\\ P_B=\\sigma (\\mathbf {W}_c \\mathbf x + \\mathbf {b}_c)</script><p> $\\mathbf {W_r, b_r}$ $\\mathbf {W_c, b_c}$ $\\psi$  box  Faster R-CNN  $\\mathbf t$  region proposals  box </p>\n<p>anchor  anchor  anchor  gt box !  anchor string$(S_a^w(x_a,w_a), S_a^h(y_a,h_a))$anchor string  $(S_w(x,w), S_h(y,h))$  $(P_s^w, P_s^h)$</p>\n<script type=\"math/tex; mode=display\">\\mathbf t^w=\\mathbf {W_r}^w \\mathbf {x+ b_r}^w \\qquad S_w(x,w)=\\psi(\\mathbf t^w, S_a^w(x_a,w_a))\n\\\\\\\\ \\mathbf t^h=\\mathbf {W_r}^h \\mathbf {x+ b_r}^h \\qquad S_h(x,w)=\\psi(\\mathbf t^h, S_a^h(y_a,h_a))\n\\\\\\\\ P_s^w=\\sigma (\\mathbf {W_c}^w \\mathbf {x+b_c}^w) \\qquad P_s^h=\\sigma (\\mathbf {W_c}^h \\mathbf {x+b_c}^h)</script><p> bbox </p>\n<script type=\"math/tex; mode=display\">B(x,y,w,h)=f(S_w(x,w),S_h(y,h))\n\\\\\\\\ P_B=g(P_s^w, P_s^h)</script><p>f g  bbox </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> n  $n^2$  anchor box  $O(n^2)$n  anchor string  $O(n)$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Anchor-strings\"><a href=\"#Anchor-strings\" class=\"headerlink\" title=\"Anchor strings\"></a>Anchor strings</h3><p>RPN  anchor string DeRPN  box  anchor string anchor string object  anchor string  $\\{a_n\\}$ (16,32,64,128,256,512,1024) $[8\\sqrt 2,1024 \\sqrt 2]$ $\\sqrt 2$ anchor string  $a_i$ anchor string $[a_i/\\sqrt 2, a_i\\sqrt 2]$2 $[8\\sqrt 2,1024 \\sqrt 2]$</p>\n<p> 2  DeRPN <br><img src=\"/images/DeRPN_fig2.png\" alt=\"\"> <center>(a)  anchor string  anchor string(b)  anchor string  anchor string(c)  bbox(d)  NMS  region proposals</center></p>\n<p> anchor string RPN  anchor box  gt box  IoU  anchor  anchor  IoU  0.7 gt  IoU  anchor  DeRPN  anchor string  anchor string </p>\n<script type=\"math/tex; mode=display\">M_j=\\{i|\\arg \\min_i |\\log e_j - \\log a_i|\\} \\cup \\{i,i+1| \\begin{vmatrix}\\frac {e_j} {a_i} - \\sqrt q \\end{vmatrix} \\le \\beta\\}, \\ (i=1,...,N) \\quad(9)</script><p>$M_j$  j  anchor string $e_j$ N  $\\{a_n\\}$ q  2</p>\n<p> anchor string $(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i$ $[(\\sqrt q-\\beta)\\times a_i, (\\sqrt q+\\beta)\\times a_i]$  i $\\beta$  $e_j$  i  i+1  anchor string </p>\n<p> $a_i$  $[a_i/ \\sqrt q,a_i\\sqrt q]$ $e_j$  i 0 gt  i  gt  anchor string  anchor string $a_i, a_{i+1}$  $[a_i/\\sqrt q, a_i \\sqrt q] \\cup [a_i \\sqrt q,qa_i\\sqrt q]$ $a_i \\sqrt q$ $e_j$  i  i+1 </p>\n<script type=\"math/tex; mode=display\">(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i</script><p></p>\n<p> anchor string  $\\sqrt q$ $\\max(\\sqrt q + \\beta, q/(\\sqrt q-\\beta))$ $\\sqrt q$  DeRPN  RPN  IoU  anchor box  gtRPN </p>\n<h3 id=\"Label-assignment\"><a href=\"#Label-assignment\" class=\"headerlink\" title=\"Label assignment\"></a>Label assignment</h3><p> anchor string  feature map  (9) anchor string observe-to-distribute  anchor string1.  anchor string / region proposal region proposal  gt  IoU 0.6 anchor string  anchor string </p>\n<h3 id=\"Consistent-network\"><a href=\"#Consistent-network\" class=\"headerlink\" title=\"Consistent network\"></a>Consistent network</h3><p>DeRPN  RPN  two-stage  2  3x3  1x1  DeRPN  anchor string  $\\{a_n\\}$ N anchor string $2\\times 2N$  anchor string anchor string  $(x,w)$ $(y,h)$ $2 \\times 2N$ </p>\n<h3 id=\"Scale-sensitive-loss-function\"><a href=\"#Scale-sensitive-loss-function\" class=\"headerlink\" title=\"Scale-sensitive loss function\"></a>Scale-sensitive loss function</h3><p></p>\n<script type=\"math/tex; mode=display\">L(\\{p_i\\},\\{t_i\\})=\\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|R_j|} L_{cls}(p_i,p_i^*) \\cdot \\Bbb I\\{i \\in R_j\\} + \\lambda \\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|G_j|} L_{reg} (t_i,t_i^*)\\cdot \\Bbb I\\{i \\in G_j\\} \\quad (10)\n\\\\\\\\ R_j=\\{k|s_k=a_j, k=1,...,M\\} \\quad (11)\n\\\\\\\\ G_j=\\{k|s_k \\in A, s_k=a_j, p_i^*=1, k=1,...,M\\} \\quad (12)</script><p>N M  batch sizes  anchor string$p_i$  i  anchor string $p_i^<em>$  gt label anchor string  1  0$t_i$ $t_i^</em>$  gt A  anchor string $R_j$  anchor string j  $a_j$$G_j$  anchor string j  $a_j$ anchor string  smooth L1 </p>\n<script type=\"math/tex; mode=display\">L_{cls}(p_i,p_i^*)=- p_i^*\\log p_i-(1-p_i^*)\\log (1-p_i)\n\\\\\\\\ L_{reg}(t_i,t_i^*)=\\sum_{j \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^j,t_i^{j*})</script><p> t  Fast/Faster R-CNN  box </p>\n<script type=\"math/tex; mode=display\">x=x_a+w_a \\times t_x \\quad (13)\n\\\\\\\\ y=y_a+h_a \\times t_y \\quad (14)\n\\\\\\\\ w=w_a \\times e^{t_w} \\qquad (15)\n\\\\\\\\ h=h_a \\times e^{t_h} \\qquad (16)</script><h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>DeRPN  region proposal  bbox region proposal</p>\n<p><strong></strong>  t  anchor string  W top-N $W_N$ top-N  (x,w) $p^W$ (x,w)  top-k  $(y^{(k)},h^{(k)})$ bbox $B_w=\\{(x,y^{(k)},w,h^{(k)}\\}$ bbox </p>\n<script type=\"math/tex; mode=display\">p^B=2/ \\left(\\frac 1 {p^W}+\\frac 1 {p^H}\\right)</script><p> $p^W$  (x,w) $p^H$  $(y^{(k)},h^{(k)})$ </p>\n<p> top-N  $H_N$ $B_h=\\{(x^{(k)},y,w^{(k)},h\\}$ $B=B_w \\cup B_h$  NMS top-M  region proposals bbox stage </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li> DeRPN</li>\n<li></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1811.06700\">DeRPN: Taking a further step toward more general object detection</a><br>","more":"<br>two-stage SOTA  anchor Faster R-CNN  RPN anchor  scale  aspect ratio K-means  anchor DeRPN  RPN  1(b)<br><img src=\"/images/DeRPN_fig1.png\" alt=\"\"></p>\n<p>DeRPN  anchor strings anchor </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> CNN  $\\mathbf x$ anchor box $B_a$ sigmoid softmax $\\sigma$ bbox </p>\n<script type=\"math/tex; mode=display\">\\mathbf t = \\mathbf {W}_t \\mathbf x+ \\mathbf {b}_r\n\\\\\\\\ B(x,y,w,h)=\\psi(\\mathbf t, B_a(x_a,y_a,w_a,h_a))\n\\\\\\\\ P_B=\\sigma (\\mathbf {W}_c \\mathbf x + \\mathbf {b}_c)</script><p> $\\mathbf {W_r, b_r}$ $\\mathbf {W_c, b_c}$ $\\psi$  box  Faster R-CNN  $\\mathbf t$  region proposals  box </p>\n<p>anchor  anchor  anchor  gt box !  anchor string$(S_a^w(x_a,w_a), S_a^h(y_a,h_a))$anchor string  $(S_w(x,w), S_h(y,h))$  $(P_s^w, P_s^h)$</p>\n<script type=\"math/tex; mode=display\">\\mathbf t^w=\\mathbf {W_r}^w \\mathbf {x+ b_r}^w \\qquad S_w(x,w)=\\psi(\\mathbf t^w, S_a^w(x_a,w_a))\n\\\\\\\\ \\mathbf t^h=\\mathbf {W_r}^h \\mathbf {x+ b_r}^h \\qquad S_h(x,w)=\\psi(\\mathbf t^h, S_a^h(y_a,h_a))\n\\\\\\\\ P_s^w=\\sigma (\\mathbf {W_c}^w \\mathbf {x+b_c}^w) \\qquad P_s^h=\\sigma (\\mathbf {W_c}^h \\mathbf {x+b_c}^h)</script><p> bbox </p>\n<script type=\"math/tex; mode=display\">B(x,y,w,h)=f(S_w(x,w),S_h(y,h))\n\\\\\\\\ P_B=g(P_s^w, P_s^h)</script><p>f g  bbox </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> n  $n^2$  anchor box  $O(n^2)$n  anchor string  $O(n)$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Anchor-strings\"><a href=\"#Anchor-strings\" class=\"headerlink\" title=\"Anchor strings\"></a>Anchor strings</h3><p>RPN  anchor string DeRPN  box  anchor string anchor string object  anchor string  $\\{a_n\\}$ (16,32,64,128,256,512,1024) $[8\\sqrt 2,1024 \\sqrt 2]$ $\\sqrt 2$ anchor string  $a_i$ anchor string $[a_i/\\sqrt 2, a_i\\sqrt 2]$2 $[8\\sqrt 2,1024 \\sqrt 2]$</p>\n<p> 2  DeRPN <br><img src=\"/images/DeRPN_fig2.png\" alt=\"\"> <center>(a)  anchor string  anchor string(b)  anchor string  anchor string(c)  bbox(d)  NMS  region proposals</center></p>\n<p> anchor string RPN  anchor box  gt box  IoU  anchor  anchor  IoU  0.7 gt  IoU  anchor  DeRPN  anchor string  anchor string </p>\n<script type=\"math/tex; mode=display\">M_j=\\{i|\\arg \\min_i |\\log e_j - \\log a_i|\\} \\cup \\{i,i+1| \\begin{vmatrix}\\frac {e_j} {a_i} - \\sqrt q \\end{vmatrix} \\le \\beta\\}, \\ (i=1,...,N) \\quad(9)</script><p>$M_j$  j  anchor string $e_j$ N  $\\{a_n\\}$ q  2</p>\n<p> anchor string $(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i$ $[(\\sqrt q-\\beta)\\times a_i, (\\sqrt q+\\beta)\\times a_i]$  i $\\beta$  $e_j$  i  i+1  anchor string </p>\n<p> $a_i$  $[a_i/ \\sqrt q,a_i\\sqrt q]$ $e_j$  i 0 gt  i  gt  anchor string  anchor string $a_i, a_{i+1}$  $[a_i/\\sqrt q, a_i \\sqrt q] \\cup [a_i \\sqrt q,qa_i\\sqrt q]$ $a_i \\sqrt q$ $e_j$  i  i+1 </p>\n<script type=\"math/tex; mode=display\">(\\sqrt q-\\beta)\\times a_i \\le e_j \\le (\\sqrt q+\\beta)\\times a_i</script><p></p>\n<p> anchor string  $\\sqrt q$ $\\max(\\sqrt q + \\beta, q/(\\sqrt q-\\beta))$ $\\sqrt q$  DeRPN  RPN  IoU  anchor box  gtRPN </p>\n<h3 id=\"Label-assignment\"><a href=\"#Label-assignment\" class=\"headerlink\" title=\"Label assignment\"></a>Label assignment</h3><p> anchor string  feature map  (9) anchor string observe-to-distribute  anchor string1.  anchor string / region proposal region proposal  gt  IoU 0.6 anchor string  anchor string </p>\n<h3 id=\"Consistent-network\"><a href=\"#Consistent-network\" class=\"headerlink\" title=\"Consistent network\"></a>Consistent network</h3><p>DeRPN  RPN  two-stage  2  3x3  1x1  DeRPN  anchor string  $\\{a_n\\}$ N anchor string $2\\times 2N$  anchor string anchor string  $(x,w)$ $(y,h)$ $2 \\times 2N$ </p>\n<h3 id=\"Scale-sensitive-loss-function\"><a href=\"#Scale-sensitive-loss-function\" class=\"headerlink\" title=\"Scale-sensitive loss function\"></a>Scale-sensitive loss function</h3><p></p>\n<script type=\"math/tex; mode=display\">L(\\{p_i\\},\\{t_i\\})=\\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|R_j|} L_{cls}(p_i,p_i^*) \\cdot \\Bbb I\\{i \\in R_j\\} + \\lambda \\sum_{j=1}^N \\sum_{i=1}^M \\frac 1 {|G_j|} L_{reg} (t_i,t_i^*)\\cdot \\Bbb I\\{i \\in G_j\\} \\quad (10)\n\\\\\\\\ R_j=\\{k|s_k=a_j, k=1,...,M\\} \\quad (11)\n\\\\\\\\ G_j=\\{k|s_k \\in A, s_k=a_j, p_i^*=1, k=1,...,M\\} \\quad (12)</script><p>N M  batch sizes  anchor string$p_i$  i  anchor string $p_i^<em>$  gt label anchor string  1  0$t_i$ $t_i^</em>$  gt A  anchor string $R_j$  anchor string j  $a_j$$G_j$  anchor string j  $a_j$ anchor string  smooth L1 </p>\n<script type=\"math/tex; mode=display\">L_{cls}(p_i,p_i^*)=- p_i^*\\log p_i-(1-p_i^*)\\log (1-p_i)\n\\\\\\\\ L_{reg}(t_i,t_i^*)=\\sum_{j \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^j,t_i^{j*})</script><p> t  Fast/Faster R-CNN  box </p>\n<script type=\"math/tex; mode=display\">x=x_a+w_a \\times t_x \\quad (13)\n\\\\\\\\ y=y_a+h_a \\times t_y \\quad (14)\n\\\\\\\\ w=w_a \\times e^{t_w} \\qquad (15)\n\\\\\\\\ h=h_a \\times e^{t_h} \\qquad (16)</script><h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>DeRPN  region proposal  bbox region proposal</p>\n<p><strong></strong>  t  anchor string  W top-N $W_N$ top-N  (x,w) $p^W$ (x,w)  top-k  $(y^{(k)},h^{(k)})$ bbox $B_w=\\{(x,y^{(k)},w,h^{(k)}\\}$ bbox </p>\n<script type=\"math/tex; mode=display\">p^B=2/ \\left(\\frac 1 {p^W}+\\frac 1 {p^H}\\right)</script><p> $p^W$  (x,w) $p^H$  $(y^{(k)},h^{(k)})$ </p>\n<p> top-N  $H_N$ $B_h=\\{(x^{(k)},y,w^{(k)},h\\}$ $B=B_w \\cup B_h$  NMS top-M  region proposals bbox stage </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li> DeRPN</li>\n<li></li>\n</ol>"},{"title":"DetNet","date":"2019-07-17T02:05:50.000Z","mathjax":true,"_content":" [DetNet: A Backbone network for Object Detection](https://arxiv.org/abs/1804.06215)\n<!-- more -->\n ImageNet  finetune  backbone  backbone  RF FPN  RetinaNet extra stage DetNet backbone\n\nDetNet  FPN extra stage FPN  ImageNet DetNet  dilated bottleneck \n\n# DetNet\n 1(A)  FPN \n![](/images/DetNet_fig1.png)<center>A.  backbone  FPN B.  backboneC. DetNet  backbone FPN </center>\n\n1.  stage  5  stages stage  2 32  FPN  stages P6  RetinaNet  P6  P7\n2.  32  feature map FPN  layer \n3.  FPN  layer  layer  layer  layer  1 A  layer  context \n\nDetNet \n1.  stage \n2.  stage  6~7  stage deep layer\n\n## DetNet \n ResNet-50  baseline ResNet-50  DetNet-59 ResNet-101  DetNetDetNet  stage 1,2,3,4  ResNet-50  stage 1,2,3,4  ResNet-50  stage \n\n|   ResNet        | output size | 50-layer             |\n|:--------:       | :------:    |   :-------:          |\n| conv1           | 112x112     | 7x7,64, stride 2     |\n|   maxpool       | 56x56       | 3x3, stride 2        |\n| conv2_x         | 56x56       | $\\begin{bmatrix} 1 \\times 1 & 64 \\\\\\\\ 3 \\times 3 & 64 \\\\\\\\ 1 \\times 1 & 256\\end{bmatrix} \\times 3$|\n|conv3_x          | 28x28       | $\\begin{bmatrix} 1 \\times 1 & 128 \\\\\\\\ 3 \\times 3 & 128 \\\\\\\\ 1 \\times 1 & 512\\end{bmatrix} \\times 4$|\n|conv4_x          | 14x14       | $\\begin{bmatrix} 1 \\times 1 & 256 \\\\\\\\ 3 \\times 3 & 256 \\\\\\\\ 1 \\times 1 & 1024\\end{bmatrix} \\times 6$|\n\n stage  DetNet 2 D DetNet-59 \n![](/images/DetNet_fig2.png)<center>fig 2. DetNet </center>\n\n1.  backbone  extra stage P6 FPN  stage 4  16 stage \n2.  stage 4  dilated bottleneck  1x1  stage  2 B\n3. bottleneck  dilated conv  dilated conv  stage 5  6  channel  stage 4 256 backbone  backbone  stage  channel  stage  ResNet-50  64->128->256->512\n\nDetNet  backbone / feature pyramid  FPN  backbone  FPN  stage 4  stage  stage 4,5,6  2 E\n\n# \n\n","source":"_posts/DetNet.md","raw":"---\ntitle: DetNet\ndate: 2019-07-17 10:05:50\ntags: object detection\nmathjax: true\n---\n [DetNet: A Backbone network for Object Detection](https://arxiv.org/abs/1804.06215)\n<!-- more -->\n ImageNet  finetune  backbone  backbone  RF FPN  RetinaNet extra stage DetNet backbone\n\nDetNet  FPN extra stage FPN  ImageNet DetNet  dilated bottleneck \n\n# DetNet\n 1(A)  FPN \n![](/images/DetNet_fig1.png)<center>A.  backbone  FPN B.  backboneC. DetNet  backbone FPN </center>\n\n1.  stage  5  stages stage  2 32  FPN  stages P6  RetinaNet  P6  P7\n2.  32  feature map FPN  layer \n3.  FPN  layer  layer  layer  layer  1 A  layer  context \n\nDetNet \n1.  stage \n2.  stage  6~7  stage deep layer\n\n## DetNet \n ResNet-50  baseline ResNet-50  DetNet-59 ResNet-101  DetNetDetNet  stage 1,2,3,4  ResNet-50  stage 1,2,3,4  ResNet-50  stage \n\n|   ResNet        | output size | 50-layer             |\n|:--------:       | :------:    |   :-------:          |\n| conv1           | 112x112     | 7x7,64, stride 2     |\n|   maxpool       | 56x56       | 3x3, stride 2        |\n| conv2_x         | 56x56       | $\\begin{bmatrix} 1 \\times 1 & 64 \\\\\\\\ 3 \\times 3 & 64 \\\\\\\\ 1 \\times 1 & 256\\end{bmatrix} \\times 3$|\n|conv3_x          | 28x28       | $\\begin{bmatrix} 1 \\times 1 & 128 \\\\\\\\ 3 \\times 3 & 128 \\\\\\\\ 1 \\times 1 & 512\\end{bmatrix} \\times 4$|\n|conv4_x          | 14x14       | $\\begin{bmatrix} 1 \\times 1 & 256 \\\\\\\\ 3 \\times 3 & 256 \\\\\\\\ 1 \\times 1 & 1024\\end{bmatrix} \\times 6$|\n\n stage  DetNet 2 D DetNet-59 \n![](/images/DetNet_fig2.png)<center>fig 2. DetNet </center>\n\n1.  backbone  extra stage P6 FPN  stage 4  16 stage \n2.  stage 4  dilated bottleneck  1x1  stage  2 B\n3. bottleneck  dilated conv  dilated conv  stage 5  6  channel  stage 4 256 backbone  backbone  stage  channel  stage  ResNet-50  64->128->256->512\n\nDetNet  backbone / feature pyramid  FPN  backbone  FPN  stage 4  stage  stage 4,5,6  2 E\n\n# \n\n","slug":"DetNet","published":1,"updated":"2020-04-24T10:36:48.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or905000dp0djdkz1c77u","content":"<p> <a href=\"https://arxiv.org/abs/1804.06215\">DetNet: A Backbone network for Object Detection</a><br><span id=\"more\"></span><br> ImageNet  finetune  backbone  backbone  RF FPN  RetinaNet extra stage DetNet backbone</p>\n<p>DetNet  FPN extra stage FPN  ImageNet DetNet  dilated bottleneck </p>\n<h1 id=\"DetNet\"><a href=\"#DetNet\" class=\"headerlink\" title=\"DetNet\"></a>DetNet</h1><p> 1(A)  FPN <br><img src=\"/images/DetNet_fig1.png\" alt=\"\"><center>A.  backbone  FPN B.  backboneC. DetNet  backbone FPN </center></p>\n<ol>\n<li> stage  5  stages stage  2 32  FPN  stages P6  RetinaNet  P6  P7</li>\n<li> 32  feature map FPN  layer </li>\n<li> FPN  layer  layer  layer  layer  1 A  layer  context </li>\n</ol>\n<p>DetNet </p>\n<ol>\n<li> stage </li>\n<li> stage  6~7  stage deep layer</li>\n</ol>\n<h2 id=\"DetNet-\"><a href=\"#DetNet-\" class=\"headerlink\" title=\"DetNet \"></a>DetNet </h2><p> ResNet-50  baseline ResNet-50  DetNet-59 ResNet-101  DetNetDetNet  stage 1,2,3,4  ResNet-50  stage 1,2,3,4  ResNet-50  stage </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">ResNet</th>\n<th style=\"text-align:center\">output size</th>\n<th style=\"text-align:center\">50-layer</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">conv1</td>\n<td style=\"text-align:center\">112x112</td>\n<td style=\"text-align:center\">7x7,64, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">maxpool</td>\n<td style=\"text-align:center\">56x56</td>\n<td style=\"text-align:center\">3x3, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">conv2_x</td>\n<td style=\"text-align:center\">56x56</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; 64 \\\\\\\\ 3 \\times 3 &amp; 64 \\\\\\\\ 1 \\times 1 &amp; 256\\end{bmatrix} \\times 3$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">conv3_x</td>\n<td style=\"text-align:center\">28x28</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; 128 \\\\\\\\ 3 \\times 3 &amp; 128 \\\\\\\\ 1 \\times 1 &amp; 512\\end{bmatrix} \\times 4$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">conv4_x</td>\n<td style=\"text-align:center\">14x14</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; 256 \\\\\\\\ 3 \\times 3 &amp; 256 \\\\\\\\ 1 \\times 1 &amp; 1024\\end{bmatrix} \\times 6$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p> stage  DetNet 2 D DetNet-59 <br><img src=\"/images/DetNet_fig2.png\" alt=\"\"><center>fig 2. DetNet </center></p>\n<ol>\n<li> backbone  extra stage P6 FPN  stage 4  16 stage </li>\n<li> stage 4  dilated bottleneck  1x1  stage  2 B</li>\n<li>bottleneck  dilated conv  dilated conv  stage 5  6  channel  stage 4 256 backbone  backbone  stage  channel  stage  ResNet-50  64-&gt;128-&gt;256-&gt;512</li>\n</ol>\n<p>DetNet  backbone / feature pyramid  FPN  backbone  FPN  stage 4  stage  stage 4,5,6  2 E</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1804.06215\">DetNet: A Backbone network for Object Detection</a><br>","more":"<br> ImageNet  finetune  backbone  backbone  RF FPN  RetinaNet extra stage DetNet backbone</p>\n<p>DetNet  FPN extra stage FPN  ImageNet DetNet  dilated bottleneck </p>\n<h1 id=\"DetNet\"><a href=\"#DetNet\" class=\"headerlink\" title=\"DetNet\"></a>DetNet</h1><p> 1(A)  FPN <br><img src=\"/images/DetNet_fig1.png\" alt=\"\"><center>A.  backbone  FPN B.  backboneC. DetNet  backbone FPN </center></p>\n<ol>\n<li> stage  5  stages stage  2 32  FPN  stages P6  RetinaNet  P6  P7</li>\n<li> 32  feature map FPN  layer </li>\n<li> FPN  layer  layer  layer  layer  1 A  layer  context </li>\n</ol>\n<p>DetNet </p>\n<ol>\n<li> stage </li>\n<li> stage  6~7  stage deep layer</li>\n</ol>\n<h2 id=\"DetNet-\"><a href=\"#DetNet-\" class=\"headerlink\" title=\"DetNet \"></a>DetNet </h2><p> ResNet-50  baseline ResNet-50  DetNet-59 ResNet-101  DetNetDetNet  stage 1,2,3,4  ResNet-50  stage 1,2,3,4  ResNet-50  stage </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">ResNet</th>\n<th style=\"text-align:center\">output size</th>\n<th style=\"text-align:center\">50-layer</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">conv1</td>\n<td style=\"text-align:center\">112x112</td>\n<td style=\"text-align:center\">7x7,64, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">maxpool</td>\n<td style=\"text-align:center\">56x56</td>\n<td style=\"text-align:center\">3x3, stride 2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">conv2_x</td>\n<td style=\"text-align:center\">56x56</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; 64 \\\\\\\\ 3 \\times 3 &amp; 64 \\\\\\\\ 1 \\times 1 &amp; 256\\end{bmatrix} \\times 3$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">conv3_x</td>\n<td style=\"text-align:center\">28x28</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; 128 \\\\\\\\ 3 \\times 3 &amp; 128 \\\\\\\\ 1 \\times 1 &amp; 512\\end{bmatrix} \\times 4$</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">conv4_x</td>\n<td style=\"text-align:center\">14x14</td>\n<td style=\"text-align:center\">$\\begin{bmatrix} 1 \\times 1 &amp; 256 \\\\\\\\ 3 \\times 3 &amp; 256 \\\\\\\\ 1 \\times 1 &amp; 1024\\end{bmatrix} \\times 6$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p> stage  DetNet 2 D DetNet-59 <br><img src=\"/images/DetNet_fig2.png\" alt=\"\"><center>fig 2. DetNet </center></p>\n<ol>\n<li> backbone  extra stage P6 FPN  stage 4  16 stage </li>\n<li> stage 4  dilated bottleneck  1x1  stage  2 B</li>\n<li>bottleneck  dilated conv  dilated conv  stage 5  6  channel  stage 4 256 backbone  backbone  stage  channel  stage  ResNet-50  64-&gt;128-&gt;256-&gt;512</li>\n</ol>\n<p>DetNet  backbone / feature pyramid  FPN  backbone  FPN  stage 4  stage  stage 4,5,6  2 E</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>"},{"title":"FSAF","date":"2019-06-27T01:14:42.000Z","mathjax":true,"_content":"[Feature Selective Anchor-Free Module for Single-Shot Object Detection](https://arxiv.org/pdf/1903.00621)\n<!-- more -->\nSOTA  feature pyramid  image pyramid feature pyramid  level  feature  anchor level  feature  anchor 2 level  feature  level  feature \n1. \n2.  overlap  anchor \n\n 1  level  feature  feature level  2  IoU  anchor \n\n![](/images/FSAF_fig2.png)\n\n feature selective anchor-free (FSAF) feature level 3\n\n![](/images/FSAF_fig3.png) <center>Fig 3 FSAF  anchor pyramid level</center>\n\n feature pyramid  level  anchor-free  anchor-based  3  level  anchor-free  box  feature level feature level Inference  FSAF  anchor-based anchor-free  FSAF  FSAF \n\n# FSAF \n FSAF  feature pyramid  single-shot  SSD, DSSD, RetinaNet FSAF  SOTA  RetinaNet\n1.  anchor-free \n2.  anchor-free GT target\n3.  feature level\n4. / anchor-free  anchor-based \n\n## \n 4  FSAF  RetinaNet Retina  backbone  backbone  feature pyramid level  $\\{P_l|l\\in [3,7]\\}$$P_l$  image  $1/2^l$  4  level  feature pyramid level  scale  feature level \n\n RetinaNetFSAF  feature level  4\n\n![](/images/FSAF_fig4.png)<center>Fig 4  FSAF  RetinaNet </center>\n\n anchor-free  3x3  K  sigmoid  anchor-based  K  3x3  4  ReLu  anchor-free  box anchor-free  anchor-based  level  feature\n\n## Ground-truth and Loss\n k  bbox  b=[x,y,w,h] feature level $P_l$  box  $b_p^l=[x_p^l,y_p^l,w_p^l,h_p^l]$ $P_l$  image  $1/2^l$ $b_p^l=b/2^l$ box $b_e^l=[x_e^l,y_e^l,w_e^l,h_e^l]$  ignore box $b_i^l=[x_i^l,y_i^l,w_i^l,h_i^l]$ $b_p^l$  $\\epsilon_e, \\ \\epsilon_i$\n$$x_e^l=x_p^l, \\ y_e^l=y_p^l, \\ w_e^l=\\epsilon_e w_p^l, \\ h_e^l=\\epsilon_e h_p^l\n\\\\\\\\x_i^l=x_p^l, \\ y_i^l=y_p^l, \\ w_i^l=\\epsilon_i w_p^l, \\ h_i^l=\\epsilon_i h_p^l$$\n [GA-RPN](/2019/06/25/GA-RPN)  anchor-free  GA-RPN  anchor-free  scale  aspect ratio  anchor anchor-free  anchor  shape  anchor-based  scale  aspect ratio\n\n 5  car  GT GT target\n\n![](/images/FSAF_fig5.png)\n\n____  GT output  K-channel maps map  k k  GT map \n-  $b_e^l$  1 5 \n-  $b_i^l - b_e^l$  5 \n-  feature level $b_i^{l-1}, b_i^{l+1}$ \n\n feature level \n\n box gt map  0 5  Focal loss\n$$FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log p_t\n\\\\\\\\p_t=\\begin{cases} p & y=1 \\\\\\\\1-p & y=0 \\end{cases}\n\\\\\\\\\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\\\\\1-\\alpha & y=0 \\end{cases}$$\nanchor-free  ignore box  focal loss  box \n\n__Box __  gt  4-channal maps 4  4K-channel  gt maps  $b_e^l$  $b_e^l$  (i,j) 4-d  $b_p^l$\n$$\\mathbf d_{i,j}^l=[d_{t_{i,j}}^l,d_{l_{i,j}}^l,d_{b_{i,j}}^l,d_{r_{i,j}}^l]$$\n $d_t^l,d_l^l,d_b^l,d_r^l$  (i,j)  $b_p^l$  top,left,bottom,right  [FCOS](FCOS)  anchor-free  (i,j)  4-d  $\\mathbf d_{i,j}^l/S$ S=4 box  IoU anchor-free  box  IoU  box  IoU \n$$L_{IoU}=-\\log IoU\n\\\\\\\\ IoU = \\frac {I(b_p,b_{gt})} {U(b_p,b_{gt})}$$\n UnitBox\n\nInference  box (i,j) $[\\hat o_{t_{i,j}},\\hat o_{l_{i,j}},\\hat o_{b_{i,j}},\\hat o_{r_{i,j}}]$ $[S\\hat o_{t_{i,j}},S\\hat o_{l_{i,j}},S\\hat o_{b_{i,j}},S\\hat o_{r_{i,j}}]$ $(i-S\\hat o_{t_{i,j}},j-S\\hat o_{l_{i,j}}), \\ (i+\\hat o_{b_{i,j}},j+\\hat o_{r_{i,j}})$ $2^l$  image  maps  (i,j)  K-d \n\n## \nFSAF  level  feature $P_l$ anchor-based  box \n\n $I$ $P_l$  $L_{FL}^I(l), \\ L_{IoU}^I(l)$\n$$L_{FL}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} FL(l,i,j)\n\\\\\\\\L_{IoU}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} IoU(l,i,j)$$\n$N(b_e^l)$  box  $I$ \n\n 6 \n\n![](/images/FSAF_fig6.png) <center>Fig 6 levelanchor-freegt target</center>\n\n $I$  feature pyramid anchor-free  $L_{FL}^I(l) + L_{IoU}^I(l)$  feature pyramid leve $P_l$\n$$l^*=\\arg \\min_l L_{FL}^I(l) + L_{IoU}^I(l)$$\n level  level Inference \n\n box size FPN  $I$  $P_{l'}$\n$$l' = \\lfloor l_0+\\log_2(\\sqrt{wh}/224) \\rfloor$$\n(w,h)  size224  ImageNet 224x224  $l_0$  target level  $P_l$  image  $1/2^l$\n$$ \\sqrt{wh}/2^{l'} \\approx 224/2^{l_0}$$\n scale  $1/2^l$  $l_0=5$ ResNet  conv5_x  feature map \n\n## Joint Inference and Training\n FSAF  RetinaNet  4 anchor-based \n\n__Inference:__ FSAF  anchor-free  pyramid level  0.05  top 1k  box level  box  anchor-based  box  NMSNMS  0.5\n\n____ backbone  ImageNet1k RetinaNet  layers  RetinaNet  layers FSAF   layers  $\\sigma=0.01$ bias  $-\\log((1-\\pi)/\\pi)$ $\\pi$  $\\pi$  RetineNet  $\\pi=0.01$ layers  b=0.1 $\\sigma=0.01$\n\n____  anchor-free  anchor-based  RetinaNet  $L^{ab}$ $L_{cls}^{af}, \\ L_{reg}^{af}$  anchor-free  $L=L^{ab}+\\lambda (L_{cls}^{af} + L_{reg}^{af})$ $\\lambda$  $\\lambda=0.5$\n\n# \n\n\n#\n feature pyramid  anchor-based single-shot  FSAF FSAF  anchor-free inference  SOTA single-shot ","source":"_posts/FSAF.md","raw":"---\ntitle: FSAF\ndate: 2019-06-27 09:14:42\ntags: object detection\nmathjax: true\n---\n[Feature Selective Anchor-Free Module for Single-Shot Object Detection](https://arxiv.org/pdf/1903.00621)\n<!-- more -->\nSOTA  feature pyramid  image pyramid feature pyramid  level  feature  anchor level  feature  anchor 2 level  feature  level  feature \n1. \n2.  overlap  anchor \n\n 1  level  feature  feature level  2  IoU  anchor \n\n![](/images/FSAF_fig2.png)\n\n feature selective anchor-free (FSAF) feature level 3\n\n![](/images/FSAF_fig3.png) <center>Fig 3 FSAF  anchor pyramid level</center>\n\n feature pyramid  level  anchor-free  anchor-based  3  level  anchor-free  box  feature level feature level Inference  FSAF  anchor-based anchor-free  FSAF  FSAF \n\n# FSAF \n FSAF  feature pyramid  single-shot  SSD, DSSD, RetinaNet FSAF  SOTA  RetinaNet\n1.  anchor-free \n2.  anchor-free GT target\n3.  feature level\n4. / anchor-free  anchor-based \n\n## \n 4  FSAF  RetinaNet Retina  backbone  backbone  feature pyramid level  $\\{P_l|l\\in [3,7]\\}$$P_l$  image  $1/2^l$  4  level  feature pyramid level  scale  feature level \n\n RetinaNetFSAF  feature level  4\n\n![](/images/FSAF_fig4.png)<center>Fig 4  FSAF  RetinaNet </center>\n\n anchor-free  3x3  K  sigmoid  anchor-based  K  3x3  4  ReLu  anchor-free  box anchor-free  anchor-based  level  feature\n\n## Ground-truth and Loss\n k  bbox  b=[x,y,w,h] feature level $P_l$  box  $b_p^l=[x_p^l,y_p^l,w_p^l,h_p^l]$ $P_l$  image  $1/2^l$ $b_p^l=b/2^l$ box $b_e^l=[x_e^l,y_e^l,w_e^l,h_e^l]$  ignore box $b_i^l=[x_i^l,y_i^l,w_i^l,h_i^l]$ $b_p^l$  $\\epsilon_e, \\ \\epsilon_i$\n$$x_e^l=x_p^l, \\ y_e^l=y_p^l, \\ w_e^l=\\epsilon_e w_p^l, \\ h_e^l=\\epsilon_e h_p^l\n\\\\\\\\x_i^l=x_p^l, \\ y_i^l=y_p^l, \\ w_i^l=\\epsilon_i w_p^l, \\ h_i^l=\\epsilon_i h_p^l$$\n [GA-RPN](/2019/06/25/GA-RPN)  anchor-free  GA-RPN  anchor-free  scale  aspect ratio  anchor anchor-free  anchor  shape  anchor-based  scale  aspect ratio\n\n 5  car  GT GT target\n\n![](/images/FSAF_fig5.png)\n\n____  GT output  K-channel maps map  k k  GT map \n-  $b_e^l$  1 5 \n-  $b_i^l - b_e^l$  5 \n-  feature level $b_i^{l-1}, b_i^{l+1}$ \n\n feature level \n\n box gt map  0 5  Focal loss\n$$FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log p_t\n\\\\\\\\p_t=\\begin{cases} p & y=1 \\\\\\\\1-p & y=0 \\end{cases}\n\\\\\\\\\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\\\\\1-\\alpha & y=0 \\end{cases}$$\nanchor-free  ignore box  focal loss  box \n\n__Box __  gt  4-channal maps 4  4K-channel  gt maps  $b_e^l$  $b_e^l$  (i,j) 4-d  $b_p^l$\n$$\\mathbf d_{i,j}^l=[d_{t_{i,j}}^l,d_{l_{i,j}}^l,d_{b_{i,j}}^l,d_{r_{i,j}}^l]$$\n $d_t^l,d_l^l,d_b^l,d_r^l$  (i,j)  $b_p^l$  top,left,bottom,right  [FCOS](FCOS)  anchor-free  (i,j)  4-d  $\\mathbf d_{i,j}^l/S$ S=4 box  IoU anchor-free  box  IoU  box  IoU \n$$L_{IoU}=-\\log IoU\n\\\\\\\\ IoU = \\frac {I(b_p,b_{gt})} {U(b_p,b_{gt})}$$\n UnitBox\n\nInference  box (i,j) $[\\hat o_{t_{i,j}},\\hat o_{l_{i,j}},\\hat o_{b_{i,j}},\\hat o_{r_{i,j}}]$ $[S\\hat o_{t_{i,j}},S\\hat o_{l_{i,j}},S\\hat o_{b_{i,j}},S\\hat o_{r_{i,j}}]$ $(i-S\\hat o_{t_{i,j}},j-S\\hat o_{l_{i,j}}), \\ (i+\\hat o_{b_{i,j}},j+\\hat o_{r_{i,j}})$ $2^l$  image  maps  (i,j)  K-d \n\n## \nFSAF  level  feature $P_l$ anchor-based  box \n\n $I$ $P_l$  $L_{FL}^I(l), \\ L_{IoU}^I(l)$\n$$L_{FL}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} FL(l,i,j)\n\\\\\\\\L_{IoU}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} IoU(l,i,j)$$\n$N(b_e^l)$  box  $I$ \n\n 6 \n\n![](/images/FSAF_fig6.png) <center>Fig 6 levelanchor-freegt target</center>\n\n $I$  feature pyramid anchor-free  $L_{FL}^I(l) + L_{IoU}^I(l)$  feature pyramid leve $P_l$\n$$l^*=\\arg \\min_l L_{FL}^I(l) + L_{IoU}^I(l)$$\n level  level Inference \n\n box size FPN  $I$  $P_{l'}$\n$$l' = \\lfloor l_0+\\log_2(\\sqrt{wh}/224) \\rfloor$$\n(w,h)  size224  ImageNet 224x224  $l_0$  target level  $P_l$  image  $1/2^l$\n$$ \\sqrt{wh}/2^{l'} \\approx 224/2^{l_0}$$\n scale  $1/2^l$  $l_0=5$ ResNet  conv5_x  feature map \n\n## Joint Inference and Training\n FSAF  RetinaNet  4 anchor-based \n\n__Inference:__ FSAF  anchor-free  pyramid level  0.05  top 1k  box level  box  anchor-based  box  NMSNMS  0.5\n\n____ backbone  ImageNet1k RetinaNet  layers  RetinaNet  layers FSAF   layers  $\\sigma=0.01$ bias  $-\\log((1-\\pi)/\\pi)$ $\\pi$  $\\pi$  RetineNet  $\\pi=0.01$ layers  b=0.1 $\\sigma=0.01$\n\n____  anchor-free  anchor-based  RetinaNet  $L^{ab}$ $L_{cls}^{af}, \\ L_{reg}^{af}$  anchor-free  $L=L^{ab}+\\lambda (L_{cls}^{af} + L_{reg}^{af})$ $\\lambda$  $\\lambda=0.5$\n\n# \n\n\n#\n feature pyramid  anchor-based single-shot  FSAF FSAF  anchor-free inference  SOTA single-shot ","slug":"FSAF","published":1,"updated":"2020-04-24T10:37:38.161Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or906000gp0dj4cr6bfwq","content":"<p><a href=\"https://arxiv.org/pdf/1903.00621\">Feature Selective Anchor-Free Module for Single-Shot Object Detection</a><br><span id=\"more\"></span><br>SOTA  feature pyramid  image pyramid feature pyramid  level  feature  anchor level  feature  anchor 2 level  feature  level  feature </p>\n<ol>\n<li></li>\n<li> overlap  anchor </li>\n</ol>\n<p> 1  level  feature  feature level  2  IoU  anchor </p>\n<p><img src=\"/images/FSAF_fig2.png\" alt=\"\"></p>\n<p> feature selective anchor-free (FSAF) feature level 3</p>\n<p><img src=\"/images/FSAF_fig3.png\" alt=\"\"> <center>Fig 3 FSAF  anchor pyramid level</center></p>\n<p> feature pyramid  level  anchor-free  anchor-based  3  level  anchor-free  box  feature level feature level Inference  FSAF  anchor-based anchor-free  FSAF  FSAF </p>\n<h1 id=\"FSAF-\"><a href=\"#FSAF-\" class=\"headerlink\" title=\"FSAF \"></a>FSAF </h1><p> FSAF  feature pyramid  single-shot  SSD, DSSD, RetinaNet FSAF  SOTA  RetinaNet</p>\n<ol>\n<li> anchor-free </li>\n<li> anchor-free GT target</li>\n<li> feature level</li>\n<li>/ anchor-free  anchor-based </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> 4  FSAF  RetinaNet Retina  backbone  backbone  feature pyramid level  $\\{P_l|l\\in [3,7]\\}$$P_l$  image  $1/2^l$  4  level  feature pyramid level  scale  feature level </p>\n<p> RetinaNetFSAF  feature level  4</p>\n<p><img src=\"/images/FSAF_fig4.png\" alt=\"\"><center>Fig 4  FSAF  RetinaNet </center></p>\n<p> anchor-free  3x3  K  sigmoid  anchor-based  K  3x3  4  ReLu  anchor-free  box anchor-free  anchor-based  level  feature</p>\n<h2 id=\"Ground-truth-and-Loss\"><a href=\"#Ground-truth-and-Loss\" class=\"headerlink\" title=\"Ground-truth and Loss\"></a>Ground-truth and Loss</h2><p> k  bbox  b=[x,y,w,h] feature level $P_l$  box  $b_p^l=[x_p^l,y_p^l,w_p^l,h_p^l]$ $P_l$  image  $1/2^l$ $b_p^l=b/2^l$ box $b_e^l=[x_e^l,y_e^l,w_e^l,h_e^l]$  ignore box $b_i^l=[x_i^l,y_i^l,w_i^l,h_i^l]$ $b_p^l$  $\\epsilon_e, \\ \\epsilon_i$</p>\n<script type=\"math/tex; mode=display\">x_e^l=x_p^l, \\ y_e^l=y_p^l, \\ w_e^l=\\epsilon_e w_p^l, \\ h_e^l=\\epsilon_e h_p^l\n\\\\\\\\x_i^l=x_p^l, \\ y_i^l=y_p^l, \\ w_i^l=\\epsilon_i w_p^l, \\ h_i^l=\\epsilon_i h_p^l</script><p> <a href=\"/2019/06/25/GA-RPN\">GA-RPN</a>  anchor-free  GA-RPN  anchor-free  scale  aspect ratio  anchor anchor-free  anchor  shape  anchor-based  scale  aspect ratio</p>\n<p> 5  car  GT GT target</p>\n<p><img src=\"/images/FSAF_fig5.png\" alt=\"\"></p>\n<p><strong></strong>  GT output  K-channel maps map  k k  GT map </p>\n<ul>\n<li> $b_e^l$  1 5 </li>\n<li> $b_i^l - b_e^l$  5 </li>\n<li> feature level $b_i^{l-1}, b_i^{l+1}$ </li>\n</ul>\n<p> feature level </p>\n<p> box gt map  0 5  Focal loss</p>\n<script type=\"math/tex; mode=display\">FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log p_t\n\\\\\\\\p_t=\\begin{cases} p & y=1 \\\\\\\\1-p & y=0 \\end{cases}\n\\\\\\\\\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\\\\\1-\\alpha & y=0 \\end{cases}</script><p>anchor-free  ignore box  focal loss  box </p>\n<p><strong>Box </strong>  gt  4-channal maps 4  4K-channel  gt maps  $b_e^l$  $b_e^l$  (i,j) 4-d  $b_p^l$</p>\n<script type=\"math/tex; mode=display\">\\mathbf d_{i,j}^l=[d_{t_{i,j}}^l,d_{l_{i,j}}^l,d_{b_{i,j}}^l,d_{r_{i,j}}^l]</script><p> $d_t^l,d_l^l,d_b^l,d_r^l$  (i,j)  $b_p^l$  top,left,bottom,right  <a href=\"FCOS\">FCOS</a>  anchor-free  (i,j)  4-d  $\\mathbf d_{i,j}^l/S$ S=4 box  IoU anchor-free  box  IoU  box  IoU </p>\n<script type=\"math/tex; mode=display\">L_{IoU}=-\\log IoU\n\\\\\\\\ IoU = \\frac {I(b_p,b_{gt})} {U(b_p,b_{gt})}</script><p> UnitBox</p>\n<p>Inference  box (i,j) $[\\hat o_{t_{i,j}},\\hat o_{l_{i,j}},\\hat o_{b_{i,j}},\\hat o_{r_{i,j}}]$ $[S\\hat o_{t_{i,j}},S\\hat o_{l_{i,j}},S\\hat o_{b_{i,j}},S\\hat o_{r_{i,j}}]$ $(i-S\\hat o_{t_{i,j}},j-S\\hat o_{l_{i,j}}), \\ (i+\\hat o_{b_{i,j}},j+\\hat o_{r_{i,j}})$ $2^l$  image  maps  (i,j)  K-d </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>FSAF  level  feature $P_l$ anchor-based  box </p>\n<p> $I$ $P_l$  $L_{FL}^I(l), \\ L_{IoU}^I(l)$</p>\n<script type=\"math/tex; mode=display\">L_{FL}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} FL(l,i,j)\n\\\\\\\\L_{IoU}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} IoU(l,i,j)</script><p>$N(b_e^l)$  box  $I$ </p>\n<p> 6 </p>\n<p><img src=\"/images/FSAF_fig6.png\" alt=\"\"> <center>Fig 6 levelanchor-freegt target</center></p>\n<p> $I$  feature pyramid anchor-free  $L_{FL}^I(l) + L_{IoU}^I(l)$  feature pyramid leve $P_l$</p>\n<script type=\"math/tex; mode=display\">l^*=\\arg \\min_l L_{FL}^I(l) + L_{IoU}^I(l)</script><p> level  level Inference </p>\n<p> box size FPN  $I$  $P_{l}$</p>\n<script type=\"math/tex; mode=display\">l' = \\lfloor l_0+\\log_2(\\sqrt{wh}/224) \\rfloor</script><p>(w,h)  size224  ImageNet 224x224  $l_0$  target level  $P_l$  image  $1/2^l$</p>\n<script type=\"math/tex; mode=display\">\\sqrt{wh}/2^{l'} \\approx 224/2^{l_0}</script><p> scale  $1/2^l$  $l_0=5$ ResNet  conv5_x  feature map </p>\n<h2 id=\"Joint-Inference-and-Training\"><a href=\"#Joint-Inference-and-Training\" class=\"headerlink\" title=\"Joint Inference and Training\"></a>Joint Inference and Training</h2><p> FSAF  RetinaNet  4 anchor-based </p>\n<p><strong>Inference:</strong> FSAF  anchor-free  pyramid level  0.05  top 1k  box level  box  anchor-based  box  NMSNMS  0.5</p>\n<p><strong></strong> backbone  ImageNet1k RetinaNet  layers  RetinaNet  layers FSAF   layers  $\\sigma=0.01$ bias  $-\\log((1-\\pi)/\\pi)$ $\\pi$  $\\pi$  RetineNet  $\\pi=0.01$ layers  b=0.1 $\\sigma=0.01$</p>\n<p><strong></strong>  anchor-free  anchor-based  RetinaNet  $L^{ab}$ $L_{cls}^{af}, \\ L_{reg}^{af}$  anchor-free  $L=L^{ab}+\\lambda (L_{cls}^{af} + L_{reg}^{af})$ $\\lambda$  $\\lambda=0.5$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> feature pyramid  anchor-based single-shot  FSAF FSAF  anchor-free inference  SOTA single-shot </p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://arxiv.org/pdf/1903.00621\">Feature Selective Anchor-Free Module for Single-Shot Object Detection</a><br>","more":"<br>SOTA  feature pyramid  image pyramid feature pyramid  level  feature  anchor level  feature  anchor 2 level  feature  level  feature </p>\n<ol>\n<li></li>\n<li> overlap  anchor </li>\n</ol>\n<p> 1  level  feature  feature level  2  IoU  anchor </p>\n<p><img src=\"/images/FSAF_fig2.png\" alt=\"\"></p>\n<p> feature selective anchor-free (FSAF) feature level 3</p>\n<p><img src=\"/images/FSAF_fig3.png\" alt=\"\"> <center>Fig 3 FSAF  anchor pyramid level</center></p>\n<p> feature pyramid  level  anchor-free  anchor-based  3  level  anchor-free  box  feature level feature level Inference  FSAF  anchor-based anchor-free  FSAF  FSAF </p>\n<h1 id=\"FSAF-\"><a href=\"#FSAF-\" class=\"headerlink\" title=\"FSAF \"></a>FSAF </h1><p> FSAF  feature pyramid  single-shot  SSD, DSSD, RetinaNet FSAF  SOTA  RetinaNet</p>\n<ol>\n<li> anchor-free </li>\n<li> anchor-free GT target</li>\n<li> feature level</li>\n<li>/ anchor-free  anchor-based </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> 4  FSAF  RetinaNet Retina  backbone  backbone  feature pyramid level  $\\{P_l|l\\in [3,7]\\}$$P_l$  image  $1/2^l$  4  level  feature pyramid level  scale  feature level </p>\n<p> RetinaNetFSAF  feature level  4</p>\n<p><img src=\"/images/FSAF_fig4.png\" alt=\"\"><center>Fig 4  FSAF  RetinaNet </center></p>\n<p> anchor-free  3x3  K  sigmoid  anchor-based  K  3x3  4  ReLu  anchor-free  box anchor-free  anchor-based  level  feature</p>\n<h2 id=\"Ground-truth-and-Loss\"><a href=\"#Ground-truth-and-Loss\" class=\"headerlink\" title=\"Ground-truth and Loss\"></a>Ground-truth and Loss</h2><p> k  bbox  b=[x,y,w,h] feature level $P_l$  box  $b_p^l=[x_p^l,y_p^l,w_p^l,h_p^l]$ $P_l$  image  $1/2^l$ $b_p^l=b/2^l$ box $b_e^l=[x_e^l,y_e^l,w_e^l,h_e^l]$  ignore box $b_i^l=[x_i^l,y_i^l,w_i^l,h_i^l]$ $b_p^l$  $\\epsilon_e, \\ \\epsilon_i$</p>\n<script type=\"math/tex; mode=display\">x_e^l=x_p^l, \\ y_e^l=y_p^l, \\ w_e^l=\\epsilon_e w_p^l, \\ h_e^l=\\epsilon_e h_p^l\n\\\\\\\\x_i^l=x_p^l, \\ y_i^l=y_p^l, \\ w_i^l=\\epsilon_i w_p^l, \\ h_i^l=\\epsilon_i h_p^l</script><p> <a href=\"/2019/06/25/GA-RPN\">GA-RPN</a>  anchor-free  GA-RPN  anchor-free  scale  aspect ratio  anchor anchor-free  anchor  shape  anchor-based  scale  aspect ratio</p>\n<p> 5  car  GT GT target</p>\n<p><img src=\"/images/FSAF_fig5.png\" alt=\"\"></p>\n<p><strong></strong>  GT output  K-channel maps map  k k  GT map </p>\n<ul>\n<li> $b_e^l$  1 5 </li>\n<li> $b_i^l - b_e^l$  5 </li>\n<li> feature level $b_i^{l-1}, b_i^{l+1}$ </li>\n</ul>\n<p> feature level </p>\n<p> box gt map  0 5  Focal loss</p>\n<script type=\"math/tex; mode=display\">FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log p_t\n\\\\\\\\p_t=\\begin{cases} p & y=1 \\\\\\\\1-p & y=0 \\end{cases}\n\\\\\\\\\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\\\\\1-\\alpha & y=0 \\end{cases}</script><p>anchor-free  ignore box  focal loss  box </p>\n<p><strong>Box </strong>  gt  4-channal maps 4  4K-channel  gt maps  $b_e^l$  $b_e^l$  (i,j) 4-d  $b_p^l$</p>\n<script type=\"math/tex; mode=display\">\\mathbf d_{i,j}^l=[d_{t_{i,j}}^l,d_{l_{i,j}}^l,d_{b_{i,j}}^l,d_{r_{i,j}}^l]</script><p> $d_t^l,d_l^l,d_b^l,d_r^l$  (i,j)  $b_p^l$  top,left,bottom,right  <a href=\"FCOS\">FCOS</a>  anchor-free  (i,j)  4-d  $\\mathbf d_{i,j}^l/S$ S=4 box  IoU anchor-free  box  IoU  box  IoU </p>\n<script type=\"math/tex; mode=display\">L_{IoU}=-\\log IoU\n\\\\\\\\ IoU = \\frac {I(b_p,b_{gt})} {U(b_p,b_{gt})}</script><p> UnitBox</p>\n<p>Inference  box (i,j) $[\\hat o_{t_{i,j}},\\hat o_{l_{i,j}},\\hat o_{b_{i,j}},\\hat o_{r_{i,j}}]$ $[S\\hat o_{t_{i,j}},S\\hat o_{l_{i,j}},S\\hat o_{b_{i,j}},S\\hat o_{r_{i,j}}]$ $(i-S\\hat o_{t_{i,j}},j-S\\hat o_{l_{i,j}}), \\ (i+\\hat o_{b_{i,j}},j+\\hat o_{r_{i,j}})$ $2^l$  image  maps  (i,j)  K-d </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>FSAF  level  feature $P_l$ anchor-based  box </p>\n<p> $I$ $P_l$  $L_{FL}^I(l), \\ L_{IoU}^I(l)$</p>\n<script type=\"math/tex; mode=display\">L_{FL}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} FL(l,i,j)\n\\\\\\\\L_{IoU}^I(l)=\\frac 1 {N(b_e^l)} \\sum_{i,j \\in b_e^l} IoU(l,i,j)</script><p>$N(b_e^l)$  box  $I$ </p>\n<p> 6 </p>\n<p><img src=\"/images/FSAF_fig6.png\" alt=\"\"> <center>Fig 6 levelanchor-freegt target</center></p>\n<p> $I$  feature pyramid anchor-free  $L_{FL}^I(l) + L_{IoU}^I(l)$  feature pyramid leve $P_l$</p>\n<script type=\"math/tex; mode=display\">l^*=\\arg \\min_l L_{FL}^I(l) + L_{IoU}^I(l)</script><p> level  level Inference </p>\n<p> box size FPN  $I$  $P_{l}$</p>\n<script type=\"math/tex; mode=display\">l' = \\lfloor l_0+\\log_2(\\sqrt{wh}/224) \\rfloor</script><p>(w,h)  size224  ImageNet 224x224  $l_0$  target level  $P_l$  image  $1/2^l$</p>\n<script type=\"math/tex; mode=display\">\\sqrt{wh}/2^{l'} \\approx 224/2^{l_0}</script><p> scale  $1/2^l$  $l_0=5$ ResNet  conv5_x  feature map </p>\n<h2 id=\"Joint-Inference-and-Training\"><a href=\"#Joint-Inference-and-Training\" class=\"headerlink\" title=\"Joint Inference and Training\"></a>Joint Inference and Training</h2><p> FSAF  RetinaNet  4 anchor-based </p>\n<p><strong>Inference:</strong> FSAF  anchor-free  pyramid level  0.05  top 1k  box level  box  anchor-based  box  NMSNMS  0.5</p>\n<p><strong></strong> backbone  ImageNet1k RetinaNet  layers  RetinaNet  layers FSAF   layers  $\\sigma=0.01$ bias  $-\\log((1-\\pi)/\\pi)$ $\\pi$  $\\pi$  RetineNet  $\\pi=0.01$ layers  b=0.1 $\\sigma=0.01$</p>\n<p><strong></strong>  anchor-free  anchor-based  RetinaNet  $L^{ab}$ $L_{cls}^{af}, \\ L_{reg}^{af}$  anchor-free  $L=L^{ab}+\\lambda (L_{cls}^{af} + L_{reg}^{af})$ $\\lambda$  $\\lambda=0.5$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> feature pyramid  anchor-based single-shot  FSAF FSAF  anchor-free inference  SOTA single-shot </p>"},{"title":"GA-RPN","date":"2019-06-25T09:01:57.000Z","mathjax":true,"_content":"[Region Proposal by Guided Anchoring](https://arxiv.org/abs/1901.03278)\n<!-- more -->\n anchor  proposaltwo-stage anchor one-stage two-stage  Faster R-CNN  feature map  anchors proposals proposals \n\n anchor alignment  consistency\n1. anchor  feature map \n2.  RF  anchor \n\n anchor  anchors feature map  scale  aspect ratio  k  anchors anchor \n1.  scale  aspect ratio\n2.  recall anchors anchors non-object anchors \n\n anchor \n1. image \n2.  scale  image \n   \n anchor guided anchoring\n1. \n2.  shape\n\n anchor shape  consistency  anchor shape  RF   scope  scale  aspect ratio  feature map  anchor shape  anchor shape  consistency  anchor shape  features  feature adaptation \n\n guided anchoring  feature adaptation  Guided Anchoring Region Proposal Network GP-RPN anchorsrecall  RPNbaseline anchor 9.1% anchors  90% scale  aspect ratio  aspect ratio  1/2   2 / region proposals guided anchoring  anchor  SSD anchor  boxguided anchoring  COCO  GA-Fast-RCNNGA-Faster-RCNN  GA-RetinaNet  mAP  baseline  2.2%, 2.7%  1.2%\n\n# Guided Anchoring\n location  shape  (x,y,w,h)  (x,y) (w,h)  image $I$ location  shape \n$$p(x,y,w,h|I)=p(x,y|I)p(w,h|x,y,I)$$\n\n1.  image\n2. shape  scale  aspect ratio  anchor \n   \n anchor  1\n\n![](/images/GA-RPN_fig1.png) <center>Fig 1 feature map  anchor  anchor  shape feature  feature map  feature map anchor</center>\n\n image $I$ feature map $F_I$ $F_I$   mapshape  shape w,h shape anchor anchor  shape  feature  anchor shape  feature \n\n leve  feature maps  FPN  RetinaNet 1 level  anchor  level  anchor \n\n## Anchor \nanchor  map $p(\\cdot|F_I)$  feature map $F_I$  $p(i,j|F_I)$  image $I$  $((i+\\frac 1 2)s,(j+\\frac 1 2)s)$ s   $F_I$  $I$  anchor $p(i,j|F_I)$  $F_I$  (i,j) \n\n $\\mathcal N_L$  $p(i,j|F_I)$$\\mathcal N_L$  1x1  element-wise  sigmoid  $\\mathcal N_L$  $\\mathcal N_L$ \n\n $\\epsilon_L$ map  region anchor  shape region 90%  region  recall RPN  4(b) region  region masked convolution \n\n## Anchor shape \n anchor  anchor  shape 1 bbox  anchor  alignment  $F_I$ shape (w,h) shape  anchor  gt box \n\n w,h  [-1,1] \n$$w=\\sigma \\cdot s \\cdot e^{dw}, \\quad h = \\sigma \\cdot s \\cdot e^{dh}$$\n shape  (dw,dh) s  $F_I$  $I$ $\\sigma$  $\\sigma=8$ $\\mathcal N_S$  shape $\\mathcal N_S$  1x1  2  element-wise  2  dw map  dh map w map  h map\n\n anchor  anchor  anchor  anchor shape  scale  aspect ratio  k  anchor anchor shape  location  recall aspect ratio  shape anchor \n\n## Anchor-Guided \n RPN  one-stage  anchors  feature map  anchor  shape/scale  feature map  anchor  shape  feature map  anchor  RPN  one-stage  anchor  feature  region  anchor  feature  anchor-guided  anchor shape  feature \n$$\\mathbf f_i'= \\mathcal N_T(\\mathbf f_i, w_i,h_i)$$\n$\\mathbf f_i$   i  feature$(w_i,h_i)$  anchor shape 3x3  $\\mathcal N_T$ 1 anchor shape  offset feature map  feature map  bbox \n\n## \n### \n anchor  shape \n$$\\mathcal L=\\lambda_1 \\mathcal L_{loc}+ \\lambda_2 \\mathcal L_{shape} + \\mathcal L_{cls} + \\mathcal L_{reg}$$\n\n### Anchor location targets\n anchor  image   label map 1 0  label map  gt box  anchor anchor gt box $(x_g,y_g,w_g,h_g)$  feature map $F_I$ $(x_g',y_g',w_g',h_g')$ $\\mathcal R(x,y,w,h)$ Anchors  gt box  IOU gt box \n1.  \n   \n   $CR=\\mathcal R(x_g',y_g',\\sigma_1 w_g', \\sigma_1 h_g')$ gt box  gt box  $\\sigma_1$ CR  1positive\n\n2. \n   \n   $IR=\\mathcal R(x_g',y_g',\\sigma_2 w_g', \\sigma_2 h_g') \\setminus CR$$\\sigma_2 > \\sigma_1$IR  `ignore` Faster R-CNN  RPNanchor  gt box  IOU  0.7  1 positive 0.3  0 negative `[0.3,0.7]`  -1 -1  anchor \n\n3. \n   \n   $OR=F_I \\setminus IR$OR  0negative\n\n level features level  feature map  scale  feature map  scale  CR IR  2 CR  IR IR  OR CR, IR, OR  recall CR  feature map  Focal Loss  anchor \n![](/images/GA-RPN_fig2.png)\n\n### Anchor shape targets\n\n shape target\n1.  anchor  gt box \n2.  anchor  gt box\n\nFaster R-CNN  anchor  IOU  gt box anchor  gt box  $(t_x,t_y,t_w,t_h)$  target anchor  $(x,y,w,h)$ \n\n anchor  anchor  w,h  shape  $(w_p,h_p)$  target $(t_w,t_h)$  anchor  $a_{\\mathbf {wh}}=\\{(x_0,y_0,w,h)|w>0,h>0\\}$  gt box $gt=(x_g,y_g,w_g,h_g)$  IoU  vIoU\n$$\\text{vIoU}(a_{\\mathbf {wh}},gt)=\\max_{w>0,h>0} IoU_{normal}(a_{wh},gt)$$\n anchor  $(x_0,y_0)$  gt box $gt$ $(x_0,y_0)$ w  h  w  h  w  h anchor  gt box  IoU IoU  $\\text{vIoU}(a_{\\mathbf {wh}}, gt)$  9  (w,h)  vIoU 9  (w,h)  RetinaNet  scales  aspect ratios  (w,h)  vIoU  bounded iou loss  shape \n$$\\mathcal L_{shape}=\\mathcal L_1(1-\\min(\\frac w {w_g}, \\frac {w_g} w)) + \\mathcal L_1 (1-\\min(\\frac h {h_g}, \\frac {h_g} h))$$\n (w,h)  anchor shape(w<sub>g</sub>,h<sub>g</sub>)  anchor  vIoU  gt box  shape $\\min(\\frac w {w_g}, \\frac {w_g} w)$  $\\min(\\frac h {h_g}, \\frac {h_g} h)$ w  w<sub>g</sub>h  h<sub>g</sub>\n\n\n1.  9  (w,h)\n2.  (x<sub>0</sub>,y<sub>0</sub>) anchor  gt box  vIoU vIoU  9  (w,h)\n3.  vIoU  gt box  anchor \n4. shape  (w,h)  anchor  gt box  (w<sub>g</sub>,h<sub>g</sub>)  shape \n\n shape  (w,h)  gt box  IoU IoU  gt box  anchor  gt box \n\n shape  (w,h)  gt box anchor  gt box  anchor  target \n\n##  proposals\n guided anchoring  RPNGA-RPN proposals proposals two-stage  RPN  GA-RPN  proposals  IoU  3\n![](/images/GA-RPN_fig3.png) <center>Fig 3  IoU  proposals </center>\n\n RPNGA-RPN \n1.  proposals \n2.  IoU  proposals \n\n RPN  GA-RPN  1  proposals  proposal \n\nGA-RPN  two-stage  proposal  RPN GA-RPN proposals  epochs 3  epochsGA-RPN proposals  inference epochs\n\n![](/images/GA-RPN_fig4.png)\n\n# \n\n\n# \n Guided Anchoring  shape  anchor","source":"_posts/GA-RPN.md","raw":"---\ntitle: GA-RPN\ndate: 2019-06-25 17:01:57\ntags: object detection\nmathjax: true\n---\n[Region Proposal by Guided Anchoring](https://arxiv.org/abs/1901.03278)\n<!-- more -->\n anchor  proposaltwo-stage anchor one-stage two-stage  Faster R-CNN  feature map  anchors proposals proposals \n\n anchor alignment  consistency\n1. anchor  feature map \n2.  RF  anchor \n\n anchor  anchors feature map  scale  aspect ratio  k  anchors anchor \n1.  scale  aspect ratio\n2.  recall anchors anchors non-object anchors \n\n anchor \n1. image \n2.  scale  image \n   \n anchor guided anchoring\n1. \n2.  shape\n\n anchor shape  consistency  anchor shape  RF   scope  scale  aspect ratio  feature map  anchor shape  anchor shape  consistency  anchor shape  features  feature adaptation \n\n guided anchoring  feature adaptation  Guided Anchoring Region Proposal Network GP-RPN anchorsrecall  RPNbaseline anchor 9.1% anchors  90% scale  aspect ratio  aspect ratio  1/2   2 / region proposals guided anchoring  anchor  SSD anchor  boxguided anchoring  COCO  GA-Fast-RCNNGA-Faster-RCNN  GA-RetinaNet  mAP  baseline  2.2%, 2.7%  1.2%\n\n# Guided Anchoring\n location  shape  (x,y,w,h)  (x,y) (w,h)  image $I$ location  shape \n$$p(x,y,w,h|I)=p(x,y|I)p(w,h|x,y,I)$$\n\n1.  image\n2. shape  scale  aspect ratio  anchor \n   \n anchor  1\n\n![](/images/GA-RPN_fig1.png) <center>Fig 1 feature map  anchor  anchor  shape feature  feature map  feature map anchor</center>\n\n image $I$ feature map $F_I$ $F_I$   mapshape  shape w,h shape anchor anchor  shape  feature  anchor shape  feature \n\n leve  feature maps  FPN  RetinaNet 1 level  anchor  level  anchor \n\n## Anchor \nanchor  map $p(\\cdot|F_I)$  feature map $F_I$  $p(i,j|F_I)$  image $I$  $((i+\\frac 1 2)s,(j+\\frac 1 2)s)$ s   $F_I$  $I$  anchor $p(i,j|F_I)$  $F_I$  (i,j) \n\n $\\mathcal N_L$  $p(i,j|F_I)$$\\mathcal N_L$  1x1  element-wise  sigmoid  $\\mathcal N_L$  $\\mathcal N_L$ \n\n $\\epsilon_L$ map  region anchor  shape region 90%  region  recall RPN  4(b) region  region masked convolution \n\n## Anchor shape \n anchor  anchor  shape 1 bbox  anchor  alignment  $F_I$ shape (w,h) shape  anchor  gt box \n\n w,h  [-1,1] \n$$w=\\sigma \\cdot s \\cdot e^{dw}, \\quad h = \\sigma \\cdot s \\cdot e^{dh}$$\n shape  (dw,dh) s  $F_I$  $I$ $\\sigma$  $\\sigma=8$ $\\mathcal N_S$  shape $\\mathcal N_S$  1x1  2  element-wise  2  dw map  dh map w map  h map\n\n anchor  anchor  anchor  anchor shape  scale  aspect ratio  k  anchor anchor shape  location  recall aspect ratio  shape anchor \n\n## Anchor-Guided \n RPN  one-stage  anchors  feature map  anchor  shape/scale  feature map  anchor  shape  feature map  anchor  RPN  one-stage  anchor  feature  region  anchor  feature  anchor-guided  anchor shape  feature \n$$\\mathbf f_i'= \\mathcal N_T(\\mathbf f_i, w_i,h_i)$$\n$\\mathbf f_i$   i  feature$(w_i,h_i)$  anchor shape 3x3  $\\mathcal N_T$ 1 anchor shape  offset feature map  feature map  bbox \n\n## \n### \n anchor  shape \n$$\\mathcal L=\\lambda_1 \\mathcal L_{loc}+ \\lambda_2 \\mathcal L_{shape} + \\mathcal L_{cls} + \\mathcal L_{reg}$$\n\n### Anchor location targets\n anchor  image   label map 1 0  label map  gt box  anchor anchor gt box $(x_g,y_g,w_g,h_g)$  feature map $F_I$ $(x_g',y_g',w_g',h_g')$ $\\mathcal R(x,y,w,h)$ Anchors  gt box  IOU gt box \n1.  \n   \n   $CR=\\mathcal R(x_g',y_g',\\sigma_1 w_g', \\sigma_1 h_g')$ gt box  gt box  $\\sigma_1$ CR  1positive\n\n2. \n   \n   $IR=\\mathcal R(x_g',y_g',\\sigma_2 w_g', \\sigma_2 h_g') \\setminus CR$$\\sigma_2 > \\sigma_1$IR  `ignore` Faster R-CNN  RPNanchor  gt box  IOU  0.7  1 positive 0.3  0 negative `[0.3,0.7]`  -1 -1  anchor \n\n3. \n   \n   $OR=F_I \\setminus IR$OR  0negative\n\n level features level  feature map  scale  feature map  scale  CR IR  2 CR  IR IR  OR CR, IR, OR  recall CR  feature map  Focal Loss  anchor \n![](/images/GA-RPN_fig2.png)\n\n### Anchor shape targets\n\n shape target\n1.  anchor  gt box \n2.  anchor  gt box\n\nFaster R-CNN  anchor  IOU  gt box anchor  gt box  $(t_x,t_y,t_w,t_h)$  target anchor  $(x,y,w,h)$ \n\n anchor  anchor  w,h  shape  $(w_p,h_p)$  target $(t_w,t_h)$  anchor  $a_{\\mathbf {wh}}=\\{(x_0,y_0,w,h)|w>0,h>0\\}$  gt box $gt=(x_g,y_g,w_g,h_g)$  IoU  vIoU\n$$\\text{vIoU}(a_{\\mathbf {wh}},gt)=\\max_{w>0,h>0} IoU_{normal}(a_{wh},gt)$$\n anchor  $(x_0,y_0)$  gt box $gt$ $(x_0,y_0)$ w  h  w  h  w  h anchor  gt box  IoU IoU  $\\text{vIoU}(a_{\\mathbf {wh}}, gt)$  9  (w,h)  vIoU 9  (w,h)  RetinaNet  scales  aspect ratios  (w,h)  vIoU  bounded iou loss  shape \n$$\\mathcal L_{shape}=\\mathcal L_1(1-\\min(\\frac w {w_g}, \\frac {w_g} w)) + \\mathcal L_1 (1-\\min(\\frac h {h_g}, \\frac {h_g} h))$$\n (w,h)  anchor shape(w<sub>g</sub>,h<sub>g</sub>)  anchor  vIoU  gt box  shape $\\min(\\frac w {w_g}, \\frac {w_g} w)$  $\\min(\\frac h {h_g}, \\frac {h_g} h)$ w  w<sub>g</sub>h  h<sub>g</sub>\n\n\n1.  9  (w,h)\n2.  (x<sub>0</sub>,y<sub>0</sub>) anchor  gt box  vIoU vIoU  9  (w,h)\n3.  vIoU  gt box  anchor \n4. shape  (w,h)  anchor  gt box  (w<sub>g</sub>,h<sub>g</sub>)  shape \n\n shape  (w,h)  gt box  IoU IoU  gt box  anchor  gt box \n\n shape  (w,h)  gt box anchor  gt box  anchor  target \n\n##  proposals\n guided anchoring  RPNGA-RPN proposals proposals two-stage  RPN  GA-RPN  proposals  IoU  3\n![](/images/GA-RPN_fig3.png) <center>Fig 3  IoU  proposals </center>\n\n RPNGA-RPN \n1.  proposals \n2.  IoU  proposals \n\n RPN  GA-RPN  1  proposals  proposal \n\nGA-RPN  two-stage  proposal  RPN GA-RPN proposals  epochs 3  epochsGA-RPN proposals  inference epochs\n\n![](/images/GA-RPN_fig4.png)\n\n# \n\n\n# \n Guided Anchoring  shape  anchor","slug":"GA-RPN","published":1,"updated":"2020-04-24T10:37:42.094Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or907000ip0dj5aw3al7i","content":"<p><a href=\"https://arxiv.org/abs/1901.03278\">Region Proposal by Guided Anchoring</a><br><span id=\"more\"></span><br> anchor  proposaltwo-stage anchor one-stage two-stage  Faster R-CNN  feature map  anchors proposals proposals </p>\n<p> anchor alignment  consistency</p>\n<ol>\n<li>anchor  feature map </li>\n<li> RF  anchor </li>\n</ol>\n<p> anchor  anchors feature map  scale  aspect ratio  k  anchors anchor </p>\n<ol>\n<li> scale  aspect ratio</li>\n<li> recall anchors anchors non-object anchors </li>\n</ol>\n<p> anchor </p>\n<ol>\n<li>image </li>\n<li> scale  image </li>\n</ol>\n<p> anchor guided anchoring</p>\n<ol>\n<li></li>\n<li> shape</li>\n</ol>\n<p> anchor shape  consistency  anchor shape  RF   scope  scale  aspect ratio  feature map  anchor shape  anchor shape  consistency  anchor shape  features  feature adaptation </p>\n<p> guided anchoring  feature adaptation  Guided Anchoring Region Proposal Network GP-RPN anchorsrecall  RPNbaseline anchor 9.1% anchors  90% scale  aspect ratio  aspect ratio  1/2   2 / region proposals guided anchoring  anchor  SSD anchor  boxguided anchoring  COCO  GA-Fast-RCNNGA-Faster-RCNN  GA-RetinaNet  mAP  baseline  2.2%, 2.7%  1.2%</p>\n<h1 id=\"Guided-Anchoring\"><a href=\"#Guided-Anchoring\" class=\"headerlink\" title=\"Guided Anchoring\"></a>Guided Anchoring</h1><p> location  shape  (x,y,w,h)  (x,y) (w,h)  image $I$ location  shape </p>\n<script type=\"math/tex; mode=display\">p(x,y,w,h|I)=p(x,y|I)p(w,h|x,y,I)</script><p></p>\n<ol>\n<li> image</li>\n<li>shape  scale  aspect ratio  anchor </li>\n</ol>\n<p> anchor  1</p>\n<p><img src=\"/images/GA-RPN_fig1.png\" alt=\"\"> <center>Fig 1 feature map  anchor  anchor  shape feature  feature map  feature map anchor</center></p>\n<p> image $I$ feature map $F_I$ $F_I$   mapshape  shape w,h shape anchor anchor  shape  feature  anchor shape  feature </p>\n<p> leve  feature maps  FPN  RetinaNet 1 level  anchor  level  anchor </p>\n<h2 id=\"Anchor-\"><a href=\"#Anchor-\" class=\"headerlink\" title=\"Anchor \"></a>Anchor </h2><p>anchor  map $p(\\cdot|F_I)$  feature map $F_I$  $p(i,j|F_I)$  image $I$  $((i+\\frac 1 2)s,(j+\\frac 1 2)s)$ s   $F_I$  $I$  anchor $p(i,j|F_I)$  $F_I$  (i,j) </p>\n<p> $\\mathcal N_L$  $p(i,j|F_I)$$\\mathcal N_L$  1x1  element-wise  sigmoid  $\\mathcal N_L$  $\\mathcal N_L$ </p>\n<p> $\\epsilon_L$ map  region anchor  shape region 90%  region  recall RPN  4(b) region  region masked convolution </p>\n<h2 id=\"Anchor-shape-\"><a href=\"#Anchor-shape-\" class=\"headerlink\" title=\"Anchor shape \"></a>Anchor shape </h2><p> anchor  anchor  shape 1 bbox  anchor  alignment  $F_I$ shape (w,h) shape  anchor  gt box </p>\n<p> w,h  [-1,1] </p>\n<script type=\"math/tex; mode=display\">w=\\sigma \\cdot s \\cdot e^{dw}, \\quad h = \\sigma \\cdot s \\cdot e^{dh}</script><p> shape  (dw,dh) s  $F_I$  $I$ $\\sigma$  $\\sigma=8$ $\\mathcal N_S$  shape $\\mathcal N_S$  1x1  2  element-wise  2  dw map  dh map w map  h map</p>\n<p> anchor  anchor  anchor  anchor shape  scale  aspect ratio  k  anchor anchor shape  location  recall aspect ratio  shape anchor </p>\n<h2 id=\"Anchor-Guided-\"><a href=\"#Anchor-Guided-\" class=\"headerlink\" title=\"Anchor-Guided \"></a>Anchor-Guided </h2><p> RPN  one-stage  anchors  feature map  anchor  shape/scale  feature map  anchor  shape  feature map  anchor  RPN  one-stage  anchor  feature  region  anchor  feature  anchor-guided  anchor shape  feature </p>\n<script type=\"math/tex; mode=display\">\\mathbf f_i'= \\mathcal N_T(\\mathbf f_i, w_i,h_i)</script><p>$\\mathbf f_i$   i  feature$(w_i,h_i)$  anchor shape 3x3  $\\mathcal N_T$ 1 anchor shape  offset feature map  feature map  bbox </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> anchor  shape </p>\n<script type=\"math/tex; mode=display\">\\mathcal L=\\lambda_1 \\mathcal L_{loc}+ \\lambda_2 \\mathcal L_{shape} + \\mathcal L_{cls} + \\mathcal L_{reg}</script><h3 id=\"Anchor-location-targets\"><a href=\"#Anchor-location-targets\" class=\"headerlink\" title=\"Anchor location targets\"></a>Anchor location targets</h3><p> anchor  image   label map 1 0  label map  gt box  anchor anchor gt box $(x_g,y_g,w_g,h_g)$  feature map $F_I$ $(x_g,y_g,w_g,h_g)$ $\\mathcal R(x,y,w,h)$ Anchors  gt box  IOU gt box </p>\n<ol>\n<li><p> </p>\n<p>$CR=\\mathcal R(x_g,y_g,\\sigma_1 w_g, \\sigma_1 h_g)$ gt box  gt box  $\\sigma_1$ CR  1positive</p>\n</li>\n<li><p></p>\n<p>$IR=\\mathcal R(x_g,y_g,\\sigma_2 w_g, \\sigma_2 h_g) \\setminus CR$$\\sigma_2 &gt; \\sigma_1$IR  <code>ignore</code> Faster R-CNN  RPNanchor  gt box  IOU  0.7  1 positive 0.3  0 negative <code>[0.3,0.7]</code>  -1 -1  anchor </p>\n</li>\n<li><p></p>\n<p>$OR=F_I \\setminus IR$OR  0negative</p>\n</li>\n</ol>\n<p> level features level  feature map  scale  feature map  scale  CR IR  2 CR  IR IR  OR CR, IR, OR  recall CR  feature map  Focal Loss  anchor <br><img src=\"/images/GA-RPN_fig2.png\" alt=\"\"></p>\n<h3 id=\"Anchor-shape-targets\"><a href=\"#Anchor-shape-targets\" class=\"headerlink\" title=\"Anchor shape targets\"></a>Anchor shape targets</h3><p> shape target</p>\n<ol>\n<li> anchor  gt box </li>\n<li> anchor  gt box</li>\n</ol>\n<p>Faster R-CNN  anchor  IOU  gt box anchor  gt box  $(t_x,t_y,t_w,t_h)$  target anchor  $(x,y,w,h)$ </p>\n<p> anchor  anchor  w,h  shape  $(w_p,h_p)$  target $(t_w,t_h)$  anchor  $a_{\\mathbf {wh}}=\\{(x_0,y_0,w,h)|w&gt;0,h&gt;0\\}$  gt box $gt=(x_g,y_g,w_g,h_g)$  IoU  vIoU</p>\n<script type=\"math/tex; mode=display\">\\text{vIoU}(a_{\\mathbf {wh}},gt)=\\max_{w>0,h>0} IoU_{normal}(a_{wh},gt)</script><p> anchor  $(x_0,y_0)$  gt box $gt$ $(x_0,y_0)$ w  h  w  h  w  h anchor  gt box  IoU IoU  $\\text{vIoU}(a_{\\mathbf {wh}}, gt)$  9  (w,h)  vIoU 9  (w,h)  RetinaNet  scales  aspect ratios  (w,h)  vIoU  bounded iou loss  shape </p>\n<script type=\"math/tex; mode=display\">\\mathcal L_{shape}=\\mathcal L_1(1-\\min(\\frac w {w_g}, \\frac {w_g} w)) + \\mathcal L_1 (1-\\min(\\frac h {h_g}, \\frac {h_g} h))</script><p> (w,h)  anchor shape(w<sub>g</sub>,h<sub>g</sub>)  anchor  vIoU  gt box  shape $\\min(\\frac w {w_g}, \\frac {w_g} w)$  $\\min(\\frac h {h_g}, \\frac {h_g} h)$ w  w<sub>g</sub>h  h<sub>g</sub></p>\n<p></p>\n<ol>\n<li> 9  (w,h)</li>\n<li> (x<sub>0</sub>,y<sub>0</sub>) anchor  gt box  vIoU vIoU  9  (w,h)</li>\n<li> vIoU  gt box  anchor </li>\n<li>shape  (w,h)  anchor  gt box  (w<sub>g</sub>,h<sub>g</sub>)  shape </li>\n</ol>\n<p> shape  (w,h)  gt box  IoU IoU  gt box  anchor  gt box </p>\n<p> shape  (w,h)  gt box anchor  gt box  anchor  target </p>\n<h2 id=\"-proposals\"><a href=\"#-proposals\" class=\"headerlink\" title=\" proposals\"></a> proposals</h2><p> guided anchoring  RPNGA-RPN proposals proposals two-stage  RPN  GA-RPN  proposals  IoU  3<br><img src=\"/images/GA-RPN_fig3.png\" alt=\"\"> <center>Fig 3  IoU  proposals </center></p>\n<p> RPNGA-RPN </p>\n<ol>\n<li> proposals </li>\n<li> IoU  proposals </li>\n</ol>\n<p> RPN  GA-RPN  1  proposals  proposal </p>\n<p>GA-RPN  two-stage  proposal  RPN GA-RPN proposals  epochs 3  epochsGA-RPN proposals  inference epochs</p>\n<p><img src=\"/images/GA-RPN_fig4.png\" alt=\"\"></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Guided Anchoring  shape  anchor</p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://arxiv.org/abs/1901.03278\">Region Proposal by Guided Anchoring</a><br>","more":"<br> anchor  proposaltwo-stage anchor one-stage two-stage  Faster R-CNN  feature map  anchors proposals proposals </p>\n<p> anchor alignment  consistency</p>\n<ol>\n<li>anchor  feature map </li>\n<li> RF  anchor </li>\n</ol>\n<p> anchor  anchors feature map  scale  aspect ratio  k  anchors anchor </p>\n<ol>\n<li> scale  aspect ratio</li>\n<li> recall anchors anchors non-object anchors </li>\n</ol>\n<p> anchor </p>\n<ol>\n<li>image </li>\n<li> scale  image </li>\n</ol>\n<p> anchor guided anchoring</p>\n<ol>\n<li></li>\n<li> shape</li>\n</ol>\n<p> anchor shape  consistency  anchor shape  RF   scope  scale  aspect ratio  feature map  anchor shape  anchor shape  consistency  anchor shape  features  feature adaptation </p>\n<p> guided anchoring  feature adaptation  Guided Anchoring Region Proposal Network GP-RPN anchorsrecall  RPNbaseline anchor 9.1% anchors  90% scale  aspect ratio  aspect ratio  1/2   2 / region proposals guided anchoring  anchor  SSD anchor  boxguided anchoring  COCO  GA-Fast-RCNNGA-Faster-RCNN  GA-RetinaNet  mAP  baseline  2.2%, 2.7%  1.2%</p>\n<h1 id=\"Guided-Anchoring\"><a href=\"#Guided-Anchoring\" class=\"headerlink\" title=\"Guided Anchoring\"></a>Guided Anchoring</h1><p> location  shape  (x,y,w,h)  (x,y) (w,h)  image $I$ location  shape </p>\n<script type=\"math/tex; mode=display\">p(x,y,w,h|I)=p(x,y|I)p(w,h|x,y,I)</script><p></p>\n<ol>\n<li> image</li>\n<li>shape  scale  aspect ratio  anchor </li>\n</ol>\n<p> anchor  1</p>\n<p><img src=\"/images/GA-RPN_fig1.png\" alt=\"\"> <center>Fig 1 feature map  anchor  anchor  shape feature  feature map  feature map anchor</center></p>\n<p> image $I$ feature map $F_I$ $F_I$   mapshape  shape w,h shape anchor anchor  shape  feature  anchor shape  feature </p>\n<p> leve  feature maps  FPN  RetinaNet 1 level  anchor  level  anchor </p>\n<h2 id=\"Anchor-\"><a href=\"#Anchor-\" class=\"headerlink\" title=\"Anchor \"></a>Anchor </h2><p>anchor  map $p(\\cdot|F_I)$  feature map $F_I$  $p(i,j|F_I)$  image $I$  $((i+\\frac 1 2)s,(j+\\frac 1 2)s)$ s   $F_I$  $I$  anchor $p(i,j|F_I)$  $F_I$  (i,j) </p>\n<p> $\\mathcal N_L$  $p(i,j|F_I)$$\\mathcal N_L$  1x1  element-wise  sigmoid  $\\mathcal N_L$  $\\mathcal N_L$ </p>\n<p> $\\epsilon_L$ map  region anchor  shape region 90%  region  recall RPN  4(b) region  region masked convolution </p>\n<h2 id=\"Anchor-shape-\"><a href=\"#Anchor-shape-\" class=\"headerlink\" title=\"Anchor shape \"></a>Anchor shape </h2><p> anchor  anchor  shape 1 bbox  anchor  alignment  $F_I$ shape (w,h) shape  anchor  gt box </p>\n<p> w,h  [-1,1] </p>\n<script type=\"math/tex; mode=display\">w=\\sigma \\cdot s \\cdot e^{dw}, \\quad h = \\sigma \\cdot s \\cdot e^{dh}</script><p> shape  (dw,dh) s  $F_I$  $I$ $\\sigma$  $\\sigma=8$ $\\mathcal N_S$  shape $\\mathcal N_S$  1x1  2  element-wise  2  dw map  dh map w map  h map</p>\n<p> anchor  anchor  anchor  anchor shape  scale  aspect ratio  k  anchor anchor shape  location  recall aspect ratio  shape anchor </p>\n<h2 id=\"Anchor-Guided-\"><a href=\"#Anchor-Guided-\" class=\"headerlink\" title=\"Anchor-Guided \"></a>Anchor-Guided </h2><p> RPN  one-stage  anchors  feature map  anchor  shape/scale  feature map  anchor  shape  feature map  anchor  RPN  one-stage  anchor  feature  region  anchor  feature  anchor-guided  anchor shape  feature </p>\n<script type=\"math/tex; mode=display\">\\mathbf f_i'= \\mathcal N_T(\\mathbf f_i, w_i,h_i)</script><p>$\\mathbf f_i$   i  feature$(w_i,h_i)$  anchor shape 3x3  $\\mathcal N_T$ 1 anchor shape  offset feature map  feature map  bbox </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> anchor  shape </p>\n<script type=\"math/tex; mode=display\">\\mathcal L=\\lambda_1 \\mathcal L_{loc}+ \\lambda_2 \\mathcal L_{shape} + \\mathcal L_{cls} + \\mathcal L_{reg}</script><h3 id=\"Anchor-location-targets\"><a href=\"#Anchor-location-targets\" class=\"headerlink\" title=\"Anchor location targets\"></a>Anchor location targets</h3><p> anchor  image   label map 1 0  label map  gt box  anchor anchor gt box $(x_g,y_g,w_g,h_g)$  feature map $F_I$ $(x_g,y_g,w_g,h_g)$ $\\mathcal R(x,y,w,h)$ Anchors  gt box  IOU gt box </p>\n<ol>\n<li><p> </p>\n<p>$CR=\\mathcal R(x_g,y_g,\\sigma_1 w_g, \\sigma_1 h_g)$ gt box  gt box  $\\sigma_1$ CR  1positive</p>\n</li>\n<li><p></p>\n<p>$IR=\\mathcal R(x_g,y_g,\\sigma_2 w_g, \\sigma_2 h_g) \\setminus CR$$\\sigma_2 &gt; \\sigma_1$IR  <code>ignore</code> Faster R-CNN  RPNanchor  gt box  IOU  0.7  1 positive 0.3  0 negative <code>[0.3,0.7]</code>  -1 -1  anchor </p>\n</li>\n<li><p></p>\n<p>$OR=F_I \\setminus IR$OR  0negative</p>\n</li>\n</ol>\n<p> level features level  feature map  scale  feature map  scale  CR IR  2 CR  IR IR  OR CR, IR, OR  recall CR  feature map  Focal Loss  anchor <br><img src=\"/images/GA-RPN_fig2.png\" alt=\"\"></p>\n<h3 id=\"Anchor-shape-targets\"><a href=\"#Anchor-shape-targets\" class=\"headerlink\" title=\"Anchor shape targets\"></a>Anchor shape targets</h3><p> shape target</p>\n<ol>\n<li> anchor  gt box </li>\n<li> anchor  gt box</li>\n</ol>\n<p>Faster R-CNN  anchor  IOU  gt box anchor  gt box  $(t_x,t_y,t_w,t_h)$  target anchor  $(x,y,w,h)$ </p>\n<p> anchor  anchor  w,h  shape  $(w_p,h_p)$  target $(t_w,t_h)$  anchor  $a_{\\mathbf {wh}}=\\{(x_0,y_0,w,h)|w&gt;0,h&gt;0\\}$  gt box $gt=(x_g,y_g,w_g,h_g)$  IoU  vIoU</p>\n<script type=\"math/tex; mode=display\">\\text{vIoU}(a_{\\mathbf {wh}},gt)=\\max_{w>0,h>0} IoU_{normal}(a_{wh},gt)</script><p> anchor  $(x_0,y_0)$  gt box $gt$ $(x_0,y_0)$ w  h  w  h  w  h anchor  gt box  IoU IoU  $\\text{vIoU}(a_{\\mathbf {wh}}, gt)$  9  (w,h)  vIoU 9  (w,h)  RetinaNet  scales  aspect ratios  (w,h)  vIoU  bounded iou loss  shape </p>\n<script type=\"math/tex; mode=display\">\\mathcal L_{shape}=\\mathcal L_1(1-\\min(\\frac w {w_g}, \\frac {w_g} w)) + \\mathcal L_1 (1-\\min(\\frac h {h_g}, \\frac {h_g} h))</script><p> (w,h)  anchor shape(w<sub>g</sub>,h<sub>g</sub>)  anchor  vIoU  gt box  shape $\\min(\\frac w {w_g}, \\frac {w_g} w)$  $\\min(\\frac h {h_g}, \\frac {h_g} h)$ w  w<sub>g</sub>h  h<sub>g</sub></p>\n<p></p>\n<ol>\n<li> 9  (w,h)</li>\n<li> (x<sub>0</sub>,y<sub>0</sub>) anchor  gt box  vIoU vIoU  9  (w,h)</li>\n<li> vIoU  gt box  anchor </li>\n<li>shape  (w,h)  anchor  gt box  (w<sub>g</sub>,h<sub>g</sub>)  shape </li>\n</ol>\n<p> shape  (w,h)  gt box  IoU IoU  gt box  anchor  gt box </p>\n<p> shape  (w,h)  gt box anchor  gt box  anchor  target </p>\n<h2 id=\"-proposals\"><a href=\"#-proposals\" class=\"headerlink\" title=\" proposals\"></a> proposals</h2><p> guided anchoring  RPNGA-RPN proposals proposals two-stage  RPN  GA-RPN  proposals  IoU  3<br><img src=\"/images/GA-RPN_fig3.png\" alt=\"\"> <center>Fig 3  IoU  proposals </center></p>\n<p> RPNGA-RPN </p>\n<ol>\n<li> proposals </li>\n<li> IoU  proposals </li>\n</ol>\n<p> RPN  GA-RPN  1  proposals  proposal </p>\n<p>GA-RPN  two-stage  proposal  RPN GA-RPN proposals  epochs 3  epochsGA-RPN proposals  inference epochs</p>\n<p><img src=\"/images/GA-RPN_fig4.png\" alt=\"\"></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Guided Anchoring  shape  anchor</p>"},{"title":"Grid-RCNN","date":"2019-07-19T09:44:19.000Z","mathjax":true,"_content":"# Grid R-CNN\n [Grid R-CNN](https://arxiv.org/abs/1811.12030)\n\n [Grid R-CNN](https://github.com/STVIR/Grid-R-CNN)\n<!-- more -->\n## 1. \n conv  fc  4 x,y,w,h  4*(C+1) fc \n![](/images/Grid-RCNN_fig1.png)\n\n Grid R-CNN R-CNN  R-CNN  1  grid points  RoI  FCN  grid points\n1. FCN  RoI  grid points\n2.  grid points  bboxExtremeNet  CornerNet  grid points  3x3  1(b)top-middle\n\n grid points  grid point  feature maps grid point grid point  feature maps  grid point  feature map feature map  grid point \n\n## 2. Grid R-CNN\n 2  region proposals RoIAlign  RoI  FCN  feature maps sigmoid probability heatmapheatmaps  target map  grid points 2.1 2.2 \n![](/images/Grid-RCNN_fig2.png)\n\n### 2.1 Grid Guided Localization\n NxN  grid points  bbox  3x3  grid points  bbox \n\n RoIAlign  RoI  14x14  feature 8  3x3  2x  56x56  feature NxN pixel-wise  sigmoid  NxN  heatmap heatmap  feature map  grid point supervision map supervision map  target grid point  5  $t_i=1$ $t_i=0$target grid point  supervision map  2.3  binary cross-entropy loss $CE=\\sum_{i=1}^{56 \\times 56} [-t_i\\log p_i-(1-t_i)\\log(1-p_i)]$ $p_i$  pixel \n\nInference  heatmap  $(H_x,H_y)$ image  $(I_x,I_y)$\n$$I_x=P_x+ \\frac {H_x}{w_o} w_p\n\\\\\\\\ I_y=P_y+ \\frac {H_y}{h_o} h_p$$\n $(P_x,P_y)$  region proposal  image $(w_p,h_p)$  proposal $(w_o,h_o)$  heatmap  ____ heatmap  proposal    \n grid points  bbox  $B=(x_l,y_u,x_r,y_b)$ j  grid point  $g_j$ $(x_j,y_j)$ $p_j$ j  heatmap  $E_i$  i  grid points  $g_j$   i  $j \\in E_i$ grid points  B\n$$x_l=\\frac 1 N \\sum_{j \\in E_1} x_j p_j, \\quad y_u=\\frac 1 N \\sum_{j \\in E_2} y_j p_j\n\\\\\\\\ x_r=\\frac 1 N \\sum_{j \\in E_3} x_j p_j, \\quad y_b=\\frac 1 N \\sum_{j \\in E_4} y_j p_j$$\n\n### 2.2 Grid Points Feature Fusion\n FCN  heatmap  RoI  grid points  3x3 grid points  point grid points  feature maps \n\n grid points  feature maps NxN  filters  feature map  grid points  feature map  grid point  i  point  feature map  $F_i$\n\n grid point L1  1  points  points  source points $S_i$ $S_i$  point j feature maps $F_j$  5x5  $T_{j \\rightarrow i}$$S_i$  source points  features  $F_i$  $F_i'$\n$$F_i'=F_i + \\sum_{j \\in S_i} T_{j \\rightarrow i} (F_j)$$\n![](/images/Grid-RCNN_fig3.png)\n\n 3(a)  point  $F_i'$  source point  $F_i'$  $T_{j \\rightarrow i}^+$ $F_i''$ heatmap grid point  L1  2  points  features  grid point  3(b)\n\n____  feature maps  sigmoid  heatmaps supervision maps  loss Binary Cross-Entropy Loss\n\n### 2.3 Extended Region Mapping\nGrid  heatmap  pixel  grid point  RoI  FCN heatmap  region proposal  image region proposal  gt grid point  region proposal  supervision map  target grid point inference  heatmap  pixel  grid point region proposal  grid point  gt grid points  region proposals  4proposal gt box 9  grid points  7  heatmap \n\n proposal gt grid points  proposal    proposal  heatmap  image  region  proposal RoI  feature map  region  proposal heatmap  region  grid points  4  supervision map  heatmap  gt box  supervision map  gt grid point  pixels gt grid point  pixels 5  pixels \n![](/images/Grid-RCNN_fig4.png)\n\n\n$$I_x'=P_x+\\frac {4H_x-w_o}{2w_o}w_p\n\\\\\\\\ I_y'=P_y+\\frac {4H_y-h_o}{2h_o}h_p$$\n\n 4   \n heatmap  image  region proposal  R' $(I_x,I_y)$ \n$$I_x'=P_x'+\\frac {H_x}{w_o} 2 w_p, \\quad I_y'=P_y'+\\frac {H_y}{h_o} 2 h_p$$\n $(P_x',P_y')$  R'  image  proposal \n$$2(x_c-P_x)=x_c-P_x'=w_p, \\quad 2(y_c-P_y)=y_c-P_y'=h_p$$\n $(x_c,y_c)$  proposal  R'  image \n\n### 2.4 Implementation Details\n\n\n# Grid R-CNN Plus\n [Grid R-CNN Plus: Faster and Better](https://arxiv.org/abs/1906.05688)\n\n Grid R-CNN  two-stage  mAP Grid R-CNN  inference  Grid R-CNN Plus\n\n Grid R-CNN Plus grid pointGrid R-CNN  supervision map grid point  supervision map  Grid R-CNN Plus  1/4  grid  feature maps  grid point  1/4grid point \n\nNMS \n\n##  Grid R-CNN\n 1  Grid R-CNN  two-stage Grid R-CNN  RPN  R-CNN region propopsals RoIAlign  CNN backbone  feature maps  RoI  RoI  bbox Grid R-CNN  R-CNN  grid points Grid  FCN  heatmaps heatmaps  grid points\n![](/images/Grid-RCNN-Plus_fig1.png)\n\nGrid R-CNN  8  3x3  2x  heatmap RPN  1000  proposals NMS  top 100  proposals grid \n\n grid points  gt grid points  proposal \n\n## Grid R-CNN Plus\n### Grid Point \n IoU > 0.5  proposals Grid  supervision map  gt grid point  2  grid point  gt label  3x3 grid points  point  gt label  supervision map  grid points  scale  center pixel  grid point \n![](/images/Grid-RCNN-Plus_fig2.png)\n\n grid point  56x56 28x28 1/4 heatmap Grid point  2  point   point  gt label \n\n### Light Grid Head\n heatmap  grid  features  14x14  7x7 RoIAlign  RoI  14x14  3x3 stride=2  size  7x7 7  3x3 stride=1  7x7 N  9 grid point grid points  2  2x  28x28  heatmaps\n\ngrid point  grid points  grid points  Grid R-CNN Plus  5x5 depth-wise depth-wise  Grid R-CNN  5x5  grid \n\n### \ngrid branch IoU > 0.5  positive proposals grid  Grid R-CNN Plus  96  192 \n\n###  NMS\nGrid R-CNN proposals  IoU  0.5  NMS top 125  proposals  grid  NMS  NMS  proposals 80 COCO  NMS  Grid R-CNN Plus  NMS\n\n## \n","source":"_posts/Grid-RCNN.md","raw":"---\ntitle: Grid-RCNN\ndate: 2019-07-19 17:44:19\ntags: object detection\nmathjax: true\n---\n# Grid R-CNN\n [Grid R-CNN](https://arxiv.org/abs/1811.12030)\n\n [Grid R-CNN](https://github.com/STVIR/Grid-R-CNN)\n<!-- more -->\n## 1. \n conv  fc  4 x,y,w,h  4*(C+1) fc \n![](/images/Grid-RCNN_fig1.png)\n\n Grid R-CNN R-CNN  R-CNN  1  grid points  RoI  FCN  grid points\n1. FCN  RoI  grid points\n2.  grid points  bboxExtremeNet  CornerNet  grid points  3x3  1(b)top-middle\n\n grid points  grid point  feature maps grid point grid point  feature maps  grid point  feature map feature map  grid point \n\n## 2. Grid R-CNN\n 2  region proposals RoIAlign  RoI  FCN  feature maps sigmoid probability heatmapheatmaps  target map  grid points 2.1 2.2 \n![](/images/Grid-RCNN_fig2.png)\n\n### 2.1 Grid Guided Localization\n NxN  grid points  bbox  3x3  grid points  bbox \n\n RoIAlign  RoI  14x14  feature 8  3x3  2x  56x56  feature NxN pixel-wise  sigmoid  NxN  heatmap heatmap  feature map  grid point supervision map supervision map  target grid point  5  $t_i=1$ $t_i=0$target grid point  supervision map  2.3  binary cross-entropy loss $CE=\\sum_{i=1}^{56 \\times 56} [-t_i\\log p_i-(1-t_i)\\log(1-p_i)]$ $p_i$  pixel \n\nInference  heatmap  $(H_x,H_y)$ image  $(I_x,I_y)$\n$$I_x=P_x+ \\frac {H_x}{w_o} w_p\n\\\\\\\\ I_y=P_y+ \\frac {H_y}{h_o} h_p$$\n $(P_x,P_y)$  region proposal  image $(w_p,h_p)$  proposal $(w_o,h_o)$  heatmap  ____ heatmap  proposal    \n grid points  bbox  $B=(x_l,y_u,x_r,y_b)$ j  grid point  $g_j$ $(x_j,y_j)$ $p_j$ j  heatmap  $E_i$  i  grid points  $g_j$   i  $j \\in E_i$ grid points  B\n$$x_l=\\frac 1 N \\sum_{j \\in E_1} x_j p_j, \\quad y_u=\\frac 1 N \\sum_{j \\in E_2} y_j p_j\n\\\\\\\\ x_r=\\frac 1 N \\sum_{j \\in E_3} x_j p_j, \\quad y_b=\\frac 1 N \\sum_{j \\in E_4} y_j p_j$$\n\n### 2.2 Grid Points Feature Fusion\n FCN  heatmap  RoI  grid points  3x3 grid points  point grid points  feature maps \n\n grid points  feature maps NxN  filters  feature map  grid points  feature map  grid point  i  point  feature map  $F_i$\n\n grid point L1  1  points  points  source points $S_i$ $S_i$  point j feature maps $F_j$  5x5  $T_{j \\rightarrow i}$$S_i$  source points  features  $F_i$  $F_i'$\n$$F_i'=F_i + \\sum_{j \\in S_i} T_{j \\rightarrow i} (F_j)$$\n![](/images/Grid-RCNN_fig3.png)\n\n 3(a)  point  $F_i'$  source point  $F_i'$  $T_{j \\rightarrow i}^+$ $F_i''$ heatmap grid point  L1  2  points  features  grid point  3(b)\n\n____  feature maps  sigmoid  heatmaps supervision maps  loss Binary Cross-Entropy Loss\n\n### 2.3 Extended Region Mapping\nGrid  heatmap  pixel  grid point  RoI  FCN heatmap  region proposal  image region proposal  gt grid point  region proposal  supervision map  target grid point inference  heatmap  pixel  grid point region proposal  grid point  gt grid points  region proposals  4proposal gt box 9  grid points  7  heatmap \n\n proposal gt grid points  proposal    proposal  heatmap  image  region  proposal RoI  feature map  region  proposal heatmap  region  grid points  4  supervision map  heatmap  gt box  supervision map  gt grid point  pixels gt grid point  pixels 5  pixels \n![](/images/Grid-RCNN_fig4.png)\n\n\n$$I_x'=P_x+\\frac {4H_x-w_o}{2w_o}w_p\n\\\\\\\\ I_y'=P_y+\\frac {4H_y-h_o}{2h_o}h_p$$\n\n 4   \n heatmap  image  region proposal  R' $(I_x,I_y)$ \n$$I_x'=P_x'+\\frac {H_x}{w_o} 2 w_p, \\quad I_y'=P_y'+\\frac {H_y}{h_o} 2 h_p$$\n $(P_x',P_y')$  R'  image  proposal \n$$2(x_c-P_x)=x_c-P_x'=w_p, \\quad 2(y_c-P_y)=y_c-P_y'=h_p$$\n $(x_c,y_c)$  proposal  R'  image \n\n### 2.4 Implementation Details\n\n\n# Grid R-CNN Plus\n [Grid R-CNN Plus: Faster and Better](https://arxiv.org/abs/1906.05688)\n\n Grid R-CNN  two-stage  mAP Grid R-CNN  inference  Grid R-CNN Plus\n\n Grid R-CNN Plus grid pointGrid R-CNN  supervision map grid point  supervision map  Grid R-CNN Plus  1/4  grid  feature maps  grid point  1/4grid point \n\nNMS \n\n##  Grid R-CNN\n 1  Grid R-CNN  two-stage Grid R-CNN  RPN  R-CNN region propopsals RoIAlign  CNN backbone  feature maps  RoI  RoI  bbox Grid R-CNN  R-CNN  grid points Grid  FCN  heatmaps heatmaps  grid points\n![](/images/Grid-RCNN-Plus_fig1.png)\n\nGrid R-CNN  8  3x3  2x  heatmap RPN  1000  proposals NMS  top 100  proposals grid \n\n grid points  gt grid points  proposal \n\n## Grid R-CNN Plus\n### Grid Point \n IoU > 0.5  proposals Grid  supervision map  gt grid point  2  grid point  gt label  3x3 grid points  point  gt label  supervision map  grid points  scale  center pixel  grid point \n![](/images/Grid-RCNN-Plus_fig2.png)\n\n grid point  56x56 28x28 1/4 heatmap Grid point  2  point   point  gt label \n\n### Light Grid Head\n heatmap  grid  features  14x14  7x7 RoIAlign  RoI  14x14  3x3 stride=2  size  7x7 7  3x3 stride=1  7x7 N  9 grid point grid points  2  2x  28x28  heatmaps\n\ngrid point  grid points  grid points  Grid R-CNN Plus  5x5 depth-wise depth-wise  Grid R-CNN  5x5  grid \n\n### \ngrid branch IoU > 0.5  positive proposals grid  Grid R-CNN Plus  96  192 \n\n###  NMS\nGrid R-CNN proposals  IoU  0.5  NMS top 125  proposals  grid  NMS  NMS  proposals 80 COCO  NMS  Grid R-CNN Plus  NMS\n\n## \n","slug":"Grid-RCNN","published":1,"updated":"2020-04-24T10:38:03.391Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or909000lp0dj4tor7hps","content":"<h1 id=\"Grid-R-CNN\"><a href=\"#Grid-R-CNN\" class=\"headerlink\" title=\"Grid R-CNN\"></a>Grid R-CNN</h1><p> <a href=\"https://arxiv.org/abs/1811.12030\">Grid R-CNN</a></p>\n<p> <a href=\"https://github.com/STVIR/Grid-R-CNN\">Grid R-CNN</a><br><span id=\"more\"></span></p>\n<h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p> conv  fc  4 x,y,w,h  4*(C+1) fc <br><img src=\"/images/Grid-RCNN_fig1.png\" alt=\"\"></p>\n<p> Grid R-CNN R-CNN  R-CNN  1  grid points  RoI  FCN  grid points</p>\n<ol>\n<li>FCN  RoI  grid points</li>\n<li> grid points  bboxExtremeNet  CornerNet  grid points  3x3  1(b)top-middle</li>\n</ol>\n<p> grid points  grid point  feature maps grid point grid point  feature maps  grid point  feature map feature map  grid point </p>\n<h2 id=\"2-Grid-R-CNN\"><a href=\"#2-Grid-R-CNN\" class=\"headerlink\" title=\"2. Grid R-CNN\"></a>2. Grid R-CNN</h2><p> 2  region proposals RoIAlign  RoI  FCN  feature maps sigmoid probability heatmapheatmaps  target map  grid points 2.1 2.2 <br><img src=\"/images/Grid-RCNN_fig2.png\" alt=\"\"></p>\n<h3 id=\"2-1-Grid-Guided-Localization\"><a href=\"#2-1-Grid-Guided-Localization\" class=\"headerlink\" title=\"2.1 Grid Guided Localization\"></a>2.1 Grid Guided Localization</h3><p> NxN  grid points  bbox  3x3  grid points  bbox </p>\n<p> RoIAlign  RoI  14x14  feature 8  3x3  2x  56x56  feature NxN pixel-wise  sigmoid  NxN  heatmap heatmap  feature map  grid point supervision map supervision map  target grid point  5  $t_i=1$ $t_i=0$target grid point  supervision map  2.3  binary cross-entropy loss $CE=\\sum_{i=1}^{56 \\times 56} [-t_i\\log p_i-(1-t_i)\\log(1-p_i)]$ $p_i$  pixel </p>\n<p>Inference  heatmap  $(H_x,H_y)$ image  $(I_x,I_y)$</p>\n<script type=\"math/tex; mode=display\">I_x=P_x+ \\frac {H_x}{w_o} w_p\n\\\\\\\\ I_y=P_y+ \\frac {H_y}{h_o} h_p</script><p> $(P_x,P_y)$  region proposal  image $(w_p,h_p)$  proposal $(w_o,h_o)$  heatmap  <strong></strong> heatmap  proposal <br> grid points  bbox  $B=(x_l,y_u,x_r,y_b)$ j  grid point  $g_j$ $(x_j,y_j)$ $p_j$ j  heatmap  $E_i$  i  grid points  $g_j$   i  $j \\in E_i$ grid points  B</p>\n<script type=\"math/tex; mode=display\">x_l=\\frac 1 N \\sum_{j \\in E_1} x_j p_j, \\quad y_u=\\frac 1 N \\sum_{j \\in E_2} y_j p_j\n\\\\\\\\ x_r=\\frac 1 N \\sum_{j \\in E_3} x_j p_j, \\quad y_b=\\frac 1 N \\sum_{j \\in E_4} y_j p_j</script><h3 id=\"2-2-Grid-Points-Feature-Fusion\"><a href=\"#2-2-Grid-Points-Feature-Fusion\" class=\"headerlink\" title=\"2.2 Grid Points Feature Fusion\"></a>2.2 Grid Points Feature Fusion</h3><p> FCN  heatmap  RoI  grid points  3x3 grid points  point grid points  feature maps </p>\n<p> grid points  feature maps NxN  filters  feature map  grid points  feature map  grid point  i  point  feature map  $F_i$</p>\n<p> grid point L1  1  points  points  source points $S_i$ $S_i$  point j feature maps $F_j$  5x5  $T_{j \\rightarrow i}$$S_i$  source points  features  $F_i$  $F_i$</p>\n<script type=\"math/tex; mode=display\">F_i'=F_i + \\sum_{j \\in S_i} T_{j \\rightarrow i} (F_j)</script><p><img src=\"/images/Grid-RCNN_fig3.png\" alt=\"\"></p>\n<p> 3(a)  point  $F_i$  source point  $F_i$  $T_{j \\rightarrow i}^+$ $F_i$ heatmap grid point  L1  2  points  features  grid point  3(b)</p>\n<p><strong></strong>  feature maps  sigmoid  heatmaps supervision maps  loss Binary Cross-Entropy Loss</p>\n<h3 id=\"2-3-Extended-Region-Mapping\"><a href=\"#2-3-Extended-Region-Mapping\" class=\"headerlink\" title=\"2.3 Extended Region Mapping\"></a>2.3 Extended Region Mapping</h3><p>Grid  heatmap  pixel  grid point  RoI  FCN heatmap  region proposal  image region proposal  gt grid point  region proposal  supervision map  target grid point inference  heatmap  pixel  grid point region proposal  grid point  gt grid points  region proposals  4proposal gt box 9  grid points  7  heatmap </p>\n<p> proposal gt grid points  proposal    proposal  heatmap  image  region  proposal RoI  feature map  region  proposal heatmap  region  grid points  4  supervision map  heatmap  gt box  supervision map  gt grid point  pixels gt grid point  pixels 5  pixels <br><img src=\"/images/Grid-RCNN_fig4.png\" alt=\"\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">I_x'=P_x+\\frac {4H_x-w_o}{2w_o}w_p\n\\\\\\\\ I_y'=P_y+\\frac {4H_y-h_o}{2h_o}h_p</script><p> 4 <br> heatmap  image  region proposal  R $(I_x,I_y)$ </p>\n<script type=\"math/tex; mode=display\">I_x'=P_x'+\\frac {H_x}{w_o} 2 w_p, \\quad I_y'=P_y'+\\frac {H_y}{h_o} 2 h_p</script><p> $(P_x,P_y)$  R  image  proposal </p>\n<script type=\"math/tex; mode=display\">2(x_c-P_x)=x_c-P_x'=w_p, \\quad 2(y_c-P_y)=y_c-P_y'=h_p</script><p> $(x_c,y_c)$  proposal  R  image </p>\n<h3 id=\"2-4-Implementation-Details\"><a href=\"#2-4-Implementation-Details\" class=\"headerlink\" title=\"2.4 Implementation Details\"></a>2.4 Implementation Details</h3><p></p>\n<h1 id=\"Grid-R-CNN-Plus\"><a href=\"#Grid-R-CNN-Plus\" class=\"headerlink\" title=\"Grid R-CNN Plus\"></a>Grid R-CNN Plus</h1><p> <a href=\"https://arxiv.org/abs/1906.05688\">Grid R-CNN Plus: Faster and Better</a></p>\n<p> Grid R-CNN  two-stage  mAP Grid R-CNN  inference  Grid R-CNN Plus</p>\n<p> Grid R-CNN Plus grid pointGrid R-CNN  supervision map grid point  supervision map  Grid R-CNN Plus  1/4  grid  feature maps  grid point  1/4grid point </p>\n<p>NMS </p>\n<h2 id=\"-Grid-R-CNN\"><a href=\"#-Grid-R-CNN\" class=\"headerlink\" title=\" Grid R-CNN\"></a> Grid R-CNN</h2><p> 1  Grid R-CNN  two-stage Grid R-CNN  RPN  R-CNN region propopsals RoIAlign  CNN backbone  feature maps  RoI  RoI  bbox Grid R-CNN  R-CNN  grid points Grid  FCN  heatmaps heatmaps  grid points<br><img src=\"/images/Grid-RCNN-Plus_fig1.png\" alt=\"\"></p>\n<p>Grid R-CNN  8  3x3  2x  heatmap RPN  1000  proposals NMS  top 100  proposals grid </p>\n<p> grid points  gt grid points  proposal </p>\n<h2 id=\"Grid-R-CNN-Plus-1\"><a href=\"#Grid-R-CNN-Plus-1\" class=\"headerlink\" title=\"Grid R-CNN Plus\"></a>Grid R-CNN Plus</h2><h3 id=\"Grid-Point-\"><a href=\"#Grid-Point-\" class=\"headerlink\" title=\"Grid Point \"></a>Grid Point </h3><p> IoU &gt; 0.5  proposals Grid  supervision map  gt grid point  2  grid point  gt label  3x3 grid points  point  gt label  supervision map  grid points  scale  center pixel  grid point <br><img src=\"/images/Grid-RCNN-Plus_fig2.png\" alt=\"\"></p>\n<p> grid point  56x56 28x28 1/4 heatmap Grid point  2  point   point  gt label </p>\n<h3 id=\"Light-Grid-Head\"><a href=\"#Light-Grid-Head\" class=\"headerlink\" title=\"Light Grid Head\"></a>Light Grid Head</h3><p> heatmap  grid  features  14x14  7x7 RoIAlign  RoI  14x14  3x3 stride=2  size  7x7 7  3x3 stride=1  7x7 N  9 grid point grid points  2  2x  28x28  heatmaps</p>\n<p>grid point  grid points  grid points  Grid R-CNN Plus  5x5 depth-wise depth-wise  Grid R-CNN  5x5  grid </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>grid branch IoU &gt; 0.5  positive proposals grid  Grid R-CNN Plus  96  192 </p>\n<h3 id=\"-NMS\"><a href=\"#-NMS\" class=\"headerlink\" title=\" NMS\"></a> NMS</h3><p>Grid R-CNN proposals  IoU  0.5  NMS top 125  proposals  grid  NMS  NMS  proposals 80 COCO  NMS  Grid R-CNN Plus  NMS</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"Grid-R-CNN\"><a href=\"#Grid-R-CNN\" class=\"headerlink\" title=\"Grid R-CNN\"></a>Grid R-CNN</h1><p> <a href=\"https://arxiv.org/abs/1811.12030\">Grid R-CNN</a></p>\n<p> <a href=\"https://github.com/STVIR/Grid-R-CNN\">Grid R-CNN</a><br>","more":"</p>\n<h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p> conv  fc  4 x,y,w,h  4*(C+1) fc <br><img src=\"/images/Grid-RCNN_fig1.png\" alt=\"\"></p>\n<p> Grid R-CNN R-CNN  R-CNN  1  grid points  RoI  FCN  grid points</p>\n<ol>\n<li>FCN  RoI  grid points</li>\n<li> grid points  bboxExtremeNet  CornerNet  grid points  3x3  1(b)top-middle</li>\n</ol>\n<p> grid points  grid point  feature maps grid point grid point  feature maps  grid point  feature map feature map  grid point </p>\n<h2 id=\"2-Grid-R-CNN\"><a href=\"#2-Grid-R-CNN\" class=\"headerlink\" title=\"2. Grid R-CNN\"></a>2. Grid R-CNN</h2><p> 2  region proposals RoIAlign  RoI  FCN  feature maps sigmoid probability heatmapheatmaps  target map  grid points 2.1 2.2 <br><img src=\"/images/Grid-RCNN_fig2.png\" alt=\"\"></p>\n<h3 id=\"2-1-Grid-Guided-Localization\"><a href=\"#2-1-Grid-Guided-Localization\" class=\"headerlink\" title=\"2.1 Grid Guided Localization\"></a>2.1 Grid Guided Localization</h3><p> NxN  grid points  bbox  3x3  grid points  bbox </p>\n<p> RoIAlign  RoI  14x14  feature 8  3x3  2x  56x56  feature NxN pixel-wise  sigmoid  NxN  heatmap heatmap  feature map  grid point supervision map supervision map  target grid point  5  $t_i=1$ $t_i=0$target grid point  supervision map  2.3  binary cross-entropy loss $CE=\\sum_{i=1}^{56 \\times 56} [-t_i\\log p_i-(1-t_i)\\log(1-p_i)]$ $p_i$  pixel </p>\n<p>Inference  heatmap  $(H_x,H_y)$ image  $(I_x,I_y)$</p>\n<script type=\"math/tex; mode=display\">I_x=P_x+ \\frac {H_x}{w_o} w_p\n\\\\\\\\ I_y=P_y+ \\frac {H_y}{h_o} h_p</script><p> $(P_x,P_y)$  region proposal  image $(w_p,h_p)$  proposal $(w_o,h_o)$  heatmap  <strong></strong> heatmap  proposal <br> grid points  bbox  $B=(x_l,y_u,x_r,y_b)$ j  grid point  $g_j$ $(x_j,y_j)$ $p_j$ j  heatmap  $E_i$  i  grid points  $g_j$   i  $j \\in E_i$ grid points  B</p>\n<script type=\"math/tex; mode=display\">x_l=\\frac 1 N \\sum_{j \\in E_1} x_j p_j, \\quad y_u=\\frac 1 N \\sum_{j \\in E_2} y_j p_j\n\\\\\\\\ x_r=\\frac 1 N \\sum_{j \\in E_3} x_j p_j, \\quad y_b=\\frac 1 N \\sum_{j \\in E_4} y_j p_j</script><h3 id=\"2-2-Grid-Points-Feature-Fusion\"><a href=\"#2-2-Grid-Points-Feature-Fusion\" class=\"headerlink\" title=\"2.2 Grid Points Feature Fusion\"></a>2.2 Grid Points Feature Fusion</h3><p> FCN  heatmap  RoI  grid points  3x3 grid points  point grid points  feature maps </p>\n<p> grid points  feature maps NxN  filters  feature map  grid points  feature map  grid point  i  point  feature map  $F_i$</p>\n<p> grid point L1  1  points  points  source points $S_i$ $S_i$  point j feature maps $F_j$  5x5  $T_{j \\rightarrow i}$$S_i$  source points  features  $F_i$  $F_i$</p>\n<script type=\"math/tex; mode=display\">F_i'=F_i + \\sum_{j \\in S_i} T_{j \\rightarrow i} (F_j)</script><p><img src=\"/images/Grid-RCNN_fig3.png\" alt=\"\"></p>\n<p> 3(a)  point  $F_i$  source point  $F_i$  $T_{j \\rightarrow i}^+$ $F_i$ heatmap grid point  L1  2  points  features  grid point  3(b)</p>\n<p><strong></strong>  feature maps  sigmoid  heatmaps supervision maps  loss Binary Cross-Entropy Loss</p>\n<h3 id=\"2-3-Extended-Region-Mapping\"><a href=\"#2-3-Extended-Region-Mapping\" class=\"headerlink\" title=\"2.3 Extended Region Mapping\"></a>2.3 Extended Region Mapping</h3><p>Grid  heatmap  pixel  grid point  RoI  FCN heatmap  region proposal  image region proposal  gt grid point  region proposal  supervision map  target grid point inference  heatmap  pixel  grid point region proposal  grid point  gt grid points  region proposals  4proposal gt box 9  grid points  7  heatmap </p>\n<p> proposal gt grid points  proposal    proposal  heatmap  image  region  proposal RoI  feature map  region  proposal heatmap  region  grid points  4  supervision map  heatmap  gt box  supervision map  gt grid point  pixels gt grid point  pixels 5  pixels <br><img src=\"/images/Grid-RCNN_fig4.png\" alt=\"\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">I_x'=P_x+\\frac {4H_x-w_o}{2w_o}w_p\n\\\\\\\\ I_y'=P_y+\\frac {4H_y-h_o}{2h_o}h_p</script><p> 4 <br> heatmap  image  region proposal  R $(I_x,I_y)$ </p>\n<script type=\"math/tex; mode=display\">I_x'=P_x'+\\frac {H_x}{w_o} 2 w_p, \\quad I_y'=P_y'+\\frac {H_y}{h_o} 2 h_p</script><p> $(P_x,P_y)$  R  image  proposal </p>\n<script type=\"math/tex; mode=display\">2(x_c-P_x)=x_c-P_x'=w_p, \\quad 2(y_c-P_y)=y_c-P_y'=h_p</script><p> $(x_c,y_c)$  proposal  R  image </p>\n<h3 id=\"2-4-Implementation-Details\"><a href=\"#2-4-Implementation-Details\" class=\"headerlink\" title=\"2.4 Implementation Details\"></a>2.4 Implementation Details</h3><p></p>\n<h1 id=\"Grid-R-CNN-Plus\"><a href=\"#Grid-R-CNN-Plus\" class=\"headerlink\" title=\"Grid R-CNN Plus\"></a>Grid R-CNN Plus</h1><p> <a href=\"https://arxiv.org/abs/1906.05688\">Grid R-CNN Plus: Faster and Better</a></p>\n<p> Grid R-CNN  two-stage  mAP Grid R-CNN  inference  Grid R-CNN Plus</p>\n<p> Grid R-CNN Plus grid pointGrid R-CNN  supervision map grid point  supervision map  Grid R-CNN Plus  1/4  grid  feature maps  grid point  1/4grid point </p>\n<p>NMS </p>\n<h2 id=\"-Grid-R-CNN\"><a href=\"#-Grid-R-CNN\" class=\"headerlink\" title=\" Grid R-CNN\"></a> Grid R-CNN</h2><p> 1  Grid R-CNN  two-stage Grid R-CNN  RPN  R-CNN region propopsals RoIAlign  CNN backbone  feature maps  RoI  RoI  bbox Grid R-CNN  R-CNN  grid points Grid  FCN  heatmaps heatmaps  grid points<br><img src=\"/images/Grid-RCNN-Plus_fig1.png\" alt=\"\"></p>\n<p>Grid R-CNN  8  3x3  2x  heatmap RPN  1000  proposals NMS  top 100  proposals grid </p>\n<p> grid points  gt grid points  proposal </p>\n<h2 id=\"Grid-R-CNN-Plus-1\"><a href=\"#Grid-R-CNN-Plus-1\" class=\"headerlink\" title=\"Grid R-CNN Plus\"></a>Grid R-CNN Plus</h2><h3 id=\"Grid-Point-\"><a href=\"#Grid-Point-\" class=\"headerlink\" title=\"Grid Point \"></a>Grid Point </h3><p> IoU &gt; 0.5  proposals Grid  supervision map  gt grid point  2  grid point  gt label  3x3 grid points  point  gt label  supervision map  grid points  scale  center pixel  grid point <br><img src=\"/images/Grid-RCNN-Plus_fig2.png\" alt=\"\"></p>\n<p> grid point  56x56 28x28 1/4 heatmap Grid point  2  point   point  gt label </p>\n<h3 id=\"Light-Grid-Head\"><a href=\"#Light-Grid-Head\" class=\"headerlink\" title=\"Light Grid Head\"></a>Light Grid Head</h3><p> heatmap  grid  features  14x14  7x7 RoIAlign  RoI  14x14  3x3 stride=2  size  7x7 7  3x3 stride=1  7x7 N  9 grid point grid points  2  2x  28x28  heatmaps</p>\n<p>grid point  grid points  grid points  Grid R-CNN Plus  5x5 depth-wise depth-wise  Grid R-CNN  5x5  grid </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>grid branch IoU &gt; 0.5  positive proposals grid  Grid R-CNN Plus  96  192 </p>\n<h3 id=\"-NMS\"><a href=\"#-NMS\" class=\"headerlink\" title=\" NMS\"></a> NMS</h3><p>Grid R-CNN proposals  IoU  0.5  NMS top 125  proposals  grid  NMS  NMS  proposals 80 COCO  NMS  Grid R-CNN Plus  NMS</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>"},{"title":"M2Det","date":"2019-06-28T09:59:08.000Z","mathjax":true,"_content":"[M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network](https://arxiv.org/abs/1811.04533)\n<!-- more -->\n# Introduction\nimage pyramid  feature pyramid size  image  image  level  feature scale  feature maps feature pyramid feature pyramid  backbone  multi-scale feature maps feature maps  feature pyramid 1\n![](/images/M2Det_fig1.png)\n\nSSD  backbone  layers 2  4  layers 6  layers  feature pyramidSTDN  DenseNet  block  pooling  scale-transfer  feature pyramidFPN  top-down  feature pyramid\n1. pyramid  feature  backbone  backbone \n2. pyramid  level  feature  scale  feature FPN  FPN  backbone  layer  feature  level \n\nsize  size  level  feature maps \n\n feature pyramid  scale  2\n![](/images/M2Det_fig2.png)\n\n backbone  multi-level features layers  base feature base feature  Thinned U-shape Modules(TUM)  Feature Fusion Modules(FFM)  block 2  multi-level multi-scale featuresmulti-leve  shallow, medium, deep  levelmulti-scale  level  features U  Scale-wise Feature Aggregation ModuleSFAM  level  scale  feature pyramid SFAM  multi-level multi-scale  multi-scale multi-level scale  feature  feature pyramid  backbone  layers  feature pyramid  Multi-Level Feature Pyramid NetworkMLFPN\n\n MLFPN  one-stage  M2Det MLFPN  SSD M2Det  SOTA  inference FPS=11.8AP=41.0 inference AP  44.2 MS-COCO  one-stage \n\n# Method\nM2Det  2 backbone  MLFPN  feature pyramid SSD  bbox  NMS MLFPN FFM, TUM  SFAMFFMv1  base feature  backbone  feature maps TUM  TUM  FFMv2  multi-level multi scale featuresSFAM  scale  level  featuresconcatenate features M2Det \n\n## MLFPN\n 2FFMv1  base feature VGG  conv4_3  conv5_3  TUM  FFMv2 TUM  scale  feature mapsFFMv2  base feature  TUM  scale  feature feature maps  TUM  TUM  base feature  multi-level multi-scale features \n$$[x_1^l,...x_i^l]=\\begin{cases} \\mathbf T_l(\\mathbf X_{base}) & l=1\n\\\\\\\\ \\mathbf T_l(\\mathbf F (\\mathbf X_{base}, \\mathbf x_i^{l-1})) & l=2,...L \\end{cases}$$\n$\\mathbf X_{base}$  base feature$x_i^l$  $l$  TUM  $i$  scale  featureL  TUM $\\mathbf T_l$   $l$  TUM $\\mathbf F$  FFMv2 \n\n### FFM\nFFM  feature  1x1  features concatenation  features FFMv1  backbone  scale  features  upsample  scale  concatenation TUM  ____  FFMv2  base feature   TUM  feature  scale concatenate  TUM FFMv1  FFMv2  4 (a)(b)\n![](/images/M2Det_fig4.png) <center>Fig 4 (a) FFMv1. (b) FFMv2. (c) TUM block  size</center>\n\n### TUM\nTUM  Thin U-shape  4(c)encoder  stride=2  3x3 decoder  feature maps  FPN  backbone  layer  upsample  element-wise sum  1x1  TUM  decoder  multi-level multi-scale features TUM  multi-scale features TUM  multi-scale features TUM  multi-scale features\n\n### SFAM\nSFAM  TUM  multi-level multi-scale features 3\n![](/images/M2Det_fig3.png)<center>Fig 3 SFAM  scale  channel  concatenate  SE attention </center>\n\n scale  features  concatenate feature pyramid  \n$$\\mathbf X=[\\mathbf X_1,...,\\mathbf X_i]$$\n $\\mathbf X_i=Concat(x_i^1,...x_i^L) \\in \\mathcal R^{W_i \\times H_i \\times C}$  $i$  scale $W_i \\times H_i$  $i$  scale  feature map  size scale  level  feature maps  $C$  4  $C=128$ concatenate  features features  SE block squeeze global average pooling $\\mathbf z \\in \\mathcal R^C$ excitation  fc \n$$\\mathbf s = \\mathbf F_{ex}(\\mathbf {z,W})=\\sigma (\\mathbf W_2 \\delta(\\mathbf W_1 \\mathbf z))$$\n$\\sigma$  ReLu$\\delta$  sigmoid$\\mathbf W_1 \\in \\mathcal R^{\\frac C r \\times C}, \\ \\mathbf W_2 \\in \\mathcal R^{C \\times \\frac C r}$ r  r=16\n\n$$\\tilde {\\mathbf X_i^c}=\\mathbf F_{scale}(\\mathbf X_i^c, s_c)=s_c \\cdot \\mathbf X_i^c$$\n\n $\\tilde {\\mathbf X_i}=[\\tilde {\\mathbf X_i^1},...,\\tilde {\\mathbf X_i^C}]$\n\n### \n VGG  ResNet  M2Det  backbonebackbone  ImageNet2012 MLFPN  8  TUM TUM  5  convs  5  6  scale  featuresTUM  scale  256  4 (c)  SSD, RefineDet  RetinaNet 320, 512  800\n\nMLFPN  6  pyramid featuresscale  1x13x35x510x1020x2040x40 scale  pyramid features 6  pyramid features  anchor(prior) box  scale  aspect ratio SSD  m  features m = 6 k  features  anchor box  scale \n$$s_k=s_{min}+\\frac {s_{max}-s_{min}} {m-1} (k-1)$$\n$s_{min}=0.2, \\ s_{max}=0.9$ features  image  anchor  scale\n\n pyramidal features  6  anchors 3  aspect ratios SSD 0.05  [soft-NMS](/2019/06/24/cv-mtds) \n\n# \n\n\n# \n MLFPN  multi-scale  M2Det  SOTA  one-stage ","source":"_posts/M2Det.md","raw":"---\ntitle: M2Det\ndate: 2019-06-28 17:59:08\ntags: object detection\nmathjax: true\n---\n[M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network](https://arxiv.org/abs/1811.04533)\n<!-- more -->\n# Introduction\nimage pyramid  feature pyramid size  image  image  level  feature scale  feature maps feature pyramid feature pyramid  backbone  multi-scale feature maps feature maps  feature pyramid 1\n![](/images/M2Det_fig1.png)\n\nSSD  backbone  layers 2  4  layers 6  layers  feature pyramidSTDN  DenseNet  block  pooling  scale-transfer  feature pyramidFPN  top-down  feature pyramid\n1. pyramid  feature  backbone  backbone \n2. pyramid  level  feature  scale  feature FPN  FPN  backbone  layer  feature  level \n\nsize  size  level  feature maps \n\n feature pyramid  scale  2\n![](/images/M2Det_fig2.png)\n\n backbone  multi-level features layers  base feature base feature  Thinned U-shape Modules(TUM)  Feature Fusion Modules(FFM)  block 2  multi-level multi-scale featuresmulti-leve  shallow, medium, deep  levelmulti-scale  level  features U  Scale-wise Feature Aggregation ModuleSFAM  level  scale  feature pyramid SFAM  multi-level multi-scale  multi-scale multi-level scale  feature  feature pyramid  backbone  layers  feature pyramid  Multi-Level Feature Pyramid NetworkMLFPN\n\n MLFPN  one-stage  M2Det MLFPN  SSD M2Det  SOTA  inference FPS=11.8AP=41.0 inference AP  44.2 MS-COCO  one-stage \n\n# Method\nM2Det  2 backbone  MLFPN  feature pyramid SSD  bbox  NMS MLFPN FFM, TUM  SFAMFFMv1  base feature  backbone  feature maps TUM  TUM  FFMv2  multi-level multi scale featuresSFAM  scale  level  featuresconcatenate features M2Det \n\n## MLFPN\n 2FFMv1  base feature VGG  conv4_3  conv5_3  TUM  FFMv2 TUM  scale  feature mapsFFMv2  base feature  TUM  scale  feature feature maps  TUM  TUM  base feature  multi-level multi-scale features \n$$[x_1^l,...x_i^l]=\\begin{cases} \\mathbf T_l(\\mathbf X_{base}) & l=1\n\\\\\\\\ \\mathbf T_l(\\mathbf F (\\mathbf X_{base}, \\mathbf x_i^{l-1})) & l=2,...L \\end{cases}$$\n$\\mathbf X_{base}$  base feature$x_i^l$  $l$  TUM  $i$  scale  featureL  TUM $\\mathbf T_l$   $l$  TUM $\\mathbf F$  FFMv2 \n\n### FFM\nFFM  feature  1x1  features concatenation  features FFMv1  backbone  scale  features  upsample  scale  concatenation TUM  ____  FFMv2  base feature   TUM  feature  scale concatenate  TUM FFMv1  FFMv2  4 (a)(b)\n![](/images/M2Det_fig4.png) <center>Fig 4 (a) FFMv1. (b) FFMv2. (c) TUM block  size</center>\n\n### TUM\nTUM  Thin U-shape  4(c)encoder  stride=2  3x3 decoder  feature maps  FPN  backbone  layer  upsample  element-wise sum  1x1  TUM  decoder  multi-level multi-scale features TUM  multi-scale features TUM  multi-scale features TUM  multi-scale features\n\n### SFAM\nSFAM  TUM  multi-level multi-scale features 3\n![](/images/M2Det_fig3.png)<center>Fig 3 SFAM  scale  channel  concatenate  SE attention </center>\n\n scale  features  concatenate feature pyramid  \n$$\\mathbf X=[\\mathbf X_1,...,\\mathbf X_i]$$\n $\\mathbf X_i=Concat(x_i^1,...x_i^L) \\in \\mathcal R^{W_i \\times H_i \\times C}$  $i$  scale $W_i \\times H_i$  $i$  scale  feature map  size scale  level  feature maps  $C$  4  $C=128$ concatenate  features features  SE block squeeze global average pooling $\\mathbf z \\in \\mathcal R^C$ excitation  fc \n$$\\mathbf s = \\mathbf F_{ex}(\\mathbf {z,W})=\\sigma (\\mathbf W_2 \\delta(\\mathbf W_1 \\mathbf z))$$\n$\\sigma$  ReLu$\\delta$  sigmoid$\\mathbf W_1 \\in \\mathcal R^{\\frac C r \\times C}, \\ \\mathbf W_2 \\in \\mathcal R^{C \\times \\frac C r}$ r  r=16\n\n$$\\tilde {\\mathbf X_i^c}=\\mathbf F_{scale}(\\mathbf X_i^c, s_c)=s_c \\cdot \\mathbf X_i^c$$\n\n $\\tilde {\\mathbf X_i}=[\\tilde {\\mathbf X_i^1},...,\\tilde {\\mathbf X_i^C}]$\n\n### \n VGG  ResNet  M2Det  backbonebackbone  ImageNet2012 MLFPN  8  TUM TUM  5  convs  5  6  scale  featuresTUM  scale  256  4 (c)  SSD, RefineDet  RetinaNet 320, 512  800\n\nMLFPN  6  pyramid featuresscale  1x13x35x510x1020x2040x40 scale  pyramid features 6  pyramid features  anchor(prior) box  scale  aspect ratio SSD  m  features m = 6 k  features  anchor box  scale \n$$s_k=s_{min}+\\frac {s_{max}-s_{min}} {m-1} (k-1)$$\n$s_{min}=0.2, \\ s_{max}=0.9$ features  image  anchor  scale\n\n pyramidal features  6  anchors 3  aspect ratios SSD 0.05  [soft-NMS](/2019/06/24/cv-mtds) \n\n# \n\n\n# \n MLFPN  multi-scale  M2Det  SOTA  one-stage ","slug":"M2Det","published":1,"updated":"2020-04-24T10:36:31.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90a000np0dj293f0i8a","content":"<p><a href=\"https://arxiv.org/abs/1811.04533\">M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</a><br><span id=\"more\"></span></p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>image pyramid  feature pyramid size  image  image  level  feature scale  feature maps feature pyramid feature pyramid  backbone  multi-scale feature maps feature maps  feature pyramid 1<br><img src=\"/images/M2Det_fig1.png\" alt=\"\"></p>\n<p>SSD  backbone  layers 2  4  layers 6  layers  feature pyramidSTDN  DenseNet  block  pooling  scale-transfer  feature pyramidFPN  top-down  feature pyramid</p>\n<ol>\n<li>pyramid  feature  backbone  backbone </li>\n<li>pyramid  level  feature  scale  feature FPN  FPN  backbone  layer  feature  level </li>\n</ol>\n<p>size  size  level  feature maps </p>\n<p> feature pyramid  scale  2<br><img src=\"/images/M2Det_fig2.png\" alt=\"\"></p>\n<p> backbone  multi-level features layers  base feature base feature  Thinned U-shape Modules(TUM)  Feature Fusion Modules(FFM)  block 2  multi-level multi-scale featuresmulti-leve  shallow, medium, deep  levelmulti-scale  level  features U  Scale-wise Feature Aggregation ModuleSFAM  level  scale  feature pyramid SFAM  multi-level multi-scale  multi-scale multi-level scale  feature  feature pyramid  backbone  layers  feature pyramid  Multi-Level Feature Pyramid NetworkMLFPN</p>\n<p> MLFPN  one-stage  M2Det MLFPN  SSD M2Det  SOTA  inference FPS=11.8AP=41.0 inference AP  44.2 MS-COCO  one-stage </p>\n<h1 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h1><p>M2Det  2 backbone  MLFPN  feature pyramid SSD  bbox  NMS MLFPN FFM, TUM  SFAMFFMv1  base feature  backbone  feature maps TUM  TUM  FFMv2  multi-level multi scale featuresSFAM  scale  level  featuresconcatenate features M2Det </p>\n<h2 id=\"MLFPN\"><a href=\"#MLFPN\" class=\"headerlink\" title=\"MLFPN\"></a>MLFPN</h2><p> 2FFMv1  base feature VGG  conv4_3  conv5_3  TUM  FFMv2 TUM  scale  feature mapsFFMv2  base feature  TUM  scale  feature feature maps  TUM  TUM  base feature  multi-level multi-scale features </p>\n<script type=\"math/tex; mode=display\">[x_1^l,...x_i^l]=\\begin{cases} \\mathbf T_l(\\mathbf X_{base}) & l=1\n\\\\\\\\ \\mathbf T_l(\\mathbf F (\\mathbf X_{base}, \\mathbf x_i^{l-1})) & l=2,...L \\end{cases}</script><p>$\\mathbf X_{base}$  base feature$x_i^l$  $l$  TUM  $i$  scale  featureL  TUM $\\mathbf T_l$   $l$  TUM $\\mathbf F$  FFMv2 </p>\n<h3 id=\"FFM\"><a href=\"#FFM\" class=\"headerlink\" title=\"FFM\"></a>FFM</h3><p>FFM  feature  1x1  features concatenation  features FFMv1  backbone  scale  features  upsample  scale  concatenation TUM  <strong></strong>  FFMv2  base feature   TUM  feature  scale concatenate  TUM FFMv1  FFMv2  4 (a)(b)<br><img src=\"/images/M2Det_fig4.png\" alt=\"\"> <center>Fig 4 (a) FFMv1. (b) FFMv2. (c) TUM block  size</center></p>\n<h3 id=\"TUM\"><a href=\"#TUM\" class=\"headerlink\" title=\"TUM\"></a>TUM</h3><p>TUM  Thin U-shape  4(c)encoder  stride=2  3x3 decoder  feature maps  FPN  backbone  layer  upsample  element-wise sum  1x1  TUM  decoder  multi-level multi-scale features TUM  multi-scale features TUM  multi-scale features TUM  multi-scale features</p>\n<h3 id=\"SFAM\"><a href=\"#SFAM\" class=\"headerlink\" title=\"SFAM\"></a>SFAM</h3><p>SFAM  TUM  multi-level multi-scale features 3<br><img src=\"/images/M2Det_fig3.png\" alt=\"\"><center>Fig 3 SFAM  scale  channel  concatenate  SE attention </center></p>\n<p> scale  features  concatenate feature pyramid  </p>\n<script type=\"math/tex; mode=display\">\\mathbf X=[\\mathbf X_1,...,\\mathbf X_i]</script><p> $\\mathbf X_i=Concat(x_i^1,x_i^L) \\in \\mathcal R^{W_i \\times H_i \\times C}$  $i$  scale $W_i \\times H_i$  $i$  scale  feature map  size scale  level  feature maps  $C$  4  $C=128$ concatenate  features features  SE block squeeze global average pooling $\\mathbf z \\in \\mathcal R^C$ excitation  fc </p>\n<script type=\"math/tex; mode=display\">\\mathbf s = \\mathbf F_{ex}(\\mathbf {z,W})=\\sigma (\\mathbf W_2 \\delta(\\mathbf W_1 \\mathbf z))</script><p>$\\sigma$  ReLu$\\delta$  sigmoid$\\mathbf W_1 \\in \\mathcal R^{\\frac C r \\times C}, \\ \\mathbf W_2 \\in \\mathcal R^{C \\times \\frac C r}$ r  r=16</p>\n<script type=\"math/tex; mode=display\">\\tilde {\\mathbf X_i^c}=\\mathbf F_{scale}(\\mathbf X_i^c, s_c)=s_c \\cdot \\mathbf X_i^c</script><p> $\\tilde {\\mathbf X_i}=[\\tilde {\\mathbf X_i^1},,\\tilde {\\mathbf X_i^C}]$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> VGG  ResNet  M2Det  backbonebackbone  ImageNet2012 MLFPN  8  TUM TUM  5  convs  5  6  scale  featuresTUM  scale  256  4 (c)  SSD, RefineDet  RetinaNet 320, 512  800</p>\n<p>MLFPN  6  pyramid featuresscale  1x13x35x510x1020x2040x40 scale  pyramid features 6  pyramid features  anchor(prior) box  scale  aspect ratio SSD  m  features m = 6 k  features  anchor box  scale </p>\n<script type=\"math/tex; mode=display\">s_k=s_{min}+\\frac {s_{max}-s_{min}} {m-1} (k-1)</script><p>$s_{min}=0.2, \\ s_{max}=0.9$ features  image  anchor  scale</p>\n<p> pyramidal features  6  anchors 3  aspect ratios SSD 0.05  <a href=\"/2019/06/24/cv-mtds\">soft-NMS</a> </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> MLFPN  multi-scale  M2Det  SOTA  one-stage </p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://arxiv.org/abs/1811.04533\">M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</a><br>","more":"</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p>image pyramid  feature pyramid size  image  image  level  feature scale  feature maps feature pyramid feature pyramid  backbone  multi-scale feature maps feature maps  feature pyramid 1<br><img src=\"/images/M2Det_fig1.png\" alt=\"\"></p>\n<p>SSD  backbone  layers 2  4  layers 6  layers  feature pyramidSTDN  DenseNet  block  pooling  scale-transfer  feature pyramidFPN  top-down  feature pyramid</p>\n<ol>\n<li>pyramid  feature  backbone  backbone </li>\n<li>pyramid  level  feature  scale  feature FPN  FPN  backbone  layer  feature  level </li>\n</ol>\n<p>size  size  level  feature maps </p>\n<p> feature pyramid  scale  2<br><img src=\"/images/M2Det_fig2.png\" alt=\"\"></p>\n<p> backbone  multi-level features layers  base feature base feature  Thinned U-shape Modules(TUM)  Feature Fusion Modules(FFM)  block 2  multi-level multi-scale featuresmulti-leve  shallow, medium, deep  levelmulti-scale  level  features U  Scale-wise Feature Aggregation ModuleSFAM  level  scale  feature pyramid SFAM  multi-level multi-scale  multi-scale multi-level scale  feature  feature pyramid  backbone  layers  feature pyramid  Multi-Level Feature Pyramid NetworkMLFPN</p>\n<p> MLFPN  one-stage  M2Det MLFPN  SSD M2Det  SOTA  inference FPS=11.8AP=41.0 inference AP  44.2 MS-COCO  one-stage </p>\n<h1 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h1><p>M2Det  2 backbone  MLFPN  feature pyramid SSD  bbox  NMS MLFPN FFM, TUM  SFAMFFMv1  base feature  backbone  feature maps TUM  TUM  FFMv2  multi-level multi scale featuresSFAM  scale  level  featuresconcatenate features M2Det </p>\n<h2 id=\"MLFPN\"><a href=\"#MLFPN\" class=\"headerlink\" title=\"MLFPN\"></a>MLFPN</h2><p> 2FFMv1  base feature VGG  conv4_3  conv5_3  TUM  FFMv2 TUM  scale  feature mapsFFMv2  base feature  TUM  scale  feature feature maps  TUM  TUM  base feature  multi-level multi-scale features </p>\n<script type=\"math/tex; mode=display\">[x_1^l,...x_i^l]=\\begin{cases} \\mathbf T_l(\\mathbf X_{base}) & l=1\n\\\\\\\\ \\mathbf T_l(\\mathbf F (\\mathbf X_{base}, \\mathbf x_i^{l-1})) & l=2,...L \\end{cases}</script><p>$\\mathbf X_{base}$  base feature$x_i^l$  $l$  TUM  $i$  scale  featureL  TUM $\\mathbf T_l$   $l$  TUM $\\mathbf F$  FFMv2 </p>\n<h3 id=\"FFM\"><a href=\"#FFM\" class=\"headerlink\" title=\"FFM\"></a>FFM</h3><p>FFM  feature  1x1  features concatenation  features FFMv1  backbone  scale  features  upsample  scale  concatenation TUM  <strong></strong>  FFMv2  base feature   TUM  feature  scale concatenate  TUM FFMv1  FFMv2  4 (a)(b)<br><img src=\"/images/M2Det_fig4.png\" alt=\"\"> <center>Fig 4 (a) FFMv1. (b) FFMv2. (c) TUM block  size</center></p>\n<h3 id=\"TUM\"><a href=\"#TUM\" class=\"headerlink\" title=\"TUM\"></a>TUM</h3><p>TUM  Thin U-shape  4(c)encoder  stride=2  3x3 decoder  feature maps  FPN  backbone  layer  upsample  element-wise sum  1x1  TUM  decoder  multi-level multi-scale features TUM  multi-scale features TUM  multi-scale features TUM  multi-scale features</p>\n<h3 id=\"SFAM\"><a href=\"#SFAM\" class=\"headerlink\" title=\"SFAM\"></a>SFAM</h3><p>SFAM  TUM  multi-level multi-scale features 3<br><img src=\"/images/M2Det_fig3.png\" alt=\"\"><center>Fig 3 SFAM  scale  channel  concatenate  SE attention </center></p>\n<p> scale  features  concatenate feature pyramid  </p>\n<script type=\"math/tex; mode=display\">\\mathbf X=[\\mathbf X_1,...,\\mathbf X_i]</script><p> $\\mathbf X_i=Concat(x_i^1,x_i^L) \\in \\mathcal R^{W_i \\times H_i \\times C}$  $i$  scale $W_i \\times H_i$  $i$  scale  feature map  size scale  level  feature maps  $C$  4  $C=128$ concatenate  features features  SE block squeeze global average pooling $\\mathbf z \\in \\mathcal R^C$ excitation  fc </p>\n<script type=\"math/tex; mode=display\">\\mathbf s = \\mathbf F_{ex}(\\mathbf {z,W})=\\sigma (\\mathbf W_2 \\delta(\\mathbf W_1 \\mathbf z))</script><p>$\\sigma$  ReLu$\\delta$  sigmoid$\\mathbf W_1 \\in \\mathcal R^{\\frac C r \\times C}, \\ \\mathbf W_2 \\in \\mathcal R^{C \\times \\frac C r}$ r  r=16</p>\n<script type=\"math/tex; mode=display\">\\tilde {\\mathbf X_i^c}=\\mathbf F_{scale}(\\mathbf X_i^c, s_c)=s_c \\cdot \\mathbf X_i^c</script><p> $\\tilde {\\mathbf X_i}=[\\tilde {\\mathbf X_i^1},,\\tilde {\\mathbf X_i^C}]$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> VGG  ResNet  M2Det  backbonebackbone  ImageNet2012 MLFPN  8  TUM TUM  5  convs  5  6  scale  featuresTUM  scale  256  4 (c)  SSD, RefineDet  RetinaNet 320, 512  800</p>\n<p>MLFPN  6  pyramid featuresscale  1x13x35x510x1020x2040x40 scale  pyramid features 6  pyramid features  anchor(prior) box  scale  aspect ratio SSD  m  features m = 6 k  features  anchor box  scale </p>\n<script type=\"math/tex; mode=display\">s_k=s_{min}+\\frac {s_{max}-s_{min}} {m-1} (k-1)</script><p>$s_{min}=0.2, \\ s_{max}=0.9$ features  image  anchor  scale</p>\n<p> pyramidal features  6  anchors 3  aspect ratios SSD 0.05  <a href=\"/2019/06/24/cv-mtds\">soft-NMS</a> </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> MLFPN  multi-scale  M2Det  SOTA  one-stage </p>"},{"title":"ImprovedGAN","date":"2019-08-01T07:48:46.000Z","mathjax":true,"_content":" [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)\n\n [improved_gan](https://github.com/openai/improved_gan)\n<!-- more -->\n# \nGAN GAN  [DCGAN](2019/07/23/GAN)  GAN  conv+BN+ReLU  GAN  Nash  Nash \n1. \n2. \n3. \n\n# GAN \n GAN  Nash  $J^{(G)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$  $J^{(D)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$Nash  $J^{(D)}$  $\\theta^{(D)}$  $J^{(G)}$  $\\theta^{(G)}$  Nash  Nash  G  D  $\\theta^{(D)}$  $J^{(D)}$  $J^{(G)}$ $\\theta^{(G)}$  $J^{(G)}$  $J^{(D)}$ x  xy y  -xy x  y  x=y=0\n\n## \n GAN  D G  D  G  G  D  $\\mathbf {f(x)}$  D  G \n$$\\|\\Bbb E_{\\mathbf x \\sim p_{data}} \\mathbf {f(x)}-\\Bbb E_{\\mathbf z \\sim p_{\\mathbf z}}\\mathbf f(G(\\mathbf z))\\|_2^2$$\nG \n\n## \nGAN  ____  ____ \n\n  \n $\\mathbf {f(x_i)} \\in \\Bbb R^A$  $\\mathbf x_i$  D  $T \\in \\Bbb R^{A \\times B \\times C}$ $M_i \\in \\Bbb R^{B \\times C}$ $i \\in \\{1,...,n\\}$ $\\{M_i |i=1,...,n\\}$ L1 \n$$c_b(\\mathbf x_i, \\mathbf x_j)=\\exp(-\\|M_{i,b}-M_{j,b}\\| _ {L_1}) \\in \\Bbb R, \\quad i,j \\in \\{1,...,n\\}, \\quad b \\in \\{1,...,B\\}$$\n\n b  row index 1minibatch layer  $\\mathbf x_i$ \n$$\\begin{aligned} &o(\\mathbf x_i) _ b = \\sum_{j=1}^n c _ b(\\mathbf x_i, \\mathbf x_j) \\in \\Bbb R\n\\\\\\\\ &o(\\mathbf x_i)=\\left[o(\\mathbf x_i) _ 1,...o(\\mathbf x_i) _ B \\right] \\in \\Bbb R^B\n\\\\\\\\ &o(\\mathbf X) \\in \\Bbb R^{n \\times B} \\end{aligned}$$\n\n minibatch layer  $o(\\mathbf x_i)$  minibatch layer  $\\mathbf {f(x_i)}$ concatenate  D  layer  minibatch layer \n![](/images/ImprovedGAN_fig1.png)\n\n## \nG  D $\\|\\mathbf \\theta -\\frac 1 t \\sum_{i=1}^t \\theta[i]\\|^2$ $\\theta[i]$  i \n\n## \nLabel  target  0  1  0.9  0.1 target  $\\alpha$ target  $\\beta$\n$$D(\\mathbf x)=\\frac {\\alpha p_{data}(\\mathbf x) + \\beta p_{model}(\\mathbf x)}{p_{data}(\\mathbf x)+p_{model}(\\mathbf x)}$$\n\n-  $p_{data}(\\mathbf x) \\gg p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\alpha$\n-  $p_{data}(\\mathbf x) \\ll p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\beta$\n\n [GAN](2019/7/23/GAN)  $D^{\\ast}$\n$$\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log (D(x)-\\beta)] + \\Bbb E_{z \\sim p_z(z)}[\\log(\\alpha-D(G(z)))] \\quad (1)$$\n\n target  target $\\alpha > \\beta$ (1)  D  $\\beta < D(x) < \\alpha$\n\n $p_{model}$ $p_{data} \\rightarrow 0$ $p_{model}$  $p_{model}$  label  $\\alpha$ label  0\n\n## \nDCGAN  BN  $\\mathbf x$ minibatch  $\\mathbf x'$ VBN $\\mathbf x$  reference batch  $\\mathbf x$ reference batch reference batch  VBN  G \n\n# \nGAN  Inception  label  $p(y|\\mathbf x)$ label  $p(y|\\mathbf x)$  $\\mathbf x$Inception  y  c zG  Inception  $\\int p(y|\\mathbf x=G(z)) dz$  KL \n$$\\exp [\\Bbb E_{\\mathbf x} \\mathbf {KL}(p(y|\\mathbf x)\\|p(y)) ]$$\n\n\n\n# \n $\\mathbf x$ K  K  $[l_1,...,l_K]$ softmax \n$$p_{model}(y=j|\\mathbf x)=\\frac {\\exp l_j} {\\sum_{k=1}^K \\exp l_k}$$\n\n log \n\n G G  y=K+1 K+1 $p_{model}(y=K+1|\\mathbf x)$  $\\mathbf x$  GAN  $1-D(\\mathbf x)$  K  $\\log p_{model}(y \\in \\{1,...,K\\}|\\mathbf x)$log \n$$\\begin{aligned} &L=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)}[\\log p_{model}(y|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]=L_{supervised}+L_{unsupervised}\n\\\\\\\\ &L_{supervised}=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)} \\log p_{model}(y|\\mathbf x, y <K+1)\n\\\\\\\\ &L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log[1- p_{model}(y=K+1|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]\\end{aligned}$$\n\n $L_{unsupervised}$  GAN  objective $L_{unsupervised}$  $D(\\mathbf x)=1-p_{model}(y=K+1|\\mathbf x)$,\n$$L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log D(\\mathbf x) - \\Bbb E_{z \\sim noise} \\log (1-D(G(z)))$$\n\n $L_{supervised}$  $L_{unsupervised}$  $\\exp[l_j(\\mathbf x)]=c(\\mathbf x) p(y=j,\\mathbf x), \\ \\forall j \\in K+1$  $\\exp[l_{K+1}(\\mathbf x)]=c(\\mathbf x) p_G(\\mathbf x)$ $c(\\mathbf x)$  G  GAN objective D G  GAN  G\n\n K+1  $l_j(\\mathbf x)\\leftarrow l_j(\\mathbf x)-f(\\mathbf x)$ softmax  $l_{K+1}(\\mathbf x)=0, \\ \\forall \\mathbf x$ $L_{supervised}$  K  D  $D(\\mathbf x)=\\frac {Z(\\mathbf x)} {Z(\\mathbf x)+1}$ $Z(\\mathbf x)=\\sum_{k=1}^K \\exp [l_k(\\mathbf x)]$","source":"_posts/ImprovedGAN.md","raw":"---\ntitle: ImprovedGAN\ndate: 2019-08-01 15:48:46\ntags: GAN\nmathjax: true\n---\n [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)\n\n [improved_gan](https://github.com/openai/improved_gan)\n<!-- more -->\n# \nGAN GAN  [DCGAN](2019/07/23/GAN)  GAN  conv+BN+ReLU  GAN  Nash  Nash \n1. \n2. \n3. \n\n# GAN \n GAN  Nash  $J^{(G)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$  $J^{(D)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$Nash  $J^{(D)}$  $\\theta^{(D)}$  $J^{(G)}$  $\\theta^{(G)}$  Nash  Nash  G  D  $\\theta^{(D)}$  $J^{(D)}$  $J^{(G)}$ $\\theta^{(G)}$  $J^{(G)}$  $J^{(D)}$ x  xy y  -xy x  y  x=y=0\n\n## \n GAN  D G  D  G  G  D  $\\mathbf {f(x)}$  D  G \n$$\\|\\Bbb E_{\\mathbf x \\sim p_{data}} \\mathbf {f(x)}-\\Bbb E_{\\mathbf z \\sim p_{\\mathbf z}}\\mathbf f(G(\\mathbf z))\\|_2^2$$\nG \n\n## \nGAN  ____  ____ \n\n  \n $\\mathbf {f(x_i)} \\in \\Bbb R^A$  $\\mathbf x_i$  D  $T \\in \\Bbb R^{A \\times B \\times C}$ $M_i \\in \\Bbb R^{B \\times C}$ $i \\in \\{1,...,n\\}$ $\\{M_i |i=1,...,n\\}$ L1 \n$$c_b(\\mathbf x_i, \\mathbf x_j)=\\exp(-\\|M_{i,b}-M_{j,b}\\| _ {L_1}) \\in \\Bbb R, \\quad i,j \\in \\{1,...,n\\}, \\quad b \\in \\{1,...,B\\}$$\n\n b  row index 1minibatch layer  $\\mathbf x_i$ \n$$\\begin{aligned} &o(\\mathbf x_i) _ b = \\sum_{j=1}^n c _ b(\\mathbf x_i, \\mathbf x_j) \\in \\Bbb R\n\\\\\\\\ &o(\\mathbf x_i)=\\left[o(\\mathbf x_i) _ 1,...o(\\mathbf x_i) _ B \\right] \\in \\Bbb R^B\n\\\\\\\\ &o(\\mathbf X) \\in \\Bbb R^{n \\times B} \\end{aligned}$$\n\n minibatch layer  $o(\\mathbf x_i)$  minibatch layer  $\\mathbf {f(x_i)}$ concatenate  D  layer  minibatch layer \n![](/images/ImprovedGAN_fig1.png)\n\n## \nG  D $\\|\\mathbf \\theta -\\frac 1 t \\sum_{i=1}^t \\theta[i]\\|^2$ $\\theta[i]$  i \n\n## \nLabel  target  0  1  0.9  0.1 target  $\\alpha$ target  $\\beta$\n$$D(\\mathbf x)=\\frac {\\alpha p_{data}(\\mathbf x) + \\beta p_{model}(\\mathbf x)}{p_{data}(\\mathbf x)+p_{model}(\\mathbf x)}$$\n\n-  $p_{data}(\\mathbf x) \\gg p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\alpha$\n-  $p_{data}(\\mathbf x) \\ll p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\beta$\n\n [GAN](2019/7/23/GAN)  $D^{\\ast}$\n$$\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log (D(x)-\\beta)] + \\Bbb E_{z \\sim p_z(z)}[\\log(\\alpha-D(G(z)))] \\quad (1)$$\n\n target  target $\\alpha > \\beta$ (1)  D  $\\beta < D(x) < \\alpha$\n\n $p_{model}$ $p_{data} \\rightarrow 0$ $p_{model}$  $p_{model}$  label  $\\alpha$ label  0\n\n## \nDCGAN  BN  $\\mathbf x$ minibatch  $\\mathbf x'$ VBN $\\mathbf x$  reference batch  $\\mathbf x$ reference batch reference batch  VBN  G \n\n# \nGAN  Inception  label  $p(y|\\mathbf x)$ label  $p(y|\\mathbf x)$  $\\mathbf x$Inception  y  c zG  Inception  $\\int p(y|\\mathbf x=G(z)) dz$  KL \n$$\\exp [\\Bbb E_{\\mathbf x} \\mathbf {KL}(p(y|\\mathbf x)\\|p(y)) ]$$\n\n\n\n# \n $\\mathbf x$ K  K  $[l_1,...,l_K]$ softmax \n$$p_{model}(y=j|\\mathbf x)=\\frac {\\exp l_j} {\\sum_{k=1}^K \\exp l_k}$$\n\n log \n\n G G  y=K+1 K+1 $p_{model}(y=K+1|\\mathbf x)$  $\\mathbf x$  GAN  $1-D(\\mathbf x)$  K  $\\log p_{model}(y \\in \\{1,...,K\\}|\\mathbf x)$log \n$$\\begin{aligned} &L=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)}[\\log p_{model}(y|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]=L_{supervised}+L_{unsupervised}\n\\\\\\\\ &L_{supervised}=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)} \\log p_{model}(y|\\mathbf x, y <K+1)\n\\\\\\\\ &L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log[1- p_{model}(y=K+1|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]\\end{aligned}$$\n\n $L_{unsupervised}$  GAN  objective $L_{unsupervised}$  $D(\\mathbf x)=1-p_{model}(y=K+1|\\mathbf x)$,\n$$L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log D(\\mathbf x) - \\Bbb E_{z \\sim noise} \\log (1-D(G(z)))$$\n\n $L_{supervised}$  $L_{unsupervised}$  $\\exp[l_j(\\mathbf x)]=c(\\mathbf x) p(y=j,\\mathbf x), \\ \\forall j \\in K+1$  $\\exp[l_{K+1}(\\mathbf x)]=c(\\mathbf x) p_G(\\mathbf x)$ $c(\\mathbf x)$  G  GAN objective D G  GAN  G\n\n K+1  $l_j(\\mathbf x)\\leftarrow l_j(\\mathbf x)-f(\\mathbf x)$ softmax  $l_{K+1}(\\mathbf x)=0, \\ \\forall \\mathbf x$ $L_{supervised}$  K  D  $D(\\mathbf x)=\\frac {Z(\\mathbf x)} {Z(\\mathbf x)+1}$ $Z(\\mathbf x)=\\sum_{k=1}^K \\exp [l_k(\\mathbf x)]$","slug":"ImprovedGAN","published":1,"updated":"2020-04-24T10:38:18.844Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90b000pp0djemkhe7w1","content":"<p> <a href=\"https://arxiv.org/abs/1606.03498\">Improved Techniques for Training GANs</a></p>\n<p> <a href=\"https://github.com/openai/improved_gan\">improved_gan</a><br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>GAN GAN  <a href=\"2019/07/23/GAN\">DCGAN</a>  GAN  conv+BN+ReLU  GAN  Nash  Nash </p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h1 id=\"GAN-\"><a href=\"#GAN-\" class=\"headerlink\" title=\"GAN \"></a>GAN </h1><p> GAN  Nash  $J^{(G)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$  $J^{(D)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$Nash  $J^{(D)}$  $\\theta^{(D)}$  $J^{(G)}$  $\\theta^{(G)}$  Nash  Nash  G  D  $\\theta^{(D)}$  $J^{(D)}$  $J^{(G)}$ $\\theta^{(G)}$  $J^{(G)}$  $J^{(D)}$ x  xy y  -xy x  y  x=y=0</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> GAN  D G  D  G  G  D  $\\mathbf {f(x)}$  D  G </p>\n<script type=\"math/tex; mode=display\">\\|\\Bbb E_{\\mathbf x \\sim p_{data}} \\mathbf {f(x)}-\\Bbb E_{\\mathbf z \\sim p_{\\mathbf z}}\\mathbf f(G(\\mathbf z))\\|_2^2</script><p>G </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>GAN  <strong></strong>  <strong></strong> </p>\n<p><br> $\\mathbf {f(x_i)} \\in \\Bbb R^A$  $\\mathbf x_i$  D  $T \\in \\Bbb R^{A \\times B \\times C}$ $M_i \\in \\Bbb R^{B \\times C}$ $i \\in \\{1,,n\\}$ $\\{M_i |i=1,,n\\}$ L1 </p>\n<script type=\"math/tex; mode=display\">c_b(\\mathbf x_i, \\mathbf x_j)=\\exp(-\\|M_{i,b}-M_{j,b}\\| _ {L_1}) \\in \\Bbb R, \\quad i,j \\in \\{1,...,n\\}, \\quad b \\in \\{1,...,B\\}</script><p> b  row index 1minibatch layer  $\\mathbf x_i$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} &o(\\mathbf x_i) _ b = \\sum_{j=1}^n c _ b(\\mathbf x_i, \\mathbf x_j) \\in \\Bbb R\n\\\\\\\\ &o(\\mathbf x_i)=\\left[o(\\mathbf x_i) _ 1,...o(\\mathbf x_i) _ B \\right] \\in \\Bbb R^B\n\\\\\\\\ &o(\\mathbf X) \\in \\Bbb R^{n \\times B} \\end{aligned}</script><p> minibatch layer  $o(\\mathbf x_i)$  minibatch layer  $\\mathbf {f(x_i)}$ concatenate  D  layer  minibatch layer <br><img src=\"/images/ImprovedGAN_fig1.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>G  D $|\\mathbf \\theta -\\frac 1 t \\sum_{i=1}^t \\theta[i]|^2$ $\\theta[i]$  i </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Label  target  0  1  0.9  0.1 target  $\\alpha$ target  $\\beta$</p>\n<script type=\"math/tex; mode=display\">D(\\mathbf x)=\\frac {\\alpha p_{data}(\\mathbf x) + \\beta p_{model}(\\mathbf x)}{p_{data}(\\mathbf x)+p_{model}(\\mathbf x)}</script><ul>\n<li> $p_{data}(\\mathbf x) \\gg p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\alpha$</li>\n<li> $p_{data}(\\mathbf x) \\ll p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\beta$</li>\n</ul>\n<p> <a href=\"2019/7/23/GAN\">GAN</a>  $D^{\\ast}$</p>\n<script type=\"math/tex; mode=display\">\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log (D(x)-\\beta)] + \\Bbb E_{z \\sim p_z(z)}[\\log(\\alpha-D(G(z)))] \\quad (1)</script><p> target  target $\\alpha &gt; \\beta$ (1)  D  $\\beta &lt; D(x) &lt; \\alpha$</p>\n<p> $p_{model}$ $p_{data} \\rightarrow 0$ $p_{model}$  $p_{model}$  label  $\\alpha$ label  0</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DCGAN  BN  $\\mathbf x$ minibatch  $\\mathbf x$ VBN $\\mathbf x$  reference batch  $\\mathbf x$ reference batch reference batch  VBN  G </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>GAN  Inception  label  $p(y|\\mathbf x)$ label  $p(y|\\mathbf x)$  $\\mathbf x$Inception  y  c zG  Inception  $\\int p(y|\\mathbf x=G(z)) dz$  KL </p>\n<script type=\"math/tex; mode=display\">\\exp [\\Bbb E_{\\mathbf x} \\mathbf {KL}(p(y|\\mathbf x)\\|p(y)) ]</script><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\mathbf x$ K  K  $[l_1,,l_K]$ softmax </p>\n<script type=\"math/tex; mode=display\">p_{model}(y=j|\\mathbf x)=\\frac {\\exp l_j} {\\sum_{k=1}^K \\exp l_k}</script><p> log </p>\n<p> G G  y=K+1 K+1 $p_{model}(y=K+1|\\mathbf x)$  $\\mathbf x$  GAN  $1-D(\\mathbf x)$  K  $\\log p_{model}(y \\in \\{1,,K\\}|\\mathbf x)$log </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} &L=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)}[\\log p_{model}(y|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]=L_{supervised}+L_{unsupervised}\n\\\\\\\\ &L_{supervised}=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)} \\log p_{model}(y|\\mathbf x, y <K+1)\n\\\\\\\\ &L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log[1- p_{model}(y=K+1|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]\\end{aligned}</script><p> $L_{unsupervised}$  GAN  objective $L_{unsupervised}$  $D(\\mathbf x)=1-p_{model}(y=K+1|\\mathbf x)$,</p>\n<script type=\"math/tex; mode=display\">L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log D(\\mathbf x) - \\Bbb E_{z \\sim noise} \\log (1-D(G(z)))</script><p> $L_{supervised}$  $L_{unsupervised}$  $\\exp[l_j(\\mathbf x)]=c(\\mathbf x) p(y=j,\\mathbf x), \\ \\forall j \\in K+1$  $\\exp[l_{K+1}(\\mathbf x)]=c(\\mathbf x) p_G(\\mathbf x)$ $c(\\mathbf x)$  G  GAN objective D G  GAN  G</p>\n<p> K+1  $l_j(\\mathbf x)\\leftarrow l_j(\\mathbf x)-f(\\mathbf x)$ softmax  $l_{K+1}(\\mathbf x)=0, \\ \\forall \\mathbf x$ $L_{supervised}$  K  D  $D(\\mathbf x)=\\frac {Z(\\mathbf x)} {Z(\\mathbf x)+1}$ $Z(\\mathbf x)=\\sum_{k=1}^K \\exp [l_k(\\mathbf x)]$</p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1606.03498\">Improved Techniques for Training GANs</a></p>\n<p> <a href=\"https://github.com/openai/improved_gan\">improved_gan</a><br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>GAN GAN  <a href=\"2019/07/23/GAN\">DCGAN</a>  GAN  conv+BN+ReLU  GAN  Nash  Nash </p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h1 id=\"GAN-\"><a href=\"#GAN-\" class=\"headerlink\" title=\"GAN \"></a>GAN </h1><p> GAN  Nash  $J^{(G)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$  $J^{(D)}(\\mathbf {\\theta}^{(D)}, \\mathbf {\\theta}^{G})$Nash  $J^{(D)}$  $\\theta^{(D)}$  $J^{(G)}$  $\\theta^{(G)}$  Nash  Nash  G  D  $\\theta^{(D)}$  $J^{(D)}$  $J^{(G)}$ $\\theta^{(G)}$  $J^{(G)}$  $J^{(D)}$ x  xy y  -xy x  y  x=y=0</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> GAN  D G  D  G  G  D  $\\mathbf {f(x)}$  D  G </p>\n<script type=\"math/tex; mode=display\">\\|\\Bbb E_{\\mathbf x \\sim p_{data}} \\mathbf {f(x)}-\\Bbb E_{\\mathbf z \\sim p_{\\mathbf z}}\\mathbf f(G(\\mathbf z))\\|_2^2</script><p>G </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>GAN  <strong></strong>  <strong></strong> </p>\n<p><br> $\\mathbf {f(x_i)} \\in \\Bbb R^A$  $\\mathbf x_i$  D  $T \\in \\Bbb R^{A \\times B \\times C}$ $M_i \\in \\Bbb R^{B \\times C}$ $i \\in \\{1,,n\\}$ $\\{M_i |i=1,,n\\}$ L1 </p>\n<script type=\"math/tex; mode=display\">c_b(\\mathbf x_i, \\mathbf x_j)=\\exp(-\\|M_{i,b}-M_{j,b}\\| _ {L_1}) \\in \\Bbb R, \\quad i,j \\in \\{1,...,n\\}, \\quad b \\in \\{1,...,B\\}</script><p> b  row index 1minibatch layer  $\\mathbf x_i$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} &o(\\mathbf x_i) _ b = \\sum_{j=1}^n c _ b(\\mathbf x_i, \\mathbf x_j) \\in \\Bbb R\n\\\\\\\\ &o(\\mathbf x_i)=\\left[o(\\mathbf x_i) _ 1,...o(\\mathbf x_i) _ B \\right] \\in \\Bbb R^B\n\\\\\\\\ &o(\\mathbf X) \\in \\Bbb R^{n \\times B} \\end{aligned}</script><p> minibatch layer  $o(\\mathbf x_i)$  minibatch layer  $\\mathbf {f(x_i)}$ concatenate  D  layer  minibatch layer <br><img src=\"/images/ImprovedGAN_fig1.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>G  D $|\\mathbf \\theta -\\frac 1 t \\sum_{i=1}^t \\theta[i]|^2$ $\\theta[i]$  i </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Label  target  0  1  0.9  0.1 target  $\\alpha$ target  $\\beta$</p>\n<script type=\"math/tex; mode=display\">D(\\mathbf x)=\\frac {\\alpha p_{data}(\\mathbf x) + \\beta p_{model}(\\mathbf x)}{p_{data}(\\mathbf x)+p_{model}(\\mathbf x)}</script><ul>\n<li> $p_{data}(\\mathbf x) \\gg p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\alpha$</li>\n<li> $p_{data}(\\mathbf x) \\ll p_{model}(\\mathbf x)$ $D(\\mathbf x) \\rightarrow \\beta$</li>\n</ul>\n<p> <a href=\"2019/7/23/GAN\">GAN</a>  $D^{\\ast}$</p>\n<script type=\"math/tex; mode=display\">\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log (D(x)-\\beta)] + \\Bbb E_{z \\sim p_z(z)}[\\log(\\alpha-D(G(z)))] \\quad (1)</script><p> target  target $\\alpha &gt; \\beta$ (1)  D  $\\beta &lt; D(x) &lt; \\alpha$</p>\n<p> $p_{model}$ $p_{data} \\rightarrow 0$ $p_{model}$  $p_{model}$  label  $\\alpha$ label  0</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DCGAN  BN  $\\mathbf x$ minibatch  $\\mathbf x$ VBN $\\mathbf x$  reference batch  $\\mathbf x$ reference batch reference batch  VBN  G </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>GAN  Inception  label  $p(y|\\mathbf x)$ label  $p(y|\\mathbf x)$  $\\mathbf x$Inception  y  c zG  Inception  $\\int p(y|\\mathbf x=G(z)) dz$  KL </p>\n<script type=\"math/tex; mode=display\">\\exp [\\Bbb E_{\\mathbf x} \\mathbf {KL}(p(y|\\mathbf x)\\|p(y)) ]</script><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\mathbf x$ K  K  $[l_1,,l_K]$ softmax </p>\n<script type=\"math/tex; mode=display\">p_{model}(y=j|\\mathbf x)=\\frac {\\exp l_j} {\\sum_{k=1}^K \\exp l_k}</script><p> log </p>\n<p> G G  y=K+1 K+1 $p_{model}(y=K+1|\\mathbf x)$  $\\mathbf x$  GAN  $1-D(\\mathbf x)$  K  $\\log p_{model}(y \\in \\{1,,K\\}|\\mathbf x)$log </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} &L=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)}[\\log p_{model}(y|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]=L_{supervised}+L_{unsupervised}\n\\\\\\\\ &L_{supervised}=-\\Bbb E_{\\mathbf x,y \\sim p_{data}(\\mathbf x,y)} \\log p_{model}(y|\\mathbf x, y <K+1)\n\\\\\\\\ &L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log[1- p_{model}(y=K+1|\\mathbf x)] - \\Bbb E_{\\mathbf x \\sim G} [\\log p_{model}(y=K+1|\\mathbf x)]\\end{aligned}</script><p> $L_{unsupervised}$  GAN  objective $L_{unsupervised}$  $D(\\mathbf x)=1-p_{model}(y=K+1|\\mathbf x)$,</p>\n<script type=\"math/tex; mode=display\">L_{unsupervised}=-\\Bbb E_{\\mathbf x \\sim p_{data}(\\mathbf x)} \\log D(\\mathbf x) - \\Bbb E_{z \\sim noise} \\log (1-D(G(z)))</script><p> $L_{supervised}$  $L_{unsupervised}$  $\\exp[l_j(\\mathbf x)]=c(\\mathbf x) p(y=j,\\mathbf x), \\ \\forall j \\in K+1$  $\\exp[l_{K+1}(\\mathbf x)]=c(\\mathbf x) p_G(\\mathbf x)$ $c(\\mathbf x)$  G  GAN objective D G  GAN  G</p>\n<p> K+1  $l_j(\\mathbf x)\\leftarrow l_j(\\mathbf x)-f(\\mathbf x)$ softmax  $l_{K+1}(\\mathbf x)=0, \\ \\forall \\mathbf x$ $L_{supervised}$  K  D  $D(\\mathbf x)=\\frac {Z(\\mathbf x)} {Z(\\mathbf x)+1}$ $Z(\\mathbf x)=\\sum_{k=1}^K \\exp [l_k(\\mathbf x)]$</p>"},{"title":"RepPoints","date":"2019-07-17T08:05:41.000Z","mathjax":true,"_content":" [RepPoints: Point Set Representation for Object Detection](https://arxiv.org/abs/1904.11490)\n<!-- more -->\n bbox  bbox  RepPointsrepresentative pointsRepPoints  gt RepPoints  anchor-free  anchor  anchor \n\n 1\n![](/images/RepPoints_fig1.png)\n\nRepPoints ~~RepPoints  bottom-up  box RepPoints  top-down  image/~~\n\n# RepPoints\n## BBox \n bbox  $\\mathcal B=(x,y,w,h)$ multi-stage  stage\n\nbbox anchors -(bbox reg)->  bbox proposals (S1)\n             -(bbox reg)->  bbox proposals (S2)\n             ...\n             -(bbox reg)->  bbox object targets\n\n scale  aspect ratio  anchorsanchor / bbox  proposal (S1) stage S1  RoIpooling/RoIAlign two-stage S1  box  multi-stage S1  S2 stage  bbox target\n\n 4-d  $(\\Delta x_p, \\Delta y_p, \\Delta w_p, \\Delta h_p)$ bbox proposal  $\\mathcal B_p=(x_p,y_p,w_p,h_p)$  bbox\n$$\\mathcal B_r=(x_p+w_p \\Delta x_p, \\ y_p+h_p\\Delta y_p, \\ w_p e^{\\Delta w_p}, \\ h_p e^{\\Delta h_p})$$\n\n gt  $\\mathcal B_t=(x_t,y_t,w_t,h_t)$gt gt target\n$$\\hat {\\mathcal F}(\\mathcal B_p, \\mathcal B_t)=(\\frac {x_t-x_p} {w_p},\\ \\frac {y_t-y_p} {h_p},\\ \\log \\frac {w_t} {w_p}, \\ \\log \\frac {h_t} {h_p})$$\n\n smooth L1 \n\n## RepPoints\n4-d bbox RepPoints \n$$\\mathcal R = \\{(x_k,y_k)\\}_{k=1}^n$$\n n  9\n\nRepPoints \n$$\\mathcal R_r = \\{(x_k+\\Delta x_k,\\ y_k+\\Delta y_k)\\}_{k=1}^n \\qquad (5)$$\n $\\{(\\Delta x_k,\\ \\Delta y_k)\\}_{k=1}^n$ refine \n\n__RepPoints  gt box:__ $\\mathcal {T: R}_P \\rightarrow \\mathcal B_P$ $\\mathcal R_P$  P  RepPoints$\\mathcal T(\\mathcal R_p)$  box\n1. Min-max function  \n   $\\mathcal {T=T_1}$ RepPoints  $\\mathcal B_p$\n\n2. Partial min-max function  \n   $\\mathcal {T=T_2}$ RepPoints  $\\mathcal B_p$\n\n3. Moment-based function  \n   $\\mathcal {T=T_3}$ RepPoints  $\\mathcal B_p$  scale scale  $\\lambda_x, \\ \\lambda_y$ box RepPoints RepPoints  size RepPoint  point loss \n\n__RepPoints __  RepPoints  pseudo box gt box  smooth L1 \n\n# RPDet\nmulti-stage  RepPoints \n\nobject centers -(RP refine)-> RepPoints proposals(S1) -(RP refine)-> RepPoints proposals(S2) ... -(RP refine)-> RepPoints object targets\n\nRPDet (RepPoints Detector)  2\n![](/images/RepPoints_fig2.png)\n\n N  RepPoints \n\n FPN backbone feature maps 3x3  offset field feature maps  spatial size  2N-channel  feature vector  2N-d  offsetsoffsets  deformable conv RepPoints deformable conv  offsets  offsets  pseudo box gt box  point losssmooth L1 \n\n offsets  deformable conv offsets (5)  refinement  RepPoints offsets  $\\Delta x, \\Delta y$ score maps\n\n##  RoI pooling \n RoI pooling  RepPoints  RoI pooling  proposals RoI pooling  RoI pooling  proposals RoI pooling \n\n# \n\n\n# \n","source":"_posts/RepPoints.md","raw":"---\ntitle: RepPoints\ndate: 2019-07-17 16:05:41\ntags: object detection\nmathjax: true\n---\n [RepPoints: Point Set Representation for Object Detection](https://arxiv.org/abs/1904.11490)\n<!-- more -->\n bbox  bbox  RepPointsrepresentative pointsRepPoints  gt RepPoints  anchor-free  anchor  anchor \n\n 1\n![](/images/RepPoints_fig1.png)\n\nRepPoints ~~RepPoints  bottom-up  box RepPoints  top-down  image/~~\n\n# RepPoints\n## BBox \n bbox  $\\mathcal B=(x,y,w,h)$ multi-stage  stage\n\nbbox anchors -(bbox reg)->  bbox proposals (S1)\n             -(bbox reg)->  bbox proposals (S2)\n             ...\n             -(bbox reg)->  bbox object targets\n\n scale  aspect ratio  anchorsanchor / bbox  proposal (S1) stage S1  RoIpooling/RoIAlign two-stage S1  box  multi-stage S1  S2 stage  bbox target\n\n 4-d  $(\\Delta x_p, \\Delta y_p, \\Delta w_p, \\Delta h_p)$ bbox proposal  $\\mathcal B_p=(x_p,y_p,w_p,h_p)$  bbox\n$$\\mathcal B_r=(x_p+w_p \\Delta x_p, \\ y_p+h_p\\Delta y_p, \\ w_p e^{\\Delta w_p}, \\ h_p e^{\\Delta h_p})$$\n\n gt  $\\mathcal B_t=(x_t,y_t,w_t,h_t)$gt gt target\n$$\\hat {\\mathcal F}(\\mathcal B_p, \\mathcal B_t)=(\\frac {x_t-x_p} {w_p},\\ \\frac {y_t-y_p} {h_p},\\ \\log \\frac {w_t} {w_p}, \\ \\log \\frac {h_t} {h_p})$$\n\n smooth L1 \n\n## RepPoints\n4-d bbox RepPoints \n$$\\mathcal R = \\{(x_k,y_k)\\}_{k=1}^n$$\n n  9\n\nRepPoints \n$$\\mathcal R_r = \\{(x_k+\\Delta x_k,\\ y_k+\\Delta y_k)\\}_{k=1}^n \\qquad (5)$$\n $\\{(\\Delta x_k,\\ \\Delta y_k)\\}_{k=1}^n$ refine \n\n__RepPoints  gt box:__ $\\mathcal {T: R}_P \\rightarrow \\mathcal B_P$ $\\mathcal R_P$  P  RepPoints$\\mathcal T(\\mathcal R_p)$  box\n1. Min-max function  \n   $\\mathcal {T=T_1}$ RepPoints  $\\mathcal B_p$\n\n2. Partial min-max function  \n   $\\mathcal {T=T_2}$ RepPoints  $\\mathcal B_p$\n\n3. Moment-based function  \n   $\\mathcal {T=T_3}$ RepPoints  $\\mathcal B_p$  scale scale  $\\lambda_x, \\ \\lambda_y$ box RepPoints RepPoints  size RepPoint  point loss \n\n__RepPoints __  RepPoints  pseudo box gt box  smooth L1 \n\n# RPDet\nmulti-stage  RepPoints \n\nobject centers -(RP refine)-> RepPoints proposals(S1) -(RP refine)-> RepPoints proposals(S2) ... -(RP refine)-> RepPoints object targets\n\nRPDet (RepPoints Detector)  2\n![](/images/RepPoints_fig2.png)\n\n N  RepPoints \n\n FPN backbone feature maps 3x3  offset field feature maps  spatial size  2N-channel  feature vector  2N-d  offsetsoffsets  deformable conv RepPoints deformable conv  offsets  offsets  pseudo box gt box  point losssmooth L1 \n\n offsets  deformable conv offsets (5)  refinement  RepPoints offsets  $\\Delta x, \\Delta y$ score maps\n\n##  RoI pooling \n RoI pooling  RepPoints  RoI pooling  proposals RoI pooling  RoI pooling  proposals RoI pooling \n\n# \n\n\n# \n","slug":"RepPoints","published":1,"updated":"2020-04-24T10:36:17.184Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90c000rp0djc83zgue2","content":"<p> <a href=\"https://arxiv.org/abs/1904.11490\">RepPoints: Point Set Representation for Object Detection</a><br><span id=\"more\"></span><br> bbox  bbox  RepPointsrepresentative pointsRepPoints  gt RepPoints  anchor-free  anchor  anchor </p>\n<p> 1<br><img src=\"/images/RepPoints_fig1.png\" alt=\"\"></p>\n<p>RepPoints <del>RepPoints  bottom-up  box RepPoints  top-down  image/</del></p>\n<h1 id=\"RepPoints\"><a href=\"#RepPoints\" class=\"headerlink\" title=\"RepPoints\"></a>RepPoints</h1><h2 id=\"BBox-\"><a href=\"#BBox-\" class=\"headerlink\" title=\"BBox \"></a>BBox </h2><p> bbox  $\\mathcal B=(x,y,w,h)$ multi-stage  stage</p>\n<p>bbox anchors -(bbox reg)-&gt;  bbox proposals (S1)<br>             -(bbox reg)-&gt;  bbox proposals (S2)<br>             <br>             -(bbox reg)-&gt;  bbox object targets</p>\n<p> scale  aspect ratio  anchorsanchor / bbox  proposal (S1) stage S1  RoIpooling/RoIAlign two-stage S1  box  multi-stage S1  S2 stage  bbox target</p>\n<p> 4-d  $(\\Delta x_p, \\Delta y_p, \\Delta w_p, \\Delta h_p)$ bbox proposal  $\\mathcal B_p=(x_p,y_p,w_p,h_p)$  bbox</p>\n<script type=\"math/tex; mode=display\">\\mathcal B_r=(x_p+w_p \\Delta x_p, \\ y_p+h_p\\Delta y_p, \\ w_p e^{\\Delta w_p}, \\ h_p e^{\\Delta h_p})</script><p> gt  $\\mathcal B_t=(x_t,y_t,w_t,h_t)$gt gt target</p>\n<script type=\"math/tex; mode=display\">\\hat {\\mathcal F}(\\mathcal B_p, \\mathcal B_t)=(\\frac {x_t-x_p} {w_p},\\ \\frac {y_t-y_p} {h_p},\\ \\log \\frac {w_t} {w_p}, \\ \\log \\frac {h_t} {h_p})</script><p> smooth L1 </p>\n<h2 id=\"RepPoints-1\"><a href=\"#RepPoints-1\" class=\"headerlink\" title=\"RepPoints\"></a>RepPoints</h2><p>4-d bbox RepPoints </p>\n<script type=\"math/tex; mode=display\">\\mathcal R = \\{(x_k,y_k)\\}_{k=1}^n</script><p> n  9</p>\n<p>RepPoints </p>\n<script type=\"math/tex; mode=display\">\\mathcal R_r = \\{(x_k+\\Delta x_k,\\ y_k+\\Delta y_k)\\}_{k=1}^n \\qquad (5)</script><p> $\\{(\\Delta x_k,\\ \\Delta y_k)\\}_{k=1}^n$ refine </p>\n<p><strong>RepPoints  gt box:</strong> $\\mathcal {T: R}_P \\rightarrow \\mathcal B_P$ $\\mathcal R_P$  P  RepPoints$\\mathcal T(\\mathcal R_p)$  box</p>\n<ol>\n<li><p>Min-max function<br>$\\mathcal {T=T_1}$ RepPoints  $\\mathcal B_p$</p>\n</li>\n<li><p>Partial min-max function<br>$\\mathcal {T=T_2}$ RepPoints  $\\mathcal B_p$</p>\n</li>\n<li><p>Moment-based function<br>$\\mathcal {T=T_3}$ RepPoints  $\\mathcal B_p$  scale scale  $\\lambda_x, \\ \\lambda_y$ box RepPoints RepPoints  size RepPoint  point loss </p>\n</li>\n</ol>\n<p><strong>RepPoints </strong>  RepPoints  pseudo box gt box  smooth L1 </p>\n<h1 id=\"RPDet\"><a href=\"#RPDet\" class=\"headerlink\" title=\"RPDet\"></a>RPDet</h1><p>multi-stage  RepPoints </p>\n<p>object centers -(RP refine)-&gt; RepPoints proposals(S1) -(RP refine)-&gt; RepPoints proposals(S2)  -(RP refine)-&gt; RepPoints object targets</p>\n<p>RPDet (RepPoints Detector)  2<br><img src=\"/images/RepPoints_fig2.png\" alt=\"\"></p>\n<p> N  RepPoints </p>\n<p> FPN backbone feature maps 3x3  offset field feature maps  spatial size  2N-channel  feature vector  2N-d  offsetsoffsets  deformable conv RepPoints deformable conv  offsets  offsets  pseudo box gt box  point losssmooth L1 </p>\n<p> offsets  deformable conv offsets (5)  refinement  RepPoints offsets  $\\Delta x, \\Delta y$ score maps</p>\n<h2 id=\"-RoI-pooling-\"><a href=\"#-RoI-pooling-\" class=\"headerlink\" title=\" RoI pooling \"></a> RoI pooling </h2><p> RoI pooling  RepPoints  RoI pooling  proposals RoI pooling  RoI pooling  proposals RoI pooling </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1904.11490\">RepPoints: Point Set Representation for Object Detection</a><br>","more":"<br> bbox  bbox  RepPointsrepresentative pointsRepPoints  gt RepPoints  anchor-free  anchor  anchor </p>\n<p> 1<br><img src=\"/images/RepPoints_fig1.png\" alt=\"\"></p>\n<p>RepPoints <del>RepPoints  bottom-up  box RepPoints  top-down  image/</del></p>\n<h1 id=\"RepPoints\"><a href=\"#RepPoints\" class=\"headerlink\" title=\"RepPoints\"></a>RepPoints</h1><h2 id=\"BBox-\"><a href=\"#BBox-\" class=\"headerlink\" title=\"BBox \"></a>BBox </h2><p> bbox  $\\mathcal B=(x,y,w,h)$ multi-stage  stage</p>\n<p>bbox anchors -(bbox reg)-&gt;  bbox proposals (S1)<br>             -(bbox reg)-&gt;  bbox proposals (S2)<br>             <br>             -(bbox reg)-&gt;  bbox object targets</p>\n<p> scale  aspect ratio  anchorsanchor / bbox  proposal (S1) stage S1  RoIpooling/RoIAlign two-stage S1  box  multi-stage S1  S2 stage  bbox target</p>\n<p> 4-d  $(\\Delta x_p, \\Delta y_p, \\Delta w_p, \\Delta h_p)$ bbox proposal  $\\mathcal B_p=(x_p,y_p,w_p,h_p)$  bbox</p>\n<script type=\"math/tex; mode=display\">\\mathcal B_r=(x_p+w_p \\Delta x_p, \\ y_p+h_p\\Delta y_p, \\ w_p e^{\\Delta w_p}, \\ h_p e^{\\Delta h_p})</script><p> gt  $\\mathcal B_t=(x_t,y_t,w_t,h_t)$gt gt target</p>\n<script type=\"math/tex; mode=display\">\\hat {\\mathcal F}(\\mathcal B_p, \\mathcal B_t)=(\\frac {x_t-x_p} {w_p},\\ \\frac {y_t-y_p} {h_p},\\ \\log \\frac {w_t} {w_p}, \\ \\log \\frac {h_t} {h_p})</script><p> smooth L1 </p>\n<h2 id=\"RepPoints-1\"><a href=\"#RepPoints-1\" class=\"headerlink\" title=\"RepPoints\"></a>RepPoints</h2><p>4-d bbox RepPoints </p>\n<script type=\"math/tex; mode=display\">\\mathcal R = \\{(x_k,y_k)\\}_{k=1}^n</script><p> n  9</p>\n<p>RepPoints </p>\n<script type=\"math/tex; mode=display\">\\mathcal R_r = \\{(x_k+\\Delta x_k,\\ y_k+\\Delta y_k)\\}_{k=1}^n \\qquad (5)</script><p> $\\{(\\Delta x_k,\\ \\Delta y_k)\\}_{k=1}^n$ refine </p>\n<p><strong>RepPoints  gt box:</strong> $\\mathcal {T: R}_P \\rightarrow \\mathcal B_P$ $\\mathcal R_P$  P  RepPoints$\\mathcal T(\\mathcal R_p)$  box</p>\n<ol>\n<li><p>Min-max function<br>$\\mathcal {T=T_1}$ RepPoints  $\\mathcal B_p$</p>\n</li>\n<li><p>Partial min-max function<br>$\\mathcal {T=T_2}$ RepPoints  $\\mathcal B_p$</p>\n</li>\n<li><p>Moment-based function<br>$\\mathcal {T=T_3}$ RepPoints  $\\mathcal B_p$  scale scale  $\\lambda_x, \\ \\lambda_y$ box RepPoints RepPoints  size RepPoint  point loss </p>\n</li>\n</ol>\n<p><strong>RepPoints </strong>  RepPoints  pseudo box gt box  smooth L1 </p>\n<h1 id=\"RPDet\"><a href=\"#RPDet\" class=\"headerlink\" title=\"RPDet\"></a>RPDet</h1><p>multi-stage  RepPoints </p>\n<p>object centers -(RP refine)-&gt; RepPoints proposals(S1) -(RP refine)-&gt; RepPoints proposals(S2)  -(RP refine)-&gt; RepPoints object targets</p>\n<p>RPDet (RepPoints Detector)  2<br><img src=\"/images/RepPoints_fig2.png\" alt=\"\"></p>\n<p> N  RepPoints </p>\n<p> FPN backbone feature maps 3x3  offset field feature maps  spatial size  2N-channel  feature vector  2N-d  offsetsoffsets  deformable conv RepPoints deformable conv  offsets  offsets  pseudo box gt box  point losssmooth L1 </p>\n<p> offsets  deformable conv offsets (5)  refinement  RepPoints offsets  $\\Delta x, \\Delta y$ score maps</p>\n<h2 id=\"-RoI-pooling-\"><a href=\"#-RoI-pooling-\" class=\"headerlink\" title=\" RoI pooling \"></a> RoI pooling </h2><p> RoI pooling  RepPoints  RoI pooling  proposals RoI pooling  RoI pooling  proposals RoI pooling </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>"},{"title":"TODO","date":"2021-02-02T03:51:13.000Z","_content":"\n/\n\nhttps://blog.csdn.net/songbinxu/article/details/79677948\n\nhttps://blog.csdn.net/itplus/article/details/21896453\n\nhttps://blog.csdn.net/itplus/article/details/21896619\n","source":"_posts/TODO.md","raw":"---\ntitle: TODO\ndate: 2021-02-02 11:51:13\ntags:\n---\n\n/\n\nhttps://blog.csdn.net/songbinxu/article/details/79677948\n\nhttps://blog.csdn.net/itplus/article/details/21896453\n\nhttps://blog.csdn.net/itplus/article/details/21896619\n","slug":"TODO","published":1,"updated":"2021-02-02T06:02:42.916Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90d000tp0dj74kh9jmg","content":"<p>/</p>\n<p><a href=\"https://blog.csdn.net/songbinxu/article/details/79677948\">https://blog.csdn.net/songbinxu/article/details/79677948</a></p>\n<p><a href=\"https://blog.csdn.net/itplus/article/details/21896453\">https://blog.csdn.net/itplus/article/details/21896453</a></p>\n<p><a href=\"https://blog.csdn.net/itplus/article/details/21896619\">https://blog.csdn.net/itplus/article/details/21896619</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>/</p>\n<p><a href=\"https://blog.csdn.net/songbinxu/article/details/79677948\">https://blog.csdn.net/songbinxu/article/details/79677948</a></p>\n<p><a href=\"https://blog.csdn.net/itplus/article/details/21896453\">https://blog.csdn.net/itplus/article/details/21896453</a></p>\n<p><a href=\"https://blog.csdn.net/itplus/article/details/21896619\">https://blog.csdn.net/itplus/article/details/21896619</a></p>\n"},{"title":"TridentNet","date":"2019-06-21T08:24:19.000Z","mathjax":true,"_content":"[Scale-Aware Trident Networks for Object Detection](https://arxiv.org/abs/1901.01892)\n<!-- more -->\n[TuSimple/simpledet](https://github.com/TuSimple/simpledet)\n# \n\n1. one stage YOLO, SSD\n2. two stage Faster R-CNN, R-FCN\n\n\n1.  image pyramids  1(a)\n2.  feature maps feature maps  SSD\n3. 2  low level  feature  high level  feature  RF  low level  feature FPN  bottom-up  top-down pathway   1(b) features  layers feature pyramids  image pyramids \n   \n![](/images/TridentNet_fig1(a).png) <center> fig1(a)</center>\n![](/images/TridentNet_fig1(b).png) <center> fig1(b)</center>\n![fig1(c)](/images/TridentNet_fig1(c).png) <center> fig1(c)</center>\n\n 1(c) trident  feature mapstrident  RF inference  TridentNet \n\n# \nbackbone  RF  backbone \n\n $d_s$ 3x3  RF  kernel size  $3+2(d_s-1)$  RF  feature map  image  s $d_s$  RF  $2(d_s-1)s$ n  RF  $2(d_s-1)sn$ n  feature map  image  s\n\n COCO benchmark  Faster R-CNNbackbone  ResNet-50  ResNet-101 _conv4_ stage  residual block  3x3  1-3  AP  a. b. c. d.  1\n\n| Backbone  |   Dilation | AP    | AP<sub>s</sub> | AP<sub>m</sub> | AP<sub>l</sub> |\n| ----------|----------- | :---: | :------------: | :------------: | :------------: |\n| ResNet-50 |  1         | 0.332 | __0.174__      | 0.384          | 0.464          |\n| ResNet-50 |  2         | 0.342 | 0.168          | __0.386__      | 0.486          |\n| ResNet-50 |  3         | 0.341 | 0.162          | 0.383          | __0.492__      |\n| ResNet-101|  1         | 0.372 | __0.200__      | __0.430__      | 0.528          |\n| ResNet-101|  2         | 0.380 | 0.191          | 0.427          | __0.538__      |\n| ResNet-101|  3         | 0.371 | 0.181          | 0.410          | __0.538__      |\n\n<font size=2> Table 1 COCO  RF  Faster R-CNN </font>\n\n RF ResNet-50  ResNet-101 \n1.  RF  RF \n2.  ResNet-101  RF  96x96 RF  RF \n\n# Trident \nTridentNet  trident  scale-aware \n## \n 2\n![](/images/TridentNet_fig2.png)\n\n image feature maps\n\n____  backbone  trident trident  1 \n\n ResNet  backbonebottleneck ResNet-50, ResNet=101  residual 1x13x31x1trident  residual  residual  residual  3x3  trident  RF backbone  stage  residual  trident  stage  stride  RF \n\n____  RPN  Fast R-CNN head\n\n1. TridentNet \n2.  feature maps feature pyramid \n3.  RF \n\n## scale-aware \ntrident  feature maps 1  scale-aware  or \n\n $[l_i,u_i]$ proposal  gt box  ROI  `(w,h)` $l_i \\le \\sqrt{wh} \\le u_i$ ROI  i \n\nscale-aware  RPN  Fast R-CNN  RPN  anchors /  box  scale-aware  gt box  anchor  Fast R-CNN head  proposal\n\n## Inference \nInference  NMS  soft-NMS \n\n____  inference  TridentNet [0,&infin;]  2  TridentNet  Faster R-CNN  TridentNet \n\n# \n COCO  80k  35k _trainval35k_ 5k _minival_\n\n## \n Faster R-CNN  MXNet  baseline backbone  ImageNet resize  image 800 Baseline  TridentNet  end-to-end  8  GPU batch size 16 12 epochs 0.02 8    10  epoch  10% ResNet  conv4 stage  backbone  feature maps conv5 stage  baseline  TridentNet  rcnn head TridentNet   image  128  ROIs TridentNet  123. scale-aware  [0,90][30,160][90,&infin;]\n\n COCO  AP $AP_{50}/AP_{75}$ $AP_s, AP_m, AP_l$  32x32, 32x32 ~ 96x96,  96x96\n\n## \n\n__TridentNet __ Baseline (Table 2(a))  ResNet-101  ResNet-101-Deformable  backbone Baseline   scale-aware \n![](/images/TridentNet_fig3.png)\n\n1. __Multi-branch__\n    Table 2(b) baseline  RF\n2. __Scale-aware__\n   Table 2(d)  Table 2(b)  scale-aware  $AP_s$ scale-sware \n3. __Weight-sharing__\n   Table 2(c)   Table 2(b) Table 2(e) TridentNet  Baseline  scale-aware \n\n____ Table 3  1-4  scale-aware Table 3  TridentNet baseline TridentNet\n\n| Branches | AP    | AP<sub>50</sub> | AP<sub>s</sub> | AP<sub>m</sub> | AP<sub>l</sub> |\n| :------: |:-----:| :-------------: | :------------: | :------------: | :------------: |\n| 1        | 33.2  | 53.8            | 17.4           |  38.4          | 46.4           |\n| 2        | 35.9  | 56.7            | __19.0__       |  40.6          | 51.2           |\n| 3        | __36.6__  | __57.3__    | 18.3           |  __41.4__      | __52.3__       |\n| 4        | 36.5  | __57.3__        | 18.8           |  __41.4__      | 51.9           |\n\n<font size=2> Table 3 COCO _minival_ ResNet-50</font>\n\n conv stage  trident  trident  TridentNet  SOTA \n\n# \n TridentNet  scale  feature maps scale-aware  inference  TridentNet baseline","source":"_posts/TridentNet.md","raw":"---\ntitle: TridentNet\ndate: 2019-06-21 16:24:19\ntags: object detection\nmathjax: true\n---\n[Scale-Aware Trident Networks for Object Detection](https://arxiv.org/abs/1901.01892)\n<!-- more -->\n[TuSimple/simpledet](https://github.com/TuSimple/simpledet)\n# \n\n1. one stage YOLO, SSD\n2. two stage Faster R-CNN, R-FCN\n\n\n1.  image pyramids  1(a)\n2.  feature maps feature maps  SSD\n3. 2  low level  feature  high level  feature  RF  low level  feature FPN  bottom-up  top-down pathway   1(b) features  layers feature pyramids  image pyramids \n   \n![](/images/TridentNet_fig1(a).png) <center> fig1(a)</center>\n![](/images/TridentNet_fig1(b).png) <center> fig1(b)</center>\n![fig1(c)](/images/TridentNet_fig1(c).png) <center> fig1(c)</center>\n\n 1(c) trident  feature mapstrident  RF inference  TridentNet \n\n# \nbackbone  RF  backbone \n\n $d_s$ 3x3  RF  kernel size  $3+2(d_s-1)$  RF  feature map  image  s $d_s$  RF  $2(d_s-1)s$ n  RF  $2(d_s-1)sn$ n  feature map  image  s\n\n COCO benchmark  Faster R-CNNbackbone  ResNet-50  ResNet-101 _conv4_ stage  residual block  3x3  1-3  AP  a. b. c. d.  1\n\n| Backbone  |   Dilation | AP    | AP<sub>s</sub> | AP<sub>m</sub> | AP<sub>l</sub> |\n| ----------|----------- | :---: | :------------: | :------------: | :------------: |\n| ResNet-50 |  1         | 0.332 | __0.174__      | 0.384          | 0.464          |\n| ResNet-50 |  2         | 0.342 | 0.168          | __0.386__      | 0.486          |\n| ResNet-50 |  3         | 0.341 | 0.162          | 0.383          | __0.492__      |\n| ResNet-101|  1         | 0.372 | __0.200__      | __0.430__      | 0.528          |\n| ResNet-101|  2         | 0.380 | 0.191          | 0.427          | __0.538__      |\n| ResNet-101|  3         | 0.371 | 0.181          | 0.410          | __0.538__      |\n\n<font size=2> Table 1 COCO  RF  Faster R-CNN </font>\n\n RF ResNet-50  ResNet-101 \n1.  RF  RF \n2.  ResNet-101  RF  96x96 RF  RF \n\n# Trident \nTridentNet  trident  scale-aware \n## \n 2\n![](/images/TridentNet_fig2.png)\n\n image feature maps\n\n____  backbone  trident trident  1 \n\n ResNet  backbonebottleneck ResNet-50, ResNet=101  residual 1x13x31x1trident  residual  residual  residual  3x3  trident  RF backbone  stage  residual  trident  stage  stride  RF \n\n____  RPN  Fast R-CNN head\n\n1. TridentNet \n2.  feature maps feature pyramid \n3.  RF \n\n## scale-aware \ntrident  feature maps 1  scale-aware  or \n\n $[l_i,u_i]$ proposal  gt box  ROI  `(w,h)` $l_i \\le \\sqrt{wh} \\le u_i$ ROI  i \n\nscale-aware  RPN  Fast R-CNN  RPN  anchors /  box  scale-aware  gt box  anchor  Fast R-CNN head  proposal\n\n## Inference \nInference  NMS  soft-NMS \n\n____  inference  TridentNet [0,&infin;]  2  TridentNet  Faster R-CNN  TridentNet \n\n# \n COCO  80k  35k _trainval35k_ 5k _minival_\n\n## \n Faster R-CNN  MXNet  baseline backbone  ImageNet resize  image 800 Baseline  TridentNet  end-to-end  8  GPU batch size 16 12 epochs 0.02 8    10  epoch  10% ResNet  conv4 stage  backbone  feature maps conv5 stage  baseline  TridentNet  rcnn head TridentNet   image  128  ROIs TridentNet  123. scale-aware  [0,90][30,160][90,&infin;]\n\n COCO  AP $AP_{50}/AP_{75}$ $AP_s, AP_m, AP_l$  32x32, 32x32 ~ 96x96,  96x96\n\n## \n\n__TridentNet __ Baseline (Table 2(a))  ResNet-101  ResNet-101-Deformable  backbone Baseline   scale-aware \n![](/images/TridentNet_fig3.png)\n\n1. __Multi-branch__\n    Table 2(b) baseline  RF\n2. __Scale-aware__\n   Table 2(d)  Table 2(b)  scale-aware  $AP_s$ scale-sware \n3. __Weight-sharing__\n   Table 2(c)   Table 2(b) Table 2(e) TridentNet  Baseline  scale-aware \n\n____ Table 3  1-4  scale-aware Table 3  TridentNet baseline TridentNet\n\n| Branches | AP    | AP<sub>50</sub> | AP<sub>s</sub> | AP<sub>m</sub> | AP<sub>l</sub> |\n| :------: |:-----:| :-------------: | :------------: | :------------: | :------------: |\n| 1        | 33.2  | 53.8            | 17.4           |  38.4          | 46.4           |\n| 2        | 35.9  | 56.7            | __19.0__       |  40.6          | 51.2           |\n| 3        | __36.6__  | __57.3__    | 18.3           |  __41.4__      | __52.3__       |\n| 4        | 36.5  | __57.3__        | 18.8           |  __41.4__      | 51.9           |\n\n<font size=2> Table 3 COCO _minival_ ResNet-50</font>\n\n conv stage  trident  trident  TridentNet  SOTA \n\n# \n TridentNet  scale  feature maps scale-aware  inference  TridentNet baseline","slug":"TridentNet","published":1,"updated":"2020-04-24T10:36:12.120Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90d000vp0dja7ogdasr","content":"<p><a href=\"https://arxiv.org/abs/1901.01892\">Scale-Aware Trident Networks for Object Detection</a><br><span id=\"more\"></span><br><a href=\"https://github.com/TuSimple/simpledet\">TuSimple/simpledet</a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li>one stage YOLO, SSD</li>\n<li>two stage Faster R-CNN, R-FCN</li>\n</ol>\n<p></p>\n<ol>\n<li> image pyramids  1(a)</li>\n<li> feature maps feature maps  SSD</li>\n<li>2  low level  feature  high level  feature  RF  low level  feature FPN  bottom-up  top-down pathway   1(b) features  layers feature pyramids  image pyramids </li>\n</ol>\n<p><img src=\"/images/TridentNet_fig1(a\" alt=\"\">.png) <center> fig1(a)</center><br><img src=\"/images/TridentNet_fig1(b\" alt=\"\">.png) <center> fig1(b)</center><br><img src=\"/images/TridentNet_fig1(c\" alt=\"fig1(c)\">.png) <center> fig1(c)</center></p>\n<p> 1(c) trident  feature mapstrident  RF inference  TridentNet </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>backbone  RF  backbone </p>\n<p> $d_s$ 3x3  RF  kernel size  $3+2(d_s-1)$  RF  feature map  image  s $d_s$  RF  $2(d_s-1)s$ n  RF  $2(d_s-1)sn$ n  feature map  image  s</p>\n<p> COCO benchmark  Faster R-CNNbackbone  ResNet-50  ResNet-101 _conv4_ stage  residual block  3x3  1-3  AP  a. b. c. d.  1</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Backbone</th>\n<th>Dilation</th>\n<th style=\"text-align:center\">AP</th>\n<th style=\"text-align:center\">AP<sub>s</sub></th>\n<th style=\"text-align:center\">AP<sub>m</sub></th>\n<th style=\"text-align:center\">AP<sub>l</sub></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ResNet-50</td>\n<td>1</td>\n<td style=\"text-align:center\">0.332</td>\n<td style=\"text-align:center\"><strong>0.174</strong></td>\n<td style=\"text-align:center\">0.384</td>\n<td style=\"text-align:center\">0.464</td>\n</tr>\n<tr>\n<td>ResNet-50</td>\n<td>2</td>\n<td style=\"text-align:center\">0.342</td>\n<td style=\"text-align:center\">0.168</td>\n<td style=\"text-align:center\"><strong>0.386</strong></td>\n<td style=\"text-align:center\">0.486</td>\n</tr>\n<tr>\n<td>ResNet-50</td>\n<td>3</td>\n<td style=\"text-align:center\">0.341</td>\n<td style=\"text-align:center\">0.162</td>\n<td style=\"text-align:center\">0.383</td>\n<td style=\"text-align:center\"><strong>0.492</strong></td>\n</tr>\n<tr>\n<td>ResNet-101</td>\n<td>1</td>\n<td style=\"text-align:center\">0.372</td>\n<td style=\"text-align:center\"><strong>0.200</strong></td>\n<td style=\"text-align:center\"><strong>0.430</strong></td>\n<td style=\"text-align:center\">0.528</td>\n</tr>\n<tr>\n<td>ResNet-101</td>\n<td>2</td>\n<td style=\"text-align:center\">0.380</td>\n<td style=\"text-align:center\">0.191</td>\n<td style=\"text-align:center\">0.427</td>\n<td style=\"text-align:center\"><strong>0.538</strong></td>\n</tr>\n<tr>\n<td>ResNet-101</td>\n<td>3</td>\n<td style=\"text-align:center\">0.371</td>\n<td style=\"text-align:center\">0.181</td>\n<td style=\"text-align:center\">0.410</td>\n<td style=\"text-align:center\"><strong>0.538</strong></td>\n</tr>\n</tbody>\n</table>\n</div>\n<font size=2> Table 1 COCO  RF  Faster R-CNN </font>\n\n<p> RF ResNet-50  ResNet-101 </p>\n<ol>\n<li> RF  RF </li>\n<li> ResNet-101  RF  96x96 RF  RF </li>\n</ol>\n<h1 id=\"Trident-\"><a href=\"#Trident-\" class=\"headerlink\" title=\"Trident \"></a>Trident </h1><p>TridentNet  trident  scale-aware </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> 2<br><img src=\"/images/TridentNet_fig2.png\" alt=\"\"></p>\n<p> image feature maps</p>\n<p><strong></strong>  backbone  trident trident  1 </p>\n<p> ResNet  backbonebottleneck ResNet-50, ResNet=101  residual 1x13x31x1trident  residual  residual  residual  3x3  trident  RF backbone  stage  residual  trident  stage  stride  RF </p>\n<p><strong></strong>  RPN  Fast R-CNN head<br></p>\n<ol>\n<li>TridentNet </li>\n<li> feature maps feature pyramid </li>\n<li> RF </li>\n</ol>\n<h2 id=\"scale-aware-\"><a href=\"#scale-aware-\" class=\"headerlink\" title=\"scale-aware \"></a>scale-aware </h2><p>trident  feature maps 1  scale-aware  or </p>\n<p> $[l_i,u_i]$ proposal  gt box  ROI  <code>(w,h)</code> $l_i \\le \\sqrt{wh} \\le u_i$ ROI  i </p>\n<p>scale-aware  RPN  Fast R-CNN  RPN  anchors /  box  scale-aware  gt box  anchor  Fast R-CNN head  proposal</p>\n<h2 id=\"Inference-\"><a href=\"#Inference-\" class=\"headerlink\" title=\"Inference \"></a>Inference </h2><p>Inference  NMS  soft-NMS </p>\n<p><strong></strong>  inference  TridentNet [0,&infin;]  2  TridentNet  Faster R-CNN  TridentNet </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> COCO  80k  35k _trainval35k_ 5k _minival_</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Faster R-CNN  MXNet  baseline backbone  ImageNet resize  image 800 Baseline  TridentNet  end-to-end  8  GPU batch size 16 12 epochs 0.02 8    10  epoch  10% ResNet  conv4 stage  backbone  feature maps conv5 stage  baseline  TridentNet  rcnn head TridentNet   image  128  ROIs TridentNet  123. scale-aware  [0,90][30,160][90,&infin;]</p>\n<p> COCO  AP $AP_{50}/AP_{75}$ $AP_s, AP_m, AP_l$  32x32, 32x32 ~ 96x96,  96x96</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>TridentNet </strong> Baseline (Table 2(a))  ResNet-101  ResNet-101-Deformable  backbone Baseline   scale-aware <br><img src=\"/images/TridentNet_fig3.png\" alt=\"\"></p>\n<ol>\n<li><strong>Multi-branch</strong><br> Table 2(b) baseline  RF</li>\n<li><strong>Scale-aware</strong><br>Table 2(d)  Table 2(b)  scale-aware  $AP_s$ scale-sware </li>\n<li><strong>Weight-sharing</strong><br>Table 2(c)   Table 2(b) Table 2(e) TridentNet  Baseline  scale-aware </li>\n</ol>\n<p><strong></strong> Table 3  1-4  scale-aware Table 3  TridentNet baseline TridentNet</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Branches</th>\n<th style=\"text-align:center\">AP</th>\n<th style=\"text-align:center\">AP<sub>50</sub></th>\n<th style=\"text-align:center\">AP<sub>s</sub></th>\n<th style=\"text-align:center\">AP<sub>m</sub></th>\n<th style=\"text-align:center\">AP<sub>l</sub></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">33.2</td>\n<td style=\"text-align:center\">53.8</td>\n<td style=\"text-align:center\">17.4</td>\n<td style=\"text-align:center\">38.4</td>\n<td style=\"text-align:center\">46.4</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">35.9</td>\n<td style=\"text-align:center\">56.7</td>\n<td style=\"text-align:center\"><strong>19.0</strong></td>\n<td style=\"text-align:center\">40.6</td>\n<td style=\"text-align:center\">51.2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\"><strong>36.6</strong></td>\n<td style=\"text-align:center\"><strong>57.3</strong></td>\n<td style=\"text-align:center\">18.3</td>\n<td style=\"text-align:center\"><strong>41.4</strong></td>\n<td style=\"text-align:center\"><strong>52.3</strong></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">36.5</td>\n<td style=\"text-align:center\"><strong>57.3</strong></td>\n<td style=\"text-align:center\">18.8</td>\n<td style=\"text-align:center\"><strong>41.4</strong></td>\n<td style=\"text-align:center\">51.9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<font size=2> Table 3 COCO _minival_ ResNet-50</font>\n\n<p> conv stage  trident  trident  TridentNet  SOTA </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> TridentNet  scale  feature maps scale-aware  inference  TridentNet baseline</p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://arxiv.org/abs/1901.01892\">Scale-Aware Trident Networks for Object Detection</a><br>","more":"<br><a href=\"https://github.com/TuSimple/simpledet\">TuSimple/simpledet</a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li>one stage YOLO, SSD</li>\n<li>two stage Faster R-CNN, R-FCN</li>\n</ol>\n<p></p>\n<ol>\n<li> image pyramids  1(a)</li>\n<li> feature maps feature maps  SSD</li>\n<li>2  low level  feature  high level  feature  RF  low level  feature FPN  bottom-up  top-down pathway   1(b) features  layers feature pyramids  image pyramids </li>\n</ol>\n<p><img src=\"/images/TridentNet_fig1(a\" alt=\"\">.png) <center> fig1(a)</center><br><img src=\"/images/TridentNet_fig1(b\" alt=\"\">.png) <center> fig1(b)</center><br><img src=\"/images/TridentNet_fig1(c\" alt=\"fig1(c)\">.png) <center> fig1(c)</center></p>\n<p> 1(c) trident  feature mapstrident  RF inference  TridentNet </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>backbone  RF  backbone </p>\n<p> $d_s$ 3x3  RF  kernel size  $3+2(d_s-1)$  RF  feature map  image  s $d_s$  RF  $2(d_s-1)s$ n  RF  $2(d_s-1)sn$ n  feature map  image  s</p>\n<p> COCO benchmark  Faster R-CNNbackbone  ResNet-50  ResNet-101 _conv4_ stage  residual block  3x3  1-3  AP  a. b. c. d.  1</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Backbone</th>\n<th>Dilation</th>\n<th style=\"text-align:center\">AP</th>\n<th style=\"text-align:center\">AP<sub>s</sub></th>\n<th style=\"text-align:center\">AP<sub>m</sub></th>\n<th style=\"text-align:center\">AP<sub>l</sub></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ResNet-50</td>\n<td>1</td>\n<td style=\"text-align:center\">0.332</td>\n<td style=\"text-align:center\"><strong>0.174</strong></td>\n<td style=\"text-align:center\">0.384</td>\n<td style=\"text-align:center\">0.464</td>\n</tr>\n<tr>\n<td>ResNet-50</td>\n<td>2</td>\n<td style=\"text-align:center\">0.342</td>\n<td style=\"text-align:center\">0.168</td>\n<td style=\"text-align:center\"><strong>0.386</strong></td>\n<td style=\"text-align:center\">0.486</td>\n</tr>\n<tr>\n<td>ResNet-50</td>\n<td>3</td>\n<td style=\"text-align:center\">0.341</td>\n<td style=\"text-align:center\">0.162</td>\n<td style=\"text-align:center\">0.383</td>\n<td style=\"text-align:center\"><strong>0.492</strong></td>\n</tr>\n<tr>\n<td>ResNet-101</td>\n<td>1</td>\n<td style=\"text-align:center\">0.372</td>\n<td style=\"text-align:center\"><strong>0.200</strong></td>\n<td style=\"text-align:center\"><strong>0.430</strong></td>\n<td style=\"text-align:center\">0.528</td>\n</tr>\n<tr>\n<td>ResNet-101</td>\n<td>2</td>\n<td style=\"text-align:center\">0.380</td>\n<td style=\"text-align:center\">0.191</td>\n<td style=\"text-align:center\">0.427</td>\n<td style=\"text-align:center\"><strong>0.538</strong></td>\n</tr>\n<tr>\n<td>ResNet-101</td>\n<td>3</td>\n<td style=\"text-align:center\">0.371</td>\n<td style=\"text-align:center\">0.181</td>\n<td style=\"text-align:center\">0.410</td>\n<td style=\"text-align:center\"><strong>0.538</strong></td>\n</tr>\n</tbody>\n</table>\n</div>\n<font size=2> Table 1 COCO  RF  Faster R-CNN </font>\n\n<p> RF ResNet-50  ResNet-101 </p>\n<ol>\n<li> RF  RF </li>\n<li> ResNet-101  RF  96x96 RF  RF </li>\n</ol>\n<h1 id=\"Trident-\"><a href=\"#Trident-\" class=\"headerlink\" title=\"Trident \"></a>Trident </h1><p>TridentNet  trident  scale-aware </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> 2<br><img src=\"/images/TridentNet_fig2.png\" alt=\"\"></p>\n<p> image feature maps</p>\n<p><strong></strong>  backbone  trident trident  1 </p>\n<p> ResNet  backbonebottleneck ResNet-50, ResNet=101  residual 1x13x31x1trident  residual  residual  residual  3x3  trident  RF backbone  stage  residual  trident  stage  stride  RF </p>\n<p><strong></strong>  RPN  Fast R-CNN head<br></p>\n<ol>\n<li>TridentNet </li>\n<li> feature maps feature pyramid </li>\n<li> RF </li>\n</ol>\n<h2 id=\"scale-aware-\"><a href=\"#scale-aware-\" class=\"headerlink\" title=\"scale-aware \"></a>scale-aware </h2><p>trident  feature maps 1  scale-aware  or </p>\n<p> $[l_i,u_i]$ proposal  gt box  ROI  <code>(w,h)</code> $l_i \\le \\sqrt{wh} \\le u_i$ ROI  i </p>\n<p>scale-aware  RPN  Fast R-CNN  RPN  anchors /  box  scale-aware  gt box  anchor  Fast R-CNN head  proposal</p>\n<h2 id=\"Inference-\"><a href=\"#Inference-\" class=\"headerlink\" title=\"Inference \"></a>Inference </h2><p>Inference  NMS  soft-NMS </p>\n<p><strong></strong>  inference  TridentNet [0,&infin;]  2  TridentNet  Faster R-CNN  TridentNet </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> COCO  80k  35k _trainval35k_ 5k _minival_</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Faster R-CNN  MXNet  baseline backbone  ImageNet resize  image 800 Baseline  TridentNet  end-to-end  8  GPU batch size 16 12 epochs 0.02 8    10  epoch  10% ResNet  conv4 stage  backbone  feature maps conv5 stage  baseline  TridentNet  rcnn head TridentNet   image  128  ROIs TridentNet  123. scale-aware  [0,90][30,160][90,&infin;]</p>\n<p> COCO  AP $AP_{50}/AP_{75}$ $AP_s, AP_m, AP_l$  32x32, 32x32 ~ 96x96,  96x96</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>TridentNet </strong> Baseline (Table 2(a))  ResNet-101  ResNet-101-Deformable  backbone Baseline   scale-aware <br><img src=\"/images/TridentNet_fig3.png\" alt=\"\"></p>\n<ol>\n<li><strong>Multi-branch</strong><br> Table 2(b) baseline  RF</li>\n<li><strong>Scale-aware</strong><br>Table 2(d)  Table 2(b)  scale-aware  $AP_s$ scale-sware </li>\n<li><strong>Weight-sharing</strong><br>Table 2(c)   Table 2(b) Table 2(e) TridentNet  Baseline  scale-aware </li>\n</ol>\n<p><strong></strong> Table 3  1-4  scale-aware Table 3  TridentNet baseline TridentNet</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Branches</th>\n<th style=\"text-align:center\">AP</th>\n<th style=\"text-align:center\">AP<sub>50</sub></th>\n<th style=\"text-align:center\">AP<sub>s</sub></th>\n<th style=\"text-align:center\">AP<sub>m</sub></th>\n<th style=\"text-align:center\">AP<sub>l</sub></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">33.2</td>\n<td style=\"text-align:center\">53.8</td>\n<td style=\"text-align:center\">17.4</td>\n<td style=\"text-align:center\">38.4</td>\n<td style=\"text-align:center\">46.4</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">35.9</td>\n<td style=\"text-align:center\">56.7</td>\n<td style=\"text-align:center\"><strong>19.0</strong></td>\n<td style=\"text-align:center\">40.6</td>\n<td style=\"text-align:center\">51.2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\"><strong>36.6</strong></td>\n<td style=\"text-align:center\"><strong>57.3</strong></td>\n<td style=\"text-align:center\">18.3</td>\n<td style=\"text-align:center\"><strong>41.4</strong></td>\n<td style=\"text-align:center\"><strong>52.3</strong></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">36.5</td>\n<td style=\"text-align:center\"><strong>57.3</strong></td>\n<td style=\"text-align:center\">18.8</td>\n<td style=\"text-align:center\"><strong>41.4</strong></td>\n<td style=\"text-align:center\">51.9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<font size=2> Table 3 COCO _minival_ ResNet-50</font>\n\n<p> conv stage  trident  trident  TridentNet  SOTA </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> TridentNet  scale  feature maps scale-aware  inference  TridentNet baseline</p>"},{"title":"WGAN","date":"2019-07-25T12:24:41.000Z","mathjax":true,"_content":" [Wasserstein GAN](https://arxiv.org/abs/1701.07875)","source":"_posts/WGAN.md","raw":"---\ntitle: WGAN\ndate: 2019-07-25 20:24:41\ntags: GAN\nmathjax: true\n---\n [Wasserstein GAN](https://arxiv.org/abs/1701.07875)","slug":"WGAN","published":1,"updated":"2020-04-24T09:25:42.769Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90e000xp0djgbhd4ge6","content":"<p> <a href=\"https://arxiv.org/abs/1701.07875\">Wasserstein GAN</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p> <a href=\"https://arxiv.org/abs/1701.07875\">Wasserstein GAN</a></p>\n"},{"title":"CV ","date":"2019-06-24T09:33:22.000Z","mathjax":true,"_content":" CV  CV\n<!-- more -->\n# RF\n k layer \n$$l_k=l_{k-1}+[(f_k-1)\\prod_{i=0}^{k-1}s_i]$$\n$s_i$  i layer $f_k$  k layer $l_0=1, \\ s_0=1$\n# NMS\n Faster R-CNN Test ProposalLayer  anchorsRPN  anchors  anchors  proposalsproposals  anchors \n1. proposal  image  [0,w-1], [0,h-1] proposal  clip  proposal \n2.  proposalproposal  image  box  16\n3.  proposals  top N1  proposalsN1 \n4.  NMS\n5.  proposals  top N2  proposalsN2 \n\nNMS \n1.  proposals  P A proposals  I proposals  K \n2.  proposal I[0] K `K.append(I[0])` I  proposal  IOUs I  IOU  proposals  I[0]  proposal  I[0]  K \n3.  2 I  \n4. K  NMS  proposals \n\n# Soft-NMS\nNMS boxes  box gt boxes box  recall  soft-NMS [Improving Object Detection With One Line of Code](https://arxiv.org/pdf/1704.04503.pdf)\n\nSoft-NMS  NMS  NMS  box  0 Soft-NMS  box  rank list \n\n\n__Input__\n   * $\\mathcal B=\\{b_1,...,b_N\\}, \\mathcal S = \\{s_1,...,S_N\\}, N_t, m$\n   *  boxes scoresNMS 0.7 $m=1 \\rightarrow \\text{NMS}; \\ m=2\\rightarrow \\text{Soft-NMS}$\n\n$\\mathcal D \\leftarrow \\{\\}$\n\n__while__ $\\mathcal B \\ne \\varnothing$ __do__\n\n&emsp; &emsp; $m \\leftarrow \\arg \\max \\mathcal S$\n\n&emsp; &emsp; $\\mathcal M \\leftarrow b_m$\n\n&emsp; &emsp; $\\mathcal D \\leftarrow \\mathcal {D \\cup M}; \\mathcal B \\leftarrow \\mathcal{B-M}$\n\n&emsp; &emsp; __for__ $b_i \\in \\mathcal B$ __do__\n\n&emsp; &emsp; &emsp; &emsp; __if__ $iou(\\mathcal M, b_i) > N_t$ __then__\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; __if__ $m=1$ __then__\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $\\mathcal {B \\leftarrow B} - b_i; \\mathcal {S \\leftarrow S} - s_i$\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; __else if__ $m=2$\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $s_i \\leftarrow s_i f[iou(\\mathcal M, b_i)]$\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; __end__\n\n&emsp; &emsp; &emsp; &emsp; __end__\n\n&emsp; &emsp; __end__\n\n__end__\n\n__return__ $\\mathcal {D,S}$\n\n Soft-NMS  f  NMS  Soft-NMS box  $s_i=s_i f(i)$ f \n1. NMS\n   $$f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 0 & iou(\\mathcal M, b_i) \\ge N_t\\end{cases}$$\n\n2. Soft-NMS\n   \n   $$f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 1-iou(\\mathcal M, b_i) & iou(\\mathcal M, b_i) \\ge N_t \\end{cases}$$\n    iou  iou=N<sub>t</sub> \n   $$f(i)=e^{-\\frac {iou(\\mathcal M, b_i)^2} \\sigma}, \\ \\forall b_i \\notin \\mathcal D$$\n    iou=0  $\\sigma$ $\\sigma$  iou \n\n# Deconvolution\n CV  semantic segmentation  bilinear interpolation\n(to be continued...)","source":"_posts/cv-mtds.md","raw":"---\ntitle: CV \ndate: 2019-06-24 17:33:22\ntags: CV\nmathjax: true\n---\n CV  CV\n<!-- more -->\n# RF\n k layer \n$$l_k=l_{k-1}+[(f_k-1)\\prod_{i=0}^{k-1}s_i]$$\n$s_i$  i layer $f_k$  k layer $l_0=1, \\ s_0=1$\n# NMS\n Faster R-CNN Test ProposalLayer  anchorsRPN  anchors  anchors  proposalsproposals  anchors \n1. proposal  image  [0,w-1], [0,h-1] proposal  clip  proposal \n2.  proposalproposal  image  box  16\n3.  proposals  top N1  proposalsN1 \n4.  NMS\n5.  proposals  top N2  proposalsN2 \n\nNMS \n1.  proposals  P A proposals  I proposals  K \n2.  proposal I[0] K `K.append(I[0])` I  proposal  IOUs I  IOU  proposals  I[0]  proposal  I[0]  K \n3.  2 I  \n4. K  NMS  proposals \n\n# Soft-NMS\nNMS boxes  box gt boxes box  recall  soft-NMS [Improving Object Detection With One Line of Code](https://arxiv.org/pdf/1704.04503.pdf)\n\nSoft-NMS  NMS  NMS  box  0 Soft-NMS  box  rank list \n\n\n__Input__\n   * $\\mathcal B=\\{b_1,...,b_N\\}, \\mathcal S = \\{s_1,...,S_N\\}, N_t, m$\n   *  boxes scoresNMS 0.7 $m=1 \\rightarrow \\text{NMS}; \\ m=2\\rightarrow \\text{Soft-NMS}$\n\n$\\mathcal D \\leftarrow \\{\\}$\n\n__while__ $\\mathcal B \\ne \\varnothing$ __do__\n\n&emsp; &emsp; $m \\leftarrow \\arg \\max \\mathcal S$\n\n&emsp; &emsp; $\\mathcal M \\leftarrow b_m$\n\n&emsp; &emsp; $\\mathcal D \\leftarrow \\mathcal {D \\cup M}; \\mathcal B \\leftarrow \\mathcal{B-M}$\n\n&emsp; &emsp; __for__ $b_i \\in \\mathcal B$ __do__\n\n&emsp; &emsp; &emsp; &emsp; __if__ $iou(\\mathcal M, b_i) > N_t$ __then__\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; __if__ $m=1$ __then__\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $\\mathcal {B \\leftarrow B} - b_i; \\mathcal {S \\leftarrow S} - s_i$\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; __else if__ $m=2$\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $s_i \\leftarrow s_i f[iou(\\mathcal M, b_i)]$\n\n&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; __end__\n\n&emsp; &emsp; &emsp; &emsp; __end__\n\n&emsp; &emsp; __end__\n\n__end__\n\n__return__ $\\mathcal {D,S}$\n\n Soft-NMS  f  NMS  Soft-NMS box  $s_i=s_i f(i)$ f \n1. NMS\n   $$f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 0 & iou(\\mathcal M, b_i) \\ge N_t\\end{cases}$$\n\n2. Soft-NMS\n   \n   $$f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 1-iou(\\mathcal M, b_i) & iou(\\mathcal M, b_i) \\ge N_t \\end{cases}$$\n    iou  iou=N<sub>t</sub> \n   $$f(i)=e^{-\\frac {iou(\\mathcal M, b_i)^2} \\sigma}, \\ \\forall b_i \\notin \\mathcal D$$\n    iou=0  $\\sigma$ $\\sigma$  iou \n\n# Deconvolution\n CV  semantic segmentation  bilinear interpolation\n(to be continued...)","slug":"cv-mtds","published":1,"updated":"2020-04-24T10:35:35.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90f000zp0dj9mkf4bd8","content":"<p> CV  CV<br><span id=\"more\"></span></p>\n<h1 id=\"RF\"><a href=\"#RF\" class=\"headerlink\" title=\"RF\"></a>RF</h1><p> k layer </p>\n<script type=\"math/tex; mode=display\">l_k=l_{k-1}+[(f_k-1)\\prod_{i=0}^{k-1}s_i]</script><p>$s_i$  i layer $f_k$  k layer $l_0=1, \\ s_0=1$</p>\n<h1 id=\"NMS\"><a href=\"#NMS\" class=\"headerlink\" title=\"NMS\"></a>NMS</h1><p> Faster R-CNN Test ProposalLayer  anchorsRPN  anchors  anchors  proposalsproposals  anchors </p>\n<ol>\n<li>proposal  image  [0,w-1], [0,h-1] proposal  clip  proposal </li>\n<li> proposalproposal  image  box  16</li>\n<li> proposals  top N1  proposalsN1 </li>\n<li> NMS</li>\n<li> proposals  top N2  proposalsN2 </li>\n</ol>\n<p>NMS </p>\n<ol>\n<li> proposals  P A proposals  I proposals  K </li>\n<li> proposal I[0] K <code>K.append(I[0])</code> I  proposal  IOUs I  IOU  proposals  I[0]  proposal  I[0]  K </li>\n<li> 2 I  </li>\n<li>K  NMS  proposals </li>\n</ol>\n<h1 id=\"Soft-NMS\"><a href=\"#Soft-NMS\" class=\"headerlink\" title=\"Soft-NMS\"></a>Soft-NMS</h1><p>NMS boxes  box gt boxes box  recall  soft-NMS <a href=\"https://arxiv.org/pdf/1704.04503.pdf\">Improving Object Detection With One Line of Code</a></p>\n<p>Soft-NMS  NMS  NMS  box  0 Soft-NMS  box  rank list </p>\n<p><strong>Input</strong></p>\n<ul>\n<li>$\\mathcal B=\\{b_1,,b_N\\}, \\mathcal S = \\{s_1,,S_N\\}, N_t, m$</li>\n<li> boxes scoresNMS 0.7 $m=1 \\rightarrow \\text{NMS}; \\ m=2\\rightarrow \\text{Soft-NMS}$</li>\n</ul>\n<p>$\\mathcal D \\leftarrow \\{\\}$</p>\n<p><strong>while</strong> $\\mathcal B \\ne \\varnothing$ <strong>do</strong></p>\n<p>&emsp; &emsp; $m \\leftarrow \\arg \\max \\mathcal S$</p>\n<p>&emsp; &emsp; $\\mathcal M \\leftarrow b_m$</p>\n<p>&emsp; &emsp; $\\mathcal D \\leftarrow \\mathcal {D \\cup M}; \\mathcal B \\leftarrow \\mathcal{B-M}$</p>\n<p>&emsp; &emsp; <strong>for</strong> $b_i \\in \\mathcal B$ <strong>do</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; <strong>if</strong> $iou(\\mathcal M, b_i) &gt; N_t$ <strong>then</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>if</strong> $m=1$ <strong>then</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $\\mathcal {B \\leftarrow B} - b_i; \\mathcal {S \\leftarrow S} - s_i$</p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>else if</strong> $m=2$</p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $s_i \\leftarrow s_i f[iou(\\mathcal M, b_i)]$</p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>end</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; <strong>end</strong></p>\n<p>&emsp; &emsp; <strong>end</strong></p>\n<p><strong>end</strong></p>\n<p><strong>return</strong> $\\mathcal {D,S}$</p>\n<p> Soft-NMS  f  NMS  Soft-NMS box  $s_i=s_i f(i)$ f </p>\n<ol>\n<li><p>NMS</p>\n<script type=\"math/tex; mode=display\">f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 0 & iou(\\mathcal M, b_i) \\ge N_t\\end{cases}</script></li>\n<li><p>Soft-NMS</p>\n<script type=\"math/tex; mode=display\">f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 1-iou(\\mathcal M, b_i) & iou(\\mathcal M, b_i) \\ge N_t \\end{cases}</script><p> iou  iou=N<sub>t</sub> </p>\n<script type=\"math/tex; mode=display\">f(i)=e^{-\\frac {iou(\\mathcal M, b_i)^2} \\sigma}, \\ \\forall b_i \\notin \\mathcal D</script><p> iou=0  $\\sigma$ $\\sigma$  iou </p>\n</li>\n</ol>\n<h1 id=\"Deconvolution\"><a href=\"#Deconvolution\" class=\"headerlink\" title=\"Deconvolution\"></a>Deconvolution</h1><p> CV  semantic segmentation  bilinear interpolation<br>(to be continued)</p>\n","site":{"data":{}},"excerpt":"<p> CV  CV<br>","more":"</p>\n<h1 id=\"RF\"><a href=\"#RF\" class=\"headerlink\" title=\"RF\"></a>RF</h1><p> k layer </p>\n<script type=\"math/tex; mode=display\">l_k=l_{k-1}+[(f_k-1)\\prod_{i=0}^{k-1}s_i]</script><p>$s_i$  i layer $f_k$  k layer $l_0=1, \\ s_0=1$</p>\n<h1 id=\"NMS\"><a href=\"#NMS\" class=\"headerlink\" title=\"NMS\"></a>NMS</h1><p> Faster R-CNN Test ProposalLayer  anchorsRPN  anchors  anchors  proposalsproposals  anchors </p>\n<ol>\n<li>proposal  image  [0,w-1], [0,h-1] proposal  clip  proposal </li>\n<li> proposalproposal  image  box  16</li>\n<li> proposals  top N1  proposalsN1 </li>\n<li> NMS</li>\n<li> proposals  top N2  proposalsN2 </li>\n</ol>\n<p>NMS </p>\n<ol>\n<li> proposals  P A proposals  I proposals  K </li>\n<li> proposal I[0] K <code>K.append(I[0])</code> I  proposal  IOUs I  IOU  proposals  I[0]  proposal  I[0]  K </li>\n<li> 2 I  </li>\n<li>K  NMS  proposals </li>\n</ol>\n<h1 id=\"Soft-NMS\"><a href=\"#Soft-NMS\" class=\"headerlink\" title=\"Soft-NMS\"></a>Soft-NMS</h1><p>NMS boxes  box gt boxes box  recall  soft-NMS <a href=\"https://arxiv.org/pdf/1704.04503.pdf\">Improving Object Detection With One Line of Code</a></p>\n<p>Soft-NMS  NMS  NMS  box  0 Soft-NMS  box  rank list </p>\n<p><strong>Input</strong></p>\n<ul>\n<li>$\\mathcal B=\\{b_1,,b_N\\}, \\mathcal S = \\{s_1,,S_N\\}, N_t, m$</li>\n<li> boxes scoresNMS 0.7 $m=1 \\rightarrow \\text{NMS}; \\ m=2\\rightarrow \\text{Soft-NMS}$</li>\n</ul>\n<p>$\\mathcal D \\leftarrow \\{\\}$</p>\n<p><strong>while</strong> $\\mathcal B \\ne \\varnothing$ <strong>do</strong></p>\n<p>&emsp; &emsp; $m \\leftarrow \\arg \\max \\mathcal S$</p>\n<p>&emsp; &emsp; $\\mathcal M \\leftarrow b_m$</p>\n<p>&emsp; &emsp; $\\mathcal D \\leftarrow \\mathcal {D \\cup M}; \\mathcal B \\leftarrow \\mathcal{B-M}$</p>\n<p>&emsp; &emsp; <strong>for</strong> $b_i \\in \\mathcal B$ <strong>do</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; <strong>if</strong> $iou(\\mathcal M, b_i) &gt; N_t$ <strong>then</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>if</strong> $m=1$ <strong>then</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $\\mathcal {B \\leftarrow B} - b_i; \\mathcal {S \\leftarrow S} - s_i$</p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>else if</strong> $m=2$</p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; $s_i \\leftarrow s_i f[iou(\\mathcal M, b_i)]$</p>\n<p>&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; <strong>end</strong></p>\n<p>&emsp; &emsp; &emsp; &emsp; <strong>end</strong></p>\n<p>&emsp; &emsp; <strong>end</strong></p>\n<p><strong>end</strong></p>\n<p><strong>return</strong> $\\mathcal {D,S}$</p>\n<p> Soft-NMS  f  NMS  Soft-NMS box  $s_i=s_i f(i)$ f </p>\n<ol>\n<li><p>NMS</p>\n<script type=\"math/tex; mode=display\">f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 0 & iou(\\mathcal M, b_i) \\ge N_t\\end{cases}</script></li>\n<li><p>Soft-NMS</p>\n<script type=\"math/tex; mode=display\">f(i) = \\begin{cases} 1 & iou(\\mathcal M, b_i) < N_t \\\\ 1-iou(\\mathcal M, b_i) & iou(\\mathcal M, b_i) \\ge N_t \\end{cases}</script><p> iou  iou=N<sub>t</sub> </p>\n<script type=\"math/tex; mode=display\">f(i)=e^{-\\frac {iou(\\mathcal M, b_i)^2} \\sigma}, \\ \\forall b_i \\notin \\mathcal D</script><p> iou=0  $\\sigma$ $\\sigma$  iou </p>\n</li>\n</ol>\n<h1 id=\"Deconvolution\"><a href=\"#Deconvolution\" class=\"headerlink\" title=\"Deconvolution\"></a>Deconvolution</h1><p> CV  semantic segmentation  bilinear interpolation<br>(to be continued)</p>"},{"title":"libra-rcnn","date":"2019-07-03T12:07:44.000Z","mathjax":true,"_content":" [Libra R-CNN: Towards Balanced Learning for Object Detection](https://arxiv.org/abs/1904.02701)\n<!-- more -->\n# Introduction\n one-stage  two-stage image  Region  region \n1.  region \n2. \n3. \n\n 1\n![](/images/libra-rcnn_fig1.png) <center>  a. b. c.  </center>\n\n\n\n## \n 1:3 region  OHEM [1] OHEM  OHEM Focal loss  Focal loss  one-stage  two-stage  first stage  1:3 Focal loss \n\n## \nFPN  PANet  top-down  feature pyramid \n![](/images/libra-rcnn_figa.png)<center>FPN</center>\n\n a'  b,c \n\n## \n\n\n Libra R-CNN R-CNNLibra R-CNN \n1. IoU  gt box  IoU \n2.  feature pyramid ____ \n3.  L1 loss 1) 2)  3)  \n\n# Methodology\nLibra R-CNN  2\n![](/images/libra-rcnn_fig2.png)\n\n\n\n## IoU-balanced Sampling\n region  gt box  3  region  IoU \n![](/images/libra-rcnn_fig3.png)\n\n 3  60%  0.05  IoU 3  IoU  0.05  37% 30%  IoU  0.05 IoU  [0,0.05) \n\n IoU-balanced  IoU  IoU  M  N \n$$p=\\frac N M$$\n\n IoU  K  N/K  IoU-balanced sampling  k \n$$p_k=\\frac N K \\cdot \\frac 1 {M_k}, \\ k \\in [0,K)$$\n$M_k$  k  K=3\n\nIoU-balanced sampling  3 gt box \n\n### SOURCE CODE\n IoU balanced sampling \n1.  proposals  IoU `max_overlaps`\n2.  proposals  IoU `max_iou=max_overlaps.max()`\n3.  `floor_thr` `(floor_thr, max_iou)`  proposals  IoU balanced sampling\n4. bin K N N/K IoU  `(max_iou-floor_thr)/K`\n5.  k  IoU  `[sk,ek)`\n6.  k  proposals  index\n   ```python\n   tmp_set = np.where(np.logical_and(max_overlaps>=sk, max_overlaps<ek))[0]\n   ```\n7.  k  index\n   ```python\n   tmp_inds = list(tmp_set & full_set) # full_set  floor_thr<iou<0.5  proposals  index\n   ```\n8.  7  k  index N/K \n   ```python\n   random_choice(tmp_inds, N/K)\n   ```\nIoU balanced sampling \n1.  proposals  gt  index `gt_inds`\n2.  1 `unique_gt_inds=gt_inds.unique()` gt  index\n   \n    gt  gt  proposals \n3.  gt  `num_gts=len(unique_gt_indx)` N  gt  `num_per_gt=N/num_gts` \n4.  i  gt `num_per_gt` \n   ```python\n   inds = torch.nonzero(assign_result.gt_inds == i.item())\n   inds = random_choice(inds, num_per_gt)\n   ```\n\n\n## Balanced Feature Pyramid\n ____  multi-level features 4\n![](/images/libra-rcnn_fig4.png)\n\n### \n l  $C_l$ L $l_{min}, l_{max}$ 4 $\\{C_2,C_3,C_4,C_5\\}$ resize  $C_4$ resize \n$$C=\\frac 1 L \\sum_{l_{min}}^{l_{max}} C_l$$\n\n rescale  4  Identity\n\n### \n non-local [2]\n\nBalanced feature pyramid $\\{P_2,P_3,P_4,P_5\\}$  FPN \n\n## Balanced L1 Loss\n Fast R-CNN \n$$L_{p,u,t^u,v}=L_{cls}(p,u) + \\lambda [u\\ge 1] L_{loc}(t^u,v)$$\n target  p  ut<sup>u</sup> v  target$\\lambda$  1.0  outliers 1.0  inliers\n\n target  $\\lambda$  outliers outliers Inliers  outliers inliers  30%  L1  smooth L1  $L_b$ inliers  outliers 1.0  outliers  5(a) ,\n![](/images/libra-rcnn_fig5.png)<center> regression error  |x|</center>\n\n L1  inliers  L1 \n$$L_{loc}=\\sum_{i \\in \\{x,y,w,h\\}} L_b (t_i^u-v_i)$$\n\n$$\\frac {\\partial L_{loc}} {\\partial w} \\propto \\frac {\\partial L_b} {\\partial t_i^u} \\propto \\frac {L_b} x$$\nw x  $t_i^u - v_i$ smooth L1  smooth L1 \n$$L_{loc}(t^u, v) = \\sum_{x,y,w,h} smooth_{L_1} (t_i^u-v_i)$$\n\n$$smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}$$\n smooth L1 \n$$\\frac {\\partial L_1} {\\partial |x|} = \\begin{cases} |x| & |x|<1\n\\\\\\\\ 1 & |x| \\ge 1 \\end{cases}$$\n |x| regression error inliers  |x|<1   |x|<1  smooth L1  |x|<1  $\\nabla_{|x|} L = |x|$  (0,0)  (1,1)  y=x (0,0) target  $|x| \\ge 1$  (1,1)  ____ \n$$\\frac {\\partial L_b} {\\partial x} = \\begin{cases} \\alpha \\ln (b|x|+1) & |x|<1\n\\\\\\\\ \\gamma & otherwise \\end{cases}$$\n $\\alpha$  inliers $\\gamma$  outliers $\\gamma$  5(a) b  |x|=1 \n$$L_b(x)=\\begin{cases} \\frac \\alpha b (b|x|+1) \\ln (b|x|+1) - \\alpha |x| & |x| < 1\n\\\\\\\\ \\gamma |x| + C & otherwise \\end{cases}$$\n |x|=1 \n$$\\frac \\alpha b (b+1) \\ln (b+1) - \\alpha=(\\alpha + \\frac \\alpha b) \\ln(b+1) -\\alpha = \\gamma + C$$\n C  $C=\\frac \\alpha b \\ln(b+1) -\\alpha$\n$$\\alpha \\ln (b+1)=\\gamma$$\n\n$$b=e^{\\gamma / \\alpha} -1\n\\\\\\\\ C=\\gamma/b-\\alpha$$\n\n 5(b) \n\n# Experiments\n\n\n# Conclusion\n Libra R-CNN\n1. IoU balanced sampling\n2. balanced feature pyramid\n3. balanced L1 loss\n\n# Reference\n1. Training Region-based Object Detectors with Online Hard Example Mining. Abhinav Shrivastava\n2. Non-local neural networks. Xiaolong Wang","source":"_posts/libra-rcnn.md","raw":"---\ntitle: libra-rcnn\ndate: 2019-07-03 20:07:44\ntags: object detection\nmathjax: true\n---\n [Libra R-CNN: Towards Balanced Learning for Object Detection](https://arxiv.org/abs/1904.02701)\n<!-- more -->\n# Introduction\n one-stage  two-stage image  Region  region \n1.  region \n2. \n3. \n\n 1\n![](/images/libra-rcnn_fig1.png) <center>  a. b. c.  </center>\n\n\n\n## \n 1:3 region  OHEM [1] OHEM  OHEM Focal loss  Focal loss  one-stage  two-stage  first stage  1:3 Focal loss \n\n## \nFPN  PANet  top-down  feature pyramid \n![](/images/libra-rcnn_figa.png)<center>FPN</center>\n\n a'  b,c \n\n## \n\n\n Libra R-CNN R-CNNLibra R-CNN \n1. IoU  gt box  IoU \n2.  feature pyramid ____ \n3.  L1 loss 1) 2)  3)  \n\n# Methodology\nLibra R-CNN  2\n![](/images/libra-rcnn_fig2.png)\n\n\n\n## IoU-balanced Sampling\n region  gt box  3  region  IoU \n![](/images/libra-rcnn_fig3.png)\n\n 3  60%  0.05  IoU 3  IoU  0.05  37% 30%  IoU  0.05 IoU  [0,0.05) \n\n IoU-balanced  IoU  IoU  M  N \n$$p=\\frac N M$$\n\n IoU  K  N/K  IoU-balanced sampling  k \n$$p_k=\\frac N K \\cdot \\frac 1 {M_k}, \\ k \\in [0,K)$$\n$M_k$  k  K=3\n\nIoU-balanced sampling  3 gt box \n\n### SOURCE CODE\n IoU balanced sampling \n1.  proposals  IoU `max_overlaps`\n2.  proposals  IoU `max_iou=max_overlaps.max()`\n3.  `floor_thr` `(floor_thr, max_iou)`  proposals  IoU balanced sampling\n4. bin K N N/K IoU  `(max_iou-floor_thr)/K`\n5.  k  IoU  `[sk,ek)`\n6.  k  proposals  index\n   ```python\n   tmp_set = np.where(np.logical_and(max_overlaps>=sk, max_overlaps<ek))[0]\n   ```\n7.  k  index\n   ```python\n   tmp_inds = list(tmp_set & full_set) # full_set  floor_thr<iou<0.5  proposals  index\n   ```\n8.  7  k  index N/K \n   ```python\n   random_choice(tmp_inds, N/K)\n   ```\nIoU balanced sampling \n1.  proposals  gt  index `gt_inds`\n2.  1 `unique_gt_inds=gt_inds.unique()` gt  index\n   \n    gt  gt  proposals \n3.  gt  `num_gts=len(unique_gt_indx)` N  gt  `num_per_gt=N/num_gts` \n4.  i  gt `num_per_gt` \n   ```python\n   inds = torch.nonzero(assign_result.gt_inds == i.item())\n   inds = random_choice(inds, num_per_gt)\n   ```\n\n\n## Balanced Feature Pyramid\n ____  multi-level features 4\n![](/images/libra-rcnn_fig4.png)\n\n### \n l  $C_l$ L $l_{min}, l_{max}$ 4 $\\{C_2,C_3,C_4,C_5\\}$ resize  $C_4$ resize \n$$C=\\frac 1 L \\sum_{l_{min}}^{l_{max}} C_l$$\n\n rescale  4  Identity\n\n### \n non-local [2]\n\nBalanced feature pyramid $\\{P_2,P_3,P_4,P_5\\}$  FPN \n\n## Balanced L1 Loss\n Fast R-CNN \n$$L_{p,u,t^u,v}=L_{cls}(p,u) + \\lambda [u\\ge 1] L_{loc}(t^u,v)$$\n target  p  ut<sup>u</sup> v  target$\\lambda$  1.0  outliers 1.0  inliers\n\n target  $\\lambda$  outliers outliers Inliers  outliers inliers  30%  L1  smooth L1  $L_b$ inliers  outliers 1.0  outliers  5(a) ,\n![](/images/libra-rcnn_fig5.png)<center> regression error  |x|</center>\n\n L1  inliers  L1 \n$$L_{loc}=\\sum_{i \\in \\{x,y,w,h\\}} L_b (t_i^u-v_i)$$\n\n$$\\frac {\\partial L_{loc}} {\\partial w} \\propto \\frac {\\partial L_b} {\\partial t_i^u} \\propto \\frac {L_b} x$$\nw x  $t_i^u - v_i$ smooth L1  smooth L1 \n$$L_{loc}(t^u, v) = \\sum_{x,y,w,h} smooth_{L_1} (t_i^u-v_i)$$\n\n$$smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}$$\n smooth L1 \n$$\\frac {\\partial L_1} {\\partial |x|} = \\begin{cases} |x| & |x|<1\n\\\\\\\\ 1 & |x| \\ge 1 \\end{cases}$$\n |x| regression error inliers  |x|<1   |x|<1  smooth L1  |x|<1  $\\nabla_{|x|} L = |x|$  (0,0)  (1,1)  y=x (0,0) target  $|x| \\ge 1$  (1,1)  ____ \n$$\\frac {\\partial L_b} {\\partial x} = \\begin{cases} \\alpha \\ln (b|x|+1) & |x|<1\n\\\\\\\\ \\gamma & otherwise \\end{cases}$$\n $\\alpha$  inliers $\\gamma$  outliers $\\gamma$  5(a) b  |x|=1 \n$$L_b(x)=\\begin{cases} \\frac \\alpha b (b|x|+1) \\ln (b|x|+1) - \\alpha |x| & |x| < 1\n\\\\\\\\ \\gamma |x| + C & otherwise \\end{cases}$$\n |x|=1 \n$$\\frac \\alpha b (b+1) \\ln (b+1) - \\alpha=(\\alpha + \\frac \\alpha b) \\ln(b+1) -\\alpha = \\gamma + C$$\n C  $C=\\frac \\alpha b \\ln(b+1) -\\alpha$\n$$\\alpha \\ln (b+1)=\\gamma$$\n\n$$b=e^{\\gamma / \\alpha} -1\n\\\\\\\\ C=\\gamma/b-\\alpha$$\n\n 5(b) \n\n# Experiments\n\n\n# Conclusion\n Libra R-CNN\n1. IoU balanced sampling\n2. balanced feature pyramid\n3. balanced L1 loss\n\n# Reference\n1. Training Region-based Object Detectors with Online Hard Example Mining. Abhinav Shrivastava\n2. Non-local neural networks. Xiaolong Wang","slug":"libra-rcnn","published":1,"updated":"2020-04-24T10:36:41.422Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90f0011p0dj4w5zb2v3","content":"<p> <a href=\"https://arxiv.org/abs/1904.02701\">Libra R-CNN: Towards Balanced Learning for Object Detection</a><br><span id=\"more\"></span></p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p> one-stage  two-stage image  Region  region </p>\n<ol>\n<li> region </li>\n<li></li>\n<li></li>\n</ol>\n<p> 1<br><img src=\"/images/libra-rcnn_fig1.png\" alt=\"\"> <center>  a. b. c.  </center></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> 1:3 region  OHEM [1] OHEM  OHEM Focal loss  Focal loss  one-stage  two-stage  first stage  1:3 Focal loss </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>FPN  PANet  top-down  feature pyramid <br><img src=\"/images/libra-rcnn_figa.png\" alt=\"\"><center>FPN</center></p>\n<p> a  b,c </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p> Libra R-CNN R-CNNLibra R-CNN </p>\n<ol>\n<li>IoU  gt box  IoU </li>\n<li> feature pyramid <strong></strong> </li>\n<li> L1 loss 1) 2)  3)  </li>\n</ol>\n<h1 id=\"Methodology\"><a href=\"#Methodology\" class=\"headerlink\" title=\"Methodology\"></a>Methodology</h1><p>Libra R-CNN  2<br><img src=\"/images/libra-rcnn_fig2.png\" alt=\"\"></p>\n<p></p>\n<h2 id=\"IoU-balanced-Sampling\"><a href=\"#IoU-balanced-Sampling\" class=\"headerlink\" title=\"IoU-balanced Sampling\"></a>IoU-balanced Sampling</h2><p> region  gt box  3  region  IoU <br><img src=\"/images/libra-rcnn_fig3.png\" alt=\"\"></p>\n<p> 3  60%  0.05  IoU 3  IoU  0.05  37% 30%  IoU  0.05 IoU  [0,0.05) </p>\n<p> IoU-balanced  IoU  IoU  M  N </p>\n<script type=\"math/tex; mode=display\">p=\\frac N M</script><p> IoU  K  N/K  IoU-balanced sampling  k </p>\n<script type=\"math/tex; mode=display\">p_k=\\frac N K \\cdot \\frac 1 {M_k}, \\ k \\in [0,K)</script><p>$M_k$  k  K=3</p>\n<p>IoU-balanced sampling  3 gt box </p>\n<h3 id=\"SOURCE-CODE\"><a href=\"#SOURCE-CODE\" class=\"headerlink\" title=\"SOURCE CODE\"></a>SOURCE CODE</h3><p> IoU balanced sampling </p>\n<ol>\n<li> proposals  IoU <code>max_overlaps</code></li>\n<li> proposals  IoU <code>max_iou=max_overlaps.max()</code></li>\n<li> <code>floor_thr</code> <code>(floor_thr, max_iou)</code>  proposals  IoU balanced sampling</li>\n<li>bin K N N/K IoU  <code>(max_iou-floor_thr)/K</code></li>\n<li> k  IoU  <code>[sk,ek)</code></li>\n<li> k  proposals  index<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp_set = np.where(np.logical_and(max_overlaps&gt;=sk, max_overlaps&lt;ek))[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></li>\n<li> k  index<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp_inds = <span class=\"built_in\">list</span>(tmp_set &amp; full_set) <span class=\"comment\"># full_set  floor_thr&lt;iou&lt;0.5  proposals  index</span></span><br></pre></td></tr></table></figure></li>\n<li> 7  k  index N/K <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">random_choice(tmp_inds, N/K)</span><br></pre></td></tr></table></figure>\nIoU balanced sampling </li>\n<li> proposals  gt  index <code>gt_inds</code></li>\n<li><p> 1 <code>unique_gt_inds=gt_inds.unique()</code> gt  index</p>\n<p> gt  gt  proposals </p>\n</li>\n<li> gt  <code>num_gts=len(unique_gt_indx)</code> N  gt  <code>num_per_gt=N/num_gts</code> </li>\n<li> i  gt <code>num_per_gt</code> <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inds = torch.nonzero(assign_result.gt_inds == i.item())</span><br><span class=\"line\">inds = random_choice(inds, num_per_gt)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"Balanced-Feature-Pyramid\"><a href=\"#Balanced-Feature-Pyramid\" class=\"headerlink\" title=\"Balanced Feature Pyramid\"></a>Balanced Feature Pyramid</h2><p> <strong></strong>  multi-level features 4<br><img src=\"/images/libra-rcnn_fig4.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> l  $C_l$ L $l_{min}, l_{max}$ 4 $\\{C_2,C_3,C_4,C_5\\}$ resize  $C_4$ resize </p>\n<script type=\"math/tex; mode=display\">C=\\frac 1 L \\sum_{l_{min}}^{l_{max}} C_l</script><p> rescale  4  Identity</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> non-local [2]</p>\n<p>Balanced feature pyramid $\\{P_2,P_3,P_4,P_5\\}$  FPN </p>\n<h2 id=\"Balanced-L1-Loss\"><a href=\"#Balanced-L1-Loss\" class=\"headerlink\" title=\"Balanced L1 Loss\"></a>Balanced L1 Loss</h2><p> Fast R-CNN </p>\n<script type=\"math/tex; mode=display\">L_{p,u,t^u,v}=L_{cls}(p,u) + \\lambda [u\\ge 1] L_{loc}(t^u,v)</script><p> target  p  ut<sup>u</sup> v  target$\\lambda$  1.0  outliers 1.0  inliers</p>\n<p> target  $\\lambda$  outliers outliers Inliers  outliers inliers  30%  L1  smooth L1  $L_b$ inliers  outliers 1.0  outliers  5(a) ,<br><img src=\"/images/libra-rcnn_fig5.png\" alt=\"\"><center> regression error  |x|</center></p>\n<p> L1  inliers  L1 </p>\n<script type=\"math/tex; mode=display\">L_{loc}=\\sum_{i \\in \\{x,y,w,h\\}} L_b (t_i^u-v_i)</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L_{loc}} {\\partial w} \\propto \\frac {\\partial L_b} {\\partial t_i^u} \\propto \\frac {L_b} x</script><p>w x  $t_i^u - v_i$ smooth L1  smooth L1 </p>\n<script type=\"math/tex; mode=display\">L_{loc}(t^u, v) = \\sum_{x,y,w,h} smooth_{L_1} (t_i^u-v_i)</script><p></p>\n<script type=\"math/tex; mode=display\">smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}</script><p> smooth L1 </p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L_1} {\\partial |x|} = \\begin{cases} |x| & |x|<1\n\\\\\\\\ 1 & |x| \\ge 1 \\end{cases}</script><p> |x| regression error inliers  |x|&lt;1   |x|&lt;1  smooth L1  |x|&lt;1  $\\nabla_{|x|} L = |x|$  (0,0)  (1,1)  y=x (0,0) target  $|x| \\ge 1$  (1,1)  <strong></strong> </p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L_b} {\\partial x} = \\begin{cases} \\alpha \\ln (b|x|+1) & |x|<1\n\\\\\\\\ \\gamma & otherwise \\end{cases}</script><p> $\\alpha$  inliers $\\gamma$  outliers $\\gamma$  5(a) b  |x|=1 </p>\n<script type=\"math/tex; mode=display\">L_b(x)=\\begin{cases} \\frac \\alpha b (b|x|+1) \\ln (b|x|+1) - \\alpha |x| & |x| < 1\n\\\\\\\\ \\gamma |x| + C & otherwise \\end{cases}</script><p> |x|=1 </p>\n<script type=\"math/tex; mode=display\">\\frac \\alpha b (b+1) \\ln (b+1) - \\alpha=(\\alpha + \\frac \\alpha b) \\ln(b+1) -\\alpha = \\gamma + C</script><p> C  $C=\\frac \\alpha b \\ln(b+1) -\\alpha$</p>\n<script type=\"math/tex; mode=display\">\\alpha \\ln (b+1)=\\gamma</script><p></p>\n<script type=\"math/tex; mode=display\">b=e^{\\gamma / \\alpha} -1\n\\\\\\\\ C=\\gamma/b-\\alpha</script><p> 5(b) </p>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p></p>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p> Libra R-CNN</p>\n<ol>\n<li>IoU balanced sampling</li>\n<li>balanced feature pyramid</li>\n<li>balanced L1 loss</li>\n</ol>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ol>\n<li>Training Region-based Object Detectors with Online Hard Example Mining. Abhinav Shrivastava</li>\n<li>Non-local neural networks. Xiaolong Wang</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1904.02701\">Libra R-CNN: Towards Balanced Learning for Object Detection</a><br>","more":"</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p> one-stage  two-stage image  Region  region </p>\n<ol>\n<li> region </li>\n<li></li>\n<li></li>\n</ol>\n<p> 1<br><img src=\"/images/libra-rcnn_fig1.png\" alt=\"\"> <center>  a. b. c.  </center></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> 1:3 region  OHEM [1] OHEM  OHEM Focal loss  Focal loss  one-stage  two-stage  first stage  1:3 Focal loss </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>FPN  PANet  top-down  feature pyramid <br><img src=\"/images/libra-rcnn_figa.png\" alt=\"\"><center>FPN</center></p>\n<p> a  b,c </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p> Libra R-CNN R-CNNLibra R-CNN </p>\n<ol>\n<li>IoU  gt box  IoU </li>\n<li> feature pyramid <strong></strong> </li>\n<li> L1 loss 1) 2)  3)  </li>\n</ol>\n<h1 id=\"Methodology\"><a href=\"#Methodology\" class=\"headerlink\" title=\"Methodology\"></a>Methodology</h1><p>Libra R-CNN  2<br><img src=\"/images/libra-rcnn_fig2.png\" alt=\"\"></p>\n<p></p>\n<h2 id=\"IoU-balanced-Sampling\"><a href=\"#IoU-balanced-Sampling\" class=\"headerlink\" title=\"IoU-balanced Sampling\"></a>IoU-balanced Sampling</h2><p> region  gt box  3  region  IoU <br><img src=\"/images/libra-rcnn_fig3.png\" alt=\"\"></p>\n<p> 3  60%  0.05  IoU 3  IoU  0.05  37% 30%  IoU  0.05 IoU  [0,0.05) </p>\n<p> IoU-balanced  IoU  IoU  M  N </p>\n<script type=\"math/tex; mode=display\">p=\\frac N M</script><p> IoU  K  N/K  IoU-balanced sampling  k </p>\n<script type=\"math/tex; mode=display\">p_k=\\frac N K \\cdot \\frac 1 {M_k}, \\ k \\in [0,K)</script><p>$M_k$  k  K=3</p>\n<p>IoU-balanced sampling  3 gt box </p>\n<h3 id=\"SOURCE-CODE\"><a href=\"#SOURCE-CODE\" class=\"headerlink\" title=\"SOURCE CODE\"></a>SOURCE CODE</h3><p> IoU balanced sampling </p>\n<ol>\n<li> proposals  IoU <code>max_overlaps</code></li>\n<li> proposals  IoU <code>max_iou=max_overlaps.max()</code></li>\n<li> <code>floor_thr</code> <code>(floor_thr, max_iou)</code>  proposals  IoU balanced sampling</li>\n<li>bin K N N/K IoU  <code>(max_iou-floor_thr)/K</code></li>\n<li> k  IoU  <code>[sk,ek)</code></li>\n<li> k  proposals  index<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp_set = np.where(np.logical_and(max_overlaps&gt;=sk, max_overlaps&lt;ek))[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure></li>\n<li> k  index<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tmp_inds = <span class=\"built_in\">list</span>(tmp_set &amp; full_set) <span class=\"comment\"># full_set  floor_thr&lt;iou&lt;0.5  proposals  index</span></span><br></pre></td></tr></table></figure></li>\n<li> 7  k  index N/K <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">random_choice(tmp_inds, N/K)</span><br></pre></td></tr></table></figure>\nIoU balanced sampling </li>\n<li> proposals  gt  index <code>gt_inds</code></li>\n<li><p> 1 <code>unique_gt_inds=gt_inds.unique()</code> gt  index</p>\n<p> gt  gt  proposals </p>\n</li>\n<li> gt  <code>num_gts=len(unique_gt_indx)</code> N  gt  <code>num_per_gt=N/num_gts</code> </li>\n<li> i  gt <code>num_per_gt</code> <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inds = torch.nonzero(assign_result.gt_inds == i.item())</span><br><span class=\"line\">inds = random_choice(inds, num_per_gt)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"Balanced-Feature-Pyramid\"><a href=\"#Balanced-Feature-Pyramid\" class=\"headerlink\" title=\"Balanced Feature Pyramid\"></a>Balanced Feature Pyramid</h2><p> <strong></strong>  multi-level features 4<br><img src=\"/images/libra-rcnn_fig4.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> l  $C_l$ L $l_{min}, l_{max}$ 4 $\\{C_2,C_3,C_4,C_5\\}$ resize  $C_4$ resize </p>\n<script type=\"math/tex; mode=display\">C=\\frac 1 L \\sum_{l_{min}}^{l_{max}} C_l</script><p> rescale  4  Identity</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> non-local [2]</p>\n<p>Balanced feature pyramid $\\{P_2,P_3,P_4,P_5\\}$  FPN </p>\n<h2 id=\"Balanced-L1-Loss\"><a href=\"#Balanced-L1-Loss\" class=\"headerlink\" title=\"Balanced L1 Loss\"></a>Balanced L1 Loss</h2><p> Fast R-CNN </p>\n<script type=\"math/tex; mode=display\">L_{p,u,t^u,v}=L_{cls}(p,u) + \\lambda [u\\ge 1] L_{loc}(t^u,v)</script><p> target  p  ut<sup>u</sup> v  target$\\lambda$  1.0  outliers 1.0  inliers</p>\n<p> target  $\\lambda$  outliers outliers Inliers  outliers inliers  30%  L1  smooth L1  $L_b$ inliers  outliers 1.0  outliers  5(a) ,<br><img src=\"/images/libra-rcnn_fig5.png\" alt=\"\"><center> regression error  |x|</center></p>\n<p> L1  inliers  L1 </p>\n<script type=\"math/tex; mode=display\">L_{loc}=\\sum_{i \\in \\{x,y,w,h\\}} L_b (t_i^u-v_i)</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L_{loc}} {\\partial w} \\propto \\frac {\\partial L_b} {\\partial t_i^u} \\propto \\frac {L_b} x</script><p>w x  $t_i^u - v_i$ smooth L1  smooth L1 </p>\n<script type=\"math/tex; mode=display\">L_{loc}(t^u, v) = \\sum_{x,y,w,h} smooth_{L_1} (t_i^u-v_i)</script><p></p>\n<script type=\"math/tex; mode=display\">smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}</script><p> smooth L1 </p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L_1} {\\partial |x|} = \\begin{cases} |x| & |x|<1\n\\\\\\\\ 1 & |x| \\ge 1 \\end{cases}</script><p> |x| regression error inliers  |x|&lt;1   |x|&lt;1  smooth L1  |x|&lt;1  $\\nabla_{|x|} L = |x|$  (0,0)  (1,1)  y=x (0,0) target  $|x| \\ge 1$  (1,1)  <strong></strong> </p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L_b} {\\partial x} = \\begin{cases} \\alpha \\ln (b|x|+1) & |x|<1\n\\\\\\\\ \\gamma & otherwise \\end{cases}</script><p> $\\alpha$  inliers $\\gamma$  outliers $\\gamma$  5(a) b  |x|=1 </p>\n<script type=\"math/tex; mode=display\">L_b(x)=\\begin{cases} \\frac \\alpha b (b|x|+1) \\ln (b|x|+1) - \\alpha |x| & |x| < 1\n\\\\\\\\ \\gamma |x| + C & otherwise \\end{cases}</script><p> |x|=1 </p>\n<script type=\"math/tex; mode=display\">\\frac \\alpha b (b+1) \\ln (b+1) - \\alpha=(\\alpha + \\frac \\alpha b) \\ln(b+1) -\\alpha = \\gamma + C</script><p> C  $C=\\frac \\alpha b \\ln(b+1) -\\alpha$</p>\n<script type=\"math/tex; mode=display\">\\alpha \\ln (b+1)=\\gamma</script><p></p>\n<script type=\"math/tex; mode=display\">b=e^{\\gamma / \\alpha} -1\n\\\\\\\\ C=\\gamma/b-\\alpha</script><p> 5(b) </p>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p></p>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p> Libra R-CNN</p>\n<ol>\n<li>IoU balanced sampling</li>\n<li>balanced feature pyramid</li>\n<li>balanced L1 loss</li>\n</ol>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><ol>\n<li>Training Region-based Object Detectors with Online Hard Example Mining. Abhinav Shrivastava</li>\n<li>Non-local neural networks. Xiaolong Wang</li>\n</ol>"},{"title":"loss","date":"2019-07-16T09:32:26.000Z","mathjax":true,"_content":" CV CV  CV \n<!-- more -->\n# Cross-Entropy Loss\n C softmax  $P=(p_1,...,p_C)$ $p_i$  i  $\\sum_i^C p_i=1$ c gt target  $T=(t_1,...,t_C)$\n$$t_i=\\begin{cases} 1 & i=c \\\\\\\\ 0 & i\\ne c \\end{cases}$$\n\n$$CE=-\\sum_{i=1}^C t_i \\log p_i$$\n\n## Binary Cross-Entropy Loss\n C=2  p t$t \\in \\{0,1\\}$\n$$CE=-t \\log p - (1-t) \\log (1-p)$$\n\n$$p_t=\\begin{cases} p & t=1 \\\\\\\\ 1-p & t=0 \\end{cases}$$\n\n$$ CE=-\\log p_t $$\n\n## Balanced Cross-Entropy Loss\nlong-tail distribution 1  0  1  1 t=1  $\\alpha$t=0  $1-\\alpha$$\\alpha \\in [0,1]$ $\\alpha$  $\\alpha$ RetinaNet  0.25\n$$CE=-\\alpha_t \\log p_t$$\n\n## Focal Loss\n balanced cross-entropy loss  $\\alpha$  $p_t \\gg 0.5$  Focal loss\n$$FL=-(1-p_t)^{\\gamma} \\log p_t \\ , \\ \\gamma \\ge 0$$\n $(1-p_t)^{\\gamma}$ \n\nFocal loss \n1. $p_t$  $(1-p_t)^{\\gamma}$ \n2. $p_t$  $(1-p_t)^{\\gamma}$ \n\n# MSE\n\n$$MSE = \\frac 1 n \\sum_{i=1}^n (Y_i-\\hat Y_i)^2$$\n n  L2  $Y_i, \\hat Y_i$  i \n\n## L2 Loss\n$$L_2=(Y_i-\\hat Y_i)^2$$\n $|Y_i-\\hat Y_i|>1$ \n## L1 Loss\n$$L_1=|Y_i-\\hat Y_i|$$\n $|Y_i-\\hat Y_i|<1$ \n## Smooth L1 Loss\n Smooth L1 \n$$L=smooth_{L_1}(Y_i-\\hat Y_i)\n\\\\\\\\ smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}$$\n\n## Regularized Loss\n L1  L2 \n\n","source":"_posts/loss.md","raw":"---\ntitle: loss\ndate: 2019-07-16 17:32:26\ntags: CV\nmathjax: true\n---\n CV CV  CV \n<!-- more -->\n# Cross-Entropy Loss\n C softmax  $P=(p_1,...,p_C)$ $p_i$  i  $\\sum_i^C p_i=1$ c gt target  $T=(t_1,...,t_C)$\n$$t_i=\\begin{cases} 1 & i=c \\\\\\\\ 0 & i\\ne c \\end{cases}$$\n\n$$CE=-\\sum_{i=1}^C t_i \\log p_i$$\n\n## Binary Cross-Entropy Loss\n C=2  p t$t \\in \\{0,1\\}$\n$$CE=-t \\log p - (1-t) \\log (1-p)$$\n\n$$p_t=\\begin{cases} p & t=1 \\\\\\\\ 1-p & t=0 \\end{cases}$$\n\n$$ CE=-\\log p_t $$\n\n## Balanced Cross-Entropy Loss\nlong-tail distribution 1  0  1  1 t=1  $\\alpha$t=0  $1-\\alpha$$\\alpha \\in [0,1]$ $\\alpha$  $\\alpha$ RetinaNet  0.25\n$$CE=-\\alpha_t \\log p_t$$\n\n## Focal Loss\n balanced cross-entropy loss  $\\alpha$  $p_t \\gg 0.5$  Focal loss\n$$FL=-(1-p_t)^{\\gamma} \\log p_t \\ , \\ \\gamma \\ge 0$$\n $(1-p_t)^{\\gamma}$ \n\nFocal loss \n1. $p_t$  $(1-p_t)^{\\gamma}$ \n2. $p_t$  $(1-p_t)^{\\gamma}$ \n\n# MSE\n\n$$MSE = \\frac 1 n \\sum_{i=1}^n (Y_i-\\hat Y_i)^2$$\n n  L2  $Y_i, \\hat Y_i$  i \n\n## L2 Loss\n$$L_2=(Y_i-\\hat Y_i)^2$$\n $|Y_i-\\hat Y_i|>1$ \n## L1 Loss\n$$L_1=|Y_i-\\hat Y_i|$$\n $|Y_i-\\hat Y_i|<1$ \n## Smooth L1 Loss\n Smooth L1 \n$$L=smooth_{L_1}(Y_i-\\hat Y_i)\n\\\\\\\\ smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}$$\n\n## Regularized Loss\n L1  L2 \n\n","slug":"loss","published":1,"updated":"2020-04-24T10:36:36.189Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90h0014p0dj39v68im5","content":"<p> CV CV  CV <br><span id=\"more\"></span></p>\n<h1 id=\"Cross-Entropy-Loss\"><a href=\"#Cross-Entropy-Loss\" class=\"headerlink\" title=\"Cross-Entropy Loss\"></a>Cross-Entropy Loss</h1><p> C softmax  $P=(p_1,,p_C)$ $p_i$  i  $\\sum_i^C p_i=1$ c gt target  $T=(t_1,,t_C)$</p>\n<script type=\"math/tex; mode=display\">t_i=\\begin{cases} 1 & i=c \\\\\\\\ 0 & i\\ne c \\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">CE=-\\sum_{i=1}^C t_i \\log p_i</script><h2 id=\"Binary-Cross-Entropy-Loss\"><a href=\"#Binary-Cross-Entropy-Loss\" class=\"headerlink\" title=\"Binary Cross-Entropy Loss\"></a>Binary Cross-Entropy Loss</h2><p> C=2  p t$t \\in \\{0,1\\}$</p>\n<script type=\"math/tex; mode=display\">CE=-t \\log p - (1-t) \\log (1-p)</script><p></p>\n<script type=\"math/tex; mode=display\">p_t=\\begin{cases} p & t=1 \\\\\\\\ 1-p & t=0 \\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">CE=-\\log p_t</script><h2 id=\"Balanced-Cross-Entropy-Loss\"><a href=\"#Balanced-Cross-Entropy-Loss\" class=\"headerlink\" title=\"Balanced Cross-Entropy Loss\"></a>Balanced Cross-Entropy Loss</h2><p>long-tail distribution 1  0  1  1 t=1  $\\alpha$t=0  $1-\\alpha$$\\alpha \\in [0,1]$ $\\alpha$  $\\alpha$ RetinaNet  0.25</p>\n<script type=\"math/tex; mode=display\">CE=-\\alpha_t \\log p_t</script><h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p> balanced cross-entropy loss  $\\alpha$  $p_t \\gg 0.5$  Focal loss</p>\n<script type=\"math/tex; mode=display\">FL=-(1-p_t)^{\\gamma} \\log p_t \\ , \\ \\gamma \\ge 0</script><p> $(1-p_t)^{\\gamma}$ </p>\n<p>Focal loss </p>\n<ol>\n<li>$p_t$  $(1-p_t)^{\\gamma}$ </li>\n<li>$p_t$  $(1-p_t)^{\\gamma}$ </li>\n</ol>\n<h1 id=\"MSE\"><a href=\"#MSE\" class=\"headerlink\" title=\"MSE\"></a>MSE</h1><p></p>\n<script type=\"math/tex; mode=display\">MSE = \\frac 1 n \\sum_{i=1}^n (Y_i-\\hat Y_i)^2</script><p> n  L2  $Y_i, \\hat Y_i$  i </p>\n<h2 id=\"L2-Loss\"><a href=\"#L2-Loss\" class=\"headerlink\" title=\"L2 Loss\"></a>L2 Loss</h2><script type=\"math/tex; mode=display\">L_2=(Y_i-\\hat Y_i)^2</script><p> $|Y_i-\\hat Y_i|&gt;1$ </p>\n<h2 id=\"L1-Loss\"><a href=\"#L1-Loss\" class=\"headerlink\" title=\"L1 Loss\"></a>L1 Loss</h2><script type=\"math/tex; mode=display\">L_1=|Y_i-\\hat Y_i|</script><p> $|Y_i-\\hat Y_i|&lt;1$ </p>\n<h2 id=\"Smooth-L1-Loss\"><a href=\"#Smooth-L1-Loss\" class=\"headerlink\" title=\"Smooth L1 Loss\"></a>Smooth L1 Loss</h2><p> Smooth L1 </p>\n<script type=\"math/tex; mode=display\">L=smooth_{L_1}(Y_i-\\hat Y_i)\n\\\\\\\\ smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}</script><h2 id=\"Regularized-Loss\"><a href=\"#Regularized-Loss\" class=\"headerlink\" title=\"Regularized Loss\"></a>Regularized Loss</h2><p> L1  L2 </p>\n","site":{"data":{}},"excerpt":"<p> CV CV  CV <br>","more":"</p>\n<h1 id=\"Cross-Entropy-Loss\"><a href=\"#Cross-Entropy-Loss\" class=\"headerlink\" title=\"Cross-Entropy Loss\"></a>Cross-Entropy Loss</h1><p> C softmax  $P=(p_1,,p_C)$ $p_i$  i  $\\sum_i^C p_i=1$ c gt target  $T=(t_1,,t_C)$</p>\n<script type=\"math/tex; mode=display\">t_i=\\begin{cases} 1 & i=c \\\\\\\\ 0 & i\\ne c \\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">CE=-\\sum_{i=1}^C t_i \\log p_i</script><h2 id=\"Binary-Cross-Entropy-Loss\"><a href=\"#Binary-Cross-Entropy-Loss\" class=\"headerlink\" title=\"Binary Cross-Entropy Loss\"></a>Binary Cross-Entropy Loss</h2><p> C=2  p t$t \\in \\{0,1\\}$</p>\n<script type=\"math/tex; mode=display\">CE=-t \\log p - (1-t) \\log (1-p)</script><p></p>\n<script type=\"math/tex; mode=display\">p_t=\\begin{cases} p & t=1 \\\\\\\\ 1-p & t=0 \\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">CE=-\\log p_t</script><h2 id=\"Balanced-Cross-Entropy-Loss\"><a href=\"#Balanced-Cross-Entropy-Loss\" class=\"headerlink\" title=\"Balanced Cross-Entropy Loss\"></a>Balanced Cross-Entropy Loss</h2><p>long-tail distribution 1  0  1  1 t=1  $\\alpha$t=0  $1-\\alpha$$\\alpha \\in [0,1]$ $\\alpha$  $\\alpha$ RetinaNet  0.25</p>\n<script type=\"math/tex; mode=display\">CE=-\\alpha_t \\log p_t</script><h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p> balanced cross-entropy loss  $\\alpha$  $p_t \\gg 0.5$  Focal loss</p>\n<script type=\"math/tex; mode=display\">FL=-(1-p_t)^{\\gamma} \\log p_t \\ , \\ \\gamma \\ge 0</script><p> $(1-p_t)^{\\gamma}$ </p>\n<p>Focal loss </p>\n<ol>\n<li>$p_t$  $(1-p_t)^{\\gamma}$ </li>\n<li>$p_t$  $(1-p_t)^{\\gamma}$ </li>\n</ol>\n<h1 id=\"MSE\"><a href=\"#MSE\" class=\"headerlink\" title=\"MSE\"></a>MSE</h1><p></p>\n<script type=\"math/tex; mode=display\">MSE = \\frac 1 n \\sum_{i=1}^n (Y_i-\\hat Y_i)^2</script><p> n  L2  $Y_i, \\hat Y_i$  i </p>\n<h2 id=\"L2-Loss\"><a href=\"#L2-Loss\" class=\"headerlink\" title=\"L2 Loss\"></a>L2 Loss</h2><script type=\"math/tex; mode=display\">L_2=(Y_i-\\hat Y_i)^2</script><p> $|Y_i-\\hat Y_i|&gt;1$ </p>\n<h2 id=\"L1-Loss\"><a href=\"#L1-Loss\" class=\"headerlink\" title=\"L1 Loss\"></a>L1 Loss</h2><script type=\"math/tex; mode=display\">L_1=|Y_i-\\hat Y_i|</script><p> $|Y_i-\\hat Y_i|&lt;1$ </p>\n<h2 id=\"Smooth-L1-Loss\"><a href=\"#Smooth-L1-Loss\" class=\"headerlink\" title=\"Smooth L1 Loss\"></a>Smooth L1 Loss</h2><p> Smooth L1 </p>\n<script type=\"math/tex; mode=display\">L=smooth_{L_1}(Y_i-\\hat Y_i)\n\\\\\\\\ smooth_{L_1}(x)=\\begin{cases} 0.5 x^2 & |x|<1\n\\\\\\\\ |x|-0.5 & otherwise \\end{cases}</script><h2 id=\"Regularized-Loss\"><a href=\"#Regularized-Loss\" class=\"headerlink\" title=\"Regularized Loss\"></a>Regularized Loss</h2><p> L1  L2 </p>"},{"title":"mAP","date":"2019-06-16T03:43:57.000Z","mathjax":true,"_content":"# mAP\n PASCAL VOC \n- mAPmean Average Precision mAP  AP  AP  AP  mAP\n<!-- more -->\n## \n0. Positive \n1. True Positive (TP): IoU  box\n2. False Positive (FP): IoU  box\n3. Precision = TP/(TP+FP) = TP/()\n4. Recall = TP/(TP+FN) = TP/(gt)\n\n TP,FP,TN,FN 4[](https://github.io/shajian/shajian.github.io) issue\n1. TP\n   \n   P (Positive) gt box  IoU $Threshold_{VOC}=0.5$ TP\n2. FP\n   \n   P (Positive) gt box  IoU  FP gt box  IoU  gt box match confidence  FP\n\n   $$\\left. \\begin{array}{} GT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_a, GT_i) \\\\\\\\\n   GT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_b, GT_i) \\\\\\\\\n   \\text{Conf}_a > \\text{Conf}_b \\end{array} \\right] \\Rightarrow Det_b \\in FP$$\n3. FN\n   \n    gt box  gt box  IoU 0 gt box  FN\n4. TN\n   \n   TN = 0 Positive  NegativeTN  Negative Positive\n\nVOC  `0.5`\n## \n### PR \n box  score  confidence confidence  box confidence  PRPrecision x Recall confidence  1  rank=1  PR  PR  R' >= R  P  PR [stackexchange](https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge)\n\n \"Aeroplane\",\n```\nBB  | confidence | GT\n----------------------\nBB1 |  0.9       | 1\n----------------------\nBB2 |  0.9       | 1\n----------------------\nBB3 |  0.7       | 0\n----------------------\nBB4 |  0.7       | 0\n----------------------\nBB5 |  0.7       | 1\n----------------------\nBB6 |  0.7       | 0\n----------------------\nBB7 |  0.7       | 0\n----------------------\nBB8 |  0.7       | 1\n----------------------\nBB9 |  0.7       | 1\n----------------------\n```\nBB  \"match\"  GT box\n\n confidence GT=1  TPGT=0  FP BBox FN=2TP=5 (BB1,BB2,BB5,BB8,BB9)FP=5 BB1 confidence  0.9  FP rank=3  case PASCAL VOC  Detection Task  [Evaluation](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/devkit_doc.html#SECTION00054000000000000000) GT box  TP+FN=5+2=7 PR \n```\nrank=1  precision=1.00 and recall=0.14\n----------\nrank=2  precision=1.00 and recall=0.29\n----------\nrank=3  precision=0.66 and recall=0.29\n----------\nrank=4  precision=0.50 and recall=0.29\n----------\nrank=5  precision=0.40 and recall=0.29\n----------\nrank=6  precision=0.50 and recall=0.43\n----------\nrank=7  precision=0.43 and recall=0.43\n----------\nrank=8  precision=0.38 and recall=0.43\n----------\nrank=9  precision=0.44 and recall=0.57\n----------\nrank=10 precision=0.50 and recall=0.71\n----------\n```\n\n\n1. rank=1 1TP  BB1  FP P=1R=1/7=0.14\n2. rank=2 2TP  BB1,BB2 FP P=1R=2/7=0.29\n3. rank=3 3TP  BB1,BB2FP  BB1 P=2/3=0.66R=2/7=0.29\n4. ...\n\n### AP\nVOC  2010  11  R   R={0,0.1,...,1} R' >= R  P  PR  AP  R average precisionVOC 2010  R' >= R  P  R  [0,1]  __PR __  AP  PR  AUC area under the curve\n\n#### 11-\n11 R  [0,1] \n$$AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,...,1}} \\rho_{interp(r)} \\qquad(1) \\\\\\\\\n\\rho_{interp(r)}=\\max_{\\tilde r:\\tilde r \\ge r} \\rho(\\tilde r) \\qquad(2) $$\n\n$\\rho(\\tilde r)$ \n[](https://github.com/rafaelpadilla/Object-Detection-Metrics)\n![](/images/mAP_fig1.png)\n\n PR 11 R  PR  R=0.2  (2) 0.2  $\\tilde r$  {0.2,0.2666,0.3333,0.4,0.4666} $\\tilde r=0.4$  P  0.4285 11- AP\n\n$AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,...,1}} \\rho_{interp(r)}$\n\n$AP=\\frac 1 {11}(1+0.6666+0.4285+0.4285+0.4285+0+0+0+0+0+0)$\n\n$AP=26.84\\%$\n\n#### \nAP \n$$AP=\\sum_{r=0}^1(r_{n+1}-r_n) \\rho_{interp}(r_{n+1}) \\qquad(3) \\\\\\\\\n\\rho_{interp}(r_{n+1})=\\max_{\\tilde r: \\tilde r \\ge r_{n+1}} \\rho(\\tilde r) \\qquad(4)$$\n$\\rho (\\tilde r)$  Recall $\\tilde r$  AP  PR  AUC\n\n![](/images/mAP_fig2.png)\n\n PR  RP  AUC  4 \n![](/images/mAP_fig3.png)\n\n AP \n\n$AP=A_1+A_2+A_3+A_4=(0.0666-0) \\times 1+(0.1333-0.0666) \\times 0.6666 \\\\\\\\ +(0.4-0.1333) \\times 0.4285+(0.4666-0.4) \\times 0.3043=24.56\\%$\n\n# ROC \n## \n1. TPR (true positive rate) (sensitivity) (recall)TPR = TP/(TP+FN)\n2. TNR (true negative rate) (specificity): TNR = TN/(FP+TN)\n3. FNR (false negative rate): FNR = 1 - TPR = FN/(TP+FN)\n4. FPR (false positive rate): FPR = 1 - TNR = FP/(FP+TN)\n5. LR+ (positive likelihood ratio):\n   \n   $LR^+=\\frac {TPR} {FPR} = \\frac {Sensitivily} {1-Specificity}$\n6. LR- (negative likelihood ratio):\n   \n   $LR^-=\\frac {FNR} {TNR} = \\frac {1-Sensitivity} {Specificity}$\n7. Youden index: Youden index = Sensitivity + Specificity - 1 = TPR - FPR\n\n## ROC \n\nROC \n\nROC  [receiver operating characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n\n TPR-FPR  ROC \n\n![](/images/mAP_fig4.png)\n\n (0,0)  (1,1) \n1.  1  Negative TP=FP=0 TPR=FPR=0\n2.  0  Positive TN=FN=0 TPR=FPR=1\n\n $(-\\infty,0) \\cup (1,+\\infty)$ $(-\\infty,0)$  2  $(1,+\\infty)$  1 \n\n ROC  y=x  y=x TPR  1FPR  0 ROC  (0,1) y=x\n\n## ROC \n X score T X>T X  $f_1(x)$ X  $f_0(x)$,\n$$TPR=\\int_T^{\\infty} f_1(x)dx \\\\\nFPR = \\int_T^{\\infty} f_0(x)dx$$\n T \n\n1. TPR(T) \n2. FPR(T) \n\n\n![ 5](/images/mAP_fig5.png)\n\n X  score score \n## AUC\n ROC  AUC \n\nAUC  Score  Score ROC  TPR  FPR  T \n$$TPR(T): T \\rightarrow y(x) \\\\\\\\\nFPR(T): T \\rightarrow x$$\n\n$$\nA =\\int_0^1 y(x) \\ dx  =\\int_0^1 TPR[FPR^{-1}(x)] \\ dx \\\\\\\\ \\stackrel{x=FPR(T)} =\\int_{-\\infty}^{+\\infty} TPR(T) \\ d[FPR(T)] =\\int_{-\\infty}^{+\\infty} TPR(T) \\cdot FPR \\ '(T) \\ dT \\\\\\\\ = \\int_{-\\infty}^{+\\infty} \\left( \\int_T^{+\\infty}  f_1(T') \\ dT' \\right) f_0(T) \\ dT \\\\\\\\ =\\int_{-\\infty}^{+\\infty}\\int_T^{+\\infty}  f_1(T')f_0(T) \\ dT' dT \\\\\\\\ = P(X_1>X_0)\n$$\n$X_1$ $X_0$\n\n $X_1$  $X_0$ :\n$$F_1(x)=\\int_{-\\infty}^{x} f_1(x) dx \\\\\\\\\nF_0(x)=\\int_{-\\infty}^{x} f_1(x) dx$$\n $f_1,f_0$\n\n$X_1, X_0$  $(X_1,X_0)$  $f(x_1,x_0)=f_1(x_1) f_0(x_0)$ $X_0 < X_1$ \n$$P(X_1>X_0)=\\iint_{G} f(x_1,x_0) dx_1 dx_0=\\int_{-\\infty}^{+\\infty}\\int_{x_0}^{+\\infty}f_1(x_1) f_0(x_0) \\ dx_1 dx_0$$\n","source":"_posts/mAP.md","raw":"---\ntitle: mAP\ndate: 2019-06-16 11:43:57\ntags: object detection\nmathjax: true\n---\n# mAP\n PASCAL VOC \n- mAPmean Average Precision mAP  AP  AP  AP  mAP\n<!-- more -->\n## \n0. Positive \n1. True Positive (TP): IoU  box\n2. False Positive (FP): IoU  box\n3. Precision = TP/(TP+FP) = TP/()\n4. Recall = TP/(TP+FN) = TP/(gt)\n\n TP,FP,TN,FN 4[](https://github.io/shajian/shajian.github.io) issue\n1. TP\n   \n   P (Positive) gt box  IoU $Threshold_{VOC}=0.5$ TP\n2. FP\n   \n   P (Positive) gt box  IoU  FP gt box  IoU  gt box match confidence  FP\n\n   $$\\left. \\begin{array}{} GT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_a, GT_i) \\\\\\\\\n   GT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_b, GT_i) \\\\\\\\\n   \\text{Conf}_a > \\text{Conf}_b \\end{array} \\right] \\Rightarrow Det_b \\in FP$$\n3. FN\n   \n    gt box  gt box  IoU 0 gt box  FN\n4. TN\n   \n   TN = 0 Positive  NegativeTN  Negative Positive\n\nVOC  `0.5`\n## \n### PR \n box  score  confidence confidence  box confidence  PRPrecision x Recall confidence  1  rank=1  PR  PR  R' >= R  P  PR [stackexchange](https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge)\n\n \"Aeroplane\",\n```\nBB  | confidence | GT\n----------------------\nBB1 |  0.9       | 1\n----------------------\nBB2 |  0.9       | 1\n----------------------\nBB3 |  0.7       | 0\n----------------------\nBB4 |  0.7       | 0\n----------------------\nBB5 |  0.7       | 1\n----------------------\nBB6 |  0.7       | 0\n----------------------\nBB7 |  0.7       | 0\n----------------------\nBB8 |  0.7       | 1\n----------------------\nBB9 |  0.7       | 1\n----------------------\n```\nBB  \"match\"  GT box\n\n confidence GT=1  TPGT=0  FP BBox FN=2TP=5 (BB1,BB2,BB5,BB8,BB9)FP=5 BB1 confidence  0.9  FP rank=3  case PASCAL VOC  Detection Task  [Evaluation](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/devkit_doc.html#SECTION00054000000000000000) GT box  TP+FN=5+2=7 PR \n```\nrank=1  precision=1.00 and recall=0.14\n----------\nrank=2  precision=1.00 and recall=0.29\n----------\nrank=3  precision=0.66 and recall=0.29\n----------\nrank=4  precision=0.50 and recall=0.29\n----------\nrank=5  precision=0.40 and recall=0.29\n----------\nrank=6  precision=0.50 and recall=0.43\n----------\nrank=7  precision=0.43 and recall=0.43\n----------\nrank=8  precision=0.38 and recall=0.43\n----------\nrank=9  precision=0.44 and recall=0.57\n----------\nrank=10 precision=0.50 and recall=0.71\n----------\n```\n\n\n1. rank=1 1TP  BB1  FP P=1R=1/7=0.14\n2. rank=2 2TP  BB1,BB2 FP P=1R=2/7=0.29\n3. rank=3 3TP  BB1,BB2FP  BB1 P=2/3=0.66R=2/7=0.29\n4. ...\n\n### AP\nVOC  2010  11  R   R={0,0.1,...,1} R' >= R  P  PR  AP  R average precisionVOC 2010  R' >= R  P  R  [0,1]  __PR __  AP  PR  AUC area under the curve\n\n#### 11-\n11 R  [0,1] \n$$AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,...,1}} \\rho_{interp(r)} \\qquad(1) \\\\\\\\\n\\rho_{interp(r)}=\\max_{\\tilde r:\\tilde r \\ge r} \\rho(\\tilde r) \\qquad(2) $$\n\n$\\rho(\\tilde r)$ \n[](https://github.com/rafaelpadilla/Object-Detection-Metrics)\n![](/images/mAP_fig1.png)\n\n PR 11 R  PR  R=0.2  (2) 0.2  $\\tilde r$  {0.2,0.2666,0.3333,0.4,0.4666} $\\tilde r=0.4$  P  0.4285 11- AP\n\n$AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,...,1}} \\rho_{interp(r)}$\n\n$AP=\\frac 1 {11}(1+0.6666+0.4285+0.4285+0.4285+0+0+0+0+0+0)$\n\n$AP=26.84\\%$\n\n#### \nAP \n$$AP=\\sum_{r=0}^1(r_{n+1}-r_n) \\rho_{interp}(r_{n+1}) \\qquad(3) \\\\\\\\\n\\rho_{interp}(r_{n+1})=\\max_{\\tilde r: \\tilde r \\ge r_{n+1}} \\rho(\\tilde r) \\qquad(4)$$\n$\\rho (\\tilde r)$  Recall $\\tilde r$  AP  PR  AUC\n\n![](/images/mAP_fig2.png)\n\n PR  RP  AUC  4 \n![](/images/mAP_fig3.png)\n\n AP \n\n$AP=A_1+A_2+A_3+A_4=(0.0666-0) \\times 1+(0.1333-0.0666) \\times 0.6666 \\\\\\\\ +(0.4-0.1333) \\times 0.4285+(0.4666-0.4) \\times 0.3043=24.56\\%$\n\n# ROC \n## \n1. TPR (true positive rate) (sensitivity) (recall)TPR = TP/(TP+FN)\n2. TNR (true negative rate) (specificity): TNR = TN/(FP+TN)\n3. FNR (false negative rate): FNR = 1 - TPR = FN/(TP+FN)\n4. FPR (false positive rate): FPR = 1 - TNR = FP/(FP+TN)\n5. LR+ (positive likelihood ratio):\n   \n   $LR^+=\\frac {TPR} {FPR} = \\frac {Sensitivily} {1-Specificity}$\n6. LR- (negative likelihood ratio):\n   \n   $LR^-=\\frac {FNR} {TNR} = \\frac {1-Sensitivity} {Specificity}$\n7. Youden index: Youden index = Sensitivity + Specificity - 1 = TPR - FPR\n\n## ROC \n\nROC \n\nROC  [receiver operating characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n\n TPR-FPR  ROC \n\n![](/images/mAP_fig4.png)\n\n (0,0)  (1,1) \n1.  1  Negative TP=FP=0 TPR=FPR=0\n2.  0  Positive TN=FN=0 TPR=FPR=1\n\n $(-\\infty,0) \\cup (1,+\\infty)$ $(-\\infty,0)$  2  $(1,+\\infty)$  1 \n\n ROC  y=x  y=x TPR  1FPR  0 ROC  (0,1) y=x\n\n## ROC \n X score T X>T X  $f_1(x)$ X  $f_0(x)$,\n$$TPR=\\int_T^{\\infty} f_1(x)dx \\\\\nFPR = \\int_T^{\\infty} f_0(x)dx$$\n T \n\n1. TPR(T) \n2. FPR(T) \n\n\n![ 5](/images/mAP_fig5.png)\n\n X  score score \n## AUC\n ROC  AUC \n\nAUC  Score  Score ROC  TPR  FPR  T \n$$TPR(T): T \\rightarrow y(x) \\\\\\\\\nFPR(T): T \\rightarrow x$$\n\n$$\nA =\\int_0^1 y(x) \\ dx  =\\int_0^1 TPR[FPR^{-1}(x)] \\ dx \\\\\\\\ \\stackrel{x=FPR(T)} =\\int_{-\\infty}^{+\\infty} TPR(T) \\ d[FPR(T)] =\\int_{-\\infty}^{+\\infty} TPR(T) \\cdot FPR \\ '(T) \\ dT \\\\\\\\ = \\int_{-\\infty}^{+\\infty} \\left( \\int_T^{+\\infty}  f_1(T') \\ dT' \\right) f_0(T) \\ dT \\\\\\\\ =\\int_{-\\infty}^{+\\infty}\\int_T^{+\\infty}  f_1(T')f_0(T) \\ dT' dT \\\\\\\\ = P(X_1>X_0)\n$$\n$X_1$ $X_0$\n\n $X_1$  $X_0$ :\n$$F_1(x)=\\int_{-\\infty}^{x} f_1(x) dx \\\\\\\\\nF_0(x)=\\int_{-\\infty}^{x} f_1(x) dx$$\n $f_1,f_0$\n\n$X_1, X_0$  $(X_1,X_0)$  $f(x_1,x_0)=f_1(x_1) f_0(x_0)$ $X_0 < X_1$ \n$$P(X_1>X_0)=\\iint_{G} f(x_1,x_0) dx_1 dx_0=\\int_{-\\infty}^{+\\infty}\\int_{x_0}^{+\\infty}f_1(x_1) f_0(x_0) \\ dx_1 dx_0$$\n","slug":"mAP","published":1,"updated":"2020-04-24T10:36:27.200Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90h0016p0dj6qwxa2c1","content":"<h1 id=\"mAP\"><a href=\"#mAP\" class=\"headerlink\" title=\"mAP\"></a>mAP</h1><p> PASCAL VOC <br>- mAPmean Average Precision mAP  AP  AP  AP  mAP<br><span id=\"more\"></span></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>Positive </li>\n<li>True Positive (TP): IoU  box</li>\n<li>False Positive (FP): IoU  box</li>\n<li>Precision = TP/(TP+FP) = TP/()</li>\n<li>Recall = TP/(TP+FN) = TP/(gt)</li>\n</ol>\n<p> TP,FP,TN,FN 4<a href=\"https://github.io/shajian/shajian.github.io\"></a> issue</p>\n<ol>\n<li><p>TP</p>\n<p>P (Positive) gt box  IoU $Threshold_{VOC}=0.5$ TP</p>\n</li>\n<li><p>FP</p>\n<p>P (Positive) gt box  IoU  FP gt box  IoU  gt box match confidence  FP</p>\n<script type=\"math/tex; mode=display\">\\left. \\begin{array}{} GT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_a, GT_i) \\\\\\\\\nGT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_b, GT_i) \\\\\\\\\n\\text{Conf}_a > \\text{Conf}_b \\end{array} \\right] \\Rightarrow Det_b \\in FP</script></li>\n<li><p>FN</p>\n<p> gt box  gt box  IoU 0 gt box  FN</p>\n</li>\n<li><p>TN</p>\n<p>TN = 0 Positive  NegativeTN  Negative Positive</p>\n</li>\n</ol>\n<p>VOC  <code>0.5</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"PR-\"><a href=\"#PR-\" class=\"headerlink\" title=\"PR \"></a>PR </h3><p> box  score  confidence confidence  box confidence  PRPrecision x Recall confidence  1  rank=1  PR  PR  R &gt;= R  P  PR <a href=\"https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge\">stackexchange</a></p>\n<p> Aeroplane,<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BB  | confidence | GT</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB1 |  0.9       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB2 |  0.9       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB3 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB4 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB5 |  0.7       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB6 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB7 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB8 |  0.7       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB9 |  0.7       | 1</span><br><span class=\"line\">----------------------</span><br></pre></td></tr></table></figure><br>BB  match  GT box</p>\n<p> confidence GT=1  TPGT=0  FP BBox FN=2TP=5 (BB1,BB2,BB5,BB8,BB9)FP=5 BB1 confidence  0.9  FP rank=3  case PASCAL VOC  Detection Task  <a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/devkit_doc.html#SECTION00054000000000000000\">Evaluation</a> GT box  TP+FN=5+2=7 PR <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rank=1  precision=1.00 and recall=0.14</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=2  precision=1.00 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=3  precision=0.66 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=4  precision=0.50 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=5  precision=0.40 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=6  precision=0.50 and recall=0.43</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=7  precision=0.43 and recall=0.43</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=8  precision=0.38 and recall=0.43</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=9  precision=0.44 and recall=0.57</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=10 precision=0.50 and recall=0.71</span><br><span class=\"line\">----------</span><br></pre></td></tr></table></figure><br></p>\n<ol>\n<li>rank=1 1TP  BB1  FP P=1R=1/7=0.14</li>\n<li>rank=2 2TP  BB1,BB2 FP P=1R=2/7=0.29</li>\n<li>rank=3 3TP  BB1,BB2FP  BB1 P=2/3=0.66R=2/7=0.29</li>\n<li></li>\n</ol>\n<h3 id=\"AP\"><a href=\"#AP\" class=\"headerlink\" title=\"AP\"></a>AP</h3><p>VOC  2010  11  R   R={0,0.1,,1} R &gt;= R  P  PR  AP  R average precisionVOC 2010  R &gt;= R  P  R  [0,1]  <strong>PR </strong>  AP  PR  AUC area under the curve</p>\n<h4 id=\"11-\"><a href=\"#11-\" class=\"headerlink\" title=\"11-\"></a>11-</h4><p>11 R  [0,1] </p>\n<script type=\"math/tex; mode=display\">AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,...,1}} \\rho_{interp(r)} \\qquad(1) \\\\\\\\\n\\rho_{interp(r)}=\\max_{\\tilde r:\\tilde r \\ge r} \\rho(\\tilde r) \\qquad(2)</script><p>$\\rho(\\tilde r)$ <br><a href=\"https://github.com/rafaelpadilla/Object-Detection-Metrics\"></a><br><img src=\"/images/mAP_fig1.png\" alt=\"\"></p>\n<p> PR 11 R  PR  R=0.2  (2) 0.2  $\\tilde r$  {0.2,0.2666,0.3333,0.4,0.4666} $\\tilde r=0.4$  P  0.4285 11- AP</p>\n<p>$AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,,1}} \\rho_{interp(r)}$</p>\n<p>$AP=\\frac 1 {11}(1+0.6666+0.4285+0.4285+0.4285+0+0+0+0+0+0)$</p>\n<p>$AP=26.84\\%$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>AP </p>\n<script type=\"math/tex; mode=display\">AP=\\sum_{r=0}^1(r_{n+1}-r_n) \\rho_{interp}(r_{n+1}) \\qquad(3) \\\\\\\\\n\\rho_{interp}(r_{n+1})=\\max_{\\tilde r: \\tilde r \\ge r_{n+1}} \\rho(\\tilde r) \\qquad(4)</script><p>$\\rho (\\tilde r)$  Recall $\\tilde r$  AP  PR  AUC<br><br><img src=\"/images/mAP_fig2.png\" alt=\"\"></p>\n<p> PR  RP  AUC  4 <br><img src=\"/images/mAP_fig3.png\" alt=\"\"></p>\n<p> AP </p>\n<p>$AP=A_1+A_2+A_3+A_4=(0.0666-0) \\times 1+(0.1333-0.0666) \\times 0.6666 \\\\\\\\ +(0.4-0.1333) \\times 0.4285+(0.4666-0.4) \\times 0.3043=24.56\\%$</p>\n<h1 id=\"ROC-\"><a href=\"#ROC-\" class=\"headerlink\" title=\"ROC \"></a>ROC </h1><h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>TPR (true positive rate) (sensitivity) (recall)TPR = TP/(TP+FN)</li>\n<li>TNR (true negative rate) (specificity): TNR = TN/(FP+TN)</li>\n<li>FNR (false negative rate): FNR = 1 - TPR = FN/(TP+FN)</li>\n<li>FPR (false positive rate): FPR = 1 - TNR = FP/(FP+TN)</li>\n<li><p>LR+ (positive likelihood ratio):</p>\n<p>$LR^+=\\frac {TPR} {FPR} = \\frac {Sensitivily} {1-Specificity}$</p>\n</li>\n<li><p>LR- (negative likelihood ratio):</p>\n<p>$LR^-=\\frac {FNR} {TNR} = \\frac {1-Sensitivity} {Specificity}$</p>\n</li>\n<li>Youden index: Youden index = Sensitivity + Specificity - 1 = TPR - FPR</li>\n</ol>\n<h2 id=\"ROC--1\"><a href=\"#ROC--1\" class=\"headerlink\" title=\"ROC \"></a>ROC </h2><p>ROC </p>\n<p>ROC  <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">receiver operating characteristic</a></p>\n<p> TPR-FPR  ROC <br><br><img src=\"/images/mAP_fig4.png\" alt=\"\"></p>\n<p> (0,0)  (1,1) </p>\n<ol>\n<li> 1  Negative TP=FP=0 TPR=FPR=0</li>\n<li> 0  Positive TN=FN=0 TPR=FPR=1</li>\n</ol>\n<p> $(-\\infty,0) \\cup (1,+\\infty)$ $(-\\infty,0)$  2  $(1,+\\infty)$  1 </p>\n<p> ROC  y=x  y=x TPR  1FPR  0 ROC  (0,1) y=x</p>\n<h2 id=\"ROC-\"><a href=\"#ROC-\" class=\"headerlink\" title=\"ROC \"></a>ROC </h2><p> X score T X&gt;T X  $f_1(x)$ X  $f_0(x)$,</p>\n<script type=\"math/tex; mode=display\">TPR=\\int_T^{\\infty} f_1(x)dx \\\\\nFPR = \\int_T^{\\infty} f_0(x)dx</script><p> T </p>\n<ol>\n<li>TPR(T) </li>\n<li>FPR(T) </li>\n</ol>\n<p><br><img src=\"/images/mAP_fig5.png\" alt=\" 5\"></p>\n<p> X  score score </p>\n<h2 id=\"AUC\"><a href=\"#AUC\" class=\"headerlink\" title=\"AUC\"></a>AUC</h2><p> ROC  AUC </p>\n<p>AUC  Score  Score ROC  TPR  FPR  T </p>\n<script type=\"math/tex; mode=display\">TPR(T): T \\rightarrow y(x) \\\\\\\\\nFPR(T): T \\rightarrow x</script><p></p>\n<script type=\"math/tex; mode=display\">\nA =\\int_0^1 y(x) \\ dx  =\\int_0^1 TPR[FPR^{-1}(x)] \\ dx \\\\\\\\ \\stackrel{x=FPR(T)} =\\int_{-\\infty}^{+\\infty} TPR(T) \\ d[FPR(T)] =\\int_{-\\infty}^{+\\infty} TPR(T) \\cdot FPR \\ '(T) \\ dT \\\\\\\\ = \\int_{-\\infty}^{+\\infty} \\left( \\int_T^{+\\infty}  f_1(T') \\ dT' \\right) f_0(T) \\ dT \\\\\\\\ =\\int_{-\\infty}^{+\\infty}\\int_T^{+\\infty}  f_1(T')f_0(T) \\ dT' dT \\\\\\\\ = P(X_1>X_0)</script><p>$X_1$ $X_0$</p>\n<p> $X_1$  $X_0$ :</p>\n<script type=\"math/tex; mode=display\">F_1(x)=\\int_{-\\infty}^{x} f_1(x) dx \\\\\\\\\nF_0(x)=\\int_{-\\infty}^{x} f_1(x) dx</script><p> $f_1,f_0$</p>\n<p>$X_1, X_0$  $(X_1,X_0)$  $f(x_1,x_0)=f_1(x_1) f_0(x_0)$ $X_0 &lt; X_1$ </p>\n<script type=\"math/tex; mode=display\">P(X_1>X_0)=\\iint_{G} f(x_1,x_0) dx_1 dx_0=\\int_{-\\infty}^{+\\infty}\\int_{x_0}^{+\\infty}f_1(x_1) f_0(x_0) \\ dx_1 dx_0</script><p></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"mAP\"><a href=\"#mAP\" class=\"headerlink\" title=\"mAP\"></a>mAP</h1><p> PASCAL VOC <br>- mAPmean Average Precision mAP  AP  AP  AP  mAP<br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>Positive </li>\n<li>True Positive (TP): IoU  box</li>\n<li>False Positive (FP): IoU  box</li>\n<li>Precision = TP/(TP+FP) = TP/()</li>\n<li>Recall = TP/(TP+FN) = TP/(gt)</li>\n</ol>\n<p> TP,FP,TN,FN 4<a href=\"https://github.io/shajian/shajian.github.io\"></a> issue</p>\n<ol>\n<li><p>TP</p>\n<p>P (Positive) gt box  IoU $Threshold_{VOC}=0.5$ TP</p>\n</li>\n<li><p>FP</p>\n<p>P (Positive) gt box  IoU  FP gt box  IoU  gt box match confidence  FP</p>\n<script type=\"math/tex; mode=display\">\\left. \\begin{array}{} GT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_a, GT_i) \\\\\\\\\nGT_1=\\underset{GT_i} {\\text{argmax}} \\quad \\text{IoU}(Det_b, GT_i) \\\\\\\\\n\\text{Conf}_a > \\text{Conf}_b \\end{array} \\right] \\Rightarrow Det_b \\in FP</script></li>\n<li><p>FN</p>\n<p> gt box  gt box  IoU 0 gt box  FN</p>\n</li>\n<li><p>TN</p>\n<p>TN = 0 Positive  NegativeTN  Negative Positive</p>\n</li>\n</ol>\n<p>VOC  <code>0.5</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"PR-\"><a href=\"#PR-\" class=\"headerlink\" title=\"PR \"></a>PR </h3><p> box  score  confidence confidence  box confidence  PRPrecision x Recall confidence  1  rank=1  PR  PR  R &gt;= R  P  PR <a href=\"https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge\">stackexchange</a></p>\n<p> Aeroplane,<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BB  | confidence | GT</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB1 |  0.9       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB2 |  0.9       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB3 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB4 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB5 |  0.7       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB6 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB7 |  0.7       | 0</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB8 |  0.7       | 1</span><br><span class=\"line\">----------------------</span><br><span class=\"line\">BB9 |  0.7       | 1</span><br><span class=\"line\">----------------------</span><br></pre></td></tr></table></figure><br>BB  match  GT box</p>\n<p> confidence GT=1  TPGT=0  FP BBox FN=2TP=5 (BB1,BB2,BB5,BB8,BB9)FP=5 BB1 confidence  0.9  FP rank=3  case PASCAL VOC  Detection Task  <a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/devkit_doc.html#SECTION00054000000000000000\">Evaluation</a> GT box  TP+FN=5+2=7 PR <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rank=1  precision=1.00 and recall=0.14</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=2  precision=1.00 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=3  precision=0.66 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=4  precision=0.50 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=5  precision=0.40 and recall=0.29</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=6  precision=0.50 and recall=0.43</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=7  precision=0.43 and recall=0.43</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=8  precision=0.38 and recall=0.43</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=9  precision=0.44 and recall=0.57</span><br><span class=\"line\">----------</span><br><span class=\"line\">rank=10 precision=0.50 and recall=0.71</span><br><span class=\"line\">----------</span><br></pre></td></tr></table></figure><br></p>\n<ol>\n<li>rank=1 1TP  BB1  FP P=1R=1/7=0.14</li>\n<li>rank=2 2TP  BB1,BB2 FP P=1R=2/7=0.29</li>\n<li>rank=3 3TP  BB1,BB2FP  BB1 P=2/3=0.66R=2/7=0.29</li>\n<li></li>\n</ol>\n<h3 id=\"AP\"><a href=\"#AP\" class=\"headerlink\" title=\"AP\"></a>AP</h3><p>VOC  2010  11  R   R={0,0.1,,1} R &gt;= R  P  PR  AP  R average precisionVOC 2010  R &gt;= R  P  R  [0,1]  <strong>PR </strong>  AP  PR  AUC area under the curve</p>\n<h4 id=\"11-\"><a href=\"#11-\" class=\"headerlink\" title=\"11-\"></a>11-</h4><p>11 R  [0,1] </p>\n<script type=\"math/tex; mode=display\">AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,...,1}} \\rho_{interp(r)} \\qquad(1) \\\\\\\\\n\\rho_{interp(r)}=\\max_{\\tilde r:\\tilde r \\ge r} \\rho(\\tilde r) \\qquad(2)</script><p>$\\rho(\\tilde r)$ <br><a href=\"https://github.com/rafaelpadilla/Object-Detection-Metrics\"></a><br><img src=\"/images/mAP_fig1.png\" alt=\"\"></p>\n<p> PR 11 R  PR  R=0.2  (2) 0.2  $\\tilde r$  {0.2,0.2666,0.3333,0.4,0.4666} $\\tilde r=0.4$  P  0.4285 11- AP</p>\n<p>$AP=\\frac 1 {11} \\sum_{r \\in {0,0.1,,1}} \\rho_{interp(r)}$</p>\n<p>$AP=\\frac 1 {11}(1+0.6666+0.4285+0.4285+0.4285+0+0+0+0+0+0)$</p>\n<p>$AP=26.84\\%$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>AP </p>\n<script type=\"math/tex; mode=display\">AP=\\sum_{r=0}^1(r_{n+1}-r_n) \\rho_{interp}(r_{n+1}) \\qquad(3) \\\\\\\\\n\\rho_{interp}(r_{n+1})=\\max_{\\tilde r: \\tilde r \\ge r_{n+1}} \\rho(\\tilde r) \\qquad(4)</script><p>$\\rho (\\tilde r)$  Recall $\\tilde r$  AP  PR  AUC<br><br><img src=\"/images/mAP_fig2.png\" alt=\"\"></p>\n<p> PR  RP  AUC  4 <br><img src=\"/images/mAP_fig3.png\" alt=\"\"></p>\n<p> AP </p>\n<p>$AP=A_1+A_2+A_3+A_4=(0.0666-0) \\times 1+(0.1333-0.0666) \\times 0.6666 \\\\\\\\ +(0.4-0.1333) \\times 0.4285+(0.4666-0.4) \\times 0.3043=24.56\\%$</p>\n<h1 id=\"ROC-\"><a href=\"#ROC-\" class=\"headerlink\" title=\"ROC \"></a>ROC </h1><h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>TPR (true positive rate) (sensitivity) (recall)TPR = TP/(TP+FN)</li>\n<li>TNR (true negative rate) (specificity): TNR = TN/(FP+TN)</li>\n<li>FNR (false negative rate): FNR = 1 - TPR = FN/(TP+FN)</li>\n<li>FPR (false positive rate): FPR = 1 - TNR = FP/(FP+TN)</li>\n<li><p>LR+ (positive likelihood ratio):</p>\n<p>$LR^+=\\frac {TPR} {FPR} = \\frac {Sensitivily} {1-Specificity}$</p>\n</li>\n<li><p>LR- (negative likelihood ratio):</p>\n<p>$LR^-=\\frac {FNR} {TNR} = \\frac {1-Sensitivity} {Specificity}$</p>\n</li>\n<li>Youden index: Youden index = Sensitivity + Specificity - 1 = TPR - FPR</li>\n</ol>\n<h2 id=\"ROC--1\"><a href=\"#ROC--1\" class=\"headerlink\" title=\"ROC \"></a>ROC </h2><p>ROC </p>\n<p>ROC  <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">receiver operating characteristic</a></p>\n<p> TPR-FPR  ROC <br><br><img src=\"/images/mAP_fig4.png\" alt=\"\"></p>\n<p> (0,0)  (1,1) </p>\n<ol>\n<li> 1  Negative TP=FP=0 TPR=FPR=0</li>\n<li> 0  Positive TN=FN=0 TPR=FPR=1</li>\n</ol>\n<p> $(-\\infty,0) \\cup (1,+\\infty)$ $(-\\infty,0)$  2  $(1,+\\infty)$  1 </p>\n<p> ROC  y=x  y=x TPR  1FPR  0 ROC  (0,1) y=x</p>\n<h2 id=\"ROC-\"><a href=\"#ROC-\" class=\"headerlink\" title=\"ROC \"></a>ROC </h2><p> X score T X&gt;T X  $f_1(x)$ X  $f_0(x)$,</p>\n<script type=\"math/tex; mode=display\">TPR=\\int_T^{\\infty} f_1(x)dx \\\\\nFPR = \\int_T^{\\infty} f_0(x)dx</script><p> T </p>\n<ol>\n<li>TPR(T) </li>\n<li>FPR(T) </li>\n</ol>\n<p><br><img src=\"/images/mAP_fig5.png\" alt=\" 5\"></p>\n<p> X  score score </p>\n<h2 id=\"AUC\"><a href=\"#AUC\" class=\"headerlink\" title=\"AUC\"></a>AUC</h2><p> ROC  AUC </p>\n<p>AUC  Score  Score ROC  TPR  FPR  T </p>\n<script type=\"math/tex; mode=display\">TPR(T): T \\rightarrow y(x) \\\\\\\\\nFPR(T): T \\rightarrow x</script><p></p>\n<script type=\"math/tex; mode=display\">\nA =\\int_0^1 y(x) \\ dx  =\\int_0^1 TPR[FPR^{-1}(x)] \\ dx \\\\\\\\ \\stackrel{x=FPR(T)} =\\int_{-\\infty}^{+\\infty} TPR(T) \\ d[FPR(T)] =\\int_{-\\infty}^{+\\infty} TPR(T) \\cdot FPR \\ '(T) \\ dT \\\\\\\\ = \\int_{-\\infty}^{+\\infty} \\left( \\int_T^{+\\infty}  f_1(T') \\ dT' \\right) f_0(T) \\ dT \\\\\\\\ =\\int_{-\\infty}^{+\\infty}\\int_T^{+\\infty}  f_1(T')f_0(T) \\ dT' dT \\\\\\\\ = P(X_1>X_0)</script><p>$X_1$ $X_0$</p>\n<p> $X_1$  $X_0$ :</p>\n<script type=\"math/tex; mode=display\">F_1(x)=\\int_{-\\infty}^{x} f_1(x) dx \\\\\\\\\nF_0(x)=\\int_{-\\infty}^{x} f_1(x) dx</script><p> $f_1,f_0$</p>\n<p>$X_1, X_0$  $(X_1,X_0)$  $f(x_1,x_0)=f_1(x_1) f_0(x_0)$ $X_0 &lt; X_1$ </p>\n<script type=\"math/tex; mode=display\">P(X_1>X_0)=\\iint_{G} f(x_1,x_0) dx_1 dx_0=\\int_{-\\infty}^{+\\infty}\\int_{x_0}^{+\\infty}f_1(x_1) f_0(x_0) \\ dx_1 dx_0</script><p></p>"},{"title":"mask-rcnn","date":"2019-07-08T09:39:57.000Z","mathjax":true,"_content":" [Mask R-CNN](https://arxiv.org/abs/1703.06870)\n<!-- more -->\n# Introduction\n Mask R-CNN   \n\nMask R-CNN  Faster R-CNN  RoI segmentation masks 1mask  RoI  pixel-to-pixel  segmentation mask mask  FCN mask   \n![](/images/mask-rcnn_fig1.png)\n\nFaster R-CNN  RoIPool RoI  image  feature map  1/16 mask  pixel-wise  RoIAlign  10%~50%  mask   \n\n binary mask  binary mask  RoI  FCN \n\n# Mask R-CNN\nFaster R-CNN Mask R-CNN  binary mask Mask R-CNN \n\n__Faster R-CNN:__  Faster R-CNN two-stage  stage  RPN proposals stage  Fast R-CNN RoIPooling  proposal  bbox \n\n__Mask R-CNN:__  Faster R-CNN  stage  RoI  binary mask\n\n RoI  $L=L_{cls}+L_{box}+L_{mask}$ $L_{cls}$  $L_{box}$  Fast/Faster R-CNN \n$$L_{cls}=L_{cls}(p,u)=-\\log p_u$$\n log lossproposal  gt  u$p_u$  proposal  u \n$$L_{loc}=L_{loc}(t^u,v)=\\sum_{i \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^u,v_i)$$\n smooth L1 loss$t_u$  u  bbox v  gt box  proposal  target  \nmask  RoI  $Km^2$  pixel-wise sigmoid K  binary mask mask  $m \\times m$ K  $L_{mark}$  RoI  gt  k$L_{mark}$  k  binary mask  K-1  binary mask  $L_{mark}$ \n$$L_{mark}=-\\frac 1{m^2} \\sum_{i=1}^{m^2} \\sum_{j=0}^1 [t_i=j] \\cdot \\log f(s_i^j)=-\\frac 1{m^2} \\sum_{i=1}^{m^2} [t_i \\cdot \\log f(s_i) + (1-t_i) \\cdot \\log (1-f(s_i))]$$\n $f(\\cdot)$  sigmoid\n\n__Mask Representation:__  RoI  bbox  fc  mask  pixel-to-pixel  RoI  FCN  RoI  $m \\times m$  maskpixel-to-pixel  RoI  RoIAlign \n\n__RoIAlign:__ RoIPool  RoI  7x7 RoI  feature map RoI  bins bin  bin  bin \n\n RoI  x  image  Faster R-CNN  stride  16 RoI  $[x/16]$ $[\\cdot]$  bin  RoI  $(x_1,y_1,x_2,y_2)$ RPN  anchor  RoI RoI  7x7  bins RoI \n$$x_1'=[x_1/16] \\quad y_1'=[y_1/16]\n\\quad x_2'=[x_2/16]\n\\quad y_2'=[y_2/16]$$\nRoI    bin \n$$w'=x_2'-x_1'+1\n\\quad h'=y_2'-y_1'+1\n\\\\\\\\ w^b=w'/7 \\quad h^b=h'/7$$\n (i,j)  bin\n$$x_1^b=\\lfloor j \\cdot w^b\\rfloor \\quad y_1^b=\\lfloor i \\cdot h^b\\rfloor \\quad x_2^b=\\lceil (j+1) \\cdot w^b\\rceil \\quad y_1^b=\\lceil (i+1) \\cdot h^b\\rceil$$\n\n $0 \\le i<7, \\ 0\\le j<7$ bin \n\n RoI  pixel-to-pixel  mask  RoIAlign  RoIAlign  RoIPool 3\n![](/images/mask-rcnn_fig3.png)\n\n RoI  $x/16$ bin  4  bin max  average \n\n__Network Architecture:__ Mask R-CNN  1.  backbone2. network head bbox  mask \n\nBackbone  ResNet  ResNeXt 50 101Faster R-CNN  ResNet  4-th stage  conv  C4 ResNet  ResNet-50  backbone  ResNet-50-C4\n\n backbone  FPNFPN  top-down  feature pyramid ResNet-FPN  backbone Mask R-CNN \n\n Network head 4\n![](/images/mask-rcnn_fig4.png)\n\nResNet-C4  backbone  head  ResNet  5-th stage 9  conv  res5ResNet-FPN  backbone  backbone  res5 head   \n 4 res5  ResNet  5-th stage 7x7  RoI feature maps  conv  stride  1 ResNet  conv conv4_x 14x14 feature maps  conv  stride  2\n# Experiments\n\n\n# Appendix\n mask  4mask  $(R,K,m,m)$ bbox  box  $(R,4)$ R  box K mxm  mask  i  $0 \\le i < R$ box  $(x_1,y_1,x_2,y_2)$ k  mask map  $M_i^k$\n1.  i  box   \n   $w=x_2-x_1, \\ h=y_2-y_1$\n2.  mask map resize  box   \n   ```python\n   mask=cv2.resize(M_i_k, (w,h))\n   ```\n3.  mask map  mask  pixel-wise sigmoid  (0,1)   \n   ```python\n   mask=np.array(mask>0.5)\n   ```\n4.  binary mask  image  image  (W,H) mask  \n   ```python\n   im_mask=np.zero((H,W), dtype=np.uint8)\n   im_mask[y1:y2,x1:x2]=mask\n   ```\n","source":"_posts/mask-rcnn.md","raw":"---\ntitle: mask-rcnn\ndate: 2019-07-08 17:39:57\ntags: object detection\nmathjax: true\n---\n [Mask R-CNN](https://arxiv.org/abs/1703.06870)\n<!-- more -->\n# Introduction\n Mask R-CNN   \n\nMask R-CNN  Faster R-CNN  RoI segmentation masks 1mask  RoI  pixel-to-pixel  segmentation mask mask  FCN mask   \n![](/images/mask-rcnn_fig1.png)\n\nFaster R-CNN  RoIPool RoI  image  feature map  1/16 mask  pixel-wise  RoIAlign  10%~50%  mask   \n\n binary mask  binary mask  RoI  FCN \n\n# Mask R-CNN\nFaster R-CNN Mask R-CNN  binary mask Mask R-CNN \n\n__Faster R-CNN:__  Faster R-CNN two-stage  stage  RPN proposals stage  Fast R-CNN RoIPooling  proposal  bbox \n\n__Mask R-CNN:__  Faster R-CNN  stage  RoI  binary mask\n\n RoI  $L=L_{cls}+L_{box}+L_{mask}$ $L_{cls}$  $L_{box}$  Fast/Faster R-CNN \n$$L_{cls}=L_{cls}(p,u)=-\\log p_u$$\n log lossproposal  gt  u$p_u$  proposal  u \n$$L_{loc}=L_{loc}(t^u,v)=\\sum_{i \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^u,v_i)$$\n smooth L1 loss$t_u$  u  bbox v  gt box  proposal  target  \nmask  RoI  $Km^2$  pixel-wise sigmoid K  binary mask mask  $m \\times m$ K  $L_{mark}$  RoI  gt  k$L_{mark}$  k  binary mask  K-1  binary mask  $L_{mark}$ \n$$L_{mark}=-\\frac 1{m^2} \\sum_{i=1}^{m^2} \\sum_{j=0}^1 [t_i=j] \\cdot \\log f(s_i^j)=-\\frac 1{m^2} \\sum_{i=1}^{m^2} [t_i \\cdot \\log f(s_i) + (1-t_i) \\cdot \\log (1-f(s_i))]$$\n $f(\\cdot)$  sigmoid\n\n__Mask Representation:__  RoI  bbox  fc  mask  pixel-to-pixel  RoI  FCN  RoI  $m \\times m$  maskpixel-to-pixel  RoI  RoIAlign \n\n__RoIAlign:__ RoIPool  RoI  7x7 RoI  feature map RoI  bins bin  bin  bin \n\n RoI  x  image  Faster R-CNN  stride  16 RoI  $[x/16]$ $[\\cdot]$  bin  RoI  $(x_1,y_1,x_2,y_2)$ RPN  anchor  RoI RoI  7x7  bins RoI \n$$x_1'=[x_1/16] \\quad y_1'=[y_1/16]\n\\quad x_2'=[x_2/16]\n\\quad y_2'=[y_2/16]$$\nRoI    bin \n$$w'=x_2'-x_1'+1\n\\quad h'=y_2'-y_1'+1\n\\\\\\\\ w^b=w'/7 \\quad h^b=h'/7$$\n (i,j)  bin\n$$x_1^b=\\lfloor j \\cdot w^b\\rfloor \\quad y_1^b=\\lfloor i \\cdot h^b\\rfloor \\quad x_2^b=\\lceil (j+1) \\cdot w^b\\rceil \\quad y_1^b=\\lceil (i+1) \\cdot h^b\\rceil$$\n\n $0 \\le i<7, \\ 0\\le j<7$ bin \n\n RoI  pixel-to-pixel  mask  RoIAlign  RoIAlign  RoIPool 3\n![](/images/mask-rcnn_fig3.png)\n\n RoI  $x/16$ bin  4  bin max  average \n\n__Network Architecture:__ Mask R-CNN  1.  backbone2. network head bbox  mask \n\nBackbone  ResNet  ResNeXt 50 101Faster R-CNN  ResNet  4-th stage  conv  C4 ResNet  ResNet-50  backbone  ResNet-50-C4\n\n backbone  FPNFPN  top-down  feature pyramid ResNet-FPN  backbone Mask R-CNN \n\n Network head 4\n![](/images/mask-rcnn_fig4.png)\n\nResNet-C4  backbone  head  ResNet  5-th stage 9  conv  res5ResNet-FPN  backbone  backbone  res5 head   \n 4 res5  ResNet  5-th stage 7x7  RoI feature maps  conv  stride  1 ResNet  conv conv4_x 14x14 feature maps  conv  stride  2\n# Experiments\n\n\n# Appendix\n mask  4mask  $(R,K,m,m)$ bbox  box  $(R,4)$ R  box K mxm  mask  i  $0 \\le i < R$ box  $(x_1,y_1,x_2,y_2)$ k  mask map  $M_i^k$\n1.  i  box   \n   $w=x_2-x_1, \\ h=y_2-y_1$\n2.  mask map resize  box   \n   ```python\n   mask=cv2.resize(M_i_k, (w,h))\n   ```\n3.  mask map  mask  pixel-wise sigmoid  (0,1)   \n   ```python\n   mask=np.array(mask>0.5)\n   ```\n4.  binary mask  image  image  (W,H) mask  \n   ```python\n   im_mask=np.zero((H,W), dtype=np.uint8)\n   im_mask[y1:y2,x1:x2]=mask\n   ```\n","slug":"mask-rcnn","published":1,"updated":"2020-04-24T10:36:21.610Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90i0018p0dja8zqhskb","content":"<p> <a href=\"https://arxiv.org/abs/1703.06870\">Mask R-CNN</a><br><span id=\"more\"></span></p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p> Mask R-CNN   </p>\n<p>Mask R-CNN  Faster R-CNN  RoI segmentation masks 1mask  RoI  pixel-to-pixel  segmentation mask mask  FCN mask <br><img src=\"/images/mask-rcnn_fig1.png\" alt=\"\"></p>\n<p>Faster R-CNN  RoIPool RoI  image  feature map  1/16 mask  pixel-wise  RoIAlign  10%~50%  mask   </p>\n<p> binary mask  binary mask  RoI  FCN </p>\n<h1 id=\"Mask-R-CNN\"><a href=\"#Mask-R-CNN\" class=\"headerlink\" title=\"Mask R-CNN\"></a>Mask R-CNN</h1><p>Faster R-CNN Mask R-CNN  binary mask Mask R-CNN </p>\n<p><strong>Faster R-CNN:</strong>  Faster R-CNN two-stage  stage  RPN proposals stage  Fast R-CNN RoIPooling  proposal  bbox </p>\n<p><strong>Mask R-CNN:</strong>  Faster R-CNN  stage  RoI  binary mask</p>\n<p> RoI  $L=L_{cls}+L_{box}+L_{mask}$ $L_{cls}$  $L_{box}$  Fast/Faster R-CNN </p>\n<script type=\"math/tex; mode=display\">L_{cls}=L_{cls}(p,u)=-\\log p_u</script><p> log lossproposal  gt  u$p_u$  proposal  u </p>\n<script type=\"math/tex; mode=display\">L_{loc}=L_{loc}(t^u,v)=\\sum_{i \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^u,v_i)</script><p> smooth L1 loss$t_u$  u  bbox v  gt box  proposal  target<br>mask  RoI  $Km^2$  pixel-wise sigmoid K  binary mask mask  $m \\times m$ K  $L_{mark}$  RoI  gt  k$L_{mark}$  k  binary mask  K-1  binary mask  $L_{mark}$ </p>\n<script type=\"math/tex; mode=display\">L_{mark}=-\\frac 1{m^2} \\sum_{i=1}^{m^2} \\sum_{j=0}^1 [t_i=j] \\cdot \\log f(s_i^j)=-\\frac 1{m^2} \\sum_{i=1}^{m^2} [t_i \\cdot \\log f(s_i) + (1-t_i) \\cdot \\log (1-f(s_i))]</script><p> $f(\\cdot)$  sigmoid</p>\n<p><strong>Mask Representation:</strong>  RoI  bbox  fc  mask  pixel-to-pixel  RoI  FCN  RoI  $m \\times m$  maskpixel-to-pixel  RoI  RoIAlign </p>\n<p><strong>RoIAlign:</strong> RoIPool  RoI  7x7 RoI  feature map RoI  bins bin  bin  bin </p>\n<p> RoI  x  image  Faster R-CNN  stride  16 RoI  $[x/16]$ $[\\cdot]$  bin  RoI  $(x_1,y_1,x_2,y_2)$ RPN  anchor  RoI RoI  7x7  bins RoI </p>\n<script type=\"math/tex; mode=display\">x_1'=[x_1/16] \\quad y_1'=[y_1/16]\n\\quad x_2'=[x_2/16]\n\\quad y_2'=[y_2/16]</script><p>RoI    bin </p>\n<script type=\"math/tex; mode=display\">w'=x_2'-x_1'+1\n\\quad h'=y_2'-y_1'+1\n\\\\\\\\ w^b=w'/7 \\quad h^b=h'/7</script><p> (i,j)  bin</p>\n<script type=\"math/tex; mode=display\">x_1^b=\\lfloor j \\cdot w^b\\rfloor \\quad y_1^b=\\lfloor i \\cdot h^b\\rfloor \\quad x_2^b=\\lceil (j+1) \\cdot w^b\\rceil \\quad y_1^b=\\lceil (i+1) \\cdot h^b\\rceil</script><p> $0 \\le i&lt;7, \\ 0\\le j&lt;7$ bin </p>\n<p> RoI  pixel-to-pixel  mask  RoIAlign  RoIAlign  RoIPool 3<br><img src=\"/images/mask-rcnn_fig3.png\" alt=\"\"></p>\n<p> RoI  $x/16$ bin  4  bin max  average </p>\n<p><strong>Network Architecture:</strong> Mask R-CNN  1.  backbone2. network head bbox  mask </p>\n<p>Backbone  ResNet  ResNeXt 50 101Faster R-CNN  ResNet  4-th stage  conv  C4 ResNet  ResNet-50  backbone  ResNet-50-C4</p>\n<p> backbone  FPNFPN  top-down  feature pyramid ResNet-FPN  backbone Mask R-CNN </p>\n<p> Network head 4<br><img src=\"/images/mask-rcnn_fig4.png\" alt=\"\"></p>\n<p>ResNet-C4  backbone  head  ResNet  5-th stage 9  conv  res5ResNet-FPN  backbone  backbone  res5 head <br> 4 res5  ResNet  5-th stage 7x7  RoI feature maps  conv  stride  1 ResNet  conv conv4_x 14x14 feature maps  conv  stride  2</p>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p></p>\n<h1 id=\"Appendix\"><a href=\"#Appendix\" class=\"headerlink\" title=\"Appendix\"></a>Appendix</h1><p> mask  4mask  $(R,K,m,m)$ bbox  box  $(R,4)$ R  box K mxm  mask  i  $0 \\le i &lt; R$ box  $(x_1,y_1,x_2,y_2)$ k  mask map  $M_i^k$</p>\n<ol>\n<li> i  box <br>$w=x_2-x_1, \\ h=y_2-y_1$</li>\n<li> mask map resize  box   <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mask=cv2.resize(M_i_k, (w,h))</span><br></pre></td></tr></table></figure></li>\n<li> mask map  mask  pixel-wise sigmoid  (0,1)   <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mask=np.array(mask&gt;<span class=\"number\">0.5</span>)</span><br></pre></td></tr></table></figure></li>\n<li> binary mask  image  image  (W,H) mask  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">im_mask=np.zero((H,W), dtype=np.uint8)</span><br><span class=\"line\">im_mask[y1:y2,x1:x2]=mask</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1703.06870\">Mask R-CNN</a><br>","more":"</p>\n<h1 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h1><p> Mask R-CNN   </p>\n<p>Mask R-CNN  Faster R-CNN  RoI segmentation masks 1mask  RoI  pixel-to-pixel  segmentation mask mask  FCN mask <br><img src=\"/images/mask-rcnn_fig1.png\" alt=\"\"></p>\n<p>Faster R-CNN  RoIPool RoI  image  feature map  1/16 mask  pixel-wise  RoIAlign  10%~50%  mask   </p>\n<p> binary mask  binary mask  RoI  FCN </p>\n<h1 id=\"Mask-R-CNN\"><a href=\"#Mask-R-CNN\" class=\"headerlink\" title=\"Mask R-CNN\"></a>Mask R-CNN</h1><p>Faster R-CNN Mask R-CNN  binary mask Mask R-CNN </p>\n<p><strong>Faster R-CNN:</strong>  Faster R-CNN two-stage  stage  RPN proposals stage  Fast R-CNN RoIPooling  proposal  bbox </p>\n<p><strong>Mask R-CNN:</strong>  Faster R-CNN  stage  RoI  binary mask</p>\n<p> RoI  $L=L_{cls}+L_{box}+L_{mask}$ $L_{cls}$  $L_{box}$  Fast/Faster R-CNN </p>\n<script type=\"math/tex; mode=display\">L_{cls}=L_{cls}(p,u)=-\\log p_u</script><p> log lossproposal  gt  u$p_u$  proposal  u </p>\n<script type=\"math/tex; mode=display\">L_{loc}=L_{loc}(t^u,v)=\\sum_{i \\in \\{x,y,w,h\\}} smooth_{L_1}(t_i^u,v_i)</script><p> smooth L1 loss$t_u$  u  bbox v  gt box  proposal  target<br>mask  RoI  $Km^2$  pixel-wise sigmoid K  binary mask mask  $m \\times m$ K  $L_{mark}$  RoI  gt  k$L_{mark}$  k  binary mask  K-1  binary mask  $L_{mark}$ </p>\n<script type=\"math/tex; mode=display\">L_{mark}=-\\frac 1{m^2} \\sum_{i=1}^{m^2} \\sum_{j=0}^1 [t_i=j] \\cdot \\log f(s_i^j)=-\\frac 1{m^2} \\sum_{i=1}^{m^2} [t_i \\cdot \\log f(s_i) + (1-t_i) \\cdot \\log (1-f(s_i))]</script><p> $f(\\cdot)$  sigmoid</p>\n<p><strong>Mask Representation:</strong>  RoI  bbox  fc  mask  pixel-to-pixel  RoI  FCN  RoI  $m \\times m$  maskpixel-to-pixel  RoI  RoIAlign </p>\n<p><strong>RoIAlign:</strong> RoIPool  RoI  7x7 RoI  feature map RoI  bins bin  bin  bin </p>\n<p> RoI  x  image  Faster R-CNN  stride  16 RoI  $[x/16]$ $[\\cdot]$  bin  RoI  $(x_1,y_1,x_2,y_2)$ RPN  anchor  RoI RoI  7x7  bins RoI </p>\n<script type=\"math/tex; mode=display\">x_1'=[x_1/16] \\quad y_1'=[y_1/16]\n\\quad x_2'=[x_2/16]\n\\quad y_2'=[y_2/16]</script><p>RoI    bin </p>\n<script type=\"math/tex; mode=display\">w'=x_2'-x_1'+1\n\\quad h'=y_2'-y_1'+1\n\\\\\\\\ w^b=w'/7 \\quad h^b=h'/7</script><p> (i,j)  bin</p>\n<script type=\"math/tex; mode=display\">x_1^b=\\lfloor j \\cdot w^b\\rfloor \\quad y_1^b=\\lfloor i \\cdot h^b\\rfloor \\quad x_2^b=\\lceil (j+1) \\cdot w^b\\rceil \\quad y_1^b=\\lceil (i+1) \\cdot h^b\\rceil</script><p> $0 \\le i&lt;7, \\ 0\\le j&lt;7$ bin </p>\n<p> RoI  pixel-to-pixel  mask  RoIAlign  RoIAlign  RoIPool 3<br><img src=\"/images/mask-rcnn_fig3.png\" alt=\"\"></p>\n<p> RoI  $x/16$ bin  4  bin max  average </p>\n<p><strong>Network Architecture:</strong> Mask R-CNN  1.  backbone2. network head bbox  mask </p>\n<p>Backbone  ResNet  ResNeXt 50 101Faster R-CNN  ResNet  4-th stage  conv  C4 ResNet  ResNet-50  backbone  ResNet-50-C4</p>\n<p> backbone  FPNFPN  top-down  feature pyramid ResNet-FPN  backbone Mask R-CNN </p>\n<p> Network head 4<br><img src=\"/images/mask-rcnn_fig4.png\" alt=\"\"></p>\n<p>ResNet-C4  backbone  head  ResNet  5-th stage 9  conv  res5ResNet-FPN  backbone  backbone  res5 head <br> 4 res5  ResNet  5-th stage 7x7  RoI feature maps  conv  stride  1 ResNet  conv conv4_x 14x14 feature maps  conv  stride  2</p>\n<h1 id=\"Experiments\"><a href=\"#Experiments\" class=\"headerlink\" title=\"Experiments\"></a>Experiments</h1><p></p>\n<h1 id=\"Appendix\"><a href=\"#Appendix\" class=\"headerlink\" title=\"Appendix\"></a>Appendix</h1><p> mask  4mask  $(R,K,m,m)$ bbox  box  $(R,4)$ R  box K mxm  mask  i  $0 \\le i &lt; R$ box  $(x_1,y_1,x_2,y_2)$ k  mask map  $M_i^k$</p>\n<ol>\n<li> i  box <br>$w=x_2-x_1, \\ h=y_2-y_1$</li>\n<li> mask map resize  box   <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mask=cv2.resize(M_i_k, (w,h))</span><br></pre></td></tr></table></figure></li>\n<li> mask map  mask  pixel-wise sigmoid  (0,1)   <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mask=np.array(mask&gt;<span class=\"number\">0.5</span>)</span><br></pre></td></tr></table></figure></li>\n<li> binary mask  image  image  (W,H) mask  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">im_mask=np.zero((H,W), dtype=np.uint8)</span><br><span class=\"line\">im_mask[y1:y2,x1:x2]=mask</span><br></pre></td></tr></table></figure>\n</li>\n</ol>"},{"title":"cmake tutorial","date":"2021-06-02T02:35:18.000Z","_content":"cmake \n<!-- more -->\n\n cmake \n\n# \n\n__main.cpp__\n\n```cpp\n#include <iostream>\n\nint main() {\n    std::cout << \"Hello World!\\n\";\n    return 0;\n}\n```\n__CMakeLists.txt__\n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(hello_world)\nadd_executable(app main.cpp)\n```\n `demo` \n```\ndemo\n| -- main.cpp\n| -- CMakeLists.txt\n```\n `demo` \n```shell\n> cmake .\n> cmake --build .\n```\n  Makefile  `demo`  `build`  `build` \n```sh\n> mkdir build\n> cd build\n> cmake ..\n> cmake --build .\n```\n\n# \n\n```\ndemo\n| -- build\n| -- main.cpp\n| -- foo.h\n| -- foo.cpp\n| -- CMakeLists.txt\n```\n\n\n\n__main.cpp__\n```cpp\n#include \"foo.h\"\n\nint main() {\n    foo();\n    return 0;\n}\n```\n\n__foo.h__\n```cpp\nvoid foo();\n```\n\n__foo.cpp__\n```cpp\n#include <iostream>\n#include \"foo.h\"\n\nvoid foo() {\n    std::cout << \"Hello World!\\n\";\n}\n```\n\n__CMakeLists.txt__\n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(hello_world)\n\nadd_executable(app main.cpp foo.cpp)\n```\n\n `includes` \n```\ndemo\n| -- build\n| -- inlcude\n    |-- foo.h\n| -- main.cpp\n| -- foo.cpp\n| -- CMakeLists.txt\n```\n\n```cmake\n...\ninlcude_directories(\"${PROJECT_SOURCE_DIR}/includes\")\nadd_executable(app main.cpp foo.cpp)\n```\n \n\n# \n CMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject (hello_world)\n\ninclude_directories(\"${PROJECT_SOURCE_DIR}/includes\")\nadd_library(foo foo.cpp)\nadd_executable(app main.cpp)\ntarget_link_libraries(app foo)\n```\n\n# \n\n- `include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])`\n\n|||\n|--|--|\n|dirN| |\n|AFTER, BEFORE|  CMAKE_INCLUDE_DIRECTORIES_BEFORE |\n|SYSTEM||\n\n\n```\ninclude_directories(include)\n```\n directory  targets  subdirectories  add_subdirectory()  \n\n# \n\n- `add_executable(target_name [EXCLUDE_FROM_ALL] source1 [source2...])`\n- `add_library(lib_name [STATIC|SHARED|MODULE][EXCLUDE_FROM_ALL] source1 [source2...])`\n\n\n```\nadd_executable(my_ext main.cpp util.cpp)\n```\n\n `my_exe`  linux  `make my_exe` `all`  `all`  `EXCLUDE_FROM_ALL` \n```\nadd_executable(my_exe EXCLUDE_FROM_ALL main.cpp)\n```\n\n`add_library` `BUILD_SHARED_LIBS` BOOL  static  shared  `cmake .. -DBUILD_SHARED_LIBS=ON`\n```\nadd_library(my_lib SHARED lib.cpp)\n```\n`MODULE`  runtime  `dlopen` \n\n# MACROS\n scope context \n\n```cmake\nmacro(set_my_variable _INPUT)\n  if(\"${_INPUT}\" STREQUAL \"Foo\")\n    set(my_output_variable \"foo\")\n  else()\n    set(my_output_variable \"bar\")\n  endif()\nendmacro(set_my_variable)\n```\n\n```\nset_my_variable(\"Foo\")\nmessage(STATUS ${my_output_variable})\n```\n\n# \n\n```\nCMakeLists.txt\neditor/\n    CMakeLists.txt\n    src/\n        editor.cpp\nhighlight/\n    CMakeLists.txt\n    include/\n        highlight.h\n    src/\n        highlight.cpp\n```\n\n\n```cmake\n# CMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\nproject (example)\n\nadd_subdirectory(highlight)\nadd_subdirectory(editor)\n```\n\nhighlight \n```cmake\n# highlight/CMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\nproject (highlight)\n\nadd_library(${PROJECT_NAME} src/highlight.cpp)\ntarget_include_directories(${PROJECT_NAME} PUBLIC include)\n```\n `target_include_directories()`  `include_directories()`\n\n\n```cmake\n# editor/CMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\nproject (editor)\n\nadd_executable(${PROJECT_NAME} src/editor.cpp)\ntarget_link_libraries(${PROJECT_NAME} PUBLIC highlight)\n```\ncmake  highlight \n\n\n# \n `make install` `cmake --install .`\n\n## \n\n`install(TARGETS <target>... [...])`\n\ntarget `[...]` \n- DESTINATION\n\n `CMAKE_INSTALL_PREFIX` `/usr/local`linux `cmake -DCMAKE_INSTALL_PREFIX=/my/path ..`\n\n- PERMISSIONS\n\n `OWNER_READ, OWNER_WRITE, OWNER_EXECUTE, GROUP_READ, GROUP_WRITE, GROUP_EXECUTE, WORLD_READ, WORLD_WRITE, WORLD_EXECUTE, SETUID, SETGID` \n\n `RUNTIME, LIBRARY, ARCHIVE, PUBLIC_HEADER, PRIVATE_HEADER` \n```cmake\nINSTALL(TARGETS myapp, mylib, mystaticlib\n    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR})\n```\n\n- CONFIGURATIONS\n\n DebugRelease `CONFIGURATIONS`  Debug  Release \n```cmake\ninstall(TARGETS target\n    CONFIGURATIONS Debug\n    RUNTIME DESTINATION Debug/bin)\ninstall(TARGETS target\n    CONFIGURATIONS Release\n    RUNTIME DESTINATION Release/bin)\n```\n `-DCMAKE_BUILD_TYPE=Debug` \n\n- RENAME\n\n\n\n- OPTIONAL\n\n\n\n- EXCLUDE_FROM_ALL\n\n\n\n- COMPONENT\n\n EXCLUDE_FROM_ALL  `Unspecified`\n\n\n```cmake\ninstall(TARGETS targets... [EXPORT <export-name>]\n        [[ARCHIVE|LIBRARY|RUNTIME|OBJECTS|FRAMEWORK|BUNDLE|\n          PRIVATE_HEADER|PUBLIC_HEADER|RESOURCE]\n         [DESTINATION <dir>]\n         [PERMISSIONS permissions...]\n         [CONFIGURATIONS [Debug|Release|...]]\n         [COMPONENT <component>]\n         [NAMELINK_COMPONENT <component>]\n         [OPTIONAL] [EXCLUDE_FROM_ALL]\n         [NAMELINK_ONLY|NAMELINK_SKIP]\n        ] [...]\n        [INCLUDES DESTINATION [<dir> ...]]\n        )\n```\n\n- EXPORT\n\n `export-name`EXPORT \n\n## \n\n```cmake\ninstall(<FILES|PROGRAMS> files...\n        TYPE <type> | DESTINATION <dir>\n        [PERMISSIONS permissions...]\n        [CONFIGURATIONS [Debug|Release|...]]\n        [COMPONENT <component>]\n        [RENAME <name>] [OPTIONAL] [EXCLUDE_FROM_ALL])\n```\n `CMAKE_SOURCE_DIR`\nFILES PROGRAMS \n\n- TYPE\n\n TYPE \n\n## \n```cmake\ninstall(DIRECTORY dirs...\n        TYPE <type> | DESTINATION <dir>\n        [FILE_PERMISSIONS permissions...]\n        [DIRECTORY_PERMISSIONS permissions...]\n        [USE_SOURCE_PERMISSIONS] [OPTIONAL] [MESSAGE_NEVER]\n        [CONFIGURATIONS [Debug|Release|...]]\n        [COMPONENT <component>] [EXCLUDE_FROM_ALL]\n        [FILES_MATCHING]\n        [[PATTERN <pattern> | REGEX <regex>]\n         [EXCLUDE] [PERMISSIONS permissions...]] [...])\n```\n\n- DIRECTORY\n\n `DESTINATION` dirs  `/`\n\n- USE_SOURCE_PERMISSIONS\n\n`FILE_PERMISSIONS`  `DIRECTORY_PERMISSIONS`  `USE_SOURCE_PERMISSIONS`  `FILE_PERMISSIONS`\n\n- PATTERN REGEX\n\nPATTERN REGEX \n```cmake\ninstall(DIRECTORY icons scripts/ DESTINATION share/myproj\n        PATTERN \"CVS\" EXCLUDE\n        PATTERN \"scripts/*\"\n        PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ\n                    GROUP_EXECUTE GROUP_READ)\n```\n `icons`  `scripts`   `share/myproj`  `CVS`  `scripts/*` \n\n `PATTERN \"CVS\" EXCLUDE`  `EXCLUDE` \"CVS\" \n\n- FILES_MATCHING\n\n `FILES_MATCHING` \n```cmake\ninstall(DIRECTORY src/ DESTINATION include/myproj\n        FILES_MATCHING PATTERN \"*.h\")\n```\n\n\n## \n```cmake\ninstall([[SCRIPT <file>] [CODE <code>]]\n        [COMPONENT <component>] [EXCLUDE_FROM_ALL] [...])\n```\nSCRIPT  CMAKE \n\nCODE  CMAKE \n```cmake\ninstall(CODE \"MESSAGE(\\\"Sample install message.\\\")\")\n```\n\n## \n```\ninstall(EXPORT <export-name> DESTINATION <dir>\n        [NAMESPACE <namespace>] [[FILE <name>.cmake]|\n        [PERMISSIONS permissions...]\n        [CONFIGURATIONS [Debug|Release|...]]\n        [EXPORT_LINK_INTERFACE_LIBRARIES]\n        [COMPONENT <component>]\n        [EXCLUDE_FROM_ALL])\ninstall(EXPORT_ANDROID_MK <export-name> DESTINATION <dir> [...])\n```\n `install(TARGETS)`  `EXPORT` `NAMESPACE`  `<export-name>.cmake` `FILE` `DESTINATION`  .cmake \n","source":"_posts/cpp/cmake_1.md","raw":"---\ntitle: cmake tutorial\ndate: 2021-06-02 10:35:18\ntags: cmake\n---\ncmake \n<!-- more -->\n\n cmake \n\n# \n\n__main.cpp__\n\n```cpp\n#include <iostream>\n\nint main() {\n    std::cout << \"Hello World!\\n\";\n    return 0;\n}\n```\n__CMakeLists.txt__\n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(hello_world)\nadd_executable(app main.cpp)\n```\n `demo` \n```\ndemo\n| -- main.cpp\n| -- CMakeLists.txt\n```\n `demo` \n```shell\n> cmake .\n> cmake --build .\n```\n  Makefile  `demo`  `build`  `build` \n```sh\n> mkdir build\n> cd build\n> cmake ..\n> cmake --build .\n```\n\n# \n\n```\ndemo\n| -- build\n| -- main.cpp\n| -- foo.h\n| -- foo.cpp\n| -- CMakeLists.txt\n```\n\n\n\n__main.cpp__\n```cpp\n#include \"foo.h\"\n\nint main() {\n    foo();\n    return 0;\n}\n```\n\n__foo.h__\n```cpp\nvoid foo();\n```\n\n__foo.cpp__\n```cpp\n#include <iostream>\n#include \"foo.h\"\n\nvoid foo() {\n    std::cout << \"Hello World!\\n\";\n}\n```\n\n__CMakeLists.txt__\n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(hello_world)\n\nadd_executable(app main.cpp foo.cpp)\n```\n\n `includes` \n```\ndemo\n| -- build\n| -- inlcude\n    |-- foo.h\n| -- main.cpp\n| -- foo.cpp\n| -- CMakeLists.txt\n```\n\n```cmake\n...\ninlcude_directories(\"${PROJECT_SOURCE_DIR}/includes\")\nadd_executable(app main.cpp foo.cpp)\n```\n \n\n# \n CMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject (hello_world)\n\ninclude_directories(\"${PROJECT_SOURCE_DIR}/includes\")\nadd_library(foo foo.cpp)\nadd_executable(app main.cpp)\ntarget_link_libraries(app foo)\n```\n\n# \n\n- `include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])`\n\n|||\n|--|--|\n|dirN| |\n|AFTER, BEFORE|  CMAKE_INCLUDE_DIRECTORIES_BEFORE |\n|SYSTEM||\n\n\n```\ninclude_directories(include)\n```\n directory  targets  subdirectories  add_subdirectory()  \n\n# \n\n- `add_executable(target_name [EXCLUDE_FROM_ALL] source1 [source2...])`\n- `add_library(lib_name [STATIC|SHARED|MODULE][EXCLUDE_FROM_ALL] source1 [source2...])`\n\n\n```\nadd_executable(my_ext main.cpp util.cpp)\n```\n\n `my_exe`  linux  `make my_exe` `all`  `all`  `EXCLUDE_FROM_ALL` \n```\nadd_executable(my_exe EXCLUDE_FROM_ALL main.cpp)\n```\n\n`add_library` `BUILD_SHARED_LIBS` BOOL  static  shared  `cmake .. -DBUILD_SHARED_LIBS=ON`\n```\nadd_library(my_lib SHARED lib.cpp)\n```\n`MODULE`  runtime  `dlopen` \n\n# MACROS\n scope context \n\n```cmake\nmacro(set_my_variable _INPUT)\n  if(\"${_INPUT}\" STREQUAL \"Foo\")\n    set(my_output_variable \"foo\")\n  else()\n    set(my_output_variable \"bar\")\n  endif()\nendmacro(set_my_variable)\n```\n\n```\nset_my_variable(\"Foo\")\nmessage(STATUS ${my_output_variable})\n```\n\n# \n\n```\nCMakeLists.txt\neditor/\n    CMakeLists.txt\n    src/\n        editor.cpp\nhighlight/\n    CMakeLists.txt\n    include/\n        highlight.h\n    src/\n        highlight.cpp\n```\n\n\n```cmake\n# CMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\nproject (example)\n\nadd_subdirectory(highlight)\nadd_subdirectory(editor)\n```\n\nhighlight \n```cmake\n# highlight/CMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\nproject (highlight)\n\nadd_library(${PROJECT_NAME} src/highlight.cpp)\ntarget_include_directories(${PROJECT_NAME} PUBLIC include)\n```\n `target_include_directories()`  `include_directories()`\n\n\n```cmake\n# editor/CMakeLists.txt\ncmake_minimum_required(VERSION 3.15)\nproject (editor)\n\nadd_executable(${PROJECT_NAME} src/editor.cpp)\ntarget_link_libraries(${PROJECT_NAME} PUBLIC highlight)\n```\ncmake  highlight \n\n\n# \n `make install` `cmake --install .`\n\n## \n\n`install(TARGETS <target>... [...])`\n\ntarget `[...]` \n- DESTINATION\n\n `CMAKE_INSTALL_PREFIX` `/usr/local`linux `cmake -DCMAKE_INSTALL_PREFIX=/my/path ..`\n\n- PERMISSIONS\n\n `OWNER_READ, OWNER_WRITE, OWNER_EXECUTE, GROUP_READ, GROUP_WRITE, GROUP_EXECUTE, WORLD_READ, WORLD_WRITE, WORLD_EXECUTE, SETUID, SETGID` \n\n `RUNTIME, LIBRARY, ARCHIVE, PUBLIC_HEADER, PRIVATE_HEADER` \n```cmake\nINSTALL(TARGETS myapp, mylib, mystaticlib\n    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR})\n```\n\n- CONFIGURATIONS\n\n DebugRelease `CONFIGURATIONS`  Debug  Release \n```cmake\ninstall(TARGETS target\n    CONFIGURATIONS Debug\n    RUNTIME DESTINATION Debug/bin)\ninstall(TARGETS target\n    CONFIGURATIONS Release\n    RUNTIME DESTINATION Release/bin)\n```\n `-DCMAKE_BUILD_TYPE=Debug` \n\n- RENAME\n\n\n\n- OPTIONAL\n\n\n\n- EXCLUDE_FROM_ALL\n\n\n\n- COMPONENT\n\n EXCLUDE_FROM_ALL  `Unspecified`\n\n\n```cmake\ninstall(TARGETS targets... [EXPORT <export-name>]\n        [[ARCHIVE|LIBRARY|RUNTIME|OBJECTS|FRAMEWORK|BUNDLE|\n          PRIVATE_HEADER|PUBLIC_HEADER|RESOURCE]\n         [DESTINATION <dir>]\n         [PERMISSIONS permissions...]\n         [CONFIGURATIONS [Debug|Release|...]]\n         [COMPONENT <component>]\n         [NAMELINK_COMPONENT <component>]\n         [OPTIONAL] [EXCLUDE_FROM_ALL]\n         [NAMELINK_ONLY|NAMELINK_SKIP]\n        ] [...]\n        [INCLUDES DESTINATION [<dir> ...]]\n        )\n```\n\n- EXPORT\n\n `export-name`EXPORT \n\n## \n\n```cmake\ninstall(<FILES|PROGRAMS> files...\n        TYPE <type> | DESTINATION <dir>\n        [PERMISSIONS permissions...]\n        [CONFIGURATIONS [Debug|Release|...]]\n        [COMPONENT <component>]\n        [RENAME <name>] [OPTIONAL] [EXCLUDE_FROM_ALL])\n```\n `CMAKE_SOURCE_DIR`\nFILES PROGRAMS \n\n- TYPE\n\n TYPE \n\n## \n```cmake\ninstall(DIRECTORY dirs...\n        TYPE <type> | DESTINATION <dir>\n        [FILE_PERMISSIONS permissions...]\n        [DIRECTORY_PERMISSIONS permissions...]\n        [USE_SOURCE_PERMISSIONS] [OPTIONAL] [MESSAGE_NEVER]\n        [CONFIGURATIONS [Debug|Release|...]]\n        [COMPONENT <component>] [EXCLUDE_FROM_ALL]\n        [FILES_MATCHING]\n        [[PATTERN <pattern> | REGEX <regex>]\n         [EXCLUDE] [PERMISSIONS permissions...]] [...])\n```\n\n- DIRECTORY\n\n `DESTINATION` dirs  `/`\n\n- USE_SOURCE_PERMISSIONS\n\n`FILE_PERMISSIONS`  `DIRECTORY_PERMISSIONS`  `USE_SOURCE_PERMISSIONS`  `FILE_PERMISSIONS`\n\n- PATTERN REGEX\n\nPATTERN REGEX \n```cmake\ninstall(DIRECTORY icons scripts/ DESTINATION share/myproj\n        PATTERN \"CVS\" EXCLUDE\n        PATTERN \"scripts/*\"\n        PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ\n                    GROUP_EXECUTE GROUP_READ)\n```\n `icons`  `scripts`   `share/myproj`  `CVS`  `scripts/*` \n\n `PATTERN \"CVS\" EXCLUDE`  `EXCLUDE` \"CVS\" \n\n- FILES_MATCHING\n\n `FILES_MATCHING` \n```cmake\ninstall(DIRECTORY src/ DESTINATION include/myproj\n        FILES_MATCHING PATTERN \"*.h\")\n```\n\n\n## \n```cmake\ninstall([[SCRIPT <file>] [CODE <code>]]\n        [COMPONENT <component>] [EXCLUDE_FROM_ALL] [...])\n```\nSCRIPT  CMAKE \n\nCODE  CMAKE \n```cmake\ninstall(CODE \"MESSAGE(\\\"Sample install message.\\\")\")\n```\n\n## \n```\ninstall(EXPORT <export-name> DESTINATION <dir>\n        [NAMESPACE <namespace>] [[FILE <name>.cmake]|\n        [PERMISSIONS permissions...]\n        [CONFIGURATIONS [Debug|Release|...]]\n        [EXPORT_LINK_INTERFACE_LIBRARIES]\n        [COMPONENT <component>]\n        [EXCLUDE_FROM_ALL])\ninstall(EXPORT_ANDROID_MK <export-name> DESTINATION <dir> [...])\n```\n `install(TARGETS)`  `EXPORT` `NAMESPACE`  `<export-name>.cmake` `FILE` `DESTINATION`  .cmake \n","slug":"cpp/cmake_1","published":1,"updated":"2021-09-15T02:08:08.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90j001bp0djaog2hfw3","content":"<p>cmake <br><span id=\"more\"></span></p>\n<p> cmake </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><strong>main.cpp</strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;Hello World!\\n&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>CMakeLists.txt</strong><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(hello_world)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp)</span><br></pre></td></tr></table></figure><br> <code>demo</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\">| -- main.cpp</span><br><span class=\"line\">| -- CMakeLists.txt</span><br></pre></td></tr></table></figure><br> <code>demo</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cmake .</span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cmake --build .</span></span><br></pre></td></tr></table></figure><br>  Makefile  <code>demo</code>  <code>build</code>  <code>build</code> <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; mkdir build</span><br><span class=\"line\">&gt; <span class=\"built_in\">cd</span> build</span><br><span class=\"line\">&gt; cmake ..</span><br><span class=\"line\">&gt; cmake --build .</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\">| -- build</span><br><span class=\"line\">| -- main.cpp</span><br><span class=\"line\">| -- foo.h</span><br><span class=\"line\">| -- foo.cpp</span><br><span class=\"line\">| -- CMakeLists.txt</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<p><strong>main.cpp</strong><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;foo.h&quot;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">foo</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>foo.h</strong><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p><strong>foo.cpp</strong><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;foo.h&quot;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;Hello World!\\n&quot;</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>CMakeLists.txt</strong><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(hello_world)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp foo.cpp)</span><br></pre></td></tr></table></figure></p>\n<p> <code>includes</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\">| -- build</span><br><span class=\"line\">| -- inlcude</span><br><span class=\"line\">    |-- foo.h</span><br><span class=\"line\">| -- main.cpp</span><br><span class=\"line\">| -- foo.cpp</span><br><span class=\"line\">| -- CMakeLists.txt</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">inlcude_directories(<span class=\"string\">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/includes&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp foo.cpp)</span><br></pre></td></tr></table></figure><br> </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (hello_world)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"string\">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/includes&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(foo foo.cpp)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(app foo)</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ul>\n<li><code>include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])</code></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>dirN</td>\n<td></td>\n</tr>\n<tr>\n<td>AFTER, BEFORE</td>\n<td> CMAKE_INCLUDE_DIRECTORIES_BEFORE </td>\n</tr>\n<tr>\n<td>SYSTEM</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(include)</span><br></pre></td></tr></table></figure><br> directory  targets  subdirectories  add_subdirectory()  </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ul>\n<li><code>add_executable(target_name [EXCLUDE_FROM_ALL] source1 [source2...])</code></li>\n<li><code>add_library(lib_name [STATIC|SHARED|MODULE][EXCLUDE_FROM_ALL] source1 [source2...])</code></li>\n</ul>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(my_ext main.cpp util.cpp)</span><br></pre></td></tr></table></figure></p>\n<p> <code>my_exe</code>  linux  <code>make my_exe</code> <code>all</code>  <code>all</code>  <code>EXCLUDE_FROM_ALL</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(my_exe EXCLUDE_FROM_ALL main.cpp)</span><br></pre></td></tr></table></figure></p>\n<p><code>add_library</code> <code>BUILD_SHARED_LIBS</code> BOOL  static  shared  <code>cmake .. -DBUILD_SHARED_LIBS=ON</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(my_lib SHARED lib.cpp)</span><br></pre></td></tr></table></figure><br><code>MODULE</code>  runtime  <code>dlopen</code> </p>\n<h1 id=\"MACROS\"><a href=\"#MACROS\" class=\"headerlink\" title=\"MACROS\"></a>MACROS</h1><p> scope context <br><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">macro</span>(set_my_variable _INPUT)</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(<span class=\"string\">&quot;$&#123;_INPUT&#125;&quot;</span> <span class=\"keyword\">STREQUAL</span> <span class=\"string\">&quot;Foo&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">set</span>(my_output_variable <span class=\"string\">&quot;foo&quot;</span>)</span><br><span class=\"line\">  <span class=\"keyword\">else</span>()</span><br><span class=\"line\">    <span class=\"keyword\">set</span>(my_output_variable <span class=\"string\">&quot;bar&quot;</span>)</span><br><span class=\"line\">  <span class=\"keyword\">endif</span>()</span><br><span class=\"line\"><span class=\"keyword\">endmacro</span>(set_my_variable)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set_my_variable(&quot;Foo&quot;)</span><br><span class=\"line\">message(STATUS $&#123;my_output_variable&#125;)</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CMakeLists.txt</span><br><span class=\"line\">editor/</span><br><span class=\"line\">    CMakeLists.txt</span><br><span class=\"line\">    src/</span><br><span class=\"line\">        editor.cpp</span><br><span class=\"line\">highlight/</span><br><span class=\"line\">    CMakeLists.txt</span><br><span class=\"line\">    include/</span><br><span class=\"line\">        highlight.h</span><br><span class=\"line\">    src/</span><br><span class=\"line\">        highlight.cpp</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (example)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span>(highlight)</span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span>(editor)</span><br></pre></td></tr></table></figure></p>\n<p>highlight <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># highlight/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (highlight)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> src/highlight.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_include_directories</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> PUBLIC <span class=\"keyword\">include</span>)</span><br></pre></td></tr></table></figure><br> <code>target_include_directories()</code>  <code>include_directories()</code></p>\n<p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># editor/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (editor)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> src/editor.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> PUBLIC highlight)</span><br></pre></td></tr></table></figure><br>cmake  highlight </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>make install</code> <code>cmake --install .</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>install(TARGETS &lt;target&gt;... [...])</code></p>\n<p>target <code>[...]</code> </p>\n<ul>\n<li>DESTINATION</li>\n</ul>\n<p> <code>CMAKE_INSTALL_PREFIX</code> <code>/usr/local</code>linux <code>cmake -DCMAKE_INSTALL_PREFIX=/my/path ..</code></p>\n<ul>\n<li>PERMISSIONS</li>\n</ul>\n<p> <code>OWNER_READ, OWNER_WRITE, OWNER_EXECUTE, GROUP_READ, GROUP_WRITE, GROUP_EXECUTE, WORLD_READ, WORLD_WRITE, WORLD_EXECUTE, SETUID, SETGID</code> </p>\n<p> <code>RUNTIME, LIBRARY, ARCHIVE, PUBLIC_HEADER, PRIVATE_HEADER</code> <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">INSTALL</span>(TARGETS myapp, mylib, mystaticlib</span><br><span class=\"line\">    RUNTIME DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_BINDIR&#125;</span></span><br><span class=\"line\">    LIBRARY DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span></span><br><span class=\"line\">    ARCHIVE DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>)</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>CONFIGURATIONS</li>\n</ul>\n<p> DebugRelease <code>CONFIGURATIONS</code>  Debug  Release <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS <span class=\"keyword\">target</span></span><br><span class=\"line\">    CONFIGURATIONS Debug</span><br><span class=\"line\">    RUNTIME DESTINATION Debug/bin)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS <span class=\"keyword\">target</span></span><br><span class=\"line\">    CONFIGURATIONS Release</span><br><span class=\"line\">    RUNTIME DESTINATION Release/bin)</span><br></pre></td></tr></table></figure><br> <code>-DCMAKE_BUILD_TYPE=Debug</code> </p>\n<ul>\n<li>RENAME</li>\n</ul>\n<p></p>\n<ul>\n<li>OPTIONAL</li>\n</ul>\n<p></p>\n<ul>\n<li>EXCLUDE_FROM_ALL</li>\n</ul>\n<p></p>\n<ul>\n<li>COMPONENT</li>\n</ul>\n<p> EXCLUDE_FROM_ALL  <code>Unspecified</code></p>\n<p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS targets... [<span class=\"keyword\">EXPORT</span> &lt;<span class=\"keyword\">export</span>-name&gt;]</span><br><span class=\"line\">        [[ARCHIVE|LIBRARY|RUNTIME|OBJECTS|FRAMEWORK|BUNDLE|</span><br><span class=\"line\">          PRIVATE_HEADER|PUBLIC_HEADER|RESOURCE]</span><br><span class=\"line\">         [DESTINATION &lt;dir&gt;]</span><br><span class=\"line\">         [PERMISSIONS permissions...]</span><br><span class=\"line\">         [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">         [COMPONENT &lt;component&gt;]</span><br><span class=\"line\">         [NAMELINK_COMPONENT &lt;component&gt;]</span><br><span class=\"line\">         [OPTIONAL] [EXCLUDE_FROM_ALL]</span><br><span class=\"line\">         [NAMELINK_ONLY|NAMELINK_SKIP]</span><br><span class=\"line\">        ] [...]</span><br><span class=\"line\">        [INCLUDES DESTINATION [&lt;dir&gt; ...]]</span><br><span class=\"line\">        )</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>EXPORT</li>\n</ul>\n<p> <code>export-name</code>EXPORT </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(&lt;FILES|PROGRAMS&gt; files...</span><br><span class=\"line\">        TYPE &lt;type&gt; | DESTINATION &lt;dir&gt;</span><br><span class=\"line\">        [PERMISSIONS permissions...]</span><br><span class=\"line\">        [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;]</span><br><span class=\"line\">        [RENAME &lt;name&gt;] [OPTIONAL] [EXCLUDE_FROM_ALL])</span><br></pre></td></tr></table></figure><br> <code>CMAKE_SOURCE_DIR</code><br>FILES PROGRAMS </p>\n<ul>\n<li>TYPE</li>\n</ul>\n<p> TYPE </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY dirs...</span><br><span class=\"line\">        TYPE &lt;type&gt; | DESTINATION &lt;dir&gt;</span><br><span class=\"line\">        [FILE_PERMISSIONS permissions...]</span><br><span class=\"line\">        [DIRECTORY_PERMISSIONS permissions...]</span><br><span class=\"line\">        [USE_SOURCE_PERMISSIONS] [OPTIONAL] [MESSAGE_NEVER]</span><br><span class=\"line\">        [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;] [EXCLUDE_FROM_ALL]</span><br><span class=\"line\">        [FILES_MATCHING]</span><br><span class=\"line\">        [[PATTERN &lt;pattern&gt; | REGEX &lt;regex&gt;]</span><br><span class=\"line\">         [EXCLUDE] [PERMISSIONS permissions...]] [...])</span><br></pre></td></tr></table></figure>\n<ul>\n<li>DIRECTORY</li>\n</ul>\n<p> <code>DESTINATION</code> dirs  <code>/</code></p>\n<ul>\n<li>USE_SOURCE_PERMISSIONS</li>\n</ul>\n<p><code>FILE_PERMISSIONS</code>  <code>DIRECTORY_PERMISSIONS</code>  <code>USE_SOURCE_PERMISSIONS</code>  <code>FILE_PERMISSIONS</code></p>\n<ul>\n<li>PATTERN REGEX</li>\n</ul>\n<p>PATTERN REGEX <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY icons scripts/ DESTINATION share/myproj</span><br><span class=\"line\">        PATTERN <span class=\"string\">&quot;CVS&quot;</span> EXCLUDE</span><br><span class=\"line\">        PATTERN <span class=\"string\">&quot;scripts/*&quot;</span></span><br><span class=\"line\">        PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ</span><br><span class=\"line\">                    GROUP_EXECUTE GROUP_READ)</span><br></pre></td></tr></table></figure><br> <code>icons</code>  <code>scripts</code>   <code>share/myproj</code>  <code>CVS</code>  <code>scripts/*</code> </p>\n<p> <code>PATTERN &quot;CVS&quot; EXCLUDE</code>  <code>EXCLUDE</code> CVS </p>\n<ul>\n<li>FILES_MATCHING</li>\n</ul>\n<p> <code>FILES_MATCHING</code> <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY src/ DESTINATION <span class=\"keyword\">include</span>/myproj</span><br><span class=\"line\">        FILES_MATCHING PATTERN <span class=\"string\">&quot;*.h&quot;</span>)</span><br></pre></td></tr></table></figure><br></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>([[SCRIPT &lt;<span class=\"keyword\">file</span>&gt;] [CODE &lt;code&gt;]]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;] [EXCLUDE_FROM_ALL] [...])</span><br></pre></td></tr></table></figure>\n<p>SCRIPT  CMAKE </p>\n<p>CODE  CMAKE <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(CODE <span class=\"string\">&quot;MESSAGE(\\&quot;Sample install message.\\&quot;)&quot;</span>)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">install(EXPORT &lt;export-name&gt; DESTINATION &lt;dir&gt;</span><br><span class=\"line\">        [NAMESPACE &lt;namespace&gt;] [[FILE &lt;name&gt;.cmake]|</span><br><span class=\"line\">        [PERMISSIONS permissions...]</span><br><span class=\"line\">        [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">        [EXPORT_LINK_INTERFACE_LIBRARIES]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;]</span><br><span class=\"line\">        [EXCLUDE_FROM_ALL])</span><br><span class=\"line\">install(EXPORT_ANDROID_MK &lt;export-name&gt; DESTINATION &lt;dir&gt; [...])</span><br></pre></td></tr></table></figure>\n<p> <code>install(TARGETS)</code>  <code>EXPORT</code> <code>NAMESPACE</code>  <code>&lt;export-name&gt;.cmake</code> <code>FILE</code> <code>DESTINATION</code>  .cmake </p>\n","site":{"data":{}},"excerpt":"<p>cmake <br>","more":"</p>\n<p> cmake </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><strong>main.cpp</strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;Hello World!\\n&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>CMakeLists.txt</strong><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(hello_world)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp)</span><br></pre></td></tr></table></figure><br> <code>demo</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\">| -- main.cpp</span><br><span class=\"line\">| -- CMakeLists.txt</span><br></pre></td></tr></table></figure><br> <code>demo</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cmake .</span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cmake --build .</span></span><br></pre></td></tr></table></figure><br>  Makefile  <code>demo</code>  <code>build</code>  <code>build</code> <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; mkdir build</span><br><span class=\"line\">&gt; <span class=\"built_in\">cd</span> build</span><br><span class=\"line\">&gt; cmake ..</span><br><span class=\"line\">&gt; cmake --build .</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\">| -- build</span><br><span class=\"line\">| -- main.cpp</span><br><span class=\"line\">| -- foo.h</span><br><span class=\"line\">| -- foo.cpp</span><br><span class=\"line\">| -- CMakeLists.txt</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<p><strong>main.cpp</strong><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;foo.h&quot;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">foo</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>foo.h</strong><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p><strong>foo.cpp</strong><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;foo.h&quot;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;Hello World!\\n&quot;</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>CMakeLists.txt</strong><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(hello_world)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp foo.cpp)</span><br></pre></td></tr></table></figure></p>\n<p> <code>includes</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">demo</span><br><span class=\"line\">| -- build</span><br><span class=\"line\">| -- inlcude</span><br><span class=\"line\">    |-- foo.h</span><br><span class=\"line\">| -- main.cpp</span><br><span class=\"line\">| -- foo.cpp</span><br><span class=\"line\">| -- CMakeLists.txt</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">inlcude_directories(<span class=\"string\">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/includes&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp foo.cpp)</span><br></pre></td></tr></table></figure><br> </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (hello_world)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">include_directories</span>(<span class=\"string\">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/includes&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(foo foo.cpp)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(app main.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(app foo)</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ul>\n<li><code>include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...])</code></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>dirN</td>\n<td></td>\n</tr>\n<tr>\n<td>AFTER, BEFORE</td>\n<td> CMAKE_INCLUDE_DIRECTORIES_BEFORE </td>\n</tr>\n<tr>\n<td>SYSTEM</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(include)</span><br></pre></td></tr></table></figure><br> directory  targets  subdirectories  add_subdirectory()  </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ul>\n<li><code>add_executable(target_name [EXCLUDE_FROM_ALL] source1 [source2...])</code></li>\n<li><code>add_library(lib_name [STATIC|SHARED|MODULE][EXCLUDE_FROM_ALL] source1 [source2...])</code></li>\n</ul>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(my_ext main.cpp util.cpp)</span><br></pre></td></tr></table></figure></p>\n<p> <code>my_exe</code>  linux  <code>make my_exe</code> <code>all</code>  <code>all</code>  <code>EXCLUDE_FROM_ALL</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(my_exe EXCLUDE_FROM_ALL main.cpp)</span><br></pre></td></tr></table></figure></p>\n<p><code>add_library</code> <code>BUILD_SHARED_LIBS</code> BOOL  static  shared  <code>cmake .. -DBUILD_SHARED_LIBS=ON</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(my_lib SHARED lib.cpp)</span><br></pre></td></tr></table></figure><br><code>MODULE</code>  runtime  <code>dlopen</code> </p>\n<h1 id=\"MACROS\"><a href=\"#MACROS\" class=\"headerlink\" title=\"MACROS\"></a>MACROS</h1><p> scope context <br><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">macro</span>(set_my_variable _INPUT)</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(<span class=\"string\">&quot;$&#123;_INPUT&#125;&quot;</span> <span class=\"keyword\">STREQUAL</span> <span class=\"string\">&quot;Foo&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">set</span>(my_output_variable <span class=\"string\">&quot;foo&quot;</span>)</span><br><span class=\"line\">  <span class=\"keyword\">else</span>()</span><br><span class=\"line\">    <span class=\"keyword\">set</span>(my_output_variable <span class=\"string\">&quot;bar&quot;</span>)</span><br><span class=\"line\">  <span class=\"keyword\">endif</span>()</span><br><span class=\"line\"><span class=\"keyword\">endmacro</span>(set_my_variable)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set_my_variable(&quot;Foo&quot;)</span><br><span class=\"line\">message(STATUS $&#123;my_output_variable&#125;)</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CMakeLists.txt</span><br><span class=\"line\">editor/</span><br><span class=\"line\">    CMakeLists.txt</span><br><span class=\"line\">    src/</span><br><span class=\"line\">        editor.cpp</span><br><span class=\"line\">highlight/</span><br><span class=\"line\">    CMakeLists.txt</span><br><span class=\"line\">    include/</span><br><span class=\"line\">        highlight.h</span><br><span class=\"line\">    src/</span><br><span class=\"line\">        highlight.cpp</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (example)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span>(highlight)</span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span>(editor)</span><br></pre></td></tr></table></figure></p>\n<p>highlight <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># highlight/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (highlight)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> src/highlight.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_include_directories</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> PUBLIC <span class=\"keyword\">include</span>)</span><br></pre></td></tr></table></figure><br> <code>target_include_directories()</code>  <code>include_directories()</code></p>\n<p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># editor/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span> (editor)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> src/editor.cpp)</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> PUBLIC highlight)</span><br></pre></td></tr></table></figure><br>cmake  highlight </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>make install</code> <code>cmake --install .</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>install(TARGETS &lt;target&gt;... [...])</code></p>\n<p>target <code>[...]</code> </p>\n<ul>\n<li>DESTINATION</li>\n</ul>\n<p> <code>CMAKE_INSTALL_PREFIX</code> <code>/usr/local</code>linux <code>cmake -DCMAKE_INSTALL_PREFIX=/my/path ..</code></p>\n<ul>\n<li>PERMISSIONS</li>\n</ul>\n<p> <code>OWNER_READ, OWNER_WRITE, OWNER_EXECUTE, GROUP_READ, GROUP_WRITE, GROUP_EXECUTE, WORLD_READ, WORLD_WRITE, WORLD_EXECUTE, SETUID, SETGID</code> </p>\n<p> <code>RUNTIME, LIBRARY, ARCHIVE, PUBLIC_HEADER, PRIVATE_HEADER</code> <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">INSTALL</span>(TARGETS myapp, mylib, mystaticlib</span><br><span class=\"line\">    RUNTIME DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_BINDIR&#125;</span></span><br><span class=\"line\">    LIBRARY DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span></span><br><span class=\"line\">    ARCHIVE DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>)</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>CONFIGURATIONS</li>\n</ul>\n<p> DebugRelease <code>CONFIGURATIONS</code>  Debug  Release <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS <span class=\"keyword\">target</span></span><br><span class=\"line\">    CONFIGURATIONS Debug</span><br><span class=\"line\">    RUNTIME DESTINATION Debug/bin)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS <span class=\"keyword\">target</span></span><br><span class=\"line\">    CONFIGURATIONS Release</span><br><span class=\"line\">    RUNTIME DESTINATION Release/bin)</span><br></pre></td></tr></table></figure><br> <code>-DCMAKE_BUILD_TYPE=Debug</code> </p>\n<ul>\n<li>RENAME</li>\n</ul>\n<p></p>\n<ul>\n<li>OPTIONAL</li>\n</ul>\n<p></p>\n<ul>\n<li>EXCLUDE_FROM_ALL</li>\n</ul>\n<p></p>\n<ul>\n<li>COMPONENT</li>\n</ul>\n<p> EXCLUDE_FROM_ALL  <code>Unspecified</code></p>\n<p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS targets... [<span class=\"keyword\">EXPORT</span> &lt;<span class=\"keyword\">export</span>-name&gt;]</span><br><span class=\"line\">        [[ARCHIVE|LIBRARY|RUNTIME|OBJECTS|FRAMEWORK|BUNDLE|</span><br><span class=\"line\">          PRIVATE_HEADER|PUBLIC_HEADER|RESOURCE]</span><br><span class=\"line\">         [DESTINATION &lt;dir&gt;]</span><br><span class=\"line\">         [PERMISSIONS permissions...]</span><br><span class=\"line\">         [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">         [COMPONENT &lt;component&gt;]</span><br><span class=\"line\">         [NAMELINK_COMPONENT &lt;component&gt;]</span><br><span class=\"line\">         [OPTIONAL] [EXCLUDE_FROM_ALL]</span><br><span class=\"line\">         [NAMELINK_ONLY|NAMELINK_SKIP]</span><br><span class=\"line\">        ] [...]</span><br><span class=\"line\">        [INCLUDES DESTINATION [&lt;dir&gt; ...]]</span><br><span class=\"line\">        )</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>EXPORT</li>\n</ul>\n<p> <code>export-name</code>EXPORT </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(&lt;FILES|PROGRAMS&gt; files...</span><br><span class=\"line\">        TYPE &lt;type&gt; | DESTINATION &lt;dir&gt;</span><br><span class=\"line\">        [PERMISSIONS permissions...]</span><br><span class=\"line\">        [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;]</span><br><span class=\"line\">        [RENAME &lt;name&gt;] [OPTIONAL] [EXCLUDE_FROM_ALL])</span><br></pre></td></tr></table></figure><br> <code>CMAKE_SOURCE_DIR</code><br>FILES PROGRAMS </p>\n<ul>\n<li>TYPE</li>\n</ul>\n<p> TYPE </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY dirs...</span><br><span class=\"line\">        TYPE &lt;type&gt; | DESTINATION &lt;dir&gt;</span><br><span class=\"line\">        [FILE_PERMISSIONS permissions...]</span><br><span class=\"line\">        [DIRECTORY_PERMISSIONS permissions...]</span><br><span class=\"line\">        [USE_SOURCE_PERMISSIONS] [OPTIONAL] [MESSAGE_NEVER]</span><br><span class=\"line\">        [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;] [EXCLUDE_FROM_ALL]</span><br><span class=\"line\">        [FILES_MATCHING]</span><br><span class=\"line\">        [[PATTERN &lt;pattern&gt; | REGEX &lt;regex&gt;]</span><br><span class=\"line\">         [EXCLUDE] [PERMISSIONS permissions...]] [...])</span><br></pre></td></tr></table></figure>\n<ul>\n<li>DIRECTORY</li>\n</ul>\n<p> <code>DESTINATION</code> dirs  <code>/</code></p>\n<ul>\n<li>USE_SOURCE_PERMISSIONS</li>\n</ul>\n<p><code>FILE_PERMISSIONS</code>  <code>DIRECTORY_PERMISSIONS</code>  <code>USE_SOURCE_PERMISSIONS</code>  <code>FILE_PERMISSIONS</code></p>\n<ul>\n<li>PATTERN REGEX</li>\n</ul>\n<p>PATTERN REGEX <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY icons scripts/ DESTINATION share/myproj</span><br><span class=\"line\">        PATTERN <span class=\"string\">&quot;CVS&quot;</span> EXCLUDE</span><br><span class=\"line\">        PATTERN <span class=\"string\">&quot;scripts/*&quot;</span></span><br><span class=\"line\">        PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ</span><br><span class=\"line\">                    GROUP_EXECUTE GROUP_READ)</span><br></pre></td></tr></table></figure><br> <code>icons</code>  <code>scripts</code>   <code>share/myproj</code>  <code>CVS</code>  <code>scripts/*</code> </p>\n<p> <code>PATTERN &quot;CVS&quot; EXCLUDE</code>  <code>EXCLUDE</code> CVS </p>\n<ul>\n<li>FILES_MATCHING</li>\n</ul>\n<p> <code>FILES_MATCHING</code> <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(DIRECTORY src/ DESTINATION <span class=\"keyword\">include</span>/myproj</span><br><span class=\"line\">        FILES_MATCHING PATTERN <span class=\"string\">&quot;*.h&quot;</span>)</span><br></pre></td></tr></table></figure><br></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>([[SCRIPT &lt;<span class=\"keyword\">file</span>&gt;] [CODE &lt;code&gt;]]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;] [EXCLUDE_FROM_ALL] [...])</span><br></pre></td></tr></table></figure>\n<p>SCRIPT  CMAKE </p>\n<p>CODE  CMAKE <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">install</span>(CODE <span class=\"string\">&quot;MESSAGE(\\&quot;Sample install message.\\&quot;)&quot;</span>)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">install(EXPORT &lt;export-name&gt; DESTINATION &lt;dir&gt;</span><br><span class=\"line\">        [NAMESPACE &lt;namespace&gt;] [[FILE &lt;name&gt;.cmake]|</span><br><span class=\"line\">        [PERMISSIONS permissions...]</span><br><span class=\"line\">        [CONFIGURATIONS [Debug|Release|...]]</span><br><span class=\"line\">        [EXPORT_LINK_INTERFACE_LIBRARIES]</span><br><span class=\"line\">        [COMPONENT &lt;component&gt;]</span><br><span class=\"line\">        [EXCLUDE_FROM_ALL])</span><br><span class=\"line\">install(EXPORT_ANDROID_MK &lt;export-name&gt; DESTINATION &lt;dir&gt; [...])</span><br></pre></td></tr></table></figure>\n<p> <code>install(TARGETS)</code>  <code>EXPORT</code> <code>NAMESPACE</code>  <code>&lt;export-name&gt;.cmake</code> <code>FILE</code> <code>DESTINATION</code>  .cmake </p>"},{"title":"cmake ","date":"2021-06-04T10:50:48.000Z","_content":"\ncmake \n<!-- more -->\n\n## find_program\n```\nfind_program (\n          <VAR>\n          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]\n          [HINTS path1 [path2 ... ENV var]]\n          [PATHS path1 [path2 ... ENV var]]\n          [PATH_SUFFIXES suffix1 [suffix2 ...]]\n          [DOC \"cache documentation string\"]\n          [REQUIRED]\n          [NO_DEFAULT_PATH]\n          [NO_PACKAGE_ROOT_PATH]\n          [NO_CMAKE_PATH]\n          [NO_CMAKE_ENVIRONMENT_PATH]\n          [NO_SYSTEM_ENVIRONMENT_PATH]\n          [NO_CMAKE_SYSTEM_PATH]\n          [CMAKE_FIND_ROOT_PATH_BOTH |\n           ONLY_CMAKE_FIND_ROOT_PATH |\n           NO_CMAKE_FIND_ROOT_PATH]\n         )\n```\n `find_program (<VAR> name1 [path1 path2 ...])`\n\n `VAR`  `<VAR>-NOTFOUND`\n- NAMES\n\n\n\n- HINTS, PATHS\n\n`ENV var` \n\n- PATH-SUFFIXES\n\n\n\n `NO_DEFAULT_PATH` \n\n...\n\n## file\n`file(WRITE filename \"message to write\" ...)`\n `filename` \n\n`file(APPEND filename \"message to write\" ...)`\n\n\n`file(READ filename variable [LIMIT numBytes] [OFFSET offset] [HEX])`\n `variable` `HEX` \n\n`file({GLOB|GLOB_RECURESE} <variable> ... [<globbing-expressions>...])`\n `<globbing-expressions>`  `<variable>` \n\n`GLOB_RECURSE` \n```\n/dir/*.py  - match all python files in /dir and subdirectories\n```\n\n## configure_file\n`configure_file(<input> <output>\n               [NO_SOURCE_PERMISSIONS | USE_SOURCE_PERMISSIONS |\n                FILE_PERMISSIONS <permissions>...]\n               [COPYONLY] [ESCAPE_QUOTES] [@ONLY]\n               [NEWLINE_STYLE [UNIX|DOS|WIN32|LF|CRLF] ])`\n\n `input`  `output`  `@VAR@`  `${VAR}` \n\n`<input>`  `#cmakedefine VAR` \n1.  `VAR`  `ON` `#define VAR`\n2.  `VAR`  `OFF` `/* #undef VAR */`\n\n`#cmakedefine01 VAR`  `#define VAR 1`  `#define VAR 0`\n\n `IMMEDIATE` \n\n\n## \ncmake  include  [](https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html)\n\n\n\n\n","source":"_posts/cpp/cmake_cmds_1.md","raw":"---\ntitle: cmake \ndate: 2021-06-04 18:50:48\ntags:\n---\n\ncmake \n<!-- more -->\n\n## find_program\n```\nfind_program (\n          <VAR>\n          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]\n          [HINTS path1 [path2 ... ENV var]]\n          [PATHS path1 [path2 ... ENV var]]\n          [PATH_SUFFIXES suffix1 [suffix2 ...]]\n          [DOC \"cache documentation string\"]\n          [REQUIRED]\n          [NO_DEFAULT_PATH]\n          [NO_PACKAGE_ROOT_PATH]\n          [NO_CMAKE_PATH]\n          [NO_CMAKE_ENVIRONMENT_PATH]\n          [NO_SYSTEM_ENVIRONMENT_PATH]\n          [NO_CMAKE_SYSTEM_PATH]\n          [CMAKE_FIND_ROOT_PATH_BOTH |\n           ONLY_CMAKE_FIND_ROOT_PATH |\n           NO_CMAKE_FIND_ROOT_PATH]\n         )\n```\n `find_program (<VAR> name1 [path1 path2 ...])`\n\n `VAR`  `<VAR>-NOTFOUND`\n- NAMES\n\n\n\n- HINTS, PATHS\n\n`ENV var` \n\n- PATH-SUFFIXES\n\n\n\n `NO_DEFAULT_PATH` \n\n...\n\n## file\n`file(WRITE filename \"message to write\" ...)`\n `filename` \n\n`file(APPEND filename \"message to write\" ...)`\n\n\n`file(READ filename variable [LIMIT numBytes] [OFFSET offset] [HEX])`\n `variable` `HEX` \n\n`file({GLOB|GLOB_RECURESE} <variable> ... [<globbing-expressions>...])`\n `<globbing-expressions>`  `<variable>` \n\n`GLOB_RECURSE` \n```\n/dir/*.py  - match all python files in /dir and subdirectories\n```\n\n## configure_file\n`configure_file(<input> <output>\n               [NO_SOURCE_PERMISSIONS | USE_SOURCE_PERMISSIONS |\n                FILE_PERMISSIONS <permissions>...]\n               [COPYONLY] [ESCAPE_QUOTES] [@ONLY]\n               [NEWLINE_STYLE [UNIX|DOS|WIN32|LF|CRLF] ])`\n\n `input`  `output`  `@VAR@`  `${VAR}` \n\n`<input>`  `#cmakedefine VAR` \n1.  `VAR`  `ON` `#define VAR`\n2.  `VAR`  `OFF` `/* #undef VAR */`\n\n`#cmakedefine01 VAR`  `#define VAR 1`  `#define VAR 0`\n\n `IMMEDIATE` \n\n\n## \ncmake  include  [](https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html)\n\n\n\n\n","slug":"cpp/cmake_cmds_1","published":1,"updated":"2021-09-15T02:08:34.168Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90k001dp0dj7lbm1yw9","content":"<p>cmake <br><span id=\"more\"></span></p>\n<h2 id=\"find-program\"><a href=\"#find-program\" class=\"headerlink\" title=\"find_program\"></a>find_program</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_program (</span><br><span class=\"line\">          &lt;VAR&gt;</span><br><span class=\"line\">          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]</span><br><span class=\"line\">          [HINTS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATHS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATH_SUFFIXES suffix1 [suffix2 ...]]</span><br><span class=\"line\">          [DOC &quot;cache documentation string&quot;]</span><br><span class=\"line\">          [REQUIRED]</span><br><span class=\"line\">          [NO_DEFAULT_PATH]</span><br><span class=\"line\">          [NO_PACKAGE_ROOT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_PATH]</span><br><span class=\"line\">          [NO_CMAKE_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_SYSTEM_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_SYSTEM_PATH]</span><br><span class=\"line\">          [CMAKE_FIND_ROOT_PATH_BOTH |</span><br><span class=\"line\">           ONLY_CMAKE_FIND_ROOT_PATH |</span><br><span class=\"line\">           NO_CMAKE_FIND_ROOT_PATH]</span><br><span class=\"line\">         )</span><br></pre></td></tr></table></figure>\n<p> <code>find_program (&lt;VAR&gt; name1 [path1 path2 ...])</code></p>\n<p> <code>VAR</code>  <code>&lt;VAR&gt;-NOTFOUND</code></p>\n<ul>\n<li>NAMES</li>\n</ul>\n<p></p>\n<ul>\n<li>HINTS, PATHS</li>\n</ul>\n<p><code>ENV var</code> </p>\n<ul>\n<li>PATH-SUFFIXES</li>\n</ul>\n<p></p>\n<p> <code>NO_DEFAULT_PATH</code> </p>\n<p></p>\n<h2 id=\"file\"><a href=\"#file\" class=\"headerlink\" title=\"file\"></a>file</h2><p><code>file(WRITE filename &quot;message to write&quot; ...)</code><br> <code>filename</code> </p>\n<p><code>file(APPEND filename &quot;message to write&quot; ...)</code><br></p>\n<p><code>file(READ filename variable [LIMIT numBytes] [OFFSET offset] [HEX])</code><br> <code>variable</code> <code>HEX</code> </p>\n<p><code>file(&#123;GLOB|GLOB_RECURESE&#125; &lt;variable&gt; ... [&lt;globbing-expressions&gt;...])</code><br> <code>&lt;globbing-expressions&gt;</code>  <code>&lt;variable&gt;</code> </p>\n<p><code>GLOB_RECURSE</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/dir/*.py  - match all python files in /dir and subdirectories</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"configure-file\"><a href=\"#configure-file\" class=\"headerlink\" title=\"configure_file\"></a>configure_file</h2><p><code>configure_file(&lt;input&gt; &lt;output&gt;\n               [NO_SOURCE_PERMISSIONS | USE_SOURCE_PERMISSIONS |\n                FILE_PERMISSIONS &lt;permissions&gt;...]\n               [COPYONLY] [ESCAPE_QUOTES] [@ONLY]\n               [NEWLINE_STYLE [UNIX|DOS|WIN32|LF|CRLF] ])</code></p>\n<p> <code>input</code>  <code>output</code>  <code>@VAR@</code>  <code>$&#123;VAR&#125;</code> </p>\n<p><code>&lt;input&gt;</code>  <code>#cmakedefine VAR</code> </p>\n<ol>\n<li> <code>VAR</code>  <code>ON</code> <code>#define VAR</code></li>\n<li> <code>VAR</code>  <code>OFF</code> <code>/* #undef VAR */</code></li>\n</ol>\n<p><code>#cmakedefine01 VAR</code>  <code>#define VAR 1</code>  <code>#define VAR 0</code></p>\n<p> <code>IMMEDIATE</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>cmake  include  <a href=\"https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html\"></a></p>\n","site":{"data":{}},"excerpt":"<p>cmake <br>","more":"</p>\n<h2 id=\"find-program\"><a href=\"#find-program\" class=\"headerlink\" title=\"find_program\"></a>find_program</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_program (</span><br><span class=\"line\">          &lt;VAR&gt;</span><br><span class=\"line\">          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]</span><br><span class=\"line\">          [HINTS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATHS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATH_SUFFIXES suffix1 [suffix2 ...]]</span><br><span class=\"line\">          [DOC &quot;cache documentation string&quot;]</span><br><span class=\"line\">          [REQUIRED]</span><br><span class=\"line\">          [NO_DEFAULT_PATH]</span><br><span class=\"line\">          [NO_PACKAGE_ROOT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_PATH]</span><br><span class=\"line\">          [NO_CMAKE_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_SYSTEM_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_SYSTEM_PATH]</span><br><span class=\"line\">          [CMAKE_FIND_ROOT_PATH_BOTH |</span><br><span class=\"line\">           ONLY_CMAKE_FIND_ROOT_PATH |</span><br><span class=\"line\">           NO_CMAKE_FIND_ROOT_PATH]</span><br><span class=\"line\">         )</span><br></pre></td></tr></table></figure>\n<p> <code>find_program (&lt;VAR&gt; name1 [path1 path2 ...])</code></p>\n<p> <code>VAR</code>  <code>&lt;VAR&gt;-NOTFOUND</code></p>\n<ul>\n<li>NAMES</li>\n</ul>\n<p></p>\n<ul>\n<li>HINTS, PATHS</li>\n</ul>\n<p><code>ENV var</code> </p>\n<ul>\n<li>PATH-SUFFIXES</li>\n</ul>\n<p></p>\n<p> <code>NO_DEFAULT_PATH</code> </p>\n<p></p>\n<h2 id=\"file\"><a href=\"#file\" class=\"headerlink\" title=\"file\"></a>file</h2><p><code>file(WRITE filename &quot;message to write&quot; ...)</code><br> <code>filename</code> </p>\n<p><code>file(APPEND filename &quot;message to write&quot; ...)</code><br></p>\n<p><code>file(READ filename variable [LIMIT numBytes] [OFFSET offset] [HEX])</code><br> <code>variable</code> <code>HEX</code> </p>\n<p><code>file(&#123;GLOB|GLOB_RECURESE&#125; &lt;variable&gt; ... [&lt;globbing-expressions&gt;...])</code><br> <code>&lt;globbing-expressions&gt;</code>  <code>&lt;variable&gt;</code> </p>\n<p><code>GLOB_RECURSE</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/dir/*.py  - match all python files in /dir and subdirectories</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"configure-file\"><a href=\"#configure-file\" class=\"headerlink\" title=\"configure_file\"></a>configure_file</h2><p><code>configure_file(&lt;input&gt; &lt;output&gt;\n               [NO_SOURCE_PERMISSIONS | USE_SOURCE_PERMISSIONS |\n                FILE_PERMISSIONS &lt;permissions&gt;...]\n               [COPYONLY] [ESCAPE_QUOTES] [@ONLY]\n               [NEWLINE_STYLE [UNIX|DOS|WIN32|LF|CRLF] ])</code></p>\n<p> <code>input</code>  <code>output</code>  <code>@VAR@</code>  <code>$&#123;VAR&#125;</code> </p>\n<p><code>&lt;input&gt;</code>  <code>#cmakedefine VAR</code> </p>\n<ol>\n<li> <code>VAR</code>  <code>ON</code> <code>#define VAR</code></li>\n<li> <code>VAR</code>  <code>OFF</code> <code>/* #undef VAR */</code></li>\n</ol>\n<p><code>#cmakedefine01 VAR</code>  <code>#define VAR 1</code>  <code>#define VAR 0</code></p>\n<p> <code>IMMEDIATE</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>cmake  include  <a href=\"https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html\"></a></p>"},{"title":"cmake ","date":"2021-06-08T06:08:47.000Z","p":"cpp/cmake_find","_content":"cmake \n<!-- more -->\n\n# find_package\n\n1. CMake \n\ncmakeModule`path_to_your_cmake/share/cmake-<version>/Modules``Find<LibaryName>.cmake`find_package[Find Modules](https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html)\n\n `CURL`\n```\nfind_package(CURL)\n```\n\n -\n\n```\n<LibaryName>_FOUND\n\n<LibaryName>_INCLUDE_DIR or <LibaryName>_INCLUDES <LibaryName>_LIBRARY or <LibaryName>_LIBRARIES\n```\n\n2.  cmake \n\n `glog`cmake  Module  `FindGlog.cmake` glog \n\n```\n# clone\ngit clone https://github.com/google/glog.git \n#  \ncd glog\ngit checkout v0.40  \n\n# \ncmake -H. -Bbuild -G \"Unix Makefiles\"\ncmake --build build\ncmake --build build --target install\n```\n\ncurlglog\n```\nfind_package(GLOG)\nadd_executable(glogtest glogtest.cc)\nif(GLOG_FOUND)\n    # glogtarget_include_directories\n    target_link_libraries(glogtest glog::glog)\nelse(GLOG_FOUND)\n    message(FATAL_ERROR GLOG library not found)\nendif(GLOG_FOUND)\n```\n\nfind_package \n\n## Module \n\n curl cmake  `Find<LibraryName>.cmake`  `.cmake`  `share/cmake-<version>/Modules`  `CMAKE_MODULE_PATH` \n\n Module  `.cmake`  Config \n\n## Config \n `<LibraryName>Config.cmake`  `<lower-case-package-name>-config.cmake`  [cmake ](/2021/06/03/cpp/cmake_im_ex)\n\n\n# find_library\n \n```\nfind_library (<VAR> name1 [path1 path2 ...])\n```\n\n```\nfind_library (\n          <VAR>\n          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]\n          [HINTS path1 [path2 ... ENV var]]\n          [PATHS path1 [path2 ... ENV var]]\n          [PATH_SUFFIXES suffix1 [suffix2 ...]]\n          [DOC \"cache documentation string\"]\n          [NO_DEFAULT_PATH]\n          [NO_CMAKE_ENVIRONMENT_PATH]\n          [NO_CMAKE_PATH]\n          [NO_SYSTEM_ENVIRONMENT_PATH]\n          [NO_CMAKE_SYSTEM_PATH]\n          [CMAKE_FIND_ROOT_PATH_BOTH |\n           ONLY_CMAKE_FIND_ROOT_PATH |\n           NO_CMAKE_FIND_ROOT_PATH]\n         )\n```\n `<VAR>`  `<VAR>-NOTFOUND` `name1`  `PATHS` `PATH-SUFFIXES`  `NO_DEFAULT_PATH` \n\n1.  cmake  `-DVAR=value` `NO_CMAKE_PATH` cmake \n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>`  `<prefix>/lib`  `<prefix>`  `CMAKE_PREFIX_PATH` \n    -  `CMAKE_LIBRARY_PATH` \n    -  `CMAKE_FRAMEWORD_PATH` \n\n2.  cmake  shell  `~/.bashrc` `NO_CMAKE_ENVIRONMENT_PATH`\n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>`  `<prefix>/lib`  `<prefix>`  `CMAKE_PREFIX_PATH` \n    -  `CMAKE_LIBRARY_PATH` \n    -  `CMAKE_FRAMEWORD_PATH` \n\n3.  `HINTS` \n\n4.  `NO_SYSTEM_ENVIRONMENT_PATH`\n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>` `PATH`  `<prefix>/[s]bin` `<prefix>/lib` `<prefix>`  `<prefix>/lib` `<prefix>`\n\n5.  cmake  `NO_CMAKE_SYSTEM_PATH`\n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>`  `<prefix>/lib`  `<prefix>`  `CMAKE_SYSTEM_PREFIX_PATH` \n    -  `CMAKE_SYSTEM_LIBRARY_PATH` \n    -  `CMAKE_SYSTEM_FRAMEWORD_PATH` \n\n","source":"_posts/cpp/cmake_find.md","raw":"---\ntitle: cmake \ndate: 2021-06-08 14:08:47\ntags:\np: cpp/cmake_find\n---\ncmake \n<!-- more -->\n\n# find_package\n\n1. CMake \n\ncmakeModule`path_to_your_cmake/share/cmake-<version>/Modules``Find<LibaryName>.cmake`find_package[Find Modules](https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html)\n\n `CURL`\n```\nfind_package(CURL)\n```\n\n -\n\n```\n<LibaryName>_FOUND\n\n<LibaryName>_INCLUDE_DIR or <LibaryName>_INCLUDES <LibaryName>_LIBRARY or <LibaryName>_LIBRARIES\n```\n\n2.  cmake \n\n `glog`cmake  Module  `FindGlog.cmake` glog \n\n```\n# clone\ngit clone https://github.com/google/glog.git \n#  \ncd glog\ngit checkout v0.40  \n\n# \ncmake -H. -Bbuild -G \"Unix Makefiles\"\ncmake --build build\ncmake --build build --target install\n```\n\ncurlglog\n```\nfind_package(GLOG)\nadd_executable(glogtest glogtest.cc)\nif(GLOG_FOUND)\n    # glogtarget_include_directories\n    target_link_libraries(glogtest glog::glog)\nelse(GLOG_FOUND)\n    message(FATAL_ERROR GLOG library not found)\nendif(GLOG_FOUND)\n```\n\nfind_package \n\n## Module \n\n curl cmake  `Find<LibraryName>.cmake`  `.cmake`  `share/cmake-<version>/Modules`  `CMAKE_MODULE_PATH` \n\n Module  `.cmake`  Config \n\n## Config \n `<LibraryName>Config.cmake`  `<lower-case-package-name>-config.cmake`  [cmake ](/2021/06/03/cpp/cmake_im_ex)\n\n\n# find_library\n \n```\nfind_library (<VAR> name1 [path1 path2 ...])\n```\n\n```\nfind_library (\n          <VAR>\n          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]\n          [HINTS path1 [path2 ... ENV var]]\n          [PATHS path1 [path2 ... ENV var]]\n          [PATH_SUFFIXES suffix1 [suffix2 ...]]\n          [DOC \"cache documentation string\"]\n          [NO_DEFAULT_PATH]\n          [NO_CMAKE_ENVIRONMENT_PATH]\n          [NO_CMAKE_PATH]\n          [NO_SYSTEM_ENVIRONMENT_PATH]\n          [NO_CMAKE_SYSTEM_PATH]\n          [CMAKE_FIND_ROOT_PATH_BOTH |\n           ONLY_CMAKE_FIND_ROOT_PATH |\n           NO_CMAKE_FIND_ROOT_PATH]\n         )\n```\n `<VAR>`  `<VAR>-NOTFOUND` `name1`  `PATHS` `PATH-SUFFIXES`  `NO_DEFAULT_PATH` \n\n1.  cmake  `-DVAR=value` `NO_CMAKE_PATH` cmake \n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>`  `<prefix>/lib`  `<prefix>`  `CMAKE_PREFIX_PATH` \n    -  `CMAKE_LIBRARY_PATH` \n    -  `CMAKE_FRAMEWORD_PATH` \n\n2.  cmake  shell  `~/.bashrc` `NO_CMAKE_ENVIRONMENT_PATH`\n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>`  `<prefix>/lib`  `<prefix>`  `CMAKE_PREFIX_PATH` \n    -  `CMAKE_LIBRARY_PATH` \n    -  `CMAKE_FRAMEWORD_PATH` \n\n3.  `HINTS` \n\n4.  `NO_SYSTEM_ENVIRONMENT_PATH`\n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>` `PATH`  `<prefix>/[s]bin` `<prefix>/lib` `<prefix>`  `<prefix>/lib` `<prefix>`\n\n5.  cmake  `NO_CMAKE_SYSTEM_PATH`\n    -  `CMAKE_LIBRARY_ARCHITECTURE` `<prefix>/lib/<arch>`  `<prefix>/lib`  `<prefix>`  `CMAKE_SYSTEM_PREFIX_PATH` \n    -  `CMAKE_SYSTEM_LIBRARY_PATH` \n    -  `CMAKE_SYSTEM_FRAMEWORD_PATH` \n\n","slug":"cpp/cmake_find","published":1,"updated":"2021-09-15T02:07:40.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90l001gp0djfi8e9y9x","content":"<p>cmake <br><span id=\"more\"></span></p>\n<h1 id=\"find-package\"><a href=\"#find-package\" class=\"headerlink\" title=\"find_package\"></a>find_package</h1><ol>\n<li>CMake </li>\n</ol>\n<p>cmakeModule<code>path_to_your_cmake/share/cmake-&lt;version&gt;/Modules</code><code>Find&lt;LibaryName&gt;.cmake</code>find_package<a href=\"https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html\">Find Modules</a></p>\n<p> <code>CURL</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(CURL)</span><br></pre></td></tr></table></figure></p>\n<p> -</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;LibaryName&gt;_FOUND</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;LibaryName&gt;_INCLUDE_DIR or &lt;LibaryName&gt;_INCLUDES &lt;LibaryName&gt;_LIBRARY or &lt;LibaryName&gt;_LIBRARIES</span><br></pre></td></tr></table></figure>\n<ol>\n<li> cmake </li>\n</ol>\n<p> <code>glog</code>cmake  Module  <code>FindGlog.cmake</code> glog </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># clone</span><br><span class=\"line\">git clone https://github.com/google/glog.git </span><br><span class=\"line\">#  </span><br><span class=\"line\">cd glog</span><br><span class=\"line\">git checkout v0.40  </span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">cmake -H. -Bbuild -G &quot;Unix Makefiles&quot;</span><br><span class=\"line\">cmake --build build</span><br><span class=\"line\">cmake --build build --target install</span><br></pre></td></tr></table></figure>\n<p>curlglog<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(GLOG)</span><br><span class=\"line\">add_executable(glogtest glogtest.cc)</span><br><span class=\"line\">if(GLOG_FOUND)</span><br><span class=\"line\">    # glogtarget_include_directories</span><br><span class=\"line\">    target_link_libraries(glogtest glog::glog)</span><br><span class=\"line\">else(GLOG_FOUND)</span><br><span class=\"line\">    message(FATAL_ERROR GLOG library not found)</span><br><span class=\"line\">endif(GLOG_FOUND)</span><br></pre></td></tr></table></figure></p>\n<p>find_package </p>\n<h2 id=\"Module-\"><a href=\"#Module-\" class=\"headerlink\" title=\"Module \"></a>Module </h2><p> curl cmake  <code>Find&lt;LibraryName&gt;.cmake</code>  <code>.cmake</code>  <code>share/cmake-&lt;version&gt;/Modules</code>  <code>CMAKE_MODULE_PATH</code> </p>\n<p> Module  <code>.cmake</code>  Config </p>\n<h2 id=\"Config-\"><a href=\"#Config-\" class=\"headerlink\" title=\"Config \"></a>Config </h2><p> <code>&lt;LibraryName&gt;Config.cmake</code>  <code>&lt;lower-case-package-name&gt;-config.cmake</code>  <a href=\"/2021/06/03/cpp/cmake_im_ex\">cmake </a></p>\n<h1 id=\"find-library\"><a href=\"#find-library\" class=\"headerlink\" title=\"find_library\"></a>find_library</h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_library (&lt;VAR&gt; name1 [path1 path2 ...])</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_library (</span><br><span class=\"line\">          &lt;VAR&gt;</span><br><span class=\"line\">          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]</span><br><span class=\"line\">          [HINTS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATHS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATH_SUFFIXES suffix1 [suffix2 ...]]</span><br><span class=\"line\">          [DOC &quot;cache documentation string&quot;]</span><br><span class=\"line\">          [NO_DEFAULT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_PATH]</span><br><span class=\"line\">          [NO_SYSTEM_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_SYSTEM_PATH]</span><br><span class=\"line\">          [CMAKE_FIND_ROOT_PATH_BOTH |</span><br><span class=\"line\">           ONLY_CMAKE_FIND_ROOT_PATH |</span><br><span class=\"line\">           NO_CMAKE_FIND_ROOT_PATH]</span><br><span class=\"line\">         )</span><br></pre></td></tr></table></figure><br> <code>&lt;VAR&gt;</code>  <code>&lt;VAR&gt;-NOTFOUND</code> <code>name1</code>  <code>PATHS</code> <code>PATH-SUFFIXES</code>  <code>NO_DEFAULT_PATH</code> </p>\n<ol>\n<li><p> cmake  <code>-DVAR=value</code> <code>NO_CMAKE_PATH</code> cmake </p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>  <code>&lt;prefix&gt;/lib</code>  <code>&lt;prefix&gt;</code>  <code>CMAKE_PREFIX_PATH</code> </li>\n<li> <code>CMAKE_LIBRARY_PATH</code> </li>\n<li> <code>CMAKE_FRAMEWORD_PATH</code> </li>\n</ul>\n</li>\n<li><p> cmake  shell  <code>~/.bashrc</code> <code>NO_CMAKE_ENVIRONMENT_PATH</code></p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>  <code>&lt;prefix&gt;/lib</code>  <code>&lt;prefix&gt;</code>  <code>CMAKE_PREFIX_PATH</code> </li>\n<li> <code>CMAKE_LIBRARY_PATH</code> </li>\n<li> <code>CMAKE_FRAMEWORD_PATH</code> </li>\n</ul>\n</li>\n<li><p> <code>HINTS</code> </p>\n</li>\n<li><p> <code>NO_SYSTEM_ENVIRONMENT_PATH</code></p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code> <code>PATH</code>  <code>&lt;prefix&gt;/[s]bin</code> <code>&lt;prefix&gt;/lib</code> <code>&lt;prefix&gt;</code>  <code>&lt;prefix&gt;/lib</code> <code>&lt;prefix&gt;</code></li>\n</ul>\n</li>\n<li><p> cmake  <code>NO_CMAKE_SYSTEM_PATH</code></p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>  <code>&lt;prefix&gt;/lib</code>  <code>&lt;prefix&gt;</code>  <code>CMAKE_SYSTEM_PREFIX_PATH</code> </li>\n<li> <code>CMAKE_SYSTEM_LIBRARY_PATH</code> </li>\n<li> <code>CMAKE_SYSTEM_FRAMEWORD_PATH</code> </li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>cmake <br>","more":"</p>\n<h1 id=\"find-package\"><a href=\"#find-package\" class=\"headerlink\" title=\"find_package\"></a>find_package</h1><ol>\n<li>CMake </li>\n</ol>\n<p>cmakeModule<code>path_to_your_cmake/share/cmake-&lt;version&gt;/Modules</code><code>Find&lt;LibaryName&gt;.cmake</code>find_package<a href=\"https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html\">Find Modules</a></p>\n<p> <code>CURL</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(CURL)</span><br></pre></td></tr></table></figure></p>\n<p> -</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;LibaryName&gt;_FOUND</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;LibaryName&gt;_INCLUDE_DIR or &lt;LibaryName&gt;_INCLUDES &lt;LibaryName&gt;_LIBRARY or &lt;LibaryName&gt;_LIBRARIES</span><br></pre></td></tr></table></figure>\n<ol>\n<li> cmake </li>\n</ol>\n<p> <code>glog</code>cmake  Module  <code>FindGlog.cmake</code> glog </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># clone</span><br><span class=\"line\">git clone https://github.com/google/glog.git </span><br><span class=\"line\">#  </span><br><span class=\"line\">cd glog</span><br><span class=\"line\">git checkout v0.40  </span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">cmake -H. -Bbuild -G &quot;Unix Makefiles&quot;</span><br><span class=\"line\">cmake --build build</span><br><span class=\"line\">cmake --build build --target install</span><br></pre></td></tr></table></figure>\n<p>curlglog<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(GLOG)</span><br><span class=\"line\">add_executable(glogtest glogtest.cc)</span><br><span class=\"line\">if(GLOG_FOUND)</span><br><span class=\"line\">    # glogtarget_include_directories</span><br><span class=\"line\">    target_link_libraries(glogtest glog::glog)</span><br><span class=\"line\">else(GLOG_FOUND)</span><br><span class=\"line\">    message(FATAL_ERROR GLOG library not found)</span><br><span class=\"line\">endif(GLOG_FOUND)</span><br></pre></td></tr></table></figure></p>\n<p>find_package </p>\n<h2 id=\"Module-\"><a href=\"#Module-\" class=\"headerlink\" title=\"Module \"></a>Module </h2><p> curl cmake  <code>Find&lt;LibraryName&gt;.cmake</code>  <code>.cmake</code>  <code>share/cmake-&lt;version&gt;/Modules</code>  <code>CMAKE_MODULE_PATH</code> </p>\n<p> Module  <code>.cmake</code>  Config </p>\n<h2 id=\"Config-\"><a href=\"#Config-\" class=\"headerlink\" title=\"Config \"></a>Config </h2><p> <code>&lt;LibraryName&gt;Config.cmake</code>  <code>&lt;lower-case-package-name&gt;-config.cmake</code>  <a href=\"/2021/06/03/cpp/cmake_im_ex\">cmake </a></p>\n<h1 id=\"find-library\"><a href=\"#find-library\" class=\"headerlink\" title=\"find_library\"></a>find_library</h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_library (&lt;VAR&gt; name1 [path1 path2 ...])</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_library (</span><br><span class=\"line\">          &lt;VAR&gt;</span><br><span class=\"line\">          name | NAMES name1 [name2 ...] [NAMES_PER_DIR]</span><br><span class=\"line\">          [HINTS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATHS path1 [path2 ... ENV var]]</span><br><span class=\"line\">          [PATH_SUFFIXES suffix1 [suffix2 ...]]</span><br><span class=\"line\">          [DOC &quot;cache documentation string&quot;]</span><br><span class=\"line\">          [NO_DEFAULT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_PATH]</span><br><span class=\"line\">          [NO_SYSTEM_ENVIRONMENT_PATH]</span><br><span class=\"line\">          [NO_CMAKE_SYSTEM_PATH]</span><br><span class=\"line\">          [CMAKE_FIND_ROOT_PATH_BOTH |</span><br><span class=\"line\">           ONLY_CMAKE_FIND_ROOT_PATH |</span><br><span class=\"line\">           NO_CMAKE_FIND_ROOT_PATH]</span><br><span class=\"line\">         )</span><br></pre></td></tr></table></figure><br> <code>&lt;VAR&gt;</code>  <code>&lt;VAR&gt;-NOTFOUND</code> <code>name1</code>  <code>PATHS</code> <code>PATH-SUFFIXES</code>  <code>NO_DEFAULT_PATH</code> </p>\n<ol>\n<li><p> cmake  <code>-DVAR=value</code> <code>NO_CMAKE_PATH</code> cmake </p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>  <code>&lt;prefix&gt;/lib</code>  <code>&lt;prefix&gt;</code>  <code>CMAKE_PREFIX_PATH</code> </li>\n<li> <code>CMAKE_LIBRARY_PATH</code> </li>\n<li> <code>CMAKE_FRAMEWORD_PATH</code> </li>\n</ul>\n</li>\n<li><p> cmake  shell  <code>~/.bashrc</code> <code>NO_CMAKE_ENVIRONMENT_PATH</code></p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>  <code>&lt;prefix&gt;/lib</code>  <code>&lt;prefix&gt;</code>  <code>CMAKE_PREFIX_PATH</code> </li>\n<li> <code>CMAKE_LIBRARY_PATH</code> </li>\n<li> <code>CMAKE_FRAMEWORD_PATH</code> </li>\n</ul>\n</li>\n<li><p> <code>HINTS</code> </p>\n</li>\n<li><p> <code>NO_SYSTEM_ENVIRONMENT_PATH</code></p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code> <code>PATH</code>  <code>&lt;prefix&gt;/[s]bin</code> <code>&lt;prefix&gt;/lib</code> <code>&lt;prefix&gt;</code>  <code>&lt;prefix&gt;/lib</code> <code>&lt;prefix&gt;</code></li>\n</ul>\n</li>\n<li><p> cmake  <code>NO_CMAKE_SYSTEM_PATH</code></p>\n<ul>\n<li> <code>CMAKE_LIBRARY_ARCHITECTURE</code> <code>&lt;prefix&gt;/lib/&lt;arch&gt;</code>  <code>&lt;prefix&gt;/lib</code>  <code>&lt;prefix&gt;</code>  <code>CMAKE_SYSTEM_PREFIX_PATH</code> </li>\n<li> <code>CMAKE_SYSTEM_LIBRARY_PATH</code> </li>\n<li> <code>CMAKE_SYSTEM_FRAMEWORD_PATH</code> </li>\n</ul>\n</li>\n</ol>"},{"title":"cmake import export","date":"2021-06-03T05:59:06.000Z","_content":"\ncmake \n<!-- more -->\n\n# \n cmake  `add_executable()`  `add_library()`  `IMPORTED` `IMPORTED` cmake  scope  `GLOBAL`  cmake \n```\nadd_executable(<name> IMPORTED [GLOBAL])\n```\n## \n cmake  Help/guide/importing-exporting \n\n\n```shell\n$ cd Help/guide/importing-exporting/MyExe\n$ mkdir build\n$ cd build\n$ cmake ..\n$ cmake --build .\n$ cmake --install . --prefix <install location>\n$ <install location>/myexe\n$ ls\n[...] main.cc [...]\n```\n CMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(MyExe)\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# Add executable\nadd_executable(myexe main.cxx)\n\n# install executable\ninstall(TARGETS myexe)\n```\n\n```\nMyExe/\n    CMakeLists.txt\n    main.cxx\n```\nmain.cxx  main  main.cc \n\n `myexe`  Help/guide/importing-exporting/Importing CMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(Importing)\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# Add executable\nadd_executable(myexe IMPORTED)\n\n# Set imported location\nset_property(TARGET myexe PROPERTY\n             IMPORTED_LOCATION \"../InstallMyExe/bin/myexe\")\n\n# Add custom command to create source file\nadd_custom_command(OUTPUT main.cc COMMAND myexe)\n\n# Use source file\nadd_executable(mynewexe main.cc)\n```\n\n`myexe`  `IMPORTED`  CMAKE  `IMPORTED_LOCATION`\n\n```\nadd_custom_command(OUTPUT main.cc COMMAND myexe)\n```\n `myexe` `main.cc`  cmake \n```\nadd_executable(mynewexe main.cc)\n```\n `main.cc`\n\n## \n\n```\nadd_library(foo STATIC IMPORTED)\nset_property(TARGET foo PROPERTY\n             IMPORTED_LOCATION \"path/to/libfoo.a\")\n```\n\n\n\n```\nadd_executable(myexe src1.c src2.c)\ntarget_link_libraries(myexe PRIVATE foo)\n```\n\n# \n cmake cmake  CMake  .cmake\n\n cmake  Help/guide/importing-exporting/MathFunctions  `MathFunctions.h` \n```cpp\n#pragma once\nnamespace MathFunctions {\ndouble sqrt(double x);\n}\n```\n `MathFunctions.cxx` \n```cpp\n#include \"MathFunctions.h\"\n#include <cmath>\nnamespace MathFunctions {\ndouble sqrt(double x) {\n    return std::sqrt(x);\n}\n}\n```\nCMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(MathFunctions)\n\n# make cache variables for install destinations\ninclude(GNUInstallDirs)\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# create library\nadd_library(MathFunctions STATIC MathFunctions.cxx)\n\n# add include directories\ntarget_include_directories(MathFunctions\n                           PUBLIC\n                           \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}>\"\n                           \"$<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>\"\n)\n\n# install the target and create export-set\ninstall(TARGETS MathFunctions\n        EXPORT MathFunctionsTargets\n        LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n        ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n        RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n        INCLUDES DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}\n)\n\n# install header file\ninstall(FILES MathFunctions.h DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\n# generate and install export file\ninstall(EXPORT MathFunctionsTargets\n        FILE MathFunctionsTargets.cmake\n        NAMESPACE MathFunctions::\n        DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n\n# include CMakePackageConfigHelpers macro\ninclude(CMakePackageConfigHelpers)\n\n# set version\nset(version 3.4.1)\n\nset_property(TARGET MathFunctions PROPERTY VERSION ${version})\nset_property(TARGET MathFunctions PROPERTY SOVERSION 3)\nset_property(TARGET MathFunctions PROPERTY\n  INTERFACE_MathFunctions_MAJOR_VERSION 3)\nset_property(TARGET MathFunctions APPEND PROPERTY\n  COMPATIBLE_INTERFACE_STRING MathFunctions_MAJOR_VERSION\n)\n\n# generate the version file for the config file\nwrite_basic_package_version_file(\n  \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfigVersion.cmake\"\n  VERSION \"${version}\"\n  COMPATIBILITY AnyNewerVersion\n)\n\n# create config file\nconfigure_package_config_file(${CMAKE_CURRENT_SOURCE_DIR}/Config.cmake.in\n  \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\"\n  INSTALL_DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n\n# install config files\ninstall(FILES\n          \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\"\n          \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfigVersion.cmake\"\n        DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n\n# generate the export targets for the build tree\nexport(EXPORT MathFunctionsTargets\n       FILE \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsTargets.cmake\"\n       NAMESPACE MathFunctions::\n)\n```\n\n `MathFunctions`  CMake \n\n`install(TARGETS)`  `install(EXPORT)`  .cmake  .cmake  CMake .cmake\n```cmake\n# Create imported target MathFunctions::MathFunctions\nadd_library(MathFunctions::MathFunctions STATIC IMPORTED)\n\nset_target_properties(MathFunctions::MathFunctions PROPERTIES\n  INTERFACE_INCLUDE_DIRECTORIES \"${_IMPORT_PREFIX}/include\"\n)\n```\n cmake  include  .cmake  `MathFunctions`\n```cmake\ninclude(${INSTALL_PREFIX}/lib/cmake/MathFunctionTargets.cmake)\nadd_executable(myexe src1.c src2.c )\ntarget_link_libraries(myexe PRIVATE MathFunctions::MathFunctions)\n```\n \n`include(${INSTALL_PREFIX}/lib/cmake/MathFunctions/MathFunctionTargets.cmake)`\n\n\n\n `install(EXPORT)` __ scope __  `myproj-targets`\n```cmake\n# A/CMakeLists.txt\nadd_executable(myexe src1.c)\ninstall(TARGETS myexe DESTINATION lib/myproj\n        EXPORT myproj-targets)\n\n# B/CMakeLists.txt\nadd_library(foo STATIC foo1.c)\ninstall(TARGETS foo DESTINATION lib EXPORTS myproj-targets)\n\n# Top CMakeLists.txt\nadd_subdirectory (A)\nadd_subdirectory (B)\ninstall(EXPORT myproj-targets DESTINATION lib/myproj)\n```\n\n## \n `find_package()` \n\n1. include `CMakePackageConfigHelpers` \n\n### \n `CMakePackageConfigHelpers`  `configure_package_config_file()` \n```\nconfigure_package_config_file(${CMAKE_CURRENT_SOURCE_DIR}/Config.cmake.in\n  \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\"\n  INSTALL_DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n```\n`INSTALL_DESTINATION`  `MathFunctionsConfig.cmake` \n\n`configure_package_config_file`  `<PackageName>Config.cmake`  `<PackageName>-Config.cmake`\n```\nconfigure_package_config_file(<input> <output>\n  INSTALL_DESTINATION <path>\n  [PATH_VARS <var1> <var2> ... <varN>]\n  [NO_SET_AND_CHECK_MACRO]\n  [NO_CHECK_REQUIRED_COMPONENTS_MACRO]\n  [INSTALL_PREFIX <path>]\n  )\n```\n`INSTALL_DESTINATION`  `INSTALL_PREFIX` @@ `MathFunctionsTargets.cmake` \n\n## \n\n `write_basic_package_version_file()`  CMAKE  `find_package`  CMAKE \n\n\n## \n\n `export()`  CMakeLists.txt  `MathFunctionsTargets.cmake` `lib/cmake/MathFunctions/MathFunctionsTargets.cmake`  `MathFunctions`  hardcode  `${_IMPORT_PREFIX}`","source":"_posts/cpp/cmake_im_ex.md","raw":"---\ntitle: cmake import export\ndate: 2021-06-03 13:59:06\ntags:\n---\n\ncmake \n<!-- more -->\n\n# \n cmake  `add_executable()`  `add_library()`  `IMPORTED` `IMPORTED` cmake  scope  `GLOBAL`  cmake \n```\nadd_executable(<name> IMPORTED [GLOBAL])\n```\n## \n cmake  Help/guide/importing-exporting \n\n\n```shell\n$ cd Help/guide/importing-exporting/MyExe\n$ mkdir build\n$ cd build\n$ cmake ..\n$ cmake --build .\n$ cmake --install . --prefix <install location>\n$ <install location>/myexe\n$ ls\n[...] main.cc [...]\n```\n CMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(MyExe)\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# Add executable\nadd_executable(myexe main.cxx)\n\n# install executable\ninstall(TARGETS myexe)\n```\n\n```\nMyExe/\n    CMakeLists.txt\n    main.cxx\n```\nmain.cxx  main  main.cc \n\n `myexe`  Help/guide/importing-exporting/Importing CMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(Importing)\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# Add executable\nadd_executable(myexe IMPORTED)\n\n# Set imported location\nset_property(TARGET myexe PROPERTY\n             IMPORTED_LOCATION \"../InstallMyExe/bin/myexe\")\n\n# Add custom command to create source file\nadd_custom_command(OUTPUT main.cc COMMAND myexe)\n\n# Use source file\nadd_executable(mynewexe main.cc)\n```\n\n`myexe`  `IMPORTED`  CMAKE  `IMPORTED_LOCATION`\n\n```\nadd_custom_command(OUTPUT main.cc COMMAND myexe)\n```\n `myexe` `main.cc`  cmake \n```\nadd_executable(mynewexe main.cc)\n```\n `main.cc`\n\n## \n\n```\nadd_library(foo STATIC IMPORTED)\nset_property(TARGET foo PROPERTY\n             IMPORTED_LOCATION \"path/to/libfoo.a\")\n```\n\n\n\n```\nadd_executable(myexe src1.c src2.c)\ntarget_link_libraries(myexe PRIVATE foo)\n```\n\n# \n cmake cmake  CMake  .cmake\n\n cmake  Help/guide/importing-exporting/MathFunctions  `MathFunctions.h` \n```cpp\n#pragma once\nnamespace MathFunctions {\ndouble sqrt(double x);\n}\n```\n `MathFunctions.cxx` \n```cpp\n#include \"MathFunctions.h\"\n#include <cmath>\nnamespace MathFunctions {\ndouble sqrt(double x) {\n    return std::sqrt(x);\n}\n}\n```\nCMakeLists.txt \n```cmake\ncmake_minimum_required(VERSION 3.15)\nproject(MathFunctions)\n\n# make cache variables for install destinations\ninclude(GNUInstallDirs)\n\n# specify the C++ standard\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED True)\n\n# create library\nadd_library(MathFunctions STATIC MathFunctions.cxx)\n\n# add include directories\ntarget_include_directories(MathFunctions\n                           PUBLIC\n                           \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}>\"\n                           \"$<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>\"\n)\n\n# install the target and create export-set\ninstall(TARGETS MathFunctions\n        EXPORT MathFunctionsTargets\n        LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n        ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n        RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n        INCLUDES DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}\n)\n\n# install header file\ninstall(FILES MathFunctions.h DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\n# generate and install export file\ninstall(EXPORT MathFunctionsTargets\n        FILE MathFunctionsTargets.cmake\n        NAMESPACE MathFunctions::\n        DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n\n# include CMakePackageConfigHelpers macro\ninclude(CMakePackageConfigHelpers)\n\n# set version\nset(version 3.4.1)\n\nset_property(TARGET MathFunctions PROPERTY VERSION ${version})\nset_property(TARGET MathFunctions PROPERTY SOVERSION 3)\nset_property(TARGET MathFunctions PROPERTY\n  INTERFACE_MathFunctions_MAJOR_VERSION 3)\nset_property(TARGET MathFunctions APPEND PROPERTY\n  COMPATIBLE_INTERFACE_STRING MathFunctions_MAJOR_VERSION\n)\n\n# generate the version file for the config file\nwrite_basic_package_version_file(\n  \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfigVersion.cmake\"\n  VERSION \"${version}\"\n  COMPATIBILITY AnyNewerVersion\n)\n\n# create config file\nconfigure_package_config_file(${CMAKE_CURRENT_SOURCE_DIR}/Config.cmake.in\n  \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\"\n  INSTALL_DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n\n# install config files\ninstall(FILES\n          \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\"\n          \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfigVersion.cmake\"\n        DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n\n# generate the export targets for the build tree\nexport(EXPORT MathFunctionsTargets\n       FILE \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsTargets.cmake\"\n       NAMESPACE MathFunctions::\n)\n```\n\n `MathFunctions`  CMake \n\n`install(TARGETS)`  `install(EXPORT)`  .cmake  .cmake  CMake .cmake\n```cmake\n# Create imported target MathFunctions::MathFunctions\nadd_library(MathFunctions::MathFunctions STATIC IMPORTED)\n\nset_target_properties(MathFunctions::MathFunctions PROPERTIES\n  INTERFACE_INCLUDE_DIRECTORIES \"${_IMPORT_PREFIX}/include\"\n)\n```\n cmake  include  .cmake  `MathFunctions`\n```cmake\ninclude(${INSTALL_PREFIX}/lib/cmake/MathFunctionTargets.cmake)\nadd_executable(myexe src1.c src2.c )\ntarget_link_libraries(myexe PRIVATE MathFunctions::MathFunctions)\n```\n \n`include(${INSTALL_PREFIX}/lib/cmake/MathFunctions/MathFunctionTargets.cmake)`\n\n\n\n `install(EXPORT)` __ scope __  `myproj-targets`\n```cmake\n# A/CMakeLists.txt\nadd_executable(myexe src1.c)\ninstall(TARGETS myexe DESTINATION lib/myproj\n        EXPORT myproj-targets)\n\n# B/CMakeLists.txt\nadd_library(foo STATIC foo1.c)\ninstall(TARGETS foo DESTINATION lib EXPORTS myproj-targets)\n\n# Top CMakeLists.txt\nadd_subdirectory (A)\nadd_subdirectory (B)\ninstall(EXPORT myproj-targets DESTINATION lib/myproj)\n```\n\n## \n `find_package()` \n\n1. include `CMakePackageConfigHelpers` \n\n### \n `CMakePackageConfigHelpers`  `configure_package_config_file()` \n```\nconfigure_package_config_file(${CMAKE_CURRENT_SOURCE_DIR}/Config.cmake.in\n  \"${CMAKE_CURRENT_BINARY_DIR}/MathFunctionsConfig.cmake\"\n  INSTALL_DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/MathFunctions\n)\n```\n`INSTALL_DESTINATION`  `MathFunctionsConfig.cmake` \n\n`configure_package_config_file`  `<PackageName>Config.cmake`  `<PackageName>-Config.cmake`\n```\nconfigure_package_config_file(<input> <output>\n  INSTALL_DESTINATION <path>\n  [PATH_VARS <var1> <var2> ... <varN>]\n  [NO_SET_AND_CHECK_MACRO]\n  [NO_CHECK_REQUIRED_COMPONENTS_MACRO]\n  [INSTALL_PREFIX <path>]\n  )\n```\n`INSTALL_DESTINATION`  `INSTALL_PREFIX` @@ `MathFunctionsTargets.cmake` \n\n## \n\n `write_basic_package_version_file()`  CMAKE  `find_package`  CMAKE \n\n\n## \n\n `export()`  CMakeLists.txt  `MathFunctionsTargets.cmake` `lib/cmake/MathFunctions/MathFunctionsTargets.cmake`  `MathFunctions`  hardcode  `${_IMPORT_PREFIX}`","slug":"cpp/cmake_im_ex","published":1,"updated":"2021-09-15T02:08:47.772Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90m001ip0dj6f9g2e5i","content":"<p>cmake <br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> cmake  <code>add_executable()</code>  <code>add_library()</code>  <code>IMPORTED</code> <code>IMPORTED</code> cmake  scope  <code>GLOBAL</code>  cmake <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(&lt;name&gt; IMPORTED [GLOBAL])</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> cmake  Help/guide/importing-exporting </p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> Help/guide/importing-exporting/MyExe</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> mkdir build</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> build</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake ..</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake --build .</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake --install . --prefix &lt;install location&gt;</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> &lt;install location&gt;/myexe</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">[...] main.cc [...]</span><br></pre></td></tr></table></figure><br> CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(MyExe)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># specify the C++ standard</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD <span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add executable</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe main.cxx)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install executable</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS myexe)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MyExe/</span><br><span class=\"line\">    CMakeLists.txt</span><br><span class=\"line\">    main.cxx</span><br></pre></td></tr></table></figure><br>main.cxx  main  main.cc </p>\n<p> <code>myexe</code>  Help/guide/importing-exporting/Importing CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(Importing)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># specify the C++ standard</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD <span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add executable</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe IMPORTED)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set imported location</span></span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> myexe PROPERTY</span><br><span class=\"line\">             IMPORTED_LOCATION <span class=\"string\">&quot;../InstallMyExe/bin/myexe&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add custom command to create source file</span></span><br><span class=\"line\"><span class=\"keyword\">add_custom_command</span>(OUTPUT main.cc <span class=\"keyword\">COMMAND</span> myexe)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use source file</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(mynewexe main.cc)</span><br></pre></td></tr></table></figure></p>\n<p><code>myexe</code>  <code>IMPORTED</code>  CMAKE  <code>IMPORTED_LOCATION</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_custom_command(OUTPUT main.cc COMMAND myexe)</span><br></pre></td></tr></table></figure>\n<p> <code>myexe</code> <code>main.cc</code>  cmake <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(mynewexe main.cc)</span><br></pre></td></tr></table></figure><br> <code>main.cc</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(foo STATIC IMPORTED)</span><br><span class=\"line\">set_property(TARGET foo PROPERTY</span><br><span class=\"line\">             IMPORTED_LOCATION &quot;path/to/libfoo.a&quot;)</span><br></pre></td></tr></table></figure><br></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(myexe src1.c src2.c)</span><br><span class=\"line\">target_link_libraries(myexe PRIVATE foo)</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> cmake cmake  CMake  .cmake</p>\n<p> cmake  Help/guide/importing-exporting/MathFunctions  <code>MathFunctions.h</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> once</span></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> MathFunctions &#123;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">sqrt</span><span class=\"params\">(<span class=\"keyword\">double</span> x)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>MathFunctions.cxx</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;MathFunctions.h&quot;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> MathFunctions &#123;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">sqrt</span><span class=\"params\">(<span class=\"keyword\">double</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> std::<span class=\"built_in\">sqrt</span>(x);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(MathFunctions)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># make cache variables for install destinations</span></span><br><span class=\"line\"><span class=\"keyword\">include</span>(GNUInstallDirs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># specify the C++ standard</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD <span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create library</span></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(MathFunctions STATIC MathFunctions.cxx)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># add include directories</span></span><br><span class=\"line\"><span class=\"keyword\">target_include_directories</span>(MathFunctions</span><br><span class=\"line\">                           PUBLIC</span><br><span class=\"line\">                           <span class=\"string\">&quot;$&lt;BUILD_INTERFACE:$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&gt;&quot;</span></span><br><span class=\"line\">                           <span class=\"string\">&quot;$&lt;INSTALL_INTERFACE:$&#123;CMAKE_INSTALL_INCLUDEDIR&#125;&gt;&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install the target and create export-set</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS MathFunctions</span><br><span class=\"line\">        <span class=\"keyword\">EXPORT</span> MathFunctionsTargets</span><br><span class=\"line\">        LIBRARY DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span></span><br><span class=\"line\">        ARCHIVE DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span></span><br><span class=\"line\">        RUNTIME DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_BINDIR&#125;</span></span><br><span class=\"line\">        INCLUDES DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_INCLUDEDIR&#125;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install header file</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(FILES MathFunctions.h DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_INCLUDEDIR&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate and install export file</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(<span class=\"keyword\">EXPORT</span> MathFunctionsTargets</span><br><span class=\"line\">        <span class=\"keyword\">FILE</span> MathFunctionsTargets.cmake</span><br><span class=\"line\">        NAMESPACE MathFunctions::</span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>/cmake/MathFunctions</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># include CMakePackageConfigHelpers macro</span></span><br><span class=\"line\"><span class=\"keyword\">include</span>(CMakePackageConfigHelpers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set version</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(version <span class=\"number\">3.4</span>.<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions PROPERTY VERSION <span class=\"variable\">$&#123;version&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions PROPERTY SOVERSION <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions PROPERTY</span><br><span class=\"line\">  INTERFACE_MathFunctions_MAJOR_VERSION <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions APPEND PROPERTY</span><br><span class=\"line\">  COMPATIBLE_INTERFACE_STRING MathFunctions_MAJOR_VERSION</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate the version file for the config file</span></span><br><span class=\"line\">write_basic_package_version_file(</span><br><span class=\"line\">  <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfigVersion.cmake&quot;</span></span><br><span class=\"line\">  VERSION <span class=\"string\">&quot;$&#123;version&#125;&quot;</span></span><br><span class=\"line\">  COMPATIBILITY AnyNewerVersion</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create config file</span></span><br><span class=\"line\">configure_package_config_file(<span class=\"variable\">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/Config.cmake.in</span><br><span class=\"line\">  <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfig.cmake&quot;</span></span><br><span class=\"line\">  INSTALL_DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>/cmake/MathFunctions</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install config files</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(FILES</span><br><span class=\"line\">          <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfig.cmake&quot;</span></span><br><span class=\"line\">          <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfigVersion.cmake&quot;</span></span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>/cmake/MathFunctions</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate the export targets for the build tree</span></span><br><span class=\"line\"><span class=\"keyword\">export</span>(<span class=\"keyword\">EXPORT</span> MathFunctionsTargets</span><br><span class=\"line\">       <span class=\"keyword\">FILE</span> <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsTargets.cmake&quot;</span></span><br><span class=\"line\">       NAMESPACE MathFunctions::</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure></p>\n<p> <code>MathFunctions</code>  CMake </p>\n<p><code>install(TARGETS)</code>  <code>install(EXPORT)</code>  .cmake  .cmake  CMake .cmake<br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create imported target MathFunctions::MathFunctions</span></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(MathFunctions::MathFunctions STATIC IMPORTED)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">set_target_properties</span>(MathFunctions::MathFunctions PROPERTIES</span><br><span class=\"line\">  INTERFACE_INCLUDE_DIRECTORIES <span class=\"string\">&quot;$&#123;_IMPORT_PREFIX&#125;/include&quot;</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure><br> cmake  include  .cmake  <code>MathFunctions</code><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">include</span>(<span class=\"variable\">$&#123;INSTALL_PREFIX&#125;</span>/lib/cmake/MathFunctionTargets.cmake)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe src1.c src2.c )</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(myexe PRIVATE MathFunctions::MathFunctions)</span><br></pre></td></tr></table></figure><br><br><code>include($&#123;INSTALL_PREFIX&#125;/lib/cmake/MathFunctions/MathFunctionTargets.cmake)</code></p>\n<p> <code>install(EXPORT)</code> <strong> scope </strong>  <code>myproj-targets</code><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># A/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe src1.c)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS myexe DESTINATION lib/myproj</span><br><span class=\"line\">        <span class=\"keyword\">EXPORT</span> myproj-targets)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># B/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(foo STATIC foo1.c)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS foo DESTINATION lib EXPORTS myproj-targets)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Top CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span> (A)</span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span> (B)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(<span class=\"keyword\">EXPORT</span> myproj-targets DESTINATION lib/myproj)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>find_package()</code> </p>\n<ol>\n<li>include <code>CMakePackageConfigHelpers</code> </li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <code>CMakePackageConfigHelpers</code>  <code>configure_package_config_file()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure_package_config_file($&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/Config.cmake.in</span><br><span class=\"line\">  &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfig.cmake&quot;</span><br><span class=\"line\">  INSTALL_DESTINATION $&#123;CMAKE_INSTALL_LIBDIR&#125;/cmake/MathFunctions</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure><br><code>INSTALL_DESTINATION</code>  <code>MathFunctionsConfig.cmake</code> </p>\n<p><code>configure_package_config_file</code>  <code>&lt;PackageName&gt;Config.cmake</code>  <code>&lt;PackageName&gt;-Config.cmake</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure_package_config_file(&lt;input&gt; &lt;output&gt;</span><br><span class=\"line\">  INSTALL_DESTINATION &lt;path&gt;</span><br><span class=\"line\">  [PATH_VARS &lt;var1&gt; &lt;var2&gt; ... &lt;varN&gt;]</span><br><span class=\"line\">  [NO_SET_AND_CHECK_MACRO]</span><br><span class=\"line\">  [NO_CHECK_REQUIRED_COMPONENTS_MACRO]</span><br><span class=\"line\">  [INSTALL_PREFIX &lt;path&gt;]</span><br><span class=\"line\">  )</span><br></pre></td></tr></table></figure><br><code>INSTALL_DESTINATION</code>  <code>INSTALL_PREFIX</code> @@ <code>MathFunctionsTargets.cmake</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>write_basic_package_version_file()</code>  CMAKE  <code>find_package</code>  CMAKE </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>export()</code>  CMakeLists.txt  <code>MathFunctionsTargets.cmake</code> <code>lib/cmake/MathFunctions/MathFunctionsTargets.cmake</code>  <code>MathFunctions</code>  hardcode  <code>$&#123;_IMPORT_PREFIX&#125;</code></p>\n","site":{"data":{}},"excerpt":"<p>cmake <br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> cmake  <code>add_executable()</code>  <code>add_library()</code>  <code>IMPORTED</code> <code>IMPORTED</code> cmake  scope  <code>GLOBAL</code>  cmake <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(&lt;name&gt; IMPORTED [GLOBAL])</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> cmake  Help/guide/importing-exporting </p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> Help/guide/importing-exporting/MyExe</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> mkdir build</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> build</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake ..</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake --build .</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> cmake --install . --prefix &lt;install location&gt;</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> &lt;install location&gt;/myexe</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">[...] main.cc [...]</span><br></pre></td></tr></table></figure><br> CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(MyExe)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># specify the C++ standard</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD <span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add executable</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe main.cxx)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install executable</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS myexe)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MyExe/</span><br><span class=\"line\">    CMakeLists.txt</span><br><span class=\"line\">    main.cxx</span><br></pre></td></tr></table></figure><br>main.cxx  main  main.cc </p>\n<p> <code>myexe</code>  Help/guide/importing-exporting/Importing CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(Importing)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># specify the C++ standard</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD <span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add executable</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe IMPORTED)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set imported location</span></span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> myexe PROPERTY</span><br><span class=\"line\">             IMPORTED_LOCATION <span class=\"string\">&quot;../InstallMyExe/bin/myexe&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add custom command to create source file</span></span><br><span class=\"line\"><span class=\"keyword\">add_custom_command</span>(OUTPUT main.cc <span class=\"keyword\">COMMAND</span> myexe)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use source file</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(mynewexe main.cc)</span><br></pre></td></tr></table></figure></p>\n<p><code>myexe</code>  <code>IMPORTED</code>  CMAKE  <code>IMPORTED_LOCATION</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_custom_command(OUTPUT main.cc COMMAND myexe)</span><br></pre></td></tr></table></figure>\n<p> <code>myexe</code> <code>main.cc</code>  cmake <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(mynewexe main.cc)</span><br></pre></td></tr></table></figure><br> <code>main.cc</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(foo STATIC IMPORTED)</span><br><span class=\"line\">set_property(TARGET foo PROPERTY</span><br><span class=\"line\">             IMPORTED_LOCATION &quot;path/to/libfoo.a&quot;)</span><br></pre></td></tr></table></figure><br></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_executable(myexe src1.c src2.c)</span><br><span class=\"line\">target_link_libraries(myexe PRIVATE foo)</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> cmake cmake  CMake  .cmake</p>\n<p> cmake  Help/guide/importing-exporting/MathFunctions  <code>MathFunctions.h</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">pragma</span> once</span></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> MathFunctions &#123;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">sqrt</span><span class=\"params\">(<span class=\"keyword\">double</span> x)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>MathFunctions.cxx</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&quot;MathFunctions.h&quot;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cmath&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> MathFunctions &#123;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">double</span> <span class=\"title\">sqrt</span><span class=\"params\">(<span class=\"keyword\">double</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> std::<span class=\"built_in\">sqrt</span>(x);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>CMakeLists.txt <br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span>(VERSION <span class=\"number\">3.15</span>)</span><br><span class=\"line\"><span class=\"keyword\">project</span>(MathFunctions)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># make cache variables for install destinations</span></span><br><span class=\"line\"><span class=\"keyword\">include</span>(GNUInstallDirs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># specify the C++ standard</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD <span class=\"number\">11</span>)</span><br><span class=\"line\"><span class=\"keyword\">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create library</span></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(MathFunctions STATIC MathFunctions.cxx)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># add include directories</span></span><br><span class=\"line\"><span class=\"keyword\">target_include_directories</span>(MathFunctions</span><br><span class=\"line\">                           PUBLIC</span><br><span class=\"line\">                           <span class=\"string\">&quot;$&lt;BUILD_INTERFACE:$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&gt;&quot;</span></span><br><span class=\"line\">                           <span class=\"string\">&quot;$&lt;INSTALL_INTERFACE:$&#123;CMAKE_INSTALL_INCLUDEDIR&#125;&gt;&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install the target and create export-set</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS MathFunctions</span><br><span class=\"line\">        <span class=\"keyword\">EXPORT</span> MathFunctionsTargets</span><br><span class=\"line\">        LIBRARY DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span></span><br><span class=\"line\">        ARCHIVE DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span></span><br><span class=\"line\">        RUNTIME DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_BINDIR&#125;</span></span><br><span class=\"line\">        INCLUDES DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_INCLUDEDIR&#125;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install header file</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(FILES MathFunctions.h DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_INCLUDEDIR&#125;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate and install export file</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(<span class=\"keyword\">EXPORT</span> MathFunctionsTargets</span><br><span class=\"line\">        <span class=\"keyword\">FILE</span> MathFunctionsTargets.cmake</span><br><span class=\"line\">        NAMESPACE MathFunctions::</span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>/cmake/MathFunctions</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># include CMakePackageConfigHelpers macro</span></span><br><span class=\"line\"><span class=\"keyword\">include</span>(CMakePackageConfigHelpers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set version</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(version <span class=\"number\">3.4</span>.<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions PROPERTY VERSION <span class=\"variable\">$&#123;version&#125;</span>)</span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions PROPERTY SOVERSION <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions PROPERTY</span><br><span class=\"line\">  INTERFACE_MathFunctions_MAJOR_VERSION <span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"keyword\">set_property</span>(<span class=\"keyword\">TARGET</span> MathFunctions APPEND PROPERTY</span><br><span class=\"line\">  COMPATIBLE_INTERFACE_STRING MathFunctions_MAJOR_VERSION</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate the version file for the config file</span></span><br><span class=\"line\">write_basic_package_version_file(</span><br><span class=\"line\">  <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfigVersion.cmake&quot;</span></span><br><span class=\"line\">  VERSION <span class=\"string\">&quot;$&#123;version&#125;&quot;</span></span><br><span class=\"line\">  COMPATIBILITY AnyNewerVersion</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create config file</span></span><br><span class=\"line\">configure_package_config_file(<span class=\"variable\">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/Config.cmake.in</span><br><span class=\"line\">  <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfig.cmake&quot;</span></span><br><span class=\"line\">  INSTALL_DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>/cmake/MathFunctions</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install config files</span></span><br><span class=\"line\"><span class=\"keyword\">install</span>(FILES</span><br><span class=\"line\">          <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfig.cmake&quot;</span></span><br><span class=\"line\">          <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfigVersion.cmake&quot;</span></span><br><span class=\"line\">        DESTINATION <span class=\"variable\">$&#123;CMAKE_INSTALL_LIBDIR&#125;</span>/cmake/MathFunctions</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate the export targets for the build tree</span></span><br><span class=\"line\"><span class=\"keyword\">export</span>(<span class=\"keyword\">EXPORT</span> MathFunctionsTargets</span><br><span class=\"line\">       <span class=\"keyword\">FILE</span> <span class=\"string\">&quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsTargets.cmake&quot;</span></span><br><span class=\"line\">       NAMESPACE MathFunctions::</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure></p>\n<p> <code>MathFunctions</code>  CMake </p>\n<p><code>install(TARGETS)</code>  <code>install(EXPORT)</code>  .cmake  .cmake  CMake .cmake<br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create imported target MathFunctions::MathFunctions</span></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(MathFunctions::MathFunctions STATIC IMPORTED)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">set_target_properties</span>(MathFunctions::MathFunctions PROPERTIES</span><br><span class=\"line\">  INTERFACE_INCLUDE_DIRECTORIES <span class=\"string\">&quot;$&#123;_IMPORT_PREFIX&#125;/include&quot;</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure><br> cmake  include  .cmake  <code>MathFunctions</code><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">include</span>(<span class=\"variable\">$&#123;INSTALL_PREFIX&#125;</span>/lib/cmake/MathFunctionTargets.cmake)</span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe src1.c src2.c )</span><br><span class=\"line\"><span class=\"keyword\">target_link_libraries</span>(myexe PRIVATE MathFunctions::MathFunctions)</span><br></pre></td></tr></table></figure><br><br><code>include($&#123;INSTALL_PREFIX&#125;/lib/cmake/MathFunctions/MathFunctionTargets.cmake)</code></p>\n<p> <code>install(EXPORT)</code> <strong> scope </strong>  <code>myproj-targets</code><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># A/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span>(myexe src1.c)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS myexe DESTINATION lib/myproj</span><br><span class=\"line\">        <span class=\"keyword\">EXPORT</span> myproj-targets)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># B/CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">add_library</span>(foo STATIC foo1.c)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(TARGETS foo DESTINATION lib EXPORTS myproj-targets)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Top CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span> (A)</span><br><span class=\"line\"><span class=\"keyword\">add_subdirectory</span> (B)</span><br><span class=\"line\"><span class=\"keyword\">install</span>(<span class=\"keyword\">EXPORT</span> myproj-targets DESTINATION lib/myproj)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>find_package()</code> </p>\n<ol>\n<li>include <code>CMakePackageConfigHelpers</code> </li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <code>CMakePackageConfigHelpers</code>  <code>configure_package_config_file()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure_package_config_file($&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/Config.cmake.in</span><br><span class=\"line\">  &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/MathFunctionsConfig.cmake&quot;</span><br><span class=\"line\">  INSTALL_DESTINATION $&#123;CMAKE_INSTALL_LIBDIR&#125;/cmake/MathFunctions</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure><br><code>INSTALL_DESTINATION</code>  <code>MathFunctionsConfig.cmake</code> </p>\n<p><code>configure_package_config_file</code>  <code>&lt;PackageName&gt;Config.cmake</code>  <code>&lt;PackageName&gt;-Config.cmake</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">configure_package_config_file(&lt;input&gt; &lt;output&gt;</span><br><span class=\"line\">  INSTALL_DESTINATION &lt;path&gt;</span><br><span class=\"line\">  [PATH_VARS &lt;var1&gt; &lt;var2&gt; ... &lt;varN&gt;]</span><br><span class=\"line\">  [NO_SET_AND_CHECK_MACRO]</span><br><span class=\"line\">  [NO_CHECK_REQUIRED_COMPONENTS_MACRO]</span><br><span class=\"line\">  [INSTALL_PREFIX &lt;path&gt;]</span><br><span class=\"line\">  )</span><br></pre></td></tr></table></figure><br><code>INSTALL_DESTINATION</code>  <code>INSTALL_PREFIX</code> @@ <code>MathFunctionsTargets.cmake</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>write_basic_package_version_file()</code>  CMAKE  <code>find_package</code>  CMAKE </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>export()</code>  CMakeLists.txt  <code>MathFunctionsTargets.cmake</code> <code>lib/cmake/MathFunctions/MathFunctionsTargets.cmake</code>  <code>MathFunctions</code>  hardcode  <code>$&#123;_IMPORT_PREFIX&#125;</code></p>"},{"title":"cmake TARGET","date":"2021-06-08T09:15:50.000Z","p":"cpp/target","_content":"cmake  TARGET\n<!-- more -->\n# target_compile_definitions\n```\ntarget_compile_definitions(<target>\n  <INTERFACE|PUBLIC|PRIVATE> [items1...]\n  [<INTERFACE|PUBLIC|PRIVATE> [items2...] ...])\n```\n\n `<target>`  `<target>`  `add_executable()`  `add_library()` \n\n- PRIVATE, PUBLIC\n\n     `<target>`  `COMPILE_DEFINITIONS` append\n\n- PUBLIC, INTERFACE\n\n     `<target>`  `INTERFACE_COMPILE_DEFINITIONS` append\n\n `-D` \n```\ntarget_compile_definitions(foo PUBLIC FOO)\ntarget_compile_definitions(foo PUBLIC -DFOO)  # -D removed\ntarget_compile_definitions(foo PUBLIC \"\" FOO) # \"\" ignored\ntarget_compile_definitions(foo PUBLIC -D FOO) # -D becomes \"\", then ignored\n```\n\n# set_target_properties\n```\nset_target_properties(target1 target2 ...\n                      PROPERTIES prop1 value1\n                      prop2 value2 ...)\n```\n\n\n# target_include_directories\n```\ntarget_include_directories(<target> [SYSTEM] [AFTER|BEFORE]\n  <INTERFACE|PUBLIC|PRIVATE> [items1...]\n  [<INTERFACE|PUBLIC|PRIVATE> [items2...] ...])\n```\n\n\n- PRIVATE, PUBLIC\n\n     `INCLUDE_DIRECTORIES` \n\n- PUBLIC, INTERFACE\n\n     `INTERFACE_INCLUDE_DIRECTORIES` \n\n\n\n`target_include_directories`   `$<...>`[](https://cmake.org/cmake/help/latest/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7)) \n\n```\ntarget_include_directories(mylib PUBLIC\n  $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include/mylib>\n  $<INSTALL_INTERFACE:include/mylib>  # <prefix>/include/mylib\n)\n```\n `export()`  `${CMAKE_CURRENT_SOURCE_DIR}/include/mylib>` `install(EXPORT)`  `include/mylib>`\n\n\n\n","source":"_posts/cpp/cmake_target.md","raw":"---\ntitle: cmake TARGET\ndate: 2021-06-08 17:15:50\ntags:\np: cpp/target\n---\ncmake  TARGET\n<!-- more -->\n# target_compile_definitions\n```\ntarget_compile_definitions(<target>\n  <INTERFACE|PUBLIC|PRIVATE> [items1...]\n  [<INTERFACE|PUBLIC|PRIVATE> [items2...] ...])\n```\n\n `<target>`  `<target>`  `add_executable()`  `add_library()` \n\n- PRIVATE, PUBLIC\n\n     `<target>`  `COMPILE_DEFINITIONS` append\n\n- PUBLIC, INTERFACE\n\n     `<target>`  `INTERFACE_COMPILE_DEFINITIONS` append\n\n `-D` \n```\ntarget_compile_definitions(foo PUBLIC FOO)\ntarget_compile_definitions(foo PUBLIC -DFOO)  # -D removed\ntarget_compile_definitions(foo PUBLIC \"\" FOO) # \"\" ignored\ntarget_compile_definitions(foo PUBLIC -D FOO) # -D becomes \"\", then ignored\n```\n\n# set_target_properties\n```\nset_target_properties(target1 target2 ...\n                      PROPERTIES prop1 value1\n                      prop2 value2 ...)\n```\n\n\n# target_include_directories\n```\ntarget_include_directories(<target> [SYSTEM] [AFTER|BEFORE]\n  <INTERFACE|PUBLIC|PRIVATE> [items1...]\n  [<INTERFACE|PUBLIC|PRIVATE> [items2...] ...])\n```\n\n\n- PRIVATE, PUBLIC\n\n     `INCLUDE_DIRECTORIES` \n\n- PUBLIC, INTERFACE\n\n     `INTERFACE_INCLUDE_DIRECTORIES` \n\n\n\n`target_include_directories`   `$<...>`[](https://cmake.org/cmake/help/latest/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7)) \n\n```\ntarget_include_directories(mylib PUBLIC\n  $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include/mylib>\n  $<INSTALL_INTERFACE:include/mylib>  # <prefix>/include/mylib\n)\n```\n `export()`  `${CMAKE_CURRENT_SOURCE_DIR}/include/mylib>` `install(EXPORT)`  `include/mylib>`\n\n\n\n","slug":"cpp/cmake_target","published":1,"updated":"2021-09-15T02:09:04.213Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90n001jp0dj0anpb0nq","content":"<p>cmake  TARGET<br><span id=\"more\"></span></p>\n<h1 id=\"target-compile-definitions\"><a href=\"#target-compile-definitions\" class=\"headerlink\" title=\"target_compile_definitions\"></a>target_compile_definitions</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_definitions(&lt;target&gt;</span><br><span class=\"line\">  &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]</span><br><span class=\"line\">  [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...])</span><br></pre></td></tr></table></figure>\n<p> <code>&lt;target&gt;</code>  <code>&lt;target&gt;</code>  <code>add_executable()</code>  <code>add_library()</code> </p>\n<ul>\n<li><p>PRIVATE, PUBLIC</p>\n<p>   <code>&lt;target&gt;</code>  <code>COMPILE_DEFINITIONS</code> append</p>\n</li>\n<li><p>PUBLIC, INTERFACE</p>\n<p>   <code>&lt;target&gt;</code>  <code>INTERFACE_COMPILE_DEFINITIONS</code> append</p>\n</li>\n</ul>\n<p> <code>-D</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_definitions(foo PUBLIC FOO)</span><br><span class=\"line\">target_compile_definitions(foo PUBLIC -DFOO)  # -D removed</span><br><span class=\"line\">target_compile_definitions(foo PUBLIC &quot;&quot; FOO) # &quot;&quot; ignored</span><br><span class=\"line\">target_compile_definitions(foo PUBLIC -D FOO) # -D becomes &quot;&quot;, then ignored</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"set-target-properties\"><a href=\"#set-target-properties\" class=\"headerlink\" title=\"set_target_properties\"></a>set_target_properties</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set_target_properties(target1 target2 ...</span><br><span class=\"line\">                      PROPERTIES prop1 value1</span><br><span class=\"line\">                      prop2 value2 ...)</span><br></pre></td></tr></table></figure>\n<p></p>\n<h1 id=\"target-include-directories\"><a href=\"#target-include-directories\" class=\"headerlink\" title=\"target_include_directories\"></a>target_include_directories</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_include_directories(&lt;target&gt; [SYSTEM] [AFTER|BEFORE]</span><br><span class=\"line\">  &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]</span><br><span class=\"line\">  [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...])</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><p>PRIVATE, PUBLIC</p>\n<p>   <code>INCLUDE_DIRECTORIES</code> </p>\n</li>\n<li><p>PUBLIC, INTERFACE</p>\n<p>   <code>INTERFACE_INCLUDE_DIRECTORIES</code> </p>\n</li>\n</ul>\n<p></p>\n<p><code>target_include_directories</code>   <code>$&lt;...&gt;</code><a href=\"https://cmake.org/cmake/help/latest/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7\"></a>) </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_include_directories(mylib PUBLIC</span><br><span class=\"line\">  $&lt;BUILD_INTERFACE:$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/include/mylib&gt;</span><br><span class=\"line\">  $&lt;INSTALL_INTERFACE:include/mylib&gt;  # &lt;prefix&gt;/include/mylib</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p> <code>export()</code>  <code>$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/include/mylib&gt;</code> <code>install(EXPORT)</code>  <code>include/mylib&gt;</code></p>\n","site":{"data":{}},"excerpt":"<p>cmake  TARGET<br>","more":"</p>\n<h1 id=\"target-compile-definitions\"><a href=\"#target-compile-definitions\" class=\"headerlink\" title=\"target_compile_definitions\"></a>target_compile_definitions</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_definitions(&lt;target&gt;</span><br><span class=\"line\">  &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]</span><br><span class=\"line\">  [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...])</span><br></pre></td></tr></table></figure>\n<p> <code>&lt;target&gt;</code>  <code>&lt;target&gt;</code>  <code>add_executable()</code>  <code>add_library()</code> </p>\n<ul>\n<li><p>PRIVATE, PUBLIC</p>\n<p>   <code>&lt;target&gt;</code>  <code>COMPILE_DEFINITIONS</code> append</p>\n</li>\n<li><p>PUBLIC, INTERFACE</p>\n<p>   <code>&lt;target&gt;</code>  <code>INTERFACE_COMPILE_DEFINITIONS</code> append</p>\n</li>\n</ul>\n<p> <code>-D</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_definitions(foo PUBLIC FOO)</span><br><span class=\"line\">target_compile_definitions(foo PUBLIC -DFOO)  # -D removed</span><br><span class=\"line\">target_compile_definitions(foo PUBLIC &quot;&quot; FOO) # &quot;&quot; ignored</span><br><span class=\"line\">target_compile_definitions(foo PUBLIC -D FOO) # -D becomes &quot;&quot;, then ignored</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"set-target-properties\"><a href=\"#set-target-properties\" class=\"headerlink\" title=\"set_target_properties\"></a>set_target_properties</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set_target_properties(target1 target2 ...</span><br><span class=\"line\">                      PROPERTIES prop1 value1</span><br><span class=\"line\">                      prop2 value2 ...)</span><br></pre></td></tr></table></figure>\n<p></p>\n<h1 id=\"target-include-directories\"><a href=\"#target-include-directories\" class=\"headerlink\" title=\"target_include_directories\"></a>target_include_directories</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_include_directories(&lt;target&gt; [SYSTEM] [AFTER|BEFORE]</span><br><span class=\"line\">  &lt;INTERFACE|PUBLIC|PRIVATE&gt; [items1...]</span><br><span class=\"line\">  [&lt;INTERFACE|PUBLIC|PRIVATE&gt; [items2...] ...])</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><p>PRIVATE, PUBLIC</p>\n<p>   <code>INCLUDE_DIRECTORIES</code> </p>\n</li>\n<li><p>PUBLIC, INTERFACE</p>\n<p>   <code>INTERFACE_INCLUDE_DIRECTORIES</code> </p>\n</li>\n</ul>\n<p></p>\n<p><code>target_include_directories</code>   <code>$&lt;...&gt;</code><a href=\"https://cmake.org/cmake/help/latest/manual/cmake-generator-expressions.7.html#manual:cmake-generator-expressions(7\"></a>) </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_include_directories(mylib PUBLIC</span><br><span class=\"line\">  $&lt;BUILD_INTERFACE:$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/include/mylib&gt;</span><br><span class=\"line\">  $&lt;INSTALL_INTERFACE:include/mylib&gt;  # &lt;prefix&gt;/include/mylib</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p> <code>export()</code>  <code>$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/include/mylib&gt;</code> <code>install(EXPORT)</code>  <code>include/mylib&gt;</code></p>"},{"title":"C++ ","date":"2021-06-28T10:47:45.000Z","_content":"","source":"_posts/cpp/constructor.md","raw":"---\ntitle: C++ \ndate: 2021-06-28 18:47:45\ntags:\n---\n","slug":"cpp/constructor","published":1,"updated":"2021-06-28T10:47:45.725Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90n001lp0dj2743dnq4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"cpp-aux-tools","date":"2019-07-11T11:16:23.000Z","p":"cpp/aux-tools","_content":" c++ \n<!-- more -->\n```c++\n// test.cpp\nint f(int i) { return 0; }\n```\n\n```\ngcc test.cpp -o test.o\n```\n f  low-level assembler name mangling\n```\nnm test.o | grep f\n// \n// 000000000000008b T _Z4fi\n```\n\n```\nc++filt -n _Z4fi\n// \n// f(int)\n```\n\n\n```\nobjdump -d test.o\n```\n option  `objdump --help`\n\n\n```\ngcc -xc++ -E -v -\n```\n\n\n```\nldd test.o\n```\n\n\n```\nexport LD_LIBRARY_PATH=/xx/xx:$LD_LIBRARY_PATH\nexport CPLUS_INCLUDE_PATH=/xx/xx:$CPLUS_INCLUDE_PATH\n```\n\n## \n```\ng++ -c x.cpp\nar crv libx.a x.o\n```\n\n## \n```\ng++ -shared -fPIC -o libx.so x.o\n```\n","source":"_posts/cpp/cpp-aux-tools.md","raw":"---\ntitle: cpp-aux-tools\ndate: 2019-07-11 19:16:23\ntags: c++\np: cpp/aux-tools\n---\n c++ \n<!-- more -->\n```c++\n// test.cpp\nint f(int i) { return 0; }\n```\n\n```\ngcc test.cpp -o test.o\n```\n f  low-level assembler name mangling\n```\nnm test.o | grep f\n// \n// 000000000000008b T _Z4fi\n```\n\n```\nc++filt -n _Z4fi\n// \n// f(int)\n```\n\n\n```\nobjdump -d test.o\n```\n option  `objdump --help`\n\n\n```\ngcc -xc++ -E -v -\n```\n\n\n```\nldd test.o\n```\n\n\n```\nexport LD_LIBRARY_PATH=/xx/xx:$LD_LIBRARY_PATH\nexport CPLUS_INCLUDE_PATH=/xx/xx:$CPLUS_INCLUDE_PATH\n```\n\n## \n```\ng++ -c x.cpp\nar crv libx.a x.o\n```\n\n## \n```\ng++ -shared -fPIC -o libx.so x.o\n```\n","slug":"cpp/cpp-aux-tools","published":1,"updated":"2021-06-12T10:05:01.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90o001mp0dj5eqcewf5","content":"<p> c++ <br><span id=\"more\"></span><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// test.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">f</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123; <span class=\"keyword\">return</span> <span class=\"number\">0</span>; &#125;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc test.cpp -o test.o</span><br></pre></td></tr></table></figure><br> f  low-level assembler name mangling<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nm test.o | grep f</span><br><span class=\"line\">// </span><br><span class=\"line\">// 000000000000008b T _Z4fi</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c++filt -n _Z4fi</span><br><span class=\"line\">// </span><br><span class=\"line\">// f(int)</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">objdump -d test.o</span><br></pre></td></tr></table></figure><br> option  <code>objdump --help</code></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -xc++ -E -v -</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ldd test.o</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH=/xx/xx:$LD_LIBRARY_PATH</span><br><span class=\"line\">export CPLUS_INCLUDE_PATH=/xx/xx:$CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -c x.cpp</span><br><span class=\"line\">ar crv libx.a x.o</span><br></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -shared -fPIC -o libx.so x.o</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p> c++ <br>","more":"<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// test.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">f</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123; <span class=\"keyword\">return</span> <span class=\"number\">0</span>; &#125;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc test.cpp -o test.o</span><br></pre></td></tr></table></figure><br> f  low-level assembler name mangling<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nm test.o | grep f</span><br><span class=\"line\">// </span><br><span class=\"line\">// 000000000000008b T _Z4fi</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c++filt -n _Z4fi</span><br><span class=\"line\">// </span><br><span class=\"line\">// f(int)</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">objdump -d test.o</span><br></pre></td></tr></table></figure><br> option  <code>objdump --help</code></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -xc++ -E -v -</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ldd test.o</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH=/xx/xx:$LD_LIBRARY_PATH</span><br><span class=\"line\">export CPLUS_INCLUDE_PATH=/xx/xx:$CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -c x.cpp</span><br><span class=\"line\">ar crv libx.a x.o</span><br></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -shared -fPIC -o libx.so x.o</span><br></pre></td></tr></table></figure>"},{"title":"GCC common usages","date":"2021-08-06T01:20:22.000Z","_content":"\n\n```c\n// hello.c\n#include <stdio.h>\nint main(int argc, char **argv)\n{\n printf(hello world\\n);\n return 0;\n}\n```\n# \n```shell\n$ gcc -o hello hello.c\n```\n\n\n# \n `-E` \n```shell\ngcc -E -o hello.pp.c hello.c\n```\n\n# \n\n```shell\n$ gcc -S hello.c\n```\n `hello.s`\n\n```shell\n$ gcc -c hello.c\n```\n `hello.o`\n\n\ngcc  [](https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html)\n\n section\n1. `Text` T\n2. `Data`:  D\n3. `Constants`    R\n4. `Undefined`:  U\n5. `Debug`\n\n `nm`  `readelf` \n\n# \n\n```shell\n$ gcc -o hello hello.o\n```\ngcc  `ld`  `crt1.o`  `hello.o`  `crt1.o` `crtn.o` `crt1.o`  `_start`  `main`  `nm` \n```shell\n$ nm /usr/lib/x86_64-linux-gnu/crt1.o\n```\n `U main`  `main`  `main` \n\n `crti.o`  `_init`  `_finit`  `main`  \n![](/images/cpp/C_linking_process.png)<center>C  [](https://akaedu.github.io/book/ch19s02.html)</center>\n\n# \n `ar` \n```shell\n$ ar crv libhello.a hello.o\n```\n `ar` [](https://linux.die.net/man/1/ar)\n\n\n\n\n```shell\n$ ar -x libhello.a\n```\n\n# \n\nexecutable executable  `main` \n\n\n```shell\n$ gcc -fPIC -c hello.c\n```\n`main` \n\n\n```shell\n$ ld -shared hello.o -o libhello.so\n```\n\n```shell\ngcc -shared -fPIC -o hello.c\n```\n\n# \n\n1.  static linker  shared library  executablelinux  `ld`google  `gold`\n2.  dynamic linker  shared librarylinux  `ld.so`\n\n static linker  linker dynamic linker  loader\n\n## \n1.  linker `-L` option `ld -o main main.c -L. -lhello`\n2.  loader `-rpath` `gcc -o main main.c -Wl,-rpath=. -L. -lhello`\n\n\n\n1.  `.`  hello  `libhello.a`  `1`   `libhello.so` `-L. -lhello`  `-Wl,-rpath=.` `-Wl`  option  linker`-rpath`  loader \n\n2.  `LD_LIBRARY_PATH`  loader \n\n3.  `/etc/ld.so.conf` `ldconfig` `/lib`  `/usr/lib`  `ldconfig`\n\n`LD_LIBRARY_PATH` \n\n `-rpath`  `$ORIGIN` `.`  Makefile  `-Wl,-rpath='$$ORIGIN'` `-Wl,-rpath='$ORIGIN'`","source":"_posts/cpp/gcc_common_usages.md","raw":"---\ntitle: GCC common usages\ndate: 2021-08-06 09:20:22\ntags: C++\n---\n\n\n```c\n// hello.c\n#include <stdio.h>\nint main(int argc, char **argv)\n{\n printf(hello world\\n);\n return 0;\n}\n```\n# \n```shell\n$ gcc -o hello hello.c\n```\n\n\n# \n `-E` \n```shell\ngcc -E -o hello.pp.c hello.c\n```\n\n# \n\n```shell\n$ gcc -S hello.c\n```\n `hello.s`\n\n```shell\n$ gcc -c hello.c\n```\n `hello.o`\n\n\ngcc  [](https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html)\n\n section\n1. `Text` T\n2. `Data`:  D\n3. `Constants`    R\n4. `Undefined`:  U\n5. `Debug`\n\n `nm`  `readelf` \n\n# \n\n```shell\n$ gcc -o hello hello.o\n```\ngcc  `ld`  `crt1.o`  `hello.o`  `crt1.o` `crtn.o` `crt1.o`  `_start`  `main`  `nm` \n```shell\n$ nm /usr/lib/x86_64-linux-gnu/crt1.o\n```\n `U main`  `main`  `main` \n\n `crti.o`  `_init`  `_finit`  `main`  \n![](/images/cpp/C_linking_process.png)<center>C  [](https://akaedu.github.io/book/ch19s02.html)</center>\n\n# \n `ar` \n```shell\n$ ar crv libhello.a hello.o\n```\n `ar` [](https://linux.die.net/man/1/ar)\n\n\n\n\n```shell\n$ ar -x libhello.a\n```\n\n# \n\nexecutable executable  `main` \n\n\n```shell\n$ gcc -fPIC -c hello.c\n```\n`main` \n\n\n```shell\n$ ld -shared hello.o -o libhello.so\n```\n\n```shell\ngcc -shared -fPIC -o hello.c\n```\n\n# \n\n1.  static linker  shared library  executablelinux  `ld`google  `gold`\n2.  dynamic linker  shared librarylinux  `ld.so`\n\n static linker  linker dynamic linker  loader\n\n## \n1.  linker `-L` option `ld -o main main.c -L. -lhello`\n2.  loader `-rpath` `gcc -o main main.c -Wl,-rpath=. -L. -lhello`\n\n\n\n1.  `.`  hello  `libhello.a`  `1`   `libhello.so` `-L. -lhello`  `-Wl,-rpath=.` `-Wl`  option  linker`-rpath`  loader \n\n2.  `LD_LIBRARY_PATH`  loader \n\n3.  `/etc/ld.so.conf` `ldconfig` `/lib`  `/usr/lib`  `ldconfig`\n\n`LD_LIBRARY_PATH` \n\n `-rpath`  `$ORIGIN` `.`  Makefile  `-Wl,-rpath='$$ORIGIN'` `-Wl,-rpath='$ORIGIN'`","slug":"cpp/gcc_common_usages","published":1,"updated":"2021-08-06T08:18:27.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90o001np0djczip23hb","content":"<p><br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// hello.c</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"> <span class=\"built_in\">printf</span>(hello world\\n);</span><br><span class=\"line\"> <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -o hello hello.c</span></span><br></pre></td></tr></table></figure>\n<p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>-E</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -E -o hello.pp.c hello.c</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -S hello.c</span></span><br></pre></td></tr></table></figure>\n<p> <code>hello.s</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c hello.c</span></span><br></pre></td></tr></table></figure>\n<p> <code>hello.o</code></p>\n<p>gcc  <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html\"></a></p>\n<p> section</p>\n<ol>\n<li><code>Text</code> T</li>\n<li><code>Data</code>:  D</li>\n<li><code>Constants</code>    R</li>\n<li><code>Undefined</code>:  U</li>\n<li><code>Debug</code></li>\n</ol>\n<p> <code>nm</code>  <code>readelf</code> </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -o hello hello.o</span></span><br></pre></td></tr></table></figure><br>gcc  <code>ld</code>  <code>crt1.o</code>  <code>hello.o</code>  <code>crt1.o</code> <code>crtn.o</code> <code>crt1.o</code>  <code>_start</code>  <code>main</code>  <code>nm</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> nm /usr/lib/x86_64-linux-gnu/crt1.o</span></span><br></pre></td></tr></table></figure><br> <code>U main</code>  <code>main</code>  <code>main</code> </p>\n<p> <code>crti.o</code>  <code>_init</code>  <code>_finit</code>  <code>main</code>  <br><img src=\"/images/cpp/C_linking_process.png\" alt=\"\"><center>C  [](https://akaedu.github.io/book/ch19s02.html)</center></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>ar</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ar crv libhello.a hello.o</span></span><br></pre></td></tr></table></figure><br> <code>ar</code> <a href=\"https://linux.die.net/man/1/ar\"></a></p>\n<p></p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ar -x libhello.a</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>executable executable  <code>main</code> </p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -fPIC -c hello.c</span></span><br></pre></td></tr></table></figure><br><code>main</code> </p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ld -shared hello.o -o libhello.so</span></span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -shared -fPIC -o hello.c</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> static linker  shared library  executablelinux  <code>ld</code>google  <code>gold</code></li>\n<li> dynamic linker  shared librarylinux  <code>ld.so</code></li>\n</ol>\n<p> static linker  linker dynamic linker  loader</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> linker <code>-L</code> option <code>ld -o main main.c -L. -lhello</code></li>\n<li> loader <code>-rpath</code> <code>gcc -o main main.c -Wl,-rpath=. -L. -lhello</code></li>\n</ol>\n<p></p>\n<ol>\n<li><p> <code>.</code>  hello  <code>libhello.a</code>  <code>1</code>   <code>libhello.so</code> <code>-L. -lhello</code>  <code>-Wl,-rpath=.</code> <code>-Wl</code>  option  linker<code>-rpath</code>  loader </p>\n</li>\n<li><p> <code>LD_LIBRARY_PATH</code>  loader </p>\n</li>\n<li><p> <code>/etc/ld.so.conf</code> <code>ldconfig</code> <code>/lib</code>  <code>/usr/lib</code>  <code>ldconfig</code></p>\n</li>\n</ol>\n<p><code>LD_LIBRARY_PATH</code> </p>\n<p> <code>-rpath</code>  <code>$ORIGIN</code> <code>.</code>  Makefile  <code>-Wl,-rpath=&#39;$$ORIGIN&#39;</code> <code>-Wl,-rpath=&#39;$ORIGIN&#39;</code></p>\n","site":{"data":{}},"excerpt":"","more":"<p><br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// hello.c</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> **argv)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"> <span class=\"built_in\">printf</span>(hello world\\n);</span><br><span class=\"line\"> <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -o hello hello.c</span></span><br></pre></td></tr></table></figure>\n<p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>-E</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -E -o hello.pp.c hello.c</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -S hello.c</span></span><br></pre></td></tr></table></figure>\n<p> <code>hello.s</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c hello.c</span></span><br></pre></td></tr></table></figure>\n<p> <code>hello.o</code></p>\n<p>gcc  <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html\"></a></p>\n<p> section</p>\n<ol>\n<li><code>Text</code> T</li>\n<li><code>Data</code>:  D</li>\n<li><code>Constants</code>    R</li>\n<li><code>Undefined</code>:  U</li>\n<li><code>Debug</code></li>\n</ol>\n<p> <code>nm</code>  <code>readelf</code> </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -o hello hello.o</span></span><br></pre></td></tr></table></figure><br>gcc  <code>ld</code>  <code>crt1.o</code>  <code>hello.o</code>  <code>crt1.o</code> <code>crtn.o</code> <code>crt1.o</code>  <code>_start</code>  <code>main</code>  <code>nm</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> nm /usr/lib/x86_64-linux-gnu/crt1.o</span></span><br></pre></td></tr></table></figure><br> <code>U main</code>  <code>main</code>  <code>main</code> </p>\n<p> <code>crti.o</code>  <code>_init</code>  <code>_finit</code>  <code>main</code>  <br><img src=\"/images/cpp/C_linking_process.png\" alt=\"\"><center>C  [](https://akaedu.github.io/book/ch19s02.html)</center></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>ar</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ar crv libhello.a hello.o</span></span><br></pre></td></tr></table></figure><br> <code>ar</code> <a href=\"https://linux.die.net/man/1/ar\"></a></p>\n<p></p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ar -x libhello.a</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>executable executable  <code>main</code> </p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -fPIC -c hello.c</span></span><br></pre></td></tr></table></figure><br><code>main</code> </p>\n<p><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ld -shared hello.o -o libhello.so</span></span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -shared -fPIC -o hello.c</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> static linker  shared library  executablelinux  <code>ld</code>google  <code>gold</code></li>\n<li> dynamic linker  shared librarylinux  <code>ld.so</code></li>\n</ol>\n<p> static linker  linker dynamic linker  loader</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> linker <code>-L</code> option <code>ld -o main main.c -L. -lhello</code></li>\n<li> loader <code>-rpath</code> <code>gcc -o main main.c -Wl,-rpath=. -L. -lhello</code></li>\n</ol>\n<p></p>\n<ol>\n<li><p> <code>.</code>  hello  <code>libhello.a</code>  <code>1</code>   <code>libhello.so</code> <code>-L. -lhello</code>  <code>-Wl,-rpath=.</code> <code>-Wl</code>  option  linker<code>-rpath</code>  loader </p>\n</li>\n<li><p> <code>LD_LIBRARY_PATH</code>  loader </p>\n</li>\n<li><p> <code>/etc/ld.so.conf</code> <code>ldconfig</code> <code>/lib</code>  <code>/usr/lib</code>  <code>ldconfig</code></p>\n</li>\n</ol>\n<p><code>LD_LIBRARY_PATH</code> </p>\n<p> <code>-rpath</code>  <code>$ORIGIN</code> <code>.</code>  Makefile  <code>-Wl,-rpath=&#39;$$ORIGIN&#39;</code> <code>-Wl,-rpath=&#39;$ORIGIN&#39;</code></p>\n"},{"title":"","date":"2021-06-08T03:06:44.000Z","p":"cpp/link","_content":"## \n1.  `/lib`, `/usr/lib` \n2.  `export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<YOUR LIB PATH>`\n3.  `/etc/ld.so.conf` `ldconfig`\n4. `gcc`  `-Wl,-rpath=<YOUR LIB PATH>`\n\n\n\n### -Wl\n `ld`\n\n### -rpath\n `$ORIGIN` Makefile  `$$ORIGIN`\n\n### --as-needed\n symbol  binary  flag `--no-as-needed`\n\n```c++\n// main.c\nvoid foo();\n\nint main(void) {\n    foo();\n    return 0;\n}\n```\n\n```c++\n// lib/foo.c\n#include <stdio.h>\n\nvoid foo() { printf(\"foo\\n\"); }\n```\n\n```c++\n// lib/bar.c\n#include <stdio.h>\n\nvoid bar() { printf(\"bar\\n\"); }\n```\n\n```makefile\n# Makefile\nmain: main.c lib/libfoo.so lib/libbar.so\n    gcc -o main main.c -Wl,--no-as-needed,-rpath='$$ORIGIN/lib' -L. -lfoo -lbar\n\nlib/libfoo.so: lib/foo.c\n    gcc -fPIC -shared -o lib/libfoo.so lib/foo.c\n\nlib/libbar.so: lib/bar.c\n    gcc -fPIC -shared -o lib/libbar.so lib/bar.c\n```\n\n `main` \n```shell\n$ ldd main\n```\n","source":"_posts/cpp/link.md","raw":"---\ntitle: \ndate: 2021-06-08 11:06:44\ntags: c++\np: cpp/link\n---\n## \n1.  `/lib`, `/usr/lib` \n2.  `export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<YOUR LIB PATH>`\n3.  `/etc/ld.so.conf` `ldconfig`\n4. `gcc`  `-Wl,-rpath=<YOUR LIB PATH>`\n\n\n\n### -Wl\n `ld`\n\n### -rpath\n `$ORIGIN` Makefile  `$$ORIGIN`\n\n### --as-needed\n symbol  binary  flag `--no-as-needed`\n\n```c++\n// main.c\nvoid foo();\n\nint main(void) {\n    foo();\n    return 0;\n}\n```\n\n```c++\n// lib/foo.c\n#include <stdio.h>\n\nvoid foo() { printf(\"foo\\n\"); }\n```\n\n```c++\n// lib/bar.c\n#include <stdio.h>\n\nvoid bar() { printf(\"bar\\n\"); }\n```\n\n```makefile\n# Makefile\nmain: main.c lib/libfoo.so lib/libbar.so\n    gcc -o main main.c -Wl,--no-as-needed,-rpath='$$ORIGIN/lib' -L. -lfoo -lbar\n\nlib/libfoo.so: lib/foo.c\n    gcc -fPIC -shared -o lib/libfoo.so lib/foo.c\n\nlib/libbar.so: lib/bar.c\n    gcc -fPIC -shared -o lib/libbar.so lib/bar.c\n```\n\n `main` \n```shell\n$ ldd main\n```\n","slug":"cpp/link","published":1,"updated":"2021-08-11T06:32:07.229Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90p001pp0djcw5t4unq","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> <code>/lib</code>, <code>/usr/lib</code> </li>\n<li> <code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:&lt;YOUR LIB PATH&gt;</code></li>\n<li> <code>/etc/ld.so.conf</code> <code>ldconfig</code></li>\n<li><code>gcc</code>  <code>-Wl,-rpath=&lt;YOUR LIB PATH&gt;</code><br></li>\n</ol>\n<h3 id=\"Wl\"><a href=\"#Wl\" class=\"headerlink\" title=\"-Wl\"></a>-Wl</h3><p> <code>ld</code></p>\n<h3 id=\"rpath\"><a href=\"#rpath\" class=\"headerlink\" title=\"-rpath\"></a>-rpath</h3><p> <code>$ORIGIN</code> Makefile  <code>$$ORIGIN</code></p>\n<h3 id=\"as-needed\"><a href=\"#as-needed\" class=\"headerlink\" title=\"as-needed\"></a>as-needed</h3><p> symbol  binary  flag <code>--no-as-needed</code></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.c</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">foo</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// lib/foo.c</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span> </span>&#123; <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;foo\\n&quot;</span>); &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// lib/bar.c</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bar</span><span class=\"params\">()</span> </span>&#123; <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;bar\\n&quot;</span>); &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Makefile</span></span><br><span class=\"line\"><span class=\"section\">main: main.c lib/libfoo.so lib/libbar.so</span></span><br><span class=\"line\">    gcc -o main main.c -Wl,--no-as-needed,-rpath=&#x27;$$ORIGIN/lib&#x27; -L. -lfoo -lbar</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">lib/libfoo.so: lib/foo.c</span></span><br><span class=\"line\">    gcc -fPIC -shared -o lib/libfoo.so lib/foo.c</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">lib/libbar.so: lib/bar.c</span></span><br><span class=\"line\">    gcc -fPIC -shared -o lib/libbar.so lib/bar.c</span><br></pre></td></tr></table></figure>\n<p> <code>main</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ldd main</span></span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> <code>/lib</code>, <code>/usr/lib</code> </li>\n<li> <code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:&lt;YOUR LIB PATH&gt;</code></li>\n<li> <code>/etc/ld.so.conf</code> <code>ldconfig</code></li>\n<li><code>gcc</code>  <code>-Wl,-rpath=&lt;YOUR LIB PATH&gt;</code><br></li>\n</ol>\n<h3 id=\"Wl\"><a href=\"#Wl\" class=\"headerlink\" title=\"-Wl\"></a>-Wl</h3><p> <code>ld</code></p>\n<h3 id=\"rpath\"><a href=\"#rpath\" class=\"headerlink\" title=\"-rpath\"></a>-rpath</h3><p> <code>$ORIGIN</code> Makefile  <code>$$ORIGIN</code></p>\n<h3 id=\"as-needed\"><a href=\"#as-needed\" class=\"headerlink\" title=\"as-needed\"></a>as-needed</h3><p> symbol  binary  flag <code>--no-as-needed</code></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.c</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">foo</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// lib/foo.c</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">foo</span><span class=\"params\">()</span> </span>&#123; <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;foo\\n&quot;</span>); &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// lib/bar.c</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bar</span><span class=\"params\">()</span> </span>&#123; <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;bar\\n&quot;</span>); &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Makefile</span></span><br><span class=\"line\"><span class=\"section\">main: main.c lib/libfoo.so lib/libbar.so</span></span><br><span class=\"line\">    gcc -o main main.c -Wl,--no-as-needed,-rpath=&#x27;$$ORIGIN/lib&#x27; -L. -lfoo -lbar</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">lib/libfoo.so: lib/foo.c</span></span><br><span class=\"line\">    gcc -fPIC -shared -o lib/libfoo.so lib/foo.c</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">lib/libbar.so: lib/bar.c</span></span><br><span class=\"line\">    gcc -fPIC -shared -o lib/libbar.so lib/bar.c</span><br></pre></td></tr></table></figure>\n<p> <code>main</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ldd main</span></span><br></pre></td></tr></table></figure></p>\n"},{"title":"C++ ","date":"2021-06-25T04:02:49.000Z","_content":"C++ \n<!-- more -->\n# \nsource code VS 2019C++ Console App `ConsoleApplication1.cpp`  VS 2019    VS `GB2312` `utf-8` vscode  `ctrl+shift+p`  `encode`  `Change File Encoding`  vscode   `UTF-8``CRLF` \n\nunicode  UTF-8 unicode  UCS2  UCS4 UTF-8  unicode  unicode  unicode UTF-8  ASCII  gb2312  UTF-8  GBK  gb2312GBK  gb2312  UTF-8 GBK  gb2312  ASCII unicode  ASCII\n\n Windows  ultraedit  UEStudio  Linux  vim  `:%!xxd` `hexdump <filename> -C`  16 \n>  vim `:%!xxd`  16  gb2312  utf-8  utf-8  16  vim \n\n `` ``\n\n## \nWindows  C++  `cl.exe`  `` `chcp` \n```shell\n> chcp\nActive code page: 936\n```\n936  `gb2312`\n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = L'';\n    return 0;\n}\n```\n vs 2019  Console App  `gb2312` Visual Studio 2019  `Developer Command Prompt for VS 2019`\n```shell\n> cd myproj\n> cl main.cpp /E > main-gb2312.i\n```\n `main-gb2312.i`  `gb2312` ``  `BAC3`\n\n VS 2019    `UTF-8 with signature`\n```shell\n> cl main.cpp /E > main-utf8-sig.i\n```\n `main-utf8-sig.i`  `gb2312` ``  `BAC3`\n\nbut `UTF-8 without signature` `UTF-8`  `cl.exe`  `gb2312` ``  UTF-8  `E5A5BD` `'` UTF-8  `27` `E5A5`  gb2312  ``  `BD`  `27`  gb2312  `?`  `3F` `'` VS \n\n![](/images/cpp/string1.png)\n\n utf-8  gb2312 \n\n `UTF-8 without signature` \n\n CODE PAGE  65001``  UTF-8 `UTF-8`   `\\source-charset:utf-8` \n```shell\n> cl /source-charset:utf-8 main.cpp /E > main-gb2312.i\n```\n\nLinux  GCC  ``  UTF-8\n```shell\n$ gcc -E main.cpp -o main-utf8.i\n```\n `main-utf8.i`  ``  `E5A5BD` UTF-8 \n\n vscode  `gb2312`  `gcc -E main.cpp -o main-gb2312.i` `main-gb2312.i` ``  `BAC3` gb2312  gb2312  gcc  UTF-8  `'`  `'` gb2312  `BAC327` gcc  UTF-8 `'``BAC3`  UTF-8 <font color=\"red\"> gb2312  UTF-8 </font> gb2312  UTF-8  gcc  `-finput-charset` \n```shell\n$ gcc -finput-charset=gb2312 -E main.cpp -o main-gb2312-ic.i\n```\n `main-gb2312-ic.i`  UTF-8  ``  `E5A5BD`GCC  ``  UTF-8 gcc `` \n\n>  UTF-8  https://www.branah.com/unicode-converter   gb2312  https://www.qqxiuzi.cn/bianma/zifuji.php \n\n\n## \n\n ``[](https://docs.microsoft.com/en-us/cpp/build/reference/execution-charset-set-execution-character-set?view=msvc-160)`` \n\n VS  `/execution-charset:<charset>`  GCC  `-fexec-charset=<charset>`  `-fwide-exec-charset=<charset>`\n\n GCC Ubuntu \n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    char c = '';\n    return 0;\n}\n```\n `c`  char \n```shell\n$ gcc -c main.cpp -o main.o\n$ objdump -Sr main.o\n\nf:  c6 45 ff bd    movb    $0xbd,-0x1(%rbp)\n```\n `0xbd`  ``  utf-8  `E5A5BD`  char  `` \n```shell\n$ gcc -c main.cpp -o main.o -fexec-charset=gb2312\n$ objdump -Sr main.o\n\nf:  c6 45 ff c3     movb    $0xc3,-0x1(%rbp)\n```\n `0xc3`  ``  gb2312  `BAC3` \n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = '';\n    return 0;\n}\n```\n `L`\n```shell\n$ gcc -c main.cpp -o main.o\n$ objdump -Sr main.o\n\nf:  c7 45 fc bd a5 e5 00    movl    $0xe5a5bd,-0x4(%rbp)\n```\n ``  UTF-8  `E5A5BD` `` \n```shell\n$ gcc -c main.cpp -o main.o -fexe-charset=gb2312\n$ objdump -Sr main.o\n\nf:  c7 45 fc c3 ba 00 00    movl    $0xbac3,-0x4(%rbp)\n```\n\n``  gb2312  `BAC3`\n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = L'';\n    return 0;\n}\n```\n `` \n```shell\n$ gcc -c main.cpp -o main.o\n$ objdump -Sr main.o\n\nf:  c7 45 fc 7d 59 00 00    movl    $0x597d,-0x4(%rbp)\n```\n `0x597d`  ``  UTF-32  `char = L''` ``  UTF-32  `7D`\n\n `L`  ``  `UTF-32`  wchar_t  4  2  ``  `UTF-16` `-fwide-exec-charset`  ____  ``\n```shell\n$ gcc -c main.cpp -o main.o -fwide-exec-charset=gb2312\n$ objdump -Sr main.o\n\nf:  c7 45 fc 00 00 ba c3   movl    $0xc3ba0000,-0x4(%rbp)\n```\n `gb2312`\n\n\n\n1. `-fexec-charset`  `''`\n2. `-fwide-exec-char`  `L`\n3. GCC  ``  `UTF-8` ``  `UTF-32`\n\n\n\n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = L'';      // -fwide-exec-charset=gb2312\n    wchar_t d = '';       // -fexec-charset=gb2312\n    char32_t e = U'';     //  -fwide-exec-charset \n    return 0;\n}\n```\n\n# \n GCC \n```c++\n// main.cpp\n#include <stdio.h>\nint main(int argc, char** argv) {\n    wchar_t a = L'';\n    char32_t b = U'';\n    char c = '';\n    int d = 0x597D;\n    wint_t e = 0x597D;\n\n    printf(\"a->%c, b->%c, c->%c, d->%c, e->%c\\n\", a, b, c, d, e);\n}\n```\n\n```shell\n$ g++ main.cpp -o main\n$ ./main\n\na->}, b->}, c->?, d->}, e->}\n```\n`c`   `?`  ASCII  `a,b,d,e`  `}` [printf ](http://www.cplusplus.com/reference/cstdio/printf/)`a,b`  UTF-32  `597D` `d,e`  char  `7D` `}`  ASCII`c`  ``  UTF-8 GCC  UTF-8   `BD` `char c = 0xBD` `%c` 127 ASCII  128~255 `wchar_t c=0xBD` `%lc`  ASCII  ``  `char`  `wchar_t`  `%lc` C  `C` locale locale  locale  `locale` \n```c++\n#include <wchar.h>\nint main(int argc, char** argv) {\n    setlocale(LC_CTYPE, \"\");    //  L, u, U  locale\n    wchar_t a = L'';\n    char32_t b = U'';\n    wchar_t c = 0xBD;   // ASCII \n    int d = 0x597D;\n    wint_t e = 0x597D;\n    printf(\"a->%lc, b->%lc, c->%lc, d->%lc, e->%lc\\n\", a, b, c, d, e);\n}\n```\n\n \n```\na->, b->, c->, d->, e->\n```\n\n `c`  `%lc` `` 1/2 [ ASCII ](https://www.w3school.com.cn/charsets/ref_html_8859.asp) ``  unicode  `597D` `wchar_t c=0xE5A5BD` UTF-8  `` GCC  `exec-charset`  `UTF-8` `UTF-8` \n\n\n `exec-charset`  `%lc`  `%s` \n```c++\n#include <locale.h>\n#include <wchar.h>\n#include <stdio.h>\nint main(int argc, char** argv) {\n    setlocale(LC_CTYPE, \"\");    //  locale `a,b,g` \n    const wchar_t* a = L\"\";\n    const char32_t* b = U\"\";\n    const char* c = \"\";\n    const char* d = \"\\xE5\\xA5\\xBD\";\n    unsigned char e[4] = {0xE5, 0xA5, 0xBD};\n    const char f[4] = {'\\xE5', '\\xA5', '\\xBD'};\n    const char32_t* g = U\"\\x597D\";\n    printf(\"a->%ls, b->%ls, c->%s, d->%s, e->%s, f->%s, g->%ls\\n\", a, b, c, d, e, f, g);\n}\n```\n`c`  `%s` `a,b`  `%ls` \n\n \n```\na->, b->, c->, d->, e->, f-> g->\n```\n\n`d,f`  `\"\"`  16 UTF-8 `e`  ``  `\\0`  ``  UTF-8 `d,e,f`  `%s``d,f`  `printf(d);printf(f);`\n\n `g` `0x` `0x` 16 char  8 bit 16  `L`  `U`64 bit  32 bit `u`  specifier  `%ls`\n\n> 1.  printf(\"%x\\n\", a);  16 \n\n> 2. GCC  `printf`  `wprintf` `fwide` .\n\n\n## C++ \nC++  `cout` \n```c++\n#include <iostream>\nint main(int argc, char** argv) {\n    const char* a = \"\";\n    std::cout << a << \"-\" << std::endl;\n}\n```\n `std::cout << '';`  ```''`  UTF-8  `E5A5BD` char `std::cout << '';`  `15050173` `E5A5BD` \n\n `wcout` \n```c++\n#include <wchar.h>\nint main(int argc, char** argv) {\n    const w_char* a = L\"\";\n    std::wcout << a << L\"-\" << std::endl;\n}\n```\n ASCII  `-` \nGCC  `UTF-8` Ubuntu terminal `locale`  `LC_CTYPE=en_US.UTF-8` `std::wcout`  `UTF-32`UCS2  UCS4 `std::wcout`  `locale` \n```c++\n#include <wchar.h>\n#include <locale>\nint main(int argc, char** argv) {\n    std::setlocale(LC_CTYPE, \"\");       //  C++ \n    // std::locale::global(std::locale(\"\"));\n    const w_char* a = L\"\";\n    std::wcout << a << L\"-\" << std::endl;\n}\n```","source":"_posts/cpp/string.md","raw":"---\ntitle: C++ \ndate: 2021-06-25 12:02:49\ntags:\n---\nC++ \n<!-- more -->\n# \nsource code VS 2019C++ Console App `ConsoleApplication1.cpp`  VS 2019    VS `GB2312` `utf-8` vscode  `ctrl+shift+p`  `encode`  `Change File Encoding`  vscode   `UTF-8``CRLF` \n\nunicode  UTF-8 unicode  UCS2  UCS4 UTF-8  unicode  unicode  unicode UTF-8  ASCII  gb2312  UTF-8  GBK  gb2312GBK  gb2312  UTF-8 GBK  gb2312  ASCII unicode  ASCII\n\n Windows  ultraedit  UEStudio  Linux  vim  `:%!xxd` `hexdump <filename> -C`  16 \n>  vim `:%!xxd`  16  gb2312  utf-8  utf-8  16  vim \n\n `` ``\n\n## \nWindows  C++  `cl.exe`  `` `chcp` \n```shell\n> chcp\nActive code page: 936\n```\n936  `gb2312`\n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = L'';\n    return 0;\n}\n```\n vs 2019  Console App  `gb2312` Visual Studio 2019  `Developer Command Prompt for VS 2019`\n```shell\n> cd myproj\n> cl main.cpp /E > main-gb2312.i\n```\n `main-gb2312.i`  `gb2312` ``  `BAC3`\n\n VS 2019    `UTF-8 with signature`\n```shell\n> cl main.cpp /E > main-utf8-sig.i\n```\n `main-utf8-sig.i`  `gb2312` ``  `BAC3`\n\nbut `UTF-8 without signature` `UTF-8`  `cl.exe`  `gb2312` ``  UTF-8  `E5A5BD` `'` UTF-8  `27` `E5A5`  gb2312  ``  `BD`  `27`  gb2312  `?`  `3F` `'` VS \n\n![](/images/cpp/string1.png)\n\n utf-8  gb2312 \n\n `UTF-8 without signature` \n\n CODE PAGE  65001``  UTF-8 `UTF-8`   `\\source-charset:utf-8` \n```shell\n> cl /source-charset:utf-8 main.cpp /E > main-gb2312.i\n```\n\nLinux  GCC  ``  UTF-8\n```shell\n$ gcc -E main.cpp -o main-utf8.i\n```\n `main-utf8.i`  ``  `E5A5BD` UTF-8 \n\n vscode  `gb2312`  `gcc -E main.cpp -o main-gb2312.i` `main-gb2312.i` ``  `BAC3` gb2312  gb2312  gcc  UTF-8  `'`  `'` gb2312  `BAC327` gcc  UTF-8 `'``BAC3`  UTF-8 <font color=\"red\"> gb2312  UTF-8 </font> gb2312  UTF-8  gcc  `-finput-charset` \n```shell\n$ gcc -finput-charset=gb2312 -E main.cpp -o main-gb2312-ic.i\n```\n `main-gb2312-ic.i`  UTF-8  ``  `E5A5BD`GCC  ``  UTF-8 gcc `` \n\n>  UTF-8  https://www.branah.com/unicode-converter   gb2312  https://www.qqxiuzi.cn/bianma/zifuji.php \n\n\n## \n\n ``[](https://docs.microsoft.com/en-us/cpp/build/reference/execution-charset-set-execution-character-set?view=msvc-160)`` \n\n VS  `/execution-charset:<charset>`  GCC  `-fexec-charset=<charset>`  `-fwide-exec-charset=<charset>`\n\n GCC Ubuntu \n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    char c = '';\n    return 0;\n}\n```\n `c`  char \n```shell\n$ gcc -c main.cpp -o main.o\n$ objdump -Sr main.o\n\nf:  c6 45 ff bd    movb    $0xbd,-0x1(%rbp)\n```\n `0xbd`  ``  utf-8  `E5A5BD`  char  `` \n```shell\n$ gcc -c main.cpp -o main.o -fexec-charset=gb2312\n$ objdump -Sr main.o\n\nf:  c6 45 ff c3     movb    $0xc3,-0x1(%rbp)\n```\n `0xc3`  ``  gb2312  `BAC3` \n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = '';\n    return 0;\n}\n```\n `L`\n```shell\n$ gcc -c main.cpp -o main.o\n$ objdump -Sr main.o\n\nf:  c7 45 fc bd a5 e5 00    movl    $0xe5a5bd,-0x4(%rbp)\n```\n ``  UTF-8  `E5A5BD` `` \n```shell\n$ gcc -c main.cpp -o main.o -fexe-charset=gb2312\n$ objdump -Sr main.o\n\nf:  c7 45 fc c3 ba 00 00    movl    $0xbac3,-0x4(%rbp)\n```\n\n``  gb2312  `BAC3`\n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = L'';\n    return 0;\n}\n```\n `` \n```shell\n$ gcc -c main.cpp -o main.o\n$ objdump -Sr main.o\n\nf:  c7 45 fc 7d 59 00 00    movl    $0x597d,-0x4(%rbp)\n```\n `0x597d`  ``  UTF-32  `char = L''` ``  UTF-32  `7D`\n\n `L`  ``  `UTF-32`  wchar_t  4  2  ``  `UTF-16` `-fwide-exec-charset`  ____  ``\n```shell\n$ gcc -c main.cpp -o main.o -fwide-exec-charset=gb2312\n$ objdump -Sr main.o\n\nf:  c7 45 fc 00 00 ba c3   movl    $0xc3ba0000,-0x4(%rbp)\n```\n `gb2312`\n\n\n\n1. `-fexec-charset`  `''`\n2. `-fwide-exec-char`  `L`\n3. GCC  ``  `UTF-8` ``  `UTF-32`\n\n\n\n```c++\n// main.cpp\nint main(int argc, char** argv) {\n    wchar_t c = L'';      // -fwide-exec-charset=gb2312\n    wchar_t d = '';       // -fexec-charset=gb2312\n    char32_t e = U'';     //  -fwide-exec-charset \n    return 0;\n}\n```\n\n# \n GCC \n```c++\n// main.cpp\n#include <stdio.h>\nint main(int argc, char** argv) {\n    wchar_t a = L'';\n    char32_t b = U'';\n    char c = '';\n    int d = 0x597D;\n    wint_t e = 0x597D;\n\n    printf(\"a->%c, b->%c, c->%c, d->%c, e->%c\\n\", a, b, c, d, e);\n}\n```\n\n```shell\n$ g++ main.cpp -o main\n$ ./main\n\na->}, b->}, c->?, d->}, e->}\n```\n`c`   `?`  ASCII  `a,b,d,e`  `}` [printf ](http://www.cplusplus.com/reference/cstdio/printf/)`a,b`  UTF-32  `597D` `d,e`  char  `7D` `}`  ASCII`c`  ``  UTF-8 GCC  UTF-8   `BD` `char c = 0xBD` `%c` 127 ASCII  128~255 `wchar_t c=0xBD` `%lc`  ASCII  ``  `char`  `wchar_t`  `%lc` C  `C` locale locale  locale  `locale` \n```c++\n#include <wchar.h>\nint main(int argc, char** argv) {\n    setlocale(LC_CTYPE, \"\");    //  L, u, U  locale\n    wchar_t a = L'';\n    char32_t b = U'';\n    wchar_t c = 0xBD;   // ASCII \n    int d = 0x597D;\n    wint_t e = 0x597D;\n    printf(\"a->%lc, b->%lc, c->%lc, d->%lc, e->%lc\\n\", a, b, c, d, e);\n}\n```\n\n \n```\na->, b->, c->, d->, e->\n```\n\n `c`  `%lc` `` 1/2 [ ASCII ](https://www.w3school.com.cn/charsets/ref_html_8859.asp) ``  unicode  `597D` `wchar_t c=0xE5A5BD` UTF-8  `` GCC  `exec-charset`  `UTF-8` `UTF-8` \n\n\n `exec-charset`  `%lc`  `%s` \n```c++\n#include <locale.h>\n#include <wchar.h>\n#include <stdio.h>\nint main(int argc, char** argv) {\n    setlocale(LC_CTYPE, \"\");    //  locale `a,b,g` \n    const wchar_t* a = L\"\";\n    const char32_t* b = U\"\";\n    const char* c = \"\";\n    const char* d = \"\\xE5\\xA5\\xBD\";\n    unsigned char e[4] = {0xE5, 0xA5, 0xBD};\n    const char f[4] = {'\\xE5', '\\xA5', '\\xBD'};\n    const char32_t* g = U\"\\x597D\";\n    printf(\"a->%ls, b->%ls, c->%s, d->%s, e->%s, f->%s, g->%ls\\n\", a, b, c, d, e, f, g);\n}\n```\n`c`  `%s` `a,b`  `%ls` \n\n \n```\na->, b->, c->, d->, e->, f-> g->\n```\n\n`d,f`  `\"\"`  16 UTF-8 `e`  ``  `\\0`  ``  UTF-8 `d,e,f`  `%s``d,f`  `printf(d);printf(f);`\n\n `g` `0x` `0x` 16 char  8 bit 16  `L`  `U`64 bit  32 bit `u`  specifier  `%ls`\n\n> 1.  printf(\"%x\\n\", a);  16 \n\n> 2. GCC  `printf`  `wprintf` `fwide` .\n\n\n## C++ \nC++  `cout` \n```c++\n#include <iostream>\nint main(int argc, char** argv) {\n    const char* a = \"\";\n    std::cout << a << \"-\" << std::endl;\n}\n```\n `std::cout << '';`  ```''`  UTF-8  `E5A5BD` char `std::cout << '';`  `15050173` `E5A5BD` \n\n `wcout` \n```c++\n#include <wchar.h>\nint main(int argc, char** argv) {\n    const w_char* a = L\"\";\n    std::wcout << a << L\"-\" << std::endl;\n}\n```\n ASCII  `-` \nGCC  `UTF-8` Ubuntu terminal `locale`  `LC_CTYPE=en_US.UTF-8` `std::wcout`  `UTF-32`UCS2  UCS4 `std::wcout`  `locale` \n```c++\n#include <wchar.h>\n#include <locale>\nint main(int argc, char** argv) {\n    std::setlocale(LC_CTYPE, \"\");       //  C++ \n    // std::locale::global(std::locale(\"\"));\n    const w_char* a = L\"\";\n    std::wcout << a << L\"-\" << std::endl;\n}\n```","slug":"cpp/string","published":1,"updated":"2021-09-15T02:04:30.045Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90q001qp0dj0ntl3t6u","content":"<p>C++ <br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>source code VS 2019C++ Console App <code>ConsoleApplication1.cpp</code>  VS 2019    VS <code>GB2312</code> <code>utf-8</code> vscode  <code>ctrl+shift+p</code>  <code>encode</code>  <code>Change File Encoding</code>  vscode   <code>UTF-8</code><code>CRLF</code> </p>\n<p>unicode  UTF-8 unicode  UCS2  UCS4 UTF-8  unicode  unicode  unicode UTF-8  ASCII  gb2312  UTF-8  GBK  gb2312GBK  gb2312  UTF-8 GBK  gb2312  ASCII unicode  ASCII</p>\n<p> Windows  ultraedit  UEStudio  Linux  vim  <code>:%!xxd</code> <code>hexdump &lt;filename&gt; -C</code>  16 </p>\n<blockquote>\n<p> vim <code>:%!xxd</code>  16  gb2312  utf-8  utf-8  16  vim </p>\n</blockquote>\n<p> <code></code> <code></code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Windows  C++  <code>cl.exe</code>  <code></code> <code>chcp</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> chcp</span></span><br><span class=\"line\">Active code page: 936</span><br></pre></td></tr></table></figure><br>936  <code>gb2312</code><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> vs 2019  Console App  <code>gb2312</code> Visual Studio 2019  <code>Developer Command Prompt for VS 2019</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> <span class=\"built_in\">cd</span> myproj</span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cl main.cpp /E &gt; main-gb2312.i</span></span><br></pre></td></tr></table></figure><br> <code>main-gb2312.i</code>  <code>gb2312</code> <code></code>  <code>BAC3</code></p>\n<p> VS 2019    <code>UTF-8 with signature</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cl main.cpp /E &gt; main-utf8-sig.i</span></span><br></pre></td></tr></table></figure><br> <code>main-utf8-sig.i</code>  <code>gb2312</code> <code></code>  <code>BAC3</code></p>\n<p>but <code>UTF-8 without signature</code> <code>UTF-8</code>  <code>cl.exe</code>  <code>gb2312</code> <code></code>  UTF-8  <code>E5A5BD</code> <code>&#39;</code> UTF-8  <code>27</code> <code>E5A5</code>  gb2312  <code></code>  <code>BD</code>  <code>27</code>  gb2312  <code>?</code>  <code>3F</code> <code>&#39;</code> VS </p>\n<p><img src=\"/images/cpp/string1.png\" alt=\"\"></p>\n<p> utf-8  gb2312 </p>\n<p> <code>UTF-8 without signature</code> </p>\n<p> CODE PAGE  65001<code></code>  UTF-8 <code>UTF-8</code>   <code>\\source-charset:utf-8</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cl /source-charset:utf-8 main.cpp /E &gt; main-gb2312.i</span></span><br></pre></td></tr></table></figure></p>\n<p>Linux  GCC  <code></code>  UTF-8<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -E main.cpp -o main-utf8.i</span></span><br></pre></td></tr></table></figure><br> <code>main-utf8.i</code>  <code></code>  <code>E5A5BD</code> UTF-8 </p>\n<p> vscode  <code>gb2312</code>  <code>gcc -E main.cpp -o main-gb2312.i</code> <code>main-gb2312.i</code> <code></code>  <code>BAC3</code> gb2312  gb2312  gcc  UTF-8  <code>&#39;</code>  <code>&#39;</code> gb2312  <code>BAC327</code> gcc  UTF-8 <code>&#39;</code><code>BAC3</code>  UTF-8 <font color=\"red\"> gb2312  UTF-8 </font> gb2312  UTF-8  gcc  <code>-finput-charset</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -finput-charset=gb2312 -E main.cpp -o main-gb2312-ic.i</span></span><br></pre></td></tr></table></figure><br> <code>main-gb2312-ic.i</code>  UTF-8  <code></code>  <code>E5A5BD</code>GCC  <code></code>  UTF-8 gcc <code></code> </p>\n<blockquote>\n<p> UTF-8  <a href=\"https://www.branah.com/unicode-converter\">https://www.branah.com/unicode-converter</a>   gb2312  <a href=\"https://www.qqxiuzi.cn/bianma/zifuji.php\">https://www.qqxiuzi.cn/bianma/zifuji.php</a> </p>\n</blockquote>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code></code><a href=\"https://docs.microsoft.com/en-us/cpp/build/reference/execution-charset-set-execution-character-set?view=msvc-160\"></a><code></code> </p>\n<p> VS  <code>/execution-charset:&lt;charset&gt;</code>  GCC  <code>-fexec-charset=&lt;charset&gt;</code>  <code>-fwide-exec-charset=&lt;charset&gt;</code></p>\n<p> GCC Ubuntu <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> c = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>c</code>  char <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c6 45 ff bd    movb    $0xbd,-0x1(%rbp)</span><br></pre></td></tr></table></figure><br> <code>0xbd</code>  <code></code>  utf-8  <code>E5A5BD</code>  char  <code></code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o -fexec-charset=gb2312</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c6 45 ff c3     movb    $0xc3,-0x1(%rbp)</span><br></pre></td></tr></table></figure><br> <code>0xc3</code>  <code></code>  gb2312  <code>BAC3</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>L</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc bd a5 e5 00    movl    $0xe5a5bd,-0x4(%rbp)</span><br></pre></td></tr></table></figure><br> <code></code>  UTF-8  <code>E5A5BD</code> <code></code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o -fexe-charset=gb2312</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc c3 ba 00 00    movl    $0xbac3,-0x4(%rbp)</span><br></pre></td></tr></table></figure></p>\n<p><code></code>  gb2312  <code>BAC3</code><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code></code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc 7d 59 00 00    movl    $0x597d,-0x4(%rbp)</span><br></pre></td></tr></table></figure><br> <code>0x597d</code>  <code></code>  UTF-32  <code>char = L&#39;&#39;</code> <code></code>  UTF-32  <code>7D</code></p>\n<p> <code>L</code>  <code></code>  <code>UTF-32</code>  wchar_t  4  2  <code></code>  <code>UTF-16</code> <code>-fwide-exec-charset</code>  <strong></strong>  <code></code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o -fwide-exec-charset=gb2312</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc 00 00 ba c3   movl    $0xc3ba0000,-0x4(%rbp)</span><br></pre></td></tr></table></figure><br> <code>gb2312</code></p>\n<p></p>\n<ol>\n<li><code>-fexec-charset</code>  <code>&#39;&#39;</code></li>\n<li><code>-fwide-exec-char</code>  <code>L</code></li>\n<li>GCC  <code></code>  <code>UTF-8</code> <code></code>  <code>UTF-32</code></li>\n</ol>\n<p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">L&#x27;&#x27;</span>;      <span class=\"comment\">// -fwide-exec-charset=gb2312</span></span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> d = <span class=\"string\">&#x27;&#x27;</span>;       <span class=\"comment\">// -fexec-charset=gb2312</span></span><br><span class=\"line\">    <span class=\"keyword\">char32_t</span> e = <span class=\"string\">U&#x27;&#x27;</span>;     <span class=\"comment\">//  -fwide-exec-charset </span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> GCC <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> a = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">char32_t</span> b = <span class=\"string\">U&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> c = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> d = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\">    <span class=\"keyword\">wint_t</span> e = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;a-&gt;%c, b-&gt;%c, c-&gt;%c, d-&gt;%c, e-&gt;%c\\n&quot;</span>, a, b, c, d, e);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> g++ main.cpp -o main</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ./main</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">a-&gt;</span><span class=\"bash\">&#125;, b-&gt;&#125;, c-&gt;?, d-&gt;&#125;, e-&gt;&#125;</span></span><br></pre></td></tr></table></figure><br><code>c</code>   <code>?</code>  ASCII  <code>a,b,d,e</code>  <code>&#125;</code> <a href=\"http://www.cplusplus.com/reference/cstdio/printf/\">printf </a><code>a,b</code>  UTF-32  <code>597D</code> <code>d,e</code>  char  <code>7D</code> <code>&#125;</code>  ASCII<code>c</code>  <code></code>  UTF-8 GCC  UTF-8   <code>BD</code> <code>char c = 0xBD</code> <code>%c</code> 127 ASCII  128~255 <code>wchar_t c=0xBD</code> <code>%lc</code>  ASCII  <code></code>  <code>char</code>  <code>wchar_t</code>  <code>%lc</code> C  <code>C</code> locale locale  locale  <code>locale</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">setlocale</span>(LC_CTYPE, <span class=\"string\">&quot;&quot;</span>);    <span class=\"comment\">//  L, u, U  locale</span></span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> a = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">char32_t</span> b = <span class=\"string\">U&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"number\">0xBD</span>;   <span class=\"comment\">// ASCII </span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> d = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\">    <span class=\"keyword\">wint_t</span> e = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;a-&gt;%lc, b-&gt;%lc, c-&gt;%lc, d-&gt;%lc, e-&gt;%lc\\n&quot;</span>, a, b, c, d, e);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a-&gt;, b-&gt;, c-&gt;, d-&gt;, e-&gt;</span><br></pre></td></tr></table></figure></p>\n<p> <code>c</code>  <code>%lc</code> <code></code> 1/2 <a href=\"https://www.w3school.com.cn/charsets/ref_html_8859.asp\"> ASCII </a> <code></code>  unicode  <code>597D</code> <code>wchar_t c=0xE5A5BD</code> UTF-8  <code></code> GCC  <code>exec-charset</code>  <code>UTF-8</code> <code>UTF-8</code> </p>\n<p> <code>exec-charset</code>  <code>%lc</code>  <code>%s</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;locale.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">setlocale</span>(LC_CTYPE, <span class=\"string\">&quot;&quot;</span>);    <span class=\"comment\">//  locale `a,b,g` </span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">wchar_t</span>* a = <span class=\"string\">L&quot;&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char32_t</span>* b = <span class=\"string\">U&quot;&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* c = <span class=\"string\">&quot;&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* d = <span class=\"string\">&quot;\\xE5\\xA5\\xBD&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> e[<span class=\"number\">4</span>] = &#123;<span class=\"number\">0xE5</span>, <span class=\"number\">0xA5</span>, <span class=\"number\">0xBD</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> f[<span class=\"number\">4</span>] = &#123;<span class=\"string\">&#x27;\\xE5&#x27;</span>, <span class=\"string\">&#x27;\\xA5&#x27;</span>, <span class=\"string\">&#x27;\\xBD&#x27;</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char32_t</span>* g = <span class=\"string\">U&quot;\\x597D&quot;</span>;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;a-&gt;%ls, b-&gt;%ls, c-&gt;%s, d-&gt;%s, e-&gt;%s, f-&gt;%s, g-&gt;%ls\\n&quot;</span>, a, b, c, d, e, f, g);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><code>c</code>  <code>%s</code> <code>a,b</code>  <code>%ls</code> </p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a-&gt;, b-&gt;, c-&gt;, d-&gt;, e-&gt;, f-&gt; g-&gt;</span><br></pre></td></tr></table></figure></p>\n<p><code>d,f</code>  <code>&quot;&quot;</code>  16 UTF-8 <code>e</code>  <code></code>  <code>\\0</code>  <code></code>  UTF-8 <code>d,e,f</code>  <code>%s</code><code>d,f</code>  <code>printf(d);printf(f);</code></p>\n<p> <code>g</code> <code>0x</code> <code>0x</code> 16 char  8 bit 16  <code>L</code>  <code>U</code>64 bit  32 bit <code>u</code>  specifier  <code>%ls</code></p>\n<blockquote>\n<ol>\n<li><p> printf(%x\\n, a);  16 </p>\n</li>\n<li><p>GCC  <code>printf</code>  <code>wprintf</code> <code>fwide</code> .</p>\n</li>\n</ol>\n</blockquote>\n<h2 id=\"C-\"><a href=\"#C-\" class=\"headerlink\" title=\"C++ \"></a>C++ </h2><p>C++  <code>cout</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* a = <span class=\"string\">&quot;&quot;</span>;</span><br><span class=\"line\">    std::cout &lt;&lt; a &lt;&lt; <span class=\"string\">&quot;-&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>std::cout &lt;&lt; &#39;&#39;;</code>  <code></code><code>&#39;&#39;</code>  UTF-8  <code>E5A5BD</code> char <code>std::cout &lt;&lt; &#39;&#39;;</code>  <code>15050173</code> <code>E5A5BD</code> </p>\n<p> <code>wcout</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> w_char* a = <span class=\"string\">L&quot;&quot;</span>;</span><br><span class=\"line\">    std::wcout &lt;&lt; a &lt;&lt; <span class=\"string\">L&quot;-&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> ASCII  <code>-</code> <br>GCC  <code>UTF-8</code> Ubuntu terminal <code>locale</code>  <code>LC_CTYPE=en_US.UTF-8</code> <code>std::wcout</code>  <code>UTF-32</code>UCS2  UCS4 <code>std::wcout</code>  <code>locale</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;locale&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    std::<span class=\"built_in\">setlocale</span>(LC_CTYPE, <span class=\"string\">&quot;&quot;</span>);       <span class=\"comment\">//  C++ </span></span><br><span class=\"line\">    <span class=\"comment\">// std::locale::global(std::locale(&quot;&quot;));</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> w_char* a = <span class=\"string\">L&quot;&quot;</span>;</span><br><span class=\"line\">    std::wcout &lt;&lt; a &lt;&lt; <span class=\"string\">L&quot;-&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>C++ <br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>source code VS 2019C++ Console App <code>ConsoleApplication1.cpp</code>  VS 2019    VS <code>GB2312</code> <code>utf-8</code> vscode  <code>ctrl+shift+p</code>  <code>encode</code>  <code>Change File Encoding</code>  vscode   <code>UTF-8</code><code>CRLF</code> </p>\n<p>unicode  UTF-8 unicode  UCS2  UCS4 UTF-8  unicode  unicode  unicode UTF-8  ASCII  gb2312  UTF-8  GBK  gb2312GBK  gb2312  UTF-8 GBK  gb2312  ASCII unicode  ASCII</p>\n<p> Windows  ultraedit  UEStudio  Linux  vim  <code>:%!xxd</code> <code>hexdump &lt;filename&gt; -C</code>  16 </p>\n<blockquote>\n<p> vim <code>:%!xxd</code>  16  gb2312  utf-8  utf-8  16  vim </p>\n</blockquote>\n<p> <code></code> <code></code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Windows  C++  <code>cl.exe</code>  <code></code> <code>chcp</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> chcp</span></span><br><span class=\"line\">Active code page: 936</span><br></pre></td></tr></table></figure><br>936  <code>gb2312</code><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> vs 2019  Console App  <code>gb2312</code> Visual Studio 2019  <code>Developer Command Prompt for VS 2019</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> <span class=\"built_in\">cd</span> myproj</span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cl main.cpp /E &gt; main-gb2312.i</span></span><br></pre></td></tr></table></figure><br> <code>main-gb2312.i</code>  <code>gb2312</code> <code></code>  <code>BAC3</code></p>\n<p> VS 2019    <code>UTF-8 with signature</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cl main.cpp /E &gt; main-utf8-sig.i</span></span><br></pre></td></tr></table></figure><br> <code>main-utf8-sig.i</code>  <code>gb2312</code> <code></code>  <code>BAC3</code></p>\n<p>but <code>UTF-8 without signature</code> <code>UTF-8</code>  <code>cl.exe</code>  <code>gb2312</code> <code></code>  UTF-8  <code>E5A5BD</code> <code>&#39;</code> UTF-8  <code>27</code> <code>E5A5</code>  gb2312  <code></code>  <code>BD</code>  <code>27</code>  gb2312  <code>?</code>  <code>3F</code> <code>&#39;</code> VS </p>\n<p><img src=\"/images/cpp/string1.png\" alt=\"\"></p>\n<p> utf-8  gb2312 </p>\n<p> <code>UTF-8 without signature</code> </p>\n<p> CODE PAGE  65001<code></code>  UTF-8 <code>UTF-8</code>   <code>\\source-charset:utf-8</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cl /source-charset:utf-8 main.cpp /E &gt; main-gb2312.i</span></span><br></pre></td></tr></table></figure></p>\n<p>Linux  GCC  <code></code>  UTF-8<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -E main.cpp -o main-utf8.i</span></span><br></pre></td></tr></table></figure><br> <code>main-utf8.i</code>  <code></code>  <code>E5A5BD</code> UTF-8 </p>\n<p> vscode  <code>gb2312</code>  <code>gcc -E main.cpp -o main-gb2312.i</code> <code>main-gb2312.i</code> <code></code>  <code>BAC3</code> gb2312  gb2312  gcc  UTF-8  <code>&#39;</code>  <code>&#39;</code> gb2312  <code>BAC327</code> gcc  UTF-8 <code>&#39;</code><code>BAC3</code>  UTF-8 <font color=\"red\"> gb2312  UTF-8 </font> gb2312  UTF-8  gcc  <code>-finput-charset</code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -finput-charset=gb2312 -E main.cpp -o main-gb2312-ic.i</span></span><br></pre></td></tr></table></figure><br> <code>main-gb2312-ic.i</code>  UTF-8  <code></code>  <code>E5A5BD</code>GCC  <code></code>  UTF-8 gcc <code></code> </p>\n<blockquote>\n<p> UTF-8  <a href=\"https://www.branah.com/unicode-converter\">https://www.branah.com/unicode-converter</a>   gb2312  <a href=\"https://www.qqxiuzi.cn/bianma/zifuji.php\">https://www.qqxiuzi.cn/bianma/zifuji.php</a> </p>\n</blockquote>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code></code><a href=\"https://docs.microsoft.com/en-us/cpp/build/reference/execution-charset-set-execution-character-set?view=msvc-160\"></a><code></code> </p>\n<p> VS  <code>/execution-charset:&lt;charset&gt;</code>  GCC  <code>-fexec-charset=&lt;charset&gt;</code>  <code>-fwide-exec-charset=&lt;charset&gt;</code></p>\n<p> GCC Ubuntu <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> c = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>c</code>  char <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c6 45 ff bd    movb    $0xbd,-0x1(%rbp)</span><br></pre></td></tr></table></figure><br> <code>0xbd</code>  <code></code>  utf-8  <code>E5A5BD</code>  char  <code></code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o -fexec-charset=gb2312</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c6 45 ff c3     movb    $0xc3,-0x1(%rbp)</span><br></pre></td></tr></table></figure><br> <code>0xc3</code>  <code></code>  gb2312  <code>BAC3</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>L</code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc bd a5 e5 00    movl    $0xe5a5bd,-0x4(%rbp)</span><br></pre></td></tr></table></figure><br> <code></code>  UTF-8  <code>E5A5BD</code> <code></code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o -fexe-charset=gb2312</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc c3 ba 00 00    movl    $0xbac3,-0x4(%rbp)</span><br></pre></td></tr></table></figure></p>\n<p><code></code>  gb2312  <code>BAC3</code><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code></code> <br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc 7d 59 00 00    movl    $0x597d,-0x4(%rbp)</span><br></pre></td></tr></table></figure><br> <code>0x597d</code>  <code></code>  UTF-32  <code>char = L&#39;&#39;</code> <code></code>  UTF-32  <code>7D</code></p>\n<p> <code>L</code>  <code></code>  <code>UTF-32</code>  wchar_t  4  2  <code></code>  <code>UTF-16</code> <code>-fwide-exec-charset</code>  <strong></strong>  <code></code><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> gcc -c main.cpp -o main.o -fwide-exec-charset=gb2312</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> objdump -Sr main.o</span></span><br><span class=\"line\"></span><br><span class=\"line\">f:  c7 45 fc 00 00 ba c3   movl    $0xc3ba0000,-0x4(%rbp)</span><br></pre></td></tr></table></figure><br> <code>gb2312</code></p>\n<p></p>\n<ol>\n<li><code>-fexec-charset</code>  <code>&#39;&#39;</code></li>\n<li><code>-fwide-exec-char</code>  <code>L</code></li>\n<li>GCC  <code></code>  <code>UTF-8</code> <code></code>  <code>UTF-32</code></li>\n</ol>\n<p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"string\">L&#x27;&#x27;</span>;      <span class=\"comment\">// -fwide-exec-charset=gb2312</span></span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> d = <span class=\"string\">&#x27;&#x27;</span>;       <span class=\"comment\">// -fexec-charset=gb2312</span></span><br><span class=\"line\">    <span class=\"keyword\">char32_t</span> e = <span class=\"string\">U&#x27;&#x27;</span>;     <span class=\"comment\">//  -fwide-exec-charset </span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> GCC <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// main.cpp</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> a = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">char32_t</span> b = <span class=\"string\">U&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> c = <span class=\"string\">&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> d = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\">    <span class=\"keyword\">wint_t</span> e = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;a-&gt;%c, b-&gt;%c, c-&gt;%c, d-&gt;%c, e-&gt;%c\\n&quot;</span>, a, b, c, d, e);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> g++ main.cpp -o main</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ./main</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">a-&gt;</span><span class=\"bash\">&#125;, b-&gt;&#125;, c-&gt;?, d-&gt;&#125;, e-&gt;&#125;</span></span><br></pre></td></tr></table></figure><br><code>c</code>   <code>?</code>  ASCII  <code>a,b,d,e</code>  <code>&#125;</code> <a href=\"http://www.cplusplus.com/reference/cstdio/printf/\">printf </a><code>a,b</code>  UTF-32  <code>597D</code> <code>d,e</code>  char  <code>7D</code> <code>&#125;</code>  ASCII<code>c</code>  <code></code>  UTF-8 GCC  UTF-8   <code>BD</code> <code>char c = 0xBD</code> <code>%c</code> 127 ASCII  128~255 <code>wchar_t c=0xBD</code> <code>%lc</code>  ASCII  <code></code>  <code>char</code>  <code>wchar_t</code>  <code>%lc</code> C  <code>C</code> locale locale  locale  <code>locale</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">setlocale</span>(LC_CTYPE, <span class=\"string\">&quot;&quot;</span>);    <span class=\"comment\">//  L, u, U  locale</span></span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> a = <span class=\"string\">L&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">char32_t</span> b = <span class=\"string\">U&#x27;&#x27;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> c = <span class=\"number\">0xBD</span>;   <span class=\"comment\">// ASCII </span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> d = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\">    <span class=\"keyword\">wint_t</span> e = <span class=\"number\">0x597D</span>;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;a-&gt;%lc, b-&gt;%lc, c-&gt;%lc, d-&gt;%lc, e-&gt;%lc\\n&quot;</span>, a, b, c, d, e);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a-&gt;, b-&gt;, c-&gt;, d-&gt;, e-&gt;</span><br></pre></td></tr></table></figure></p>\n<p> <code>c</code>  <code>%lc</code> <code></code> 1/2 <a href=\"https://www.w3school.com.cn/charsets/ref_html_8859.asp\"> ASCII </a> <code></code>  unicode  <code>597D</code> <code>wchar_t c=0xE5A5BD</code> UTF-8  <code></code> GCC  <code>exec-charset</code>  <code>UTF-8</code> <code>UTF-8</code> </p>\n<p> <code>exec-charset</code>  <code>%lc</code>  <code>%s</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;locale.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">setlocale</span>(LC_CTYPE, <span class=\"string\">&quot;&quot;</span>);    <span class=\"comment\">//  locale `a,b,g` </span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">wchar_t</span>* a = <span class=\"string\">L&quot;&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char32_t</span>* b = <span class=\"string\">U&quot;&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* c = <span class=\"string\">&quot;&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* d = <span class=\"string\">&quot;\\xE5\\xA5\\xBD&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> e[<span class=\"number\">4</span>] = &#123;<span class=\"number\">0xE5</span>, <span class=\"number\">0xA5</span>, <span class=\"number\">0xBD</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> f[<span class=\"number\">4</span>] = &#123;<span class=\"string\">&#x27;\\xE5&#x27;</span>, <span class=\"string\">&#x27;\\xA5&#x27;</span>, <span class=\"string\">&#x27;\\xBD&#x27;</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char32_t</span>* g = <span class=\"string\">U&quot;\\x597D&quot;</span>;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">&quot;a-&gt;%ls, b-&gt;%ls, c-&gt;%s, d-&gt;%s, e-&gt;%s, f-&gt;%s, g-&gt;%ls\\n&quot;</span>, a, b, c, d, e, f, g);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><code>c</code>  <code>%s</code> <code>a,b</code>  <code>%ls</code> </p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a-&gt;, b-&gt;, c-&gt;, d-&gt;, e-&gt;, f-&gt; g-&gt;</span><br></pre></td></tr></table></figure></p>\n<p><code>d,f</code>  <code>&quot;&quot;</code>  16 UTF-8 <code>e</code>  <code></code>  <code>\\0</code>  <code></code>  UTF-8 <code>d,e,f</code>  <code>%s</code><code>d,f</code>  <code>printf(d);printf(f);</code></p>\n<p> <code>g</code> <code>0x</code> <code>0x</code> 16 char  8 bit 16  <code>L</code>  <code>U</code>64 bit  32 bit <code>u</code>  specifier  <code>%ls</code></p>\n<blockquote>\n<ol>\n<li><p> printf(%x\\n, a);  16 </p>\n</li>\n<li><p>GCC  <code>printf</code>  <code>wprintf</code> <code>fwide</code> .</p>\n</li>\n</ol>\n</blockquote>\n<h2 id=\"C-\"><a href=\"#C-\" class=\"headerlink\" title=\"C++ \"></a>C++ </h2><p>C++  <code>cout</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* a = <span class=\"string\">&quot;&quot;</span>;</span><br><span class=\"line\">    std::cout &lt;&lt; a &lt;&lt; <span class=\"string\">&quot;-&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>std::cout &lt;&lt; &#39;&#39;;</code>  <code></code><code>&#39;&#39;</code>  UTF-8  <code>E5A5BD</code> char <code>std::cout &lt;&lt; &#39;&#39;;</code>  <code>15050173</code> <code>E5A5BD</code> </p>\n<p> <code>wcout</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> w_char* a = <span class=\"string\">L&quot;&quot;</span>;</span><br><span class=\"line\">    std::wcout &lt;&lt; a &lt;&lt; <span class=\"string\">L&quot;-&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> ASCII  <code>-</code> <br>GCC  <code>UTF-8</code> Ubuntu terminal <code>locale</code>  <code>LC_CTYPE=en_US.UTF-8</code> <code>std::wcout</code>  <code>UTF-32</code>UCS2  UCS4 <code>std::wcout</code>  <code>locale</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;wchar.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;locale&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    std::<span class=\"built_in\">setlocale</span>(LC_CTYPE, <span class=\"string\">&quot;&quot;</span>);       <span class=\"comment\">//  C++ </span></span><br><span class=\"line\">    <span class=\"comment\">// std::locale::global(std::locale(&quot;&quot;));</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> w_char* a = <span class=\"string\">L&quot;&quot;</span>;</span><br><span class=\"line\">    std::wcout &lt;&lt; a &lt;&lt; <span class=\"string\">L&quot;-&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>"},{"title":"C++ ","date":"2021-07-05T09:30:28.000Z","p":"cpp/declare","_content":"# const  constexpr\n`const` \n\n`constexpr`  `constexpr` \n\n `constexpr`   class`constexpr`  `nullptr`  `0` `constexpr`  `static` \n\n`constexpr` `constexprt` \n```c++\n// \nconst int i = 1;\nint j = 2;\nconstexpr int *q = &j;          // OK, q \nconstexpr int *p = &i;          // errorp  int const int \nconstexpr const int *cp = &i;   // OK\n```\n\n# \n\n```c++\ntypedef char *pstring;          // pstring  char *\nconst pstring cstr = 0;         // cstr  char \nconst pstring *ps;              // ps  char * const  char \n```\n `char *`  \n\n`const`  `pstring` `pstring`  `const pstring`  `char * const` `const pstring cstr`  const  const   `typedef const char *cpstring`\n\n# auto \n\n\n## const  auto\n1.  `auto` \n\n2. `auto`  top-level  `const` low=level  `const` top-level `const` `const auto`\n```c++\nconst int i = 123;\nconst int *const p = &i;\nauto x = pi;                // x  const int\nconst auto cx = pi;         // cx  const int\n```\n\n3.  `auto`  top-level `const`    top-level `const` `const` \n```c++\nconst int i = 123;  // top-level const\nauto &r = i;    // r  i  i r  const int &  int & \n```\n\n4.  `&`  `*`  `const`  `int`  `const int` \n```c++\nint i = 123;\nconst int j = 234;\nauto &r = i, *p = &j    // error. r  int & p  const int * \n```\n\n# decltype\n\n\n\n1. decltype      top-level `const`  \n```c++\nconst int ci = 123, &cj = ci;\ndecltype(ci) x = 0;             // x  const int\ndecltype(cj) y = x;             // y  const int &\n```\n\n2. decltype      `decltype(expr)` \n\n```c++\nint i = 123, *p = &i, &r = i;\ndecltype(r+1) b;                // OK b  int  r+1  b \ndecltype(*p) c;                 // error, c  int &  *p , c \n```\n\n3.  `(x)` `decltype((x))` \n\n\n","source":"_posts/cpp/type_declare.md","raw":"---\ntitle: C++ \ndate: 2021-07-05 17:30:28\ntags:\np: cpp/declare\n---\n# const  constexpr\n`const` \n\n`constexpr`  `constexpr` \n\n `constexpr`   class`constexpr`  `nullptr`  `0` `constexpr`  `static` \n\n`constexpr` `constexprt` \n```c++\n// \nconst int i = 1;\nint j = 2;\nconstexpr int *q = &j;          // OK, q \nconstexpr int *p = &i;          // errorp  int const int \nconstexpr const int *cp = &i;   // OK\n```\n\n# \n\n```c++\ntypedef char *pstring;          // pstring  char *\nconst pstring cstr = 0;         // cstr  char \nconst pstring *ps;              // ps  char * const  char \n```\n `char *`  \n\n`const`  `pstring` `pstring`  `const pstring`  `char * const` `const pstring cstr`  const  const   `typedef const char *cpstring`\n\n# auto \n\n\n## const  auto\n1.  `auto` \n\n2. `auto`  top-level  `const` low=level  `const` top-level `const` `const auto`\n```c++\nconst int i = 123;\nconst int *const p = &i;\nauto x = pi;                // x  const int\nconst auto cx = pi;         // cx  const int\n```\n\n3.  `auto`  top-level `const`    top-level `const` `const` \n```c++\nconst int i = 123;  // top-level const\nauto &r = i;    // r  i  i r  const int &  int & \n```\n\n4.  `&`  `*`  `const`  `int`  `const int` \n```c++\nint i = 123;\nconst int j = 234;\nauto &r = i, *p = &j    // error. r  int & p  const int * \n```\n\n# decltype\n\n\n\n1. decltype      top-level `const`  \n```c++\nconst int ci = 123, &cj = ci;\ndecltype(ci) x = 0;             // x  const int\ndecltype(cj) y = x;             // y  const int &\n```\n\n2. decltype      `decltype(expr)` \n\n```c++\nint i = 123, *p = &i, &r = i;\ndecltype(r+1) b;                // OK b  int  r+1  b \ndecltype(*p) c;                 // error, c  int &  *p , c \n```\n\n3.  `(x)` `decltype((x))` \n\n\n","slug":"cpp/type_declare","published":1,"updated":"2021-07-06T01:03:00.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90r001rp0dja0sv3hqv","content":"<h1 id=\"const--constexpr\"><a href=\"#const--constexpr\" class=\"headerlink\" title=\"const  constexpr\"></a>const  constexpr</h1><p><code>const</code> </p>\n<p><code>constexpr</code>  <code>constexpr</code> </p>\n<p> <code>constexpr</code>   class<code>constexpr</code>  <code>nullptr</code>  <code>0</code> <code>constexpr</code>  <code>static</code> </p>\n<p><code>constexpr</code> <code>constexprt</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> j = <span class=\"number\">2</span>;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">int</span> *q = &amp;j;          <span class=\"comment\">// OK, q </span></span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">int</span> *p = &amp;i;          <span class=\"comment\">// errorp  int const int </span></span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *cp = &amp;i;   <span class=\"comment\">// OK</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">char</span> *pstring;          <span class=\"comment\">// pstring  char *</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> pstring cstr = <span class=\"number\">0</span>;         <span class=\"comment\">// cstr  char </span></span><br><span class=\"line\"><span class=\"keyword\">const</span> pstring *ps;              <span class=\"comment\">// ps  char * const  char </span></span><br></pre></td></tr></table></figure><br> <code>char *</code>  </p>\n<p><code>const</code>  <code>pstring</code> <code>pstring</code>  <code>const pstring</code>  <code>char * const</code> <code>const pstring cstr</code>  const  const   <code>typedef const char *cpstring</code></p>\n<h1 id=\"auto\"><a href=\"#auto\" class=\"headerlink\" title=\"auto\"></a>auto</h1><p></p>\n<h2 id=\"const--auto\"><a href=\"#const--auto\" class=\"headerlink\" title=\"const  auto\"></a>const  auto</h2><ol>\n<li><p> <code>auto</code> </p>\n</li>\n<li><p><code>auto</code>  top-level  <code>const</code> low=level  <code>const</code> top-level <code>const</code> <code>const auto</code></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *<span class=\"keyword\">const</span> p = &amp;i;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> x = pi;                <span class=\"comment\">// x  const int</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">auto</span> cx = pi;         <span class=\"comment\">// cx  const int</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p> <code>auto</code>  top-level <code>const</code>    top-level <code>const</code> <code>const</code> </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;  <span class=\"comment\">// top-level const</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> &amp;r = i;    <span class=\"comment\">// r  i  i r  const int &amp;  int &amp; </span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p> <code>&amp;</code>  <code>*</code>  <code>const</code>  <code>int</code>  <code>const int</code> </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> j = <span class=\"number\">234</span>;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> &amp;r = i, *p = &amp;j    <span class=\"comment\">// error. r  int &amp; p  const int * </span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h1 id=\"decltype\"><a href=\"#decltype\" class=\"headerlink\" title=\"decltype\"></a>decltype</h1><p></p>\n<ol>\n<li><p>decltype      top-level <code>const</code>  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> ci = <span class=\"number\">123</span>, &amp;cj = ci;</span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(ci) x = <span class=\"number\">0</span>;             <span class=\"comment\">// x  const int</span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(cj) y = x;             <span class=\"comment\">// y  const int &amp;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>decltype      <code>decltype(expr)</code> </p>\n</li>\n</ol>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">123</span>, *p = &amp;i, &amp;r = i;</span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(r+<span class=\"number\">1</span>) b;                <span class=\"comment\">// OK b  int  r+1  b </span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(*p) c;                 <span class=\"comment\">// error, c  int &amp;  *p , c </span></span><br></pre></td></tr></table></figure>\n<ol>\n<li> <code>(x)</code> <code>decltype((x))</code> </li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"const--constexpr\"><a href=\"#const--constexpr\" class=\"headerlink\" title=\"const  constexpr\"></a>const  constexpr</h1><p><code>const</code> </p>\n<p><code>constexpr</code>  <code>constexpr</code> </p>\n<p> <code>constexpr</code>   class<code>constexpr</code>  <code>nullptr</code>  <code>0</code> <code>constexpr</code>  <code>static</code> </p>\n<p><code>constexpr</code> <code>constexprt</code> <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> j = <span class=\"number\">2</span>;</span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">int</span> *q = &amp;j;          <span class=\"comment\">// OK, q </span></span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">int</span> *p = &amp;i;          <span class=\"comment\">// errorp  int const int </span></span><br><span class=\"line\"><span class=\"keyword\">constexpr</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *cp = &amp;i;   <span class=\"comment\">// OK</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">char</span> *pstring;          <span class=\"comment\">// pstring  char *</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> pstring cstr = <span class=\"number\">0</span>;         <span class=\"comment\">// cstr  char </span></span><br><span class=\"line\"><span class=\"keyword\">const</span> pstring *ps;              <span class=\"comment\">// ps  char * const  char </span></span><br></pre></td></tr></table></figure><br> <code>char *</code>  </p>\n<p><code>const</code>  <code>pstring</code> <code>pstring</code>  <code>const pstring</code>  <code>char * const</code> <code>const pstring cstr</code>  const  const   <code>typedef const char *cpstring</code></p>\n<h1 id=\"auto\"><a href=\"#auto\" class=\"headerlink\" title=\"auto\"></a>auto</h1><p></p>\n<h2 id=\"const--auto\"><a href=\"#const--auto\" class=\"headerlink\" title=\"const  auto\"></a>const  auto</h2><ol>\n<li><p> <code>auto</code> </p>\n</li>\n<li><p><code>auto</code>  top-level  <code>const</code> low=level  <code>const</code> top-level <code>const</code> <code>const auto</code></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> *<span class=\"keyword\">const</span> p = &amp;i;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> x = pi;                <span class=\"comment\">// x  const int</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">auto</span> cx = pi;         <span class=\"comment\">// cx  const int</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p> <code>auto</code>  top-level <code>const</code>    top-level <code>const</code> <code>const</code> </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;  <span class=\"comment\">// top-level const</span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> &amp;r = i;    <span class=\"comment\">// r  i  i r  const int &amp;  int &amp; </span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p> <code>&amp;</code>  <code>*</code>  <code>const</code>  <code>int</code>  <code>const int</code> </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">123</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> j = <span class=\"number\">234</span>;</span><br><span class=\"line\"><span class=\"keyword\">auto</span> &amp;r = i, *p = &amp;j    <span class=\"comment\">// error. r  int &amp; p  const int * </span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h1 id=\"decltype\"><a href=\"#decltype\" class=\"headerlink\" title=\"decltype\"></a>decltype</h1><p></p>\n<ol>\n<li><p>decltype      top-level <code>const</code>  </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> ci = <span class=\"number\">123</span>, &amp;cj = ci;</span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(ci) x = <span class=\"number\">0</span>;             <span class=\"comment\">// x  const int</span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(cj) y = x;             <span class=\"comment\">// y  const int &amp;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>decltype      <code>decltype(expr)</code> </p>\n</li>\n</ol>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">123</span>, *p = &amp;i, &amp;r = i;</span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(r+<span class=\"number\">1</span>) b;                <span class=\"comment\">// OK b  int  r+1  b </span></span><br><span class=\"line\"><span class=\"keyword\">decltype</span>(*p) c;                 <span class=\"comment\">// error, c  int &amp;  *p , c </span></span><br></pre></td></tr></table></figure>\n<ol>\n<li> <code>(x)</code> <code>decltype((x))</code> </li>\n</ol>\n"},{"title":"cv.methods","p":"cv/methods1","date":"2020-05-27T03:30:03.000Z","mathjax":true,"_content":"\n CV       \n\n<!-- more -->\n\n# \n## crop resize\n\n\n\n## resize\nresize \n","source":"_posts/cv/methods.md","raw":"---\ntitle: cv.methods\np: cv/methods1\ndate: 2020-05-27 11:30:03\ntags: CV\nmathjax: true\n---\n\n CV       \n\n<!-- more -->\n\n# \n## crop resize\n\n\n\n## resize\nresize \n","slug":"cv/methods","published":1,"updated":"2021-01-18T07:04:04.578Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90r001up0dj8zkj88yz","content":"<p> CV       </p>\n<span id=\"more\"></span>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"crop-resize\"><a href=\"#crop-resize\" class=\"headerlink\" title=\"crop resize\"></a>crop resize</h2><p></p>\n<h2 id=\"resize\"><a href=\"#resize\" class=\"headerlink\" title=\"resize\"></a>resize</h2><p>resize </p>\n","site":{"data":{}},"excerpt":"<p> CV       </p>","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"crop-resize\"><a href=\"#crop-resize\" class=\"headerlink\" title=\"crop resize\"></a>crop resize</h2><p></p>\n<h2 id=\"resize\"><a href=\"#resize\" class=\"headerlink\" title=\"resize\"></a>resize</h2><p>resize </p>"},{"title":"Histogram Equalization","date":"2020-06-23T10:07:00.000Z","_content":"","source":"_posts/dip/hist_equal.md","raw":"---\ntitle: Histogram Equalization\ndate: 2020-06-23 18:07:00\ntags:\n---\n","slug":"dip/hist_equal","published":1,"updated":"2020-06-23T10:07:00.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90s001vp0dj3uyd6f8o","content":"","site":{"data":{}},"excerpt":"","more":""},{"p":"dl/metrics","title":"Metrics","date":"2021-02-20T02:09:36.000Z","_content":"\n/\n<!-- more -->\n\n- Precision\n$$\\frac {\\text{true positives}}{\\text{true positives + false positives}}$$\n\n- Recall\n$$TPR=\\frac {\\text{true positives}}{\\text{true positives + false negatives}}$$\n <b></b>  positive  negative \n\n- F1 score\n$$\\frac {2 \\times \\text {precision} \\times \\text{recall}} {\\text{precision + recall}}$$\nF1 score  precision  recall  precision  recall F1 score  precision, recall  $\\in [0,1]$ F1 score $\\in [0,1]$F1 score \n\n\n- ROC curve\n\\\nreceiver operating characteristic curveTPRFPR FPR  TPR\n$$FPR=\\frac {\\text{false positives}}{\\text{false positives + true negatives}}$$\n positive  score score  positive negative\\\nROC \n  1. `(0,1)`FPR=0TPR=1<b>0</b>\n  2. `(1,0)`FPR=1, TPR=0<b>0</b>\n  3. `(0,0)`FPR=TRP=0<b>0</b> negative\n  4. `(1,1)`FPR=TRP=1<b>0</b> positive\n\n   1  0  `3.`  `4.`  ROC  `(0,0)`  `(1,1)`  ROC  0  1\n  \\\n\n   ROC  ISO  $y=ax+b$\n  $$a=\\frac N P$$\n  ISO \n    1.  `b=0` b  ROC \n\n\n- AUC\n\\\nROC Area under the ROC curve AUC=1 AUC=0.5 AUC < 0.5 \n\\\nAUC \n  1.  (FPR, TPR)\n  2.  FPR  `i`   `i+1`  FPR  `dx`\n  3.   `i`  `i+1`  TPR  `y`\n  4.  `ds=y * dx`\n  5.  AUC \n\n### \n1.  Recall /  hit rate /  Sensitivity /TPR\n2. FPR / fall-out\n2.  Specificity / TNR  = 1-FPR","source":"_posts/dl/Metrics.md","raw":"---\np: dl/metrics\ntitle: Metrics\ndate: 2021-02-20 10:09:36\ntags:\n---\n\n/\n<!-- more -->\n\n- Precision\n$$\\frac {\\text{true positives}}{\\text{true positives + false positives}}$$\n\n- Recall\n$$TPR=\\frac {\\text{true positives}}{\\text{true positives + false negatives}}$$\n <b></b>  positive  negative \n\n- F1 score\n$$\\frac {2 \\times \\text {precision} \\times \\text{recall}} {\\text{precision + recall}}$$\nF1 score  precision  recall  precision  recall F1 score  precision, recall  $\\in [0,1]$ F1 score $\\in [0,1]$F1 score \n\n\n- ROC curve\n\\\nreceiver operating characteristic curveTPRFPR FPR  TPR\n$$FPR=\\frac {\\text{false positives}}{\\text{false positives + true negatives}}$$\n positive  score score  positive negative\\\nROC \n  1. `(0,1)`FPR=0TPR=1<b>0</b>\n  2. `(1,0)`FPR=1, TPR=0<b>0</b>\n  3. `(0,0)`FPR=TRP=0<b>0</b> negative\n  4. `(1,1)`FPR=TRP=1<b>0</b> positive\n\n   1  0  `3.`  `4.`  ROC  `(0,0)`  `(1,1)`  ROC  0  1\n  \\\n\n   ROC  ISO  $y=ax+b$\n  $$a=\\frac N P$$\n  ISO \n    1.  `b=0` b  ROC \n\n\n- AUC\n\\\nROC Area under the ROC curve AUC=1 AUC=0.5 AUC < 0.5 \n\\\nAUC \n  1.  (FPR, TPR)\n  2.  FPR  `i`   `i+1`  FPR  `dx`\n  3.   `i`  `i+1`  TPR  `y`\n  4.  `ds=y * dx`\n  5.  AUC \n\n### \n1.  Recall /  hit rate /  Sensitivity /TPR\n2. FPR / fall-out\n2.  Specificity / TNR  = 1-FPR","slug":"dl/Metrics","published":1,"updated":"2021-02-20T04:04:21.462Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90t001yp0djhsh2fl49","content":"<p>/<br><span id=\"more\"></span></p>\n<ul>\n<li><p>Precision</p>\n<script type=\"math/tex; mode=display\">\\frac {\\text{true positives}}{\\text{true positives + false positives}}</script></li>\n<li><p>Recall</p>\n<script type=\"math/tex; mode=display\">TPR=\\frac {\\text{true positives}}{\\text{true positives + false negatives}}</script><p> <b></b>  positive  negative </p>\n</li>\n<li><p>F1 score</p>\n<script type=\"math/tex; mode=display\">\\frac {2 \\times \\text {precision} \\times \\text{recall}} {\\text{precision + recall}}</script><p>F1 score  precision  recall  precision  recall F1 score  precision, recall  $\\in [0,1]$ F1 score $\\in [0,1]$F1 score </p>\n</li>\n</ul>\n<ul>\n<li><p>ROC curve<br>\\<br>receiver operating characteristic curveTPRFPR FPR  TPR</p>\n<script type=\"math/tex; mode=display\">FPR=\\frac {\\text{false positives}}{\\text{false positives + true negatives}}</script><p> positive  score score  positive negative\\<br>ROC </p>\n<ol>\n<li><code>(0,1)</code>FPR=0TPR=1<b>0</b></li>\n<li><code>(1,0)</code>FPR=1, TPR=0<b>0</b></li>\n<li><code>(0,0)</code>FPR=TRP=0<b>0</b> negative</li>\n<li><code>(1,1)</code>FPR=TRP=1<b>0</b> positive</li>\n</ol>\n<p> 1  0  <code>3.</code>  <code>4.</code>  ROC  <code>(0,0)</code>  <code>(1,1)</code>  ROC  0  1<br>\\</p>\n<p> ROC  ISO  $y=ax+b$</p>\n<script type=\"math/tex; mode=display\">a=\\frac N P</script><p>ISO </p>\n<ol>\n<li> <code>b=0</code> b  ROC </li>\n</ol>\n</li>\n</ul>\n<ul>\n<li>AUC<br>\\<br>ROC Area under the ROC curve AUC=1 AUC=0.5 AUC &lt; 0.5 <br>\\<br>AUC <ol>\n<li> (FPR, TPR)</li>\n<li> FPR  <code>i</code>   <code>i+1</code>  FPR  <code>dx</code></li>\n<li>  <code>i</code>  <code>i+1</code>  TPR  <code>y</code></li>\n<li> <code>ds=y * dx</code></li>\n<li> AUC </li>\n</ol>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li> Recall /  hit rate /  Sensitivity /TPR</li>\n<li>FPR / fall-out</li>\n<li> Specificity / TNR  = 1-FPR</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>/<br>","more":"</p>\n<ul>\n<li><p>Precision</p>\n<script type=\"math/tex; mode=display\">\\frac {\\text{true positives}}{\\text{true positives + false positives}}</script></li>\n<li><p>Recall</p>\n<script type=\"math/tex; mode=display\">TPR=\\frac {\\text{true positives}}{\\text{true positives + false negatives}}</script><p> <b></b>  positive  negative </p>\n</li>\n<li><p>F1 score</p>\n<script type=\"math/tex; mode=display\">\\frac {2 \\times \\text {precision} \\times \\text{recall}} {\\text{precision + recall}}</script><p>F1 score  precision  recall  precision  recall F1 score  precision, recall  $\\in [0,1]$ F1 score $\\in [0,1]$F1 score </p>\n</li>\n</ul>\n<ul>\n<li><p>ROC curve<br>\\<br>receiver operating characteristic curveTPRFPR FPR  TPR</p>\n<script type=\"math/tex; mode=display\">FPR=\\frac {\\text{false positives}}{\\text{false positives + true negatives}}</script><p> positive  score score  positive negative\\<br>ROC </p>\n<ol>\n<li><code>(0,1)</code>FPR=0TPR=1<b>0</b></li>\n<li><code>(1,0)</code>FPR=1, TPR=0<b>0</b></li>\n<li><code>(0,0)</code>FPR=TRP=0<b>0</b> negative</li>\n<li><code>(1,1)</code>FPR=TRP=1<b>0</b> positive</li>\n</ol>\n<p> 1  0  <code>3.</code>  <code>4.</code>  ROC  <code>(0,0)</code>  <code>(1,1)</code>  ROC  0  1<br>\\</p>\n<p> ROC  ISO  $y=ax+b$</p>\n<script type=\"math/tex; mode=display\">a=\\frac N P</script><p>ISO </p>\n<ol>\n<li> <code>b=0</code> b  ROC </li>\n</ol>\n</li>\n</ul>\n<ul>\n<li>AUC<br>\\<br>ROC Area under the ROC curve AUC=1 AUC=0.5 AUC &lt; 0.5 <br>\\<br>AUC <ol>\n<li> (FPR, TPR)</li>\n<li> FPR  <code>i</code>   <code>i+1</code>  FPR  <code>dx</code></li>\n<li>  <code>i</code>  <code>i+1</code>  TPR  <code>y</code></li>\n<li> <code>ds=y * dx</code></li>\n<li> AUC </li>\n</ol>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li> Recall /  hit rate /  Sensitivity /TPR</li>\n<li>FPR / fall-out</li>\n<li> Specificity / TNR  = 1-FPR</li>\n</ol>"},{"p":"dl/training_ops","title":"Training Operations","date":"2021-02-19T06:16:51.000Z","_content":"\n\n# Weight Decay\n\n\n# Momentum\n","source":"_posts/dl/Training-Operations.md","raw":"---\np: dl/training_ops\ntitle: Training Operations\ndate: 2021-02-19 14:16:51\ntags:\n---\n\n\n# Weight Decay\n\n\n# Momentum\n","slug":"dl/Training-Operations","published":1,"updated":"2021-02-19T06:18:41.500Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90u0020p0dj7jx9e3uv","content":"<p></p>\n<h1 id=\"Weight-Decay\"><a href=\"#Weight-Decay\" class=\"headerlink\" title=\"Weight Decay\"></a>Weight Decay</h1><p></p>\n<h1 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Momentum\"></a>Momentum</h1>","site":{"data":{}},"excerpt":"","more":"<p></p>\n<h1 id=\"Weight-Decay\"><a href=\"#Weight-Decay\" class=\"headerlink\" title=\"Weight Decay\"></a>Weight Decay</h1><p></p>\n<h1 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Momentum\"></a>Momentum</h1>"},{"title":"Convolution","date":"2021-02-19T01:27:01.000Z","p":"dl/conv","mathjax":true,"_content":"# \n holes $\\alpha$ $k$ $\\alpha(k-1)+1$\n\n\n\nDilated Convolution  long-range informationDilated Convolution  kernel  Hybrid Dilated ConvolutionHDC\n\nHDC \n1.  1  [2,4,6]  2\n2.  [1,2,5,1,2,5] \n3. \n$$M_i=\\max[M_{i+1}-2r_i, 2r_i-M_{i+1}, r_i]$$\n $r_i$  `i` $M_i$  `i`  dilated rate `L` $M_L=r_L$\n\n\n# \n feature shape  $(c_0,h,w)$original filter  $(k,k,c_0,c_1)$ feature shape  $(c_1,h,w)$ n  feature shape  $(c_0/n, h, w)$ filter shape  $(k,k,c_0/n, c_1/n)$ feature shape  $(c_1/n, h, w)$ channel  concatenate feature shape $(c_1, h, w)$\n$$k \\times k \\times \\frac {c_0} n \\times \\frac {c_1} n \\times n$$\n\n\n# Bottleneck\n shape  $(c_0, h, w)$ shape  $(c_1, h, w)$ filter  $k \\times k \\times c_0 \\times c_1$ bottleneck  $1\\times 1 \\times c_0 \\times c_2$  filter $k \\times k \\times c_2 \\times c_2$  filter $1 \\times 1 \\times c_2 \\times c_1$  filter $c_2 < c_1, c_0$\n\n# Depthwise Conv\n shape  $(c_0, h, w)$ channel  filter  $k \\times k \\times c_0$ filter shape  $c_1$ $(c_0, h, w)$  $1 \\times 1 \\times c_0 \\times c_1$ $(c_1, h, w)$ \n\n# \n [deformable conv](/obj_det/two_stage)","source":"_posts/dl/conv.md","raw":"---\ntitle: Convolution\ndate: 2021-02-19 09:27:01\ntags: CNN, Deep Learning\np: dl/conv\nmathjax: true\n---\n# \n holes $\\alpha$ $k$ $\\alpha(k-1)+1$\n\n\n\nDilated Convolution  long-range informationDilated Convolution  kernel  Hybrid Dilated ConvolutionHDC\n\nHDC \n1.  1  [2,4,6]  2\n2.  [1,2,5,1,2,5] \n3. \n$$M_i=\\max[M_{i+1}-2r_i, 2r_i-M_{i+1}, r_i]$$\n $r_i$  `i` $M_i$  `i`  dilated rate `L` $M_L=r_L$\n\n\n# \n feature shape  $(c_0,h,w)$original filter  $(k,k,c_0,c_1)$ feature shape  $(c_1,h,w)$ n  feature shape  $(c_0/n, h, w)$ filter shape  $(k,k,c_0/n, c_1/n)$ feature shape  $(c_1/n, h, w)$ channel  concatenate feature shape $(c_1, h, w)$\n$$k \\times k \\times \\frac {c_0} n \\times \\frac {c_1} n \\times n$$\n\n\n# Bottleneck\n shape  $(c_0, h, w)$ shape  $(c_1, h, w)$ filter  $k \\times k \\times c_0 \\times c_1$ bottleneck  $1\\times 1 \\times c_0 \\times c_2$  filter $k \\times k \\times c_2 \\times c_2$  filter $1 \\times 1 \\times c_2 \\times c_1$  filter $c_2 < c_1, c_0$\n\n# Depthwise Conv\n shape  $(c_0, h, w)$ channel  filter  $k \\times k \\times c_0$ filter shape  $c_1$ $(c_0, h, w)$  $1 \\times 1 \\times c_0 \\times c_1$ $(c_1, h, w)$ \n\n# \n [deformable conv](/obj_det/two_stage)","slug":"dl/conv","published":1,"updated":"2021-03-06T10:23:39.491Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90v0021p0djh6qc1q6e","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> holes $\\alpha$ $k$ $\\alpha(k-1)+1$</p>\n<p></p>\n<p>Dilated Convolution  long-range informationDilated Convolution  kernel  Hybrid Dilated ConvolutionHDC</p>\n<p>HDC </p>\n<ol>\n<li> 1  [2,4,6]  2</li>\n<li> [1,2,5,1,2,5] </li>\n<li><script type=\"math/tex; mode=display\">M_i=\\max[M_{i+1}-2r_i, 2r_i-M_{i+1}, r_i]</script> $r_i$  <code>i</code> $M_i$  <code>i</code>  dilated rate <code>L</code> $M_L=r_L$</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> feature shape  $(c_0,h,w)$original filter  $(k,k,c_0,c_1)$ feature shape  $(c_1,h,w)$ n  feature shape  $(c_0/n, h, w)$ filter shape  $(k,k,c_0/n, c_1/n)$ feature shape  $(c_1/n, h, w)$ channel  concatenate feature shape $(c_1, h, w)$</p>\n<script type=\"math/tex; mode=display\">k \\times k \\times \\frac {c_0} n \\times \\frac {c_1} n \\times n</script><p></p>\n<h1 id=\"Bottleneck\"><a href=\"#Bottleneck\" class=\"headerlink\" title=\"Bottleneck\"></a>Bottleneck</h1><p> shape  $(c_0, h, w)$ shape  $(c_1, h, w)$ filter  $k \\times k \\times c_0 \\times c_1$ bottleneck  $1\\times 1 \\times c_0 \\times c_2$  filter $k \\times k \\times c_2 \\times c_2$  filter $1 \\times 1 \\times c_2 \\times c_1$  filter $c_2 &lt; c_1, c_0$</p>\n<h1 id=\"Depthwise-Conv\"><a href=\"#Depthwise-Conv\" class=\"headerlink\" title=\"Depthwise Conv\"></a>Depthwise Conv</h1><p> shape  $(c_0, h, w)$ channel  filter  $k \\times k \\times c_0$ filter shape  $c_1$ $(c_0, h, w)$  $1 \\times 1 \\times c_0 \\times c_1$ $(c_1, h, w)$ </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <a href=\"/obj_det/two_stage\">deformable conv</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> holes $\\alpha$ $k$ $\\alpha(k-1)+1$</p>\n<p></p>\n<p>Dilated Convolution  long-range informationDilated Convolution  kernel  Hybrid Dilated ConvolutionHDC</p>\n<p>HDC </p>\n<ol>\n<li> 1  [2,4,6]  2</li>\n<li> [1,2,5,1,2,5] </li>\n<li><script type=\"math/tex; mode=display\">M_i=\\max[M_{i+1}-2r_i, 2r_i-M_{i+1}, r_i]</script> $r_i$  <code>i</code> $M_i$  <code>i</code>  dilated rate <code>L</code> $M_L=r_L$</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> feature shape  $(c_0,h,w)$original filter  $(k,k,c_0,c_1)$ feature shape  $(c_1,h,w)$ n  feature shape  $(c_0/n, h, w)$ filter shape  $(k,k,c_0/n, c_1/n)$ feature shape  $(c_1/n, h, w)$ channel  concatenate feature shape $(c_1, h, w)$</p>\n<script type=\"math/tex; mode=display\">k \\times k \\times \\frac {c_0} n \\times \\frac {c_1} n \\times n</script><p></p>\n<h1 id=\"Bottleneck\"><a href=\"#Bottleneck\" class=\"headerlink\" title=\"Bottleneck\"></a>Bottleneck</h1><p> shape  $(c_0, h, w)$ shape  $(c_1, h, w)$ filter  $k \\times k \\times c_0 \\times c_1$ bottleneck  $1\\times 1 \\times c_0 \\times c_2$  filter $k \\times k \\times c_2 \\times c_2$  filter $1 \\times 1 \\times c_2 \\times c_1$  filter $c_2 &lt; c_1, c_0$</p>\n<h1 id=\"Depthwise-Conv\"><a href=\"#Depthwise-Conv\" class=\"headerlink\" title=\"Depthwise Conv\"></a>Depthwise Conv</h1><p> shape  $(c_0, h, w)$ channel  filter  $k \\times k \\times c_0$ filter shape  $c_1$ $(c_0, h, w)$  $1 \\times 1 \\times c_0 \\times c_1$ $(c_1, h, w)$ </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <a href=\"/obj_det/two_stage\">deformable conv</a></p>\n"},{"title":"Normalization","date":"2021-03-08T03:26:46.000Z","_content":"\n# Batch Norm\n channel  `(B,H,W)`  channel \n$$y=\\frac {x-E[x]} {\\sqrt{Var[x]+\\epsilon}} \\cdot \\gamma + \\beta$$\n\n1.  mini-batch\n2.  W  b  BN \n3.  sigmoid  BN \n\n# Layer Norm\nLayer Norm  `(C,H,W)` \n\n# Instance Norm\nInstance Norm  channel  `(H,W)` \n\n# Group Norm\n Layer Norm  Group Norm  `(C,H,W)`  channel  `G`  `(C/G, H, W)` \n\n","source":"_posts/dl/norm.md","raw":"---\ntitle: Normalization\ndate: 2021-03-08 11:26:46\ntags:\n---\n\n# Batch Norm\n channel  `(B,H,W)`  channel \n$$y=\\frac {x-E[x]} {\\sqrt{Var[x]+\\epsilon}} \\cdot \\gamma + \\beta$$\n\n1.  mini-batch\n2.  W  b  BN \n3.  sigmoid  BN \n\n# Layer Norm\nLayer Norm  `(C,H,W)` \n\n# Instance Norm\nInstance Norm  channel  `(H,W)` \n\n# Group Norm\n Layer Norm  Group Norm  `(C,H,W)`  channel  `G`  `(C/G, H, W)` \n\n","slug":"dl/norm","published":1,"updated":"2021-03-12T07:39:48.056Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90v0023p0dja9tdfcrg","content":"<h1 id=\"Batch-Norm\"><a href=\"#Batch-Norm\" class=\"headerlink\" title=\"Batch Norm\"></a>Batch Norm</h1><p> channel  <code>(B,H,W)</code>  channel </p>\n<script type=\"math/tex; mode=display\">y=\\frac {x-E[x]} {\\sqrt{Var[x]+\\epsilon}} \\cdot \\gamma + \\beta</script><p></p>\n<ol>\n<li> mini-batch</li>\n<li> W  b  BN </li>\n<li> sigmoid  BN </li>\n</ol>\n<h1 id=\"Layer-Norm\"><a href=\"#Layer-Norm\" class=\"headerlink\" title=\"Layer Norm\"></a>Layer Norm</h1><p>Layer Norm  <code>(C,H,W)</code> </p>\n<h1 id=\"Instance-Norm\"><a href=\"#Instance-Norm\" class=\"headerlink\" title=\"Instance Norm\"></a>Instance Norm</h1><p>Instance Norm  channel  <code>(H,W)</code> </p>\n<h1 id=\"Group-Norm\"><a href=\"#Group-Norm\" class=\"headerlink\" title=\"Group Norm\"></a>Group Norm</h1><p> Layer Norm  Group Norm  <code>(C,H,W)</code>  channel  <code>G</code>  <code>(C/G, H, W)</code> </p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Batch-Norm\"><a href=\"#Batch-Norm\" class=\"headerlink\" title=\"Batch Norm\"></a>Batch Norm</h1><p> channel  <code>(B,H,W)</code>  channel </p>\n<script type=\"math/tex; mode=display\">y=\\frac {x-E[x]} {\\sqrt{Var[x]+\\epsilon}} \\cdot \\gamma + \\beta</script><p></p>\n<ol>\n<li> mini-batch</li>\n<li> W  b  BN </li>\n<li> sigmoid  BN </li>\n</ol>\n<h1 id=\"Layer-Norm\"><a href=\"#Layer-Norm\" class=\"headerlink\" title=\"Layer Norm\"></a>Layer Norm</h1><p>Layer Norm  <code>(C,H,W)</code> </p>\n<h1 id=\"Instance-Norm\"><a href=\"#Instance-Norm\" class=\"headerlink\" title=\"Instance Norm\"></a>Instance Norm</h1><p>Instance Norm  channel  <code>(H,W)</code> </p>\n<h1 id=\"Group-Norm\"><a href=\"#Group-Norm\" class=\"headerlink\" title=\"Group Norm\"></a>Group Norm</h1><p> Layer Norm  Group Norm  <code>(C,H,W)</code>  channel  <code>G</code>  <code>(C/G, H, W)</code> </p>\n"},{"title":"Receptive Field","date":"2021-02-18T02:51:00.000Z","p":"dl/receptive_field","mathjax":true,"_content":"\n# Size\n\n fully CNN  `k` layer  receptive field \n$$l_k=l_{k-1} + ((f_k-1)*\\prod_{i=1}^{k-1} s_i)$$\n$l_{k-1}$  `k-1` layer  receptive field $f_k$  `k` layer  filter $s_i$  `i` layer  stride  $l_1$ $l_1=f_1$\n\n\n\n `L`  layer layer  feature map  $f_l, \\ l=1,...,L$ layer  filter  $k_l$stride  $s_l$ $r_l$  layer  feature map $f_l$  receptive field $r_l$  $f_l$  $f_L$  feature map$r_L=1$\n\n$r_{L-1}=k_L$ feature map $k_L$  $r_l$ $r_{l-1}$\n\n $k_l=1$ $s_l=1$ $r_{l-1}=r_l$ $s_l>1$ $r_{l-1}=s_l \\cdot r_l -(s_l-1)$ $r_l$  $f_{l-1}$  $s_l-1$  $r_{l-1}=(s_l-1)\\cdot(r_l-1)+ r_l=s_l \\cdot r_l-s_l+1$\n\n $k_l>1$ $f_{l-1}$  $k_l-1$ \n$$r_{l-1}=s_l \\cdot r_l + (k_l-s_l)$$\n$r_L=1, \\ r_{L-1}=k_L$\n$$r_{L-2}=s_{L-1} r_{L-1}+(k_{L-1}-s_{L-1})=s_{L-1}(k_L-1)+k_{L-1}$$\n$$r_{L-3}=s_{L-2} r_{L-2}+(k_{L-2}-s_{L-2})=s_{L-2}s_{L-1}(k_L-1)+s_{L-2}(k_{L-1}-1)+k_{L-2}$$\n$$\\cdots$$\n$$r_{l}=s_{l+1}\\cdots s_{L-1}(k_L-1)+s_{l+1}\\cdots s_{L-2}(k_{L-1}-1)+ \\cdots s_{l+1}(k_{l+2}-1)+k_{l+1}=1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right]$$\n $$\\prod_{l+1}^{l}s_i=1$$\n\n\n$$\\begin{aligned} r_{l-1}&=1+\\sum_{j=l}^{L} \\left[(k_{j}-1) \\prod_{i=l}^{j-1}s_i \\right] \\\\ &=1+(k_l-1)+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\cdot s_l \\right] \\\\&=k_l-s_l+s_l \\left(1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right] \\right) \\\\&=s_l \\cdot r_l +k_l-s_l\\end{aligned}$$\n\n\noutput feature size \n$$w_l=\\frac {w_{l-1}+2p_l-k_l} {s_l}+1$$\n $w$  $h$  2D image \n\n# Region\n feature map  region Receptive Field region  feature map  $f_L(i,j)$ region \n\n $f_l$  region  $u_l, \\ v_l$<b> 0 </b> `0` $f_L$  $u_L=v_L=i$\n\n $u_l, \\ v_l$ $u_{l-1}, v_{l-1}$\n\n $u_l=0$ $f_l$  region  $u_{l-1}=-p_l$$f_{l-1}$  $p_l$  $u_l=1$ $u_{l-1}=s_l-p_l$ $f_{l-1}$  $-p_l$ $s_l$ $u_l=2$ $s_l$ $u_{l-1}=2s_l-p_l$\n$$u_{l-1}=u_l \\cdot s_l -p_l$$\n$$v_{l-1}=v_l \\cdot s_l - p_l + k_l-1$$\n\n$$u_{L-1}=u_L \\cdot s_L - p_L$$\n$$u_{L-2}=u_{L-1} \\cdot s_{L-1}-p_{L-1}=s_{L-1}s_L u_L-s_{L-1}p_L-p_{L-1}$$\n$$u_{L-3}=u_{L-2} \\cdot s_{L-2}-p_{L-2}=s_{L-2}s_{L-1}s_L u_L-s_{L-2}s_{L-1}p_L-s_{L-2}p_{L-1}-p_{L-2}$$\n$$\\cdots$$\n$$u_l=s_{l+1}\\cdots s_L u_L-s_{l+1}\\cdots s_{L-1} p_{L}-\\cdots-s_{l+1} p_{l+2}-p_{l+1}=u_L\\prod_{i=l+1}^L s_i-\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1} s_i$$\n\n$\\prod_{i=l+1}^l s_i=1$, \n$$v_l=v_L \\prod_{i=l+1}^L s_i - \\sum_{j=l+1}^L(1+p_j-k_j)\\prod_{i=l+1}^{j-1} s_i$$\n\n# Relation\nReceptive Field size  region \n$$r_l=v_l-u_l+1$$\n\n# Stride & Padding\n stride   padding\n\n$$S_l=\\prod_{i=l+1}^L s_i$$\n\n$$P_l=\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1}s_i$$\n\n\n$$S_{l-1}=s_l \\cdot S_l$$\n$$P_{l-1}=p_l+s_l \\cdot P_l$$\n\nregion \n$$u_l=u_L \\cdot S_l - P_l$$\n\n# Center\nreceptive field  region  `l` layer \n$$c_l=\\frac {u_l+v_l} 2$$\n\n","source":"_posts/dl/receptive_field.md","raw":"---\ntitle: Receptive Field\ndate: 2021-02-18 10:51:00\np: dl/receptive_field\ntags: Deep Learning, CNN\nmathjax: true\n---\n\n# Size\n\n fully CNN  `k` layer  receptive field \n$$l_k=l_{k-1} + ((f_k-1)*\\prod_{i=1}^{k-1} s_i)$$\n$l_{k-1}$  `k-1` layer  receptive field $f_k$  `k` layer  filter $s_i$  `i` layer  stride  $l_1$ $l_1=f_1$\n\n\n\n `L`  layer layer  feature map  $f_l, \\ l=1,...,L$ layer  filter  $k_l$stride  $s_l$ $r_l$  layer  feature map $f_l$  receptive field $r_l$  $f_l$  $f_L$  feature map$r_L=1$\n\n$r_{L-1}=k_L$ feature map $k_L$  $r_l$ $r_{l-1}$\n\n $k_l=1$ $s_l=1$ $r_{l-1}=r_l$ $s_l>1$ $r_{l-1}=s_l \\cdot r_l -(s_l-1)$ $r_l$  $f_{l-1}$  $s_l-1$  $r_{l-1}=(s_l-1)\\cdot(r_l-1)+ r_l=s_l \\cdot r_l-s_l+1$\n\n $k_l>1$ $f_{l-1}$  $k_l-1$ \n$$r_{l-1}=s_l \\cdot r_l + (k_l-s_l)$$\n$r_L=1, \\ r_{L-1}=k_L$\n$$r_{L-2}=s_{L-1} r_{L-1}+(k_{L-1}-s_{L-1})=s_{L-1}(k_L-1)+k_{L-1}$$\n$$r_{L-3}=s_{L-2} r_{L-2}+(k_{L-2}-s_{L-2})=s_{L-2}s_{L-1}(k_L-1)+s_{L-2}(k_{L-1}-1)+k_{L-2}$$\n$$\\cdots$$\n$$r_{l}=s_{l+1}\\cdots s_{L-1}(k_L-1)+s_{l+1}\\cdots s_{L-2}(k_{L-1}-1)+ \\cdots s_{l+1}(k_{l+2}-1)+k_{l+1}=1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right]$$\n $$\\prod_{l+1}^{l}s_i=1$$\n\n\n$$\\begin{aligned} r_{l-1}&=1+\\sum_{j=l}^{L} \\left[(k_{j}-1) \\prod_{i=l}^{j-1}s_i \\right] \\\\ &=1+(k_l-1)+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\cdot s_l \\right] \\\\&=k_l-s_l+s_l \\left(1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right] \\right) \\\\&=s_l \\cdot r_l +k_l-s_l\\end{aligned}$$\n\n\noutput feature size \n$$w_l=\\frac {w_{l-1}+2p_l-k_l} {s_l}+1$$\n $w$  $h$  2D image \n\n# Region\n feature map  region Receptive Field region  feature map  $f_L(i,j)$ region \n\n $f_l$  region  $u_l, \\ v_l$<b> 0 </b> `0` $f_L$  $u_L=v_L=i$\n\n $u_l, \\ v_l$ $u_{l-1}, v_{l-1}$\n\n $u_l=0$ $f_l$  region  $u_{l-1}=-p_l$$f_{l-1}$  $p_l$  $u_l=1$ $u_{l-1}=s_l-p_l$ $f_{l-1}$  $-p_l$ $s_l$ $u_l=2$ $s_l$ $u_{l-1}=2s_l-p_l$\n$$u_{l-1}=u_l \\cdot s_l -p_l$$\n$$v_{l-1}=v_l \\cdot s_l - p_l + k_l-1$$\n\n$$u_{L-1}=u_L \\cdot s_L - p_L$$\n$$u_{L-2}=u_{L-1} \\cdot s_{L-1}-p_{L-1}=s_{L-1}s_L u_L-s_{L-1}p_L-p_{L-1}$$\n$$u_{L-3}=u_{L-2} \\cdot s_{L-2}-p_{L-2}=s_{L-2}s_{L-1}s_L u_L-s_{L-2}s_{L-1}p_L-s_{L-2}p_{L-1}-p_{L-2}$$\n$$\\cdots$$\n$$u_l=s_{l+1}\\cdots s_L u_L-s_{l+1}\\cdots s_{L-1} p_{L}-\\cdots-s_{l+1} p_{l+2}-p_{l+1}=u_L\\prod_{i=l+1}^L s_i-\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1} s_i$$\n\n$\\prod_{i=l+1}^l s_i=1$, \n$$v_l=v_L \\prod_{i=l+1}^L s_i - \\sum_{j=l+1}^L(1+p_j-k_j)\\prod_{i=l+1}^{j-1} s_i$$\n\n# Relation\nReceptive Field size  region \n$$r_l=v_l-u_l+1$$\n\n# Stride & Padding\n stride   padding\n\n$$S_l=\\prod_{i=l+1}^L s_i$$\n\n$$P_l=\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1}s_i$$\n\n\n$$S_{l-1}=s_l \\cdot S_l$$\n$$P_{l-1}=p_l+s_l \\cdot P_l$$\n\nregion \n$$u_l=u_L \\cdot S_l - P_l$$\n\n# Center\nreceptive field  region  `l` layer \n$$c_l=\\frac {u_l+v_l} 2$$\n\n","slug":"dl/receptive_field","published":1,"updated":"2021-02-19T02:18:58.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or90z0025p0dje6ai3d7g","content":"<h1 id=\"Size\"><a href=\"#Size\" class=\"headerlink\" title=\"Size\"></a>Size</h1><p> fully CNN  <code>k</code> layer  receptive field </p>\n<script type=\"math/tex; mode=display\">l_k=l_{k-1} + ((f_k-1)*\\prod_{i=1}^{k-1} s_i)</script><p>$l_{k-1}$  <code>k-1</code> layer  receptive field $f_k$  <code>k</code> layer  filter $s_i$  <code>i</code> layer  stride  $l_1$ $l_1=f_1$</p>\n<p> <code>L</code>  layer layer  feature map  $f_l, \\ l=1,,L$ layer  filter  $k_l$stride  $s_l$ $r_l$  layer  feature map $f_l$  receptive field $r_l$  $f_l$  $f_L$  feature map$r_L=1$</p>\n<p>$r_{L-1}=k_L$ feature map $k_L$  $r_l$ $r_{l-1}$</p>\n<p> $k_l=1$ $s_l=1$ $r_{l-1}=r_l$ $s_l&gt;1$ $r_{l-1}=s_l \\cdot r_l -(s_l-1)$ $r_l$  $f_{l-1}$  $s_l-1$  $r_{l-1}=(s_l-1)\\cdot(r_l-1)+ r_l=s_l \\cdot r_l-s_l+1$</p>\n<p> $k_l&gt;1$ $f_{l-1}$  $k_l-1$ </p>\n<script type=\"math/tex; mode=display\">r_{l-1}=s_l \\cdot r_l + (k_l-s_l)</script><p>$r_L=1, \\ r_{L-1}=k_L$</p>\n<script type=\"math/tex; mode=display\">r_{L-2}=s_{L-1} r_{L-1}+(k_{L-1}-s_{L-1})=s_{L-1}(k_L-1)+k_{L-1}</script><script type=\"math/tex; mode=display\">r_{L-3}=s_{L-2} r_{L-2}+(k_{L-2}-s_{L-2})=s_{L-2}s_{L-1}(k_L-1)+s_{L-2}(k_{L-1}-1)+k_{L-2}</script><script type=\"math/tex; mode=display\">\\cdots</script><script type=\"math/tex; mode=display\">r_{l}=s_{l+1}\\cdots s_{L-1}(k_L-1)+s_{l+1}\\cdots s_{L-2}(k_{L-1}-1)+ \\cdots s_{l+1}(k_{l+2}-1)+k_{l+1}=1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right]</script><p> <script type=\"math/tex\">\\prod_{l+1}^{l}s_i=1</script></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} r_{l-1}&=1+\\sum_{j=l}^{L} \\left[(k_{j}-1) \\prod_{i=l}^{j-1}s_i \\right] \\\\ &=1+(k_l-1)+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\cdot s_l \\right] \\\\&=k_l-s_l+s_l \\left(1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right] \\right) \\\\&=s_l \\cdot r_l +k_l-s_l\\end{aligned}</script><p></p>\n<p>output feature size </p>\n<script type=\"math/tex; mode=display\">w_l=\\frac {w_{l-1}+2p_l-k_l} {s_l}+1</script><p> $w$  $h$  2D image </p>\n<h1 id=\"Region\"><a href=\"#Region\" class=\"headerlink\" title=\"Region\"></a>Region</h1><p> feature map  region Receptive Field region  feature map  $f_L(i,j)$ region </p>\n<p> $f_l$  region  $u_l, \\ v_l$<b> 0 </b> <code>0</code> $f_L$  $u_L=v_L=i$</p>\n<p> $u_l, \\ v_l$ $u_{l-1}, v_{l-1}$</p>\n<p> $u_l=0$ $f_l$  region  $u_{l-1}=-p_l$$f_{l-1}$  $p_l$  $u_l=1$ $u_{l-1}=s_l-p_l$ $f_{l-1}$  $-p_l$ $s_l$ $u_l=2$ $s_l$ $u_{l-1}=2s_l-p_l$</p>\n<script type=\"math/tex; mode=display\">u_{l-1}=u_l \\cdot s_l -p_l</script><script type=\"math/tex; mode=display\">v_{l-1}=v_l \\cdot s_l - p_l + k_l-1</script><p></p>\n<script type=\"math/tex; mode=display\">u_{L-1}=u_L \\cdot s_L - p_L</script><script type=\"math/tex; mode=display\">u_{L-2}=u_{L-1} \\cdot s_{L-1}-p_{L-1}=s_{L-1}s_L u_L-s_{L-1}p_L-p_{L-1}</script><script type=\"math/tex; mode=display\">u_{L-3}=u_{L-2} \\cdot s_{L-2}-p_{L-2}=s_{L-2}s_{L-1}s_L u_L-s_{L-2}s_{L-1}p_L-s_{L-2}p_{L-1}-p_{L-2}</script><script type=\"math/tex; mode=display\">\\cdots</script><script type=\"math/tex; mode=display\">u_l=s_{l+1}\\cdots s_L u_L-s_{l+1}\\cdots s_{L-1} p_{L}-\\cdots-s_{l+1} p_{l+2}-p_{l+1}=u_L\\prod_{i=l+1}^L s_i-\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1} s_i</script><p>$\\prod_{i=l+1}^l s_i=1$, </p>\n<script type=\"math/tex; mode=display\">v_l=v_L \\prod_{i=l+1}^L s_i - \\sum_{j=l+1}^L(1+p_j-k_j)\\prod_{i=l+1}^{j-1} s_i</script><h1 id=\"Relation\"><a href=\"#Relation\" class=\"headerlink\" title=\"Relation\"></a>Relation</h1><p>Receptive Field size  region </p>\n<script type=\"math/tex; mode=display\">r_l=v_l-u_l+1</script><h1 id=\"Stride-amp-Padding\"><a href=\"#Stride-amp-Padding\" class=\"headerlink\" title=\"Stride &amp; Padding\"></a>Stride &amp; Padding</h1><p> stride   padding</p>\n<script type=\"math/tex; mode=display\">S_l=\\prod_{i=l+1}^L s_i</script><script type=\"math/tex; mode=display\">P_l=\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1}s_i</script><p></p>\n<script type=\"math/tex; mode=display\">S_{l-1}=s_l \\cdot S_l</script><script type=\"math/tex; mode=display\">P_{l-1}=p_l+s_l \\cdot P_l</script><p>region </p>\n<script type=\"math/tex; mode=display\">u_l=u_L \\cdot S_l - P_l</script><h1 id=\"Center\"><a href=\"#Center\" class=\"headerlink\" title=\"Center\"></a>Center</h1><p>receptive field  region  <code>l</code> layer </p>\n<script type=\"math/tex; mode=display\">c_l=\\frac {u_l+v_l} 2</script>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Size\"><a href=\"#Size\" class=\"headerlink\" title=\"Size\"></a>Size</h1><p> fully CNN  <code>k</code> layer  receptive field </p>\n<script type=\"math/tex; mode=display\">l_k=l_{k-1} + ((f_k-1)*\\prod_{i=1}^{k-1} s_i)</script><p>$l_{k-1}$  <code>k-1</code> layer  receptive field $f_k$  <code>k</code> layer  filter $s_i$  <code>i</code> layer  stride  $l_1$ $l_1=f_1$</p>\n<p> <code>L</code>  layer layer  feature map  $f_l, \\ l=1,,L$ layer  filter  $k_l$stride  $s_l$ $r_l$  layer  feature map $f_l$  receptive field $r_l$  $f_l$  $f_L$  feature map$r_L=1$</p>\n<p>$r_{L-1}=k_L$ feature map $k_L$  $r_l$ $r_{l-1}$</p>\n<p> $k_l=1$ $s_l=1$ $r_{l-1}=r_l$ $s_l&gt;1$ $r_{l-1}=s_l \\cdot r_l -(s_l-1)$ $r_l$  $f_{l-1}$  $s_l-1$  $r_{l-1}=(s_l-1)\\cdot(r_l-1)+ r_l=s_l \\cdot r_l-s_l+1$</p>\n<p> $k_l&gt;1$ $f_{l-1}$  $k_l-1$ </p>\n<script type=\"math/tex; mode=display\">r_{l-1}=s_l \\cdot r_l + (k_l-s_l)</script><p>$r_L=1, \\ r_{L-1}=k_L$</p>\n<script type=\"math/tex; mode=display\">r_{L-2}=s_{L-1} r_{L-1}+(k_{L-1}-s_{L-1})=s_{L-1}(k_L-1)+k_{L-1}</script><script type=\"math/tex; mode=display\">r_{L-3}=s_{L-2} r_{L-2}+(k_{L-2}-s_{L-2})=s_{L-2}s_{L-1}(k_L-1)+s_{L-2}(k_{L-1}-1)+k_{L-2}</script><script type=\"math/tex; mode=display\">\\cdots</script><script type=\"math/tex; mode=display\">r_{l}=s_{l+1}\\cdots s_{L-1}(k_L-1)+s_{l+1}\\cdots s_{L-2}(k_{L-1}-1)+ \\cdots s_{l+1}(k_{l+2}-1)+k_{l+1}=1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right]</script><p> <script type=\"math/tex\">\\prod_{l+1}^{l}s_i=1</script></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} r_{l-1}&=1+\\sum_{j=l}^{L} \\left[(k_{j}-1) \\prod_{i=l}^{j-1}s_i \\right] \\\\ &=1+(k_l-1)+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\cdot s_l \\right] \\\\&=k_l-s_l+s_l \\left(1+\\sum_{j=l+1}^{L} \\left[(k_{j}-1) \\prod_{i=l+1}^{j-1}s_i \\right] \\right) \\\\&=s_l \\cdot r_l +k_l-s_l\\end{aligned}</script><p></p>\n<p>output feature size </p>\n<script type=\"math/tex; mode=display\">w_l=\\frac {w_{l-1}+2p_l-k_l} {s_l}+1</script><p> $w$  $h$  2D image </p>\n<h1 id=\"Region\"><a href=\"#Region\" class=\"headerlink\" title=\"Region\"></a>Region</h1><p> feature map  region Receptive Field region  feature map  $f_L(i,j)$ region </p>\n<p> $f_l$  region  $u_l, \\ v_l$<b> 0 </b> <code>0</code> $f_L$  $u_L=v_L=i$</p>\n<p> $u_l, \\ v_l$ $u_{l-1}, v_{l-1}$</p>\n<p> $u_l=0$ $f_l$  region  $u_{l-1}=-p_l$$f_{l-1}$  $p_l$  $u_l=1$ $u_{l-1}=s_l-p_l$ $f_{l-1}$  $-p_l$ $s_l$ $u_l=2$ $s_l$ $u_{l-1}=2s_l-p_l$</p>\n<script type=\"math/tex; mode=display\">u_{l-1}=u_l \\cdot s_l -p_l</script><script type=\"math/tex; mode=display\">v_{l-1}=v_l \\cdot s_l - p_l + k_l-1</script><p></p>\n<script type=\"math/tex; mode=display\">u_{L-1}=u_L \\cdot s_L - p_L</script><script type=\"math/tex; mode=display\">u_{L-2}=u_{L-1} \\cdot s_{L-1}-p_{L-1}=s_{L-1}s_L u_L-s_{L-1}p_L-p_{L-1}</script><script type=\"math/tex; mode=display\">u_{L-3}=u_{L-2} \\cdot s_{L-2}-p_{L-2}=s_{L-2}s_{L-1}s_L u_L-s_{L-2}s_{L-1}p_L-s_{L-2}p_{L-1}-p_{L-2}</script><script type=\"math/tex; mode=display\">\\cdots</script><script type=\"math/tex; mode=display\">u_l=s_{l+1}\\cdots s_L u_L-s_{l+1}\\cdots s_{L-1} p_{L}-\\cdots-s_{l+1} p_{l+2}-p_{l+1}=u_L\\prod_{i=l+1}^L s_i-\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1} s_i</script><p>$\\prod_{i=l+1}^l s_i=1$, </p>\n<script type=\"math/tex; mode=display\">v_l=v_L \\prod_{i=l+1}^L s_i - \\sum_{j=l+1}^L(1+p_j-k_j)\\prod_{i=l+1}^{j-1} s_i</script><h1 id=\"Relation\"><a href=\"#Relation\" class=\"headerlink\" title=\"Relation\"></a>Relation</h1><p>Receptive Field size  region </p>\n<script type=\"math/tex; mode=display\">r_l=v_l-u_l+1</script><h1 id=\"Stride-amp-Padding\"><a href=\"#Stride-amp-Padding\" class=\"headerlink\" title=\"Stride &amp; Padding\"></a>Stride &amp; Padding</h1><p> stride   padding</p>\n<script type=\"math/tex; mode=display\">S_l=\\prod_{i=l+1}^L s_i</script><script type=\"math/tex; mode=display\">P_l=\\sum_{j=l+1}^L p_j \\prod_{i=l+1}^{j-1}s_i</script><p></p>\n<script type=\"math/tex; mode=display\">S_{l-1}=s_l \\cdot S_l</script><script type=\"math/tex; mode=display\">P_{l-1}=p_l+s_l \\cdot P_l</script><p>region </p>\n<script type=\"math/tex; mode=display\">u_l=u_L \\cdot S_l - P_l</script><h1 id=\"Center\"><a href=\"#Center\" class=\"headerlink\" title=\"Center\"></a>Center</h1><p>receptive field  region  <code>l</code> layer </p>\n<script type=\"math/tex; mode=display\">c_l=\\frac {u_l+v_l} 2</script>"},{"title":"Deep Learning Tricks1","p":"dl/tricks1","date":"2021-01-08T06:32:52.000Z","mathjax":true,"_content":"\n<!-- more -->\n# BatchNorm\n## BatchNorm \n1. \n2.  `Internal Covariate Shift` BN BN  BN \n3. \n\n## BatchNorm \n `m` $\\epsilon$\n\n$\\mu=\\frac 1 m \\sum_{i=1}^m x_i$\n\n$\\sigma^2=\\frac 1 m \\sum_{i=1}^m (x_i - \\mu)^2$\n\n$\\hat x_i=\\frac {x_i -\\mu} {\\sqrt{\\sigma^2+\\epsilon}}$\n\n$y_i=\\gamma \\hat x_i+\\beta$\n\n `scale and shift` $\\gamma, \\beta$  BN  $\\gamma, \\ \\beta$\n\n## BatchNorm \nBatchNorm  BatchNorm","source":"_posts/dl/tricks_1.md","raw":"---\ntitle: Deep Learning Tricks1\np: dl/tricks1\ndate: 2021-01-08 14:32:52\ntags: Deep Learning\nmathjax: true\n---\n\n<!-- more -->\n# BatchNorm\n## BatchNorm \n1. \n2.  `Internal Covariate Shift` BN BN  BN \n3. \n\n## BatchNorm \n `m` $\\epsilon$\n\n$\\mu=\\frac 1 m \\sum_{i=1}^m x_i$\n\n$\\sigma^2=\\frac 1 m \\sum_{i=1}^m (x_i - \\mu)^2$\n\n$\\hat x_i=\\frac {x_i -\\mu} {\\sqrt{\\sigma^2+\\epsilon}}$\n\n$y_i=\\gamma \\hat x_i+\\beta$\n\n `scale and shift` $\\gamma, \\beta$  BN  $\\gamma, \\ \\beta$\n\n## BatchNorm \nBatchNorm  BatchNorm","slug":"dl/tricks_1","published":1,"updated":"2021-01-08T11:11:04.076Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or9100026p0dj89ku7h0o","content":"<p><br><span id=\"more\"></span></p>\n<h1 id=\"BatchNorm\"><a href=\"#BatchNorm\" class=\"headerlink\" title=\"BatchNorm\"></a>BatchNorm</h1><h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><ol>\n<li></li>\n<li> <code>Internal Covariate Shift</code> BN BN  BN </li>\n<li></li>\n</ol>\n<h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><p> <code>m</code> $\\epsilon$</p>\n<p>$\\mu=\\frac 1 m \\sum_{i=1}^m x_i$</p>\n<p>$\\sigma^2=\\frac 1 m \\sum_{i=1}^m (x_i - \\mu)^2$</p>\n<p>$\\hat x_i=\\frac {x_i -\\mu} {\\sqrt{\\sigma^2+\\epsilon}}$</p>\n<p>$y_i=\\gamma \\hat x_i+\\beta$</p>\n<p> <code>scale and shift</code> $\\gamma, \\beta$  BN  $\\gamma, \\ \\beta$</p>\n<h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><p>BatchNorm  BatchNorm</p>\n","site":{"data":{}},"excerpt":"<p><br>","more":"</p>\n<h1 id=\"BatchNorm\"><a href=\"#BatchNorm\" class=\"headerlink\" title=\"BatchNorm\"></a>BatchNorm</h1><h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><ol>\n<li></li>\n<li> <code>Internal Covariate Shift</code> BN BN  BN </li>\n<li></li>\n</ol>\n<h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><p> <code>m</code> $\\epsilon$</p>\n<p>$\\mu=\\frac 1 m \\sum_{i=1}^m x_i$</p>\n<p>$\\sigma^2=\\frac 1 m \\sum_{i=1}^m (x_i - \\mu)^2$</p>\n<p>$\\hat x_i=\\frac {x_i -\\mu} {\\sqrt{\\sigma^2+\\epsilon}}$</p>\n<p>$y_i=\\gamma \\hat x_i+\\beta$</p>\n<p> <code>scale and shift</code> $\\gamma, \\beta$  BN  $\\gamma, \\ \\beta$</p>\n<h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><p>BatchNorm  BatchNorm</p>"},{"title":"Cross Entropy Loss","p":"dl/x_ent_loss","date":"2021-01-12T02:35:40.000Z","mathjax":true,"_content":"\n\n<!-- more -->\n# \n\n## \n`C`  `C` ground truth  one-hot \n## \n `C`  `C` ground truth  `0`  `1` `1`\n\n# \n`C` \n## Sigmoid\n Sigmoid  `(0,1)` \n\nSigmoid /ground truth  `1/0` Sigmoid  `(0,1)` 0.5\n## Softmax\nSoftmax  `(0,1)`  1Softmax \n\n# \n# Cross-Entropy Loss\n\n$$CE=-\\sum_{i=1}^C y_i \\log (x_i)$$\n $y_i$  ground truth `i`$x_i$  `i`  $\\log(x_i)$  GT  one-hot  $i=c$ \n\nGT: $y=1$ $y=0$  Sigmoid `x` \n$$CE=-y \\log (x) - (1-y) \\log(1-x)$$\n\n\n\n `C`  `C` \n$$CE=-\\sum_{i=1}^C y_i \\log(x_i) - (1-y_i) \\log(1-x_i)$$\n\n\n## Balanced Cross Entropy\n $\\alpha \\in [0,1]$ \n$$\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0 \\end{cases}$$\n\n\n$$x_t=\\begin{cases} x & y=1 \\\\ 1-x & y=0 \\end{cases}$$\n\n$\\alpha$ \n$$CE=-\\alpha_t \\log(x_t)$$\n $\\alpha$  $\\alpha$  cross validation \n\n## Focal Loss\n Focal loss \n$$FL=-(1-x_t) ^{\\gamma} \\log(x_t)$$\n\n$$FL=-y(1-x)^{\\gamma} \\log(x) -(1-y)x^{\\gamma} \\log(1-x)$$\n\n$\\gamma \\ge 0$\n\n\nFocal loss  scale  $(1-x_t)^{\\gamma}$ $x_t$  scale  easy  hard \n\n Focal loss  $\\alpha$  Focal loss \n$$FL=-\\alpha_t (1-x_t)^{\\gamma} \\log (x_t)$$\n","source":"_posts/dl/x_ent_loss.md","raw":"---\ntitle: Cross Entropy Loss\np: dl/x_ent_loss\ndate: 2021-01-12 10:35:40\ntags: Deep Learning\nmathjax: true\n---\n\n\n<!-- more -->\n# \n\n## \n`C`  `C` ground truth  one-hot \n## \n `C`  `C` ground truth  `0`  `1` `1`\n\n# \n`C` \n## Sigmoid\n Sigmoid  `(0,1)` \n\nSigmoid /ground truth  `1/0` Sigmoid  `(0,1)` 0.5\n## Softmax\nSoftmax  `(0,1)`  1Softmax \n\n# \n# Cross-Entropy Loss\n\n$$CE=-\\sum_{i=1}^C y_i \\log (x_i)$$\n $y_i$  ground truth `i`$x_i$  `i`  $\\log(x_i)$  GT  one-hot  $i=c$ \n\nGT: $y=1$ $y=0$  Sigmoid `x` \n$$CE=-y \\log (x) - (1-y) \\log(1-x)$$\n\n\n\n `C`  `C` \n$$CE=-\\sum_{i=1}^C y_i \\log(x_i) - (1-y_i) \\log(1-x_i)$$\n\n\n## Balanced Cross Entropy\n $\\alpha \\in [0,1]$ \n$$\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0 \\end{cases}$$\n\n\n$$x_t=\\begin{cases} x & y=1 \\\\ 1-x & y=0 \\end{cases}$$\n\n$\\alpha$ \n$$CE=-\\alpha_t \\log(x_t)$$\n $\\alpha$  $\\alpha$  cross validation \n\n## Focal Loss\n Focal loss \n$$FL=-(1-x_t) ^{\\gamma} \\log(x_t)$$\n\n$$FL=-y(1-x)^{\\gamma} \\log(x) -(1-y)x^{\\gamma} \\log(1-x)$$\n\n$\\gamma \\ge 0$\n\n\nFocal loss  scale  $(1-x_t)^{\\gamma}$ $x_t$  scale  easy  hard \n\n Focal loss  $\\alpha$  Focal loss \n$$FL=-\\alpha_t (1-x_t)^{\\gamma} \\log (x_t)$$\n","slug":"dl/x_ent_loss","published":1,"updated":"2021-01-12T09:33:12.331Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or9100027p0djhj6f9a90","content":"<p><br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>C</code>  <code>C</code> ground truth  one-hot </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>C</code>  <code>C</code> ground truth  <code>0</code>  <code>1</code> <code>1</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><code>C</code> </p>\n<h2 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h2><p> Sigmoid  <code>(0,1)</code> </p>\n<p>Sigmoid /ground truth  <code>1/0</code> Sigmoid  <code>(0,1)</code> 0.5</p>\n<h2 id=\"Softmax\"><a href=\"#Softmax\" class=\"headerlink\" title=\"Softmax\"></a>Softmax</h2><p>Softmax  <code>(0,1)</code>  1Softmax </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h1 id=\"Cross-Entropy-Loss\"><a href=\"#Cross-Entropy-Loss\" class=\"headerlink\" title=\"Cross-Entropy Loss\"></a>Cross-Entropy Loss</h1><p></p>\n<script type=\"math/tex; mode=display\">CE=-\\sum_{i=1}^C y_i \\log (x_i)</script><p> $y_i$  ground truth <code>i</code>$x_i$  <code>i</code>  $\\log(x_i)$  GT  one-hot  $i=c$ </p>\n<p>GT: $y=1$ $y=0$  Sigmoid <code>x</code> </p>\n<script type=\"math/tex; mode=display\">CE=-y \\log (x) - (1-y) \\log(1-x)</script><p></p>\n<p> <code>C</code>  <code>C</code> </p>\n<script type=\"math/tex; mode=display\">CE=-\\sum_{i=1}^C y_i \\log(x_i) - (1-y_i) \\log(1-x_i)</script><h2 id=\"Balanced-Cross-Entropy\"><a href=\"#Balanced-Cross-Entropy\" class=\"headerlink\" title=\"Balanced Cross Entropy\"></a>Balanced Cross Entropy</h2><p> $\\alpha \\in [0,1]$ </p>\n<script type=\"math/tex; mode=display\">\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0 \\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">x_t=\\begin{cases} x & y=1 \\\\ 1-x & y=0 \\end{cases}</script><p>$\\alpha$ </p>\n<script type=\"math/tex; mode=display\">CE=-\\alpha_t \\log(x_t)</script><p> $\\alpha$  $\\alpha$  cross validation </p>\n<h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p> Focal loss </p>\n<script type=\"math/tex; mode=display\">FL=-(1-x_t) ^{\\gamma} \\log(x_t)</script><p></p>\n<script type=\"math/tex; mode=display\">FL=-y(1-x)^{\\gamma} \\log(x) -(1-y)x^{\\gamma} \\log(1-x)</script><p>$\\gamma \\ge 0$</p>\n<p>Focal loss  scale  $(1-x_t)^{\\gamma}$ $x_t$  scale  easy  hard </p>\n<p> Focal loss  $\\alpha$  Focal loss </p>\n<script type=\"math/tex; mode=display\">FL=-\\alpha_t (1-x_t)^{\\gamma} \\log (x_t)</script>","site":{"data":{}},"excerpt":"<p><br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>C</code>  <code>C</code> ground truth  one-hot </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>C</code>  <code>C</code> ground truth  <code>0</code>  <code>1</code> <code>1</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><code>C</code> </p>\n<h2 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h2><p> Sigmoid  <code>(0,1)</code> </p>\n<p>Sigmoid /ground truth  <code>1/0</code> Sigmoid  <code>(0,1)</code> 0.5</p>\n<h2 id=\"Softmax\"><a href=\"#Softmax\" class=\"headerlink\" title=\"Softmax\"></a>Softmax</h2><p>Softmax  <code>(0,1)</code>  1Softmax </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h1 id=\"Cross-Entropy-Loss\"><a href=\"#Cross-Entropy-Loss\" class=\"headerlink\" title=\"Cross-Entropy Loss\"></a>Cross-Entropy Loss</h1><p></p>\n<script type=\"math/tex; mode=display\">CE=-\\sum_{i=1}^C y_i \\log (x_i)</script><p> $y_i$  ground truth <code>i</code>$x_i$  <code>i</code>  $\\log(x_i)$  GT  one-hot  $i=c$ </p>\n<p>GT: $y=1$ $y=0$  Sigmoid <code>x</code> </p>\n<script type=\"math/tex; mode=display\">CE=-y \\log (x) - (1-y) \\log(1-x)</script><p></p>\n<p> <code>C</code>  <code>C</code> </p>\n<script type=\"math/tex; mode=display\">CE=-\\sum_{i=1}^C y_i \\log(x_i) - (1-y_i) \\log(1-x_i)</script><h2 id=\"Balanced-Cross-Entropy\"><a href=\"#Balanced-Cross-Entropy\" class=\"headerlink\" title=\"Balanced Cross Entropy\"></a>Balanced Cross Entropy</h2><p> $\\alpha \\in [0,1]$ </p>\n<script type=\"math/tex; mode=display\">\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0 \\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">x_t=\\begin{cases} x & y=1 \\\\ 1-x & y=0 \\end{cases}</script><p>$\\alpha$ </p>\n<script type=\"math/tex; mode=display\">CE=-\\alpha_t \\log(x_t)</script><p> $\\alpha$  $\\alpha$  cross validation </p>\n<h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p> Focal loss </p>\n<script type=\"math/tex; mode=display\">FL=-(1-x_t) ^{\\gamma} \\log(x_t)</script><p></p>\n<script type=\"math/tex; mode=display\">FL=-y(1-x)^{\\gamma} \\log(x) -(1-y)x^{\\gamma} \\log(1-x)</script><p>$\\gamma \\ge 0$</p>\n<p>Focal loss  scale  $(1-x_t)^{\\gamma}$ $x_t$  scale  easy  hard </p>\n<p> Focal loss  $\\alpha$  Focal loss </p>\n<script type=\"math/tex; mode=display\">FL=-\\alpha_t (1-x_t)^{\\gamma} \\log (x_t)</script>"},{"title":"Dynamic Programming (3)","date":"2019-08-27T11:03:44.000Z","p":"dp/DP3","mathjax":true,"_content":" [DP2](2019/08/14/DP2)  DP \n\n##  FLOWSHOP\n A  BB  A A B  $i=\\{0,1,2,3\\}$ A  $p_i=\\{3,4,8,10\\}$B  $q_i=\\{6,2,9,15\\}$ $0,1,2,3$\n\n<!-- more -->\n\n| processor 1 | $A_0: 0-3$ | $A_1:3-7$ | $A_2:7-15$ | $A_3:15-25$ | |\n|:---------:|:--------:| :-----------: | :-------:  | :--------:  |:--:|\n| __processor 2__  |  |$B_0: 3-9$ | $B_1:9-11$ | $B_2:15-24$ | $B_3:25-40$ |\n\n B  40 DP  d  (k,S) k  A B S k  0 d  $k \\le p_d$ $B_d$  $A_d$  $B_d$ __ k'  $q_d$__ $B_d$   $A_d$  $k-p_d$  k'   $k-p_d+q_d$\n\n k = 0 $d_1=0$ $k=0<p_0$ $B_0$  $A_0$  $d_2=1$  k  $q_0=6$ $k>p_1$ $B_1$  $k-p_1=6-4=2$ $B_1$  $A_1$  7  2  $d_3=2$  k  $k:=k-p_1+q_1=6-4+2=4$ $k<p_2$ $B_2$  $A_2$  15  $d_4=3$  k  $k:=q_2=9$ $k<p_3$ $B_3$  $A_3$  25  k  $k=q_3=15$ $f(k,S)=k  \\  S=\\emptyset$\n\nDPFE \n\n$$f(k,S)=\\min_{d \\in S} \\{p_d + f(\\max (k-p_d,0)+q_d, S-\\{d\\})\\}$$\n\n $f(k,\\emptyset)=k$ $f(0,S^{\\ast})$$S^{\\ast}$ \n```python\ni=[0,1,2,3]\np=[3,4,8,10]\nq=[6,2,9,15]\n\ndef flowshop(k,S)\n    if len(S)==0:\n        return k, []\n    m=1e8\n    for j in range(len(S)):\n        d=S[j]\n        m1, path1=flowshow(max(k-p[d],0)+q[d], S[:j]+S[j+1:])\n        m1+=p[d]\n        if m>m1:\n            m=m1\n            path=[s]+path1\n    return m, path\n\nm, path=flowshow(0,i)\nprint(m)\nprint(path)\n```\n\n##  HANOI\n N  x  y  z  $f(N)$\n\n$$f(i)=2f(i-1)+1$$\n\n x  i  y  x  i-1  z  x  y  z  i-1  y  $f(1)=1$ $f(2)=2 f(1)+1=3, \\ f(3)=2f(2)+1=7, \\ \\cdots$\n\n\n### \n x  y  $<x,y>$ $F(S)$ concatenation\n\n$$F(N,x,y)=F(N-1,x,z)F(1,x,y)F(N-1,z,y)$$\n\n $S=(N,x,y)$ $F(1,x,y)=<x,y>$\n$$\\begin{aligned} F(2,x,y)&=F(1,x,z)F(1,x,y)F(1,z,y)=<x,z><x,y><z,y>\n\\\\\\\\F(3,x,y)&=F(2,x,z)F(1,x,y)F(2,z,y)\n\\\\\\\\ &=<x,y><x,z><y,z><x,y><z,x><z,y><x,y>\\end{aligned}$$\n\n\n```python\npegs = [1,2,3]\ndef hanoi(n,i=1,j=2):\n    if n==1:\n        return [(i,j)]\n    k = pegs.difference({i,j}).pop()\n    return hanoi(n-1,i,k)+hanoi(1,i,j)+hanoi(n-1,k,j)\n\nif __name__ == '__main__':\n    s=hanoi(3)\n    print(s)\n```\n\n##  ILP\n\n$$\\max c^{\\top}x\n\\\\\\\\ s.t. Ax \\le b\n\\\\\\\\ x_1,...,x_n \\in \\mathbf N \\cup \\{0\\}$$\n A  b, c  DP  $x_1$  $x_1$  $\\sum_{i=2}^n c_i x_i$  $x$  $x_i$  $x_1,...,x_{i-1}$  S  j  $x_{j+1}$  $x_j$ DPFE  DPFE \n$$f(j,S)=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,S \\cup \\{(j+1,x_{j+1})\\})\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}$$\n $D$  $S$  $f(0,\\emptyset)$\n\n\n\n$$Ax \\le b$$\n\n $A$  $m \\times n$ m  \n\n$$A_{i,:}x \\le b_i \\Rightarrow \\sum_{j=1}^n A_{i,j}x_j \\le b_i$$\n\n $x_j$  $x_j$  j $x_{j+1}$ \n\n$$\\sum_{k=j+2}^n A_{i,k}x_k \\le b_i - A_{i,1}x_1 - \\cdots A_{i,j+1}x_{j+1}$$\n\n S DPFE \n\n$$f(j,(y_1,...,y_m))=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,(y_1-A_{1,j+1}x_{j+1},...,y_m-A_{m,j+1}x_{j+1}))\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}$$\n\n $f(0,(b_1,...,b_m))$ $D$ j $S=(j,(y_1,...,y_m))$\n\n$$A_{1,j+1}x_{j+1} + A_{1,j+2}x_{j+2} + \\cdots + A_{1,n}x_n \\le y_1\n\\\\\\\\ \\vdots\n\\\\\\\\ A_{m,j+1}x_{j+1} + A_{m,j+2}x_{j+2} + \\cdots + A_{m,n}x_n \\le y_m$$\n $x_{j+1}$  \n$$\\{0,...,\\min \\{\\lfloor \\frac{y_1}{A_{1,j+1}} \\rfloor, ..., \\lfloor \\frac{y_m}{A_{m,j+1}} \\rfloor\\}\\}$$\n\n $\\frac {y_i} 0$ $\\infty$ i  $x_{j+1}$ \n\n $D$  \n$$y_i=b_i-\\sum_{p \\in S} A_{i,p_1}p_2$$\n\n\n$c=(3,5), \\ b=(4,12,18)$$A=\\begin{pmatrix} 1 & 0 \\\\\\\\ 0 & 2 \\\\\\\\ 3 & 2 \\end{pmatrix}$ $x=(x_1,x_2)$\n\n```python\nc=[3,5]\nb=[4,12,18]\na=[[1,0],\n   [0,2],\n   [3,2]]\n\nm,n=len(b),len(c)\n\ndef d=(j,y):\n    return min([y[i]//a[i][j] if a[i][j] > 0 else 1e8 for i in range(m)])\n\ndef ilp(j,y):\n    if j==n:\n        return 0, []\n    dm=d(j,y)\n    m_=-1\n    x_=None\n    for d_ in range(dm+1):\n        y_=[y[i]-a[i][j]*d_ for i in range(m)]\n        m1,x1=ilp(j+1,y_)\n        m1+=c[j]*d_\n        if m_ < m1:\n            m_ = m1\n            x_ = [d_]+x1\n    return m_, x_\n\nif __name__ == '__main__':\n    m_, x_ = ilp(0,b)\n    print(m_)   # 36\n    print(x_)   # [2,6]\n```\n\n##  ILP  ILPKNAP\n n=3 $(v_0,v_1,v_2)=(15,25,24)$ $(w_0,w_1,w_2)=(10,18,15)$ 22 ILP  $(x_0,x_1,x_2)$ $c=(v_0,v_1,v_2)$ $A=(w_0,w_1,w_2)$ $b=(22)$ $x_0,x_1,x_2 \\in \\mathbf N \\cup \\{0\\}$\n\n##  INTVL\n N  $P=\\{0,...,N-1\\}$ $(s_i,t_i)$  $i$  $w_i$DPFE \n\n$$f(p,q)=\\max_{d \\in P} \\{f(p,s_d)+c(d|p,q)+f(t_d,q)\\}$$\n f(p,q)  $[p,q]$  d $[s_d,t_d]$  d $[p,s_d]$  $[t_d,q]$  d  $p \\le s_d, t_d \\le q$ $f(p,q)=0, \\ p \\ge q$ $f(0,T)$ $T \\ge \\max_i \\{t_i\\}$\n\n $[p,s_d]$  $[t_d,q]$  $f(p,s_d), \\ f(t_d, q)$ $P$ $f(p,q)=0, \\ p \\ge q$ DPFE \n\n$$f(S,p,q)=\\max_{d \\in S} \\{f(S_L,p,s_d)+c(d|p,q)+f(S_R,t_d,q)\\}$$\n $S_L, \\ S_R \\subset P$  $[p,s_d]$  $[t_d,q]$  $(s_i,t_i)$  $f(S,p,q)=0, \\ p \\ge q \\text{ or } S=\\emptyset$ $f(P,0,T)$ $T \\ge \\max_i \\{t_i\\}$\n```python\nP=[0,1,2,3,4,5]\ns=[9,8,3,5,2,1]\nt=[12,11,10,7,6,4]\nw=[1,2,7,4,4,2]\nT=max(t)\nn=len(s)\n\ndef get_S(prev_S, p, q):\n    return [i for i in prev_S if s[i]>=p and t[i]<=q]\n\ndef intvl(S, p, q):\n    if len(S)==0 or p>=q:\n        return 0, []\n    m_=0\n    d_=None\n    for d in S:\n        m1, d1=intvl(get_S(S, p, s[d]), p, s[d])\n        m2, d2=intvl(get_S(S, t[d], q), t[d], q)\n        m=m1+m2+w[d]\n        if m_<m:\n            m_=m\n            d_=[d]+d1+d2\n    return m_, d_\n\nif __name__ == '__main__':\n    m, d= intvl(P, 0, T)\n    print(m)\n    print(d)\n```\n\n $P$ N $P$  i  $P$  N-i-1  N  N-1-i  i  $D_i=\\{j|t_j \\le s_i\\}$  $\\pi(i)=\\max D_i$ $\\pi(i)$ DPFE \n\n$$f(k)=\\max\\{w_k+f(\\pi(k)), f(k-1)\\}$$\n\nk  1  0  k $w_k+f(\\pi(k))$ k $f(k-1)$ k\n\n$$f(k)=\\max_{d \\in \\{0,1\\}} \\{d\\cdot(w_k+f(\\pi (k-1)))+(1-d)\\cdot f(k-1)\\}$$\n\n\n```python\nimport numpy as np\n\ns=[9,8,3,5,2,1]\nt=[12,11,10,7,6,4]\nw=[1,2,7,4,4,2]\n\nP=np.argsort(t)\nt=np.sort(t)\ns=np.array(s)[P]\nw=np.array(w)[P]\n\ndef pi(k):\n    for i in range(k-1,-1,-1):\n        if t[i]<=s[k]:\n            return i\n    return -1\n\ndef intvl1(k):\n    if k==-1:\n        return 0, []\n    m1,d1=intvl1(pi(k))\n    m2,d2=intvl2(k-1)\n    if m1+w[k]>=m2:\n        return m1+w[k], [k]+d1\n    else:\n        return m2, d2\n\nif __name__ == '__main__':\n    m, d= intvl(P, 0, T)\n    print(m)\n    print(P[d])\n```\n","source":"_posts/dp/DP3.md","raw":"---\ntitle: Dynamic Programming (3)\ndate: 2019-08-27 19:03:44\np: dp/DP3\ntags: \n    - math\n    - DP\nmathjax: true\n---\n [DP2](2019/08/14/DP2)  DP \n\n##  FLOWSHOP\n A  BB  A A B  $i=\\{0,1,2,3\\}$ A  $p_i=\\{3,4,8,10\\}$B  $q_i=\\{6,2,9,15\\}$ $0,1,2,3$\n\n<!-- more -->\n\n| processor 1 | $A_0: 0-3$ | $A_1:3-7$ | $A_2:7-15$ | $A_3:15-25$ | |\n|:---------:|:--------:| :-----------: | :-------:  | :--------:  |:--:|\n| __processor 2__  |  |$B_0: 3-9$ | $B_1:9-11$ | $B_2:15-24$ | $B_3:25-40$ |\n\n B  40 DP  d  (k,S) k  A B S k  0 d  $k \\le p_d$ $B_d$  $A_d$  $B_d$ __ k'  $q_d$__ $B_d$   $A_d$  $k-p_d$  k'   $k-p_d+q_d$\n\n k = 0 $d_1=0$ $k=0<p_0$ $B_0$  $A_0$  $d_2=1$  k  $q_0=6$ $k>p_1$ $B_1$  $k-p_1=6-4=2$ $B_1$  $A_1$  7  2  $d_3=2$  k  $k:=k-p_1+q_1=6-4+2=4$ $k<p_2$ $B_2$  $A_2$  15  $d_4=3$  k  $k:=q_2=9$ $k<p_3$ $B_3$  $A_3$  25  k  $k=q_3=15$ $f(k,S)=k  \\  S=\\emptyset$\n\nDPFE \n\n$$f(k,S)=\\min_{d \\in S} \\{p_d + f(\\max (k-p_d,0)+q_d, S-\\{d\\})\\}$$\n\n $f(k,\\emptyset)=k$ $f(0,S^{\\ast})$$S^{\\ast}$ \n```python\ni=[0,1,2,3]\np=[3,4,8,10]\nq=[6,2,9,15]\n\ndef flowshop(k,S)\n    if len(S)==0:\n        return k, []\n    m=1e8\n    for j in range(len(S)):\n        d=S[j]\n        m1, path1=flowshow(max(k-p[d],0)+q[d], S[:j]+S[j+1:])\n        m1+=p[d]\n        if m>m1:\n            m=m1\n            path=[s]+path1\n    return m, path\n\nm, path=flowshow(0,i)\nprint(m)\nprint(path)\n```\n\n##  HANOI\n N  x  y  z  $f(N)$\n\n$$f(i)=2f(i-1)+1$$\n\n x  i  y  x  i-1  z  x  y  z  i-1  y  $f(1)=1$ $f(2)=2 f(1)+1=3, \\ f(3)=2f(2)+1=7, \\ \\cdots$\n\n\n### \n x  y  $<x,y>$ $F(S)$ concatenation\n\n$$F(N,x,y)=F(N-1,x,z)F(1,x,y)F(N-1,z,y)$$\n\n $S=(N,x,y)$ $F(1,x,y)=<x,y>$\n$$\\begin{aligned} F(2,x,y)&=F(1,x,z)F(1,x,y)F(1,z,y)=<x,z><x,y><z,y>\n\\\\\\\\F(3,x,y)&=F(2,x,z)F(1,x,y)F(2,z,y)\n\\\\\\\\ &=<x,y><x,z><y,z><x,y><z,x><z,y><x,y>\\end{aligned}$$\n\n\n```python\npegs = [1,2,3]\ndef hanoi(n,i=1,j=2):\n    if n==1:\n        return [(i,j)]\n    k = pegs.difference({i,j}).pop()\n    return hanoi(n-1,i,k)+hanoi(1,i,j)+hanoi(n-1,k,j)\n\nif __name__ == '__main__':\n    s=hanoi(3)\n    print(s)\n```\n\n##  ILP\n\n$$\\max c^{\\top}x\n\\\\\\\\ s.t. Ax \\le b\n\\\\\\\\ x_1,...,x_n \\in \\mathbf N \\cup \\{0\\}$$\n A  b, c  DP  $x_1$  $x_1$  $\\sum_{i=2}^n c_i x_i$  $x$  $x_i$  $x_1,...,x_{i-1}$  S  j  $x_{j+1}$  $x_j$ DPFE  DPFE \n$$f(j,S)=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,S \\cup \\{(j+1,x_{j+1})\\})\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}$$\n $D$  $S$  $f(0,\\emptyset)$\n\n\n\n$$Ax \\le b$$\n\n $A$  $m \\times n$ m  \n\n$$A_{i,:}x \\le b_i \\Rightarrow \\sum_{j=1}^n A_{i,j}x_j \\le b_i$$\n\n $x_j$  $x_j$  j $x_{j+1}$ \n\n$$\\sum_{k=j+2}^n A_{i,k}x_k \\le b_i - A_{i,1}x_1 - \\cdots A_{i,j+1}x_{j+1}$$\n\n S DPFE \n\n$$f(j,(y_1,...,y_m))=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,(y_1-A_{1,j+1}x_{j+1},...,y_m-A_{m,j+1}x_{j+1}))\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}$$\n\n $f(0,(b_1,...,b_m))$ $D$ j $S=(j,(y_1,...,y_m))$\n\n$$A_{1,j+1}x_{j+1} + A_{1,j+2}x_{j+2} + \\cdots + A_{1,n}x_n \\le y_1\n\\\\\\\\ \\vdots\n\\\\\\\\ A_{m,j+1}x_{j+1} + A_{m,j+2}x_{j+2} + \\cdots + A_{m,n}x_n \\le y_m$$\n $x_{j+1}$  \n$$\\{0,...,\\min \\{\\lfloor \\frac{y_1}{A_{1,j+1}} \\rfloor, ..., \\lfloor \\frac{y_m}{A_{m,j+1}} \\rfloor\\}\\}$$\n\n $\\frac {y_i} 0$ $\\infty$ i  $x_{j+1}$ \n\n $D$  \n$$y_i=b_i-\\sum_{p \\in S} A_{i,p_1}p_2$$\n\n\n$c=(3,5), \\ b=(4,12,18)$$A=\\begin{pmatrix} 1 & 0 \\\\\\\\ 0 & 2 \\\\\\\\ 3 & 2 \\end{pmatrix}$ $x=(x_1,x_2)$\n\n```python\nc=[3,5]\nb=[4,12,18]\na=[[1,0],\n   [0,2],\n   [3,2]]\n\nm,n=len(b),len(c)\n\ndef d=(j,y):\n    return min([y[i]//a[i][j] if a[i][j] > 0 else 1e8 for i in range(m)])\n\ndef ilp(j,y):\n    if j==n:\n        return 0, []\n    dm=d(j,y)\n    m_=-1\n    x_=None\n    for d_ in range(dm+1):\n        y_=[y[i]-a[i][j]*d_ for i in range(m)]\n        m1,x1=ilp(j+1,y_)\n        m1+=c[j]*d_\n        if m_ < m1:\n            m_ = m1\n            x_ = [d_]+x1\n    return m_, x_\n\nif __name__ == '__main__':\n    m_, x_ = ilp(0,b)\n    print(m_)   # 36\n    print(x_)   # [2,6]\n```\n\n##  ILP  ILPKNAP\n n=3 $(v_0,v_1,v_2)=(15,25,24)$ $(w_0,w_1,w_2)=(10,18,15)$ 22 ILP  $(x_0,x_1,x_2)$ $c=(v_0,v_1,v_2)$ $A=(w_0,w_1,w_2)$ $b=(22)$ $x_0,x_1,x_2 \\in \\mathbf N \\cup \\{0\\}$\n\n##  INTVL\n N  $P=\\{0,...,N-1\\}$ $(s_i,t_i)$  $i$  $w_i$DPFE \n\n$$f(p,q)=\\max_{d \\in P} \\{f(p,s_d)+c(d|p,q)+f(t_d,q)\\}$$\n f(p,q)  $[p,q]$  d $[s_d,t_d]$  d $[p,s_d]$  $[t_d,q]$  d  $p \\le s_d, t_d \\le q$ $f(p,q)=0, \\ p \\ge q$ $f(0,T)$ $T \\ge \\max_i \\{t_i\\}$\n\n $[p,s_d]$  $[t_d,q]$  $f(p,s_d), \\ f(t_d, q)$ $P$ $f(p,q)=0, \\ p \\ge q$ DPFE \n\n$$f(S,p,q)=\\max_{d \\in S} \\{f(S_L,p,s_d)+c(d|p,q)+f(S_R,t_d,q)\\}$$\n $S_L, \\ S_R \\subset P$  $[p,s_d]$  $[t_d,q]$  $(s_i,t_i)$  $f(S,p,q)=0, \\ p \\ge q \\text{ or } S=\\emptyset$ $f(P,0,T)$ $T \\ge \\max_i \\{t_i\\}$\n```python\nP=[0,1,2,3,4,5]\ns=[9,8,3,5,2,1]\nt=[12,11,10,7,6,4]\nw=[1,2,7,4,4,2]\nT=max(t)\nn=len(s)\n\ndef get_S(prev_S, p, q):\n    return [i for i in prev_S if s[i]>=p and t[i]<=q]\n\ndef intvl(S, p, q):\n    if len(S)==0 or p>=q:\n        return 0, []\n    m_=0\n    d_=None\n    for d in S:\n        m1, d1=intvl(get_S(S, p, s[d]), p, s[d])\n        m2, d2=intvl(get_S(S, t[d], q), t[d], q)\n        m=m1+m2+w[d]\n        if m_<m:\n            m_=m\n            d_=[d]+d1+d2\n    return m_, d_\n\nif __name__ == '__main__':\n    m, d= intvl(P, 0, T)\n    print(m)\n    print(d)\n```\n\n $P$ N $P$  i  $P$  N-i-1  N  N-1-i  i  $D_i=\\{j|t_j \\le s_i\\}$  $\\pi(i)=\\max D_i$ $\\pi(i)$ DPFE \n\n$$f(k)=\\max\\{w_k+f(\\pi(k)), f(k-1)\\}$$\n\nk  1  0  k $w_k+f(\\pi(k))$ k $f(k-1)$ k\n\n$$f(k)=\\max_{d \\in \\{0,1\\}} \\{d\\cdot(w_k+f(\\pi (k-1)))+(1-d)\\cdot f(k-1)\\}$$\n\n\n```python\nimport numpy as np\n\ns=[9,8,3,5,2,1]\nt=[12,11,10,7,6,4]\nw=[1,2,7,4,4,2]\n\nP=np.argsort(t)\nt=np.sort(t)\ns=np.array(s)[P]\nw=np.array(w)[P]\n\ndef pi(k):\n    for i in range(k-1,-1,-1):\n        if t[i]<=s[k]:\n            return i\n    return -1\n\ndef intvl1(k):\n    if k==-1:\n        return 0, []\n    m1,d1=intvl1(pi(k))\n    m2,d2=intvl2(k-1)\n    if m1+w[k]>=m2:\n        return m1+w[k], [k]+d1\n    else:\n        return m2, d2\n\nif __name__ == '__main__':\n    m, d= intvl(P, 0, T)\n    print(m)\n    print(P[d])\n```\n","slug":"dp/DP3","published":1,"updated":"2020-04-24T10:32:58.204Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or911002ap0dj4nvkc92b","content":"<p> <a href=\"2019/08/14/DP2\">DP2</a>  DP </p>\n<h2 id=\"-FLOWSHOP\"><a href=\"#-FLOWSHOP\" class=\"headerlink\" title=\" FLOWSHOP\"></a> FLOWSHOP</h2><p> A  BB  A A B  $i=\\{0,1,2,3\\}$ A  $p_i=\\{3,4,8,10\\}$B  $q_i=\\{6,2,9,15\\}$ $0,1,2,3$</p>\n<span id=\"more\"></span>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">processor 1</th>\n<th style=\"text-align:center\">$A_0: 0-3$</th>\n<th style=\"text-align:center\">$A_1:3-7$</th>\n<th style=\"text-align:center\">$A_2:7-15$</th>\n<th style=\"text-align:center\">$A_3:15-25$</th>\n<th style=\"text-align:center\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>processor 2</strong></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">$B_0: 3-9$</td>\n<td style=\"text-align:center\">$B_1:9-11$</td>\n<td style=\"text-align:center\">$B_2:15-24$</td>\n<td style=\"text-align:center\">$B_3:25-40$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p> B  40 DP  d  (k,S) k  A B S k  0 d  $k \\le p_d$ $B_d$  $A_d$  $B_d$ <strong> k  $q_d$</strong> $B_d$   $A_d$  $k-p_d$  k   $k-p_d+q_d$</p>\n<p> k = 0 $d_1=0$ $k=0<p_0$ $B_0$  $A_0$  $d_2=1$  k  $q_0=6$ $k>p_1$ $B_1$  $k-p_1=6-4=2$ $B_1$  $A_1$  7  2  $d_3=2$  k  $k:=k-p_1+q_1=6-4+2=4$ $k&lt;p_2$ $B_2$  $A_2$  15  $d_4=3$  k  $k:=q_2=9$ $k&lt;p_3$ $B_3$  $A_3$  25  k  $k=q_3=15$ $f(k,S)=k  \\  S=\\emptyset$</p>\n<p>DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_{d \\in S} \\{p_d + f(\\max (k-p_d,0)+q_d, S-\\{d\\})\\}</script><p> $f(k,\\emptyset)=k$ $f(0,S^{\\ast})$$S^{\\ast}$ <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">i=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\">p=[<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">8</span>,<span class=\"number\">10</span>]</span><br><span class=\"line\">q=[<span class=\"number\">6</span>,<span class=\"number\">2</span>,<span class=\"number\">9</span>,<span class=\"number\">15</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">flowshop</span>(<span class=\"params\">k,S</span>)</span></span><br><span class=\"line\"><span class=\"function\">    <span class=\"title\">if</span> <span class=\"title\">len</span>(<span class=\"params\">S</span>)==0:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> k, []</span><br><span class=\"line\">    m=<span class=\"number\">1e8</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(S)):</span><br><span class=\"line\">        d=S[j]</span><br><span class=\"line\">        m1, path1=flowshow(<span class=\"built_in\">max</span>(k-p[d],<span class=\"number\">0</span>)+q[d], S[:j]+S[j+<span class=\"number\">1</span>:])</span><br><span class=\"line\">        m1+=p[d]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m&gt;m1:</span><br><span class=\"line\">            m=m1</span><br><span class=\"line\">            path=[s]+path1</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m, path</span><br><span class=\"line\"></span><br><span class=\"line\">m, path=flowshow(<span class=\"number\">0</span>,i)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(m)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(path)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-HANOI\"><a href=\"#-HANOI\" class=\"headerlink\" title=\" HANOI\"></a> HANOI</h2><p> N  x  y  z  $f(N)$</p>\n<script type=\"math/tex; mode=display\">f(i)=2f(i-1)+1</script><p> x  i  y  x  i-1  z  x  y  z  i-1  y  $f(1)=1$ $f(2)=2 f(1)+1=3, \\ f(3)=2f(2)+1=7, \\ \\cdots$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> x  y  $<x,y>$ $F(S)$ concatenation</p>\n<script type=\"math/tex; mode=display\">F(N,x,y)=F(N-1,x,z)F(1,x,y)F(N-1,z,y)</script><p> $S=(N,x,y)$ $F(1,x,y)=<x,y>$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F(2,x,y)&=F(1,x,z)F(1,x,y)F(1,z,y)=<x,z><x,y><z,y>\n\\\\\\\\F(3,x,y)&=F(2,x,z)F(1,x,y)F(2,z,y)\n\\\\\\\\ &=<x,y><x,z><y,z><x,y><z,x><z,y><x,y>\\end{aligned}</script><p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pegs = [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hanoi</span>(<span class=\"params\">n,i=<span class=\"number\">1</span>,j=<span class=\"number\">2</span></span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n==<span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [(i,j)]</span><br><span class=\"line\">    k = pegs.difference(&#123;i,j&#125;).pop()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> hanoi(n-<span class=\"number\">1</span>,i,k)+hanoi(<span class=\"number\">1</span>,i,j)+hanoi(n-<span class=\"number\">1</span>,k,j)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    s=hanoi(<span class=\"number\">3</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(s)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-ILP\"><a href=\"#-ILP\" class=\"headerlink\" title=\" ILP\"></a> ILP</h2><p></p>\n<script type=\"math/tex; mode=display\">\\max c^{\\top}x\n\\\\\\\\ s.t. Ax \\le b\n\\\\\\\\ x_1,...,x_n \\in \\mathbf N \\cup \\{0\\}</script><p> A  b, c  DP  $x_1$  $x_1$  $\\sum_{i=2}^n c_i x_i$  $x$  $x_i$  $x_1,,x_{i-1}$  S  j  $x_{j+1}$  $x_j$ DPFE  DPFE </p>\n<script type=\"math/tex; mode=display\">f(j,S)=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,S \\cup \\{(j+1,x_{j+1})\\})\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}</script><p> $D$  $S$  $f(0,\\emptyset)$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">Ax \\le b</script><p> $A$  $m \\times n$ m  </p>\n<script type=\"math/tex; mode=display\">A_{i,:}x \\le b_i \\Rightarrow \\sum_{j=1}^n A_{i,j}x_j \\le b_i</script><p> $x_j$  $x_j$  j $x_{j+1}$ </p>\n<script type=\"math/tex; mode=display\">\\sum_{k=j+2}^n A_{i,k}x_k \\le b_i - A_{i,1}x_1 - \\cdots A_{i,j+1}x_{j+1}</script><p> S DPFE </p>\n<script type=\"math/tex; mode=display\">f(j,(y_1,...,y_m))=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,(y_1-A_{1,j+1}x_{j+1},...,y_m-A_{m,j+1}x_{j+1}))\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}</script><p> $f(0,(b_1,,b_m))$ $D$ j $S=(j,(y_1,,y_m))$</p>\n<script type=\"math/tex; mode=display\">A_{1,j+1}x_{j+1} + A_{1,j+2}x_{j+2} + \\cdots + A_{1,n}x_n \\le y_1\n\\\\\\\\ \\vdots\n\\\\\\\\ A_{m,j+1}x_{j+1} + A_{m,j+2}x_{j+2} + \\cdots + A_{m,n}x_n \\le y_m</script><p> $x_{j+1}$  </p>\n<script type=\"math/tex; mode=display\">\\{0,...,\\min \\{\\lfloor \\frac{y_1}{A_{1,j+1}} \\rfloor, ..., \\lfloor \\frac{y_m}{A_{m,j+1}} \\rfloor\\}\\}</script><p> $\\frac {y_i} 0$ $\\infty$ i  $x_{j+1}$ </p>\n<p> $D$  </p>\n<script type=\"math/tex; mode=display\">y_i=b_i-\\sum_{p \\in S} A_{i,p_1}p_2</script><p></p>\n<p>$c=(3,5), \\ b=(4,12,18)$$A=\\begin{pmatrix} 1 &amp; 0 \\\\\\\\ 0 &amp; 2 \\\\\\\\ 3 &amp; 2 \\end{pmatrix}$ $x=(x_1,x_2)$<br><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c=[<span class=\"number\">3</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\">b=[<span class=\"number\">4</span>,<span class=\"number\">12</span>,<span class=\"number\">18</span>]</span><br><span class=\"line\">a=[[<span class=\"number\">1</span>,<span class=\"number\">0</span>],</span><br><span class=\"line\">   [<span class=\"number\">0</span>,<span class=\"number\">2</span>],</span><br><span class=\"line\">   [<span class=\"number\">3</span>,<span class=\"number\">2</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">m,n=<span class=\"built_in\">len</span>(b),<span class=\"built_in\">len</span>(c)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">d</span>=(<span class=\"params\">j,y</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">min</span>([y[i]//a[i][j] <span class=\"keyword\">if</span> a[i][j] &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"number\">1e8</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(m)])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ilp</span>(<span class=\"params\">j,y</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> j==n:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>, []</span><br><span class=\"line\">    dm=d(j,y)</span><br><span class=\"line\">    m_=-<span class=\"number\">1</span></span><br><span class=\"line\">    x_=<span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> d_ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(dm+<span class=\"number\">1</span>):</span><br><span class=\"line\">        y_=[y[i]-a[i][j]*d_ <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(m)]</span><br><span class=\"line\">        m1,x1=ilp(j+<span class=\"number\">1</span>,y_)</span><br><span class=\"line\">        m1+=c[j]*d_</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m_ &lt; m1:</span><br><span class=\"line\">            m_ = m1</span><br><span class=\"line\">            x_ = [d_]+x1</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m_, x_</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    m_, x_ = ilp(<span class=\"number\">0</span>,b)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(m_)   <span class=\"comment\"># 36</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(x_)   <span class=\"comment\"># [2,6]</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-ILP--ILPKNAP\"><a href=\"#-ILP--ILPKNAP\" class=\"headerlink\" title=\" ILP  ILPKNAP\"></a> ILP  ILPKNAP</h2><p> n=3 $(v_0,v_1,v_2)=(15,25,24)$ $(w_0,w_1,w_2)=(10,18,15)$ 22 ILP  $(x_0,x_1,x_2)$ $c=(v_0,v_1,v_2)$ $A=(w_0,w_1,w_2)$ $b=(22)$ $x_0,x_1,x_2 \\in \\mathbf N \\cup \\{0\\}$</p>\n<h2 id=\"-INTVL\"><a href=\"#-INTVL\" class=\"headerlink\" title=\" INTVL\"></a> INTVL</h2><p> N  $P=\\{0,,N-1\\}$ $(s_i,t_i)$  $i$  $w_i$DPFE </p>\n<script type=\"math/tex; mode=display\">f(p,q)=\\max_{d \\in P} \\{f(p,s_d)+c(d|p,q)+f(t_d,q)\\}</script><p> f(p,q)  $[p,q]$  d $[s_d,t_d]$  d $[p,s_d]$  $[t_d,q]$  d  $p \\le s_d, t_d \\le q$ $f(p,q)=0, \\ p \\ge q$ $f(0,T)$ $T \\ge \\max_i \\{t_i\\}$</p>\n<p> $[p,s_d]$  $[t_d,q]$  $f(p,s_d), \\ f(t_d, q)$ $P$ $f(p,q)=0, \\ p \\ge q$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(S,p,q)=\\max_{d \\in S} \\{f(S_L,p,s_d)+c(d|p,q)+f(S_R,t_d,q)\\}</script><p> $S_L, \\ S_R \\subset P$  $[p,s_d]$  $[t_d,q]$  $(s_i,t_i)$  $f(S,p,q)=0, \\ p \\ge q \\text{ or } S=\\emptyset$ $f(P,0,T)$ $T \\ge \\max_i \\{t_i\\}$<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">P=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\">s=[<span class=\"number\">9</span>,<span class=\"number\">8</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]</span><br><span class=\"line\">t=[<span class=\"number\">12</span>,<span class=\"number\">11</span>,<span class=\"number\">10</span>,<span class=\"number\">7</span>,<span class=\"number\">6</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\">w=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">7</span>,<span class=\"number\">4</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>]</span><br><span class=\"line\">T=<span class=\"built_in\">max</span>(t)</span><br><span class=\"line\">n=<span class=\"built_in\">len</span>(s)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_S</span>(<span class=\"params\">prev_S, p, q</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> prev_S <span class=\"keyword\">if</span> s[i]&gt;=p <span class=\"keyword\">and</span> t[i]&lt;=q]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">intvl</span>(<span class=\"params\">S, p, q</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(S)==<span class=\"number\">0</span> <span class=\"keyword\">or</span> p&gt;=q:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>, []</span><br><span class=\"line\">    m_=<span class=\"number\">0</span></span><br><span class=\"line\">    d_=<span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> S:</span><br><span class=\"line\">        m1, d1=intvl(get_S(S, p, s[d]), p, s[d])</span><br><span class=\"line\">        m2, d2=intvl(get_S(S, t[d], q), t[d], q)</span><br><span class=\"line\">        m=m1+m2+w[d]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m_&lt;m:</span><br><span class=\"line\">            m_=m</span><br><span class=\"line\">            d_=[d]+d1+d2</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m_, d_</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    m, d= intvl(P, <span class=\"number\">0</span>, T)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(m)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(d)</span><br></pre></td></tr></table></figure></p>\n<p> $P$ N $P$  i  $P$  N-i-1  N  N-1-i  i  $D_i=\\{j|t_j \\le s_i\\}$  $\\pi(i)=\\max D_i$ $\\pi(i)$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(k)=\\max\\{w_k+f(\\pi(k)), f(k-1)\\}</script><p>k  1  0  k $w_k+f(\\pi(k))$ k $f(k-1)$ k</p>\n<script type=\"math/tex; mode=display\">f(k)=\\max_{d \\in \\{0,1\\}} \\{d\\cdot(w_k+f(\\pi (k-1)))+(1-d)\\cdot f(k-1)\\}</script><p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">s=[<span class=\"number\">9</span>,<span class=\"number\">8</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]</span><br><span class=\"line\">t=[<span class=\"number\">12</span>,<span class=\"number\">11</span>,<span class=\"number\">10</span>,<span class=\"number\">7</span>,<span class=\"number\">6</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\">w=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">7</span>,<span class=\"number\">4</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">P=np.argsort(t)</span><br><span class=\"line\">t=np.sort(t)</span><br><span class=\"line\">s=np.array(s)[P]</span><br><span class=\"line\">w=np.array(w)[P]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">pi</span>(<span class=\"params\">k</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k-<span class=\"number\">1</span>,-<span class=\"number\">1</span>,-<span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> t[i]&lt;=s[k]:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> i</span><br><span class=\"line\">    <span class=\"keyword\">return</span> -<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">intvl1</span>(<span class=\"params\">k</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> k==-<span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>, []</span><br><span class=\"line\">    m1,d1=intvl1(pi(k))</span><br><span class=\"line\">    m2,d2=intvl2(k-<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> m1+w[k]&gt;=m2:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> m1+w[k], [k]+d1</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> m2, d2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    m, d= intvl(P, <span class=\"number\">0</span>, T)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(m)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(P[d])</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"2019/08/14/DP2\">DP2</a>  DP </p>\n<h2 id=\"-FLOWSHOP\"><a href=\"#-FLOWSHOP\" class=\"headerlink\" title=\" FLOWSHOP\"></a> FLOWSHOP</h2><p> A  BB  A A B  $i=\\{0,1,2,3\\}$ A  $p_i=\\{3,4,8,10\\}$B  $q_i=\\{6,2,9,15\\}$ $0,1,2,3$</p>","more":"<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">processor 1</th>\n<th style=\"text-align:center\">$A_0: 0-3$</th>\n<th style=\"text-align:center\">$A_1:3-7$</th>\n<th style=\"text-align:center\">$A_2:7-15$</th>\n<th style=\"text-align:center\">$A_3:15-25$</th>\n<th style=\"text-align:center\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>processor 2</strong></td>\n<td style=\"text-align:center\"></td>\n<td style=\"text-align:center\">$B_0: 3-9$</td>\n<td style=\"text-align:center\">$B_1:9-11$</td>\n<td style=\"text-align:center\">$B_2:15-24$</td>\n<td style=\"text-align:center\">$B_3:25-40$</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p> B  40 DP  d  (k,S) k  A B S k  0 d  $k \\le p_d$ $B_d$  $A_d$  $B_d$ <strong> k  $q_d$</strong> $B_d$   $A_d$  $k-p_d$  k   $k-p_d+q_d$</p>\n<p> k = 0 $d_1=0$ $k=0<p_0$ $B_0$  $A_0$  $d_2=1$  k  $q_0=6$ $k>p_1$ $B_1$  $k-p_1=6-4=2$ $B_1$  $A_1$  7  2  $d_3=2$  k  $k:=k-p_1+q_1=6-4+2=4$ $k&lt;p_2$ $B_2$  $A_2$  15  $d_4=3$  k  $k:=q_2=9$ $k&lt;p_3$ $B_3$  $A_3$  25  k  $k=q_3=15$ $f(k,S)=k  \\  S=\\emptyset$</p>\n<p>DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_{d \\in S} \\{p_d + f(\\max (k-p_d,0)+q_d, S-\\{d\\})\\}</script><p> $f(k,\\emptyset)=k$ $f(0,S^{\\ast})$$S^{\\ast}$ <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">i=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\">p=[<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">8</span>,<span class=\"number\">10</span>]</span><br><span class=\"line\">q=[<span class=\"number\">6</span>,<span class=\"number\">2</span>,<span class=\"number\">9</span>,<span class=\"number\">15</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">flowshop</span>(<span class=\"params\">k,S</span>)</span></span><br><span class=\"line\"><span class=\"function\">    <span class=\"title\">if</span> <span class=\"title\">len</span>(<span class=\"params\">S</span>)==0:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> k, []</span><br><span class=\"line\">    m=<span class=\"number\">1e8</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(S)):</span><br><span class=\"line\">        d=S[j]</span><br><span class=\"line\">        m1, path1=flowshow(<span class=\"built_in\">max</span>(k-p[d],<span class=\"number\">0</span>)+q[d], S[:j]+S[j+<span class=\"number\">1</span>:])</span><br><span class=\"line\">        m1+=p[d]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m&gt;m1:</span><br><span class=\"line\">            m=m1</span><br><span class=\"line\">            path=[s]+path1</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m, path</span><br><span class=\"line\"></span><br><span class=\"line\">m, path=flowshow(<span class=\"number\">0</span>,i)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(m)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(path)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-HANOI\"><a href=\"#-HANOI\" class=\"headerlink\" title=\" HANOI\"></a> HANOI</h2><p> N  x  y  z  $f(N)$</p>\n<script type=\"math/tex; mode=display\">f(i)=2f(i-1)+1</script><p> x  i  y  x  i-1  z  x  y  z  i-1  y  $f(1)=1$ $f(2)=2 f(1)+1=3, \\ f(3)=2f(2)+1=7, \\ \\cdots$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> x  y  $<x,y>$ $F(S)$ concatenation</p>\n<script type=\"math/tex; mode=display\">F(N,x,y)=F(N-1,x,z)F(1,x,y)F(N-1,z,y)</script><p> $S=(N,x,y)$ $F(1,x,y)=<x,y>$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F(2,x,y)&=F(1,x,z)F(1,x,y)F(1,z,y)=<x,z><x,y><z,y>\n\\\\\\\\F(3,x,y)&=F(2,x,z)F(1,x,y)F(2,z,y)\n\\\\\\\\ &=<x,y><x,z><y,z><x,y><z,x><z,y><x,y>\\end{aligned}</script><p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pegs = [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hanoi</span>(<span class=\"params\">n,i=<span class=\"number\">1</span>,j=<span class=\"number\">2</span></span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n==<span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [(i,j)]</span><br><span class=\"line\">    k = pegs.difference(&#123;i,j&#125;).pop()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> hanoi(n-<span class=\"number\">1</span>,i,k)+hanoi(<span class=\"number\">1</span>,i,j)+hanoi(n-<span class=\"number\">1</span>,k,j)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    s=hanoi(<span class=\"number\">3</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(s)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-ILP\"><a href=\"#-ILP\" class=\"headerlink\" title=\" ILP\"></a> ILP</h2><p></p>\n<script type=\"math/tex; mode=display\">\\max c^{\\top}x\n\\\\\\\\ s.t. Ax \\le b\n\\\\\\\\ x_1,...,x_n \\in \\mathbf N \\cup \\{0\\}</script><p> A  b, c  DP  $x_1$  $x_1$  $\\sum_{i=2}^n c_i x_i$  $x$  $x_i$  $x_1,,x_{i-1}$  S  j  $x_{j+1}$  $x_j$ DPFE  DPFE </p>\n<script type=\"math/tex; mode=display\">f(j,S)=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,S \\cup \\{(j+1,x_{j+1})\\})\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}</script><p> $D$  $S$  $f(0,\\emptyset)$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">Ax \\le b</script><p> $A$  $m \\times n$ m  </p>\n<script type=\"math/tex; mode=display\">A_{i,:}x \\le b_i \\Rightarrow \\sum_{j=1}^n A_{i,j}x_j \\le b_i</script><p> $x_j$  $x_j$  j $x_{j+1}$ </p>\n<script type=\"math/tex; mode=display\">\\sum_{k=j+2}^n A_{i,k}x_k \\le b_i - A_{i,1}x_1 - \\cdots A_{i,j+1}x_{j+1}</script><p> S DPFE </p>\n<script type=\"math/tex; mode=display\">f(j,(y_1,...,y_m))=\\begin{cases} \\max_{x_{j+1} \\in D} \\{c_{j+1}x_{j+1}+f(j+1,(y_1-A_{1,j+1}x_{j+1},...,y_m-A_{m,j+1}x_{j+1}))\\} & j < n\n\\\\\\\\ 0 & j=n \\end{cases}</script><p> $f(0,(b_1,,b_m))$ $D$ j $S=(j,(y_1,,y_m))$</p>\n<script type=\"math/tex; mode=display\">A_{1,j+1}x_{j+1} + A_{1,j+2}x_{j+2} + \\cdots + A_{1,n}x_n \\le y_1\n\\\\\\\\ \\vdots\n\\\\\\\\ A_{m,j+1}x_{j+1} + A_{m,j+2}x_{j+2} + \\cdots + A_{m,n}x_n \\le y_m</script><p> $x_{j+1}$  </p>\n<script type=\"math/tex; mode=display\">\\{0,...,\\min \\{\\lfloor \\frac{y_1}{A_{1,j+1}} \\rfloor, ..., \\lfloor \\frac{y_m}{A_{m,j+1}} \\rfloor\\}\\}</script><p> $\\frac {y_i} 0$ $\\infty$ i  $x_{j+1}$ </p>\n<p> $D$  </p>\n<script type=\"math/tex; mode=display\">y_i=b_i-\\sum_{p \\in S} A_{i,p_1}p_2</script><p></p>\n<p>$c=(3,5), \\ b=(4,12,18)$$A=\\begin{pmatrix} 1 &amp; 0 \\\\\\\\ 0 &amp; 2 \\\\\\\\ 3 &amp; 2 \\end{pmatrix}$ $x=(x_1,x_2)$<br><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c=[<span class=\"number\">3</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\">b=[<span class=\"number\">4</span>,<span class=\"number\">12</span>,<span class=\"number\">18</span>]</span><br><span class=\"line\">a=[[<span class=\"number\">1</span>,<span class=\"number\">0</span>],</span><br><span class=\"line\">   [<span class=\"number\">0</span>,<span class=\"number\">2</span>],</span><br><span class=\"line\">   [<span class=\"number\">3</span>,<span class=\"number\">2</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\">m,n=<span class=\"built_in\">len</span>(b),<span class=\"built_in\">len</span>(c)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">d</span>=(<span class=\"params\">j,y</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">min</span>([y[i]//a[i][j] <span class=\"keyword\">if</span> a[i][j] &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"number\">1e8</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(m)])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ilp</span>(<span class=\"params\">j,y</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> j==n:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>, []</span><br><span class=\"line\">    dm=d(j,y)</span><br><span class=\"line\">    m_=-<span class=\"number\">1</span></span><br><span class=\"line\">    x_=<span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> d_ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(dm+<span class=\"number\">1</span>):</span><br><span class=\"line\">        y_=[y[i]-a[i][j]*d_ <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(m)]</span><br><span class=\"line\">        m1,x1=ilp(j+<span class=\"number\">1</span>,y_)</span><br><span class=\"line\">        m1+=c[j]*d_</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m_ &lt; m1:</span><br><span class=\"line\">            m_ = m1</span><br><span class=\"line\">            x_ = [d_]+x1</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m_, x_</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    m_, x_ = ilp(<span class=\"number\">0</span>,b)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(m_)   <span class=\"comment\"># 36</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(x_)   <span class=\"comment\"># [2,6]</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-ILP--ILPKNAP\"><a href=\"#-ILP--ILPKNAP\" class=\"headerlink\" title=\" ILP  ILPKNAP\"></a> ILP  ILPKNAP</h2><p> n=3 $(v_0,v_1,v_2)=(15,25,24)$ $(w_0,w_1,w_2)=(10,18,15)$ 22 ILP  $(x_0,x_1,x_2)$ $c=(v_0,v_1,v_2)$ $A=(w_0,w_1,w_2)$ $b=(22)$ $x_0,x_1,x_2 \\in \\mathbf N \\cup \\{0\\}$</p>\n<h2 id=\"-INTVL\"><a href=\"#-INTVL\" class=\"headerlink\" title=\" INTVL\"></a> INTVL</h2><p> N  $P=\\{0,,N-1\\}$ $(s_i,t_i)$  $i$  $w_i$DPFE </p>\n<script type=\"math/tex; mode=display\">f(p,q)=\\max_{d \\in P} \\{f(p,s_d)+c(d|p,q)+f(t_d,q)\\}</script><p> f(p,q)  $[p,q]$  d $[s_d,t_d]$  d $[p,s_d]$  $[t_d,q]$  d  $p \\le s_d, t_d \\le q$ $f(p,q)=0, \\ p \\ge q$ $f(0,T)$ $T \\ge \\max_i \\{t_i\\}$</p>\n<p> $[p,s_d]$  $[t_d,q]$  $f(p,s_d), \\ f(t_d, q)$ $P$ $f(p,q)=0, \\ p \\ge q$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(S,p,q)=\\max_{d \\in S} \\{f(S_L,p,s_d)+c(d|p,q)+f(S_R,t_d,q)\\}</script><p> $S_L, \\ S_R \\subset P$  $[p,s_d]$  $[t_d,q]$  $(s_i,t_i)$  $f(S,p,q)=0, \\ p \\ge q \\text{ or } S=\\emptyset$ $f(P,0,T)$ $T \\ge \\max_i \\{t_i\\}$<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">P=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\">s=[<span class=\"number\">9</span>,<span class=\"number\">8</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]</span><br><span class=\"line\">t=[<span class=\"number\">12</span>,<span class=\"number\">11</span>,<span class=\"number\">10</span>,<span class=\"number\">7</span>,<span class=\"number\">6</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\">w=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">7</span>,<span class=\"number\">4</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>]</span><br><span class=\"line\">T=<span class=\"built_in\">max</span>(t)</span><br><span class=\"line\">n=<span class=\"built_in\">len</span>(s)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_S</span>(<span class=\"params\">prev_S, p, q</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> prev_S <span class=\"keyword\">if</span> s[i]&gt;=p <span class=\"keyword\">and</span> t[i]&lt;=q]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">intvl</span>(<span class=\"params\">S, p, q</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(S)==<span class=\"number\">0</span> <span class=\"keyword\">or</span> p&gt;=q:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>, []</span><br><span class=\"line\">    m_=<span class=\"number\">0</span></span><br><span class=\"line\">    d_=<span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> S:</span><br><span class=\"line\">        m1, d1=intvl(get_S(S, p, s[d]), p, s[d])</span><br><span class=\"line\">        m2, d2=intvl(get_S(S, t[d], q), t[d], q)</span><br><span class=\"line\">        m=m1+m2+w[d]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> m_&lt;m:</span><br><span class=\"line\">            m_=m</span><br><span class=\"line\">            d_=[d]+d1+d2</span><br><span class=\"line\">    <span class=\"keyword\">return</span> m_, d_</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    m, d= intvl(P, <span class=\"number\">0</span>, T)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(m)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(d)</span><br></pre></td></tr></table></figure></p>\n<p> $P$ N $P$  i  $P$  N-i-1  N  N-1-i  i  $D_i=\\{j|t_j \\le s_i\\}$  $\\pi(i)=\\max D_i$ $\\pi(i)$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(k)=\\max\\{w_k+f(\\pi(k)), f(k-1)\\}</script><p>k  1  0  k $w_k+f(\\pi(k))$ k $f(k-1)$ k</p>\n<script type=\"math/tex; mode=display\">f(k)=\\max_{d \\in \\{0,1\\}} \\{d\\cdot(w_k+f(\\pi (k-1)))+(1-d)\\cdot f(k-1)\\}</script><p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">s=[<span class=\"number\">9</span>,<span class=\"number\">8</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]</span><br><span class=\"line\">t=[<span class=\"number\">12</span>,<span class=\"number\">11</span>,<span class=\"number\">10</span>,<span class=\"number\">7</span>,<span class=\"number\">6</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\">w=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">7</span>,<span class=\"number\">4</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">P=np.argsort(t)</span><br><span class=\"line\">t=np.sort(t)</span><br><span class=\"line\">s=np.array(s)[P]</span><br><span class=\"line\">w=np.array(w)[P]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">pi</span>(<span class=\"params\">k</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k-<span class=\"number\">1</span>,-<span class=\"number\">1</span>,-<span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> t[i]&lt;=s[k]:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> i</span><br><span class=\"line\">    <span class=\"keyword\">return</span> -<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">intvl1</span>(<span class=\"params\">k</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> k==-<span class=\"number\">1</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>, []</span><br><span class=\"line\">    m1,d1=intvl1(pi(k))</span><br><span class=\"line\">    m2,d2=intvl2(k-<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> m1+w[k]&gt;=m2:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> m1+w[k], [k]+d1</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> m2, d2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    m, d= intvl(P, <span class=\"number\">0</span>, T)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(m)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(P[d])</span><br></pre></td></tr></table></figure></p>"},{"title":"Dynamic Programming (3)","date":"2019-12-20T12:13:18.000Z","p":"dp/DP4","mathjax":true,"_content":"\n## 1. \n\n\n<!-- more -->\n\n N-  `k`  `x`  $C(k,x)$ $(k,s)$ `k`  `s`$D(k)$  `k`  $(k+1,s+x-D(k))$ $C(k,x)$ $I(k,s,x), \\ s>0$ $|s|$  $I(k,s,x), \\ s < 0$","source":"_posts/dp/DP4.md","raw":"---\ntitle: Dynamic Programming (3)\ndate: 2019-12-20 20:13:18\np: dp/DP4\ntags:\n    - math\n    - DP\nmathjax: true\n---\n\n## 1. \n\n\n<!-- more -->\n\n N-  `k`  `x`  $C(k,x)$ $(k,s)$ `k`  `s`$D(k)$  `k`  $(k+1,s+x-D(k))$ $C(k,x)$ $I(k,s,x), \\ s>0$ $|s|$  $I(k,s,x), \\ s < 0$","slug":"dp/DP4","published":1,"updated":"2020-04-24T10:33:06.640Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or912002bp0djhdx8bzai","content":"<h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<span id=\"more\"></span>\n<p> N-  <code>k</code>  <code>x</code>  $C(k,x)$ $(k,s)$ <code>k</code>  <code>s</code>$D(k)$  <code>k</code>  $(k+1,s+x-D(k))$ $C(k,x)$ $I(k,s,x), \\ s&gt;0$ $|s|$  $I(k,s,x), \\ s &lt; 0$</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>","more":"<p> N-  <code>k</code>  <code>x</code>  $C(k,x)$ $(k,s)$ <code>k</code>  <code>s</code>$D(k)$  <code>k</code>  $(k+1,s+x-D(k))$ $C(k,x)$ $I(k,s,x), \\ s&gt;0$ $|s|$  $I(k,s,x), \\ s &lt; 0$</p>"},{"title":"DenseNet","p":"img_cls/densenet","date":"2019-12-31T07:27:49.000Z","mathjax":true,"_content":"\n [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n\n layer deep layerResNet  shortcut early layer  later layer  densenet1\n<!-- more -->\n\n![](/images/img_cls/densenet_1.png)\n\n\n## DenseNet \n $\\mathbf x_0$ $L$  $H_l(\\cdot)$ $\\mathbf x_l$\n### ResNet\n $l$  $\\mathbf x_l = H_l(\\mathbf x_{l-1})$ ResNet  Identity  $\\mathbf x_l = H_l(\\mathbf x_{l-1})+\\mathbf x_{l-1}$ResNet  layer  block layerblock  layer  shortcut \n### Dense \n layer  layer  $l$  layer  layer \n$$\\mathbf x_l=H_l([\\mathbf x_0, ... , \\mathbf x_{l-1}])$$\n $[\\mathbf x_0, ... , \\mathbf x_{l-1}]$  `concatenate`  ResNet  `sum` \n\n### \nDenseNet  layer  $H_l(\\cdot)$ \n1.  BN\n2. ReLU\n3. `3x3` conv\n   \n\n### Pooling \n early layer  later layer  feature maps  2 layer  block Dense Blockblock  feature maps  block  layer block  BN `1x1`  `2x2` \n![](/images/img_cls/densenet_2.png)\n\n### Growth rate\n $k_0$  Dense Block  channels $H_l$  $k$  feature maps $l^{th}$ layer  $\\mathbf x_0$  $l-1$  layer  concatenation $k_0+k(l-1)$  feature maps $k$  $l^{th}$  layer  `in_channels`  $k$  DenseNet  $k$  _growth rate_  layer  feature maps  _growth rate_  layer  block  layer  feature maps collective knowledge feature maps  global state layer  k  feature maps  global state _growth rate_  layer  global state  layer  global state  global state  layer  layer  layer  global state global states \n\n### Bottleneck layers\nlater layer  layer `3x3`   `1x1`  bottleneck layer later layer  bottleneck layer  DenseNet  DenseNet-B layer  $H_l(\\cdot)$  BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3) ____ \n\n### Compression\n feature maps  dense block  feature maps  $m$ dense block  layer  1 feature maps  $\\lfloor \\theta m \\rfloor$ $0 < \\theta \\le 1$ $\\theta=1$ feature maps  $\\theta <1$  DenseNet  DenseNet-C DenseNet-BC  bottleneck layer  $\\theta <1$  DenseNet\n\n### \n CIFAR-10,CIFAR-100,SVHN  ImageNet  DenseNet\n\n size  `32x32`DenseNet  3  dense block dense block  layer dense block  `1x1` 16-out_channels  DenseNet-BC  _growth rate_  `3x3` conv padding=1  zero  feature map size  dense block  softmax  dense block  feature maps  `32x32, 16x16, 8x8` DenseNet B\\C dense block  $\\{L=40,k=12\\}$, $\\{L=100,k=12\\}$  $\\{L=100,k=24\\}$ DenseNet-BC  $\\{L=100,k=12\\}$, $\\{L=250,k=24\\}$  $\\{L=190,k=40\\}$\n\n ImageNet 4  dense block  DenseNet-BC `224x224` layer  `7x7` 2k-out_channelsstride=2  k  _growth-rate_  dense block  $k=32$ 1 \n![](/images/img_cls/densenet_3.png) <center>ImageNet  DenseNet-BC  k=32 conv  __BN-ReLU-Conv__ </center>\n\n## \n\n\n### \n__CIFAR__  CIFAR-10  CIFAR-100  `32x32`  CIFAR-10  10CIFAR-100  100 50000  10000 5000  /  RGB  `mean`  `std`  50000 \n\n__SVHN__  SVHN  `32x32`  73257  26032 531131  6000  255  `[0,1]` \n\n__ImageNet__   ILSVRC 2012  120  5  1000 ResNet  single-crop  10-crop  `224x224` \n\n### \nCIFAR  SVHN  batch  64epoch  300  40 lr = 0.1 50%  75%  epoch  10%\n\nImageNet  batch  256 epoch  90 lr=0.1 epoch = 30  epoch = 60  10%\n\n $10^{-4}$Nesterov momentum  0.9\n\n DenseNet \n\n## DenseNet \n\n1. dense block  layer \n2.  `concatenate`  ResNet  `sum` \n3. layer  layer  filter \n4.  DenseNet early layer \n5. layer ","source":"_posts/img_cls/densenet.md","raw":"---\ntitle: DenseNet\np: img_cls/densenet\ndate: 2019-12-31 15:27:49\ntags: image classification\nmathjax: true\n---\n\n [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n\n layer deep layerResNet  shortcut early layer  later layer  densenet1\n<!-- more -->\n\n![](/images/img_cls/densenet_1.png)\n\n\n## DenseNet \n $\\mathbf x_0$ $L$  $H_l(\\cdot)$ $\\mathbf x_l$\n### ResNet\n $l$  $\\mathbf x_l = H_l(\\mathbf x_{l-1})$ ResNet  Identity  $\\mathbf x_l = H_l(\\mathbf x_{l-1})+\\mathbf x_{l-1}$ResNet  layer  block layerblock  layer  shortcut \n### Dense \n layer  layer  $l$  layer  layer \n$$\\mathbf x_l=H_l([\\mathbf x_0, ... , \\mathbf x_{l-1}])$$\n $[\\mathbf x_0, ... , \\mathbf x_{l-1}]$  `concatenate`  ResNet  `sum` \n\n### \nDenseNet  layer  $H_l(\\cdot)$ \n1.  BN\n2. ReLU\n3. `3x3` conv\n   \n\n### Pooling \n early layer  later layer  feature maps  2 layer  block Dense Blockblock  feature maps  block  layer block  BN `1x1`  `2x2` \n![](/images/img_cls/densenet_2.png)\n\n### Growth rate\n $k_0$  Dense Block  channels $H_l$  $k$  feature maps $l^{th}$ layer  $\\mathbf x_0$  $l-1$  layer  concatenation $k_0+k(l-1)$  feature maps $k$  $l^{th}$  layer  `in_channels`  $k$  DenseNet  $k$  _growth rate_  layer  feature maps  _growth rate_  layer  block  layer  feature maps collective knowledge feature maps  global state layer  k  feature maps  global state _growth rate_  layer  global state  layer  global state  global state  layer  layer  layer  global state global states \n\n### Bottleneck layers\nlater layer  layer `3x3`   `1x1`  bottleneck layer later layer  bottleneck layer  DenseNet  DenseNet-B layer  $H_l(\\cdot)$  BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3) ____ \n\n### Compression\n feature maps  dense block  feature maps  $m$ dense block  layer  1 feature maps  $\\lfloor \\theta m \\rfloor$ $0 < \\theta \\le 1$ $\\theta=1$ feature maps  $\\theta <1$  DenseNet  DenseNet-C DenseNet-BC  bottleneck layer  $\\theta <1$  DenseNet\n\n### \n CIFAR-10,CIFAR-100,SVHN  ImageNet  DenseNet\n\n size  `32x32`DenseNet  3  dense block dense block  layer dense block  `1x1` 16-out_channels  DenseNet-BC  _growth rate_  `3x3` conv padding=1  zero  feature map size  dense block  softmax  dense block  feature maps  `32x32, 16x16, 8x8` DenseNet B\\C dense block  $\\{L=40,k=12\\}$, $\\{L=100,k=12\\}$  $\\{L=100,k=24\\}$ DenseNet-BC  $\\{L=100,k=12\\}$, $\\{L=250,k=24\\}$  $\\{L=190,k=40\\}$\n\n ImageNet 4  dense block  DenseNet-BC `224x224` layer  `7x7` 2k-out_channelsstride=2  k  _growth-rate_  dense block  $k=32$ 1 \n![](/images/img_cls/densenet_3.png) <center>ImageNet  DenseNet-BC  k=32 conv  __BN-ReLU-Conv__ </center>\n\n## \n\n\n### \n__CIFAR__  CIFAR-10  CIFAR-100  `32x32`  CIFAR-10  10CIFAR-100  100 50000  10000 5000  /  RGB  `mean`  `std`  50000 \n\n__SVHN__  SVHN  `32x32`  73257  26032 531131  6000  255  `[0,1]` \n\n__ImageNet__   ILSVRC 2012  120  5  1000 ResNet  single-crop  10-crop  `224x224` \n\n### \nCIFAR  SVHN  batch  64epoch  300  40 lr = 0.1 50%  75%  epoch  10%\n\nImageNet  batch  256 epoch  90 lr=0.1 epoch = 30  epoch = 60  10%\n\n $10^{-4}$Nesterov momentum  0.9\n\n DenseNet \n\n## DenseNet \n\n1. dense block  layer \n2.  `concatenate`  ResNet  `sum` \n3. layer  layer  filter \n4.  DenseNet early layer \n5. layer ","slug":"img_cls/densenet","published":1,"updated":"2020-04-24T10:33:15.098Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or913002dp0dj001b96yg","content":"<p> <a href=\"https://arxiv.org/abs/1608.06993\">Densely Connected Convolutional Networks</a></p>\n<p> layer deep layerResNet  shortcut early layer  later layer  densenet1<br><span id=\"more\"></span></p>\n<p><img src=\"/images/img_cls/densenet_1.png\" alt=\"\"></p>\n<h2 id=\"DenseNet-\"><a href=\"#DenseNet-\" class=\"headerlink\" title=\"DenseNet \"></a>DenseNet </h2><p> $\\mathbf x_0$ $L$  $H_l(\\cdot)$ $\\mathbf x_l$</p>\n<h3 id=\"ResNet\"><a href=\"#ResNet\" class=\"headerlink\" title=\"ResNet\"></a>ResNet</h3><p> $l$  $\\mathbf x_l = H_l(\\mathbf x_{l-1})$ ResNet  Identity  $\\mathbf x_l = H_l(\\mathbf x_{l-1})+\\mathbf x_{l-1}$ResNet  layer  block layerblock  layer  shortcut </p>\n<h3 id=\"Dense-\"><a href=\"#Dense-\" class=\"headerlink\" title=\"Dense \"></a>Dense </h3><p> layer  layer  $l$  layer  layer </p>\n<script type=\"math/tex; mode=display\">\\mathbf x_l=H_l([\\mathbf x_0, ... , \\mathbf x_{l-1}])</script><p> $[\\mathbf x_0,  , \\mathbf x_{l-1}]$  <code>concatenate</code>  ResNet  <code>sum</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>DenseNet  layer  $H_l(\\cdot)$ </p>\n<ol>\n<li> BN</li>\n<li>ReLU</li>\n<li><code>3x3</code> conv</li>\n</ol>\n<p></p>\n<h3 id=\"Pooling-\"><a href=\"#Pooling-\" class=\"headerlink\" title=\"Pooling \"></a>Pooling </h3><p> early layer  later layer  feature maps  2 layer  block Dense Blockblock  feature maps  block  layer block  BN <code>1x1</code>  <code>2x2</code> <br><img src=\"/images/img_cls/densenet_2.png\" alt=\"\"></p>\n<h3 id=\"Growth-rate\"><a href=\"#Growth-rate\" class=\"headerlink\" title=\"Growth rate\"></a>Growth rate</h3><p> $k_0$  Dense Block  channels $H_l$  $k$  feature maps $l^{th}$ layer  $\\mathbf x_0$  $l-1$  layer  concatenation $k_0+k(l-1)$  feature maps $k$  $l^{th}$  layer  <code>in_channels</code>  $k$  DenseNet  $k$  _growth rate_  layer  feature maps  _growth rate_  layer  block  layer  feature maps collective knowledge feature maps  global state layer  k  feature maps  global state _growth rate_  layer  global state  layer  global state  global state  layer  layer  layer  global state global states </p>\n<h3 id=\"Bottleneck-layers\"><a href=\"#Bottleneck-layers\" class=\"headerlink\" title=\"Bottleneck layers\"></a>Bottleneck layers</h3><p>later layer  layer <code>3x3</code>   <code>1x1</code>  bottleneck layer later layer  bottleneck layer  DenseNet  DenseNet-B layer  $H_l(\\cdot)$  BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3) <strong></strong> </p>\n<h3 id=\"Compression\"><a href=\"#Compression\" class=\"headerlink\" title=\"Compression\"></a>Compression</h3><p> feature maps  dense block  feature maps  $m$ dense block  layer  1 feature maps  $\\lfloor \\theta m \\rfloor$ $0 &lt; \\theta \\le 1$ $\\theta=1$ feature maps  $\\theta &lt;1$  DenseNet  DenseNet-C DenseNet-BC  bottleneck layer  $\\theta &lt;1$  DenseNet</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> CIFAR-10,CIFAR-100,SVHN  ImageNet  DenseNet</p>\n<p> size  <code>32x32</code>DenseNet  3  dense block dense block  layer dense block  <code>1x1</code> 16-out_channels  DenseNet-BC  _growth rate_  <code>3x3</code> conv padding=1  zero  feature map size  dense block  softmax  dense block  feature maps  <code>32x32, 16x16, 8x8</code> DenseNet B\\C dense block  $\\{L=40,k=12\\}$, $\\{L=100,k=12\\}$  $\\{L=100,k=24\\}$ DenseNet-BC  $\\{L=100,k=12\\}$, $\\{L=250,k=24\\}$  $\\{L=190,k=40\\}$</p>\n<p> ImageNet 4  dense block  DenseNet-BC <code>224x224</code> layer  <code>7x7</code> 2k-out_channelsstride=2  k  _growth-rate_  dense block  $k=32$ 1 <br><img src=\"/images/img_cls/densenet_3.png\" alt=\"\"> <center>ImageNet  DenseNet-BC  k=32 conv  __BN-ReLU-Conv__ </center></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>CIFAR</strong>  CIFAR-10  CIFAR-100  <code>32x32</code>  CIFAR-10  10CIFAR-100  100 50000  10000 5000  /  RGB  <code>mean</code>  <code>std</code>  50000 </p>\n<p><strong>SVHN</strong>  SVHN  <code>32x32</code>  73257  26032 531131  6000  255  <code>[0,1]</code> </p>\n<p><strong>ImageNet</strong>   ILSVRC 2012  120  5  1000 ResNet  single-crop  10-crop  <code>224x224</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>CIFAR  SVHN  batch  64epoch  300  40 lr = 0.1 50%  75%  epoch  10%</p>\n<p>ImageNet  batch  256 epoch  90 lr=0.1 epoch = 30  epoch = 60  10%</p>\n<p> $10^{-4}$Nesterov momentum  0.9</p>\n<p> DenseNet </p>\n<h2 id=\"DenseNet-\"><a href=\"#DenseNet-\" class=\"headerlink\" title=\"DenseNet \"></a>DenseNet </h2><ol>\n<li>dense block  layer </li>\n<li> <code>concatenate</code>  ResNet  <code>sum</code> </li>\n<li>layer  layer  filter </li>\n<li> DenseNet early layer </li>\n<li>layer </li>\n</ol>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1608.06993\">Densely Connected Convolutional Networks</a></p>\n<p> layer deep layerResNet  shortcut early layer  later layer  densenet1<br>","more":"</p>\n<p><img src=\"/images/img_cls/densenet_1.png\" alt=\"\"></p>\n<h2 id=\"DenseNet-\"><a href=\"#DenseNet-\" class=\"headerlink\" title=\"DenseNet \"></a>DenseNet </h2><p> $\\mathbf x_0$ $L$  $H_l(\\cdot)$ $\\mathbf x_l$</p>\n<h3 id=\"ResNet\"><a href=\"#ResNet\" class=\"headerlink\" title=\"ResNet\"></a>ResNet</h3><p> $l$  $\\mathbf x_l = H_l(\\mathbf x_{l-1})$ ResNet  Identity  $\\mathbf x_l = H_l(\\mathbf x_{l-1})+\\mathbf x_{l-1}$ResNet  layer  block layerblock  layer  shortcut </p>\n<h3 id=\"Dense-\"><a href=\"#Dense-\" class=\"headerlink\" title=\"Dense \"></a>Dense </h3><p> layer  layer  $l$  layer  layer </p>\n<script type=\"math/tex; mode=display\">\\mathbf x_l=H_l([\\mathbf x_0, ... , \\mathbf x_{l-1}])</script><p> $[\\mathbf x_0,  , \\mathbf x_{l-1}]$  <code>concatenate</code>  ResNet  <code>sum</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>DenseNet  layer  $H_l(\\cdot)$ </p>\n<ol>\n<li> BN</li>\n<li>ReLU</li>\n<li><code>3x3</code> conv</li>\n</ol>\n<p></p>\n<h3 id=\"Pooling-\"><a href=\"#Pooling-\" class=\"headerlink\" title=\"Pooling \"></a>Pooling </h3><p> early layer  later layer  feature maps  2 layer  block Dense Blockblock  feature maps  block  layer block  BN <code>1x1</code>  <code>2x2</code> <br><img src=\"/images/img_cls/densenet_2.png\" alt=\"\"></p>\n<h3 id=\"Growth-rate\"><a href=\"#Growth-rate\" class=\"headerlink\" title=\"Growth rate\"></a>Growth rate</h3><p> $k_0$  Dense Block  channels $H_l$  $k$  feature maps $l^{th}$ layer  $\\mathbf x_0$  $l-1$  layer  concatenation $k_0+k(l-1)$  feature maps $k$  $l^{th}$  layer  <code>in_channels</code>  $k$  DenseNet  $k$  _growth rate_  layer  feature maps  _growth rate_  layer  block  layer  feature maps collective knowledge feature maps  global state layer  k  feature maps  global state _growth rate_  layer  global state  layer  global state  global state  layer  layer  layer  global state global states </p>\n<h3 id=\"Bottleneck-layers\"><a href=\"#Bottleneck-layers\" class=\"headerlink\" title=\"Bottleneck layers\"></a>Bottleneck layers</h3><p>later layer  layer <code>3x3</code>   <code>1x1</code>  bottleneck layer later layer  bottleneck layer  DenseNet  DenseNet-B layer  $H_l(\\cdot)$  BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3) <strong></strong> </p>\n<h3 id=\"Compression\"><a href=\"#Compression\" class=\"headerlink\" title=\"Compression\"></a>Compression</h3><p> feature maps  dense block  feature maps  $m$ dense block  layer  1 feature maps  $\\lfloor \\theta m \\rfloor$ $0 &lt; \\theta \\le 1$ $\\theta=1$ feature maps  $\\theta &lt;1$  DenseNet  DenseNet-C DenseNet-BC  bottleneck layer  $\\theta &lt;1$  DenseNet</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> CIFAR-10,CIFAR-100,SVHN  ImageNet  DenseNet</p>\n<p> size  <code>32x32</code>DenseNet  3  dense block dense block  layer dense block  <code>1x1</code> 16-out_channels  DenseNet-BC  _growth rate_  <code>3x3</code> conv padding=1  zero  feature map size  dense block  softmax  dense block  feature maps  <code>32x32, 16x16, 8x8</code> DenseNet B\\C dense block  $\\{L=40,k=12\\}$, $\\{L=100,k=12\\}$  $\\{L=100,k=24\\}$ DenseNet-BC  $\\{L=100,k=12\\}$, $\\{L=250,k=24\\}$  $\\{L=190,k=40\\}$</p>\n<p> ImageNet 4  dense block  DenseNet-BC <code>224x224</code> layer  <code>7x7</code> 2k-out_channelsstride=2  k  _growth-rate_  dense block  $k=32$ 1 <br><img src=\"/images/img_cls/densenet_3.png\" alt=\"\"> <center>ImageNet  DenseNet-BC  k=32 conv  __BN-ReLU-Conv__ </center></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>CIFAR</strong>  CIFAR-10  CIFAR-100  <code>32x32</code>  CIFAR-10  10CIFAR-100  100 50000  10000 5000  /  RGB  <code>mean</code>  <code>std</code>  50000 </p>\n<p><strong>SVHN</strong>  SVHN  <code>32x32</code>  73257  26032 531131  6000  255  <code>[0,1]</code> </p>\n<p><strong>ImageNet</strong>   ILSVRC 2012  120  5  1000 ResNet  single-crop  10-crop  <code>224x224</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>CIFAR  SVHN  batch  64epoch  300  40 lr = 0.1 50%  75%  epoch  10%</p>\n<p>ImageNet  batch  256 epoch  90 lr=0.1 epoch = 30  epoch = 60  10%</p>\n<p> $10^{-4}$Nesterov momentum  0.9</p>\n<p> DenseNet </p>\n<h2 id=\"DenseNet-\"><a href=\"#DenseNet-\" class=\"headerlink\" title=\"DenseNet \"></a>DenseNet </h2><ol>\n<li>dense block  layer </li>\n<li> <code>concatenate</code>  ResNet  <code>sum</code> </li>\n<li>layer  layer  filter </li>\n<li> DenseNet early layer </li>\n<li>layer </li>\n</ol>"},{"title":"img_cls/resnet.md","p":"img_cls/resnet","date":"2021-01-19T09:25:25.000Z","mathjax":true,"_content":" Resnet \n<!-- more -->\n\n# ImageNet\n## \n1. scale w,h  resize  `[256,418]` \n2.  resized  center crop  `224x224` \n3. 10-crop testingcrop center 5  patch 5  patch 10  patch softmax \n\n## \n1. baseline  VGG plain conv  activation  BatchNorm \n2.  conv3_1,  conv4_1, conv5_1 stride=2\n![](/images/img_cls/resnet_1.png)<center> 1. </center>\n3.  conv block  shortcut output  concatenate conv3_1,  conv4_1, conv5_1 output  (H,W)  (C)  shortcut a. identity mapping stride=2 H  W 0 b. `1x1` convstride=2  channel \n4.  ResNet-18  ResNet-34  identity mapping zero-padding \n5. conv3_1,  conv4_1, conv5_1  ResNet-18  ResNet-34conv block  `3x3` conv layer  conv3_1,  conv4_1, conv5_1  conv block  conv layer  ResNet-50ResNet-101  ResNet-152conv block  conv layer  bottleneckconv  `1x1`, `3x3`, `1x1`  conv3_1,  conv4_1, conv5_1  conv block  `3x3` \n6.  `2x2x2x2x2=32` `224x224` conv  feature  `7x7` feature map  GAP channel  full connection  1000  softmax \n7. ResNet-x `x`  layer \n8. shortcut  residual function  channel  relu \n9.  shortcut  stride=2 \n## \n### plain vs. resnet\n 18 layers  34 layers  plain  ResNettop-1 \n\n| | plain | ResNet|\n|:--------:       | :------:    |   :-------:          |\n|18 layers| 27.94 | 27.88|\n| 34 layers| 28.54| <b> 25.03 </b>|\n <center> 1. plain  Resnet ResNet  identity shortcutImageNet 10-crop testing</center>\n\n\n- plain\n- ResNet  identity mapping zero padding channel shortcutResNet-34  ResNet-18  ResNet \n- ResNet-18  plain-18 \n\n### Projection Shortcut\n `1x1` conv  identity mapping conv block  shortcut \n\n$$\\mathbf y = \\mathcal F(\\mathbf x, \\{W_i\\}) + W_s \\mathbf x $$\n 34 layers \n\n* A shortcut  identity mapping zero-padding  ResNet-34 \n* Bconv3_1, conv4_1, conv5_1 projection shortcut shortcut  identity mapping zero-padding\n* C shortcuts  projection shortcut zero-padding\n\n\n|model|top-1 err | top-5 err|\n|:--|:--|:--|\n|plain-34| 28.54| 10.02|\n|ResNet-34 A|25.03|7.76|\n|ResNet-34 B|24.52|7.46|\n|ResNet-34 C|24.19|7.4|\n|ResNet-50|22.85|6.71|\n|ResNet-101|21.75|6.05|\n|ResNet-50|<b>21.43</b>|<b>5.71</b>|\n<center> 2. projection shortcut  ResNet <font color='clan'>ResNet-50/101/152  B</font>ImageNet 10-crop testing</center>\n\n\n-  plain B  A C  B  A  projection shortcutprojection shortcut C  B \n\n### Bottleneck \n 1  conv block  conv  bottleneck  conv`1x1`, `3x3`, `1x1` `1x1`  channel 1/4(H,W) `3x3` (H,W) channel  `1x1`  channel 4  conv layer  bottleneck \n![](/images/img_cls/resnet_2.png)<center> 2. ImageNet  1 conv bottleneck  ResNet-50/101/152 </center>\n\n Bottleneck identity shortcut  projectionmodel  shortcut  channel  4  shortcut \n\n### ResNet-50/101/152\n ResNet-34  conv block  bottleneck  ResNet-50 1ResNet-34  `3+4+6+3=16`  conv block layer  16ResNet-50  B\n\n ResNet-50  bottleneck  ResNet-101  ResNet152\n\nResNet-50/101/152  ResNet-34  2 ResNet \n\n ResNet <font color=\"red\"></font>\n\n ResNet \n\n## \n\n1.  SGD \n2. mini-batch=256\n3.  `0.1`  `1/10` \n4.  `0.0001`momentum=0.9\n5.  BatchNorm Dropout\n\n# CIFAR-10\n SOTA  ResNet-34  plain  size  `32x32` ImageNet  size `224x224` \n## \n\n layer  kernel ImageNet  `7x7` `3x3`  convstride=1 channel  16 6n6  conv layer 2n  conv layer  3  feature size  `(32, 16, 8)`channel  filter  `(16, 32, 64)` GAP + full connection + softmax layer  `6n+2` \n>  stride=2  conv layer  1 \n\n\n\n| map size|32x32|16x16|8x8|\n|:---|:---|:---|:---|\n|#layers|2n+1|2n|2n|\n|#filters|16|32|64|\n\n\n identity shortcut identity shortcut layer  rate=2  (H,W)  channel  channel residual function  channel  channel  channel  (H,W)  element-wise  add \n\n6n  conv layer conv layer  shortcut 3n  shortcut identity shortcut\n\n## \n\n-  ImageNet  mini-batch=128 `0.1` 32k  48k  `1/10` 64k \n- CIFAR-10  50k 10k 10 45k/5k  train/val \n-  4 pixel  0.5  crop  32x32  patch\n\n## \n `n={3,5,7,9}`  `20, 32, 44, 56`  layer  3\n![](/images/img_cls/resnet_3.png)<center> 3. CIFAR-10  plain-110  60%</center>\n\n 3 ResNet n=18  ResNet-110 0.1  0.01 80%  400  0.1  ImageNet \n\n\n\nResNet-110  deep & thin \n||#layers|#params(M)|error(%)|\n|:---|:---|:---|:---|\n|FitNet|19|2.5|8.39|\n|Highway|19|2.3|7.54(7.72  0.16)|\n|Highway|32|1.25|8.8|\n|ResNet|20|0.27|8.75|\n|ResNet|32|0.46|7.51|\n|ResNet|44|0.66|7.17|\n|ResNet|56|0.85|6.97|\n|ResNet|110|1.7|<b>6.43</b>(6.610.16)|\n|ResNet|1202|19.4|7.93|\n<center>CIFAR-10  Highway  ResNet-110  5  6.43%  6.61%0.16</center>\n\n## Layer \n 4  CIFAR-10  `3x3` layer  BN activate  layer \n![](/images/img_cls/resnet_4.png)<center> 4. 3x3</center>\n\n 4ResNet  plain  ResNet  0  relu  sigmoid  ResNet  layer  layer \n\n##  layers>1000\nn=200 6n+2=1202  3  `<0.1%` `7.93%` ResNet-110 `maxout``dropout`  deep & thin deep \n> deep: thin:  conv-bn-reluwide:  feature size \n\n\n# \n Faster R-CNN baseline  VGG-16  ResNet-101\n\n## \n1.  ImageNet  fine-tune","source":"_posts/img_cls/resnet.md","raw":"---\ntitle: img_cls/resnet.md\np: img_cls/resnet\ndate: 2021-01-19 17:25:25\ntags: img cls\nmathjax: true\n---\n Resnet \n<!-- more -->\n\n# ImageNet\n## \n1. scale w,h  resize  `[256,418]` \n2.  resized  center crop  `224x224` \n3. 10-crop testingcrop center 5  patch 5  patch 10  patch softmax \n\n## \n1. baseline  VGG plain conv  activation  BatchNorm \n2.  conv3_1,  conv4_1, conv5_1 stride=2\n![](/images/img_cls/resnet_1.png)<center> 1. </center>\n3.  conv block  shortcut output  concatenate conv3_1,  conv4_1, conv5_1 output  (H,W)  (C)  shortcut a. identity mapping stride=2 H  W 0 b. `1x1` convstride=2  channel \n4.  ResNet-18  ResNet-34  identity mapping zero-padding \n5. conv3_1,  conv4_1, conv5_1  ResNet-18  ResNet-34conv block  `3x3` conv layer  conv3_1,  conv4_1, conv5_1  conv block  conv layer  ResNet-50ResNet-101  ResNet-152conv block  conv layer  bottleneckconv  `1x1`, `3x3`, `1x1`  conv3_1,  conv4_1, conv5_1  conv block  `3x3` \n6.  `2x2x2x2x2=32` `224x224` conv  feature  `7x7` feature map  GAP channel  full connection  1000  softmax \n7. ResNet-x `x`  layer \n8. shortcut  residual function  channel  relu \n9.  shortcut  stride=2 \n## \n### plain vs. resnet\n 18 layers  34 layers  plain  ResNettop-1 \n\n| | plain | ResNet|\n|:--------:       | :------:    |   :-------:          |\n|18 layers| 27.94 | 27.88|\n| 34 layers| 28.54| <b> 25.03 </b>|\n <center> 1. plain  Resnet ResNet  identity shortcutImageNet 10-crop testing</center>\n\n\n- plain\n- ResNet  identity mapping zero padding channel shortcutResNet-34  ResNet-18  ResNet \n- ResNet-18  plain-18 \n\n### Projection Shortcut\n `1x1` conv  identity mapping conv block  shortcut \n\n$$\\mathbf y = \\mathcal F(\\mathbf x, \\{W_i\\}) + W_s \\mathbf x $$\n 34 layers \n\n* A shortcut  identity mapping zero-padding  ResNet-34 \n* Bconv3_1, conv4_1, conv5_1 projection shortcut shortcut  identity mapping zero-padding\n* C shortcuts  projection shortcut zero-padding\n\n\n|model|top-1 err | top-5 err|\n|:--|:--|:--|\n|plain-34| 28.54| 10.02|\n|ResNet-34 A|25.03|7.76|\n|ResNet-34 B|24.52|7.46|\n|ResNet-34 C|24.19|7.4|\n|ResNet-50|22.85|6.71|\n|ResNet-101|21.75|6.05|\n|ResNet-50|<b>21.43</b>|<b>5.71</b>|\n<center> 2. projection shortcut  ResNet <font color='clan'>ResNet-50/101/152  B</font>ImageNet 10-crop testing</center>\n\n\n-  plain B  A C  B  A  projection shortcutprojection shortcut C  B \n\n### Bottleneck \n 1  conv block  conv  bottleneck  conv`1x1`, `3x3`, `1x1` `1x1`  channel 1/4(H,W) `3x3` (H,W) channel  `1x1`  channel 4  conv layer  bottleneck \n![](/images/img_cls/resnet_2.png)<center> 2. ImageNet  1 conv bottleneck  ResNet-50/101/152 </center>\n\n Bottleneck identity shortcut  projectionmodel  shortcut  channel  4  shortcut \n\n### ResNet-50/101/152\n ResNet-34  conv block  bottleneck  ResNet-50 1ResNet-34  `3+4+6+3=16`  conv block layer  16ResNet-50  B\n\n ResNet-50  bottleneck  ResNet-101  ResNet152\n\nResNet-50/101/152  ResNet-34  2 ResNet \n\n ResNet <font color=\"red\"></font>\n\n ResNet \n\n## \n\n1.  SGD \n2. mini-batch=256\n3.  `0.1`  `1/10` \n4.  `0.0001`momentum=0.9\n5.  BatchNorm Dropout\n\n# CIFAR-10\n SOTA  ResNet-34  plain  size  `32x32` ImageNet  size `224x224` \n## \n\n layer  kernel ImageNet  `7x7` `3x3`  convstride=1 channel  16 6n6  conv layer 2n  conv layer  3  feature size  `(32, 16, 8)`channel  filter  `(16, 32, 64)` GAP + full connection + softmax layer  `6n+2` \n>  stride=2  conv layer  1 \n\n\n\n| map size|32x32|16x16|8x8|\n|:---|:---|:---|:---|\n|#layers|2n+1|2n|2n|\n|#filters|16|32|64|\n\n\n identity shortcut identity shortcut layer  rate=2  (H,W)  channel  channel residual function  channel  channel  channel  (H,W)  element-wise  add \n\n6n  conv layer conv layer  shortcut 3n  shortcut identity shortcut\n\n## \n\n-  ImageNet  mini-batch=128 `0.1` 32k  48k  `1/10` 64k \n- CIFAR-10  50k 10k 10 45k/5k  train/val \n-  4 pixel  0.5  crop  32x32  patch\n\n## \n `n={3,5,7,9}`  `20, 32, 44, 56`  layer  3\n![](/images/img_cls/resnet_3.png)<center> 3. CIFAR-10  plain-110  60%</center>\n\n 3 ResNet n=18  ResNet-110 0.1  0.01 80%  400  0.1  ImageNet \n\n\n\nResNet-110  deep & thin \n||#layers|#params(M)|error(%)|\n|:---|:---|:---|:---|\n|FitNet|19|2.5|8.39|\n|Highway|19|2.3|7.54(7.72  0.16)|\n|Highway|32|1.25|8.8|\n|ResNet|20|0.27|8.75|\n|ResNet|32|0.46|7.51|\n|ResNet|44|0.66|7.17|\n|ResNet|56|0.85|6.97|\n|ResNet|110|1.7|<b>6.43</b>(6.610.16)|\n|ResNet|1202|19.4|7.93|\n<center>CIFAR-10  Highway  ResNet-110  5  6.43%  6.61%0.16</center>\n\n## Layer \n 4  CIFAR-10  `3x3` layer  BN activate  layer \n![](/images/img_cls/resnet_4.png)<center> 4. 3x3</center>\n\n 4ResNet  plain  ResNet  0  relu  sigmoid  ResNet  layer  layer \n\n##  layers>1000\nn=200 6n+2=1202  3  `<0.1%` `7.93%` ResNet-110 `maxout``dropout`  deep & thin deep \n> deep: thin:  conv-bn-reluwide:  feature size \n\n\n# \n Faster R-CNN baseline  VGG-16  ResNet-101\n\n## \n1.  ImageNet  fine-tune","slug":"img_cls/resnet","published":1,"updated":"2021-01-28T08:12:36.889Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or913002fp0dj441i7dry","content":"<p> Resnet <br><span id=\"more\"></span></p>\n<h1 id=\"ImageNet\"><a href=\"#ImageNet\" class=\"headerlink\" title=\"ImageNet\"></a>ImageNet</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>scale w,h  resize  <code>[256,418]</code> </li>\n<li> resized  center crop  <code>224x224</code> </li>\n<li>10-crop testingcrop center 5  patch 5  patch 10  patch softmax </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>baseline  VGG plain conv  activation  BatchNorm </li>\n<li> conv3_1,  conv4_1, conv5_1 stride=2<br><img src=\"/images/img_cls/resnet_1.png\" alt=\"\"><center> 1. </center></li>\n<li> conv block  shortcut output  concatenate conv3_1,  conv4_1, conv5_1 output  (H,W)  (C)  shortcut a. identity mapping stride=2 H  W 0 b. <code>1x1</code> convstride=2  channel </li>\n<li> ResNet-18  ResNet-34  identity mapping zero-padding </li>\n<li>conv3_1,  conv4_1, conv5_1  ResNet-18  ResNet-34conv block  <code>3x3</code> conv layer  conv3_1,  conv4_1, conv5_1  conv block  conv layer  ResNet-50ResNet-101  ResNet-152conv block  conv layer  bottleneckconv  <code>1x1</code>, <code>3x3</code>, <code>1x1</code>  conv3_1,  conv4_1, conv5_1  conv block  <code>3x3</code> </li>\n<li> <code>2x2x2x2x2=32</code> <code>224x224</code> conv  feature  <code>7x7</code> feature map  GAP channel  full connection  1000  softmax </li>\n<li>ResNet-x <code>x</code>  layer </li>\n<li>shortcut  residual function  channel  relu </li>\n<li> shortcut  stride=2 <h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"plain-vs-resnet\"><a href=\"#plain-vs-resnet\" class=\"headerlink\" title=\"plain vs. resnet\"></a>plain vs. resnet</h3> 18 layers  34 layers  plain  ResNettop-1 </li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">plain</th>\n<th style=\"text-align:center\">ResNet</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">18 layers</td>\n<td style=\"text-align:center\">27.94</td>\n<td style=\"text-align:center\">27.88</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">34 layers</td>\n<td style=\"text-align:center\">28.54</td>\n<td style=\"text-align:center\"><b> 25.03 </b></td>\n</tr>\n</tbody>\n</table>\n</div>\n <center> 1. plain  Resnet ResNet  identity shortcutImageNet 10-crop testing</center>\n\n\n- plain\n- ResNet  identity mapping zero padding channel shortcutResNet-34  ResNet-18  ResNet \n- ResNet-18  plain-18 \n\n### Projection Shortcut\n `1x1` conv  identity mapping conv block  shortcut \n\n$$\\mathbf y = \\mathcal F(\\mathbf x, \\{W_i\\}) + W_s \\mathbf x $$\n 34 layers \n\n* A shortcut  identity mapping zero-padding  ResNet-34 \n* Bconv3_1, conv4_1, conv5_1 projection shortcut shortcut  identity mapping zero-padding\n* C shortcuts  projection shortcut zero-padding\n\n\n|model|top-1 err | top-5 err|\n|:--|:--|:--|\n|plain-34| 28.54| 10.02|\n|ResNet-34 A|25.03|7.76|\n|ResNet-34 B|24.52|7.46|\n|ResNet-34 C|24.19|7.4|\n|ResNet-50|22.85|6.71|\n|ResNet-101|21.75|6.05|\n|ResNet-50|<b>21.43</b>|<b>5.71</b>|\n<center> 2. projection shortcut  ResNet <font color='clan'>ResNet-50/101/152  B</font>ImageNet 10-crop testing</center>\n\n<p></p>\n<ul>\n<li> plain B  A C  B  A  projection shortcutprojection shortcut C  B </li>\n</ul>\n<h3 id=\"Bottleneck-\"><a href=\"#Bottleneck-\" class=\"headerlink\" title=\"Bottleneck \"></a>Bottleneck </h3><p> 1  conv block  conv  bottleneck  conv<code>1x1</code>, <code>3x3</code>, <code>1x1</code> <code>1x1</code>  channel 1/4(H,W) <code>3x3</code> (H,W) channel  <code>1x1</code>  channel 4  conv layer  bottleneck <br><img src=\"/images/img_cls/resnet_2.png\" alt=\"\"><center> 2. ImageNet  1 conv bottleneck  ResNet-50/101/152 </center></p>\n<p> Bottleneck identity shortcut  projectionmodel  shortcut  channel  4  shortcut </p>\n<h3 id=\"ResNet-50-101-152\"><a href=\"#ResNet-50-101-152\" class=\"headerlink\" title=\"ResNet-50/101/152\"></a>ResNet-50/101/152</h3><p> ResNet-34  conv block  bottleneck  ResNet-50 1ResNet-34  <code>3+4+6+3=16</code>  conv block layer  16ResNet-50  B</p>\n<p> ResNet-50  bottleneck  ResNet-101  ResNet152</p>\n<p>ResNet-50/101/152  ResNet-34  2 ResNet </p>\n<p> ResNet <font color=\"red\"></font></p>\n<p> ResNet </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> SGD </li>\n<li>mini-batch=256</li>\n<li> <code>0.1</code>  <code>1/10</code> </li>\n<li> <code>0.0001</code>momentum=0.9</li>\n<li> BatchNorm Dropout</li>\n</ol>\n<h1 id=\"CIFAR-10\"><a href=\"#CIFAR-10\" class=\"headerlink\" title=\"CIFAR-10\"></a>CIFAR-10</h1><p> SOTA  ResNet-34  plain  size  <code>32x32</code> ImageNet  size <code>224x224</code> </p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p> layer  kernel ImageNet  <code>7x7</code> <code>3x3</code>  convstride=1 channel  16 6n6  conv layer 2n  conv layer  3  feature size  <code>(32, 16, 8)</code>channel  filter  <code>(16, 32, 64)</code> GAP + full connection + softmax layer  <code>6n+2</code> </p>\n<blockquote>\n<p> stride=2  conv layer  1 </p>\n</blockquote>\n<p></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"> map size</th>\n<th style=\"text-align:left\">32x32</th>\n<th style=\"text-align:left\">16x16</th>\n<th style=\"text-align:left\">8x8</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">#layers</td>\n<td style=\"text-align:left\">2n+1</td>\n<td style=\"text-align:left\">2n</td>\n<td style=\"text-align:left\">2n</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">#filters</td>\n<td style=\"text-align:left\">16</td>\n<td style=\"text-align:left\">32</td>\n<td style=\"text-align:left\">64</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p> identity shortcut identity shortcut layer  rate=2  (H,W)  channel  channel residual function  channel  channel  channel  (H,W)  element-wise  add </p>\n<p>6n  conv layer conv layer  shortcut 3n  shortcut identity shortcut</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li> ImageNet  mini-batch=128 <code>0.1</code> 32k  48k  <code>1/10</code> 64k </li>\n<li>CIFAR-10  50k 10k 10 45k/5k  train/val </li>\n<li> 4 pixel  0.5  crop  32x32  patch</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>n=&#123;3,5,7,9&#125;</code>  <code>20, 32, 44, 56</code>  layer  3<br><img src=\"/images/img_cls/resnet_3.png\" alt=\"\"><center> 3. CIFAR-10  plain-110  60%</center></p>\n<p> 3 ResNet n=18  ResNet-110 0.1  0.01 80%  400  0.1  ImageNet </p>\n<p></p>\n<p>ResNet-110  deep &amp; thin <br>||#layers|#params(M)|error(%)|<br>|:-|:-|:-|:-|<br>|FitNet|19|2.5|8.39|<br>|Highway|19|2.3|7.54(7.72  0.16)|<br>|Highway|32|1.25|8.8|<br>|ResNet|20|0.27|8.75|<br>|ResNet|32|0.46|7.51|<br>|ResNet|44|0.66|7.17|<br>|ResNet|56|0.85|6.97|<br>|ResNet|110|1.7|<b>6.43</b>(6.610.16)|<br>|ResNet|1202|19.4|7.93|</p>\n<center>CIFAR-10  Highway  ResNet-110  5  6.43%  6.61%0.16</center>\n\n<h2 id=\"Layer-\"><a href=\"#Layer-\" class=\"headerlink\" title=\"Layer \"></a>Layer </h2><p> 4  CIFAR-10  <code>3x3</code> layer  BN activate  layer <br><img src=\"/images/img_cls/resnet_4.png\" alt=\"\"><center> 4. 3x3</center></p>\n<p> 4ResNet  plain  ResNet  0  relu  sigmoid  ResNet  layer  layer </p>\n<h2 id=\"-layers-gt-1000\"><a href=\"#-layers-gt-1000\" class=\"headerlink\" title=\" layers&gt;1000\"></a> layers&gt;1000</h2><p>n=200 6n+2=1202  3  <code>&lt;0.1%</code> <code>7.93%</code> ResNet-110 <code>maxout</code><code>dropout</code>  deep &amp; thin deep </p>\n<blockquote>\n<p>deep: thin:  conv-bn-reluwide:  feature size </p>\n</blockquote>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Faster R-CNN baseline  VGG-16  ResNet-101</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> ImageNet  fine-tune</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p> Resnet <br>","more":"</p>\n<h1 id=\"ImageNet\"><a href=\"#ImageNet\" class=\"headerlink\" title=\"ImageNet\"></a>ImageNet</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>scale w,h  resize  <code>[256,418]</code> </li>\n<li> resized  center crop  <code>224x224</code> </li>\n<li>10-crop testingcrop center 5  patch 5  patch 10  patch softmax </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>baseline  VGG plain conv  activation  BatchNorm </li>\n<li> conv3_1,  conv4_1, conv5_1 stride=2<br><img src=\"/images/img_cls/resnet_1.png\" alt=\"\"><center> 1. </center></li>\n<li> conv block  shortcut output  concatenate conv3_1,  conv4_1, conv5_1 output  (H,W)  (C)  shortcut a. identity mapping stride=2 H  W 0 b. <code>1x1</code> convstride=2  channel </li>\n<li> ResNet-18  ResNet-34  identity mapping zero-padding </li>\n<li>conv3_1,  conv4_1, conv5_1  ResNet-18  ResNet-34conv block  <code>3x3</code> conv layer  conv3_1,  conv4_1, conv5_1  conv block  conv layer  ResNet-50ResNet-101  ResNet-152conv block  conv layer  bottleneckconv  <code>1x1</code>, <code>3x3</code>, <code>1x1</code>  conv3_1,  conv4_1, conv5_1  conv block  <code>3x3</code> </li>\n<li> <code>2x2x2x2x2=32</code> <code>224x224</code> conv  feature  <code>7x7</code> feature map  GAP channel  full connection  1000  softmax </li>\n<li>ResNet-x <code>x</code>  layer </li>\n<li>shortcut  residual function  channel  relu </li>\n<li> shortcut  stride=2 <h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"plain-vs-resnet\"><a href=\"#plain-vs-resnet\" class=\"headerlink\" title=\"plain vs. resnet\"></a>plain vs. resnet</h3> 18 layers  34 layers  plain  ResNettop-1 </li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">plain</th>\n<th style=\"text-align:center\">ResNet</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">18 layers</td>\n<td style=\"text-align:center\">27.94</td>\n<td style=\"text-align:center\">27.88</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">34 layers</td>\n<td style=\"text-align:center\">28.54</td>\n<td style=\"text-align:center\"><b> 25.03 </b></td>\n</tr>\n</tbody>\n</table>\n</div>\n <center> 1. plain  Resnet ResNet  identity shortcutImageNet 10-crop testing</center>\n\n\n- plain\n- ResNet  identity mapping zero padding channel shortcutResNet-34  ResNet-18  ResNet \n- ResNet-18  plain-18 \n\n### Projection Shortcut\n `1x1` conv  identity mapping conv block  shortcut \n\n$$\\mathbf y = \\mathcal F(\\mathbf x, \\{W_i\\}) + W_s \\mathbf x $$\n 34 layers \n\n* A shortcut  identity mapping zero-padding  ResNet-34 \n* Bconv3_1, conv4_1, conv5_1 projection shortcut shortcut  identity mapping zero-padding\n* C shortcuts  projection shortcut zero-padding\n\n\n|model|top-1 err | top-5 err|\n|:--|:--|:--|\n|plain-34| 28.54| 10.02|\n|ResNet-34 A|25.03|7.76|\n|ResNet-34 B|24.52|7.46|\n|ResNet-34 C|24.19|7.4|\n|ResNet-50|22.85|6.71|\n|ResNet-101|21.75|6.05|\n|ResNet-50|<b>21.43</b>|<b>5.71</b>|\n<center> 2. projection shortcut  ResNet <font color='clan'>ResNet-50/101/152  B</font>ImageNet 10-crop testing</center>\n\n<p></p>\n<ul>\n<li> plain B  A C  B  A  projection shortcutprojection shortcut C  B </li>\n</ul>\n<h3 id=\"Bottleneck-\"><a href=\"#Bottleneck-\" class=\"headerlink\" title=\"Bottleneck \"></a>Bottleneck </h3><p> 1  conv block  conv  bottleneck  conv<code>1x1</code>, <code>3x3</code>, <code>1x1</code> <code>1x1</code>  channel 1/4(H,W) <code>3x3</code> (H,W) channel  <code>1x1</code>  channel 4  conv layer  bottleneck <br><img src=\"/images/img_cls/resnet_2.png\" alt=\"\"><center> 2. ImageNet  1 conv bottleneck  ResNet-50/101/152 </center></p>\n<p> Bottleneck identity shortcut  projectionmodel  shortcut  channel  4  shortcut </p>\n<h3 id=\"ResNet-50-101-152\"><a href=\"#ResNet-50-101-152\" class=\"headerlink\" title=\"ResNet-50/101/152\"></a>ResNet-50/101/152</h3><p> ResNet-34  conv block  bottleneck  ResNet-50 1ResNet-34  <code>3+4+6+3=16</code>  conv block layer  16ResNet-50  B</p>\n<p> ResNet-50  bottleneck  ResNet-101  ResNet152</p>\n<p>ResNet-50/101/152  ResNet-34  2 ResNet </p>\n<p> ResNet <font color=\"red\"></font></p>\n<p> ResNet </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> SGD </li>\n<li>mini-batch=256</li>\n<li> <code>0.1</code>  <code>1/10</code> </li>\n<li> <code>0.0001</code>momentum=0.9</li>\n<li> BatchNorm Dropout</li>\n</ol>\n<h1 id=\"CIFAR-10\"><a href=\"#CIFAR-10\" class=\"headerlink\" title=\"CIFAR-10\"></a>CIFAR-10</h1><p> SOTA  ResNet-34  plain  size  <code>32x32</code> ImageNet  size <code>224x224</code> </p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p> layer  kernel ImageNet  <code>7x7</code> <code>3x3</code>  convstride=1 channel  16 6n6  conv layer 2n  conv layer  3  feature size  <code>(32, 16, 8)</code>channel  filter  <code>(16, 32, 64)</code> GAP + full connection + softmax layer  <code>6n+2</code> </p>\n<blockquote>\n<p> stride=2  conv layer  1 </p>\n</blockquote>\n<p></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"> map size</th>\n<th style=\"text-align:left\">32x32</th>\n<th style=\"text-align:left\">16x16</th>\n<th style=\"text-align:left\">8x8</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">#layers</td>\n<td style=\"text-align:left\">2n+1</td>\n<td style=\"text-align:left\">2n</td>\n<td style=\"text-align:left\">2n</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">#filters</td>\n<td style=\"text-align:left\">16</td>\n<td style=\"text-align:left\">32</td>\n<td style=\"text-align:left\">64</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p> identity shortcut identity shortcut layer  rate=2  (H,W)  channel  channel residual function  channel  channel  channel  (H,W)  element-wise  add </p>\n<p>6n  conv layer conv layer  shortcut 3n  shortcut identity shortcut</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li> ImageNet  mini-batch=128 <code>0.1</code> 32k  48k  <code>1/10</code> 64k </li>\n<li>CIFAR-10  50k 10k 10 45k/5k  train/val </li>\n<li> 4 pixel  0.5  crop  32x32  patch</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>n=&#123;3,5,7,9&#125;</code>  <code>20, 32, 44, 56</code>  layer  3<br><img src=\"/images/img_cls/resnet_3.png\" alt=\"\"><center> 3. CIFAR-10  plain-110  60%</center></p>\n<p> 3 ResNet n=18  ResNet-110 0.1  0.01 80%  400  0.1  ImageNet </p>\n<p></p>\n<p>ResNet-110  deep &amp; thin <br>||#layers|#params(M)|error(%)|<br>|:-|:-|:-|:-|<br>|FitNet|19|2.5|8.39|<br>|Highway|19|2.3|7.54(7.72  0.16)|<br>|Highway|32|1.25|8.8|<br>|ResNet|20|0.27|8.75|<br>|ResNet|32|0.46|7.51|<br>|ResNet|44|0.66|7.17|<br>|ResNet|56|0.85|6.97|<br>|ResNet|110|1.7|<b>6.43</b>(6.610.16)|<br>|ResNet|1202|19.4|7.93|</p>\n<center>CIFAR-10  Highway  ResNet-110  5  6.43%  6.61%0.16</center>\n\n<h2 id=\"Layer-\"><a href=\"#Layer-\" class=\"headerlink\" title=\"Layer \"></a>Layer </h2><p> 4  CIFAR-10  <code>3x3</code> layer  BN activate  layer <br><img src=\"/images/img_cls/resnet_4.png\" alt=\"\"><center> 4. 3x3</center></p>\n<p> 4ResNet  plain  ResNet  0  relu  sigmoid  ResNet  layer  layer </p>\n<h2 id=\"-layers-gt-1000\"><a href=\"#-layers-gt-1000\" class=\"headerlink\" title=\" layers&gt;1000\"></a> layers&gt;1000</h2><p>n=200 6n+2=1202  3  <code>&lt;0.1%</code> <code>7.93%</code> ResNet-110 <code>maxout</code><code>dropout</code>  deep &amp; thin deep </p>\n<blockquote>\n<p>deep: thin:  conv-bn-reluwide:  feature size </p>\n</blockquote>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Faster R-CNN baseline  VGG-16  ResNet-101</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li> ImageNet  fine-tune</li>\n</ol>"},{"title":"Perceptron for Halfspaces","date":"2021-09-15T02:40:35.000Z","p":"ml/halfspace","mathjax":true,"_content":"\n\n<!--more-->\n\n# \n $S=\\{(\\mathbf x_i, y_i)\\}_{i=1}^m$\n\n$$L_d=\\{h_{\\mathbf w, b}: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}$$\n\n\n  \n\n$$HS_d=\\text{sign} \\circ L_d$$\n\n $\\mathbf w'=(b, w_1, \\cdots w_d)$$\\mathbf x'=(1, x_1, \\cdots x_d)$\n\n$$h_{\\mathbf w, b}(\\mathbf x) = \\langle \\mathbf w', \\mathbf x' \\rangle$$\n\n ERM $\\mathbf w^*$ $\\forall i = 1, \\cdots , m$ $\\text{sign}(\\langle \\mathbf w^*, \\mathbf x_i \\rangle)=y_i$\n\n$$y_i \\langle \\mathbf w^*, \\mathbf x_i \\rangle > 0, \\quad \\forall i = 1, \\cdots, m$$ (1)\n\n$\\mathbf w^*$ \n\n## Perceptron \n $t$ $\\mathbf w^{(t)}$ $\\mathbf w^{(1)}=\\mathbf 0$ $t$  $\\mathbf w^{(t)}$  $y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle \\le 0$\n\n$$\\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i$$\n\n\n\n$$y_i \\langle \\mathbf w^{(t+1)}, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}+y_i \\mathbf x_i, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle+\\|\\mathbf x_i \\|^2$$\n\n $(\\mathbf x_i, y_i)$  $\\mathbf w^{(t)}$  $\\le 0$ $\\| \\mathbf x_i \\|^2 \\ge 0$ $\\mathbf w$\n\n____\n\n $(\\mathbf x_1, y_1), \\cdots , (\\mathbf x_m, y_m)$\n\n: $\\mathbf w^{(1)}=(0,\\cdots,0)$\n\n$\\quad \\text{for} \\ t=1,2,\\dots$\n\n$\\quad \\quad \\text{if} \\ (\\exists \\ i \\ s.t. \\ y_i \\langle \\mathbf w^(t), \\mathbf x_i \\rangle \\le 0) \\ \\text{then}$\n\n$\\quad \\quad \\quad \\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i$\n\n$\\quad \\quad \\text{else}$\n\n$\\quad \\quad \\quad \\text{output} \\ \\mathbf w^{(t)}$\n\n\n $\\mathbf w$\n\n $B=\\min \\{\\|\\mathbf w\\|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$ $R=\\max_i \\| \\mathbf x_i \\|$ $(RB)^2$  $\\forall \\ in \\in [m], \\ y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle > 0$\n\n $\\{\\|\\mathbf w\\|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 0\\}$   $\\mathbf w$  $\\forall \\ 0<\\gamma <1$ $\\gamma \\mathbf w$  $\\|\\gamma \\mathbf w\\|^2=\\gamma^2 \\|\\mathbf w\\|^2 < \\|\\mathbf w \\|^2$\n\n $\\{\\|\\mathbf w\\|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$  $|y_i\\langle \\mathbf w, \\mathbf x_i \\rangle|=\\|\\mathbf w \\|\\cdot\\|\\mathbf x_i\\| \\cdot|\\cos \\theta_i|\\ge 1 \\Rightarrow \\|\\mathbf w \\| \\ge 1/(\\|\\mathbf x_i\\| \\cdot|\\cos \\theta_i|)$   $\\forall i \\in [m]$  (1) $\\mathbf w$  $\\mathbf w$ $\\|\\mathbf x_i\\| \\cdot|\\cos \\theta_i|$ \n\n $(RB)^2$ \n\n____\n\n $\\mathbf w^*$  $B$  $\\forall \\ i \\in [m]$ $y_i \\langle \\mathbf w^*, \\mathbf x_i \\rangle \\ge 1$ $\\mathbf w^*$ \n\n $\\mathbf w^{(1)}=\\mathbf 0$ $\\langle \\mathbf w^*, \\mathbf w^{(1)}\\rangle=0$\n\n$$\\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle - \\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, \\mathbf w^{(t+1)}-\\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, y_i \\mathbf x_i\\rangle=y_i\\langle \\mathbf w^*, \\mathbf x_i\\rangle \\ge 1$$\n\n\n\n$$\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle=\\sum_{t=1}^T \\left( \\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle-\\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle \\right) \\ge T$$\n\n\n\n$$\\|\\mathbf w^{(t+1)}\\|^2=\\|\\mathbf w^{(t)}+y_i \\mathbf x_i\\|^2=\\|\\mathbf w^{(t)}\\|^2+2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle+y_i^2\\| \\mathbf x_i\\|^2 \\le \\|\\mathbf w^{(t)}\\|^2+R^2$$\n\n $t+1$  $\\mathbf w^{(t)}$  $(\\mathbf x_i, y_i)$ $2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle \\le 0$ $\\| \\mathbf x_i \\|^2 \\le R$ $\\|\\mathbf w^{(1)}\\|^2=0$\n\n$$\\|\\mathbf w^{(T+1)} \\|^2 \\le TR^2$$\n\n\n\n$$\\frac {\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle} {\\|\\mathbf w^*\\| \\cdot \\|\\mathbf w^{(T+1)}\\|} \\ge \\frac T {B \\sqrt T R}=\\frac {\\sqrt T} {BR}$$\n\n Cauchy-Schwartz  $<1$ $1 > \\sqrt T / (BR)$\n\n$$T \\le (RB)^2$$\n\n## VC \n\n## \n\n$\\mathbb R^d$  Halfspance  VC  $d$\n\n____\n\n $VCdim(\\mathcal H)=d$\n\n-  $C$ $|C|=d$ $\\mathcal H$ shattered \n-  $|C|=d+1$  $\\mathcal H$ shattered\n\n $\\mathbf e_1, \\cdots, \\mathbf e_d$one-hot Halfspace shattered\n\n$$\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle): \\mathbf w \\in \\mathbb R^d\\}$$\n\n $(y_1, \\cdots, y_d)$ $\\mathbf w=(y_1, \\cdots, y_d)$ $h(\\mathbf e_i)=\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle)=y_i$ $\\mathbf e_1, \\cdots, \\mathbf e_d$  $\\mathcal H$ shattered\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1} \\in R^d$ $d+1$  $\\sum_{i=1}^{d+1} a_i \\mathbf x_i=\\mathbf 0$ $a_1, \\cdots, a_{d+1}$  $0$ $I=\\{i:a_i>0\\}$$J=\\{j:a_j<0\\}$ $I, \\ J$ \n\n- $I, \\ J$ \n\n$$\\sum_{i \\in I}a_i \\mathbf x_i = \\sum_{j \\in J} |a_j|\\mathbf x_j$$\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle >0, \\ \\forall \\ i \\in I$ $\\langle \\mathbf w, \\mathbf x_i \\rangle <0, \\ \\forall \\ i \\in J$\n\n$$0 < \\sum_{i \\in I} a_i \\langle \\mathbf w, \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{i \\in I} a_i \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{j \\in J} |a_j| \\mathbf x_j \\rangle=\\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0$$\n\n $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered\n\n- $I=\\emptyset, \\ J \\neq \\emptyset$\n\n$$\\sum_{j \\in J} |a_j|\\mathbf x_j=0$$\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle <0, \\ \\forall \\ i \\in J$\n\n$$0=\\langle \\mathbf w, \\sum_{j \\in J} |a_j|\\mathbf x_j \\rangle= \\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0$$\n\n $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered\n\n- $I \\neq \\emptyset, \\ J = \\emptyset$\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathbf H$ shattered $VCdim(\\mathbf H)=d$\n\n## \n$\\mathbb R^d$  Halfspance  VC  $d+1$\n\n____\n\n $d+1$  $C=(\\mathbf 0, \\mathbf e_1, \\cdots, \\mathbf e_d)$\n\n$$\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w, \\mathbf x \\rangle + b): \\mathbf w \\in \\mathbb R^d\\}$$\n\n label  $(y_1, \\cdots, y_{d+1})$ $\\mathbf w, b$ \n$$y_1 \\cdot b > 0$$\n$$y_i(w_i+b)>0, \\ \\forall i \\in [d]$$\n\n $C$  $\\mathcal H$ shattered\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$ $\\mathcal H$ shattered $\\mathbb R^{d+1}$  halfspace  $\\mathcal H'=\\{\\text{sign}(\\langle \\mathbf w', \\mathbf x'\\rangle): \\mathbf w' \\in \\mathbb R^{d+1}\\}$ $\\mathbf w'=(b, w_1, \\cdots , w_d)$ $\\mathbf x'=(1,x_1, \\cdots, x_d)$  $\\mathcal H$ $\\mathbb R^d$   $\\mathcal H \\subset \\mathcal H'$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H'$ shattered$\\mathbb R^{d+1}$  $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H'$ shattered\n\n$$VCdim(\\mathcal H)=d+1$$\n\n","source":"_posts/ml/halfspace.md","raw":"---\ntitle: Perceptron for Halfspaces\ndate: 2021-09-15 10:40:35\ntags: machine learning\np: ml/halfspace\nmathjax: true\n---\n\n\n<!--more-->\n\n# \n $S=\\{(\\mathbf x_i, y_i)\\}_{i=1}^m$\n\n$$L_d=\\{h_{\\mathbf w, b}: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}$$\n\n\n  \n\n$$HS_d=\\text{sign} \\circ L_d$$\n\n $\\mathbf w'=(b, w_1, \\cdots w_d)$$\\mathbf x'=(1, x_1, \\cdots x_d)$\n\n$$h_{\\mathbf w, b}(\\mathbf x) = \\langle \\mathbf w', \\mathbf x' \\rangle$$\n\n ERM $\\mathbf w^*$ $\\forall i = 1, \\cdots , m$ $\\text{sign}(\\langle \\mathbf w^*, \\mathbf x_i \\rangle)=y_i$\n\n$$y_i \\langle \\mathbf w^*, \\mathbf x_i \\rangle > 0, \\quad \\forall i = 1, \\cdots, m$$ (1)\n\n$\\mathbf w^*$ \n\n## Perceptron \n $t$ $\\mathbf w^{(t)}$ $\\mathbf w^{(1)}=\\mathbf 0$ $t$  $\\mathbf w^{(t)}$  $y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle \\le 0$\n\n$$\\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i$$\n\n\n\n$$y_i \\langle \\mathbf w^{(t+1)}, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}+y_i \\mathbf x_i, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle+\\|\\mathbf x_i \\|^2$$\n\n $(\\mathbf x_i, y_i)$  $\\mathbf w^{(t)}$  $\\le 0$ $\\| \\mathbf x_i \\|^2 \\ge 0$ $\\mathbf w$\n\n____\n\n $(\\mathbf x_1, y_1), \\cdots , (\\mathbf x_m, y_m)$\n\n: $\\mathbf w^{(1)}=(0,\\cdots,0)$\n\n$\\quad \\text{for} \\ t=1,2,\\dots$\n\n$\\quad \\quad \\text{if} \\ (\\exists \\ i \\ s.t. \\ y_i \\langle \\mathbf w^(t), \\mathbf x_i \\rangle \\le 0) \\ \\text{then}$\n\n$\\quad \\quad \\quad \\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i$\n\n$\\quad \\quad \\text{else}$\n\n$\\quad \\quad \\quad \\text{output} \\ \\mathbf w^{(t)}$\n\n\n $\\mathbf w$\n\n $B=\\min \\{\\|\\mathbf w\\|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$ $R=\\max_i \\| \\mathbf x_i \\|$ $(RB)^2$  $\\forall \\ in \\in [m], \\ y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle > 0$\n\n $\\{\\|\\mathbf w\\|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 0\\}$   $\\mathbf w$  $\\forall \\ 0<\\gamma <1$ $\\gamma \\mathbf w$  $\\|\\gamma \\mathbf w\\|^2=\\gamma^2 \\|\\mathbf w\\|^2 < \\|\\mathbf w \\|^2$\n\n $\\{\\|\\mathbf w\\|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$  $|y_i\\langle \\mathbf w, \\mathbf x_i \\rangle|=\\|\\mathbf w \\|\\cdot\\|\\mathbf x_i\\| \\cdot|\\cos \\theta_i|\\ge 1 \\Rightarrow \\|\\mathbf w \\| \\ge 1/(\\|\\mathbf x_i\\| \\cdot|\\cos \\theta_i|)$   $\\forall i \\in [m]$  (1) $\\mathbf w$  $\\mathbf w$ $\\|\\mathbf x_i\\| \\cdot|\\cos \\theta_i|$ \n\n $(RB)^2$ \n\n____\n\n $\\mathbf w^*$  $B$  $\\forall \\ i \\in [m]$ $y_i \\langle \\mathbf w^*, \\mathbf x_i \\rangle \\ge 1$ $\\mathbf w^*$ \n\n $\\mathbf w^{(1)}=\\mathbf 0$ $\\langle \\mathbf w^*, \\mathbf w^{(1)}\\rangle=0$\n\n$$\\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle - \\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, \\mathbf w^{(t+1)}-\\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, y_i \\mathbf x_i\\rangle=y_i\\langle \\mathbf w^*, \\mathbf x_i\\rangle \\ge 1$$\n\n\n\n$$\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle=\\sum_{t=1}^T \\left( \\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle-\\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle \\right) \\ge T$$\n\n\n\n$$\\|\\mathbf w^{(t+1)}\\|^2=\\|\\mathbf w^{(t)}+y_i \\mathbf x_i\\|^2=\\|\\mathbf w^{(t)}\\|^2+2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle+y_i^2\\| \\mathbf x_i\\|^2 \\le \\|\\mathbf w^{(t)}\\|^2+R^2$$\n\n $t+1$  $\\mathbf w^{(t)}$  $(\\mathbf x_i, y_i)$ $2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle \\le 0$ $\\| \\mathbf x_i \\|^2 \\le R$ $\\|\\mathbf w^{(1)}\\|^2=0$\n\n$$\\|\\mathbf w^{(T+1)} \\|^2 \\le TR^2$$\n\n\n\n$$\\frac {\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle} {\\|\\mathbf w^*\\| \\cdot \\|\\mathbf w^{(T+1)}\\|} \\ge \\frac T {B \\sqrt T R}=\\frac {\\sqrt T} {BR}$$\n\n Cauchy-Schwartz  $<1$ $1 > \\sqrt T / (BR)$\n\n$$T \\le (RB)^2$$\n\n## VC \n\n## \n\n$\\mathbb R^d$  Halfspance  VC  $d$\n\n____\n\n $VCdim(\\mathcal H)=d$\n\n-  $C$ $|C|=d$ $\\mathcal H$ shattered \n-  $|C|=d+1$  $\\mathcal H$ shattered\n\n $\\mathbf e_1, \\cdots, \\mathbf e_d$one-hot Halfspace shattered\n\n$$\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle): \\mathbf w \\in \\mathbb R^d\\}$$\n\n $(y_1, \\cdots, y_d)$ $\\mathbf w=(y_1, \\cdots, y_d)$ $h(\\mathbf e_i)=\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle)=y_i$ $\\mathbf e_1, \\cdots, \\mathbf e_d$  $\\mathcal H$ shattered\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1} \\in R^d$ $d+1$  $\\sum_{i=1}^{d+1} a_i \\mathbf x_i=\\mathbf 0$ $a_1, \\cdots, a_{d+1}$  $0$ $I=\\{i:a_i>0\\}$$J=\\{j:a_j<0\\}$ $I, \\ J$ \n\n- $I, \\ J$ \n\n$$\\sum_{i \\in I}a_i \\mathbf x_i = \\sum_{j \\in J} |a_j|\\mathbf x_j$$\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle >0, \\ \\forall \\ i \\in I$ $\\langle \\mathbf w, \\mathbf x_i \\rangle <0, \\ \\forall \\ i \\in J$\n\n$$0 < \\sum_{i \\in I} a_i \\langle \\mathbf w, \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{i \\in I} a_i \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{j \\in J} |a_j| \\mathbf x_j \\rangle=\\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0$$\n\n $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered\n\n- $I=\\emptyset, \\ J \\neq \\emptyset$\n\n$$\\sum_{j \\in J} |a_j|\\mathbf x_j=0$$\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle <0, \\ \\forall \\ i \\in J$\n\n$$0=\\langle \\mathbf w, \\sum_{j \\in J} |a_j|\\mathbf x_j \\rangle= \\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0$$\n\n $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered\n\n- $I \\neq \\emptyset, \\ J = \\emptyset$\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathbf H$ shattered $VCdim(\\mathbf H)=d$\n\n## \n$\\mathbb R^d$  Halfspance  VC  $d+1$\n\n____\n\n $d+1$  $C=(\\mathbf 0, \\mathbf e_1, \\cdots, \\mathbf e_d)$\n\n$$\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w, \\mathbf x \\rangle + b): \\mathbf w \\in \\mathbb R^d\\}$$\n\n label  $(y_1, \\cdots, y_{d+1})$ $\\mathbf w, b$ \n$$y_1 \\cdot b > 0$$\n$$y_i(w_i+b)>0, \\ \\forall i \\in [d]$$\n\n $C$  $\\mathcal H$ shattered\n\n $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$ $\\mathcal H$ shattered $\\mathbb R^{d+1}$  halfspace  $\\mathcal H'=\\{\\text{sign}(\\langle \\mathbf w', \\mathbf x'\\rangle): \\mathbf w' \\in \\mathbb R^{d+1}\\}$ $\\mathbf w'=(b, w_1, \\cdots , w_d)$ $\\mathbf x'=(1,x_1, \\cdots, x_d)$  $\\mathcal H$ $\\mathbb R^d$   $\\mathcal H \\subset \\mathcal H'$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H'$ shattered$\\mathbb R^{d+1}$  $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H'$ shattered\n\n$$VCdim(\\mathcal H)=d+1$$\n\n","slug":"ml/halfspace","published":1,"updated":"2021-09-24T10:27:18.518Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or914002hp0dj2u9w2rjf","content":"<p><br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $S=\\{(\\mathbf x_i, y_i)\\}_{i=1}^m$</p>\n<script type=\"math/tex; mode=display\">L_d=\\{h_{\\mathbf w, b}: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}</script><p>  </p>\n<script type=\"math/tex; mode=display\">HS_d=\\text{sign} \\circ L_d</script><p> $\\mathbf w=(b, w_1, \\cdots w_d)$$\\mathbf x=(1, x_1, \\cdots x_d)$</p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w, b}(\\mathbf x) = \\langle \\mathbf w', \\mathbf x' \\rangle</script><p> ERM $\\mathbf w^<em>$ $\\forall i = 1, \\cdots , m$ $\\text{sign}(\\langle \\mathbf w^</em>, \\mathbf x_i \\rangle)=y_i$</p>\n<script type=\"math/tex; mode=display\">y_i \\langle \\mathbf w^*, \\mathbf x_i \\rangle > 0, \\quad \\forall i = 1, \\cdots, m$$ (1)\n\n$\\mathbf w^*$ \n\n## Perceptron \n $t$ $\\mathbf w^{(t)}$ $\\mathbf w^{(1)}=\\mathbf 0$ $t$  $\\mathbf w^{(t)}$  $y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle \\le 0$\n\n$$\\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i</script><p></p>\n<script type=\"math/tex; mode=display\">y_i \\langle \\mathbf w^{(t+1)}, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}+y_i \\mathbf x_i, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle+\\|\\mathbf x_i \\|^2</script><p> $(\\mathbf x_i, y_i)$  $\\mathbf w^{(t)}$  $\\le 0$ $| \\mathbf x_i |^2 \\ge 0$ $\\mathbf w$</p>\n<p><strong></strong></p>\n<p> $(\\mathbf x_1, y_1), \\cdots , (\\mathbf x_m, y_m)$</p>\n<p>: $\\mathbf w^{(1)}=(0,\\cdots,0)$</p>\n<p>$\\quad \\text{for} \\ t=1,2,\\dots$</p>\n<p>$\\quad \\quad \\text{if} \\ (\\exists \\ i \\ s.t. \\ y_i \\langle \\mathbf w^(t), \\mathbf x_i \\rangle \\le 0) \\ \\text{then}$</p>\n<p>$\\quad \\quad \\quad \\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i$</p>\n<p>$\\quad \\quad \\text{else}$</p>\n<p>$\\quad \\quad \\quad \\text{output} \\ \\mathbf w^{(t)}$</p>\n<p> $\\mathbf w$</p>\n<p> $B=\\min \\{|\\mathbf w|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$ $R=\\max_i | \\mathbf x_i |$ $(RB)^2$  $\\forall \\ in \\in [m], \\ y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle &gt; 0$</p>\n<p> $\\{|\\mathbf w|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 0\\}$   $\\mathbf w$  $\\forall \\ 0&lt;\\gamma &lt;1$ $\\gamma \\mathbf w$  $|\\gamma \\mathbf w|^2=\\gamma^2 |\\mathbf w|^2 &lt; |\\mathbf w |^2$</p>\n<p> $\\{|\\mathbf w|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$  $|y_i\\langle \\mathbf w, \\mathbf x_i \\rangle|=|\\mathbf w |\\cdot|\\mathbf x_i| \\cdot|\\cos \\theta_i|\\ge 1 \\Rightarrow |\\mathbf w | \\ge 1/(|\\mathbf x_i| \\cdot|\\cos \\theta_i|)$   $\\forall i \\in [m]$  (1) $\\mathbf w$  $\\mathbf w$ $|\\mathbf x_i| \\cdot|\\cos \\theta_i|$ </p>\n<p> $(RB)^2$ </p>\n<p><strong></strong></p>\n<p> $\\mathbf w^<em>$  $B$  $\\forall \\ i \\in [m]$ $y_i \\langle \\mathbf w^</em>, \\mathbf x_i \\rangle \\ge 1$ $\\mathbf w^*$ </p>\n<p> $\\mathbf w^{(1)}=\\mathbf 0$ $\\langle \\mathbf w^*, \\mathbf w^{(1)}\\rangle=0$</p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle - \\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, \\mathbf w^{(t+1)}-\\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, y_i \\mathbf x_i\\rangle=y_i\\langle \\mathbf w^*, \\mathbf x_i\\rangle \\ge 1</script><p></p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle=\\sum_{t=1}^T \\left( \\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle-\\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle \\right) \\ge T</script><p></p>\n<script type=\"math/tex; mode=display\">\\|\\mathbf w^{(t+1)}\\|^2=\\|\\mathbf w^{(t)}+y_i \\mathbf x_i\\|^2=\\|\\mathbf w^{(t)}\\|^2+2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle+y_i^2\\| \\mathbf x_i\\|^2 \\le \\|\\mathbf w^{(t)}\\|^2+R^2</script><p> $t+1$  $\\mathbf w^{(t)}$  $(\\mathbf x_i, y_i)$ $2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle \\le 0$ $| \\mathbf x_i |^2 \\le R$ $|\\mathbf w^{(1)}|^2=0$</p>\n<script type=\"math/tex; mode=display\">\\|\\mathbf w^{(T+1)} \\|^2 \\le TR^2</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac {\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle} {\\|\\mathbf w^*\\| \\cdot \\|\\mathbf w^{(T+1)}\\|} \\ge \\frac T {B \\sqrt T R}=\\frac {\\sqrt T} {BR}</script><p> Cauchy-Schwartz  $<1$ $1 > \\sqrt T / (BR)$</p>\n<script type=\"math/tex; mode=display\">T \\le (RB)^2</script><h2 id=\"VC-\"><a href=\"#VC-\" class=\"headerlink\" title=\"VC \"></a>VC </h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathbb R^d$  Halfspance  VC  $d$</p>\n<p><strong></strong></p>\n<p> $VCdim(\\mathcal H)=d$</p>\n<ul>\n<li> $C$ $|C|=d$ $\\mathcal H$ shattered </li>\n<li> $|C|=d+1$  $\\mathcal H$ shattered</li>\n</ul>\n<p> $\\mathbf e_1, \\cdots, \\mathbf e_d$one-hot Halfspace shattered</p>\n<script type=\"math/tex; mode=display\">\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle): \\mathbf w \\in \\mathbb R^d\\}</script><p> $(y_1, \\cdots, y_d)$ $\\mathbf w=(y_1, \\cdots, y_d)$ $h(\\mathbf e_i)=\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle)=y_i$ $\\mathbf e_1, \\cdots, \\mathbf e_d$  $\\mathcal H$ shattered</p>\n<p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1} \\in R^d$ $d+1$  $\\sum_{i=1}^{d+1} a_i \\mathbf x_i=\\mathbf 0$ $a_1, \\cdots, a_{d+1}$  $0$ $I=\\{i:a_i&gt;0\\}$$J=\\{j:a_j&lt;0\\}$ $I, \\ J$ </p>\n<ul>\n<li>$I, \\ J$ </li>\n</ul>\n<script type=\"math/tex; mode=display\">\\sum_{i \\in I}a_i \\mathbf x_i = \\sum_{j \\in J} |a_j|\\mathbf x_j</script><p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle &gt;0, \\ \\forall \\ i \\in I$ $\\langle \\mathbf w, \\mathbf x_i \\rangle &lt;0, \\ \\forall \\ i \\in J$</p>\n<script type=\"math/tex; mode=display\">0 < \\sum_{i \\in I} a_i \\langle \\mathbf w, \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{i \\in I} a_i \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{j \\in J} |a_j| \\mathbf x_j \\rangle=\\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0</script><p> $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered</p>\n<ul>\n<li>$I=\\emptyset, \\ J \\neq \\emptyset$</li>\n</ul>\n<script type=\"math/tex; mode=display\">\\sum_{j \\in J} |a_j|\\mathbf x_j=0</script><p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle &lt;0, \\ \\forall \\ i \\in J$</p>\n<script type=\"math/tex; mode=display\">0=\\langle \\mathbf w, \\sum_{j \\in J} |a_j|\\mathbf x_j \\rangle= \\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0</script><p> $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered</p>\n<ul>\n<li>$I \\neq \\emptyset, \\ J = \\emptyset$</li>\n</ul>\n<p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathbf H$ shattered $VCdim(\\mathbf H)=d$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathbb R^d$  Halfspance  VC  $d+1$</p>\n<p><strong></strong></p>\n<p> $d+1$  $C=(\\mathbf 0, \\mathbf e_1, \\cdots, \\mathbf e_d)$</p>\n<script type=\"math/tex; mode=display\">\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w, \\mathbf x \\rangle + b): \\mathbf w \\in \\mathbb R^d\\}</script><p> label  $(y_1, \\cdots, y_{d+1})$ $\\mathbf w, b$ </p>\n<script type=\"math/tex; mode=display\">y_1 \\cdot b > 0</script><script type=\"math/tex; mode=display\">y_i(w_i+b)>0, \\ \\forall i \\in [d]</script><p> $C$  $\\mathcal H$ shattered</p>\n<p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$ $\\mathcal H$ shattered $\\mathbb R^{d+1}$  halfspace  $\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w, \\mathbf x\\rangle): \\mathbf w \\in \\mathbb R^{d+1}\\}$ $\\mathbf w=(b, w_1, \\cdots , w_d)$ $\\mathbf x=(1,x_1, \\cdots, x_d)$  $\\mathcal H$ $\\mathbb R^d$   $\\mathcal H \\subset \\mathcal H$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H$ shattered$\\mathbb R^{d+1}$  $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H$ shattered</p>\n<p><script type=\"math/tex\">VCdim(\\mathcal H)=d+1</script></p>\n","site":{"data":{}},"excerpt":"<p><br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $S=\\{(\\mathbf x_i, y_i)\\}_{i=1}^m$</p>\n<script type=\"math/tex; mode=display\">L_d=\\{h_{\\mathbf w, b}: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}</script><p>  </p>\n<script type=\"math/tex; mode=display\">HS_d=\\text{sign} \\circ L_d</script><p> $\\mathbf w=(b, w_1, \\cdots w_d)$$\\mathbf x=(1, x_1, \\cdots x_d)$</p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w, b}(\\mathbf x) = \\langle \\mathbf w', \\mathbf x' \\rangle</script><p> ERM $\\mathbf w^<em>$ $\\forall i = 1, \\cdots , m$ $\\text{sign}(\\langle \\mathbf w^</em>, \\mathbf x_i \\rangle)=y_i$</p>\n<script type=\"math/tex; mode=display\">y_i \\langle \\mathbf w^*, \\mathbf x_i \\rangle > 0, \\quad \\forall i = 1, \\cdots, m$$ (1)\n\n$\\mathbf w^*$ \n\n## Perceptron \n $t$ $\\mathbf w^{(t)}$ $\\mathbf w^{(1)}=\\mathbf 0$ $t$  $\\mathbf w^{(t)}$  $y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle \\le 0$\n\n$$\\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i</script><p></p>\n<script type=\"math/tex; mode=display\">y_i \\langle \\mathbf w^{(t+1)}, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}+y_i \\mathbf x_i, \\mathbf x_i \\rangle=y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle+\\|\\mathbf x_i \\|^2</script><p> $(\\mathbf x_i, y_i)$  $\\mathbf w^{(t)}$  $\\le 0$ $| \\mathbf x_i |^2 \\ge 0$ $\\mathbf w$</p>\n<p><strong></strong></p>\n<p> $(\\mathbf x_1, y_1), \\cdots , (\\mathbf x_m, y_m)$</p>\n<p>: $\\mathbf w^{(1)}=(0,\\cdots,0)$</p>\n<p>$\\quad \\text{for} \\ t=1,2,\\dots$</p>\n<p>$\\quad \\quad \\text{if} \\ (\\exists \\ i \\ s.t. \\ y_i \\langle \\mathbf w^(t), \\mathbf x_i \\rangle \\le 0) \\ \\text{then}$</p>\n<p>$\\quad \\quad \\quad \\mathbf w^{(t+1)}=\\mathbf w^{(t)}+y_i \\mathbf x_i$</p>\n<p>$\\quad \\quad \\text{else}$</p>\n<p>$\\quad \\quad \\quad \\text{output} \\ \\mathbf w^{(t)}$</p>\n<p> $\\mathbf w$</p>\n<p> $B=\\min \\{|\\mathbf w|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$ $R=\\max_i | \\mathbf x_i |$ $(RB)^2$  $\\forall \\ in \\in [m], \\ y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i \\rangle &gt; 0$</p>\n<p> $\\{|\\mathbf w|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 0\\}$   $\\mathbf w$  $\\forall \\ 0&lt;\\gamma &lt;1$ $\\gamma \\mathbf w$  $|\\gamma \\mathbf w|^2=\\gamma^2 |\\mathbf w|^2 &lt; |\\mathbf w |^2$</p>\n<p> $\\{|\\mathbf w|: \\forall \\ i \\in [m], \\ y_i \\langle \\mathbf w, \\mathbf x_i \\rangle \\ge 1\\}$  $|y_i\\langle \\mathbf w, \\mathbf x_i \\rangle|=|\\mathbf w |\\cdot|\\mathbf x_i| \\cdot|\\cos \\theta_i|\\ge 1 \\Rightarrow |\\mathbf w | \\ge 1/(|\\mathbf x_i| \\cdot|\\cos \\theta_i|)$   $\\forall i \\in [m]$  (1) $\\mathbf w$  $\\mathbf w$ $|\\mathbf x_i| \\cdot|\\cos \\theta_i|$ </p>\n<p> $(RB)^2$ </p>\n<p><strong></strong></p>\n<p> $\\mathbf w^<em>$  $B$  $\\forall \\ i \\in [m]$ $y_i \\langle \\mathbf w^</em>, \\mathbf x_i \\rangle \\ge 1$ $\\mathbf w^*$ </p>\n<p> $\\mathbf w^{(1)}=\\mathbf 0$ $\\langle \\mathbf w^*, \\mathbf w^{(1)}\\rangle=0$</p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle - \\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, \\mathbf w^{(t+1)}-\\mathbf w^{(t)}\\rangle=\\langle \\mathbf w^*, y_i \\mathbf x_i\\rangle=y_i\\langle \\mathbf w^*, \\mathbf x_i\\rangle \\ge 1</script><p></p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle=\\sum_{t=1}^T \\left( \\langle \\mathbf w^*, \\mathbf w^{(t+1)}\\rangle-\\langle \\mathbf w^*, \\mathbf w^{(t)}\\rangle \\right) \\ge T</script><p></p>\n<script type=\"math/tex; mode=display\">\\|\\mathbf w^{(t+1)}\\|^2=\\|\\mathbf w^{(t)}+y_i \\mathbf x_i\\|^2=\\|\\mathbf w^{(t)}\\|^2+2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle+y_i^2\\| \\mathbf x_i\\|^2 \\le \\|\\mathbf w^{(t)}\\|^2+R^2</script><p> $t+1$  $\\mathbf w^{(t)}$  $(\\mathbf x_i, y_i)$ $2y_i \\langle \\mathbf w^{(t)}, \\mathbf x_i\\rangle \\le 0$ $| \\mathbf x_i |^2 \\le R$ $|\\mathbf w^{(1)}|^2=0$</p>\n<script type=\"math/tex; mode=display\">\\|\\mathbf w^{(T+1)} \\|^2 \\le TR^2</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac {\\langle \\mathbf w^*, \\mathbf w^{(T+1)} \\rangle} {\\|\\mathbf w^*\\| \\cdot \\|\\mathbf w^{(T+1)}\\|} \\ge \\frac T {B \\sqrt T R}=\\frac {\\sqrt T} {BR}</script><p> Cauchy-Schwartz  $<1$ $1 > \\sqrt T / (BR)$</p>\n<script type=\"math/tex; mode=display\">T \\le (RB)^2</script><h2 id=\"VC-\"><a href=\"#VC-\" class=\"headerlink\" title=\"VC \"></a>VC </h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathbb R^d$  Halfspance  VC  $d$</p>\n<p><strong></strong></p>\n<p> $VCdim(\\mathcal H)=d$</p>\n<ul>\n<li> $C$ $|C|=d$ $\\mathcal H$ shattered </li>\n<li> $|C|=d+1$  $\\mathcal H$ shattered</li>\n</ul>\n<p> $\\mathbf e_1, \\cdots, \\mathbf e_d$one-hot Halfspace shattered</p>\n<script type=\"math/tex; mode=display\">\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle): \\mathbf w \\in \\mathbb R^d\\}</script><p> $(y_1, \\cdots, y_d)$ $\\mathbf w=(y_1, \\cdots, y_d)$ $h(\\mathbf e_i)=\\text{sign}(\\langle \\mathbf w , \\mathbf x\\rangle)=y_i$ $\\mathbf e_1, \\cdots, \\mathbf e_d$  $\\mathcal H$ shattered</p>\n<p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1} \\in R^d$ $d+1$  $\\sum_{i=1}^{d+1} a_i \\mathbf x_i=\\mathbf 0$ $a_1, \\cdots, a_{d+1}$  $0$ $I=\\{i:a_i&gt;0\\}$$J=\\{j:a_j&lt;0\\}$ $I, \\ J$ </p>\n<ul>\n<li>$I, \\ J$ </li>\n</ul>\n<script type=\"math/tex; mode=display\">\\sum_{i \\in I}a_i \\mathbf x_i = \\sum_{j \\in J} |a_j|\\mathbf x_j</script><p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle &gt;0, \\ \\forall \\ i \\in I$ $\\langle \\mathbf w, \\mathbf x_i \\rangle &lt;0, \\ \\forall \\ i \\in J$</p>\n<script type=\"math/tex; mode=display\">0 < \\sum_{i \\in I} a_i \\langle \\mathbf w, \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{i \\in I} a_i \\mathbf x_i \\rangle=\\langle \\mathbf w, \\sum_{j \\in J} |a_j| \\mathbf x_j \\rangle=\\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0</script><p> $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered</p>\n<ul>\n<li>$I=\\emptyset, \\ J \\neq \\emptyset$</li>\n</ul>\n<script type=\"math/tex; mode=display\">\\sum_{j \\in J} |a_j|\\mathbf x_j=0</script><p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered $\\mathbf w$ $\\langle \\mathbf w, \\mathbf x_i \\rangle &lt;0, \\ \\forall \\ i \\in J$</p>\n<script type=\"math/tex; mode=display\">0=\\langle \\mathbf w, \\sum_{j \\in J} |a_j|\\mathbf x_j \\rangle= \\sum_{j \\in J} |a_j| \\langle \\mathbf w, \\mathbf x_j \\rangle <0</script><p> $\\mathbf w$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathcal H$ shattered</p>\n<ul>\n<li>$I \\neq \\emptyset, \\ J = \\emptyset$</li>\n</ul>\n<p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+1}$  $\\mathbf H$ shattered $VCdim(\\mathbf H)=d$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathbb R^d$  Halfspance  VC  $d+1$</p>\n<p><strong></strong></p>\n<p> $d+1$  $C=(\\mathbf 0, \\mathbf e_1, \\cdots, \\mathbf e_d)$</p>\n<script type=\"math/tex; mode=display\">\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w, \\mathbf x \\rangle + b): \\mathbf w \\in \\mathbb R^d\\}</script><p> label  $(y_1, \\cdots, y_{d+1})$ $\\mathbf w, b$ </p>\n<script type=\"math/tex; mode=display\">y_1 \\cdot b > 0</script><script type=\"math/tex; mode=display\">y_i(w_i+b)>0, \\ \\forall i \\in [d]</script><p> $C$  $\\mathcal H$ shattered</p>\n<p> $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$ $\\mathcal H$ shattered $\\mathbb R^{d+1}$  halfspace  $\\mathcal H=\\{\\text{sign}(\\langle \\mathbf w, \\mathbf x\\rangle): \\mathbf w \\in \\mathbb R^{d+1}\\}$ $\\mathbf w=(b, w_1, \\cdots , w_d)$ $\\mathbf x=(1,x_1, \\cdots, x_d)$  $\\mathcal H$ $\\mathbb R^d$   $\\mathcal H \\subset \\mathcal H$ $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H$ shattered$\\mathbb R^{d+1}$  $\\mathbf x_1, \\cdots, \\mathbf x_{d+2}$  $\\mathcal H$ shattered</p>\n<p><script type=\"math/tex\">VCdim(\\mathcal H)=d+1</script></p>"},{"title":"k fold ","date":"2021-09-19T08:50:18.000Z","p":"ml/k_fold","mathjax":true,"_content":"\nK \n\n<!--more-->\n# \n\n\n1.  m k  $m/k$\n2.  k  i  i  i \n3. k \n\n# \n $d$\n\n<center> k fold </center>\n\n**input:**\n1.  $S=(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)$\n2.  $\\Theta$\n3.  $A$\n4. k-fold  $k$\n\n****\n1.  $S$  $S_1, \\cdots, S_k$\n\n**foreach** $\\theta \\in \\Theta$\n\n&emsp; **for** $i=1,\\cdots,k$\n\n&emsp; &emsp; $h_{i,\\theta}=A(S - S_i; \\theta)$\n\n &emsp; error$(\\theta)=\\frac 1 k \\sum_{i=1}^k L_{S_i}(h_{i, \\theta})$\n\n **output**\n 1. $\\theta^*=\\argmin_{\\theta} \\[\\text{error}(\\theta)]$\n 2. $h_{\\theta^*}=A(S;\\theta^*)$\n\n\n1.  k-fold \n2. ","source":"_posts/ml/k_fold.md","raw":"---\ntitle: k fold \ndate: 2021-09-19 16:50:18\ntags: machine learning\np: ml/k_fold\nmathjax: true\n---\n\nK \n\n<!--more-->\n# \n\n\n1.  m k  $m/k$\n2.  k  i  i  i \n3. k \n\n# \n $d$\n\n<center> k fold </center>\n\n**input:**\n1.  $S=(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)$\n2.  $\\Theta$\n3.  $A$\n4. k-fold  $k$\n\n****\n1.  $S$  $S_1, \\cdots, S_k$\n\n**foreach** $\\theta \\in \\Theta$\n\n&emsp; **for** $i=1,\\cdots,k$\n\n&emsp; &emsp; $h_{i,\\theta}=A(S - S_i; \\theta)$\n\n &emsp; error$(\\theta)=\\frac 1 k \\sum_{i=1}^k L_{S_i}(h_{i, \\theta})$\n\n **output**\n 1. $\\theta^*=\\argmin_{\\theta} \\[\\text{error}(\\theta)]$\n 2. $h_{\\theta^*}=A(S;\\theta^*)$\n\n\n1.  k-fold \n2. ","slug":"ml/k_fold","published":1,"updated":"2021-09-26T02:33:01.992Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or915002jp0djba5k80ji","content":"<p>K </p>\n<span id=\"more\"></span>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> m k  $m/k$</li>\n<li> k  i  i  i </li>\n<li>k </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $d$</p>\n<center> k fold </center>\n\n<p><strong>input:</strong></p>\n<ol>\n<li> $S=(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)$</li>\n<li> $\\Theta$</li>\n<li> $A$</li>\n<li>k-fold  $k$</li>\n</ol>\n<p><strong></strong></p>\n<ol>\n<li> $S$  $S_1, \\cdots, S_k$</li>\n</ol>\n<p><strong>foreach</strong> $\\theta \\in \\Theta$</p>\n<p>&emsp; <strong>for</strong> $i=1,\\cdots,k$</p>\n<p>&emsp; &emsp; $h_{i,\\theta}=A(S - S_i; \\theta)$</p>\n<p> &emsp; error$(\\theta)=\\frac 1 k \\sum_{i=1}^k L_{S_i}(h_{i, \\theta})$</p>\n<p> <strong>output</strong></p>\n<ol>\n<li>$\\theta^*=\\argmin_{\\theta} [\\text{error}(\\theta)]$</li>\n<li>$h_{\\theta^<em>}=A(S;\\theta^</em>)$</li>\n</ol>\n<p></p>\n<ol>\n<li> k-fold </li>\n<li></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>K </p>","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> m k  $m/k$</li>\n<li> k  i  i  i </li>\n<li>k </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $d$</p>\n<center> k fold </center>\n\n<p><strong>input:</strong></p>\n<ol>\n<li> $S=(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)$</li>\n<li> $\\Theta$</li>\n<li> $A$</li>\n<li>k-fold  $k$</li>\n</ol>\n<p><strong></strong></p>\n<ol>\n<li> $S$  $S_1, \\cdots, S_k$</li>\n</ol>\n<p><strong>foreach</strong> $\\theta \\in \\Theta$</p>\n<p>&emsp; <strong>for</strong> $i=1,\\cdots,k$</p>\n<p>&emsp; &emsp; $h_{i,\\theta}=A(S - S_i; \\theta)$</p>\n<p> &emsp; error$(\\theta)=\\frac 1 k \\sum_{i=1}^k L_{S_i}(h_{i, \\theta})$</p>\n<p> <strong>output</strong></p>\n<ol>\n<li>$\\theta^*=\\argmin_{\\theta} [\\text{error}(\\theta)]$</li>\n<li>$h_{\\theta^<em>}=A(S;\\theta^</em>)$</li>\n</ol>\n<p></p>\n<ol>\n<li> k-fold </li>\n<li></li>\n</ol>"},{"title":"","date":"2021-09-26T10:07:50.000Z","p":"ml/kernel","mathjax":true,"_content":"\n# \n Halfspace  margin  \n<!--more-->\n\n# \n\n $\\{-10,-9,-8,\\cdots, 0, 1, \\cdots 9, 10\\}$ $|x|>2$  $+1$ $-1$ $\\psi: \\mathbb R \\rightarrow \\mathbb R^2$\n\n$$\\psi(x)=(x, x^2)$$\n\n $\\mathbb R^2$  $\\mathbf w=(0, 1), \\ b=5$ $h(x)=\\text{sign}(\\mathbf w^{\\top} \\psi(x) - b)$ \n\n****\n\n1.  $\\mathcal X$  $\\psi: \\mathcal X \\rightarrow \\mathcal F$\n\n2.  $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $\\hat S=\\{(\\psi(\\mathbf x_1), y_1), \\cdots ,(\\psi(\\mathbf x_m), y_m)\\}$\n\n3.  $\\hat S$ \n\n4.  $\\mathbf x$  $h(\\psi(\\mathbf x))$\n\n** $\\psi$**\n\n\n $p=\\sum_{i=0}^k w_i x^i$ $\\psi(x)=(x^0, x^1, \\cdots, x^k)$ $\\mathbf x$ $p(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R$ \n\n$$p(\\mathbf x)=\\sum_{J \\in [n]^r: \\ r\\le k} w_J \\prod_{i=1}^r x_{J_i}$$\n\n\n $\\mathbf x$  $n$ $J$  $r$  $\\mathbf x$  $r$  $\\mathbf x=[x_1, \\cdots, x_n]$   $r$  $r$  $\\prod_{i=1}^r x_{J_i}$\n\n1.  0 $r=0$  1 $1$ \n\n2.  1$r=1$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}$ $n$ \n\n3.  2$r=2$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}, \\ x_{J_2}$ $x_{J_1} x_{J_2}$  $n^2$ \n\n4.  k$r=k$ $[x_1, x_2, \\cdots, x_n]$  k  $x_{J_1}, \\cdots, x_{J_k}$ $\\prod_{i=1}^k x_{J_i}$  $n^k$ \n\n\n\n$$S_{k+1}=\\frac {a_1(1-n^{k+1})}{1-n}=\\frac {n^{k+1}-1} {n-1}$$\n\n $n=1$  $S_{k+1}=a_1 \\times (k+1)=k+1$\n\n $\\psi(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R^d$ k  $d=S_{k+1}$$\\psi(\\mathbf x)$  $\\prod_{i=1}^r x_{J_i}$\n\n $d=S_{k+1}$  SVM  \n\n# \n\n $\\psi$  $\\mathcal X$  Hilbert \n\n$$K(\\mathbf x, \\mathbf x')=\\psi^{\\top}(\\mathbf x) \\psi(\\mathbf x')$$\n\n $K$ \n\n\n\n$$\\min_{\\mathbf w} f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m)) + R(\\|\\mathbf w\\|) \\quad(1)$$\n\n $f:\\mathbb R^m \\rightarrow \\mathbb R$ $R: \\mathbb R_+ \\rightarrow \\mathbb R$ \n\n Soft-SVM $R(a)=\\lambda a^2$$f(a_1, \\cdots, a_m)=\\frac 1 m \\sum_{i} \\max \\{0, 1- y_ia_i\\}, \\ a_i=\\mathbf w^{\\top}\\mathbf x_i$\n\nHard-SVM $R(a)=a^2$ $\\forall i \\in [m]$  $y_i(a_i+b)\\ge 1$ $f(a_1, \\cdots, a_m)=0$ $f(a_1, \\cdots, a_m)=\\infty$ Hard-SVM  $\\infty$\n\n** $\\boldsymbol \\alpha \\in \\mathbb R^m$ $\\mathbf w=\\boldsymbol \\alpha^{\\top} \\boldsymbol \\psi$  (1) **\n\n $\\boldsymbol \\psi = [\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ [SVM](/2021/09/22/ml/svm) $\\mathbf w$ \n\n\n\n $\\mathbf w^{\\ast}$  1 $\\mathbf w^{\\ast}$  Hilbert  $[\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ span $\\mathbf w$ $\\mathbf u$ \n\n$$\\mathbf w^{\\ast}=\\mathbf w + \\mathbf u=\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)+\\mathbf u$$\n\n $\\mathbf u^{\\top} \\psi(\\mathbf x_i)=0, \\ \\forall i \\in [m]$\n\n $\\|\\mathbf w^{\\ast}\\|^2=\\|\\mathbf w\\|^2+\\|\\mathbf u\\|^2+2\\mathbf w^{\\top} \\mathbf u$ $\\mathbf w$  $\\mathbf u$  $\\mathbf w^{\\top}\\mathbf u=0$ $\\|\\mathbf w^{\\ast}\\|^2=\\|\\mathbf w\\|^2+\\|\\mathbf u\\|^2 \\ge \\|\\mathbf w\\|^2$ $R$  $R(\\|\\mathbf w^{\\ast}\\|) \\ge R(\\|\\mathbf w\\|)$\n\n\n\n$$\\mathbf w^{\\top} \\psi(\\mathbf x_i)=(\\mathbf w^{\\ast}-\\mathbf u)^{\\top} \\psi(\\mathbf x_i)=\\mathbf w^{\\ast}\\psi(\\mathbf x_i)$$\n\n\n\n$$f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m))=f(\\mathbf w^{\\ast \\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\ast \\top} \\psi(\\mathbf x_m))$$\n\n (1)  $L(\\cdot)$ $L(\\mathbf w^{\\ast}) \\ge L(\\mathbf w)$  $\\mathbf w^{\\ast}$  $\\mathbf w$ \n\n 1 $\\mathbf w =\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$\n\n$$\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\left(\\sum_{j=1}^m \\alpha_j \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j \\psi^{\\top}(\\mathbf x_j)\\psi(\\mathbf x_i) \\quad (2)$$\n\n\n$$\\|\\mathbf w\\|^2=\\Vert \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i) \\Vert^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j \\psi^{\\top}(\\mathbf x_i)\\psi(\\mathbf x_j) \\quad(3)$$\n\n 1\n\n$$\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} f\\left(\\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_1), \\cdots, \\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_m)\\right) + R \\left(\\sqrt{\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i,\\mathbf x_j)}\\right) \\quad(4)$$\n\n $\\mathbf w \\in \\mathbb R^d$  $\\boldsymbol \\alpha \\in \\mathbb R^m$ $m << d$ \n\n $G_{m \\times m}$ $G_{ij}=K(\\mathbf x_i,\\mathbf x_j)$ Gram (2,3) \n\n$$\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=G_{i,:} \\cdot \\boldsymbol \\alpha=(G \\boldsymbol \\alpha)_i$$\n\n$$\\|\\mathbf w\\|^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=\\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha$$\n\n\n Soft-SVM  $\\min_{\\mathbf w} (\\lambda \\|\\mathbf w\\|^2+\\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(\\mathbf w^{\\top} \\mathbf x_i)\\})$ 4\n\n$$\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} \\ \\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(G \\boldsymbol \\alpha)_i\\} + \\lambda \\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha$$\n\n $\\boldsymbol \\alpha$ \n\n$$\\mathbf w^{\\top}\\psi(\\mathbf x)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x, \\mathbf x_j)$$\n\n$K(\\mathbf x, \\mathbf x_j)$  G \n\n#  Soft-SVM \n\n [SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD  Soft-SVM \n\n$$\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2+\\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)\\}\\right) \\quad(5)$$\n\n  [SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD  \n\n$$\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i$$\n\n\n\n$$\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)$$\n\n\n\n$$\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\theta^{(t)}$$\n\n $\\mathbf w, \\boldsymbol \\theta \\in \\mathbb R^d$ $d$  $\\boldsymbol \\theta$ $\\mathbf w = \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$  $\\boldsymbol \\alpha$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\mathbf w$  $dim(\\boldsymbol \\alpha)=m > dim(\\mathbf w)=d$ $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$  $\\boldsymbol \\beta$\n\n$$\\boldsymbol \\theta^{(t)}=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)$$\n\n\n\n\n$$\\boldsymbol \\alpha = \\frac 1 {\\lambda t} \\boldsymbol \\beta$$\n\n[SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD  $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\boldsymbol \\beta$\n\n $\\boldsymbol {\\theta}$ \n\n$$\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)+y_i \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t+1)} \\psi(\\mathbf x_j)$$\n\n $\\boldsymbol \\beta$  $i$ \n\n$$\\boldsymbol \\beta_{j}^{(t+1)}= \\begin{cases} \\boldsymbol \\beta_{j}^{(t)} & j \\neq i \\\\\\\\ \\boldsymbol \\beta_{i}^{(t)}+y_i & j=i \\end{cases}$$\n\n $i$ \n\n$$y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)=y_i \\left(\\sum_{j=1}^m \\alpha_j^{(t)} \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i)$$\n\n [SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD \n\n<center> Soft-SVM  SGD </center>\n\n**** 5\n\n****  $T$\n\n**** $\\boldsymbol \\beta^{(1)}=\\mathbf 0$\n\n**for** $\\ t=1,\\cdots, T$\n\n&emsp; $\\boldsymbol \\alpha^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\beta^{(t)}$\n\n&emsp;  $i \\in [m]$\n\n&emsp;  $\\forall j \\in [m]$  $j\\neq i$ $\\beta_j^{(t+1)}=\\beta_j^{(t)}$\n\n&emsp;  $\\ y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i) < 1$\n\n&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}+y_i$\n\n&emsp; \n\n&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}$\n\n**** $\\overline {\\boldsymbol \\alpha}=\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}$\n\n $\\boldsymbol \\alpha$  $\\mathbf w$\n\n$$\\overline {\\mathbf w}=\\sum_{i=1}^m \\overline {\\boldsymbol \\alpha}\\psi(\\mathbf x_i)$$\n\n $\\overline {\\boldsymbol \\alpha}$ \n\n$$\\overline {\\mathbf w}=\\sum_{i=1}^m \\left(\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}\\right)\\psi(\\mathbf x_i)=\\frac 1 T \\sum_{t=1}^T\\left(\\sum_{i=1}^m \\boldsymbol \\alpha^{(t)}\\psi(\\mathbf x_i)\\right)=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}$$\n\n Soft-SVM ","source":"_posts/ml/kernel.md","raw":"---\ntitle: \ndate: 2021-09-26 18:07:50\ntags: machine learning\np: ml/kernel\nmathjax: true\n---\n\n# \n Halfspace  margin  \n<!--more-->\n\n# \n\n $\\{-10,-9,-8,\\cdots, 0, 1, \\cdots 9, 10\\}$ $|x|>2$  $+1$ $-1$ $\\psi: \\mathbb R \\rightarrow \\mathbb R^2$\n\n$$\\psi(x)=(x, x^2)$$\n\n $\\mathbb R^2$  $\\mathbf w=(0, 1), \\ b=5$ $h(x)=\\text{sign}(\\mathbf w^{\\top} \\psi(x) - b)$ \n\n****\n\n1.  $\\mathcal X$  $\\psi: \\mathcal X \\rightarrow \\mathcal F$\n\n2.  $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $\\hat S=\\{(\\psi(\\mathbf x_1), y_1), \\cdots ,(\\psi(\\mathbf x_m), y_m)\\}$\n\n3.  $\\hat S$ \n\n4.  $\\mathbf x$  $h(\\psi(\\mathbf x))$\n\n** $\\psi$**\n\n\n $p=\\sum_{i=0}^k w_i x^i$ $\\psi(x)=(x^0, x^1, \\cdots, x^k)$ $\\mathbf x$ $p(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R$ \n\n$$p(\\mathbf x)=\\sum_{J \\in [n]^r: \\ r\\le k} w_J \\prod_{i=1}^r x_{J_i}$$\n\n\n $\\mathbf x$  $n$ $J$  $r$  $\\mathbf x$  $r$  $\\mathbf x=[x_1, \\cdots, x_n]$   $r$  $r$  $\\prod_{i=1}^r x_{J_i}$\n\n1.  0 $r=0$  1 $1$ \n\n2.  1$r=1$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}$ $n$ \n\n3.  2$r=2$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}, \\ x_{J_2}$ $x_{J_1} x_{J_2}$  $n^2$ \n\n4.  k$r=k$ $[x_1, x_2, \\cdots, x_n]$  k  $x_{J_1}, \\cdots, x_{J_k}$ $\\prod_{i=1}^k x_{J_i}$  $n^k$ \n\n\n\n$$S_{k+1}=\\frac {a_1(1-n^{k+1})}{1-n}=\\frac {n^{k+1}-1} {n-1}$$\n\n $n=1$  $S_{k+1}=a_1 \\times (k+1)=k+1$\n\n $\\psi(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R^d$ k  $d=S_{k+1}$$\\psi(\\mathbf x)$  $\\prod_{i=1}^r x_{J_i}$\n\n $d=S_{k+1}$  SVM  \n\n# \n\n $\\psi$  $\\mathcal X$  Hilbert \n\n$$K(\\mathbf x, \\mathbf x')=\\psi^{\\top}(\\mathbf x) \\psi(\\mathbf x')$$\n\n $K$ \n\n\n\n$$\\min_{\\mathbf w} f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m)) + R(\\|\\mathbf w\\|) \\quad(1)$$\n\n $f:\\mathbb R^m \\rightarrow \\mathbb R$ $R: \\mathbb R_+ \\rightarrow \\mathbb R$ \n\n Soft-SVM $R(a)=\\lambda a^2$$f(a_1, \\cdots, a_m)=\\frac 1 m \\sum_{i} \\max \\{0, 1- y_ia_i\\}, \\ a_i=\\mathbf w^{\\top}\\mathbf x_i$\n\nHard-SVM $R(a)=a^2$ $\\forall i \\in [m]$  $y_i(a_i+b)\\ge 1$ $f(a_1, \\cdots, a_m)=0$ $f(a_1, \\cdots, a_m)=\\infty$ Hard-SVM  $\\infty$\n\n** $\\boldsymbol \\alpha \\in \\mathbb R^m$ $\\mathbf w=\\boldsymbol \\alpha^{\\top} \\boldsymbol \\psi$  (1) **\n\n $\\boldsymbol \\psi = [\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ [SVM](/2021/09/22/ml/svm) $\\mathbf w$ \n\n\n\n $\\mathbf w^{\\ast}$  1 $\\mathbf w^{\\ast}$  Hilbert  $[\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ span $\\mathbf w$ $\\mathbf u$ \n\n$$\\mathbf w^{\\ast}=\\mathbf w + \\mathbf u=\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)+\\mathbf u$$\n\n $\\mathbf u^{\\top} \\psi(\\mathbf x_i)=0, \\ \\forall i \\in [m]$\n\n $\\|\\mathbf w^{\\ast}\\|^2=\\|\\mathbf w\\|^2+\\|\\mathbf u\\|^2+2\\mathbf w^{\\top} \\mathbf u$ $\\mathbf w$  $\\mathbf u$  $\\mathbf w^{\\top}\\mathbf u=0$ $\\|\\mathbf w^{\\ast}\\|^2=\\|\\mathbf w\\|^2+\\|\\mathbf u\\|^2 \\ge \\|\\mathbf w\\|^2$ $R$  $R(\\|\\mathbf w^{\\ast}\\|) \\ge R(\\|\\mathbf w\\|)$\n\n\n\n$$\\mathbf w^{\\top} \\psi(\\mathbf x_i)=(\\mathbf w^{\\ast}-\\mathbf u)^{\\top} \\psi(\\mathbf x_i)=\\mathbf w^{\\ast}\\psi(\\mathbf x_i)$$\n\n\n\n$$f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m))=f(\\mathbf w^{\\ast \\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\ast \\top} \\psi(\\mathbf x_m))$$\n\n (1)  $L(\\cdot)$ $L(\\mathbf w^{\\ast}) \\ge L(\\mathbf w)$  $\\mathbf w^{\\ast}$  $\\mathbf w$ \n\n 1 $\\mathbf w =\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$\n\n$$\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\left(\\sum_{j=1}^m \\alpha_j \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j \\psi^{\\top}(\\mathbf x_j)\\psi(\\mathbf x_i) \\quad (2)$$\n\n\n$$\\|\\mathbf w\\|^2=\\Vert \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i) \\Vert^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j \\psi^{\\top}(\\mathbf x_i)\\psi(\\mathbf x_j) \\quad(3)$$\n\n 1\n\n$$\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} f\\left(\\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_1), \\cdots, \\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_m)\\right) + R \\left(\\sqrt{\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i,\\mathbf x_j)}\\right) \\quad(4)$$\n\n $\\mathbf w \\in \\mathbb R^d$  $\\boldsymbol \\alpha \\in \\mathbb R^m$ $m << d$ \n\n $G_{m \\times m}$ $G_{ij}=K(\\mathbf x_i,\\mathbf x_j)$ Gram (2,3) \n\n$$\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=G_{i,:} \\cdot \\boldsymbol \\alpha=(G \\boldsymbol \\alpha)_i$$\n\n$$\\|\\mathbf w\\|^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=\\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha$$\n\n\n Soft-SVM  $\\min_{\\mathbf w} (\\lambda \\|\\mathbf w\\|^2+\\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(\\mathbf w^{\\top} \\mathbf x_i)\\})$ 4\n\n$$\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} \\ \\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(G \\boldsymbol \\alpha)_i\\} + \\lambda \\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha$$\n\n $\\boldsymbol \\alpha$ \n\n$$\\mathbf w^{\\top}\\psi(\\mathbf x)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x, \\mathbf x_j)$$\n\n$K(\\mathbf x, \\mathbf x_j)$  G \n\n#  Soft-SVM \n\n [SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD  Soft-SVM \n\n$$\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2+\\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)\\}\\right) \\quad(5)$$\n\n  [SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD  \n\n$$\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i$$\n\n\n\n$$\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)$$\n\n\n\n$$\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\theta^{(t)}$$\n\n $\\mathbf w, \\boldsymbol \\theta \\in \\mathbb R^d$ $d$  $\\boldsymbol \\theta$ $\\mathbf w = \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$  $\\boldsymbol \\alpha$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\mathbf w$  $dim(\\boldsymbol \\alpha)=m > dim(\\mathbf w)=d$ $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$  $\\boldsymbol \\beta$\n\n$$\\boldsymbol \\theta^{(t)}=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)$$\n\n\n\n\n$$\\boldsymbol \\alpha = \\frac 1 {\\lambda t} \\boldsymbol \\beta$$\n\n[SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD  $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\boldsymbol \\beta$\n\n $\\boldsymbol {\\theta}$ \n\n$$\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)+y_i \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t+1)} \\psi(\\mathbf x_j)$$\n\n $\\boldsymbol \\beta$  $i$ \n\n$$\\boldsymbol \\beta_{j}^{(t+1)}= \\begin{cases} \\boldsymbol \\beta_{j}^{(t)} & j \\neq i \\\\\\\\ \\boldsymbol \\beta_{i}^{(t)}+y_i & j=i \\end{cases}$$\n\n $i$ \n\n$$y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)=y_i \\left(\\sum_{j=1}^m \\alpha_j^{(t)} \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i)$$\n\n [SVM](/2021/09/22/ml/svm)  Soft-SVM  SGD \n\n<center> Soft-SVM  SGD </center>\n\n**** 5\n\n****  $T$\n\n**** $\\boldsymbol \\beta^{(1)}=\\mathbf 0$\n\n**for** $\\ t=1,\\cdots, T$\n\n&emsp; $\\boldsymbol \\alpha^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\beta^{(t)}$\n\n&emsp;  $i \\in [m]$\n\n&emsp;  $\\forall j \\in [m]$  $j\\neq i$ $\\beta_j^{(t+1)}=\\beta_j^{(t)}$\n\n&emsp;  $\\ y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i) < 1$\n\n&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}+y_i$\n\n&emsp; \n\n&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}$\n\n**** $\\overline {\\boldsymbol \\alpha}=\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}$\n\n $\\boldsymbol \\alpha$  $\\mathbf w$\n\n$$\\overline {\\mathbf w}=\\sum_{i=1}^m \\overline {\\boldsymbol \\alpha}\\psi(\\mathbf x_i)$$\n\n $\\overline {\\boldsymbol \\alpha}$ \n\n$$\\overline {\\mathbf w}=\\sum_{i=1}^m \\left(\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}\\right)\\psi(\\mathbf x_i)=\\frac 1 T \\sum_{t=1}^T\\left(\\sum_{i=1}^m \\boldsymbol \\alpha^{(t)}\\psi(\\mathbf x_i)\\right)=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}$$\n\n Soft-SVM ","slug":"ml/kernel","published":1,"updated":"2021-09-27T08:30:10.250Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or916002lp0dja1osfjr8","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Halfspace  margin  <br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\{-10,-9,-8,\\cdots, 0, 1, \\cdots 9, 10\\}$ $|x|&gt;2$  $+1$ $-1$ $\\psi: \\mathbb R \\rightarrow \\mathbb R^2$</p>\n<script type=\"math/tex; mode=display\">\\psi(x)=(x, x^2)</script><p> $\\mathbb R^2$  $\\mathbf w=(0, 1), \\ b=5$ $h(x)=\\text{sign}(\\mathbf w^{\\top} \\psi(x) - b)$ </p>\n<p><strong></strong></p>\n<ol>\n<li><p> $\\mathcal X$  $\\psi: \\mathcal X \\rightarrow \\mathcal F$</p>\n</li>\n<li><p> $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $\\hat S=\\{(\\psi(\\mathbf x_1), y_1), \\cdots ,(\\psi(\\mathbf x_m), y_m)\\}$</p>\n</li>\n<li><p> $\\hat S$ </p>\n</li>\n<li><p> $\\mathbf x$  $h(\\psi(\\mathbf x))$</p>\n</li>\n</ol>\n<p><strong> $\\psi$</strong></p>\n<p> $p=\\sum_{i=0}^k w_i x^i$ $\\psi(x)=(x^0, x^1, \\cdots, x^k)$ $\\mathbf x$ $p(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R$ </p>\n<script type=\"math/tex; mode=display\">p(\\mathbf x)=\\sum_{J \\in [n]^r: \\ r\\le k} w_J \\prod_{i=1}^r x_{J_i}</script><p> $\\mathbf x$  $n$ $J$  $r$  $\\mathbf x$  $r$  $\\mathbf x=[x_1, \\cdots, x_n]$   $r$  $r$  $\\prod_{i=1}^r x_{J_i}$</p>\n<ol>\n<li><p> 0 $r=0$  1 $1$ </p>\n</li>\n<li><p> 1$r=1$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}$ $n$ </p>\n</li>\n<li><p> 2$r=2$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}, \\ x_{J_2}$ $x_{J_1} x_{J_2}$  $n^2$ </p>\n</li>\n<li><p> k$r=k$ $[x_1, x_2, \\cdots, x_n]$  k  $x_{J_1}, \\cdots, x_{J_k}$ $\\prod_{i=1}^k x_{J_i}$  $n^k$ </p>\n</li>\n</ol>\n<p></p>\n<script type=\"math/tex; mode=display\">S_{k+1}=\\frac {a_1(1-n^{k+1})}{1-n}=\\frac {n^{k+1}-1} {n-1}</script><p> $n=1$  $S_{k+1}=a_1 \\times (k+1)=k+1$</p>\n<p> $\\psi(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R^d$ k  $d=S_{k+1}$$\\psi(\\mathbf x)$  $\\prod_{i=1}^r x_{J_i}$</p>\n<p> $d=S_{k+1}$  SVM  </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\psi$  $\\mathcal X$  Hilbert </p>\n<script type=\"math/tex; mode=display\">K(\\mathbf x, \\mathbf x')=\\psi^{\\top}(\\mathbf x) \\psi(\\mathbf x')</script><p> $K$ </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m)) + R(\\|\\mathbf w\\|) \\quad(1)</script><p> $f:\\mathbb R^m \\rightarrow \\mathbb R$ $R: \\mathbb R_+ \\rightarrow \\mathbb R$ </p>\n<p> Soft-SVM $R(a)=\\lambda a^2$$f(a_1, \\cdots, a_m)=\\frac 1 m \\sum_{i} \\max \\{0, 1- y_ia_i\\}, \\ a_i=\\mathbf w^{\\top}\\mathbf x_i$</p>\n<p>Hard-SVM $R(a)=a^2$ $\\forall i \\in [m]$  $y_i(a_i+b)\\ge 1$ $f(a_1, \\cdots, a_m)=0$ $f(a_1, \\cdots, a_m)=\\infty$ Hard-SVM  $\\infty$</p>\n<p><strong> $\\boldsymbol \\alpha \\in \\mathbb R^m$ $\\mathbf w=\\boldsymbol \\alpha^{\\top} \\boldsymbol \\psi$  (1) </strong></p>\n<p> $\\boldsymbol \\psi = [\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ <a href=\"/2021/09/22/ml/svm\">SVM</a> $\\mathbf w$ </p>\n<p></p>\n<p> $\\mathbf w^{\\ast}$  1 $\\mathbf w^{\\ast}$  Hilbert  $[\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ span $\\mathbf w$ $\\mathbf u$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\ast}=\\mathbf w + \\mathbf u=\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)+\\mathbf u</script><p> $\\mathbf u^{\\top} \\psi(\\mathbf x_i)=0, \\ \\forall i \\in [m]$</p>\n<p> $|\\mathbf w^{\\ast}|^2=|\\mathbf w|^2+|\\mathbf u|^2+2\\mathbf w^{\\top} \\mathbf u$ $\\mathbf w$  $\\mathbf u$  $\\mathbf w^{\\top}\\mathbf u=0$ $|\\mathbf w^{\\ast}|^2=|\\mathbf w|^2+|\\mathbf u|^2 \\ge |\\mathbf w|^2$ $R$  $R(|\\mathbf w^{\\ast}|) \\ge R(|\\mathbf w|)$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top} \\psi(\\mathbf x_i)=(\\mathbf w^{\\ast}-\\mathbf u)^{\\top} \\psi(\\mathbf x_i)=\\mathbf w^{\\ast}\\psi(\\mathbf x_i)</script><p></p>\n<script type=\"math/tex; mode=display\">f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m))=f(\\mathbf w^{\\ast \\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\ast \\top} \\psi(\\mathbf x_m))</script><p> (1)  $L(\\cdot)$ $L(\\mathbf w^{\\ast}) \\ge L(\\mathbf w)$  $\\mathbf w^{\\ast}$  $\\mathbf w$ </p>\n<p> 1 $\\mathbf w =\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$</p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\left(\\sum_{j=1}^m \\alpha_j \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j \\psi^{\\top}(\\mathbf x_j)\\psi(\\mathbf x_i) \\quad (2)</script><script type=\"math/tex; mode=display\">\\|\\mathbf w\\|^2=\\Vert \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i) \\Vert^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j \\psi^{\\top}(\\mathbf x_i)\\psi(\\mathbf x_j) \\quad(3)</script><p> 1</p>\n<script type=\"math/tex; mode=display\">\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} f\\left(\\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_1), \\cdots, \\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_m)\\right) + R \\left(\\sqrt{\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i,\\mathbf x_j)}\\right) \\quad(4)</script><p> $\\mathbf w \\in \\mathbb R^d$  $\\boldsymbol \\alpha \\in \\mathbb R^m$ $m &lt;&lt; d$ </p>\n<p> $G_{m \\times m}$ $G_{ij}=K(\\mathbf x_i,\\mathbf x_j)$ Gram (2,3) </p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=G_{i,:} \\cdot \\boldsymbol \\alpha=(G \\boldsymbol \\alpha)_i</script><script type=\"math/tex; mode=display\">\\|\\mathbf w\\|^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=\\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha</script><p> Soft-SVM  $\\min_{\\mathbf w} (\\lambda |\\mathbf w|^2+\\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(\\mathbf w^{\\top} \\mathbf x_i)\\})$ 4</p>\n<script type=\"math/tex; mode=display\">\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} \\ \\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(G \\boldsymbol \\alpha)_i\\} + \\lambda \\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha</script><p> $\\boldsymbol \\alpha$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top}\\psi(\\mathbf x)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x, \\mathbf x_j)</script><p>$K(\\mathbf x, \\mathbf x_j)$  G </p>\n<h1 id=\"-Soft-SVM-\"><a href=\"#-Soft-SVM-\" class=\"headerlink\" title=\" Soft-SVM \"></a> Soft-SVM </h1><p> <a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD  Soft-SVM </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2+\\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)\\}\\right) \\quad(5)</script><p>  <a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD  </p>\n<script type=\"math/tex; mode=display\">\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i</script><p></p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\theta^{(t)}</script><p> $\\mathbf w, \\boldsymbol \\theta \\in \\mathbb R^d$ $d$  $\\boldsymbol \\theta$ $\\mathbf w = \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$  $\\boldsymbol \\alpha$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\mathbf w$  $dim(\\boldsymbol \\alpha)=m &gt; dim(\\mathbf w)=d$ $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$  $\\boldsymbol \\beta$</p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\theta^{(t)}=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)</script><p></p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\alpha = \\frac 1 {\\lambda t} \\boldsymbol \\beta</script><p><a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD  $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\boldsymbol \\beta$</p>\n<p> $\\boldsymbol {\\theta}$ </p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)+y_i \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t+1)} \\psi(\\mathbf x_j)</script><p> $\\boldsymbol \\beta$  $i$ </p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\beta_{j}^{(t+1)}= \\begin{cases} \\boldsymbol \\beta_{j}^{(t)} & j \\neq i \\\\\\\\ \\boldsymbol \\beta_{i}^{(t)}+y_i & j=i \\end{cases}</script><p> $i$ </p>\n<script type=\"math/tex; mode=display\">y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)=y_i \\left(\\sum_{j=1}^m \\alpha_j^{(t)} \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i)</script><p> <a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD </p>\n<center> Soft-SVM  SGD </center>\n\n<p><strong></strong> 5</p>\n<p><strong></strong>  $T$</p>\n<p><strong></strong> $\\boldsymbol \\beta^{(1)}=\\mathbf 0$</p>\n<p><strong>for</strong> $\\ t=1,\\cdots, T$</p>\n<p>&emsp; $\\boldsymbol \\alpha^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\beta^{(t)}$</p>\n<p>&emsp;  $i \\in [m]$</p>\n<p>&emsp;  $\\forall j \\in [m]$  $j\\neq i$ $\\beta_j^{(t+1)}=\\beta_j^{(t)}$</p>\n<p>&emsp;  $\\ y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i) &lt; 1$</p>\n<p>&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}+y_i$</p>\n<p>&emsp; </p>\n<p>&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}$</p>\n<p><strong></strong> $\\overline {\\boldsymbol \\alpha}=\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}$</p>\n<p> $\\boldsymbol \\alpha$  $\\mathbf w$</p>\n<script type=\"math/tex; mode=display\">\\overline {\\mathbf w}=\\sum_{i=1}^m \\overline {\\boldsymbol \\alpha}\\psi(\\mathbf x_i)</script><p> $\\overline {\\boldsymbol \\alpha}$ </p>\n<script type=\"math/tex; mode=display\">\\overline {\\mathbf w}=\\sum_{i=1}^m \\left(\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}\\right)\\psi(\\mathbf x_i)=\\frac 1 T \\sum_{t=1}^T\\left(\\sum_{i=1}^m \\boldsymbol \\alpha^{(t)}\\psi(\\mathbf x_i)\\right)=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}</script><p> Soft-SVM </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Halfspace  margin  <br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\{-10,-9,-8,\\cdots, 0, 1, \\cdots 9, 10\\}$ $|x|&gt;2$  $+1$ $-1$ $\\psi: \\mathbb R \\rightarrow \\mathbb R^2$</p>\n<script type=\"math/tex; mode=display\">\\psi(x)=(x, x^2)</script><p> $\\mathbb R^2$  $\\mathbf w=(0, 1), \\ b=5$ $h(x)=\\text{sign}(\\mathbf w^{\\top} \\psi(x) - b)$ </p>\n<p><strong></strong></p>\n<ol>\n<li><p> $\\mathcal X$  $\\psi: \\mathcal X \\rightarrow \\mathcal F$</p>\n</li>\n<li><p> $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $\\hat S=\\{(\\psi(\\mathbf x_1), y_1), \\cdots ,(\\psi(\\mathbf x_m), y_m)\\}$</p>\n</li>\n<li><p> $\\hat S$ </p>\n</li>\n<li><p> $\\mathbf x$  $h(\\psi(\\mathbf x))$</p>\n</li>\n</ol>\n<p><strong> $\\psi$</strong></p>\n<p> $p=\\sum_{i=0}^k w_i x^i$ $\\psi(x)=(x^0, x^1, \\cdots, x^k)$ $\\mathbf x$ $p(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R$ </p>\n<script type=\"math/tex; mode=display\">p(\\mathbf x)=\\sum_{J \\in [n]^r: \\ r\\le k} w_J \\prod_{i=1}^r x_{J_i}</script><p> $\\mathbf x$  $n$ $J$  $r$  $\\mathbf x$  $r$  $\\mathbf x=[x_1, \\cdots, x_n]$   $r$  $r$  $\\prod_{i=1}^r x_{J_i}$</p>\n<ol>\n<li><p> 0 $r=0$  1 $1$ </p>\n</li>\n<li><p> 1$r=1$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}$ $n$ </p>\n</li>\n<li><p> 2$r=2$ $[x_1, x_2, \\cdots, x_n]$  $x_{J_1}, \\ x_{J_2}$ $x_{J_1} x_{J_2}$  $n^2$ </p>\n</li>\n<li><p> k$r=k$ $[x_1, x_2, \\cdots, x_n]$  k  $x_{J_1}, \\cdots, x_{J_k}$ $\\prod_{i=1}^k x_{J_i}$  $n^k$ </p>\n</li>\n</ol>\n<p></p>\n<script type=\"math/tex; mode=display\">S_{k+1}=\\frac {a_1(1-n^{k+1})}{1-n}=\\frac {n^{k+1}-1} {n-1}</script><p> $n=1$  $S_{k+1}=a_1 \\times (k+1)=k+1$</p>\n<p> $\\psi(\\mathbf x): \\mathbb R^n \\rightarrow \\mathbb R^d$ k  $d=S_{k+1}$$\\psi(\\mathbf x)$  $\\prod_{i=1}^r x_{J_i}$</p>\n<p> $d=S_{k+1}$  SVM  </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\psi$  $\\mathcal X$  Hilbert </p>\n<script type=\"math/tex; mode=display\">K(\\mathbf x, \\mathbf x')=\\psi^{\\top}(\\mathbf x) \\psi(\\mathbf x')</script><p> $K$ </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m)) + R(\\|\\mathbf w\\|) \\quad(1)</script><p> $f:\\mathbb R^m \\rightarrow \\mathbb R$ $R: \\mathbb R_+ \\rightarrow \\mathbb R$ </p>\n<p> Soft-SVM $R(a)=\\lambda a^2$$f(a_1, \\cdots, a_m)=\\frac 1 m \\sum_{i} \\max \\{0, 1- y_ia_i\\}, \\ a_i=\\mathbf w^{\\top}\\mathbf x_i$</p>\n<p>Hard-SVM $R(a)=a^2$ $\\forall i \\in [m]$  $y_i(a_i+b)\\ge 1$ $f(a_1, \\cdots, a_m)=0$ $f(a_1, \\cdots, a_m)=\\infty$ Hard-SVM  $\\infty$</p>\n<p><strong> $\\boldsymbol \\alpha \\in \\mathbb R^m$ $\\mathbf w=\\boldsymbol \\alpha^{\\top} \\boldsymbol \\psi$  (1) </strong></p>\n<p> $\\boldsymbol \\psi = [\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ <a href=\"/2021/09/22/ml/svm\">SVM</a> $\\mathbf w$ </p>\n<p></p>\n<p> $\\mathbf w^{\\ast}$  1 $\\mathbf w^{\\ast}$  Hilbert  $[\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)]$ span $\\mathbf w$ $\\mathbf u$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\ast}=\\mathbf w + \\mathbf u=\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)+\\mathbf u</script><p> $\\mathbf u^{\\top} \\psi(\\mathbf x_i)=0, \\ \\forall i \\in [m]$</p>\n<p> $|\\mathbf w^{\\ast}|^2=|\\mathbf w|^2+|\\mathbf u|^2+2\\mathbf w^{\\top} \\mathbf u$ $\\mathbf w$  $\\mathbf u$  $\\mathbf w^{\\top}\\mathbf u=0$ $|\\mathbf w^{\\ast}|^2=|\\mathbf w|^2+|\\mathbf u|^2 \\ge |\\mathbf w|^2$ $R$  $R(|\\mathbf w^{\\ast}|) \\ge R(|\\mathbf w|)$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top} \\psi(\\mathbf x_i)=(\\mathbf w^{\\ast}-\\mathbf u)^{\\top} \\psi(\\mathbf x_i)=\\mathbf w^{\\ast}\\psi(\\mathbf x_i)</script><p></p>\n<script type=\"math/tex; mode=display\">f(\\mathbf w^{\\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\top} \\psi(\\mathbf x_m))=f(\\mathbf w^{\\ast \\top} \\psi(\\mathbf x_1), \\cdots, \\mathbf w^{\\ast \\top} \\psi(\\mathbf x_m))</script><p> (1)  $L(\\cdot)$ $L(\\mathbf w^{\\ast}) \\ge L(\\mathbf w)$  $\\mathbf w^{\\ast}$  $\\mathbf w$ </p>\n<p> 1 $\\mathbf w =\\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$</p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\left(\\sum_{j=1}^m \\alpha_j \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j \\psi^{\\top}(\\mathbf x_j)\\psi(\\mathbf x_i) \\quad (2)</script><script type=\"math/tex; mode=display\">\\|\\mathbf w\\|^2=\\Vert \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i) \\Vert^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j \\psi^{\\top}(\\mathbf x_i)\\psi(\\mathbf x_j) \\quad(3)</script><p> 1</p>\n<script type=\"math/tex; mode=display\">\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} f\\left(\\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_1), \\cdots, \\sum_{j=1}^m \\alpha_j K(\\mathbf x_j, \\mathbf x_m)\\right) + R \\left(\\sqrt{\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i,\\mathbf x_j)}\\right) \\quad(4)</script><p> $\\mathbf w \\in \\mathbb R^d$  $\\boldsymbol \\alpha \\in \\mathbb R^m$ $m &lt;&lt; d$ </p>\n<p> $G_{m \\times m}$ $G_{ij}=K(\\mathbf x_i,\\mathbf x_j)$ Gram (2,3) </p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top}\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=G_{i,:} \\cdot \\boldsymbol \\alpha=(G \\boldsymbol \\alpha)_i</script><script type=\"math/tex; mode=display\">\\|\\mathbf w\\|^2=\\sum_{i=1}^m \\sum_{j=1}^m\\alpha_i \\alpha_j K(\\mathbf x_i, \\mathbf x_j)=\\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha</script><p> Soft-SVM  $\\min_{\\mathbf w} (\\lambda |\\mathbf w|^2+\\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(\\mathbf w^{\\top} \\mathbf x_i)\\})$ 4</p>\n<script type=\"math/tex; mode=display\">\\min_{\\boldsymbol \\alpha \\in \\mathbb R^m} \\ \\frac 1 m \\sum_{i=1}^m \\max\\{0, 1-y_i(G \\boldsymbol \\alpha)_i\\} + \\lambda \\boldsymbol \\alpha^{\\top} G \\boldsymbol \\alpha</script><p> $\\boldsymbol \\alpha$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top}\\psi(\\mathbf x)=\\sum_{j=1}^m \\alpha_j K(\\mathbf x, \\mathbf x_j)</script><p>$K(\\mathbf x, \\mathbf x_j)$  G </p>\n<h1 id=\"-Soft-SVM-\"><a href=\"#-Soft-SVM-\" class=\"headerlink\" title=\" Soft-SVM \"></a> Soft-SVM </h1><p> <a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD  Soft-SVM </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2+\\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)\\}\\right) \\quad(5)</script><p>  <a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD  </p>\n<script type=\"math/tex; mode=display\">\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i</script><p></p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\theta^{(t)}</script><p> $\\mathbf w, \\boldsymbol \\theta \\in \\mathbb R^d$ $d$  $\\boldsymbol \\theta$ $\\mathbf w = \\sum_{i=1}^m \\alpha_i \\psi(\\mathbf x_i)$  $\\boldsymbol \\alpha$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\mathbf w$  $dim(\\boldsymbol \\alpha)=m &gt; dim(\\mathbf w)=d$ $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$  $\\boldsymbol \\beta$</p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\theta^{(t)}=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)</script><p></p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\alpha = \\frac 1 {\\lambda t} \\boldsymbol \\beta</script><p><a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD  $\\boldsymbol \\theta$ $\\psi(\\mathbf x_1), \\cdots, \\psi(\\mathbf x_m)$ $\\boldsymbol \\beta$</p>\n<p> $\\boldsymbol {\\theta}$ </p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\theta^{(t+1)}=\\boldsymbol \\theta^{(t)} +y_i\\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t)} \\psi(\\mathbf x_j)+y_i \\psi(\\mathbf x_i)=\\sum_{j=1}^m \\beta_j^{(t+1)} \\psi(\\mathbf x_j)</script><p> $\\boldsymbol \\beta$  $i$ </p>\n<script type=\"math/tex; mode=display\">\\boldsymbol \\beta_{j}^{(t+1)}= \\begin{cases} \\boldsymbol \\beta_{j}^{(t)} & j \\neq i \\\\\\\\ \\boldsymbol \\beta_{i}^{(t)}+y_i & j=i \\end{cases}</script><p> $i$ </p>\n<script type=\"math/tex; mode=display\">y_i \\mathbf w^{\\top} \\psi(\\mathbf x_i)=y_i \\left(\\sum_{j=1}^m \\alpha_j^{(t)} \\psi(\\mathbf x_j)\\right)^{\\top} \\psi(\\mathbf x_i)=y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i)</script><p> <a href=\"/2021/09/22/ml/svm\">SVM</a>  Soft-SVM  SGD </p>\n<center> Soft-SVM  SGD </center>\n\n<p><strong></strong> 5</p>\n<p><strong></strong>  $T$</p>\n<p><strong></strong> $\\boldsymbol \\beta^{(1)}=\\mathbf 0$</p>\n<p><strong>for</strong> $\\ t=1,\\cdots, T$</p>\n<p>&emsp; $\\boldsymbol \\alpha^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol \\beta^{(t)}$</p>\n<p>&emsp;  $i \\in [m]$</p>\n<p>&emsp;  $\\forall j \\in [m]$  $j\\neq i$ $\\beta_j^{(t+1)}=\\beta_j^{(t)}$</p>\n<p>&emsp;  $\\ y_i\\sum_{j=1}^m \\alpha_j^{(t)} K(\\mathbf x_j, \\mathbf x_i) &lt; 1$</p>\n<p>&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}+y_i$</p>\n<p>&emsp; </p>\n<p>&emsp; &emsp; $\\beta_i^{(t+1)}=\\beta_i^{(t)}$</p>\n<p><strong></strong> $\\overline {\\boldsymbol \\alpha}=\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}$</p>\n<p> $\\boldsymbol \\alpha$  $\\mathbf w$</p>\n<script type=\"math/tex; mode=display\">\\overline {\\mathbf w}=\\sum_{i=1}^m \\overline {\\boldsymbol \\alpha}\\psi(\\mathbf x_i)</script><p> $\\overline {\\boldsymbol \\alpha}$ </p>\n<script type=\"math/tex; mode=display\">\\overline {\\mathbf w}=\\sum_{i=1}^m \\left(\\frac 1 T \\sum_{t=1}^T \\boldsymbol \\alpha^{(t)}\\right)\\psi(\\mathbf x_i)=\\frac 1 T \\sum_{t=1}^T\\left(\\sum_{i=1}^m \\boldsymbol \\alpha^{(t)}\\psi(\\mathbf x_i)\\right)=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}</script><p> Soft-SVM </p>"},{"title":"","date":"2021-09-17T06:01:41.000Z","p":"ml/linear","mathjax":true,"_content":"\n\n<!--more-->\n\n# \n## \nhypothesis\n\n$$\\mathcal H = L_d=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}$$\n\n\n\n$$l(h,(\\mathbf x, y))=(h(\\mathbf x) - y)^2$$\n\n $m$ \n\n$$L_S(h)=\\frac 1 m \\sum_{i=1}^m (h(\\mathbf x_i) - y_i)^2$$\n\n## ERM\n\n ERM 0\n\n$$\\sum_{i=1}^m (\\mathbf w^{\\top} \\mathbf x_i - y_i)\\mathbf x_i = \\mathbf 0 \\Rightarrow \\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf w)\\mathbf x_i=\\sum_{i=0}^m y_i \\mathbf x_i$$\n\n $A \\mathbf w=\\mathbf b$ \n\n$$A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right), \\quad \\mathbf b = \\sum_{i=0}^m y_i \\mathbf x_i$$\n\n $(\\mathbf x^{\\top} \\mathbf w)\\mathbf x=\\mathbf x(\\mathbf x^{\\top} \\mathbf w)=(\\mathbf {x x}^{\\top}) \\mathbf w$ \n\n### A \n $A$  ERM \n\n$$\\mathbf w = A^{-1} \\mathbf b$$\n\n $A$ \n\n---\n**span $\\mathbb R^d$ $A$ **\n\n\n\n\n____\n\n $\\forall \\ \\mathbf v \\in \\mathbb R^d$\n\n$$A \\mathbf v=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)\\mathbf v=\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\mathbf v=\\sum_{i=1}^m\\mathbf x_i (\\mathbf x_i^{\\top} \\mathbf v)=\\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf v)\\mathbf x_i$$\n\n\n $\\mathbb R^d$  $d$  $d$ $\\mathbf x_1, \\cdots, \\mathbf x_d$ $d$  $\\mathbf x_j=\\sum_{i=1}^d c_{ji} \\mathbf x_i$ $\\mathbf x_i^{\\top} \\mathbf v=p_i, \\ \\forall i \\in [m]$\n\n$$\\begin{aligned}A \\mathbf v&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{j=d+1}^m \\sum_{k=1}^d p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{k=1}^d\\sum_{j=d+1}^m  p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d \\left(p_i + \\sum_{j=d+1}^m p_j c_{ji}\\right)\\mathbf x_i\n\\\\&=\\sum_{i=1}^d q_i \\mathbf x_i\\end{aligned}$$\n\n$A$  $\\mathbf x_1, \\cdots, \\mathbf x_d$  $\\exists \\ \\mathbf v \\in \\mathbb R^d$ $\\forall i \\in [d], \\ q_i\\neq 0$ $A$  $q_i$  0 $A$ \n\n### A \n\n---\n $A$ $b$  $A$ \n\n____\n\n$A$  $A=VDV^{\\top}$ $D$ $V$  $V$  $V^{\\top}V=I_{d\\times d}$ $D^+$\n\n$$D_{ii}^+=\\begin{cases}  1 /D_{ii} & D_{ii} \\neq 0 \\\\ 0 & D_{ii}=0\\end{cases}$$\n\n$$A^+=VD^+V^{\\top}, \\quad \\hat {\\mathbf w}=A^+b$$\n\n $V$ \n\n$$V=[\\mathbf v_1, \\cdots, \\mathbf v_d]$$\n\n\n\n$$\\begin{aligned}A\\hat {\\mathbf w}&=AA^+ \\mathbf b\n\\\\&=VDV^{\\top}VD^+V^{\\top}\\mathbf b\n\\\\&=VDD^+V^{\\top}\\mathbf b\n\\\\&=\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top} \\mathbf b\n\\\\&= \\overline A \\ \\mathbf b\n\n\\\\&=\\sum_{i:D_{ii}\\neq 0}( \\mathbf v_i^{\\top} \\mathbf b) \\mathbf v_i\n\\\\&= \\sum_{i=1}^d q_i \\mathbf v_i\n\\end{aligned}$$\n\n \n\n$$q_i=\\begin{cases} \\mathbf v_i^{\\top} \\mathbf b & D_{ii}\\neq 0 \\\\ 0 & D_{ii} = 0 \\end{cases}$$\n\n $A$  $A$  $\\mathbf b$  $\\overline A$  $D_{ii} \\neq 0$  $\\mathbf v_i$ span\n\n$$A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)=[\\mathbf v_1, \\cdots, \\mathbf v_d]D[\\mathbf v_1^{\\top}, \\cdots, \\mathbf v_d^{\\top}]^{\\top}=\\sum_{i:D_{ii} \\neq 0} \\mathbf v_i\\mathbf v_i^{\\top}$$\n\n $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$  $\\mathbf b = \\sum_{i=1}^m y_i \\mathbf x_i$  $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$   $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$ **** $(\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top})\\mathbf b=\\mathbf b$\n\n$$A \\hat{\\mathbf w}=\\mathbf b$$\n\n $\\hat {\\mathbf w}=A^+b$ \n\n\n\n $A$  `scipy` ","source":"_posts/ml/linear.md","raw":"---\ntitle: \ndate: 2021-09-17 14:01:41\ntags: machine learning\np: ml/linear\nmathjax: true\n---\n\n\n<!--more-->\n\n# \n## \nhypothesis\n\n$$\\mathcal H = L_d=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}$$\n\n\n\n$$l(h,(\\mathbf x, y))=(h(\\mathbf x) - y)^2$$\n\n $m$ \n\n$$L_S(h)=\\frac 1 m \\sum_{i=1}^m (h(\\mathbf x_i) - y_i)^2$$\n\n## ERM\n\n ERM 0\n\n$$\\sum_{i=1}^m (\\mathbf w^{\\top} \\mathbf x_i - y_i)\\mathbf x_i = \\mathbf 0 \\Rightarrow \\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf w)\\mathbf x_i=\\sum_{i=0}^m y_i \\mathbf x_i$$\n\n $A \\mathbf w=\\mathbf b$ \n\n$$A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right), \\quad \\mathbf b = \\sum_{i=0}^m y_i \\mathbf x_i$$\n\n $(\\mathbf x^{\\top} \\mathbf w)\\mathbf x=\\mathbf x(\\mathbf x^{\\top} \\mathbf w)=(\\mathbf {x x}^{\\top}) \\mathbf w$ \n\n### A \n $A$  ERM \n\n$$\\mathbf w = A^{-1} \\mathbf b$$\n\n $A$ \n\n---\n**span $\\mathbb R^d$ $A$ **\n\n\n\n\n____\n\n $\\forall \\ \\mathbf v \\in \\mathbb R^d$\n\n$$A \\mathbf v=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)\\mathbf v=\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\mathbf v=\\sum_{i=1}^m\\mathbf x_i (\\mathbf x_i^{\\top} \\mathbf v)=\\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf v)\\mathbf x_i$$\n\n\n $\\mathbb R^d$  $d$  $d$ $\\mathbf x_1, \\cdots, \\mathbf x_d$ $d$  $\\mathbf x_j=\\sum_{i=1}^d c_{ji} \\mathbf x_i$ $\\mathbf x_i^{\\top} \\mathbf v=p_i, \\ \\forall i \\in [m]$\n\n$$\\begin{aligned}A \\mathbf v&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{j=d+1}^m \\sum_{k=1}^d p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{k=1}^d\\sum_{j=d+1}^m  p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d \\left(p_i + \\sum_{j=d+1}^m p_j c_{ji}\\right)\\mathbf x_i\n\\\\&=\\sum_{i=1}^d q_i \\mathbf x_i\\end{aligned}$$\n\n$A$  $\\mathbf x_1, \\cdots, \\mathbf x_d$  $\\exists \\ \\mathbf v \\in \\mathbb R^d$ $\\forall i \\in [d], \\ q_i\\neq 0$ $A$  $q_i$  0 $A$ \n\n### A \n\n---\n $A$ $b$  $A$ \n\n____\n\n$A$  $A=VDV^{\\top}$ $D$ $V$  $V$  $V^{\\top}V=I_{d\\times d}$ $D^+$\n\n$$D_{ii}^+=\\begin{cases}  1 /D_{ii} & D_{ii} \\neq 0 \\\\ 0 & D_{ii}=0\\end{cases}$$\n\n$$A^+=VD^+V^{\\top}, \\quad \\hat {\\mathbf w}=A^+b$$\n\n $V$ \n\n$$V=[\\mathbf v_1, \\cdots, \\mathbf v_d]$$\n\n\n\n$$\\begin{aligned}A\\hat {\\mathbf w}&=AA^+ \\mathbf b\n\\\\&=VDV^{\\top}VD^+V^{\\top}\\mathbf b\n\\\\&=VDD^+V^{\\top}\\mathbf b\n\\\\&=\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top} \\mathbf b\n\\\\&= \\overline A \\ \\mathbf b\n\n\\\\&=\\sum_{i:D_{ii}\\neq 0}( \\mathbf v_i^{\\top} \\mathbf b) \\mathbf v_i\n\\\\&= \\sum_{i=1}^d q_i \\mathbf v_i\n\\end{aligned}$$\n\n \n\n$$q_i=\\begin{cases} \\mathbf v_i^{\\top} \\mathbf b & D_{ii}\\neq 0 \\\\ 0 & D_{ii} = 0 \\end{cases}$$\n\n $A$  $A$  $\\mathbf b$  $\\overline A$  $D_{ii} \\neq 0$  $\\mathbf v_i$ span\n\n$$A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)=[\\mathbf v_1, \\cdots, \\mathbf v_d]D[\\mathbf v_1^{\\top}, \\cdots, \\mathbf v_d^{\\top}]^{\\top}=\\sum_{i:D_{ii} \\neq 0} \\mathbf v_i\\mathbf v_i^{\\top}$$\n\n $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$  $\\mathbf b = \\sum_{i=1}^m y_i \\mathbf x_i$  $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$   $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$ **** $(\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top})\\mathbf b=\\mathbf b$\n\n$$A \\hat{\\mathbf w}=\\mathbf b$$\n\n $\\hat {\\mathbf w}=A^+b$ \n\n\n\n $A$  `scipy` ","slug":"ml/linear","published":1,"updated":"2021-09-24T10:27:00.353Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or916002np0dj6qla6qfn","content":"<p><br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>hypothesis</p>\n<script type=\"math/tex; mode=display\">\\mathcal H = L_d=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}</script><p></p>\n<script type=\"math/tex; mode=display\">l(h,(\\mathbf x, y))=(h(\\mathbf x) - y)^2</script><p> $m$ </p>\n<script type=\"math/tex; mode=display\">L_S(h)=\\frac 1 m \\sum_{i=1}^m (h(\\mathbf x_i) - y_i)^2</script><h2 id=\"ERM\"><a href=\"#ERM\" class=\"headerlink\" title=\"ERM\"></a>ERM</h2><p> ERM 0</p>\n<script type=\"math/tex; mode=display\">\\sum_{i=1}^m (\\mathbf w^{\\top} \\mathbf x_i - y_i)\\mathbf x_i = \\mathbf 0 \\Rightarrow \\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf w)\\mathbf x_i=\\sum_{i=0}^m y_i \\mathbf x_i</script><p> $A \\mathbf w=\\mathbf b$ </p>\n<script type=\"math/tex; mode=display\">A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right), \\quad \\mathbf b = \\sum_{i=0}^m y_i \\mathbf x_i</script><p> $(\\mathbf x^{\\top} \\mathbf w)\\mathbf x=\\mathbf x(\\mathbf x^{\\top} \\mathbf w)=(\\mathbf {x x}^{\\top}) \\mathbf w$ </p>\n<h3 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A \"></a>A </h3><p> $A$  ERM </p>\n<script type=\"math/tex; mode=display\">\\mathbf w = A^{-1} \\mathbf b</script><p> $A$ </p>\n<hr>\n<p><strong>span $\\mathbb R^d$ $A$ </strong></p>\n<p></p>\n<p><strong></strong></p>\n<p> $\\forall \\ \\mathbf v \\in \\mathbb R^d$</p>\n<script type=\"math/tex; mode=display\">A \\mathbf v=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)\\mathbf v=\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\mathbf v=\\sum_{i=1}^m\\mathbf x_i (\\mathbf x_i^{\\top} \\mathbf v)=\\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf v)\\mathbf x_i</script><p> $\\mathbb R^d$  $d$  $d$ $\\mathbf x_1, \\cdots, \\mathbf x_d$ $d$  $\\mathbf x_j=\\sum_{i=1}^d c_{ji} \\mathbf x_i$ $\\mathbf x_i^{\\top} \\mathbf v=p_i, \\ \\forall i \\in [m]$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}A \\mathbf v&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{j=d+1}^m \\sum_{k=1}^d p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{k=1}^d\\sum_{j=d+1}^m  p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d \\left(p_i + \\sum_{j=d+1}^m p_j c_{ji}\\right)\\mathbf x_i\n\\\\&=\\sum_{i=1}^d q_i \\mathbf x_i\\end{aligned}</script><p>$A$  $\\mathbf x_1, \\cdots, \\mathbf x_d$  $\\exists \\ \\mathbf v \\in \\mathbb R^d$ $\\forall i \\in [d], \\ q_i\\neq 0$ $A$  $q_i$  0 $A$ </p>\n<h3 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A \"></a>A </h3><hr>\n<p> $A$ $b$  $A$ </p>\n<p><strong></strong></p>\n<p>$A$  $A=VDV^{\\top}$ $D$ $V$  $V$  $V^{\\top}V=I_{d\\times d}$ $D^+$</p>\n<script type=\"math/tex; mode=display\">D_{ii}^+=\\begin{cases}  1 /D_{ii} & D_{ii} \\neq 0 \\\\ 0 & D_{ii}=0\\end{cases}</script><script type=\"math/tex; mode=display\">A^+=VD^+V^{\\top}, \\quad \\hat {\\mathbf w}=A^+b</script><p> $V$ </p>\n<script type=\"math/tex; mode=display\">V=[\\mathbf v_1, \\cdots, \\mathbf v_d]</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}A\\hat {\\mathbf w}&=AA^+ \\mathbf b\n\\\\&=VDV^{\\top}VD^+V^{\\top}\\mathbf b\n\\\\&=VDD^+V^{\\top}\\mathbf b\n\\\\&=\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top} \\mathbf b\n\\\\&= \\overline A \\ \\mathbf b\n\n\\\\&=\\sum_{i:D_{ii}\\neq 0}( \\mathbf v_i^{\\top} \\mathbf b) \\mathbf v_i\n\\\\&= \\sum_{i=1}^d q_i \\mathbf v_i\n\\end{aligned}</script><p> </p>\n<script type=\"math/tex; mode=display\">q_i=\\begin{cases} \\mathbf v_i^{\\top} \\mathbf b & D_{ii}\\neq 0 \\\\ 0 & D_{ii} = 0 \\end{cases}</script><p> $A$  $A$  $\\mathbf b$  $\\overline A$  $D_{ii} \\neq 0$  $\\mathbf v_i$ span</p>\n<script type=\"math/tex; mode=display\">A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)=[\\mathbf v_1, \\cdots, \\mathbf v_d]D[\\mathbf v_1^{\\top}, \\cdots, \\mathbf v_d^{\\top}]^{\\top}=\\sum_{i:D_{ii} \\neq 0} \\mathbf v_i\\mathbf v_i^{\\top}</script><p> $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$  $\\mathbf b = \\sum_{i=1}^m y_i \\mathbf x_i$  $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$   $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$ <strong></strong> $(\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top})\\mathbf b=\\mathbf b$</p>\n<script type=\"math/tex; mode=display\">A \\hat{\\mathbf w}=\\mathbf b</script><p> $\\hat {\\mathbf w}=A^+b$ </p>\n<p> $A$  <code>scipy</code> </p>\n","site":{"data":{}},"excerpt":"<p><br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>hypothesis</p>\n<script type=\"math/tex; mode=display\">\\mathcal H = L_d=\\{\\langle \\mathbf w, \\mathbf x \\rangle+b: \\mathbf w \\in \\mathbb R^d, b \\in \\mathbb R\\}</script><p></p>\n<script type=\"math/tex; mode=display\">l(h,(\\mathbf x, y))=(h(\\mathbf x) - y)^2</script><p> $m$ </p>\n<script type=\"math/tex; mode=display\">L_S(h)=\\frac 1 m \\sum_{i=1}^m (h(\\mathbf x_i) - y_i)^2</script><h2 id=\"ERM\"><a href=\"#ERM\" class=\"headerlink\" title=\"ERM\"></a>ERM</h2><p> ERM 0</p>\n<script type=\"math/tex; mode=display\">\\sum_{i=1}^m (\\mathbf w^{\\top} \\mathbf x_i - y_i)\\mathbf x_i = \\mathbf 0 \\Rightarrow \\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf w)\\mathbf x_i=\\sum_{i=0}^m y_i \\mathbf x_i</script><p> $A \\mathbf w=\\mathbf b$ </p>\n<script type=\"math/tex; mode=display\">A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right), \\quad \\mathbf b = \\sum_{i=0}^m y_i \\mathbf x_i</script><p> $(\\mathbf x^{\\top} \\mathbf w)\\mathbf x=\\mathbf x(\\mathbf x^{\\top} \\mathbf w)=(\\mathbf {x x}^{\\top}) \\mathbf w$ </p>\n<h3 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A \"></a>A </h3><p> $A$  ERM </p>\n<script type=\"math/tex; mode=display\">\\mathbf w = A^{-1} \\mathbf b</script><p> $A$ </p>\n<hr>\n<p><strong>span $\\mathbb R^d$ $A$ </strong></p>\n<p></p>\n<p><strong></strong></p>\n<p> $\\forall \\ \\mathbf v \\in \\mathbb R^d$</p>\n<script type=\"math/tex; mode=display\">A \\mathbf v=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)\\mathbf v=\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\mathbf v=\\sum_{i=1}^m\\mathbf x_i (\\mathbf x_i^{\\top} \\mathbf v)=\\sum_{i=1}^m(\\mathbf x_i^{\\top} \\mathbf v)\\mathbf x_i</script><p> $\\mathbb R^d$  $d$  $d$ $\\mathbf x_1, \\cdots, \\mathbf x_d$ $d$  $\\mathbf x_j=\\sum_{i=1}^d c_{ji} \\mathbf x_i$ $\\mathbf x_i^{\\top} \\mathbf v=p_i, \\ \\forall i \\in [m]$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}A \\mathbf v&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{j=d+1}^m \\sum_{k=1}^d p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d p_i\\mathbf x_i + \\sum_{k=1}^d\\sum_{j=d+1}^m  p_j c_{jk} \\mathbf x_k\n\\\\&=\\sum_{i=1}^d \\left(p_i + \\sum_{j=d+1}^m p_j c_{ji}\\right)\\mathbf x_i\n\\\\&=\\sum_{i=1}^d q_i \\mathbf x_i\\end{aligned}</script><p>$A$  $\\mathbf x_1, \\cdots, \\mathbf x_d$  $\\exists \\ \\mathbf v \\in \\mathbb R^d$ $\\forall i \\in [d], \\ q_i\\neq 0$ $A$  $q_i$  0 $A$ </p>\n<h3 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A \"></a>A </h3><hr>\n<p> $A$ $b$  $A$ </p>\n<p><strong></strong></p>\n<p>$A$  $A=VDV^{\\top}$ $D$ $V$  $V$  $V^{\\top}V=I_{d\\times d}$ $D^+$</p>\n<script type=\"math/tex; mode=display\">D_{ii}^+=\\begin{cases}  1 /D_{ii} & D_{ii} \\neq 0 \\\\ 0 & D_{ii}=0\\end{cases}</script><script type=\"math/tex; mode=display\">A^+=VD^+V^{\\top}, \\quad \\hat {\\mathbf w}=A^+b</script><p> $V$ </p>\n<script type=\"math/tex; mode=display\">V=[\\mathbf v_1, \\cdots, \\mathbf v_d]</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}A\\hat {\\mathbf w}&=AA^+ \\mathbf b\n\\\\&=VDV^{\\top}VD^+V^{\\top}\\mathbf b\n\\\\&=VDD^+V^{\\top}\\mathbf b\n\\\\&=\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top} \\mathbf b\n\\\\&= \\overline A \\ \\mathbf b\n\n\\\\&=\\sum_{i:D_{ii}\\neq 0}( \\mathbf v_i^{\\top} \\mathbf b) \\mathbf v_i\n\\\\&= \\sum_{i=1}^d q_i \\mathbf v_i\n\\end{aligned}</script><p> </p>\n<script type=\"math/tex; mode=display\">q_i=\\begin{cases} \\mathbf v_i^{\\top} \\mathbf b & D_{ii}\\neq 0 \\\\ 0 & D_{ii} = 0 \\end{cases}</script><p> $A$  $A$  $\\mathbf b$  $\\overline A$  $D_{ii} \\neq 0$  $\\mathbf v_i$ span</p>\n<script type=\"math/tex; mode=display\">A=\\left(\\sum_{i=1}^m\\mathbf x_i \\mathbf x_i^{\\top} \\right)=[\\mathbf v_1, \\cdots, \\mathbf v_d]D[\\mathbf v_1^{\\top}, \\cdots, \\mathbf v_d^{\\top}]^{\\top}=\\sum_{i:D_{ii} \\neq 0} \\mathbf v_i\\mathbf v_i^{\\top}</script><p> $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$  $\\mathbf b = \\sum_{i=1}^m y_i \\mathbf x_i$  $\\mathbf x_1, \\cdots , \\mathbf x_m$  $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$   $\\{\\mathbf v_i: D_{ii} \\neq 0\\}$ <strong></strong> $(\\sum_{i:D_{ii}\\neq 0} \\mathbf v_i \\mathbf v_i^{\\top})\\mathbf b=\\mathbf b$</p>\n<script type=\"math/tex; mode=display\">A \\hat{\\mathbf w}=\\mathbf b</script><p> $\\hat {\\mathbf w}=A^+b$ </p>\n<p> $A$  <code>scipy</code> </p>"},{"title":"","date":"2021-09-29T09:58:26.000Z","mathjax":true,"p":"ml/multiclass_algo","_content":"\n Perception  $0-1$ $0-1$ convex surrogate\n<!--more-->\n\n# \n\n\n1. \n2.  upper bound \n\n hinge  $0-1$ \n\n$$l^{0-1}(\\mathbf w, (\\mathbf x, y))=\\mathbb I_{y\\neq \\text{sign}(\\langle \\mathbf w, \\mathbf x\\rangle)}=\\mathbb I_{y \\langle \\mathbf w, \\mathbf x\\rangle \\le 0}$$\n\n$$l^{hinge}(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}$$\n\n $\\forall \\ y \\langle \\mathbf w, \\mathbf x\\rangle \\in \\mathbb R, \\ l^{hinge}(\\mathbf w, (\\mathbf x, y)) \\ge l^{0-1}(\\mathbf w, (\\mathbf x, y))$\n\n#  Hinge \n\n Hinge  [](/2021/09/22/ml/multiclass)\n\n$$h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg}\\max_{y' \\in \\mathcal Y} \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle \\tag{1}$$\n\n$h_{\\mathbf w}(\\mathbf x)$    $\\mathbf w$ \n\n$$\\langle \\mathbf w, \\Psi(\\mathbf x, y)\\rangle \\le \\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))\\rangle$$\n\n $y$  $\\mathbf w$ \n\n $\\Delta(h_{\\mathbf w}(\\mathbf x), y)$ $y$ $h_{\\mathbf w}(\\mathbf x)$  $0-1$ \n\n$$\\Delta(h_{\\mathbf w}(\\mathbf x), y) \\le \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle$$\n\n $h_{\\mathbf w}(\\mathbf x) \\in \\mathcal Y$ upper bound \n\n$$\\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\stackrel{def}=  l(\\mathbf w, (\\mathbf x, y)) \\tag{*} \\label{\\star}$$\n\n $l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle\\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)$\n\n$$h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg} \\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\tag{2}$$\n\n \n\n$$h_{\\mathbf w}(\\mathbf x)=y \\tag{3}$$\n\n,  (3)  (2)  \n\n$$\\Delta(y, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y)\\rangle \\ge \\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle, \\ \\forall y' \\in \\mathcal Y \\setminus \\{y\\}$$\n\n $\\Delta(y,y)=0$\n\n$$\\langle \\mathbf w,\\Psi(\\mathbf x, y)\\rangle \\ge \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle+\\Delta(y', y) \\tag{4}$$\n\n (4) \n\n$$l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y) \\tag{5}$$\n\n(5)  (4) (5) \n\n$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  ** 1** **$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz **\n\n\n$\\eqref{\\star}$  $l(\\mathbf w, (\\mathbf x, y))$  hinge  $\\Delta$  $0-1$  $\\mathcal Y = \\{\\pm 1\\}$  $\\Psi(\\mathbf x, y)=y\\mathbf x/2$ hinge  hinge \n\n$$l(\\mathbf w, (\\mathbf x, y))=\\max_{y'\\in \\{y, -y\\}} \\Delta(y', y)+\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle$$\n\n $y'=y$  $\\Delta(y', y)=0$$\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle=0$\n\n $y'=-y$ $\\Delta(y', y)=1$$\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle=-y \\langle \\mathbf w, \\mathbf x\\rangle$\n\n $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}$ [](/2021/09/22/ml/multiclass) \n\n $\\mathcal Y=\\{1, 2\\}$   hinge  [](/2021/09/22/ml/multiclass)  $\\Psi(\\mathbf x, y)$  $\\mathbf w$ \n\n$$\\mathbf w'=\\begin{bmatrix} \\mathbf w \\\\\\\\ -\\mathbf w \\end{bmatrix}\n\n\\\\\\\\\\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}=\\begin{bmatrix} \\mathbf x \\\\\\\\ \\mathbf 0 \\end{bmatrix}\n\\\\\\\\\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}=\\begin{bmatrix} \\mathbf 0 \\\\\\\\ \\mathbf x \\end{bmatrix}\n\\\\\\\\h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w'^{\\top} \\Psi(\\mathbf x, y)$$\n\n $\\eqref{\\star}$ \n\n$$l(\\mathbf w, (\\mathbf x, y))=\\max_{y' \\in \\{1,2\\}} \\Delta(y', y)+\\mathbf w'^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))$$\n\n1.  $y'=y$\n\n $\\Delta(y', y)+\\mathbf w'^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))=0$\n\n2.  $y' \\neq y$ $\\Delta(y', y)=1$\n\n $y'=1, y=2$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))=2\\mathbf w^{\\top}\\mathbf x$\n\n $y'=2, y=1$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))=-2\\mathbf w^{\\top}\\mathbf x$\n\n $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-(-1)^{y-1}2 \\mathbf w^{\\top}\\mathbf x\\}$  \n\n# \n\n $\\mathbf w, \\ \\mathbf x \\in \\mathbb R^n$  $\\mathbf w, \\ \\Psi(\\mathbf x, y) \\in \\mathbb R^{nk}$  SGD \n\n$$L=l(\\mathbf w, (\\mathbf x, y))+ \\frac {\\lambda} 2 \\Vert \\mathbf w \\Vert^2$$\n\n\n# Appendix\n**1. 1**\n\n $i=1,\\cdots, r$ $f_i: \\mathbb R^d \\rightarrow \\mathbb R$  $g(x)=\\max_{i \\in [r]} f_i(x)$ \n\n\n\n$$\\begin{aligned} g(\\alpha u +(1-\\alpha)v) &= \\max_i f_i(\\alpha u + (1-\\alpha)v)\n\\\\\\\\ & \\le \\max_i [\\alpha f_i(u)+(1-\\alpha)f_i(v)]\n\\\\\\\\ &=\\alpha \\max_i f_i(u) + (1-\\alpha) \\max_i f_i(v)\n\\\\\\\\ &=\\alpha g(u) + (1-\\alpha) g(v)\n\\end{aligned}$$\n\n$\\alpha \\in (0,1)$\n\n**2. $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz **\n\n $\\mathbf w_1, \\mathbf w_2$ $y_i=\\arg_{y'} \\ l(\\mathbf w_i, (\\mathbf x, y))$ $i$  $1,2,\\cdots , k$ $\\mathbf w_i$ \n\n $\\mathbf w_1$ $y_1$  $(\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle)$  $(\\Delta(y_1, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)>(\\Delta(y_2, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)$\n\n $l(\\mathbf w_1, (\\mathbf x, y)) \\ge l(\\mathbf w_2, (\\mathbf x, y))\\ge 0$\n\n$$\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}$$\n\n $l(\\mathbf w_2, (\\mathbf x, y)) \\ge l(\\mathbf w_1, (\\mathbf x, y)) \\ge 0$\n\n$$\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}$$\n\n$\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\\le \\rho \\|\\mathbf w_1 - \\mathbf w_2\\|$ \n\n$$\\rho=\\max_{y' \\in \\mathcal Y} \\|\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\|$$\n","source":"_posts/ml/multiclass_algo.md","raw":"---\ntitle: \ndate: 2021-09-29 17:58:26\ntags: machine learning\nmathjax: true\np: ml/multiclass_algo\n---\n\n Perception  $0-1$ $0-1$ convex surrogate\n<!--more-->\n\n# \n\n\n1. \n2.  upper bound \n\n hinge  $0-1$ \n\n$$l^{0-1}(\\mathbf w, (\\mathbf x, y))=\\mathbb I_{y\\neq \\text{sign}(\\langle \\mathbf w, \\mathbf x\\rangle)}=\\mathbb I_{y \\langle \\mathbf w, \\mathbf x\\rangle \\le 0}$$\n\n$$l^{hinge}(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}$$\n\n $\\forall \\ y \\langle \\mathbf w, \\mathbf x\\rangle \\in \\mathbb R, \\ l^{hinge}(\\mathbf w, (\\mathbf x, y)) \\ge l^{0-1}(\\mathbf w, (\\mathbf x, y))$\n\n#  Hinge \n\n Hinge  [](/2021/09/22/ml/multiclass)\n\n$$h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg}\\max_{y' \\in \\mathcal Y} \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle \\tag{1}$$\n\n$h_{\\mathbf w}(\\mathbf x)$    $\\mathbf w$ \n\n$$\\langle \\mathbf w, \\Psi(\\mathbf x, y)\\rangle \\le \\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))\\rangle$$\n\n $y$  $\\mathbf w$ \n\n $\\Delta(h_{\\mathbf w}(\\mathbf x), y)$ $y$ $h_{\\mathbf w}(\\mathbf x)$  $0-1$ \n\n$$\\Delta(h_{\\mathbf w}(\\mathbf x), y) \\le \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle$$\n\n $h_{\\mathbf w}(\\mathbf x) \\in \\mathcal Y$ upper bound \n\n$$\\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\stackrel{def}=  l(\\mathbf w, (\\mathbf x, y)) \\tag{*} \\label{\\star}$$\n\n $l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle\\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)$\n\n$$h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg} \\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\tag{2}$$\n\n \n\n$$h_{\\mathbf w}(\\mathbf x)=y \\tag{3}$$\n\n,  (3)  (2)  \n\n$$\\Delta(y, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y)\\rangle \\ge \\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle, \\ \\forall y' \\in \\mathcal Y \\setminus \\{y\\}$$\n\n $\\Delta(y,y)=0$\n\n$$\\langle \\mathbf w,\\Psi(\\mathbf x, y)\\rangle \\ge \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle+\\Delta(y', y) \\tag{4}$$\n\n (4) \n\n$$l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y) \\tag{5}$$\n\n(5)  (4) (5) \n\n$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  ** 1** **$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz **\n\n\n$\\eqref{\\star}$  $l(\\mathbf w, (\\mathbf x, y))$  hinge  $\\Delta$  $0-1$  $\\mathcal Y = \\{\\pm 1\\}$  $\\Psi(\\mathbf x, y)=y\\mathbf x/2$ hinge  hinge \n\n$$l(\\mathbf w, (\\mathbf x, y))=\\max_{y'\\in \\{y, -y\\}} \\Delta(y', y)+\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle$$\n\n $y'=y$  $\\Delta(y', y)=0$$\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle=0$\n\n $y'=-y$ $\\Delta(y', y)=1$$\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle=-y \\langle \\mathbf w, \\mathbf x\\rangle$\n\n $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}$ [](/2021/09/22/ml/multiclass) \n\n $\\mathcal Y=\\{1, 2\\}$   hinge  [](/2021/09/22/ml/multiclass)  $\\Psi(\\mathbf x, y)$  $\\mathbf w$ \n\n$$\\mathbf w'=\\begin{bmatrix} \\mathbf w \\\\\\\\ -\\mathbf w \\end{bmatrix}\n\n\\\\\\\\\\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}=\\begin{bmatrix} \\mathbf x \\\\\\\\ \\mathbf 0 \\end{bmatrix}\n\\\\\\\\\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}=\\begin{bmatrix} \\mathbf 0 \\\\\\\\ \\mathbf x \\end{bmatrix}\n\\\\\\\\h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w'^{\\top} \\Psi(\\mathbf x, y)$$\n\n $\\eqref{\\star}$ \n\n$$l(\\mathbf w, (\\mathbf x, y))=\\max_{y' \\in \\{1,2\\}} \\Delta(y', y)+\\mathbf w'^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))$$\n\n1.  $y'=y$\n\n $\\Delta(y', y)+\\mathbf w'^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))=0$\n\n2.  $y' \\neq y$ $\\Delta(y', y)=1$\n\n $y'=1, y=2$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))=2\\mathbf w^{\\top}\\mathbf x$\n\n $y'=2, y=1$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))=-2\\mathbf w^{\\top}\\mathbf x$\n\n $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-(-1)^{y-1}2 \\mathbf w^{\\top}\\mathbf x\\}$  \n\n# \n\n $\\mathbf w, \\ \\mathbf x \\in \\mathbb R^n$  $\\mathbf w, \\ \\Psi(\\mathbf x, y) \\in \\mathbb R^{nk}$  SGD \n\n$$L=l(\\mathbf w, (\\mathbf x, y))+ \\frac {\\lambda} 2 \\Vert \\mathbf w \\Vert^2$$\n\n\n# Appendix\n**1. 1**\n\n $i=1,\\cdots, r$ $f_i: \\mathbb R^d \\rightarrow \\mathbb R$  $g(x)=\\max_{i \\in [r]} f_i(x)$ \n\n\n\n$$\\begin{aligned} g(\\alpha u +(1-\\alpha)v) &= \\max_i f_i(\\alpha u + (1-\\alpha)v)\n\\\\\\\\ & \\le \\max_i [\\alpha f_i(u)+(1-\\alpha)f_i(v)]\n\\\\\\\\ &=\\alpha \\max_i f_i(u) + (1-\\alpha) \\max_i f_i(v)\n\\\\\\\\ &=\\alpha g(u) + (1-\\alpha) g(v)\n\\end{aligned}$$\n\n$\\alpha \\in (0,1)$\n\n**2. $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz **\n\n $\\mathbf w_1, \\mathbf w_2$ $y_i=\\arg_{y'} \\ l(\\mathbf w_i, (\\mathbf x, y))$ $i$  $1,2,\\cdots , k$ $\\mathbf w_i$ \n\n $\\mathbf w_1$ $y_1$  $(\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle)$  $(\\Delta(y_1, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)>(\\Delta(y_2, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)$\n\n $l(\\mathbf w_1, (\\mathbf x, y)) \\ge l(\\mathbf w_2, (\\mathbf x, y))\\ge 0$\n\n$$\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}$$\n\n $l(\\mathbf w_2, (\\mathbf x, y)) \\ge l(\\mathbf w_1, (\\mathbf x, y)) \\ge 0$\n\n$$\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}$$\n\n$\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\\le \\rho \\|\\mathbf w_1 - \\mathbf w_2\\|$ \n\n$$\\rho=\\max_{y' \\in \\mathcal Y} \\|\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\|$$\n","slug":"ml/multiclass_algo","published":1,"updated":"2021-09-30T08:20:12.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or917002pp0djeu0r7613","content":"<p> Perception  $0-1$ $0-1$ convex surrogate<br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li></li>\n<li> upper bound </li>\n</ol>\n<p> hinge  $0-1$ </p>\n<script type=\"math/tex; mode=display\">l^{0-1}(\\mathbf w, (\\mathbf x, y))=\\mathbb I_{y\\neq \\text{sign}(\\langle \\mathbf w, \\mathbf x\\rangle)}=\\mathbb I_{y \\langle \\mathbf w, \\mathbf x\\rangle \\le 0}</script><script type=\"math/tex; mode=display\">l^{hinge}(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}</script><p> $\\forall \\ y \\langle \\mathbf w, \\mathbf x\\rangle \\in \\mathbb R, \\ l^{hinge}(\\mathbf w, (\\mathbf x, y)) \\ge l^{0-1}(\\mathbf w, (\\mathbf x, y))$</p>\n<h1 id=\"-Hinge-\"><a href=\"#-Hinge-\" class=\"headerlink\" title=\" Hinge \"></a> Hinge </h1><p> Hinge  <a href=\"/2021/09/22/ml/multiclass\"></a></p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg}\\max_{y' \\in \\mathcal Y} \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle \\tag{1}</script><p>$h_{\\mathbf w}(\\mathbf x)$    $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w, \\Psi(\\mathbf x, y)\\rangle \\le \\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))\\rangle</script><p> $y$  $\\mathbf w$ </p>\n<p> $\\Delta(h_{\\mathbf w}(\\mathbf x), y)$ $y$ $h_{\\mathbf w}(\\mathbf x)$  $0-1$ </p>\n<script type=\"math/tex; mode=display\">\\Delta(h_{\\mathbf w}(\\mathbf x), y) \\le \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle</script><p> $h_{\\mathbf w}(\\mathbf x) \\in \\mathcal Y$ upper bound </p>\n<script type=\"math/tex; mode=display\">\\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\stackrel{def}=  l(\\mathbf w, (\\mathbf x, y)) \\tag{*} \\label{\\star}</script><p> $l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle\\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)$</p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg} \\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\tag{2}</script><p> </p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w}(\\mathbf x)=y \\tag{3}</script><p>,  (3)  (2)  </p>\n<script type=\"math/tex; mode=display\">\\Delta(y, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y)\\rangle \\ge \\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle, \\ \\forall y' \\in \\mathcal Y \\setminus \\{y\\}</script><p> $\\Delta(y,y)=0$</p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w,\\Psi(\\mathbf x, y)\\rangle \\ge \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle+\\Delta(y', y) \\tag{4}</script><p> (4) </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y) \\tag{5}</script><p>(5)  (4) (5) </p>\n<p>$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  <strong> 1</strong> <strong>$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz </strong></p>\n<p>$\\eqref{\\star}$  $l(\\mathbf w, (\\mathbf x, y))$  hinge  $\\Delta$  $0-1$  $\\mathcal Y = \\{\\pm 1\\}$  $\\Psi(\\mathbf x, y)=y\\mathbf x/2$ hinge  hinge </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, (\\mathbf x, y))=\\max_{y'\\in \\{y, -y\\}} \\Delta(y', y)+\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle</script><p> $y=y$  $\\Delta(y, y)=0$$\\langle \\mathbf w, (y-y)\\mathbf x/2 \\rangle=0$</p>\n<p> $y=-y$ $\\Delta(y, y)=1$$\\langle \\mathbf w, (y-y)\\mathbf x/2 \\rangle=-y \\langle \\mathbf w, \\mathbf x\\rangle$</p>\n<p> $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}$ <a href=\"/2021/09/22/ml/multiclass\"></a> </p>\n<p> $\\mathcal Y=\\{1, 2\\}$   hinge  <a href=\"/2021/09/22/ml/multiclass\"></a>  $\\Psi(\\mathbf x, y)$  $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w'=\\begin{bmatrix} \\mathbf w \\\\\\\\ -\\mathbf w \\end{bmatrix}\n\n\\\\\\\\\\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}=\\begin{bmatrix} \\mathbf x \\\\\\\\ \\mathbf 0 \\end{bmatrix}\n\\\\\\\\\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}=\\begin{bmatrix} \\mathbf 0 \\\\\\\\ \\mathbf x \\end{bmatrix}\n\\\\\\\\h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w'^{\\top} \\Psi(\\mathbf x, y)</script><p> $\\eqref{\\star}$ </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, (\\mathbf x, y))=\\max_{y' \\in \\{1,2\\}} \\Delta(y', y)+\\mathbf w'^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))</script><ol>\n<li> $y=y$</li>\n</ol>\n<p> $\\Delta(y, y)+\\mathbf w^{\\top}(\\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y))=0$</p>\n<ol>\n<li> $y \\neq y$ $\\Delta(y, y)=1$</li>\n</ol>\n<p> $y=1, y=2$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y))=2\\mathbf w^{\\top}\\mathbf x$</p>\n<p> $y=2, y=1$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y))=-2\\mathbf w^{\\top}\\mathbf x$</p>\n<p> $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-(-1)^{y-1}2 \\mathbf w^{\\top}\\mathbf x\\}$  </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\mathbf w, \\ \\mathbf x \\in \\mathbb R^n$  $\\mathbf w, \\ \\Psi(\\mathbf x, y) \\in \\mathbb R^{nk}$  SGD </p>\n<script type=\"math/tex; mode=display\">L=l(\\mathbf w, (\\mathbf x, y))+ \\frac {\\lambda} 2 \\Vert \\mathbf w \\Vert^2</script><h1 id=\"Appendix\"><a href=\"#Appendix\" class=\"headerlink\" title=\"Appendix\"></a>Appendix</h1><p><strong>1. 1</strong></p>\n<p> $i=1,\\cdots, r$ $f_i: \\mathbb R^d \\rightarrow \\mathbb R$  $g(x)=\\max_{i \\in [r]} f_i(x)$ </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} g(\\alpha u +(1-\\alpha)v) &= \\max_i f_i(\\alpha u + (1-\\alpha)v)\n\\\\\\\\ & \\le \\max_i [\\alpha f_i(u)+(1-\\alpha)f_i(v)]\n\\\\\\\\ &=\\alpha \\max_i f_i(u) + (1-\\alpha) \\max_i f_i(v)\n\\\\\\\\ &=\\alpha g(u) + (1-\\alpha) g(v)\n\\end{aligned}</script><p>$\\alpha \\in (0,1)$</p>\n<p><strong>2. $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz </strong></p>\n<p> $\\mathbf w_1, \\mathbf w_2$ $y_i=\\arg_{y} \\ l(\\mathbf w_i, (\\mathbf x, y))$ $i$  $1,2,\\cdots , k$ $\\mathbf w_i$ </p>\n<p> $\\mathbf w_1$ $y_1$  $(\\Delta(y, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y)\\rangle)$  $(\\Delta(y_1, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)&gt;(\\Delta(y_2, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)$</p>\n<p> $l(\\mathbf w_1, (\\mathbf x, y)) \\ge l(\\mathbf w_2, (\\mathbf x, y))\\ge 0$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}</script><p> $l(\\mathbf w_2, (\\mathbf x, y)) \\ge l(\\mathbf w_1, (\\mathbf x, y)) \\ge 0$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}</script><p>$|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))|\\le \\rho |\\mathbf w_1 - \\mathbf w_2|$ </p>\n<script type=\"math/tex; mode=display\">\\rho=\\max_{y' \\in \\mathcal Y} \\|\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\|</script>","site":{"data":{}},"excerpt":"<p> Perception  $0-1$ $0-1$ convex surrogate<br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li></li>\n<li> upper bound </li>\n</ol>\n<p> hinge  $0-1$ </p>\n<script type=\"math/tex; mode=display\">l^{0-1}(\\mathbf w, (\\mathbf x, y))=\\mathbb I_{y\\neq \\text{sign}(\\langle \\mathbf w, \\mathbf x\\rangle)}=\\mathbb I_{y \\langle \\mathbf w, \\mathbf x\\rangle \\le 0}</script><script type=\"math/tex; mode=display\">l^{hinge}(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}</script><p> $\\forall \\ y \\langle \\mathbf w, \\mathbf x\\rangle \\in \\mathbb R, \\ l^{hinge}(\\mathbf w, (\\mathbf x, y)) \\ge l^{0-1}(\\mathbf w, (\\mathbf x, y))$</p>\n<h1 id=\"-Hinge-\"><a href=\"#-Hinge-\" class=\"headerlink\" title=\" Hinge \"></a> Hinge </h1><p> Hinge  <a href=\"/2021/09/22/ml/multiclass\"></a></p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg}\\max_{y' \\in \\mathcal Y} \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle \\tag{1}</script><p>$h_{\\mathbf w}(\\mathbf x)$    $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w, \\Psi(\\mathbf x, y)\\rangle \\le \\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))\\rangle</script><p> $y$  $\\mathbf w$ </p>\n<p> $\\Delta(h_{\\mathbf w}(\\mathbf x), y)$ $y$ $h_{\\mathbf w}(\\mathbf x)$  $0-1$ </p>\n<script type=\"math/tex; mode=display\">\\Delta(h_{\\mathbf w}(\\mathbf x), y) \\le \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle</script><p> $h_{\\mathbf w}(\\mathbf x) \\in \\mathcal Y$ upper bound </p>\n<script type=\"math/tex; mode=display\">\\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\stackrel{def}=  l(\\mathbf w, (\\mathbf x, y)) \\tag{*} \\label{\\star}</script><p> $l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)+\\langle \\mathbf w, \\Psi(\\mathbf x, h_{\\mathbf w}(\\mathbf x))-\\Psi(\\mathbf x, y)\\rangle\\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y)$</p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w}(\\mathbf x)=\\mathop{\\arg} \\max_{y' \\in \\mathcal Y} \\ (\\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle) \\tag{2}</script><p> </p>\n<script type=\"math/tex; mode=display\">h_{\\mathbf w}(\\mathbf x)=y \\tag{3}</script><p>,  (3)  (2)  </p>\n<script type=\"math/tex; mode=display\">\\Delta(y, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y)\\rangle \\ge \\Delta(y', y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\rangle, \\ \\forall y' \\in \\mathcal Y \\setminus \\{y\\}</script><p> $\\Delta(y,y)=0$</p>\n<script type=\"math/tex; mode=display\">\\langle \\mathbf w,\\Psi(\\mathbf x, y)\\rangle \\ge \\langle \\mathbf w, \\Psi(\\mathbf x, y')\\rangle+\\Delta(y', y) \\tag{4}</script><p> (4) </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, (\\mathbf x, y)) \\ge \\Delta(h_{\\mathbf w}(\\mathbf x), y) \\tag{5}</script><p>(5)  (4) (5) </p>\n<p>$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  <strong> 1</strong> <strong>$l(\\mathbf w, (\\mathbf x, y))$  $\\mathbf w$  $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz </strong></p>\n<p>$\\eqref{\\star}$  $l(\\mathbf w, (\\mathbf x, y))$  hinge  $\\Delta$  $0-1$  $\\mathcal Y = \\{\\pm 1\\}$  $\\Psi(\\mathbf x, y)=y\\mathbf x/2$ hinge  hinge </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, (\\mathbf x, y))=\\max_{y'\\in \\{y, -y\\}} \\Delta(y', y)+\\langle \\mathbf w, (y'-y)\\mathbf x/2 \\rangle</script><p> $y=y$  $\\Delta(y, y)=0$$\\langle \\mathbf w, (y-y)\\mathbf x/2 \\rangle=0$</p>\n<p> $y=-y$ $\\Delta(y, y)=1$$\\langle \\mathbf w, (y-y)\\mathbf x/2 \\rangle=-y \\langle \\mathbf w, \\mathbf x\\rangle$</p>\n<p> $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-y \\langle \\mathbf w, \\mathbf x\\rangle\\}$ <a href=\"/2021/09/22/ml/multiclass\"></a> </p>\n<p> $\\mathcal Y=\\{1, 2\\}$   hinge  <a href=\"/2021/09/22/ml/multiclass\"></a>  $\\Psi(\\mathbf x, y)$  $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w'=\\begin{bmatrix} \\mathbf w \\\\\\\\ -\\mathbf w \\end{bmatrix}\n\n\\\\\\\\\\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}=\\begin{bmatrix} \\mathbf x \\\\\\\\ \\mathbf 0 \\end{bmatrix}\n\\\\\\\\\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}=\\begin{bmatrix} \\mathbf 0 \\\\\\\\ \\mathbf x \\end{bmatrix}\n\\\\\\\\h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w'^{\\top} \\Psi(\\mathbf x, y)</script><p> $\\eqref{\\star}$ </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, (\\mathbf x, y))=\\max_{y' \\in \\{1,2\\}} \\Delta(y', y)+\\mathbf w'^{\\top}(\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y))</script><ol>\n<li> $y=y$</li>\n</ol>\n<p> $\\Delta(y, y)+\\mathbf w^{\\top}(\\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y))=0$</p>\n<ol>\n<li> $y \\neq y$ $\\Delta(y, y)=1$</li>\n</ol>\n<p> $y=1, y=2$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y))=2\\mathbf w^{\\top}\\mathbf x$</p>\n<p> $y=2, y=1$ $\\mathbf w^{\\top}(\\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y))=-2\\mathbf w^{\\top}\\mathbf x$</p>\n<p> $l(\\mathbf w, (\\mathbf x, y))=\\max \\{0, 1-(-1)^{y-1}2 \\mathbf w^{\\top}\\mathbf x\\}$  </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> $\\mathbf w, \\ \\mathbf x \\in \\mathbb R^n$  $\\mathbf w, \\ \\Psi(\\mathbf x, y) \\in \\mathbb R^{nk}$  SGD </p>\n<script type=\"math/tex; mode=display\">L=l(\\mathbf w, (\\mathbf x, y))+ \\frac {\\lambda} 2 \\Vert \\mathbf w \\Vert^2</script><h1 id=\"Appendix\"><a href=\"#Appendix\" class=\"headerlink\" title=\"Appendix\"></a>Appendix</h1><p><strong>1. 1</strong></p>\n<p> $i=1,\\cdots, r$ $f_i: \\mathbb R^d \\rightarrow \\mathbb R$  $g(x)=\\max_{i \\in [r]} f_i(x)$ </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} g(\\alpha u +(1-\\alpha)v) &= \\max_i f_i(\\alpha u + (1-\\alpha)v)\n\\\\\\\\ & \\le \\max_i [\\alpha f_i(u)+(1-\\alpha)f_i(v)]\n\\\\\\\\ &=\\alpha \\max_i f_i(u) + (1-\\alpha) \\max_i f_i(v)\n\\\\\\\\ &=\\alpha g(u) + (1-\\alpha) g(v)\n\\end{aligned}</script><p>$\\alpha \\in (0,1)$</p>\n<p><strong>2. $l(\\mathbf w, (\\mathbf x, y))$  $\\rho-$Lipschitz </strong></p>\n<p> $\\mathbf w_1, \\mathbf w_2$ $y_i=\\arg_{y} \\ l(\\mathbf w_i, (\\mathbf x, y))$ $i$  $1,2,\\cdots , k$ $\\mathbf w_i$ </p>\n<p> $\\mathbf w_1$ $y_1$  $(\\Delta(y, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y)-\\Psi(\\mathbf x, y)\\rangle)$  $(\\Delta(y_1, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)&gt;(\\Delta(y_2, y)+\\langle \\mathbf w, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)$</p>\n<p> $l(\\mathbf w_1, (\\mathbf x, y)) \\ge l(\\mathbf w_2, (\\mathbf x, y))\\ge 0$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}</script><p> $l(\\mathbf w_2, (\\mathbf x, y)) \\ge l(\\mathbf w_1, (\\mathbf x, y)) \\ge 0$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))\\|\n&=\\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_1, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_1)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\& \\le \\|(\\Delta(y_2, y)+\\langle \\mathbf w_2, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)-(\\Delta(y_2, y)+\\langle \\mathbf w_1, \\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\rangle)\\|\n\\\\\\\\ & \\le \\|\\mathbf w_1-\\mathbf w_2\\|\\cdot \\|\\Psi(\\mathbf x, y_2)-\\Psi(\\mathbf x, y)\\|\n\\end{aligned}</script><p>$|l(\\mathbf w_1, (\\mathbf x, y)) - l(\\mathbf w_2, (\\mathbf x, y))|\\le \\rho |\\mathbf w_1 - \\mathbf w_2|$ </p>\n<script type=\"math/tex; mode=display\">\\rho=\\max_{y' \\in \\mathcal Y} \\|\\Psi(\\mathbf x, y')-\\Psi(\\mathbf x, y)\\|</script>"},{"title":"","date":"2021-09-28T05:52:35.000Z","mathjax":true,"p":"ml/multiclass","_content":"\n SVM\n\n<!--more-->\n# Reduction\n\n $h: \\mathcal X \\rightarrow \\mathcal Y$ $\\mathcal Y=\\{1,\\cdots,k\\}$ $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}, \\ y_i \\in \\mathcal Y$\n\n## One-V.S.-All\n\n One-V.S.-Rest k  $h_i: \\mathcal X \\rightarrow \\{1,-1\\}, \\ \\forall i \\in [k]$ k  $S_1, \\cdots, S_k$\n\n$$S_i=\\{(\\mathbf x_1, (-1)^{\\mathbb I(y_1\\neq i)}), \\cdots, (\\mathbf x_m, (-1)^{\\mathbb I(y_m\\neq i)})\\}$$\n\n $j$  $(\\mathbf x_j, y_j)$ $y_j=i$ $S_i$  $h_i$  $S_i$\n\n$$h(\\mathbf x) \\in arg \\max_{i \\in [k]} \\ h_i(\\mathbf x)$$\n\n $(\\mathbf x_j, y_j)$ $y_j=c$ $h_c(\\mathbf x_j)=1$ $h_i(\\mathbf x_j)=-1, \\ \\forall i \\neq c$ $h_c(\\mathbf x_j)$  $-1$\n\n $\\mathbf x$ $h_i(\\mathbf x)=1$$k=3$ $h_1(\\mathbf x)=h_2(\\mathbf x)=1$ $h_i(\\mathbf x)=\\mathbf w_i^{\\top} \\mathbf x$\n\n![](/images/ml/multiclass_fig1.png)\n\n<center>1 h1:h2:h3:</center>\n\n## All Pairs\n k  $1 \\le i < j \\le k$ \n\n$$S_{ij}=\\{(\\mathbf x_l, (-1)^{I(y_l=j)}): y_l=i \\lor y_l=j \\}$$\n\n $S_{ij}$  $(\\mathbf x_l, y_l)$  $i$  $j$ $S_{ij}$  $C_k^2$  $C_k^2$  $h_{ij}: \\mathcal X \\rightarrow \\{\\pm 1\\}$ $c$  $k-1$  $h_{ij}$ $i=c$  $j=c$\n\n** $c$ $k-1$ **\n\n $\\forall i < c, \\ h_{ic}(\\mathbf x)=-1$ $\\forall i>c, \\ h_{ci}(\\mathbf x)=1$\n\n\n\n<center>All-Pairs</center>\n\n**input:**  $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $A$.\n\n**for** $\\ i = 1, \\cdots, k-1$\n\n&emsp; **for** $\\ j=i+1, \\cdots, k$\n\n&emsp;&emsp; **for** $\\ t=1,\\cdots, m$\n\n&emsp;&emsp;&emsp;  $y_t=i$$S_{ij} += \\{(\\mathbf x_t, 1)\\}$\n\n&emsp;&emsp;&emsp;  $y_t=j$$S_{ij} += \\{(\\mathbf x_t, -1)\\}$\n\n&emsp;&emsp; $h_{ij}= A(S_{ij})$\n\n**output:**\n$$h(\\mathbf x) \\in arg\\max_{i \\in [k]}\\left(\\sum_{j=1}^k \\text{sign}(j-i) \\cdot h_{ij}(\\mathbf x)\\right)$$\n\n $h_{ij}(\\mathbf x)=\\mathbf w_{ij}^{\\top}\\mathbf x$\n\n## reduction \n\n reduction  $h_i$  $h_{ij}$ One-V.S.-All  2 \n![](/images/ml/multiclass_fig2.png)\n\n<center>2k=3</center>\n\n $1,2,3$  $40\\%, 20\\%, 40\\%$ $h_2$ $h_2$  $2$  $\\mathbf w_1=(-1/\\sqrt 2, 1/\\sqrt 2), \\ \\mathbf w_2=(0,1), \\ \\mathbf w_3=(1/\\sqrt 2, 1/\\sqrt 2)$ $h(\\mathbf x)=arg\\max_i h_i(\\mathbf x)=arg\\max_i \\mathbf w_i^{\\top}\\mathbf x$ \n\n $\\mathcal H=\\{\\mathbf x \\rightarrow  arg\\max_i \\mathbf w_i^{\\top}\\mathbf x: \\mathbf w \\in \\mathbb R^d\\}$  approximation error  0 One-V.S.-All \n\n> approximation error: \n\n reduction \n\n# \n\n$$h(\\mathbf x)=arg\\max_{i \\in [k]} W^{\\top} \\mathbf x$$\n\n $W \\in \\mathbb R^{d \\times k}$ $\\mathbf x \\in \\mathbb R^n$$W^{\\top} \\mathbf x$  $W$  $W=[\\mathbf w_1, \\cdots, \\mathbf w_k]$ $\\mathbf x$\n\n$$h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y) \\tag{1}\\label{1} $$\n\n$\\Psi(\\mathbf x, y)$  $(\\mathbf x, y)$ \n\n$$\\Psi(\\mathbf x, y)=[0,\\cdots, 0, x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}$$\n\n$x_1$  $(y-1)n$  0$x_n$  $(k-y)n$  0$\\Psi(\\mathbf x, y), \\mathbf w \\in \\mathbb R^{nk}$$\\mathbf w$  \n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_k \\end{bmatrix}$$\n\n\n\n$$h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w_y^{\\top} \\mathbf x \\tag{2}\\label{2}$$\n\n $h(\\mathbf x)$ \n\n $\\mathbf w$ $\\mathbf w_1, \\mathbf w_2$ $\\mathbf w_2=-\\mathbf x_1$\n\n1. \n$$h(\\mathbf x)=arg \\max_{i\\in \\{1, 2\\}} \\begin{bmatrix} \\mathbf w_1, & -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x$$\n\n2. \n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ -\\mathbf w_1 \\end{bmatrix}$$\n$$ \\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}$$\n$$\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}$$\n$$h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y)$$\n\n $h(\\mathbf x)=\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)$ $\\mathbf w_1^{\\top} \\mathbf x>0$ $\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)=1$ $\\begin{bmatrix} \\mathbf w_1 , & -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x=[y_1, \\ -y_1]^{\\top}$ $y_1>-y_1$ $1$\n\n $\\mathbf w$ \n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\mathbf w_2 \\end{bmatrix}$$\n $\\mathbf w_2=-\\mathbf w_1$ \n\n## \n$\\mathcal X = \\mathbb R^2, \\ \\mathcal Y =\\{1,2,3,4\\}, \\ k=4$\n![](/images/ml/multiclass_fig3.png)\n\n\n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_4 \\end{bmatrix}$$\n\n $\\forall i \\in [4], \\ \\mathbf w_i \\in \\mathbb R^2$\n\n $\\eqref{2}$ $i \\in [k]$ $\\mathbf x$  $\\mathbf w_i$ \n\n$$\\max_{\\mathbf w_i} \\sum_{j \\in [m]:\\ y_j = i} \\mathbf w_i^{\\top} \\mathbf x_j \\tag{3} \\label{3}$$\n\n$(\\alpha \\mathbf w^{\\top})\\mathbf x=\\alpha (\\mathbf w^{\\top} \\mathbf x)$ $\\alpha$  $\\|\\mathbf w\\|=1$\n\n $\\|\\mathbf x\\|$  $\\eqref{3}$  $\\mathbf w_i^{\\star}$ $\\|\\mathbf x\\|$ $\\eqref{3}$  $\\mathbf w_i^{\\star}$  $\\|\\mathbf x\\|$   $\\|\\mathbf x\\|=1$\n\n $i$  $\\mathbf x$  x  $\\theta$ x  $\\theta_1, \\ \\theta_2$ $\\mathbf w_i$  x  $\\theta_0$\n\n$$\\mathbf w_i=(\\cos \\theta_0, \\sin \\theta_0), \\quad \\mathbf x=(\\cos \\theta, \\sin \\theta)$$\n\n\n\n$$\\begin{aligned}\\max_{\\theta_0}& \\int_{\\theta_1}^{\\theta_2} \\cos \\theta_0 \\cos \\theta+\\sin \\theta_0 \\sin \\theta d\\theta\n\\\\\\\\ &=\\cos \\theta_0 \\sin \\theta - \\sin \\theta_0 \\cos \\theta |_{\\theta_1}^{\\theta_2}\n\\\\\\\\&=-(\\cos \\theta_2-\\cos \\theta_1) \\sin \\theta_0+(\\sin \\theta_2-\\sin \\theta_1)\\cos \\theta_0\n\\\\\\\\ &=\\sqrt{a^2+b^2} \\sin(\\theta_0+\\phi)\n\\end{aligned}$$\n\n \n$$a=-(\\cos \\theta_2-\\cos \\theta_1), \\quad b = \\sin \\theta_2-\\sin \\theta_1$$\n\n$$\\sin \\phi=\\frac b {\\sqrt{a^2+b^2}}, \\quad \\cos \\phi = \\frac a {\\sqrt{a^2+b^2}}$$\n\n $\\theta_0+\\phi=\\pi / 2 + 2k\\pi, \\ k \\in \\mathbb Z$\n\n$$\\theta_0=\\pi/2- \\phi+2k \\pi, \\ k \\in Z \\tag{4}\\label{4}$$\n\n $\\phi$  \n\n$$\\begin{aligned}\\sin \\phi&=\\frac {\\sin \\theta_2-\\sin \\theta_1}{[(\\cos \\theta_2-\\cos \\theta_1)^2+(\\sin \\theta_2-\\sin \\theta_1)^2]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2(\\cos \\theta_2\\cos \\theta_1+\\sin \\theta_2 \\sin \\theta_1)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2\\cos(\\theta_2-\\theta_!)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {(4 \\sin^2 \\beta)^{1/2}}\n\\\\\\\\ &= \\frac {\\cos \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}\n\\end{aligned}$$\n\n $\\alpha=(\\theta_2+\\theta_1)/2, \\ \\beta=(\\theta_2-\\theta_1)/2$\n\n$$\\cos \\phi=\\frac {\\sin \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}$$\n\n $\\theta_2-\\theta_1 < 2\\pi$ $\\beta < \\pi \\Rightarrow \\sin \\beta > 0$\n $\\sin \\phi = \\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ \n $\\cos \\alpha$  $\\sin (\\pm \\alpha+\\gamma)$  $\\sin \\alpha$  $\\cos (\\pm \\alpha+\\gamma)$ $\\phi=\\pm \\alpha+\\gamma$ $\\gamma$  $\\alpha$  $+$  $-$  $+,-$ \n\n$$\\begin{array}{c|c}\n & \\pi/ 2 + \\alpha &&  \\pi/ 2 - \\alpha && 3\\pi/ 2 + \\alpha && 3\\pi/ 2 - \\alpha \\\\\\\\\n\\hline \n\\alpha \\in (0, \\pi/2) \\quad \\sin(\\cdot)  & + && + && - && -\\\\\\\\\n\\hline\n=&\\cos \\alpha && \\cos \\alpha && - \\cos \\alpha && - \\cos \\alpha\n\\\\\\\\\n\\hline\n\\\\\\\\\n\\hline\n\\alpha \\in (0, \\pi/2) \\quad \\cos(\\cdot)  & - && + && + && -\\\\\\\\\n\\hline\n=&-\\sin \\alpha && \\sin \\alpha &&  \\sin \\alpha && - \\sin \\alpha\n\\end{array}$$\n\n $\\alpha \\in (0,\\pi)$ $\\sin(\\cdot)$  $\\cdot$  $\\sin(\\cdot)$  $\\forall \\alpha \\in \\mathbb R$  $2m\\pi$\n\n $\\phi=\\pi/2-\\alpha$  $\\sin \\phi=\\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ $\\eqref{4}$ \n\n$$\\phi=\\pi/2-\\alpha+2m \\pi, \\ m \\in \\mathbb Z$$\n\n$$\\theta_0=\\alpha+2k \\pi=(\\theta_2+\\theta_1)/2+2k \\pi, \\ k \\in \\mathbb Z$$\n\n $2\\pi$ $\\theta_0=(\\theta_2+\\theta_1)/2$ $\\mathbf w_i$ \n\n","source":"_posts/ml/multiclass.md","raw":"---\ntitle: \ndate: 2021-09-28 13:52:35\ntags: machine learning\nmathjax: true\np: ml/multiclass\n---\n\n SVM\n\n<!--more-->\n# Reduction\n\n $h: \\mathcal X \\rightarrow \\mathcal Y$ $\\mathcal Y=\\{1,\\cdots,k\\}$ $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}, \\ y_i \\in \\mathcal Y$\n\n## One-V.S.-All\n\n One-V.S.-Rest k  $h_i: \\mathcal X \\rightarrow \\{1,-1\\}, \\ \\forall i \\in [k]$ k  $S_1, \\cdots, S_k$\n\n$$S_i=\\{(\\mathbf x_1, (-1)^{\\mathbb I(y_1\\neq i)}), \\cdots, (\\mathbf x_m, (-1)^{\\mathbb I(y_m\\neq i)})\\}$$\n\n $j$  $(\\mathbf x_j, y_j)$ $y_j=i$ $S_i$  $h_i$  $S_i$\n\n$$h(\\mathbf x) \\in arg \\max_{i \\in [k]} \\ h_i(\\mathbf x)$$\n\n $(\\mathbf x_j, y_j)$ $y_j=c$ $h_c(\\mathbf x_j)=1$ $h_i(\\mathbf x_j)=-1, \\ \\forall i \\neq c$ $h_c(\\mathbf x_j)$  $-1$\n\n $\\mathbf x$ $h_i(\\mathbf x)=1$$k=3$ $h_1(\\mathbf x)=h_2(\\mathbf x)=1$ $h_i(\\mathbf x)=\\mathbf w_i^{\\top} \\mathbf x$\n\n![](/images/ml/multiclass_fig1.png)\n\n<center>1 h1:h2:h3:</center>\n\n## All Pairs\n k  $1 \\le i < j \\le k$ \n\n$$S_{ij}=\\{(\\mathbf x_l, (-1)^{I(y_l=j)}): y_l=i \\lor y_l=j \\}$$\n\n $S_{ij}$  $(\\mathbf x_l, y_l)$  $i$  $j$ $S_{ij}$  $C_k^2$  $C_k^2$  $h_{ij}: \\mathcal X \\rightarrow \\{\\pm 1\\}$ $c$  $k-1$  $h_{ij}$ $i=c$  $j=c$\n\n** $c$ $k-1$ **\n\n $\\forall i < c, \\ h_{ic}(\\mathbf x)=-1$ $\\forall i>c, \\ h_{ci}(\\mathbf x)=1$\n\n\n\n<center>All-Pairs</center>\n\n**input:**  $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $A$.\n\n**for** $\\ i = 1, \\cdots, k-1$\n\n&emsp; **for** $\\ j=i+1, \\cdots, k$\n\n&emsp;&emsp; **for** $\\ t=1,\\cdots, m$\n\n&emsp;&emsp;&emsp;  $y_t=i$$S_{ij} += \\{(\\mathbf x_t, 1)\\}$\n\n&emsp;&emsp;&emsp;  $y_t=j$$S_{ij} += \\{(\\mathbf x_t, -1)\\}$\n\n&emsp;&emsp; $h_{ij}= A(S_{ij})$\n\n**output:**\n$$h(\\mathbf x) \\in arg\\max_{i \\in [k]}\\left(\\sum_{j=1}^k \\text{sign}(j-i) \\cdot h_{ij}(\\mathbf x)\\right)$$\n\n $h_{ij}(\\mathbf x)=\\mathbf w_{ij}^{\\top}\\mathbf x$\n\n## reduction \n\n reduction  $h_i$  $h_{ij}$ One-V.S.-All  2 \n![](/images/ml/multiclass_fig2.png)\n\n<center>2k=3</center>\n\n $1,2,3$  $40\\%, 20\\%, 40\\%$ $h_2$ $h_2$  $2$  $\\mathbf w_1=(-1/\\sqrt 2, 1/\\sqrt 2), \\ \\mathbf w_2=(0,1), \\ \\mathbf w_3=(1/\\sqrt 2, 1/\\sqrt 2)$ $h(\\mathbf x)=arg\\max_i h_i(\\mathbf x)=arg\\max_i \\mathbf w_i^{\\top}\\mathbf x$ \n\n $\\mathcal H=\\{\\mathbf x \\rightarrow  arg\\max_i \\mathbf w_i^{\\top}\\mathbf x: \\mathbf w \\in \\mathbb R^d\\}$  approximation error  0 One-V.S.-All \n\n> approximation error: \n\n reduction \n\n# \n\n$$h(\\mathbf x)=arg\\max_{i \\in [k]} W^{\\top} \\mathbf x$$\n\n $W \\in \\mathbb R^{d \\times k}$ $\\mathbf x \\in \\mathbb R^n$$W^{\\top} \\mathbf x$  $W$  $W=[\\mathbf w_1, \\cdots, \\mathbf w_k]$ $\\mathbf x$\n\n$$h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y) \\tag{1}\\label{1} $$\n\n$\\Psi(\\mathbf x, y)$  $(\\mathbf x, y)$ \n\n$$\\Psi(\\mathbf x, y)=[0,\\cdots, 0, x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}$$\n\n$x_1$  $(y-1)n$  0$x_n$  $(k-y)n$  0$\\Psi(\\mathbf x, y), \\mathbf w \\in \\mathbb R^{nk}$$\\mathbf w$  \n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_k \\end{bmatrix}$$\n\n\n\n$$h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w_y^{\\top} \\mathbf x \\tag{2}\\label{2}$$\n\n $h(\\mathbf x)$ \n\n $\\mathbf w$ $\\mathbf w_1, \\mathbf w_2$ $\\mathbf w_2=-\\mathbf x_1$\n\n1. \n$$h(\\mathbf x)=arg \\max_{i\\in \\{1, 2\\}} \\begin{bmatrix} \\mathbf w_1, & -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x$$\n\n2. \n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ -\\mathbf w_1 \\end{bmatrix}$$\n$$ \\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}$$\n$$\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}$$\n$$h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y)$$\n\n $h(\\mathbf x)=\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)$ $\\mathbf w_1^{\\top} \\mathbf x>0$ $\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)=1$ $\\begin{bmatrix} \\mathbf w_1 , & -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x=[y_1, \\ -y_1]^{\\top}$ $y_1>-y_1$ $1$\n\n $\\mathbf w$ \n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\mathbf w_2 \\end{bmatrix}$$\n $\\mathbf w_2=-\\mathbf w_1$ \n\n## \n$\\mathcal X = \\mathbb R^2, \\ \\mathcal Y =\\{1,2,3,4\\}, \\ k=4$\n![](/images/ml/multiclass_fig3.png)\n\n\n\n$$\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_4 \\end{bmatrix}$$\n\n $\\forall i \\in [4], \\ \\mathbf w_i \\in \\mathbb R^2$\n\n $\\eqref{2}$ $i \\in [k]$ $\\mathbf x$  $\\mathbf w_i$ \n\n$$\\max_{\\mathbf w_i} \\sum_{j \\in [m]:\\ y_j = i} \\mathbf w_i^{\\top} \\mathbf x_j \\tag{3} \\label{3}$$\n\n$(\\alpha \\mathbf w^{\\top})\\mathbf x=\\alpha (\\mathbf w^{\\top} \\mathbf x)$ $\\alpha$  $\\|\\mathbf w\\|=1$\n\n $\\|\\mathbf x\\|$  $\\eqref{3}$  $\\mathbf w_i^{\\star}$ $\\|\\mathbf x\\|$ $\\eqref{3}$  $\\mathbf w_i^{\\star}$  $\\|\\mathbf x\\|$   $\\|\\mathbf x\\|=1$\n\n $i$  $\\mathbf x$  x  $\\theta$ x  $\\theta_1, \\ \\theta_2$ $\\mathbf w_i$  x  $\\theta_0$\n\n$$\\mathbf w_i=(\\cos \\theta_0, \\sin \\theta_0), \\quad \\mathbf x=(\\cos \\theta, \\sin \\theta)$$\n\n\n\n$$\\begin{aligned}\\max_{\\theta_0}& \\int_{\\theta_1}^{\\theta_2} \\cos \\theta_0 \\cos \\theta+\\sin \\theta_0 \\sin \\theta d\\theta\n\\\\\\\\ &=\\cos \\theta_0 \\sin \\theta - \\sin \\theta_0 \\cos \\theta |_{\\theta_1}^{\\theta_2}\n\\\\\\\\&=-(\\cos \\theta_2-\\cos \\theta_1) \\sin \\theta_0+(\\sin \\theta_2-\\sin \\theta_1)\\cos \\theta_0\n\\\\\\\\ &=\\sqrt{a^2+b^2} \\sin(\\theta_0+\\phi)\n\\end{aligned}$$\n\n \n$$a=-(\\cos \\theta_2-\\cos \\theta_1), \\quad b = \\sin \\theta_2-\\sin \\theta_1$$\n\n$$\\sin \\phi=\\frac b {\\sqrt{a^2+b^2}}, \\quad \\cos \\phi = \\frac a {\\sqrt{a^2+b^2}}$$\n\n $\\theta_0+\\phi=\\pi / 2 + 2k\\pi, \\ k \\in \\mathbb Z$\n\n$$\\theta_0=\\pi/2- \\phi+2k \\pi, \\ k \\in Z \\tag{4}\\label{4}$$\n\n $\\phi$  \n\n$$\\begin{aligned}\\sin \\phi&=\\frac {\\sin \\theta_2-\\sin \\theta_1}{[(\\cos \\theta_2-\\cos \\theta_1)^2+(\\sin \\theta_2-\\sin \\theta_1)^2]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2(\\cos \\theta_2\\cos \\theta_1+\\sin \\theta_2 \\sin \\theta_1)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2\\cos(\\theta_2-\\theta_!)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {(4 \\sin^2 \\beta)^{1/2}}\n\\\\\\\\ &= \\frac {\\cos \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}\n\\end{aligned}$$\n\n $\\alpha=(\\theta_2+\\theta_1)/2, \\ \\beta=(\\theta_2-\\theta_1)/2$\n\n$$\\cos \\phi=\\frac {\\sin \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}$$\n\n $\\theta_2-\\theta_1 < 2\\pi$ $\\beta < \\pi \\Rightarrow \\sin \\beta > 0$\n $\\sin \\phi = \\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ \n $\\cos \\alpha$  $\\sin (\\pm \\alpha+\\gamma)$  $\\sin \\alpha$  $\\cos (\\pm \\alpha+\\gamma)$ $\\phi=\\pm \\alpha+\\gamma$ $\\gamma$  $\\alpha$  $+$  $-$  $+,-$ \n\n$$\\begin{array}{c|c}\n & \\pi/ 2 + \\alpha &&  \\pi/ 2 - \\alpha && 3\\pi/ 2 + \\alpha && 3\\pi/ 2 - \\alpha \\\\\\\\\n\\hline \n\\alpha \\in (0, \\pi/2) \\quad \\sin(\\cdot)  & + && + && - && -\\\\\\\\\n\\hline\n=&\\cos \\alpha && \\cos \\alpha && - \\cos \\alpha && - \\cos \\alpha\n\\\\\\\\\n\\hline\n\\\\\\\\\n\\hline\n\\alpha \\in (0, \\pi/2) \\quad \\cos(\\cdot)  & - && + && + && -\\\\\\\\\n\\hline\n=&-\\sin \\alpha && \\sin \\alpha &&  \\sin \\alpha && - \\sin \\alpha\n\\end{array}$$\n\n $\\alpha \\in (0,\\pi)$ $\\sin(\\cdot)$  $\\cdot$  $\\sin(\\cdot)$  $\\forall \\alpha \\in \\mathbb R$  $2m\\pi$\n\n $\\phi=\\pi/2-\\alpha$  $\\sin \\phi=\\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ $\\eqref{4}$ \n\n$$\\phi=\\pi/2-\\alpha+2m \\pi, \\ m \\in \\mathbb Z$$\n\n$$\\theta_0=\\alpha+2k \\pi=(\\theta_2+\\theta_1)/2+2k \\pi, \\ k \\in \\mathbb Z$$\n\n $2\\pi$ $\\theta_0=(\\theta_2+\\theta_1)/2$ $\\mathbf w_i$ \n\n","slug":"ml/multiclass","published":1,"updated":"2021-09-30T08:13:18.030Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or918002qp0dj4uu1ftx6","content":"<p> SVM</p>\n<span id=\"more\"></span>\n<h1 id=\"Reduction\"><a href=\"#Reduction\" class=\"headerlink\" title=\"Reduction\"></a>Reduction</h1><p> $h: \\mathcal X \\rightarrow \\mathcal Y$ $\\mathcal Y=\\{1,\\cdots,k\\}$ $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}, \\ y_i \\in \\mathcal Y$</p>\n<h2 id=\"One-V-S-All\"><a href=\"#One-V-S-All\" class=\"headerlink\" title=\"One-V.S.-All\"></a>One-V.S.-All</h2><p> One-V.S.-Rest k  $h_i: \\mathcal X \\rightarrow \\{1,-1\\}, \\ \\forall i \\in [k]$ k  $S_1, \\cdots, S_k$</p>\n<script type=\"math/tex; mode=display\">S_i=\\{(\\mathbf x_1, (-1)^{\\mathbb I(y_1\\neq i)}), \\cdots, (\\mathbf x_m, (-1)^{\\mathbb I(y_m\\neq i)})\\}</script><p> $j$  $(\\mathbf x_j, y_j)$ $y_j=i$ $S_i$  $h_i$  $S_i$</p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x) \\in arg \\max_{i \\in [k]} \\ h_i(\\mathbf x)</script><p> $(\\mathbf x_j, y_j)$ $y_j=c$ $h_c(\\mathbf x_j)=1$ $h_i(\\mathbf x_j)=-1, \\ \\forall i \\neq c$ $h_c(\\mathbf x_j)$  $-1$</p>\n<p> $\\mathbf x$ $h_i(\\mathbf x)=1$$k=3$ $h_1(\\mathbf x)=h_2(\\mathbf x)=1$ $h_i(\\mathbf x)=\\mathbf w_i^{\\top} \\mathbf x$</p>\n<p><img src=\"/images/ml/multiclass_fig1.png\" alt=\"\"></p>\n<center>1 h1:h2:h3:</center>\n\n<h2 id=\"All-Pairs\"><a href=\"#All-Pairs\" class=\"headerlink\" title=\"All Pairs\"></a>All Pairs</h2><p> k  $1 \\le i &lt; j \\le k$ </p>\n<script type=\"math/tex; mode=display\">S_{ij}=\\{(\\mathbf x_l, (-1)^{I(y_l=j)}): y_l=i \\lor y_l=j \\}</script><p> $S_{ij}$  $(\\mathbf x_l, y_l)$  $i$  $j$ $S_{ij}$  $C_k^2$  $C_k^2$  $h_{ij}: \\mathcal X \\rightarrow \\{\\pm 1\\}$ $c$  $k-1$  $h_{ij}$ $i=c$  $j=c$</p>\n<p><strong> $c$ $k-1$ </strong></p>\n<p> $\\forall i &lt; c, \\ h_{ic}(\\mathbf x)=-1$ $\\forall i&gt;c, \\ h_{ci}(\\mathbf x)=1$</p>\n<p></p>\n<center>All-Pairs</center>\n\n<p><strong>input:</strong>  $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $A$.</p>\n<p><strong>for</strong> $\\ i = 1, \\cdots, k-1$</p>\n<p>&emsp; <strong>for</strong> $\\ j=i+1, \\cdots, k$</p>\n<p>&emsp;&emsp; <strong>for</strong> $\\ t=1,\\cdots, m$</p>\n<p>&emsp;&emsp;&emsp;  $y_t=i$$S_{ij} += \\{(\\mathbf x_t, 1)\\}$</p>\n<p>&emsp;&emsp;&emsp;  $y_t=j$$S_{ij} += \\{(\\mathbf x_t, -1)\\}$</p>\n<p>&emsp;&emsp; $h_{ij}= A(S_{ij})$</p>\n<p><strong>output:</strong></p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x) \\in arg\\max_{i \\in [k]}\\left(\\sum_{j=1}^k \\text{sign}(j-i) \\cdot h_{ij}(\\mathbf x)\\right)</script><p> $h_{ij}(\\mathbf x)=\\mathbf w_{ij}^{\\top}\\mathbf x$</p>\n<h2 id=\"reduction-\"><a href=\"#reduction-\" class=\"headerlink\" title=\"reduction \"></a>reduction </h2><p> reduction  $h_i$  $h_{ij}$ One-V.S.-All  2 <br><img src=\"/images/ml/multiclass_fig2.png\" alt=\"\"></p>\n<center>2k=3</center>\n\n<p> $1,2,3$  $40\\%, 20\\%, 40\\%$ $h_2$ $h_2$  $2$  $\\mathbf w_1=(-1/\\sqrt 2, 1/\\sqrt 2), \\ \\mathbf w_2=(0,1), \\ \\mathbf w_3=(1/\\sqrt 2, 1/\\sqrt 2)$ $h(\\mathbf x)=arg\\max_i h_i(\\mathbf x)=arg\\max_i \\mathbf w_i^{\\top}\\mathbf x$ </p>\n<p> $\\mathcal H=\\{\\mathbf x \\rightarrow  arg\\max_i \\mathbf w_i^{\\top}\\mathbf x: \\mathbf w \\in \\mathbb R^d\\}$  approximation error  0 One-V.S.-All </p>\n<blockquote>\n<p>approximation error: </p>\n</blockquote>\n<p> reduction </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><script type=\"math/tex; mode=display\">h(\\mathbf x)=arg\\max_{i \\in [k]} W^{\\top} \\mathbf x</script><p> $W \\in \\mathbb R^{d \\times k}$ $\\mathbf x \\in \\mathbb R^n$$W^{\\top} \\mathbf x$  $W$  $W=[\\mathbf w_1, \\cdots, \\mathbf w_k]$ $\\mathbf x$</p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y) \\tag{1}\\label{1}</script><p>$\\Psi(\\mathbf x, y)$  $(\\mathbf x, y)$ </p>\n<script type=\"math/tex; mode=display\">\\Psi(\\mathbf x, y)=[0,\\cdots, 0, x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}</script><p>$x_1$  $(y-1)n$  0$x_n$  $(k-y)n$  0$\\Psi(\\mathbf x, y), \\mathbf w \\in \\mathbb R^{nk}$$\\mathbf w$  </p>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_k \\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w_y^{\\top} \\mathbf x \\tag{2}\\label{2}</script><p> $h(\\mathbf x)$ </p>\n<p> $\\mathbf w$ $\\mathbf w_1, \\mathbf w_2$ $\\mathbf w_2=-\\mathbf x_1$</p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{i\\in \\{1, 2\\}} \\begin{bmatrix} \\mathbf w_1, & -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x</script></li>\n<li><p></p>\n</li>\n</ol>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ -\\mathbf w_1 \\end{bmatrix}</script><script type=\"math/tex; mode=display\">\\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}</script><script type=\"math/tex; mode=display\">\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}</script><script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y)</script><p> $h(\\mathbf x)=\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)$ $\\mathbf w_1^{\\top} \\mathbf x&gt;0$ $\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)=1$ $\\begin{bmatrix} \\mathbf w_1 , &amp; -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x=[y_1, \\ -y_1]^{\\top}$ $y_1&gt;-y_1$ $1$</p>\n<p> $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\mathbf w_2 \\end{bmatrix}</script><p> $\\mathbf w_2=-\\mathbf w_1$ </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathcal X = \\mathbb R^2, \\ \\mathcal Y =\\{1,2,3,4\\}, \\ k=4$<br><img src=\"/images/ml/multiclass_fig3.png\" alt=\"\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_4 \\end{bmatrix}</script><p> $\\forall i \\in [4], \\ \\mathbf w_i \\in \\mathbb R^2$</p>\n<p> $\\eqref{2}$ $i \\in [k]$ $\\mathbf x$  $\\mathbf w_i$ </p>\n<script type=\"math/tex; mode=display\">\\max_{\\mathbf w_i} \\sum_{j \\in [m]:\\ y_j = i} \\mathbf w_i^{\\top} \\mathbf x_j \\tag{3} \\label{3}</script><p>$(\\alpha \\mathbf w^{\\top})\\mathbf x=\\alpha (\\mathbf w^{\\top} \\mathbf x)$ $\\alpha$  $|\\mathbf w|=1$</p>\n<p> $|\\mathbf x|$  $\\eqref{3}$  $\\mathbf w_i^{\\star}$ $|\\mathbf x|$ $\\eqref{3}$  $\\mathbf w_i^{\\star}$  $|\\mathbf x|$   $|\\mathbf x|=1$</p>\n<p> $i$  $\\mathbf x$  x  $\\theta$ x  $\\theta_1, \\ \\theta_2$ $\\mathbf w_i$  x  $\\theta_0$</p>\n<script type=\"math/tex; mode=display\">\\mathbf w_i=(\\cos \\theta_0, \\sin \\theta_0), \\quad \\mathbf x=(\\cos \\theta, \\sin \\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\max_{\\theta_0}& \\int_{\\theta_1}^{\\theta_2} \\cos \\theta_0 \\cos \\theta+\\sin \\theta_0 \\sin \\theta d\\theta\n\\\\\\\\ &=\\cos \\theta_0 \\sin \\theta - \\sin \\theta_0 \\cos \\theta |_{\\theta_1}^{\\theta_2}\n\\\\\\\\&=-(\\cos \\theta_2-\\cos \\theta_1) \\sin \\theta_0+(\\sin \\theta_2-\\sin \\theta_1)\\cos \\theta_0\n\\\\\\\\ &=\\sqrt{a^2+b^2} \\sin(\\theta_0+\\phi)\n\\end{aligned}</script><p> </p>\n<script type=\"math/tex; mode=display\">a=-(\\cos \\theta_2-\\cos \\theta_1), \\quad b = \\sin \\theta_2-\\sin \\theta_1</script><script type=\"math/tex; mode=display\">\\sin \\phi=\\frac b {\\sqrt{a^2+b^2}}, \\quad \\cos \\phi = \\frac a {\\sqrt{a^2+b^2}}</script><p> $\\theta_0+\\phi=\\pi / 2 + 2k\\pi, \\ k \\in \\mathbb Z$</p>\n<script type=\"math/tex; mode=display\">\\theta_0=\\pi/2- \\phi+2k \\pi, \\ k \\in Z \\tag{4}\\label{4}</script><p> $\\phi$  </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\sin \\phi&=\\frac {\\sin \\theta_2-\\sin \\theta_1}{[(\\cos \\theta_2-\\cos \\theta_1)^2+(\\sin \\theta_2-\\sin \\theta_1)^2]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2(\\cos \\theta_2\\cos \\theta_1+\\sin \\theta_2 \\sin \\theta_1)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2\\cos(\\theta_2-\\theta_!)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {(4 \\sin^2 \\beta)^{1/2}}\n\\\\\\\\ &= \\frac {\\cos \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}\n\\end{aligned}</script><p> $\\alpha=(\\theta_2+\\theta_1)/2, \\ \\beta=(\\theta_2-\\theta_1)/2$</p>\n<script type=\"math/tex; mode=display\">\\cos \\phi=\\frac {\\sin \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}</script><p> $\\theta_2-\\theta_1 &lt; 2\\pi$ $\\beta &lt; \\pi \\Rightarrow \\sin \\beta &gt; 0$<br> $\\sin \\phi = \\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ <br> $\\cos \\alpha$  $\\sin (\\pm \\alpha+\\gamma)$  $\\sin \\alpha$  $\\cos (\\pm \\alpha+\\gamma)$ $\\phi=\\pm \\alpha+\\gamma$ $\\gamma$  $\\alpha$  $+$  $-$  $+,-$ </p>\n<script type=\"math/tex; mode=display\">\\begin{array}{c|c}\n & \\pi/ 2 + \\alpha &&  \\pi/ 2 - \\alpha && 3\\pi/ 2 + \\alpha && 3\\pi/ 2 - \\alpha \\\\\\\\\n\\hline \n\\alpha \\in (0, \\pi/2) \\quad \\sin(\\cdot)  & + && + && - && -\\\\\\\\\n\\hline\n=&\\cos \\alpha && \\cos \\alpha && - \\cos \\alpha && - \\cos \\alpha\n\\\\\\\\\n\\hline\n\\\\\\\\\n\\hline\n\\alpha \\in (0, \\pi/2) \\quad \\cos(\\cdot)  & - && + && + && -\\\\\\\\\n\\hline\n=&-\\sin \\alpha && \\sin \\alpha &&  \\sin \\alpha && - \\sin \\alpha\n\\end{array}</script><p> $\\alpha \\in (0,\\pi)$ $\\sin(\\cdot)$  $\\cdot$  $\\sin(\\cdot)$  $\\forall \\alpha \\in \\mathbb R$  $2m\\pi$</p>\n<p> $\\phi=\\pi/2-\\alpha$  $\\sin \\phi=\\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ $\\eqref{4}$ </p>\n<script type=\"math/tex; mode=display\">\\phi=\\pi/2-\\alpha+2m \\pi, \\ m \\in \\mathbb Z</script><script type=\"math/tex; mode=display\">\\theta_0=\\alpha+2k \\pi=(\\theta_2+\\theta_1)/2+2k \\pi, \\ k \\in \\mathbb Z</script><p> $2\\pi$ $\\theta_0=(\\theta_2+\\theta_1)/2$ $\\mathbf w_i$ </p>\n","site":{"data":{}},"excerpt":"<p> SVM</p>","more":"<h1 id=\"Reduction\"><a href=\"#Reduction\" class=\"headerlink\" title=\"Reduction\"></a>Reduction</h1><p> $h: \\mathcal X \\rightarrow \\mathcal Y$ $\\mathcal Y=\\{1,\\cdots,k\\}$ $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}, \\ y_i \\in \\mathcal Y$</p>\n<h2 id=\"One-V-S-All\"><a href=\"#One-V-S-All\" class=\"headerlink\" title=\"One-V.S.-All\"></a>One-V.S.-All</h2><p> One-V.S.-Rest k  $h_i: \\mathcal X \\rightarrow \\{1,-1\\}, \\ \\forall i \\in [k]$ k  $S_1, \\cdots, S_k$</p>\n<script type=\"math/tex; mode=display\">S_i=\\{(\\mathbf x_1, (-1)^{\\mathbb I(y_1\\neq i)}), \\cdots, (\\mathbf x_m, (-1)^{\\mathbb I(y_m\\neq i)})\\}</script><p> $j$  $(\\mathbf x_j, y_j)$ $y_j=i$ $S_i$  $h_i$  $S_i$</p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x) \\in arg \\max_{i \\in [k]} \\ h_i(\\mathbf x)</script><p> $(\\mathbf x_j, y_j)$ $y_j=c$ $h_c(\\mathbf x_j)=1$ $h_i(\\mathbf x_j)=-1, \\ \\forall i \\neq c$ $h_c(\\mathbf x_j)$  $-1$</p>\n<p> $\\mathbf x$ $h_i(\\mathbf x)=1$$k=3$ $h_1(\\mathbf x)=h_2(\\mathbf x)=1$ $h_i(\\mathbf x)=\\mathbf w_i^{\\top} \\mathbf x$</p>\n<p><img src=\"/images/ml/multiclass_fig1.png\" alt=\"\"></p>\n<center>1 h1:h2:h3:</center>\n\n<h2 id=\"All-Pairs\"><a href=\"#All-Pairs\" class=\"headerlink\" title=\"All Pairs\"></a>All Pairs</h2><p> k  $1 \\le i &lt; j \\le k$ </p>\n<script type=\"math/tex; mode=display\">S_{ij}=\\{(\\mathbf x_l, (-1)^{I(y_l=j)}): y_l=i \\lor y_l=j \\}</script><p> $S_{ij}$  $(\\mathbf x_l, y_l)$  $i$  $j$ $S_{ij}$  $C_k^2$  $C_k^2$  $h_{ij}: \\mathcal X \\rightarrow \\{\\pm 1\\}$ $c$  $k-1$  $h_{ij}$ $i=c$  $j=c$</p>\n<p><strong> $c$ $k-1$ </strong></p>\n<p> $\\forall i &lt; c, \\ h_{ic}(\\mathbf x)=-1$ $\\forall i&gt;c, \\ h_{ci}(\\mathbf x)=1$</p>\n<p></p>\n<center>All-Pairs</center>\n\n<p><strong>input:</strong>  $S=\\{(\\mathbf x_1, y_1), \\cdots, (\\mathbf x_m, y_m)\\}$ $A$.</p>\n<p><strong>for</strong> $\\ i = 1, \\cdots, k-1$</p>\n<p>&emsp; <strong>for</strong> $\\ j=i+1, \\cdots, k$</p>\n<p>&emsp;&emsp; <strong>for</strong> $\\ t=1,\\cdots, m$</p>\n<p>&emsp;&emsp;&emsp;  $y_t=i$$S_{ij} += \\{(\\mathbf x_t, 1)\\}$</p>\n<p>&emsp;&emsp;&emsp;  $y_t=j$$S_{ij} += \\{(\\mathbf x_t, -1)\\}$</p>\n<p>&emsp;&emsp; $h_{ij}= A(S_{ij})$</p>\n<p><strong>output:</strong></p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x) \\in arg\\max_{i \\in [k]}\\left(\\sum_{j=1}^k \\text{sign}(j-i) \\cdot h_{ij}(\\mathbf x)\\right)</script><p> $h_{ij}(\\mathbf x)=\\mathbf w_{ij}^{\\top}\\mathbf x$</p>\n<h2 id=\"reduction-\"><a href=\"#reduction-\" class=\"headerlink\" title=\"reduction \"></a>reduction </h2><p> reduction  $h_i$  $h_{ij}$ One-V.S.-All  2 <br><img src=\"/images/ml/multiclass_fig2.png\" alt=\"\"></p>\n<center>2k=3</center>\n\n<p> $1,2,3$  $40\\%, 20\\%, 40\\%$ $h_2$ $h_2$  $2$  $\\mathbf w_1=(-1/\\sqrt 2, 1/\\sqrt 2), \\ \\mathbf w_2=(0,1), \\ \\mathbf w_3=(1/\\sqrt 2, 1/\\sqrt 2)$ $h(\\mathbf x)=arg\\max_i h_i(\\mathbf x)=arg\\max_i \\mathbf w_i^{\\top}\\mathbf x$ </p>\n<p> $\\mathcal H=\\{\\mathbf x \\rightarrow  arg\\max_i \\mathbf w_i^{\\top}\\mathbf x: \\mathbf w \\in \\mathbb R^d\\}$  approximation error  0 One-V.S.-All </p>\n<blockquote>\n<p>approximation error: </p>\n</blockquote>\n<p> reduction </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><script type=\"math/tex; mode=display\">h(\\mathbf x)=arg\\max_{i \\in [k]} W^{\\top} \\mathbf x</script><p> $W \\in \\mathbb R^{d \\times k}$ $\\mathbf x \\in \\mathbb R^n$$W^{\\top} \\mathbf x$  $W$  $W=[\\mathbf w_1, \\cdots, \\mathbf w_k]$ $\\mathbf x$</p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y) \\tag{1}\\label{1}</script><p>$\\Psi(\\mathbf x, y)$  $(\\mathbf x, y)$ </p>\n<script type=\"math/tex; mode=display\">\\Psi(\\mathbf x, y)=[0,\\cdots, 0, x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}</script><p>$x_1$  $(y-1)n$  0$x_n$  $(k-y)n$  0$\\Psi(\\mathbf x, y), \\mathbf w \\in \\mathbb R^{nk}$$\\mathbf w$  </p>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_k \\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w_y^{\\top} \\mathbf x \\tag{2}\\label{2}</script><p> $h(\\mathbf x)$ </p>\n<p> $\\mathbf w$ $\\mathbf w_1, \\mathbf w_2$ $\\mathbf w_2=-\\mathbf x_1$</p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{i\\in \\{1, 2\\}} \\begin{bmatrix} \\mathbf w_1, & -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x</script></li>\n<li><p></p>\n</li>\n</ol>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ -\\mathbf w_1 \\end{bmatrix}</script><script type=\"math/tex; mode=display\">\\Psi(\\mathbf x, y=1)=[x_1,\\cdots, x_n, 0,\\cdots 0]^{\\top}</script><script type=\"math/tex; mode=display\">\\Psi(\\mathbf x, y=2)=[0,\\cdots 0, x_1,\\cdots, x_n]^{\\top}</script><script type=\"math/tex; mode=display\">h(\\mathbf x)=arg \\max_{y \\in \\mathcal Y} \\mathbf w^{\\top} \\Psi(\\mathbf x, y)</script><p> $h(\\mathbf x)=\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)$ $\\mathbf w_1^{\\top} \\mathbf x&gt;0$ $\\text{sign}(\\mathbf w_1^{\\top} \\mathbf x)=1$ $\\begin{bmatrix} \\mathbf w_1 , &amp; -\\mathbf w_1 \\end{bmatrix}^{\\top} \\mathbf x=[y_1, \\ -y_1]^{\\top}$ $y_1&gt;-y_1$ $1$</p>\n<p> $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\mathbf w_2 \\end{bmatrix}</script><p> $\\mathbf w_2=-\\mathbf w_1$ </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathcal X = \\mathbb R^2, \\ \\mathcal Y =\\{1,2,3,4\\}, \\ k=4$<br><img src=\"/images/ml/multiclass_fig3.png\" alt=\"\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w=\\begin{bmatrix} \\mathbf w_1 \\\\\\\\ \\vdots \\\\\\\\ \\mathbf w_4 \\end{bmatrix}</script><p> $\\forall i \\in [4], \\ \\mathbf w_i \\in \\mathbb R^2$</p>\n<p> $\\eqref{2}$ $i \\in [k]$ $\\mathbf x$  $\\mathbf w_i$ </p>\n<script type=\"math/tex; mode=display\">\\max_{\\mathbf w_i} \\sum_{j \\in [m]:\\ y_j = i} \\mathbf w_i^{\\top} \\mathbf x_j \\tag{3} \\label{3}</script><p>$(\\alpha \\mathbf w^{\\top})\\mathbf x=\\alpha (\\mathbf w^{\\top} \\mathbf x)$ $\\alpha$  $|\\mathbf w|=1$</p>\n<p> $|\\mathbf x|$  $\\eqref{3}$  $\\mathbf w_i^{\\star}$ $|\\mathbf x|$ $\\eqref{3}$  $\\mathbf w_i^{\\star}$  $|\\mathbf x|$   $|\\mathbf x|=1$</p>\n<p> $i$  $\\mathbf x$  x  $\\theta$ x  $\\theta_1, \\ \\theta_2$ $\\mathbf w_i$  x  $\\theta_0$</p>\n<script type=\"math/tex; mode=display\">\\mathbf w_i=(\\cos \\theta_0, \\sin \\theta_0), \\quad \\mathbf x=(\\cos \\theta, \\sin \\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\max_{\\theta_0}& \\int_{\\theta_1}^{\\theta_2} \\cos \\theta_0 \\cos \\theta+\\sin \\theta_0 \\sin \\theta d\\theta\n\\\\\\\\ &=\\cos \\theta_0 \\sin \\theta - \\sin \\theta_0 \\cos \\theta |_{\\theta_1}^{\\theta_2}\n\\\\\\\\&=-(\\cos \\theta_2-\\cos \\theta_1) \\sin \\theta_0+(\\sin \\theta_2-\\sin \\theta_1)\\cos \\theta_0\n\\\\\\\\ &=\\sqrt{a^2+b^2} \\sin(\\theta_0+\\phi)\n\\end{aligned}</script><p> </p>\n<script type=\"math/tex; mode=display\">a=-(\\cos \\theta_2-\\cos \\theta_1), \\quad b = \\sin \\theta_2-\\sin \\theta_1</script><script type=\"math/tex; mode=display\">\\sin \\phi=\\frac b {\\sqrt{a^2+b^2}}, \\quad \\cos \\phi = \\frac a {\\sqrt{a^2+b^2}}</script><p> $\\theta_0+\\phi=\\pi / 2 + 2k\\pi, \\ k \\in \\mathbb Z$</p>\n<script type=\"math/tex; mode=display\">\\theta_0=\\pi/2- \\phi+2k \\pi, \\ k \\in Z \\tag{4}\\label{4}</script><p> $\\phi$  </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\sin \\phi&=\\frac {\\sin \\theta_2-\\sin \\theta_1}{[(\\cos \\theta_2-\\cos \\theta_1)^2+(\\sin \\theta_2-\\sin \\theta_1)^2]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2(\\cos \\theta_2\\cos \\theta_1+\\sin \\theta_2 \\sin \\theta_1)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {[2-2\\cos(\\theta_2-\\theta_!)]^{1/2}}\n\\\\\\\\ &=\\frac {2 \\cos \\alpha \\sin \\beta} {(4 \\sin^2 \\beta)^{1/2}}\n\\\\\\\\ &= \\frac {\\cos \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}\n\\end{aligned}</script><p> $\\alpha=(\\theta_2+\\theta_1)/2, \\ \\beta=(\\theta_2-\\theta_1)/2$</p>\n<script type=\"math/tex; mode=display\">\\cos \\phi=\\frac {\\sin \\alpha \\sin \\beta} {(\\sin^2 \\beta)^{1/2}}</script><p> $\\theta_2-\\theta_1 &lt; 2\\pi$ $\\beta &lt; \\pi \\Rightarrow \\sin \\beta &gt; 0$<br> $\\sin \\phi = \\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ <br> $\\cos \\alpha$  $\\sin (\\pm \\alpha+\\gamma)$  $\\sin \\alpha$  $\\cos (\\pm \\alpha+\\gamma)$ $\\phi=\\pm \\alpha+\\gamma$ $\\gamma$  $\\alpha$  $+$  $-$  $+,-$ </p>\n<script type=\"math/tex; mode=display\">\\begin{array}{c|c}\n & \\pi/ 2 + \\alpha &&  \\pi/ 2 - \\alpha && 3\\pi/ 2 + \\alpha && 3\\pi/ 2 - \\alpha \\\\\\\\\n\\hline \n\\alpha \\in (0, \\pi/2) \\quad \\sin(\\cdot)  & + && + && - && -\\\\\\\\\n\\hline\n=&\\cos \\alpha && \\cos \\alpha && - \\cos \\alpha && - \\cos \\alpha\n\\\\\\\\\n\\hline\n\\\\\\\\\n\\hline\n\\alpha \\in (0, \\pi/2) \\quad \\cos(\\cdot)  & - && + && + && -\\\\\\\\\n\\hline\n=&-\\sin \\alpha && \\sin \\alpha &&  \\sin \\alpha && - \\sin \\alpha\n\\end{array}</script><p> $\\alpha \\in (0,\\pi)$ $\\sin(\\cdot)$  $\\cdot$  $\\sin(\\cdot)$  $\\forall \\alpha \\in \\mathbb R$  $2m\\pi$</p>\n<p> $\\phi=\\pi/2-\\alpha$  $\\sin \\phi=\\cos \\alpha, \\ \\cos \\phi=\\sin \\alpha$ $\\eqref{4}$ </p>\n<script type=\"math/tex; mode=display\">\\phi=\\pi/2-\\alpha+2m \\pi, \\ m \\in \\mathbb Z</script><script type=\"math/tex; mode=display\">\\theta_0=\\alpha+2k \\pi=(\\theta_2+\\theta_1)/2+2k \\pi, \\ k \\in \\mathbb Z</script><p> $2\\pi$ $\\theta_0=(\\theta_2+\\theta_1)/2$ $\\mathbf w_i$ </p>"},{"title":"","date":"2021-09-22T08:04:37.000Z","p":"ml/svm","mathjax":true,"_content":"\n\n\n<!--more-->\n\n#  Hard-SVM\n\n $S=(\\mathbf x_1,y_1), \\cdots, (\\mathbf x_m, y_m)$ $\\mathbf x \\in \\mathbb R^d, \\ y \\in \\{1,-1\\}$\n\n$$\\forall i \\in [m], \\quad y_i (\\mathbf w^{\\top} \\mathbf x_i+b )>0$$\n\n halfspace $(\\mathbf w , b)$  ERM $L_S(h)=0$ $(\\mathbf w, b)$\n\n> \n\n\n\n## \n\n** $\\mathbf x$  $(\\mathbf w, b)$  $\\|\\mathbf w\\|=1$ $|\\mathbf w^{\\top}\\mathbf x+b|$**\n\n $\\|\\mathbf w\\|=1$  $a\\mathbf w \\mathbf x+ab=1, \\ \\forall a \\neq 0$ $\\mathbf w$ $b$ \n\n****\n\n\n\n$$\\min\\{\\|\\mathbf {x-v}: \\mathbf w^{\\top}\\mathbf v+b=0\\}$$\n\n $\\mathbf v=\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w$\n\n$$\\mathbf w^{\\top} \\mathbf v+b=\\mathbf w^{\\top}\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\|\\mathbf w\\|^2+b=0$$\n\n\n\n $\\mathbf x, \\ \\mathbf v$ \n\n$$\\|\\mathbf x-\\mathbf v\\|=|\\mathbf w^{\\top} \\mathbf x+b|\\|\\mathbf w\\|=|\\mathbf w^{\\top} \\mathbf x+b|$$\n\n $\\mathbf u$\n\n$$\\begin{aligned} \\Vert \\mathbf {x-u}\\Vert^2 &=\\|\\mathbf {x-v+v-u}\\|^2\n\\\\ &=\\|\\mathbf {x-v}\\|^2+\\|\\mathbf {v-u}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &\\ge\\|\\mathbf {x-v}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2+2(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2\\end{aligned}$$\n\n $\\mathbf v$  $\\mathbf w^{\\top}\\mathbf v=\\mathbf w^{\\top}\\mathbf u=-b$\n\n$\\mathbf x$  $\\|\\mathbf {x-v}\\|^2$ $|\\mathbf w^{\\top} \\mathbf x+b|$\n\n## Hard-SVM\n\nHard-SVM \n\n$$arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} |\\mathbf w^{\\top} \\mathbf x_i+b| \\quad s.t. \\ \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b)>0$$\n\n\n\n$$arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\quad(1)$$\n\n### \n\n $\\|\\mathbf w\\|=1$  $(\\mathbf w, b)$,  $\\gamma=\\min_{i \\in [m]} \\ y_i(\\mathbf w^{\\top}\\mathbf x_i+b)$ $\\forall i \\in [m]$ \n\n$$y_i (\\mathbf w^{\\top}\\mathbf x_i+b) \\ge \\gamma$$\n\n $\\gamma>0$\n\n$$y_i (\\frac {\\mathbf w^{\\top}} {\\gamma}\\mathbf x_i+\\frac {b}{\\gamma}) \\ge 1$$\n\n\n\n (1)  $\\gamma$ \n $\\|\\mathbf w\\|=1$\n $\\frac {\\|\\mathbf w^{\\top}\\|}{\\gamma}$ $b$  $\\mathbf w$ (1) \n\n$$arg \\min_{(\\mathbf w, b)}\\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1 \\quad(2)$$\n\n\n# Soft-SVM\n\nHard-SVM  Soft-SVM (2)  $\\{\\xi_i:\\xi_i \\ge 0, \\forall i \\in [m]\\}$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1-\\xi_i$ $\\|\\mathbf w\\|$  Hard-SVM  Soft-SVM \n\n<center>Soft-SVM</center>\n\n**input:** $(\\mathbf x_1, y_1), \\cdots (\\mathbf x_m, y_m)$\n\n**parameter:**  $\\lambda >0$ \n\n**solve:**\n\n$$\\min_{\\mathbf w, b, \\boldsymbol \\xi} \\left(\\lambda \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\xi_i\\right)$$\n$$s.t. \\ \\forall i, \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1- \\xi_i, \\ \\xi_i \\ge 0$$\n\n**output:** $\\mathbf w, b$\n\n hinge \n\n$$l(\\mathbf w, b, \\mathbf x, y)=\\max \\{0, 1-y(\\mathbf w^{\\top}\\mathbf x+b)\\}$$\n\n $S$  $L_S(\\mathbf w, b)$\n\n$$\\min_{\\mathbf w, b} (\\lambda \\|\\mathbf w\\|^2+L_S(\\mathbf w, b))$$\n\n $(\\mathbf w, b)$  $(\\mathbf x_i, y_i)$ $\\xi_i \\ge 0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1$ $\\xi_i=0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) < 1$ $1-y_i(\\mathbf w^{\\top} \\mathbf x_i+b) =\\xi_i$ $L_S(\\mathbf w, b)=\\frac 1 m \\sum_{i=1}^m \\xi_i$\n\n $0<\\xi<1$ $\\xi_i \\ge 1$ $i$ **Soft-SVM **\n\n\n## \n{% raw %}\nSVM  Hard-SVM  $\\mathbf w_0=\\frac {\\mathbf w^{\\ast}} {\\gamma^{\\ast}}$ $\\mathbf w^{\\ast}$  (1) $\\gamma^{\\ast}$  (1)  $\\forall i \\in [m], \\ y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)\\ge\\gamma^{\\ast}$ $\\mathbf w_0$ $\\{(\\mathbf x_i, y_i): y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)=\\gamma^{\\ast}\\}$  $\\gamma^{\\ast}$\n{% endraw %}\n\n $b=0$ $b$  $w_1$ $\\mathbf x$  $\\mathbf x_1=1$ Hard-SVM \n\n$$\\min_{\\mathbf w} \\ \\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i \\mathbf w^{\\top} \\mathbf x \\ge 1 \\quad(3)$$ \n\n $\\mathbf w_0$  $I=\\{\\mathbf x_i: |\\mathbf w_0^{\\top}\\mathbf x_i|=1\\}$** $\\alpha_1, \\cdots$ **\n\n$$\\mathbf w_0=\\sum_{i \\in I} \\alpha_i \\mathbf x_i$$\n\n\n\n## \n\n\n\n$$g(\\mathbf w)=\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)=\\begin{cases} 0 & \\forall i, \\ y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1 \\\\ \\infty & \\text{otherwise} \\end{cases}$$\n\n $\\alpha_i$  $y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1$ $\\forall i , \\ \\alpha=0$  $g(\\mathbf w)$  $0$$\\forall i, \\ \\alpha=\\infty$  $g(\\mathbf w)$  $\\infty$\n\n (3) \n\n$$\\min_{\\mathbf w}\\ (\\|\\mathbf w\\|^2+ g(\\mathbf w))$$\n\n\n\n$$\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)$$\n\n $\\frac 1 2$ \n\n$$\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)\\\\\\\\ \\ge\n \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)$$\n\n\n\n$$ \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)$$\n\n $\\boldsymbol \\alpha$  0 \n\n$$\\mathbf w-\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i=\\mathbf 0 \\Rightarrow \\mathbf w=\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i$$\n\n $\\mathbf w$ \n\n$$\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2+\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)\\right)$$\n\n\n\n$$\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2=\\frac 1 2 \\left(\\sum_i \\alpha_i y_i \\mathbf x_i^{\\top}\\right)\\left(\\sum_j \\alpha_j y_j \\mathbf x_j \\right)$$\n\n\n\n$$\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)=\\sum_i \\alpha_i-\\left(\\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\right)\\left(\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\right)$$\n\n\n\n$$\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\sum_{i=1}^m \\alpha_i-\\frac 1 2 \\sum_{1=1}^m \\sum_{j=1}^m \\alpha_i  \\alpha_j y_iy_j \\mathbf x_i^{\\top}\\mathbf x_j \\right)$$\n\n## SGD  Soft-SVM\n\n hinge  Soft-SVM \n\n$$\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\mathbf x_i\\}\\right) \\tag{4} \\label{4}$$\n\n $f(\\mathbf w)=\\frac {\\lambda} 2 \\|\\mathbf w\\|^2+L_S(\\mathbf w)$ \n\n $t$  $\\mathbf v_t \\in \\partial l_{\\mathcal D}(\\mathbf w^{(t)})$ $\\partial l_{\\mathcal D}(\\mathbf w^{(t)})$  $\\mathbf w^{(t)}$  $\\mathcal D$   $S$  $z$ $\\partial l(\\mathbf w^{(t)}, z)$ $\\mathbb E[\\lambda \\mathbf w^{(t)}+\\mathbf v_t]$  $f$  $\\mathbf w^{(t)}$  $\\eta=\\frac 1 {\\lambda t}$\n\n$$\\begin{aligned}\\mathbf w^{(t+1)} &=\\mathbf w^{(t)}-\\frac 1 {\\lambda t}(\\lambda \\mathbf w^{(t)}+\\mathbf v_t)\n\\\\\\\\ &=\\left(1-\\frac 1 t\\right)\\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\left(\\frac {t-2}{t-1}\\mathbf w^{(t-1)}-\\frac 1 {\\lambda (t-1)}\\mathbf v_{t-1}\\right)-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-2} t \\mathbf w^{(t-1)}-\\frac 1 {\\lambda t} \\mathbf v_{t-1}-\\frac 1 {\\lambda t} \\mathbf v_t\\end{aligned}$$\n\n\n\n$$\\mathbf w^{(t+1)}=-\\frac 1 {\\lambda t}\\sum_{i=1}^t \\mathbf v_i$$\n\n$\\mathbf v_i$  hinge  $\\mathbf w^{(i)}$  $y\\mathbf w^{(i)\\top} \\mathbf x \\ge 1$  $0$ $y\\mathbf w^{(i)\\top} \\mathbf x < 1$  $-y\\mathbf x$ $\\boldsymbol {\\theta}^{(t)}=-\\sum_{i=1}^t \\mathbf v_i$ SGD \n\n### \n<center>SGD  Soft-SVM</center>\n\n****  $\\eqref{4}$\n\n**** $T$ \n\n**** $\\boldsymbol {\\theta}^{(1)}=\\mathbf 0$\n\n**for** $\\ t=1,\\cdots, T$\n\n&emsp; $\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol {\\theta}^{(t)}$\n\n&emsp;  $[m]$  $i$\n\n&emsp;  $\\ y_i\\mathbf w^{(t)\\top} \\mathbf x_i < 1$\n\n&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i$\n\n&emsp; \n\n&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}$\n\n**** $\\overline {\\mathbf w}=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}$\n\n $\\mathbf w^{T}$  $\\overline {\\mathbf w}=\\frac 1 {k} \\sum_{t=T-k+1}^T \\mathbf w^{(t)}$ latest k  $\\mathbf w{(t)}$  ","source":"_posts/ml/svm.md","raw":"---\ntitle: \ndate: 2021-09-22 16:04:37\ntags: machine learning\np: ml/svm\nmathjax: true\n---\n\n\n\n<!--more-->\n\n#  Hard-SVM\n\n $S=(\\mathbf x_1,y_1), \\cdots, (\\mathbf x_m, y_m)$ $\\mathbf x \\in \\mathbb R^d, \\ y \\in \\{1,-1\\}$\n\n$$\\forall i \\in [m], \\quad y_i (\\mathbf w^{\\top} \\mathbf x_i+b )>0$$\n\n halfspace $(\\mathbf w , b)$  ERM $L_S(h)=0$ $(\\mathbf w, b)$\n\n> \n\n\n\n## \n\n** $\\mathbf x$  $(\\mathbf w, b)$  $\\|\\mathbf w\\|=1$ $|\\mathbf w^{\\top}\\mathbf x+b|$**\n\n $\\|\\mathbf w\\|=1$  $a\\mathbf w \\mathbf x+ab=1, \\ \\forall a \\neq 0$ $\\mathbf w$ $b$ \n\n****\n\n\n\n$$\\min\\{\\|\\mathbf {x-v}: \\mathbf w^{\\top}\\mathbf v+b=0\\}$$\n\n $\\mathbf v=\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w$\n\n$$\\mathbf w^{\\top} \\mathbf v+b=\\mathbf w^{\\top}\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\|\\mathbf w\\|^2+b=0$$\n\n\n\n $\\mathbf x, \\ \\mathbf v$ \n\n$$\\|\\mathbf x-\\mathbf v\\|=|\\mathbf w^{\\top} \\mathbf x+b|\\|\\mathbf w\\|=|\\mathbf w^{\\top} \\mathbf x+b|$$\n\n $\\mathbf u$\n\n$$\\begin{aligned} \\Vert \\mathbf {x-u}\\Vert^2 &=\\|\\mathbf {x-v+v-u}\\|^2\n\\\\ &=\\|\\mathbf {x-v}\\|^2+\\|\\mathbf {v-u}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &\\ge\\|\\mathbf {x-v}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2+2(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2\\end{aligned}$$\n\n $\\mathbf v$  $\\mathbf w^{\\top}\\mathbf v=\\mathbf w^{\\top}\\mathbf u=-b$\n\n$\\mathbf x$  $\\|\\mathbf {x-v}\\|^2$ $|\\mathbf w^{\\top} \\mathbf x+b|$\n\n## Hard-SVM\n\nHard-SVM \n\n$$arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} |\\mathbf w^{\\top} \\mathbf x_i+b| \\quad s.t. \\ \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b)>0$$\n\n\n\n$$arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\quad(1)$$\n\n### \n\n $\\|\\mathbf w\\|=1$  $(\\mathbf w, b)$,  $\\gamma=\\min_{i \\in [m]} \\ y_i(\\mathbf w^{\\top}\\mathbf x_i+b)$ $\\forall i \\in [m]$ \n\n$$y_i (\\mathbf w^{\\top}\\mathbf x_i+b) \\ge \\gamma$$\n\n $\\gamma>0$\n\n$$y_i (\\frac {\\mathbf w^{\\top}} {\\gamma}\\mathbf x_i+\\frac {b}{\\gamma}) \\ge 1$$\n\n\n\n (1)  $\\gamma$ \n $\\|\\mathbf w\\|=1$\n $\\frac {\\|\\mathbf w^{\\top}\\|}{\\gamma}$ $b$  $\\mathbf w$ (1) \n\n$$arg \\min_{(\\mathbf w, b)}\\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1 \\quad(2)$$\n\n\n# Soft-SVM\n\nHard-SVM  Soft-SVM (2)  $\\{\\xi_i:\\xi_i \\ge 0, \\forall i \\in [m]\\}$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1-\\xi_i$ $\\|\\mathbf w\\|$  Hard-SVM  Soft-SVM \n\n<center>Soft-SVM</center>\n\n**input:** $(\\mathbf x_1, y_1), \\cdots (\\mathbf x_m, y_m)$\n\n**parameter:**  $\\lambda >0$ \n\n**solve:**\n\n$$\\min_{\\mathbf w, b, \\boldsymbol \\xi} \\left(\\lambda \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\xi_i\\right)$$\n$$s.t. \\ \\forall i, \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1- \\xi_i, \\ \\xi_i \\ge 0$$\n\n**output:** $\\mathbf w, b$\n\n hinge \n\n$$l(\\mathbf w, b, \\mathbf x, y)=\\max \\{0, 1-y(\\mathbf w^{\\top}\\mathbf x+b)\\}$$\n\n $S$  $L_S(\\mathbf w, b)$\n\n$$\\min_{\\mathbf w, b} (\\lambda \\|\\mathbf w\\|^2+L_S(\\mathbf w, b))$$\n\n $(\\mathbf w, b)$  $(\\mathbf x_i, y_i)$ $\\xi_i \\ge 0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1$ $\\xi_i=0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) < 1$ $1-y_i(\\mathbf w^{\\top} \\mathbf x_i+b) =\\xi_i$ $L_S(\\mathbf w, b)=\\frac 1 m \\sum_{i=1}^m \\xi_i$\n\n $0<\\xi<1$ $\\xi_i \\ge 1$ $i$ **Soft-SVM **\n\n\n## \n{% raw %}\nSVM  Hard-SVM  $\\mathbf w_0=\\frac {\\mathbf w^{\\ast}} {\\gamma^{\\ast}}$ $\\mathbf w^{\\ast}$  (1) $\\gamma^{\\ast}$  (1)  $\\forall i \\in [m], \\ y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)\\ge\\gamma^{\\ast}$ $\\mathbf w_0$ $\\{(\\mathbf x_i, y_i): y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)=\\gamma^{\\ast}\\}$  $\\gamma^{\\ast}$\n{% endraw %}\n\n $b=0$ $b$  $w_1$ $\\mathbf x$  $\\mathbf x_1=1$ Hard-SVM \n\n$$\\min_{\\mathbf w} \\ \\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i \\mathbf w^{\\top} \\mathbf x \\ge 1 \\quad(3)$$ \n\n $\\mathbf w_0$  $I=\\{\\mathbf x_i: |\\mathbf w_0^{\\top}\\mathbf x_i|=1\\}$** $\\alpha_1, \\cdots$ **\n\n$$\\mathbf w_0=\\sum_{i \\in I} \\alpha_i \\mathbf x_i$$\n\n\n\n## \n\n\n\n$$g(\\mathbf w)=\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)=\\begin{cases} 0 & \\forall i, \\ y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1 \\\\ \\infty & \\text{otherwise} \\end{cases}$$\n\n $\\alpha_i$  $y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1$ $\\forall i , \\ \\alpha=0$  $g(\\mathbf w)$  $0$$\\forall i, \\ \\alpha=\\infty$  $g(\\mathbf w)$  $\\infty$\n\n (3) \n\n$$\\min_{\\mathbf w}\\ (\\|\\mathbf w\\|^2+ g(\\mathbf w))$$\n\n\n\n$$\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)$$\n\n $\\frac 1 2$ \n\n$$\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)\\\\\\\\ \\ge\n \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)$$\n\n\n\n$$ \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)$$\n\n $\\boldsymbol \\alpha$  0 \n\n$$\\mathbf w-\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i=\\mathbf 0 \\Rightarrow \\mathbf w=\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i$$\n\n $\\mathbf w$ \n\n$$\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2+\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)\\right)$$\n\n\n\n$$\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2=\\frac 1 2 \\left(\\sum_i \\alpha_i y_i \\mathbf x_i^{\\top}\\right)\\left(\\sum_j \\alpha_j y_j \\mathbf x_j \\right)$$\n\n\n\n$$\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)=\\sum_i \\alpha_i-\\left(\\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\right)\\left(\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\right)$$\n\n\n\n$$\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\sum_{i=1}^m \\alpha_i-\\frac 1 2 \\sum_{1=1}^m \\sum_{j=1}^m \\alpha_i  \\alpha_j y_iy_j \\mathbf x_i^{\\top}\\mathbf x_j \\right)$$\n\n## SGD  Soft-SVM\n\n hinge  Soft-SVM \n\n$$\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\mathbf x_i\\}\\right) \\tag{4} \\label{4}$$\n\n $f(\\mathbf w)=\\frac {\\lambda} 2 \\|\\mathbf w\\|^2+L_S(\\mathbf w)$ \n\n $t$  $\\mathbf v_t \\in \\partial l_{\\mathcal D}(\\mathbf w^{(t)})$ $\\partial l_{\\mathcal D}(\\mathbf w^{(t)})$  $\\mathbf w^{(t)}$  $\\mathcal D$   $S$  $z$ $\\partial l(\\mathbf w^{(t)}, z)$ $\\mathbb E[\\lambda \\mathbf w^{(t)}+\\mathbf v_t]$  $f$  $\\mathbf w^{(t)}$  $\\eta=\\frac 1 {\\lambda t}$\n\n$$\\begin{aligned}\\mathbf w^{(t+1)} &=\\mathbf w^{(t)}-\\frac 1 {\\lambda t}(\\lambda \\mathbf w^{(t)}+\\mathbf v_t)\n\\\\\\\\ &=\\left(1-\\frac 1 t\\right)\\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\left(\\frac {t-2}{t-1}\\mathbf w^{(t-1)}-\\frac 1 {\\lambda (t-1)}\\mathbf v_{t-1}\\right)-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-2} t \\mathbf w^{(t-1)}-\\frac 1 {\\lambda t} \\mathbf v_{t-1}-\\frac 1 {\\lambda t} \\mathbf v_t\\end{aligned}$$\n\n\n\n$$\\mathbf w^{(t+1)}=-\\frac 1 {\\lambda t}\\sum_{i=1}^t \\mathbf v_i$$\n\n$\\mathbf v_i$  hinge  $\\mathbf w^{(i)}$  $y\\mathbf w^{(i)\\top} \\mathbf x \\ge 1$  $0$ $y\\mathbf w^{(i)\\top} \\mathbf x < 1$  $-y\\mathbf x$ $\\boldsymbol {\\theta}^{(t)}=-\\sum_{i=1}^t \\mathbf v_i$ SGD \n\n### \n<center>SGD  Soft-SVM</center>\n\n****  $\\eqref{4}$\n\n**** $T$ \n\n**** $\\boldsymbol {\\theta}^{(1)}=\\mathbf 0$\n\n**for** $\\ t=1,\\cdots, T$\n\n&emsp; $\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol {\\theta}^{(t)}$\n\n&emsp;  $[m]$  $i$\n\n&emsp;  $\\ y_i\\mathbf w^{(t)\\top} \\mathbf x_i < 1$\n\n&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i$\n\n&emsp; \n\n&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}$\n\n**** $\\overline {\\mathbf w}=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}$\n\n $\\mathbf w^{T}$  $\\overline {\\mathbf w}=\\frac 1 {k} \\sum_{t=T-k+1}^T \\mathbf w^{(t)}$ latest k  $\\mathbf w{(t)}$  ","slug":"ml/svm","published":1,"updated":"2021-09-30T08:15:48.519Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91c002rp0djeulw6nsi","content":"<p></p>\n<span id=\"more\"></span>\n<h1 id=\"-Hard-SVM\"><a href=\"#-Hard-SVM\" class=\"headerlink\" title=\" Hard-SVM\"></a> Hard-SVM</h1><p> $S=(\\mathbf x_1,y_1), \\cdots, (\\mathbf x_m, y_m)$ $\\mathbf x \\in \\mathbb R^d, \\ y \\in \\{1,-1\\}$</p>\n<script type=\"math/tex; mode=display\">\\forall i \\in [m], \\quad y_i (\\mathbf w^{\\top} \\mathbf x_i+b )>0</script><p> halfspace $(\\mathbf w , b)$  ERM $L_S(h)=0$ $(\\mathbf w, b)$</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong> $\\mathbf x$  $(\\mathbf w, b)$  $|\\mathbf w|=1$ $|\\mathbf w^{\\top}\\mathbf x+b|$</strong></p>\n<p> $|\\mathbf w|=1$  $a\\mathbf w \\mathbf x+ab=1, \\ \\forall a \\neq 0$ $\\mathbf w$ $b$ </p>\n<p><strong></strong></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\min\\{\\|\\mathbf {x-v}: \\mathbf w^{\\top}\\mathbf v+b=0\\}</script><p> $\\mathbf v=\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w$</p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top} \\mathbf v+b=\\mathbf w^{\\top}\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\|\\mathbf w\\|^2+b=0</script><p></p>\n<p> $\\mathbf x, \\ \\mathbf v$ </p>\n<script type=\"math/tex; mode=display\">\\|\\mathbf x-\\mathbf v\\|=|\\mathbf w^{\\top} \\mathbf x+b|\\|\\mathbf w\\|=|\\mathbf w^{\\top} \\mathbf x+b|</script><p> $\\mathbf u$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} \\Vert \\mathbf {x-u}\\Vert^2 &=\\|\\mathbf {x-v+v-u}\\|^2\n\\\\ &=\\|\\mathbf {x-v}\\|^2+\\|\\mathbf {v-u}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &\\ge\\|\\mathbf {x-v}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2+2(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2\\end{aligned}</script><p> $\\mathbf v$  $\\mathbf w^{\\top}\\mathbf v=\\mathbf w^{\\top}\\mathbf u=-b$</p>\n<p>$\\mathbf x$  $|\\mathbf {x-v}|^2$ $|\\mathbf w^{\\top} \\mathbf x+b|$</p>\n<h2 id=\"Hard-SVM\"><a href=\"#Hard-SVM\" class=\"headerlink\" title=\"Hard-SVM\"></a>Hard-SVM</h2><p>Hard-SVM </p>\n<script type=\"math/tex; mode=display\">arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} |\\mathbf w^{\\top} \\mathbf x_i+b| \\quad s.t. \\ \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b)>0</script><p></p>\n<script type=\"math/tex; mode=display\">arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\quad(1)</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> $|\\mathbf w|=1$  $(\\mathbf w, b)$,  $\\gamma=\\min_{i \\in [m]} \\ y_i(\\mathbf w^{\\top}\\mathbf x_i+b)$ $\\forall i \\in [m]$ </p>\n<script type=\"math/tex; mode=display\">y_i (\\mathbf w^{\\top}\\mathbf x_i+b) \\ge \\gamma</script><p> $\\gamma&gt;0$</p>\n<script type=\"math/tex; mode=display\">y_i (\\frac {\\mathbf w^{\\top}} {\\gamma}\\mathbf x_i+\\frac {b}{\\gamma}) \\ge 1</script><p> (1)  $\\gamma$ <br> $|\\mathbf w|=1$<br> $\\frac {|\\mathbf w^{\\top}|}{\\gamma}$ $b$  $\\mathbf w$ (1) </p>\n<script type=\"math/tex; mode=display\">arg \\min_{(\\mathbf w, b)}\\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1 \\quad(2)</script><h1 id=\"Soft-SVM\"><a href=\"#Soft-SVM\" class=\"headerlink\" title=\"Soft-SVM\"></a>Soft-SVM</h1><p>Hard-SVM  Soft-SVM (2)  $\\{\\xi_i:\\xi_i \\ge 0, \\forall i \\in [m]\\}$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1-\\xi_i$ $|\\mathbf w|$  Hard-SVM  Soft-SVM </p>\n<center>Soft-SVM</center>\n\n<p><strong>input:</strong> $(\\mathbf x_1, y_1), \\cdots (\\mathbf x_m, y_m)$</p>\n<p><strong>parameter:</strong>  $\\lambda &gt;0$ </p>\n<p><strong>solve:</strong></p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w, b, \\boldsymbol \\xi} \\left(\\lambda \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\xi_i\\right)</script><script type=\"math/tex; mode=display\">s.t. \\ \\forall i, \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1- \\xi_i, \\ \\xi_i \\ge 0</script><p><strong>output:</strong> $\\mathbf w, b$</p>\n<p> hinge </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, b, \\mathbf x, y)=\\max \\{0, 1-y(\\mathbf w^{\\top}\\mathbf x+b)\\}</script><p> $S$  $L_S(\\mathbf w, b)$</p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w, b} (\\lambda \\|\\mathbf w\\|^2+L_S(\\mathbf w, b))</script><p> $(\\mathbf w, b)$  $(\\mathbf x_i, y_i)$ $\\xi_i \\ge 0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1$ $\\xi_i=0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) &lt; 1$ $1-y_i(\\mathbf w^{\\top} \\mathbf x_i+b) =\\xi_i$ $L_S(\\mathbf w, b)=\\frac 1 m \\sum_{i=1}^m \\xi_i$</p>\n<p> $0&lt;\\xi&lt;1$ $\\xi_i \\ge 1$ $i$ <strong>Soft-SVM </strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>\nSVM  Hard-SVM  $\\mathbf w_0=\\frac {\\mathbf w^{\\ast}} {\\gamma^{\\ast}}$ $\\mathbf w^{\\ast}$  (1) $\\gamma^{\\ast}$  (1)  $\\forall i \\in [m], \\ y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)\\ge\\gamma^{\\ast}$ $\\mathbf w_0$ $\\{(\\mathbf x_i, y_i): y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)=\\gamma^{\\ast}\\}$  $\\gamma^{\\ast}$\n\n<p> $b=0$ $b$  $w_1$ $\\mathbf x$  $\\mathbf x_1=1$ Hard-SVM </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\ \\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i \\mathbf w^{\\top} \\mathbf x \\ge 1 \\quad(3)</script><p> $\\mathbf w_0$  $I=\\{\\mathbf x_i: |\\mathbf w_0^{\\top}\\mathbf x_i|=1\\}$<strong> $\\alpha_1, \\cdots$ </strong></p>\n<script type=\"math/tex; mode=display\">\\mathbf w_0=\\sum_{i \\in I} \\alpha_i \\mathbf x_i</script><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">g(\\mathbf w)=\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)=\\begin{cases} 0 & \\forall i, \\ y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1 \\\\ \\infty & \\text{otherwise} \\end{cases}</script><p> $\\alpha_i$  $y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1$ $\\forall i , \\ \\alpha=0$  $g(\\mathbf w)$  $0$$\\forall i, \\ \\alpha=\\infty$  $g(\\mathbf w)$  $\\infty$</p>\n<p> (3) </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w}\\ (\\|\\mathbf w\\|^2+ g(\\mathbf w))</script><p></p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)</script><p> $\\frac 1 2$ </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)\\\\\\\\ \\ge\n \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)</script><p> $\\boldsymbol \\alpha$  0 </p>\n<script type=\"math/tex; mode=display\">\\mathbf w-\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i=\\mathbf 0 \\Rightarrow \\mathbf w=\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i</script><p> $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2+\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)\\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2=\\frac 1 2 \\left(\\sum_i \\alpha_i y_i \\mathbf x_i^{\\top}\\right)\\left(\\sum_j \\alpha_j y_j \\mathbf x_j \\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)=\\sum_i \\alpha_i-\\left(\\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\right)\\left(\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\sum_{i=1}^m \\alpha_i-\\frac 1 2 \\sum_{1=1}^m \\sum_{j=1}^m \\alpha_i  \\alpha_j y_iy_j \\mathbf x_i^{\\top}\\mathbf x_j \\right)</script><h2 id=\"SGD--Soft-SVM\"><a href=\"#SGD--Soft-SVM\" class=\"headerlink\" title=\"SGD  Soft-SVM\"></a>SGD  Soft-SVM</h2><p> hinge  Soft-SVM </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\mathbf x_i\\}\\right) \\tag{4} \\label{4}</script><p> $f(\\mathbf w)=\\frac {\\lambda} 2 |\\mathbf w|^2+L_S(\\mathbf w)$ </p>\n<p> $t$  $\\mathbf v_t \\in \\partial l_{\\mathcal D}(\\mathbf w^{(t)})$ $\\partial l_{\\mathcal D}(\\mathbf w^{(t)})$  $\\mathbf w^{(t)}$  $\\mathcal D$   $S$  $z$ $\\partial l(\\mathbf w^{(t)}, z)$ $\\mathbb E[\\lambda \\mathbf w^{(t)}+\\mathbf v_t]$  $f$  $\\mathbf w^{(t)}$  $\\eta=\\frac 1 {\\lambda t}$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\mathbf w^{(t+1)} &=\\mathbf w^{(t)}-\\frac 1 {\\lambda t}(\\lambda \\mathbf w^{(t)}+\\mathbf v_t)\n\\\\\\\\ &=\\left(1-\\frac 1 t\\right)\\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\left(\\frac {t-2}{t-1}\\mathbf w^{(t-1)}-\\frac 1 {\\lambda (t-1)}\\mathbf v_{t-1}\\right)-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-2} t \\mathbf w^{(t-1)}-\\frac 1 {\\lambda t} \\mathbf v_{t-1}-\\frac 1 {\\lambda t} \\mathbf v_t\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{(t+1)}=-\\frac 1 {\\lambda t}\\sum_{i=1}^t \\mathbf v_i</script><p>$\\mathbf v_i$  hinge  $\\mathbf w^{(i)}$  $y\\mathbf w^{(i)\\top} \\mathbf x \\ge 1$  $0$ $y\\mathbf w^{(i)\\top} \\mathbf x &lt; 1$  $-y\\mathbf x$ $\\boldsymbol {\\theta}^{(t)}=-\\sum_{i=1}^t \\mathbf v_i$ SGD </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><center>SGD  Soft-SVM</center>\n\n<p><strong></strong>  $\\eqref{4}$</p>\n<p><strong></strong> $T$ </p>\n<p><strong></strong> $\\boldsymbol {\\theta}^{(1)}=\\mathbf 0$</p>\n<p><strong>for</strong> $\\ t=1,\\cdots, T$</p>\n<p>&emsp; $\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol {\\theta}^{(t)}$</p>\n<p>&emsp;  $[m]$  $i$</p>\n<p>&emsp;  $\\ y_i\\mathbf w^{(t)\\top} \\mathbf x_i &lt; 1$</p>\n<p>&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i$</p>\n<p>&emsp; </p>\n<p>&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}$</p>\n<p><strong></strong> $\\overline {\\mathbf w}=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}$</p>\n<p> $\\mathbf w^{T}$  $\\overline {\\mathbf w}=\\frac 1 {k} \\sum_{t=T-k+1}^T \\mathbf w^{(t)}$ latest k  $\\mathbf w{(t)}$  </p>\n","site":{"data":{}},"excerpt":"<p></p>","more":"<h1 id=\"-Hard-SVM\"><a href=\"#-Hard-SVM\" class=\"headerlink\" title=\" Hard-SVM\"></a> Hard-SVM</h1><p> $S=(\\mathbf x_1,y_1), \\cdots, (\\mathbf x_m, y_m)$ $\\mathbf x \\in \\mathbb R^d, \\ y \\in \\{1,-1\\}$</p>\n<script type=\"math/tex; mode=display\">\\forall i \\in [m], \\quad y_i (\\mathbf w^{\\top} \\mathbf x_i+b )>0</script><p> halfspace $(\\mathbf w , b)$  ERM $L_S(h)=0$ $(\\mathbf w, b)$</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong> $\\mathbf x$  $(\\mathbf w, b)$  $|\\mathbf w|=1$ $|\\mathbf w^{\\top}\\mathbf x+b|$</strong></p>\n<p> $|\\mathbf w|=1$  $a\\mathbf w \\mathbf x+ab=1, \\ \\forall a \\neq 0$ $\\mathbf w$ $b$ </p>\n<p><strong></strong></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\min\\{\\|\\mathbf {x-v}: \\mathbf w^{\\top}\\mathbf v+b=0\\}</script><p> $\\mathbf v=\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w$</p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{\\top} \\mathbf v+b=\\mathbf w^{\\top}\\mathbf x-(\\mathbf w^{\\top} \\mathbf x+b)\\|\\mathbf w\\|^2+b=0</script><p></p>\n<p> $\\mathbf x, \\ \\mathbf v$ </p>\n<script type=\"math/tex; mode=display\">\\|\\mathbf x-\\mathbf v\\|=|\\mathbf w^{\\top} \\mathbf x+b|\\|\\mathbf w\\|=|\\mathbf w^{\\top} \\mathbf x+b|</script><p> $\\mathbf u$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} \\Vert \\mathbf {x-u}\\Vert^2 &=\\|\\mathbf {x-v+v-u}\\|^2\n\\\\ &=\\|\\mathbf {x-v}\\|^2+\\|\\mathbf {v-u}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &\\ge\\|\\mathbf {x-v}\\|^2+2(\\mathbf {x-v})^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2+2(\\mathbf w^{\\top} \\mathbf x+b)\\mathbf w^{\\top}(\\mathbf {v-u})\n\\\\ &=\\|\\mathbf {x-v}\\|^2\\end{aligned}</script><p> $\\mathbf v$  $\\mathbf w^{\\top}\\mathbf v=\\mathbf w^{\\top}\\mathbf u=-b$</p>\n<p>$\\mathbf x$  $|\\mathbf {x-v}|^2$ $|\\mathbf w^{\\top} \\mathbf x+b|$</p>\n<h2 id=\"Hard-SVM\"><a href=\"#Hard-SVM\" class=\"headerlink\" title=\"Hard-SVM\"></a>Hard-SVM</h2><p>Hard-SVM </p>\n<script type=\"math/tex; mode=display\">arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} |\\mathbf w^{\\top} \\mathbf x_i+b| \\quad s.t. \\ \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b)>0</script><p></p>\n<script type=\"math/tex; mode=display\">arg \\max_{(\\mathbf w, b): \\|\\mathbf w\\|=1} \\ \\min_{i \\in [m]} y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\quad(1)</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> $|\\mathbf w|=1$  $(\\mathbf w, b)$,  $\\gamma=\\min_{i \\in [m]} \\ y_i(\\mathbf w^{\\top}\\mathbf x_i+b)$ $\\forall i \\in [m]$ </p>\n<script type=\"math/tex; mode=display\">y_i (\\mathbf w^{\\top}\\mathbf x_i+b) \\ge \\gamma</script><p> $\\gamma&gt;0$</p>\n<script type=\"math/tex; mode=display\">y_i (\\frac {\\mathbf w^{\\top}} {\\gamma}\\mathbf x_i+\\frac {b}{\\gamma}) \\ge 1</script><p> (1)  $\\gamma$ <br> $|\\mathbf w|=1$<br> $\\frac {|\\mathbf w^{\\top}|}{\\gamma}$ $b$  $\\mathbf w$ (1) </p>\n<script type=\"math/tex; mode=display\">arg \\min_{(\\mathbf w, b)}\\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1 \\quad(2)</script><h1 id=\"Soft-SVM\"><a href=\"#Soft-SVM\" class=\"headerlink\" title=\"Soft-SVM\"></a>Soft-SVM</h1><p>Hard-SVM  Soft-SVM (2)  $\\{\\xi_i:\\xi_i \\ge 0, \\forall i \\in [m]\\}$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1-\\xi_i$ $|\\mathbf w|$  Hard-SVM  Soft-SVM </p>\n<center>Soft-SVM</center>\n\n<p><strong>input:</strong> $(\\mathbf x_1, y_1), \\cdots (\\mathbf x_m, y_m)$</p>\n<p><strong>parameter:</strong>  $\\lambda &gt;0$ </p>\n<p><strong>solve:</strong></p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w, b, \\boldsymbol \\xi} \\left(\\lambda \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\xi_i\\right)</script><script type=\"math/tex; mode=display\">s.t. \\ \\forall i, \\ y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1- \\xi_i, \\ \\xi_i \\ge 0</script><p><strong>output:</strong> $\\mathbf w, b$</p>\n<p> hinge </p>\n<script type=\"math/tex; mode=display\">l(\\mathbf w, b, \\mathbf x, y)=\\max \\{0, 1-y(\\mathbf w^{\\top}\\mathbf x+b)\\}</script><p> $S$  $L_S(\\mathbf w, b)$</p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w, b} (\\lambda \\|\\mathbf w\\|^2+L_S(\\mathbf w, b))</script><p> $(\\mathbf w, b)$  $(\\mathbf x_i, y_i)$ $\\xi_i \\ge 0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) \\ge 1$ $\\xi_i=0$ $y_i(\\mathbf w^{\\top} \\mathbf x_i+b) &lt; 1$ $1-y_i(\\mathbf w^{\\top} \\mathbf x_i+b) =\\xi_i$ $L_S(\\mathbf w, b)=\\frac 1 m \\sum_{i=1}^m \\xi_i$</p>\n<p> $0&lt;\\xi&lt;1$ $\\xi_i \\ge 1$ $i$ <strong>Soft-SVM </strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>\nSVM  Hard-SVM  $\\mathbf w_0=\\frac {\\mathbf w^{\\ast}} {\\gamma^{\\ast}}$ $\\mathbf w^{\\ast}$  (1) $\\gamma^{\\ast}$  (1)  $\\forall i \\in [m], \\ y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)\\ge\\gamma^{\\ast}$ $\\mathbf w_0$ $\\{(\\mathbf x_i, y_i): y_i(\\mathbf w^{{\\ast}\\top} \\mathbf x_i+b)=\\gamma^{\\ast}\\}$  $\\gamma^{\\ast}$\n\n<p> $b=0$ $b$  $w_1$ $\\mathbf x$  $\\mathbf x_1=1$ Hard-SVM </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\ \\|\\mathbf w\\|^2 \\quad s.t. \\quad \\forall i \\in [m], \\ y_i \\mathbf w^{\\top} \\mathbf x \\ge 1 \\quad(3)</script><p> $\\mathbf w_0$  $I=\\{\\mathbf x_i: |\\mathbf w_0^{\\top}\\mathbf x_i|=1\\}$<strong> $\\alpha_1, \\cdots$ </strong></p>\n<script type=\"math/tex; mode=display\">\\mathbf w_0=\\sum_{i \\in I} \\alpha_i \\mathbf x_i</script><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">g(\\mathbf w)=\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)=\\begin{cases} 0 & \\forall i, \\ y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1 \\\\ \\infty & \\text{otherwise} \\end{cases}</script><p> $\\alpha_i$  $y_i(\\mathbf w^{\\top}\\mathbf x_i) \\ge 1$ $\\forall i , \\ \\alpha=0$  $g(\\mathbf w)$  $0$$\\forall i, \\ \\alpha=\\infty$  $g(\\mathbf w)$  $\\infty$</p>\n<p> (3) </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w}\\ (\\|\\mathbf w\\|^2+ g(\\mathbf w))</script><p></p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)</script><p> $\\frac 1 2$ </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)\\\\\\\\ \\ge\n \\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\min_{\\mathbf w} \\left(\\frac 1 2 \\|\\mathbf w\\|^2+\\sum_{i=1}^m \\alpha_i (1-y_i \\mathbf w^{\\top}\\mathbf x_i)\\right)</script><p> $\\boldsymbol \\alpha$  0 </p>\n<script type=\"math/tex; mode=display\">\\mathbf w-\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i=\\mathbf 0 \\Rightarrow \\mathbf w=\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i</script><p> $\\mathbf w$ </p>\n<script type=\"math/tex; mode=display\">\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2+\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)\\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac 1 2 \\|\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\|^2=\\frac 1 2 \\left(\\sum_i \\alpha_i y_i \\mathbf x_i^{\\top}\\right)\\left(\\sum_j \\alpha_j y_j \\mathbf x_j \\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\sum_{i=1}^m \\alpha_i \\left(1-y_i \\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\mathbf x_i \\right)=\\sum_i \\alpha_i-\\left(\\sum_{j=1}^m \\alpha_j y_j \\mathbf x_j^{\\top}\\right)\\left(\\sum_{i=1}^m \\alpha_i y_i \\mathbf x_i\\right)</script><p></p>\n<script type=\"math/tex; mode=display\">\\max_{\\boldsymbol \\alpha \\in \\mathbb R^m:\\boldsymbol \\alpha \\ge \\mathbf 0} \\left(\\sum_{i=1}^m \\alpha_i-\\frac 1 2 \\sum_{1=1}^m \\sum_{j=1}^m \\alpha_i  \\alpha_j y_iy_j \\mathbf x_i^{\\top}\\mathbf x_j \\right)</script><h2 id=\"SGD--Soft-SVM\"><a href=\"#SGD--Soft-SVM\" class=\"headerlink\" title=\"SGD  Soft-SVM\"></a>SGD  Soft-SVM</h2><p> hinge  Soft-SVM </p>\n<script type=\"math/tex; mode=display\">\\min_{\\mathbf w} \\left(\\frac {\\lambda} 2 \\|\\mathbf w\\|^2 + \\frac 1 m \\sum_{i=1}^m \\max \\{0, 1-y_i \\mathbf w^{\\top} \\mathbf x_i\\}\\right) \\tag{4} \\label{4}</script><p> $f(\\mathbf w)=\\frac {\\lambda} 2 |\\mathbf w|^2+L_S(\\mathbf w)$ </p>\n<p> $t$  $\\mathbf v_t \\in \\partial l_{\\mathcal D}(\\mathbf w^{(t)})$ $\\partial l_{\\mathcal D}(\\mathbf w^{(t)})$  $\\mathbf w^{(t)}$  $\\mathcal D$   $S$  $z$ $\\partial l(\\mathbf w^{(t)}, z)$ $\\mathbb E[\\lambda \\mathbf w^{(t)}+\\mathbf v_t]$  $f$  $\\mathbf w^{(t)}$  $\\eta=\\frac 1 {\\lambda t}$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\mathbf w^{(t+1)} &=\\mathbf w^{(t)}-\\frac 1 {\\lambda t}(\\lambda \\mathbf w^{(t)}+\\mathbf v_t)\n\\\\\\\\ &=\\left(1-\\frac 1 t\\right)\\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\mathbf w^{(t)}-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-1} t \\left(\\frac {t-2}{t-1}\\mathbf w^{(t-1)}-\\frac 1 {\\lambda (t-1)}\\mathbf v_{t-1}\\right)-\\frac 1 {\\lambda t} \\mathbf v_t\n\\\\\\\\ &=\\frac {t-2} t \\mathbf w^{(t-1)}-\\frac 1 {\\lambda t} \\mathbf v_{t-1}-\\frac 1 {\\lambda t} \\mathbf v_t\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf w^{(t+1)}=-\\frac 1 {\\lambda t}\\sum_{i=1}^t \\mathbf v_i</script><p>$\\mathbf v_i$  hinge  $\\mathbf w^{(i)}$  $y\\mathbf w^{(i)\\top} \\mathbf x \\ge 1$  $0$ $y\\mathbf w^{(i)\\top} \\mathbf x &lt; 1$  $-y\\mathbf x$ $\\boldsymbol {\\theta}^{(t)}=-\\sum_{i=1}^t \\mathbf v_i$ SGD </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><center>SGD  Soft-SVM</center>\n\n<p><strong></strong>  $\\eqref{4}$</p>\n<p><strong></strong> $T$ </p>\n<p><strong></strong> $\\boldsymbol {\\theta}^{(1)}=\\mathbf 0$</p>\n<p><strong>for</strong> $\\ t=1,\\cdots, T$</p>\n<p>&emsp; $\\mathbf w^{(t)}=\\frac 1 {\\lambda t} \\boldsymbol {\\theta}^{(t)}$</p>\n<p>&emsp;  $[m]$  $i$</p>\n<p>&emsp;  $\\ y_i\\mathbf w^{(t)\\top} \\mathbf x_i &lt; 1$</p>\n<p>&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}-\\mathbf v_t=\\boldsymbol {\\theta}^{(t)}+y_i \\mathbf x_i$</p>\n<p>&emsp; </p>\n<p>&emsp; &emsp; $\\boldsymbol {\\theta}^{(t+1)}=\\boldsymbol {\\theta}^{(t)}$</p>\n<p><strong></strong> $\\overline {\\mathbf w}=\\frac 1 T \\sum_{t=1}^T \\mathbf w^{(t)}$</p>\n<p> $\\mathbf w^{T}$  $\\overline {\\mathbf w}=\\frac 1 {k} \\sum_{t=T-k+1}^T \\mathbf w^{(t)}$ latest k  $\\mathbf w{(t)}$  </p>"},{"title":"YOLO","date":"2020-04-20T05:58:33.000Z","p":"obj_det/YOLO","mathjax":true,"_content":"\n# YOLOv1\n## \none-stage bbox \n1. YOLO  45 \n2. \n3. \n\n<!-- more -->\n\n## \nYOLOv1 1 VOC \n![](/images/obj_det/YOLOv1_fig1.jpg) <center> 1 YOLOv1 </center>\n\n shape : `448,448,3`\n shape `7,7,35`\n\n### \n\n1.  `SxS`  grid cell grid cell  VOC  `S=7`\n3.  grid cell  `B`  box `B=3`\n4.  box  5  `(x,y,w,h,IOU)`\n5. VOC  `C=20` grid cell  `C`  grid cell  `B`  box  `C` `B`  box   box \n2.  `448`  `7` `448/7=64` 1  `s-2`  layer  6  map  spatial size  `7x7`channel  `35` `B*5+C=3*5+20` \n6. \n7.  `S*S*B`  box box  4 1  IOU  C  0.2 box  box  0 0.4 box 0.2\n\n____  grid cell  1  box  box\n\n____  grid cell`x,y,w,h,IOU,class` gt `Y`  grid cell  box box  size  aspect ratio grid cell `B`  box  IOU  box  box  box \n\n### \n\n$$\\begin{aligned} L&=\\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(x_i-\\hat x_i)^2+(y_i-\\hat y_i)^2 \\\\\\\\ &+ \\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(\\sqrt {w_i}- \\sqrt {\\hat w_i})^2+(\\sqrt {h_i}- \\sqrt {\\hat h_i})^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (C_i-\\hat C_i)^2 \\\\\\\\ &+ \\lambda_{noobj} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}(C_i-\\hat C_i)^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2} \\mathbf 1_i^{obj} \\sum_{c \\in classes}\\left(p_i(c)-\\hat p_i(c)\\right)^2 \\end{aligned}\n$$\n\n____\n\n `^`  `^`  ground truth `x, y, w, h` `C`  IOU`pi(c)`  `c` \n\n$\\mathbf 1_{ij}^{obj}$  `i`  grid cell  grid cell  `j`  box  gt box  IOU `j` box \n\n box   box$\\Delta w, \\ \\Delta h$  box  box  `w,h`\n\n$\\mathbf 1_{ij}^{noobj}$  i)  `i`  grid cell  ii)  `j`  box  gt box  IOU  `B`  box \n\n$\\mathbf 1_i^{obj}$  `i`  grid cell \n\n box  box  IOU  box  IOU  $\\lambda_{coord}=5, \\ \\lambda_{noobj}=0.5$\n\n## \n1. GT label  size  `S*S*(5+20)` `5`  4 1  IOU20  id  one-hot vector  `(S,S,5+20)` IOU, class id, x,y,w,h\n2.  size  `S*S*(B*5+20)` `(5+20,S,S)` class id, IOU, x,y,w,h\n3. GT label  x,y,w,h / `x=x*S-(int)x*S, y=y*S-(int)y*S`\n4.  x,y  GT label  grid cell  w,h \n\n\n# YOLOv2\n## \nYOLOv2  YOLOv1 \n1. \n2.  Batch Normalization\n3. \n\nYOLOv1  `224x224`  `448x448` YOLOv2  batch  size\n\n## \n VOC YOLOv2  `cfg/yolov2-voc.cfg` \n### \n1.  size  10  batch  `320, 352, ..., 608`  `(3,d,d)`\n2.  32 `(125, d/32, d/32)``(d/32,d/32)`  YOLOv1  grid cell  `S=d/32` grid cell grid cell  grid cell  `5`  box box  `1`  IOU  `4`  box  `20`  channel  `125=5*(1+4+20)`YOLOv1  cell  `B`  box  `20` \n\n3.  30 GT label  `30x5` `5`  4  1  id x,h,w,h,class idGT label \n4. `(route:-1-4)`  ResNet  identity mapping\n\n### \n\n\n$$L=L_p+L_{box}+L_C$$\n\n____\n\n$$L_p=\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\sum_{c=1}^{20} \\mathbf 1_{ij}^{obj} [\\hat p_{ij}(c)-p_{ij}(c)]^2$$\n\n____\n\n$$\\begin{aligned}L_{box}&=\\lambda_{obj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (\\hat x_{ij} - x_{ij})^2 + (\\hat y_{ij} - y_{ij})^2+ (\\hat w_{ij} - w_{ij})^2+ (\\hat h_{ij} - h_{ij})^2 \n\\\\ &+ \\lambda_{noobj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{noobj} (\\hat x_{ij} - x_{ij}^a)^2 + (\\hat y_{ij} - y_{ij}^a)^2+ (\\hat w_{ij} - w_{ij}^a)^2+ (\\hat h_{ij} - h_{ij}^a)^2 \\end{aligned}$$\n\n____\n\n$$\\begin{aligned}L_C &=\\lambda_{obj}^{conf}\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj}[\\hat C_{ij}-iou(\\hat \\text{box}_{ij}, \\text{box}_{ij})]^2  \n\\\\&+ \\lambda_{noobj}^{conf}\\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}[\\hat C_{ij}-0]^2 \\end{aligned}$$\n\n ^  network  a  anchor GT label\n\n____\n\n shape `batch, B, 4+1+C, S, S` feature map  height  width  `S` grid size `4`  4 `1`  IOU`C` \n\n YOLOv1  grid cell grid cell  grid cell  `B=5`  box size 5  anchor box  yolov2-voc.cfg  layer  `anchors`  5  width height  feature map  size `SxS`anchor box  grid cell  0.5 `(i,j)`  grid cell  anchor box  `(i+0.5, j+0.5)`\n\n `x,y,h,w`  2\n![](/images/obj_det/YOLOv2_fig2.png) <center>2  box  anchor box </center>\n\n $\\sigma(t_x), \\sigma(t_y), t_w, t_h$\n\n GT label  size  `30*5` `x,y,w,h, class id` `x,y,w,h`  original image  size `x,y`  YOLOv1 \n\n\n $x_{ij}, y_{ij}, w_{ij}, h_{ij}$  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$ GT box  anchor box box  GT box  anchor box  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$\n\n location `(i,j)`  `B`  box  GT label  box  IOU IOU IOU  0.5 $\\mathbf 1_{ij}^{noobj}=0$ 0\n\n GT box GT box  IOU  box IOU  $\\mathbf 1_{ij}^{obj}=1$ GT box  box$\\sum_{c=1}^C$  `c`  GT label  class id $p_{ij}(c)=1$ `C-1`  $p_{ij}(c)=0$\n\n# YOLOv3\n YOLOv2 \n1.  scale  feature maps feature maps  `NxNx[3*(4+1+C)]` `N` 2 \n2.  `9`  scale  anchor box  `3`  scale  feature maps scale  feature maps  grid cell  `9/3=3`  anchor box\n\n VOC  `cfg/yolov3-voc.cfg`\n\n1.  `32` `(h,w)`feature map  `(h/32,w/32)` scale  feature maps  `(h/16,w/16)`  `(h/8, w/8)`\n2.  GT label   `90*5` `90`\n3.  Residual layer\n","source":"_posts/obj_det/YOLO.md","raw":"---\ntitle: YOLO\ndate: 2020-04-20 13:58:33\np: obj_det/YOLO\ntags: object detection\nmathjax: true\n---\n\n# YOLOv1\n## \none-stage bbox \n1. YOLO  45 \n2. \n3. \n\n<!-- more -->\n\n## \nYOLOv1 1 VOC \n![](/images/obj_det/YOLOv1_fig1.jpg) <center> 1 YOLOv1 </center>\n\n shape : `448,448,3`\n shape `7,7,35`\n\n### \n\n1.  `SxS`  grid cell grid cell  VOC  `S=7`\n3.  grid cell  `B`  box `B=3`\n4.  box  5  `(x,y,w,h,IOU)`\n5. VOC  `C=20` grid cell  `C`  grid cell  `B`  box  `C` `B`  box   box \n2.  `448`  `7` `448/7=64` 1  `s-2`  layer  6  map  spatial size  `7x7`channel  `35` `B*5+C=3*5+20` \n6. \n7.  `S*S*B`  box box  4 1  IOU  C  0.2 box  box  0 0.4 box 0.2\n\n____  grid cell  1  box  box\n\n____  grid cell`x,y,w,h,IOU,class` gt `Y`  grid cell  box box  size  aspect ratio grid cell `B`  box  IOU  box  box  box \n\n### \n\n$$\\begin{aligned} L&=\\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(x_i-\\hat x_i)^2+(y_i-\\hat y_i)^2 \\\\\\\\ &+ \\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(\\sqrt {w_i}- \\sqrt {\\hat w_i})^2+(\\sqrt {h_i}- \\sqrt {\\hat h_i})^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (C_i-\\hat C_i)^2 \\\\\\\\ &+ \\lambda_{noobj} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}(C_i-\\hat C_i)^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2} \\mathbf 1_i^{obj} \\sum_{c \\in classes}\\left(p_i(c)-\\hat p_i(c)\\right)^2 \\end{aligned}\n$$\n\n____\n\n `^`  `^`  ground truth `x, y, w, h` `C`  IOU`pi(c)`  `c` \n\n$\\mathbf 1_{ij}^{obj}$  `i`  grid cell  grid cell  `j`  box  gt box  IOU `j` box \n\n box   box$\\Delta w, \\ \\Delta h$  box  box  `w,h`\n\n$\\mathbf 1_{ij}^{noobj}$  i)  `i`  grid cell  ii)  `j`  box  gt box  IOU  `B`  box \n\n$\\mathbf 1_i^{obj}$  `i`  grid cell \n\n box  box  IOU  box  IOU  $\\lambda_{coord}=5, \\ \\lambda_{noobj}=0.5$\n\n## \n1. GT label  size  `S*S*(5+20)` `5`  4 1  IOU20  id  one-hot vector  `(S,S,5+20)` IOU, class id, x,y,w,h\n2.  size  `S*S*(B*5+20)` `(5+20,S,S)` class id, IOU, x,y,w,h\n3. GT label  x,y,w,h / `x=x*S-(int)x*S, y=y*S-(int)y*S`\n4.  x,y  GT label  grid cell  w,h \n\n\n# YOLOv2\n## \nYOLOv2  YOLOv1 \n1. \n2.  Batch Normalization\n3. \n\nYOLOv1  `224x224`  `448x448` YOLOv2  batch  size\n\n## \n VOC YOLOv2  `cfg/yolov2-voc.cfg` \n### \n1.  size  10  batch  `320, 352, ..., 608`  `(3,d,d)`\n2.  32 `(125, d/32, d/32)``(d/32,d/32)`  YOLOv1  grid cell  `S=d/32` grid cell grid cell  grid cell  `5`  box box  `1`  IOU  `4`  box  `20`  channel  `125=5*(1+4+20)`YOLOv1  cell  `B`  box  `20` \n\n3.  30 GT label  `30x5` `5`  4  1  id x,h,w,h,class idGT label \n4. `(route:-1-4)`  ResNet  identity mapping\n\n### \n\n\n$$L=L_p+L_{box}+L_C$$\n\n____\n\n$$L_p=\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\sum_{c=1}^{20} \\mathbf 1_{ij}^{obj} [\\hat p_{ij}(c)-p_{ij}(c)]^2$$\n\n____\n\n$$\\begin{aligned}L_{box}&=\\lambda_{obj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (\\hat x_{ij} - x_{ij})^2 + (\\hat y_{ij} - y_{ij})^2+ (\\hat w_{ij} - w_{ij})^2+ (\\hat h_{ij} - h_{ij})^2 \n\\\\ &+ \\lambda_{noobj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{noobj} (\\hat x_{ij} - x_{ij}^a)^2 + (\\hat y_{ij} - y_{ij}^a)^2+ (\\hat w_{ij} - w_{ij}^a)^2+ (\\hat h_{ij} - h_{ij}^a)^2 \\end{aligned}$$\n\n____\n\n$$\\begin{aligned}L_C &=\\lambda_{obj}^{conf}\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj}[\\hat C_{ij}-iou(\\hat \\text{box}_{ij}, \\text{box}_{ij})]^2  \n\\\\&+ \\lambda_{noobj}^{conf}\\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}[\\hat C_{ij}-0]^2 \\end{aligned}$$\n\n ^  network  a  anchor GT label\n\n____\n\n shape `batch, B, 4+1+C, S, S` feature map  height  width  `S` grid size `4`  4 `1`  IOU`C` \n\n YOLOv1  grid cell grid cell  grid cell  `B=5`  box size 5  anchor box  yolov2-voc.cfg  layer  `anchors`  5  width height  feature map  size `SxS`anchor box  grid cell  0.5 `(i,j)`  grid cell  anchor box  `(i+0.5, j+0.5)`\n\n `x,y,h,w`  2\n![](/images/obj_det/YOLOv2_fig2.png) <center>2  box  anchor box </center>\n\n $\\sigma(t_x), \\sigma(t_y), t_w, t_h$\n\n GT label  size  `30*5` `x,y,w,h, class id` `x,y,w,h`  original image  size `x,y`  YOLOv1 \n\n\n $x_{ij}, y_{ij}, w_{ij}, h_{ij}$  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$ GT box  anchor box box  GT box  anchor box  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$\n\n location `(i,j)`  `B`  box  GT label  box  IOU IOU IOU  0.5 $\\mathbf 1_{ij}^{noobj}=0$ 0\n\n GT box GT box  IOU  box IOU  $\\mathbf 1_{ij}^{obj}=1$ GT box  box$\\sum_{c=1}^C$  `c`  GT label  class id $p_{ij}(c)=1$ `C-1`  $p_{ij}(c)=0$\n\n# YOLOv3\n YOLOv2 \n1.  scale  feature maps feature maps  `NxNx[3*(4+1+C)]` `N` 2 \n2.  `9`  scale  anchor box  `3`  scale  feature maps scale  feature maps  grid cell  `9/3=3`  anchor box\n\n VOC  `cfg/yolov3-voc.cfg`\n\n1.  `32` `(h,w)`feature map  `(h/32,w/32)` scale  feature maps  `(h/16,w/16)`  `(h/8, w/8)`\n2.  GT label   `90*5` `90`\n3.  Residual layer\n","slug":"obj_det/YOLO","published":1,"updated":"2021-02-23T08:14:31.583Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91d002up0dje4eb95rx","content":"<h1 id=\"YOLOv1\"><a href=\"#YOLOv1\" class=\"headerlink\" title=\"YOLOv1\"></a>YOLOv1</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>one-stage bbox </p>\n<ol>\n<li>YOLO  45 </li>\n<li></li>\n<li></li>\n</ol>\n<span id=\"more\"></span>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>YOLOv1 1 VOC <br><img src=\"/images/obj_det/YOLOv1_fig1.jpg\" alt=\"\"> <center> 1 YOLOv1 </center></p>\n<p> shape : <code>448,448,3</code><br> shape <code>7,7,35</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li> <code>SxS</code>  grid cell grid cell  VOC  <code>S=7</code></li>\n<li> grid cell  <code>B</code>  box <code>B=3</code></li>\n<li> box  5  <code>(x,y,w,h,IOU)</code></li>\n<li>VOC  <code>C=20</code> grid cell  <code>C</code>  grid cell  <code>B</code>  box  <code>C</code> <code>B</code>  box   box </li>\n<li> <code>448</code>  <code>7</code> <code>448/7=64</code> 1  <code>s-2</code>  layer  6  map  spatial size  <code>7x7</code>channel  <code>35</code> <code>B*5+C=3*5+20</code> </li>\n<li></li>\n<li> <code>S*S*B</code>  box box  4 1  IOU  C  0.2 box  box  0 0.4 box 0.2</li>\n</ol>\n<p><strong></strong>  grid cell  1  box  box</p>\n<p><strong></strong>  grid cell<code>x,y,w,h,IOU,class</code> gt <code>Y</code>  grid cell  box box  size  aspect ratio grid cell <code>B</code>  box  IOU  box  box  box </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><script type=\"math/tex; mode=display\">\\begin{aligned} L&=\\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(x_i-\\hat x_i)^2+(y_i-\\hat y_i)^2 \\\\\\\\ &+ \\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(\\sqrt {w_i}- \\sqrt {\\hat w_i})^2+(\\sqrt {h_i}- \\sqrt {\\hat h_i})^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (C_i-\\hat C_i)^2 \\\\\\\\ &+ \\lambda_{noobj} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}(C_i-\\hat C_i)^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2} \\mathbf 1_i^{obj} \\sum_{c \\in classes}\\left(p_i(c)-\\hat p_i(c)\\right)^2 \\end{aligned}</script><p><strong></strong></p>\n<p> <code>^</code>  <code>^</code>  ground truth <code>x, y, w, h</code> <code>C</code>  IOU<code>pi(c)</code>  <code>c</code> </p>\n<p>$\\mathbf 1_{ij}^{obj}$  <code>i</code>  grid cell  grid cell  <code>j</code>  box  gt box  IOU <code>j</code> box </p>\n<p> box   box$\\Delta w, \\ \\Delta h$  box  box  <code>w,h</code></p>\n<p>$\\mathbf 1_{ij}^{noobj}$  i)  <code>i</code>  grid cell  ii)  <code>j</code>  box  gt box  IOU  <code>B</code>  box </p>\n<p>$\\mathbf 1_i^{obj}$  <code>i</code>  grid cell </p>\n<p> box  box  IOU  box  IOU  $\\lambda_{coord}=5, \\ \\lambda_{noobj}=0.5$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>GT label  size  <code>S*S*(5+20)</code> <code>5</code>  4 1  IOU20  id  one-hot vector  <code>(S,S,5+20)</code> IOU, class id, x,y,w,h</li>\n<li> size  <code>S*S*(B*5+20)</code> <code>(5+20,S,S)</code> class id, IOU, x,y,w,h</li>\n<li>GT label  x,y,w,h / <code>x=x*S-(int)x*S, y=y*S-(int)y*S</code></li>\n<li> x,y  GT label  grid cell  w,h </li>\n</ol>\n<h1 id=\"YOLOv2\"><a href=\"#YOLOv2\" class=\"headerlink\" title=\"YOLOv2\"></a>YOLOv2</h1><h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p>YOLOv2  YOLOv1 </p>\n<ol>\n<li></li>\n<li> Batch Normalization</li>\n<li></li>\n</ol>\n<p>YOLOv1  <code>224x224</code>  <code>448x448</code> YOLOv2  batch  size</p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p> VOC YOLOv2  <code>cfg/yolov2-voc.cfg</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li> size  10  batch  <code>320, 352, ..., 608</code>  <code>(3,d,d)</code></li>\n<li><p> 32 <code>(125, d/32, d/32)</code><code>(d/32,d/32)</code>  YOLOv1  grid cell  <code>S=d/32</code> grid cell grid cell  grid cell  <code>5</code>  box box  <code>1</code>  IOU  <code>4</code>  box  <code>20</code>  channel  <code>125=5*(1+4+20)</code>YOLOv1  cell  <code>B</code>  box  <code>20</code> </p>\n</li>\n<li><p> 30 GT label  <code>30x5</code> <code>5</code>  4  1  id x,h,w,h,class idGT label </p>\n</li>\n<li><code>(route:-1-4)</code>  ResNet  identity mapping</li>\n</ol>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">L=L_p+L_{box}+L_C</script><p><strong></strong></p>\n<script type=\"math/tex; mode=display\">L_p=\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\sum_{c=1}^{20} \\mathbf 1_{ij}^{obj} [\\hat p_{ij}(c)-p_{ij}(c)]^2</script><p><strong></strong></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}L_{box}&=\\lambda_{obj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (\\hat x_{ij} - x_{ij})^2 + (\\hat y_{ij} - y_{ij})^2+ (\\hat w_{ij} - w_{ij})^2+ (\\hat h_{ij} - h_{ij})^2 \n\\\\ &+ \\lambda_{noobj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{noobj} (\\hat x_{ij} - x_{ij}^a)^2 + (\\hat y_{ij} - y_{ij}^a)^2+ (\\hat w_{ij} - w_{ij}^a)^2+ (\\hat h_{ij} - h_{ij}^a)^2 \\end{aligned}</script><p><strong></strong></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}L_C &=\\lambda_{obj}^{conf}\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj}[\\hat C_{ij}-iou(\\hat \\text{box}_{ij}, \\text{box}_{ij})]^2  \n\\\\&+ \\lambda_{noobj}^{conf}\\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}[\\hat C_{ij}-0]^2 \\end{aligned}</script><p> ^  network  a  anchor GT label</p>\n<p><strong></strong></p>\n<p> shape <code>batch, B, 4+1+C, S, S</code> feature map  height  width  <code>S</code> grid size <code>4</code>  4 <code>1</code>  IOU<code>C</code> </p>\n<p> YOLOv1  grid cell grid cell  grid cell  <code>B=5</code>  box size 5  anchor box  yolov2-voc.cfg  layer  <code>anchors</code>  5  width height  feature map  size <code>SxS</code>anchor box  grid cell  0.5 <code>(i,j)</code>  grid cell  anchor box  <code>(i+0.5, j+0.5)</code></p>\n<p> <code>x,y,h,w</code>  2<br><img src=\"/images/obj_det/YOLOv2_fig2.png\" alt=\"\"> <center>2  box  anchor box </center></p>\n<p> $\\sigma(t_x), \\sigma(t_y), t_w, t_h$</p>\n<p> GT label  size  <code>30*5</code> <code>x,y,w,h, class id</code> <code>x,y,w,h</code>  original image  size <code>x,y</code>  YOLOv1 </p>\n<p> $x_{ij}, y_{ij}, w_{ij}, h_{ij}$  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$ GT box  anchor box box  GT box  anchor box  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$</p>\n<p> location <code>(i,j)</code>  <code>B</code>  box  GT label  box  IOU IOU IOU  0.5 $\\mathbf 1_{ij}^{noobj}=0$ 0</p>\n<p> GT box GT box  IOU  box IOU  $\\mathbf 1_{ij}^{obj}=1$ GT box  box$\\sum_{c=1}^C$  <code>c</code>  GT label  class id $p_{ij}(c)=1$ <code>C-1</code>  $p_{ij}(c)=0$</p>\n<h1 id=\"YOLOv3\"><a href=\"#YOLOv3\" class=\"headerlink\" title=\"YOLOv3\"></a>YOLOv3</h1><p> YOLOv2 </p>\n<ol>\n<li> scale  feature maps feature maps  <code>NxNx[3*(4+1+C)]</code> <code>N</code> 2 </li>\n<li> <code>9</code>  scale  anchor box  <code>3</code>  scale  feature maps scale  feature maps  grid cell  <code>9/3=3</code>  anchor box</li>\n</ol>\n<p> VOC  <code>cfg/yolov3-voc.cfg</code></p>\n<ol>\n<li> <code>32</code> <code>(h,w)</code>feature map  <code>(h/32,w/32)</code> scale  feature maps  <code>(h/16,w/16)</code>  <code>(h/8, w/8)</code></li>\n<li> GT label   <code>90*5</code> <code>90</code></li>\n<li> Residual layer</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"YOLOv1\"><a href=\"#YOLOv1\" class=\"headerlink\" title=\"YOLOv1\"></a>YOLOv1</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>one-stage bbox </p>\n<ol>\n<li>YOLO  45 </li>\n<li></li>\n<li></li>\n</ol>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>YOLOv1 1 VOC <br><img src=\"/images/obj_det/YOLOv1_fig1.jpg\" alt=\"\"> <center> 1 YOLOv1 </center></p>\n<p> shape : <code>448,448,3</code><br> shape <code>7,7,35</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li> <code>SxS</code>  grid cell grid cell  VOC  <code>S=7</code></li>\n<li> grid cell  <code>B</code>  box <code>B=3</code></li>\n<li> box  5  <code>(x,y,w,h,IOU)</code></li>\n<li>VOC  <code>C=20</code> grid cell  <code>C</code>  grid cell  <code>B</code>  box  <code>C</code> <code>B</code>  box   box </li>\n<li> <code>448</code>  <code>7</code> <code>448/7=64</code> 1  <code>s-2</code>  layer  6  map  spatial size  <code>7x7</code>channel  <code>35</code> <code>B*5+C=3*5+20</code> </li>\n<li></li>\n<li> <code>S*S*B</code>  box box  4 1  IOU  C  0.2 box  box  0 0.4 box 0.2</li>\n</ol>\n<p><strong></strong>  grid cell  1  box  box</p>\n<p><strong></strong>  grid cell<code>x,y,w,h,IOU,class</code> gt <code>Y</code>  grid cell  box box  size  aspect ratio grid cell <code>B</code>  box  IOU  box  box  box </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><script type=\"math/tex; mode=display\">\\begin{aligned} L&=\\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(x_i-\\hat x_i)^2+(y_i-\\hat y_i)^2 \\\\\\\\ &+ \\lambda_{coord} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj}(\\sqrt {w_i}- \\sqrt {\\hat w_i})^2+(\\sqrt {h_i}- \\sqrt {\\hat h_i})^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (C_i-\\hat C_i)^2 \\\\\\\\ &+ \\lambda_{noobj} \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}(C_i-\\hat C_i)^2 \\\\\\\\ &+ \\sum_{i=1}^{S^2} \\mathbf 1_i^{obj} \\sum_{c \\in classes}\\left(p_i(c)-\\hat p_i(c)\\right)^2 \\end{aligned}</script><p><strong></strong></p>\n<p> <code>^</code>  <code>^</code>  ground truth <code>x, y, w, h</code> <code>C</code>  IOU<code>pi(c)</code>  <code>c</code> </p>\n<p>$\\mathbf 1_{ij}^{obj}$  <code>i</code>  grid cell  grid cell  <code>j</code>  box  gt box  IOU <code>j</code> box </p>\n<p> box   box$\\Delta w, \\ \\Delta h$  box  box  <code>w,h</code></p>\n<p>$\\mathbf 1_{ij}^{noobj}$  i)  <code>i</code>  grid cell  ii)  <code>j</code>  box  gt box  IOU  <code>B</code>  box </p>\n<p>$\\mathbf 1_i^{obj}$  <code>i</code>  grid cell </p>\n<p> box  box  IOU  box  IOU  $\\lambda_{coord}=5, \\ \\lambda_{noobj}=0.5$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>GT label  size  <code>S*S*(5+20)</code> <code>5</code>  4 1  IOU20  id  one-hot vector  <code>(S,S,5+20)</code> IOU, class id, x,y,w,h</li>\n<li> size  <code>S*S*(B*5+20)</code> <code>(5+20,S,S)</code> class id, IOU, x,y,w,h</li>\n<li>GT label  x,y,w,h / <code>x=x*S-(int)x*S, y=y*S-(int)y*S</code></li>\n<li> x,y  GT label  grid cell  w,h </li>\n</ol>\n<h1 id=\"YOLOv2\"><a href=\"#YOLOv2\" class=\"headerlink\" title=\"YOLOv2\"></a>YOLOv2</h1><h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p>YOLOv2  YOLOv1 </p>\n<ol>\n<li></li>\n<li> Batch Normalization</li>\n<li></li>\n</ol>\n<p>YOLOv1  <code>224x224</code>  <code>448x448</code> YOLOv2  batch  size</p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p> VOC YOLOv2  <code>cfg/yolov2-voc.cfg</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li> size  10  batch  <code>320, 352, ..., 608</code>  <code>(3,d,d)</code></li>\n<li><p> 32 <code>(125, d/32, d/32)</code><code>(d/32,d/32)</code>  YOLOv1  grid cell  <code>S=d/32</code> grid cell grid cell  grid cell  <code>5</code>  box box  <code>1</code>  IOU  <code>4</code>  box  <code>20</code>  channel  <code>125=5*(1+4+20)</code>YOLOv1  cell  <code>B</code>  box  <code>20</code> </p>\n</li>\n<li><p> 30 GT label  <code>30x5</code> <code>5</code>  4  1  id x,h,w,h,class idGT label </p>\n</li>\n<li><code>(route:-1-4)</code>  ResNet  identity mapping</li>\n</ol>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">L=L_p+L_{box}+L_C</script><p><strong></strong></p>\n<script type=\"math/tex; mode=display\">L_p=\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\sum_{c=1}^{20} \\mathbf 1_{ij}^{obj} [\\hat p_{ij}(c)-p_{ij}(c)]^2</script><p><strong></strong></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}L_{box}&=\\lambda_{obj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj} (\\hat x_{ij} - x_{ij})^2 + (\\hat y_{ij} - y_{ij})^2+ (\\hat w_{ij} - w_{ij})^2+ (\\hat h_{ij} - h_{ij})^2 \n\\\\ &+ \\lambda_{noobj}^{coord} \\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{noobj} (\\hat x_{ij} - x_{ij}^a)^2 + (\\hat y_{ij} - y_{ij}^a)^2+ (\\hat w_{ij} - w_{ij}^a)^2+ (\\hat h_{ij} - h_{ij}^a)^2 \\end{aligned}</script><p><strong></strong></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}L_C &=\\lambda_{obj}^{conf}\\sum_{i=1}^{S^2} \\sum_{j=1}^B \\mathbf 1_{ij}^{obj}[\\hat C_{ij}-iou(\\hat \\text{box}_{ij}, \\text{box}_{ij})]^2  \n\\\\&+ \\lambda_{noobj}^{conf}\\sum_{i=1}^{S^2}\\sum_{j=1}^B \\mathbf 1_{ij}^{noobj}[\\hat C_{ij}-0]^2 \\end{aligned}</script><p> ^  network  a  anchor GT label</p>\n<p><strong></strong></p>\n<p> shape <code>batch, B, 4+1+C, S, S</code> feature map  height  width  <code>S</code> grid size <code>4</code>  4 <code>1</code>  IOU<code>C</code> </p>\n<p> YOLOv1  grid cell grid cell  grid cell  <code>B=5</code>  box size 5  anchor box  yolov2-voc.cfg  layer  <code>anchors</code>  5  width height  feature map  size <code>SxS</code>anchor box  grid cell  0.5 <code>(i,j)</code>  grid cell  anchor box  <code>(i+0.5, j+0.5)</code></p>\n<p> <code>x,y,h,w</code>  2<br><img src=\"/images/obj_det/YOLOv2_fig2.png\" alt=\"\"> <center>2  box  anchor box </center></p>\n<p> $\\sigma(t_x), \\sigma(t_y), t_w, t_h$</p>\n<p> GT label  size  <code>30*5</code> <code>x,y,w,h, class id</code> <code>x,y,w,h</code>  original image  size <code>x,y</code>  YOLOv1 </p>\n<p> $x_{ij}, y_{ij}, w_{ij}, h_{ij}$  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$ GT box  anchor box box  GT box  anchor box  $\\sigma(t_x), \\sigma(t_y), t_w, t_h$</p>\n<p> location <code>(i,j)</code>  <code>B</code>  box  GT label  box  IOU IOU IOU  0.5 $\\mathbf 1_{ij}^{noobj}=0$ 0</p>\n<p> GT box GT box  IOU  box IOU  $\\mathbf 1_{ij}^{obj}=1$ GT box  box$\\sum_{c=1}^C$  <code>c</code>  GT label  class id $p_{ij}(c)=1$ <code>C-1</code>  $p_{ij}(c)=0$</p>\n<h1 id=\"YOLOv3\"><a href=\"#YOLOv3\" class=\"headerlink\" title=\"YOLOv3\"></a>YOLOv3</h1><p> YOLOv2 </p>\n<ol>\n<li> scale  feature maps feature maps  <code>NxNx[3*(4+1+C)]</code> <code>N</code> 2 </li>\n<li> <code>9</code>  scale  anchor box  <code>3</code>  scale  feature maps scale  feature maps  grid cell  <code>9/3=3</code>  anchor box</li>\n</ol>\n<p> VOC  <code>cfg/yolov3-voc.cfg</code></p>\n<ol>\n<li> <code>32</code> <code>(h,w)</code>feature map  <code>(h/32,w/32)</code> scale  feature maps  <code>(h/16,w/16)</code>  <code>(h/8, w/8)</code></li>\n<li> GT label   <code>90*5</code> <code>90</code></li>\n<li> Residual layer</li>\n</ol>"},{"title":"Anchor-free Object Detection","date":"2021-02-25T04:31:28.000Z","_content":"# FCOS\n scale  detection head  feature maps  location  `C`  `4`  center  location  gt box box  target  $\\mathbf t^{*}=(l^{*}, t^{*}, r^{*}, b^{*})$ location `(x,y)`  gt box $B_i=(x_0^{(i)}, y_0^{(i)}, x_1^{(i)}, y_1^{(i)})$ \n$$l^{*}=x-x_0^{(i)}, \\quad t^{*}=y-y_0^{(i)}$$\n$$r^{*}=x_1^{(i)} - x, \\quad b^{*}=y_1^{(i)} - y$$\n\n\n$$\\begin{aligned} L({\\mathbf p_{x,y}}, {\\mathbf t_{x,y}})&=\\frac 1 {N_{pos}} \\sum_{x,y} L_{cls}(\\mathbf p_{x,y}, c_{x,y}^{*}) \\\\ &+ \\frac {\\lambda} {N_{pos}} \\sum_{x,y} \\mathbb I(c_{x,y}^{*}>0) \\cdot L_{reg}(\\mathbf t_{x,y}, t_{x,y}^{*})\\end{aligned}$$\n\n$c_{x,y}^{*}$  location `(x,y)` $c_{x,y}^{*}=0$ $c_{x,y}^{*}$ fg id $L_{cls}$  Focal Loss $L_{reg}$  IOU Loss\n\n location  gt box  location  gt box   multi-level \n## FPN for FCOS\n FPN multi-level  feature maps ${P_3, P_4, P_5, P_6, P_7}$ $P_3, P_4, P_5$  backbone  $C_3, C_4, C_5$  `1x1` conv $P_6, p_7$  $P_5, P_6$  stride=2  conv  level feature  stride  `8,16,32,64,128`\n\n scale  feature  box  $P_i$ location  $\\max(l^{*},t^{*},r^{*},b^{*})>m_i$  $\\max(l^{*},t^{*},r^{*},b^{*}) < m_{i-1}$ location  $L_{reg}$ $m_2=0, \\ m_3=64, \\ m_4=128, \\ m_5=256, \\ m_6=512, \\ m_7=\\infty$ anchor based  anchor  base scale  8\n\n level  feature  size  location  ambiguous location location  location  size/area \n\n FPN  level   head  level\n feature  $P_3$  $[0,64]$ level  head  single scale FCOS  $exp(x)$ target  $exp(x)$  multi scale FCOS  $exp(s_i x)$ $s_i$ \n## Center-ness for FCOS\n box location \n\n single-layer  1\n\n![](/images/obj_det/anchor_free_fig1.png)<center> 1</center>\n\n location  center-ness location  $\\mathbf t^{*}=(l^{*},t^{*},r^{*},b^{*})$center-ness \n$$\\text{centerness}^{*}=\\sqrt{\\frac {\\min(l^*, r^*)} {\\max(l^*,r^*)} \\times \\frac {\\min(t^*, b^*)} {\\max(t^*,b^*)}}$$\n center-ness center-ness  $[0,1]$ BCE loss \n\n__ center-ness  __ box  ranking NMS\n\n center-ness  gt box  location \n\n# CornerNet\nanchor based 1.  anchor2. anchor  aspect ratio  multi-scale feature \n\n anchor free \n\n1. box  4  `corner pooling``corner pooling` encoding  location  feature vector feature vector encoding \n2.  box  feature  size  `(w,h)` O(wh) anchor box  anchor  w  h  anchor  size  wh  feature  anchor  wh  $O(w^2h^2)$ anchor  feature map  anchor  1  w  2  w-1 ...  w  1  $w+(w-1)+\\cdots +1$ feature  anchor  $(1+2+\\cdots+w)(1+2+\\cdots+h)=\\frac {w(w+1)h(h+1)} 4$anchor based  anchor  feature  location  scale  aspect ratio  anchor  K  $Kwh$ \n\n## \nbase ConvNet  hourglass network corner pooling  corner pooling hourglass network  feature  pooling  heatmapsembeddings  offsets\n\n__heatmap:__\n\n heatmaps heatmap  C channels C heatmap  $H \\times W$heatmap  location  heatmap  binary mask\n\n corner  location  location  location  corner  corner  location  location corner box  gt box gt box  IOU  t t  0.3\n\n\n$$f_{cij}=\\begin{cases} e^{-\\frac {x^2+y^2}{2 \\sigma^2}} & x^2+y^2 \\le r^2 \\\\ 0 & \\text{otherwise} \\end{cases}$$\n `(i,j)`  location $x, y$  location  corner $c$  gt $\\sigma=r/3$ $r$ \n\nheatmap  location  corner  focal loss\n$$L_{det}=-\\frac 1 N \\sum_{c=1}^C\\sum_{i=1}^H \\sum_{j=1}^W \\begin{cases} (1-p_{cij})^{\\alpha} \\log p_{cij} & y_{cij}=1 \\\\ (1-f_{cij})^{\\beta}p_{cij}^{\\alpha} \\log (1-p_{cij}) & o.w. \\end{cases}$$\n$p_{cij}$  heatmap  location $y_{cij}$  heatmap  gt target N  image  object $\\alpha=2, \\ \\beta=4$  corner  negative location \n\n__offset:__\n\nhourglass  feature size  image size  n gt corner $(x,y)$  heatmap  $(\\lfloor x/n, y/n \\rfloor)$ image  $[0,n)$size  IOUgt offset \n$$\\mathbf o_k=\\left(\\frac {x_k} n - \\lfloor \\frac {x_k} n \\rfloor, \\frac {y_k} n - \\lfloor \\frac {y_k} n \\rfloor \\right)$$\n $k$  k  gt corner offset  $\\hat \\mathbf o_k$ smooth L1 \n\n__embedding:__\n\n corner  corner  gt box\n\n corner  embedding vector corner  gt box embedding  vector  L1 \n\n embedding  target  `pull`  `push`  $e_{tk}$  k  corner  embedding$e_{bk}$  k  corner  embedding \n$$L_{pull}=\\frac 1 N \\sum_{k=1}^N [(e_{tk}-e_k)^2+(e_{bk}-e_k)^2]$$\n$$L_{push}=\\frac 1 {N(N-1)} \\sum_{k=1}^N \\sum_{j=1, j\\ne k}^N \\max (0, \\Delta-|e_k-e_j|)$$\n$$e_k=\\frac {e_{tk}+e_{bk}} 2$$\nN  image $\\Delta=1$  corner  embeding \n\n K  top-left  K  bottom-right  $K^2$  pair  pair  embedding  L1  0.5 pair  heatmap  soft nms\n\n## Corner Pooling\n hourglass  feature `heatmap, offset, embedding` Corner Pooling \n\nhourglass  $f_t, f_l, f_b, f_r$    side $f_t, f_l$ $f_b, f_r$  corner pooling  feature size  $H \\times W$ location `(i,j)`  $f_t$  corner pooling  `(i,j)`  `(H,j)`  location  max  $t_{ij}$ location  max  $l_{ij}$\n$$t_{ij}=\\begin{cases} \\max[f_t(i,j), t_{(i+1)j}] & i < H \\\\ f_t(H,j) & i=H \\end{cases}$$\n$$l_{ij}=\\begin{cases} \\max[f_l(i,j), l_{i(j+1)}] & i < H \\\\ f_l(i,W) & i=H \\end{cases}$$\n $f_t$ $f_l$\n\n 2\n![](/images/obj_det/anchor_free_fig2.png)<center> 2. backbone  residule module shortcut  2x conv left-most  top most corner pooling  element-wise add conv  shortcut  mergeelement-wise add)</center>\n\n## Hourglass Network\n backbone  VGGResNet  densenet  hourglass \n\nHourglass network  hourglass Hourglass  input feature  resolution maxpooling  skip layer  feature  hourglass  level \n\n stride=2  conv  maxpooling\n\n \n$$L=L_{det}+\\alpha L_{pull} + \\beta L_{push} + \\gamma L_{off}$$","source":"_posts/obj_det/anchor_free.md","raw":"---\ntitle: Anchor-free Object Detection\ndate: 2021-02-25 12:31:28\ntags:\n---\n# FCOS\n scale  detection head  feature maps  location  `C`  `4`  center  location  gt box box  target  $\\mathbf t^{*}=(l^{*}, t^{*}, r^{*}, b^{*})$ location `(x,y)`  gt box $B_i=(x_0^{(i)}, y_0^{(i)}, x_1^{(i)}, y_1^{(i)})$ \n$$l^{*}=x-x_0^{(i)}, \\quad t^{*}=y-y_0^{(i)}$$\n$$r^{*}=x_1^{(i)} - x, \\quad b^{*}=y_1^{(i)} - y$$\n\n\n$$\\begin{aligned} L({\\mathbf p_{x,y}}, {\\mathbf t_{x,y}})&=\\frac 1 {N_{pos}} \\sum_{x,y} L_{cls}(\\mathbf p_{x,y}, c_{x,y}^{*}) \\\\ &+ \\frac {\\lambda} {N_{pos}} \\sum_{x,y} \\mathbb I(c_{x,y}^{*}>0) \\cdot L_{reg}(\\mathbf t_{x,y}, t_{x,y}^{*})\\end{aligned}$$\n\n$c_{x,y}^{*}$  location `(x,y)` $c_{x,y}^{*}=0$ $c_{x,y}^{*}$ fg id $L_{cls}$  Focal Loss $L_{reg}$  IOU Loss\n\n location  gt box  location  gt box   multi-level \n## FPN for FCOS\n FPN multi-level  feature maps ${P_3, P_4, P_5, P_6, P_7}$ $P_3, P_4, P_5$  backbone  $C_3, C_4, C_5$  `1x1` conv $P_6, p_7$  $P_5, P_6$  stride=2  conv  level feature  stride  `8,16,32,64,128`\n\n scale  feature  box  $P_i$ location  $\\max(l^{*},t^{*},r^{*},b^{*})>m_i$  $\\max(l^{*},t^{*},r^{*},b^{*}) < m_{i-1}$ location  $L_{reg}$ $m_2=0, \\ m_3=64, \\ m_4=128, \\ m_5=256, \\ m_6=512, \\ m_7=\\infty$ anchor based  anchor  base scale  8\n\n level  feature  size  location  ambiguous location location  location  size/area \n\n FPN  level   head  level\n feature  $P_3$  $[0,64]$ level  head  single scale FCOS  $exp(x)$ target  $exp(x)$  multi scale FCOS  $exp(s_i x)$ $s_i$ \n## Center-ness for FCOS\n box location \n\n single-layer  1\n\n![](/images/obj_det/anchor_free_fig1.png)<center> 1</center>\n\n location  center-ness location  $\\mathbf t^{*}=(l^{*},t^{*},r^{*},b^{*})$center-ness \n$$\\text{centerness}^{*}=\\sqrt{\\frac {\\min(l^*, r^*)} {\\max(l^*,r^*)} \\times \\frac {\\min(t^*, b^*)} {\\max(t^*,b^*)}}$$\n center-ness center-ness  $[0,1]$ BCE loss \n\n__ center-ness  __ box  ranking NMS\n\n center-ness  gt box  location \n\n# CornerNet\nanchor based 1.  anchor2. anchor  aspect ratio  multi-scale feature \n\n anchor free \n\n1. box  4  `corner pooling``corner pooling` encoding  location  feature vector feature vector encoding \n2.  box  feature  size  `(w,h)` O(wh) anchor box  anchor  w  h  anchor  size  wh  feature  anchor  wh  $O(w^2h^2)$ anchor  feature map  anchor  1  w  2  w-1 ...  w  1  $w+(w-1)+\\cdots +1$ feature  anchor  $(1+2+\\cdots+w)(1+2+\\cdots+h)=\\frac {w(w+1)h(h+1)} 4$anchor based  anchor  feature  location  scale  aspect ratio  anchor  K  $Kwh$ \n\n## \nbase ConvNet  hourglass network corner pooling  corner pooling hourglass network  feature  pooling  heatmapsembeddings  offsets\n\n__heatmap:__\n\n heatmaps heatmap  C channels C heatmap  $H \\times W$heatmap  location  heatmap  binary mask\n\n corner  location  location  location  corner  corner  location  location corner box  gt box gt box  IOU  t t  0.3\n\n\n$$f_{cij}=\\begin{cases} e^{-\\frac {x^2+y^2}{2 \\sigma^2}} & x^2+y^2 \\le r^2 \\\\ 0 & \\text{otherwise} \\end{cases}$$\n `(i,j)`  location $x, y$  location  corner $c$  gt $\\sigma=r/3$ $r$ \n\nheatmap  location  corner  focal loss\n$$L_{det}=-\\frac 1 N \\sum_{c=1}^C\\sum_{i=1}^H \\sum_{j=1}^W \\begin{cases} (1-p_{cij})^{\\alpha} \\log p_{cij} & y_{cij}=1 \\\\ (1-f_{cij})^{\\beta}p_{cij}^{\\alpha} \\log (1-p_{cij}) & o.w. \\end{cases}$$\n$p_{cij}$  heatmap  location $y_{cij}$  heatmap  gt target N  image  object $\\alpha=2, \\ \\beta=4$  corner  negative location \n\n__offset:__\n\nhourglass  feature size  image size  n gt corner $(x,y)$  heatmap  $(\\lfloor x/n, y/n \\rfloor)$ image  $[0,n)$size  IOUgt offset \n$$\\mathbf o_k=\\left(\\frac {x_k} n - \\lfloor \\frac {x_k} n \\rfloor, \\frac {y_k} n - \\lfloor \\frac {y_k} n \\rfloor \\right)$$\n $k$  k  gt corner offset  $\\hat \\mathbf o_k$ smooth L1 \n\n__embedding:__\n\n corner  corner  gt box\n\n corner  embedding vector corner  gt box embedding  vector  L1 \n\n embedding  target  `pull`  `push`  $e_{tk}$  k  corner  embedding$e_{bk}$  k  corner  embedding \n$$L_{pull}=\\frac 1 N \\sum_{k=1}^N [(e_{tk}-e_k)^2+(e_{bk}-e_k)^2]$$\n$$L_{push}=\\frac 1 {N(N-1)} \\sum_{k=1}^N \\sum_{j=1, j\\ne k}^N \\max (0, \\Delta-|e_k-e_j|)$$\n$$e_k=\\frac {e_{tk}+e_{bk}} 2$$\nN  image $\\Delta=1$  corner  embeding \n\n K  top-left  K  bottom-right  $K^2$  pair  pair  embedding  L1  0.5 pair  heatmap  soft nms\n\n## Corner Pooling\n hourglass  feature `heatmap, offset, embedding` Corner Pooling \n\nhourglass  $f_t, f_l, f_b, f_r$    side $f_t, f_l$ $f_b, f_r$  corner pooling  feature size  $H \\times W$ location `(i,j)`  $f_t$  corner pooling  `(i,j)`  `(H,j)`  location  max  $t_{ij}$ location  max  $l_{ij}$\n$$t_{ij}=\\begin{cases} \\max[f_t(i,j), t_{(i+1)j}] & i < H \\\\ f_t(H,j) & i=H \\end{cases}$$\n$$l_{ij}=\\begin{cases} \\max[f_l(i,j), l_{i(j+1)}] & i < H \\\\ f_l(i,W) & i=H \\end{cases}$$\n $f_t$ $f_l$\n\n 2\n![](/images/obj_det/anchor_free_fig2.png)<center> 2. backbone  residule module shortcut  2x conv left-most  top most corner pooling  element-wise add conv  shortcut  mergeelement-wise add)</center>\n\n## Hourglass Network\n backbone  VGGResNet  densenet  hourglass \n\nHourglass network  hourglass Hourglass  input feature  resolution maxpooling  skip layer  feature  hourglass  level \n\n stride=2  conv  maxpooling\n\n \n$$L=L_{det}+\\alpha L_{pull} + \\beta L_{push} + \\gamma L_{off}$$","slug":"obj_det/anchor_free","published":1,"updated":"2021-03-06T07:18:07.937Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91e002wp0djbmp08sh9","content":"<h1 id=\"FCOS\"><a href=\"#FCOS\" class=\"headerlink\" title=\"FCOS\"></a>FCOS</h1><p> scale  detection head  feature maps  location  <code>C</code>  <code>4</code>  center  location  gt box box  target  $\\mathbf t^{<em>}=(l^{</em>}, t^{<em>}, r^{</em>}, b^{*})$ location <code>(x,y)</code>  gt box $B_i=(x_0^{(i)}, y_0^{(i)}, x_1^{(i)}, y_1^{(i)})$ </p>\n<script type=\"math/tex; mode=display\">l^{*}=x-x_0^{(i)}, \\quad t^{*}=y-y_0^{(i)}</script><script type=\"math/tex; mode=display\">r^{*}=x_1^{(i)} - x, \\quad b^{*}=y_1^{(i)} - y</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} L({\\mathbf p_{x,y}}, {\\mathbf t_{x,y}})&=\\frac 1 {N_{pos}} \\sum_{x,y} L_{cls}(\\mathbf p_{x,y}, c_{x,y}^{*}) \\\\ &+ \\frac {\\lambda} {N_{pos}} \\sum_{x,y} \\mathbb I(c_{x,y}^{*}>0) \\cdot L_{reg}(\\mathbf t_{x,y}, t_{x,y}^{*})\\end{aligned}</script><p>$c_{x,y}^{<em>}$  location <code>(x,y)</code> $c_{x,y}^{</em>}=0$ $c_{x,y}^{*}$ fg id $L_{cls}$  Focal Loss $L_{reg}$  IOU Loss</p>\n<p> location  gt box  location  gt box   multi-level </p>\n<h2 id=\"FPN-for-FCOS\"><a href=\"#FPN-for-FCOS\" class=\"headerlink\" title=\"FPN for FCOS\"></a>FPN for FCOS</h2><p> FPN multi-level  feature maps ${P_3, P_4, P_5, P_6, P_7}$ $P_3, P_4, P_5$  backbone  $C_3, C_4, C_5$  <code>1x1</code> conv $P_6, p_7$  $P_5, P_6$  stride=2  conv  level feature  stride  <code>8,16,32,64,128</code></p>\n<p> scale  feature  box  $P_i$ location  $\\max(l^{<em>},t^{</em>},r^{<em>},b^{</em>})&gt;m_i$  $\\max(l^{<em>},t^{</em>},r^{<em>},b^{</em>}) &lt; m_{i-1}$ location  $L_{reg}$ $m_2=0, \\ m_3=64, \\ m_4=128, \\ m_5=256, \\ m_6=512, \\ m_7=\\infty$ anchor based  anchor  base scale  8</p>\n<p> level  feature  size  location  ambiguous location location  location  size/area </p>\n<p> FPN  level   head  level<br> feature  $P_3$  $[0,64]$ level  head  single scale FCOS  $exp(x)$ target  $exp(x)$  multi scale FCOS  $exp(s_i x)$ $s_i$ </p>\n<h2 id=\"Center-ness-for-FCOS\"><a href=\"#Center-ness-for-FCOS\" class=\"headerlink\" title=\"Center-ness for FCOS\"></a>Center-ness for FCOS</h2><p> box location </p>\n<p> single-layer  1</p>\n<p><img src=\"/images/obj_det/anchor_free_fig1.png\" alt=\"\"><center> 1</center></p>\n<p> location  center-ness location  $\\mathbf t^{<em>}=(l^{</em>},t^{<em>},r^{</em>},b^{*})$center-ness </p>\n<script type=\"math/tex; mode=display\">\\text{centerness}^{*}=\\sqrt{\\frac {\\min(l^*, r^*)} {\\max(l^*,r^*)} \\times \\frac {\\min(t^*, b^*)} {\\max(t^*,b^*)}}</script><p> center-ness center-ness  $[0,1]$ BCE loss </p>\n<p><strong> center-ness  </strong> box  ranking NMS</p>\n<p> center-ness  gt box  location </p>\n<h1 id=\"CornerNet\"><a href=\"#CornerNet\" class=\"headerlink\" title=\"CornerNet\"></a>CornerNet</h1><p>anchor based 1.  anchor2. anchor  aspect ratio  multi-scale feature </p>\n<p> anchor free </p>\n<ol>\n<li>box  4  <code>corner pooling</code><code>corner pooling</code> encoding  location  feature vector feature vector encoding </li>\n<li> box  feature  size  <code>(w,h)</code> O(wh) anchor box  anchor  w  h  anchor  size  wh  feature  anchor  wh  $O(w^2h^2)$ anchor  feature map  anchor  1  w  2  w-1   w  1  $w+(w-1)+\\cdots +1$ feature  anchor  $(1+2+\\cdots+w)(1+2+\\cdots+h)=\\frac {w(w+1)h(h+1)} 4$anchor based  anchor  feature  location  scale  aspect ratio  anchor  K  $Kwh$ </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>base ConvNet  hourglass network corner pooling  corner pooling hourglass network  feature  pooling  heatmapsembeddings  offsets</p>\n<p><strong>heatmap:</strong></p>\n<p> heatmaps heatmap  C channels C heatmap  $H \\times W$heatmap  location  heatmap  binary mask</p>\n<p> corner  location  location  location  corner  corner  location  location corner box  gt box gt box  IOU  t t  0.3</p>\n<p></p>\n<script type=\"math/tex; mode=display\">f_{cij}=\\begin{cases} e^{-\\frac {x^2+y^2}{2 \\sigma^2}} & x^2+y^2 \\le r^2 \\\\ 0 & \\text{otherwise} \\end{cases}</script><p> <code>(i,j)</code>  location $x, y$  location  corner $c$  gt $\\sigma=r/3$ $r$ </p>\n<p>heatmap  location  corner  focal loss</p>\n<script type=\"math/tex; mode=display\">L_{det}=-\\frac 1 N \\sum_{c=1}^C\\sum_{i=1}^H \\sum_{j=1}^W \\begin{cases} (1-p_{cij})^{\\alpha} \\log p_{cij} & y_{cij}=1 \\\\ (1-f_{cij})^{\\beta}p_{cij}^{\\alpha} \\log (1-p_{cij}) & o.w. \\end{cases}</script><p>$p_{cij}$  heatmap  location $y_{cij}$  heatmap  gt target N  image  object $\\alpha=2, \\ \\beta=4$  corner  negative location </p>\n<p><strong>offset:</strong></p>\n<p>hourglass  feature size  image size  n gt corner $(x,y)$  heatmap  $(\\lfloor x/n, y/n \\rfloor)$ image  $[0,n)$size  IOUgt offset </p>\n<script type=\"math/tex; mode=display\">\\mathbf o_k=\\left(\\frac {x_k} n - \\lfloor \\frac {x_k} n \\rfloor, \\frac {y_k} n - \\lfloor \\frac {y_k} n \\rfloor \\right)</script><p> $k$  k  gt corner offset  $\\hat \\mathbf o_k$ smooth L1 </p>\n<p><strong>embedding:</strong></p>\n<p> corner  corner  gt box</p>\n<p> corner  embedding vector corner  gt box embedding  vector  L1 </p>\n<p> embedding  target  <code>pull</code>  <code>push</code>  $e_{tk}$  k  corner  embedding$e_{bk}$  k  corner  embedding </p>\n<script type=\"math/tex; mode=display\">L_{pull}=\\frac 1 N \\sum_{k=1}^N [(e_{tk}-e_k)^2+(e_{bk}-e_k)^2]</script><script type=\"math/tex; mode=display\">L_{push}=\\frac 1 {N(N-1)} \\sum_{k=1}^N \\sum_{j=1, j\\ne k}^N \\max (0, \\Delta-|e_k-e_j|)</script><script type=\"math/tex; mode=display\">e_k=\\frac {e_{tk}+e_{bk}} 2</script><p>N  image $\\Delta=1$  corner  embeding </p>\n<p> K  top-left  K  bottom-right  $K^2$  pair  pair  embedding  L1  0.5 pair  heatmap  soft nms</p>\n<h2 id=\"Corner-Pooling\"><a href=\"#Corner-Pooling\" class=\"headerlink\" title=\"Corner Pooling\"></a>Corner Pooling</h2><p> hourglass  feature <code>heatmap, offset, embedding</code> Corner Pooling </p>\n<p>hourglass  $f_t, f_l, f_b, f_r$    side $f_t, f_l$ $f_b, f_r$  corner pooling  feature size  $H \\times W$ location <code>(i,j)</code>  $f_t$  corner pooling  <code>(i,j)</code>  <code>(H,j)</code>  location  max  $t_{ij}$ location  max  $l_{ij}$</p>\n<script type=\"math/tex; mode=display\">t_{ij}=\\begin{cases} \\max[f_t(i,j), t_{(i+1)j}] & i < H \\\\ f_t(H,j) & i=H \\end{cases}</script><script type=\"math/tex; mode=display\">l_{ij}=\\begin{cases} \\max[f_l(i,j), l_{i(j+1)}] & i < H \\\\ f_l(i,W) & i=H \\end{cases}</script><p> $f_t$ $f_l$</p>\n<p> 2<br><img src=\"/images/obj_det/anchor_free_fig2.png\" alt=\"\"><center> 2. backbone  residule module shortcut  2x conv left-most  top most corner pooling  element-wise add conv  shortcut  mergeelement-wise add)</center></p>\n<h2 id=\"Hourglass-Network\"><a href=\"#Hourglass-Network\" class=\"headerlink\" title=\"Hourglass Network\"></a>Hourglass Network</h2><p> backbone  VGGResNet  densenet  hourglass </p>\n<p>Hourglass network  hourglass Hourglass  input feature  resolution maxpooling  skip layer  feature  hourglass  level </p>\n<p> stride=2  conv  maxpooling</p>\n<p> </p>\n<script type=\"math/tex; mode=display\">L=L_{det}+\\alpha L_{pull} + \\beta L_{push} + \\gamma L_{off}</script>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"FCOS\"><a href=\"#FCOS\" class=\"headerlink\" title=\"FCOS\"></a>FCOS</h1><p> scale  detection head  feature maps  location  <code>C</code>  <code>4</code>  center  location  gt box box  target  $\\mathbf t^{<em>}=(l^{</em>}, t^{<em>}, r^{</em>}, b^{*})$ location <code>(x,y)</code>  gt box $B_i=(x_0^{(i)}, y_0^{(i)}, x_1^{(i)}, y_1^{(i)})$ </p>\n<script type=\"math/tex; mode=display\">l^{*}=x-x_0^{(i)}, \\quad t^{*}=y-y_0^{(i)}</script><script type=\"math/tex; mode=display\">r^{*}=x_1^{(i)} - x, \\quad b^{*}=y_1^{(i)} - y</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} L({\\mathbf p_{x,y}}, {\\mathbf t_{x,y}})&=\\frac 1 {N_{pos}} \\sum_{x,y} L_{cls}(\\mathbf p_{x,y}, c_{x,y}^{*}) \\\\ &+ \\frac {\\lambda} {N_{pos}} \\sum_{x,y} \\mathbb I(c_{x,y}^{*}>0) \\cdot L_{reg}(\\mathbf t_{x,y}, t_{x,y}^{*})\\end{aligned}</script><p>$c_{x,y}^{<em>}$  location <code>(x,y)</code> $c_{x,y}^{</em>}=0$ $c_{x,y}^{*}$ fg id $L_{cls}$  Focal Loss $L_{reg}$  IOU Loss</p>\n<p> location  gt box  location  gt box   multi-level </p>\n<h2 id=\"FPN-for-FCOS\"><a href=\"#FPN-for-FCOS\" class=\"headerlink\" title=\"FPN for FCOS\"></a>FPN for FCOS</h2><p> FPN multi-level  feature maps ${P_3, P_4, P_5, P_6, P_7}$ $P_3, P_4, P_5$  backbone  $C_3, C_4, C_5$  <code>1x1</code> conv $P_6, p_7$  $P_5, P_6$  stride=2  conv  level feature  stride  <code>8,16,32,64,128</code></p>\n<p> scale  feature  box  $P_i$ location  $\\max(l^{<em>},t^{</em>},r^{<em>},b^{</em>})&gt;m_i$  $\\max(l^{<em>},t^{</em>},r^{<em>},b^{</em>}) &lt; m_{i-1}$ location  $L_{reg}$ $m_2=0, \\ m_3=64, \\ m_4=128, \\ m_5=256, \\ m_6=512, \\ m_7=\\infty$ anchor based  anchor  base scale  8</p>\n<p> level  feature  size  location  ambiguous location location  location  size/area </p>\n<p> FPN  level   head  level<br> feature  $P_3$  $[0,64]$ level  head  single scale FCOS  $exp(x)$ target  $exp(x)$  multi scale FCOS  $exp(s_i x)$ $s_i$ </p>\n<h2 id=\"Center-ness-for-FCOS\"><a href=\"#Center-ness-for-FCOS\" class=\"headerlink\" title=\"Center-ness for FCOS\"></a>Center-ness for FCOS</h2><p> box location </p>\n<p> single-layer  1</p>\n<p><img src=\"/images/obj_det/anchor_free_fig1.png\" alt=\"\"><center> 1</center></p>\n<p> location  center-ness location  $\\mathbf t^{<em>}=(l^{</em>},t^{<em>},r^{</em>},b^{*})$center-ness </p>\n<script type=\"math/tex; mode=display\">\\text{centerness}^{*}=\\sqrt{\\frac {\\min(l^*, r^*)} {\\max(l^*,r^*)} \\times \\frac {\\min(t^*, b^*)} {\\max(t^*,b^*)}}</script><p> center-ness center-ness  $[0,1]$ BCE loss </p>\n<p><strong> center-ness  </strong> box  ranking NMS</p>\n<p> center-ness  gt box  location </p>\n<h1 id=\"CornerNet\"><a href=\"#CornerNet\" class=\"headerlink\" title=\"CornerNet\"></a>CornerNet</h1><p>anchor based 1.  anchor2. anchor  aspect ratio  multi-scale feature </p>\n<p> anchor free </p>\n<ol>\n<li>box  4  <code>corner pooling</code><code>corner pooling</code> encoding  location  feature vector feature vector encoding </li>\n<li> box  feature  size  <code>(w,h)</code> O(wh) anchor box  anchor  w  h  anchor  size  wh  feature  anchor  wh  $O(w^2h^2)$ anchor  feature map  anchor  1  w  2  w-1   w  1  $w+(w-1)+\\cdots +1$ feature  anchor  $(1+2+\\cdots+w)(1+2+\\cdots+h)=\\frac {w(w+1)h(h+1)} 4$anchor based  anchor  feature  location  scale  aspect ratio  anchor  K  $Kwh$ </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>base ConvNet  hourglass network corner pooling  corner pooling hourglass network  feature  pooling  heatmapsembeddings  offsets</p>\n<p><strong>heatmap:</strong></p>\n<p> heatmaps heatmap  C channels C heatmap  $H \\times W$heatmap  location  heatmap  binary mask</p>\n<p> corner  location  location  location  corner  corner  location  location corner box  gt box gt box  IOU  t t  0.3</p>\n<p></p>\n<script type=\"math/tex; mode=display\">f_{cij}=\\begin{cases} e^{-\\frac {x^2+y^2}{2 \\sigma^2}} & x^2+y^2 \\le r^2 \\\\ 0 & \\text{otherwise} \\end{cases}</script><p> <code>(i,j)</code>  location $x, y$  location  corner $c$  gt $\\sigma=r/3$ $r$ </p>\n<p>heatmap  location  corner  focal loss</p>\n<script type=\"math/tex; mode=display\">L_{det}=-\\frac 1 N \\sum_{c=1}^C\\sum_{i=1}^H \\sum_{j=1}^W \\begin{cases} (1-p_{cij})^{\\alpha} \\log p_{cij} & y_{cij}=1 \\\\ (1-f_{cij})^{\\beta}p_{cij}^{\\alpha} \\log (1-p_{cij}) & o.w. \\end{cases}</script><p>$p_{cij}$  heatmap  location $y_{cij}$  heatmap  gt target N  image  object $\\alpha=2, \\ \\beta=4$  corner  negative location </p>\n<p><strong>offset:</strong></p>\n<p>hourglass  feature size  image size  n gt corner $(x,y)$  heatmap  $(\\lfloor x/n, y/n \\rfloor)$ image  $[0,n)$size  IOUgt offset </p>\n<script type=\"math/tex; mode=display\">\\mathbf o_k=\\left(\\frac {x_k} n - \\lfloor \\frac {x_k} n \\rfloor, \\frac {y_k} n - \\lfloor \\frac {y_k} n \\rfloor \\right)</script><p> $k$  k  gt corner offset  $\\hat \\mathbf o_k$ smooth L1 </p>\n<p><strong>embedding:</strong></p>\n<p> corner  corner  gt box</p>\n<p> corner  embedding vector corner  gt box embedding  vector  L1 </p>\n<p> embedding  target  <code>pull</code>  <code>push</code>  $e_{tk}$  k  corner  embedding$e_{bk}$  k  corner  embedding </p>\n<script type=\"math/tex; mode=display\">L_{pull}=\\frac 1 N \\sum_{k=1}^N [(e_{tk}-e_k)^2+(e_{bk}-e_k)^2]</script><script type=\"math/tex; mode=display\">L_{push}=\\frac 1 {N(N-1)} \\sum_{k=1}^N \\sum_{j=1, j\\ne k}^N \\max (0, \\Delta-|e_k-e_j|)</script><script type=\"math/tex; mode=display\">e_k=\\frac {e_{tk}+e_{bk}} 2</script><p>N  image $\\Delta=1$  corner  embeding </p>\n<p> K  top-left  K  bottom-right  $K^2$  pair  pair  embedding  L1  0.5 pair  heatmap  soft nms</p>\n<h2 id=\"Corner-Pooling\"><a href=\"#Corner-Pooling\" class=\"headerlink\" title=\"Corner Pooling\"></a>Corner Pooling</h2><p> hourglass  feature <code>heatmap, offset, embedding</code> Corner Pooling </p>\n<p>hourglass  $f_t, f_l, f_b, f_r$    side $f_t, f_l$ $f_b, f_r$  corner pooling  feature size  $H \\times W$ location <code>(i,j)</code>  $f_t$  corner pooling  <code>(i,j)</code>  <code>(H,j)</code>  location  max  $t_{ij}$ location  max  $l_{ij}$</p>\n<script type=\"math/tex; mode=display\">t_{ij}=\\begin{cases} \\max[f_t(i,j), t_{(i+1)j}] & i < H \\\\ f_t(H,j) & i=H \\end{cases}</script><script type=\"math/tex; mode=display\">l_{ij}=\\begin{cases} \\max[f_l(i,j), l_{i(j+1)}] & i < H \\\\ f_l(i,W) & i=H \\end{cases}</script><p> $f_t$ $f_l$</p>\n<p> 2<br><img src=\"/images/obj_det/anchor_free_fig2.png\" alt=\"\"><center> 2. backbone  residule module shortcut  2x conv left-most  top most corner pooling  element-wise add conv  shortcut  mergeelement-wise add)</center></p>\n<h2 id=\"Hourglass-Network\"><a href=\"#Hourglass-Network\" class=\"headerlink\" title=\"Hourglass Network\"></a>Hourglass Network</h2><p> backbone  VGGResNet  densenet  hourglass </p>\n<p>Hourglass network  hourglass Hourglass  input feature  resolution maxpooling  skip layer  feature  hourglass  level </p>\n<p> stride=2  conv  maxpooling</p>\n<p> </p>\n<script type=\"math/tex; mode=display\">L=L_{det}+\\alpha L_{pull} + \\beta L_{push} + \\gamma L_{off}</script>"},{"title":"lightweight","date":"2021-03-05T08:18:13.000Z","_content":"\n# ThunderNet\n(two-stage detector)\n\n CV  real-time  two-stage  real-time  two-stage  ThunderNet\n\n\n\n1.  backbone  backbone  `SNet`\n2.  Light-Head R-CNN  detection head \n3.  RPN  R-CNN  subnet \n4. small backbone  `Context Enhancement Module`  `Spatial Attention Module`CEM  scale  feature backbone  feature local  global SAM  RPN  RoI warping \n5. input resolution`320x320` size  inference \n\n## backbone\n\n__Receptive Field:__\n\n encode  long-range \n\n__early & late stage feature:__\n\n\n\n\n__SNet__\n\nSNet  real-time  backboneSNet  ShuffleNetV2  `3x3` depthwise conv  `5x5` depthwise conv\n\ndepthwise conv:  $c_{in}$  $k \\times k$  feature  shape  feature shape  $1 \\times 1 \\times c_{in}\\times c_{out}$  feature channel  $c_{out}$ \n\n## Detection Part\n RPN  Detection HeadLight-Head R-CNN  detection head  backbone  heavy backbone  dection head  imbalance\n\n RPN 256-d `3x3` conv  `5x5`  depthwise  256-d `1x1` convanchor  scale`{32, 64, 128, 256, 512}`aspect ratio`{1:2, 3:4, 1:1, 4:3, 2:1}`\n\ndetection head Light-head R-CNN  thin feature map $\\alpha \\times p \\times p$ $p=7, \\ \\alpha=10$ thundernet  backbone  input image size  $\\alpha=5$ PSRoI PSRoI  feature  245-d R-CNN subnet  fc  1024-d\n\n## CEM\ncontext enhancement module\n\nLight-Head R-CNN  global convolutional networkGCN  thin feature mapGCN  large kernel Receptive Field  encode  GCN  SNet thundernet  GCN CEM \n\n FPN FPN multi-scale   featureCEM merge  layer  feature$C_4, \\ C_5, \\ C_{glb}$ $C_{glb}$  global feature $C_5$  global average pooling  scale  feature  `1x1-245` conv channel  245 $C_5$  `2x` upsample $C_4$  feature  size $C_{glb}$  broadcast  $C_4$  feature  size spatial size  feature \n\n## SAM\nspatial attention module\n\n RoI warping  feature  thin feature maps  region  feature  region  feature  thundernet  feature  SAM \n\nSAM  RPN  RoI warping  feature RPN  RPN  feature SAM 1. RPN  feature2. CEM  thin feature mapsSAM  feature \n$$\\mathcal F^{SAM}=\\mathcal F^{CEM} \\cdot sigmoid[\\theta(\\mathcal F^{RPN})]$$\n $\\theta$  $\\mathcal F^{RPN}$  $\\mathcal F^{CEM}$  `1x1` conv \n\nSAM  RoI warping \n\nthunernet  1\n\n![](/images/obj_det/lightweight_fig1.png)<center> 1</center>\n\n# Light-Head R-CNN\n(two-stage detector)\n\n detection head\n1. L large backbone ResNet101\n2. S small backbone Xception\n\nbackbone  conv block  $C_5$$C_5$  separable conv `kx1`  `1xk`  conv channel  $10 \\times p \\times p$ R-FCN  channel  $(C+1) \\times p \\times p$$p \\times p$  bin positive-sensitive R-FCN small\n\n\n__R-CNN subnet__\n\nPSRoI pooling  2048-d box  C-d  4-d \n\n__RPN__\n\nRPN  $C_4$  anchor box  proposalsanchor  scale  `{32,64,128,256,512}`aspect ratio  `{1:2,1:1,2:1}`\n\n\n![](/images/obj_det/lightweight_fig2.png)<center> 2 </center>","source":"_posts/obj_det/lightweight.md","raw":"---\ntitle: lightweight\ndate: 2021-03-05 16:18:13\ntags:\n---\n\n# ThunderNet\n(two-stage detector)\n\n CV  real-time  two-stage  real-time  two-stage  ThunderNet\n\n\n\n1.  backbone  backbone  `SNet`\n2.  Light-Head R-CNN  detection head \n3.  RPN  R-CNN  subnet \n4. small backbone  `Context Enhancement Module`  `Spatial Attention Module`CEM  scale  feature backbone  feature local  global SAM  RPN  RoI warping \n5. input resolution`320x320` size  inference \n\n## backbone\n\n__Receptive Field:__\n\n encode  long-range \n\n__early & late stage feature:__\n\n\n\n\n__SNet__\n\nSNet  real-time  backboneSNet  ShuffleNetV2  `3x3` depthwise conv  `5x5` depthwise conv\n\ndepthwise conv:  $c_{in}$  $k \\times k$  feature  shape  feature shape  $1 \\times 1 \\times c_{in}\\times c_{out}$  feature channel  $c_{out}$ \n\n## Detection Part\n RPN  Detection HeadLight-Head R-CNN  detection head  backbone  heavy backbone  dection head  imbalance\n\n RPN 256-d `3x3` conv  `5x5`  depthwise  256-d `1x1` convanchor  scale`{32, 64, 128, 256, 512}`aspect ratio`{1:2, 3:4, 1:1, 4:3, 2:1}`\n\ndetection head Light-head R-CNN  thin feature map $\\alpha \\times p \\times p$ $p=7, \\ \\alpha=10$ thundernet  backbone  input image size  $\\alpha=5$ PSRoI PSRoI  feature  245-d R-CNN subnet  fc  1024-d\n\n## CEM\ncontext enhancement module\n\nLight-Head R-CNN  global convolutional networkGCN  thin feature mapGCN  large kernel Receptive Field  encode  GCN  SNet thundernet  GCN CEM \n\n FPN FPN multi-scale   featureCEM merge  layer  feature$C_4, \\ C_5, \\ C_{glb}$ $C_{glb}$  global feature $C_5$  global average pooling  scale  feature  `1x1-245` conv channel  245 $C_5$  `2x` upsample $C_4$  feature  size $C_{glb}$  broadcast  $C_4$  feature  size spatial size  feature \n\n## SAM\nspatial attention module\n\n RoI warping  feature  thin feature maps  region  feature  region  feature  thundernet  feature  SAM \n\nSAM  RPN  RoI warping  feature RPN  RPN  feature SAM 1. RPN  feature2. CEM  thin feature mapsSAM  feature \n$$\\mathcal F^{SAM}=\\mathcal F^{CEM} \\cdot sigmoid[\\theta(\\mathcal F^{RPN})]$$\n $\\theta$  $\\mathcal F^{RPN}$  $\\mathcal F^{CEM}$  `1x1` conv \n\nSAM  RoI warping \n\nthunernet  1\n\n![](/images/obj_det/lightweight_fig1.png)<center> 1</center>\n\n# Light-Head R-CNN\n(two-stage detector)\n\n detection head\n1. L large backbone ResNet101\n2. S small backbone Xception\n\nbackbone  conv block  $C_5$$C_5$  separable conv `kx1`  `1xk`  conv channel  $10 \\times p \\times p$ R-FCN  channel  $(C+1) \\times p \\times p$$p \\times p$  bin positive-sensitive R-FCN small\n\n\n__R-CNN subnet__\n\nPSRoI pooling  2048-d box  C-d  4-d \n\n__RPN__\n\nRPN  $C_4$  anchor box  proposalsanchor  scale  `{32,64,128,256,512}`aspect ratio  `{1:2,1:1,2:1}`\n\n\n![](/images/obj_det/lightweight_fig2.png)<center> 2 </center>","slug":"obj_det/lightweight","published":1,"updated":"2021-03-06T06:38:12.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91f002zp0djcsdvcz2k","content":"<h1 id=\"ThunderNet\"><a href=\"#ThunderNet\" class=\"headerlink\" title=\"ThunderNet\"></a>ThunderNet</h1><p>(two-stage detector)</p>\n<p> CV  real-time  two-stage  real-time  two-stage  ThunderNet</p>\n<p></p>\n<ol>\n<li> backbone  backbone  <code>SNet</code></li>\n<li> Light-Head R-CNN  detection head </li>\n<li> RPN  R-CNN  subnet </li>\n<li>small backbone  <code>Context Enhancement Module</code>  <code>Spatial Attention Module</code>CEM  scale  feature backbone  feature local  global SAM  RPN  RoI warping </li>\n<li>input resolution<code>320x320</code> size  inference </li>\n</ol>\n<h2 id=\"backbone\"><a href=\"#backbone\" class=\"headerlink\" title=\"backbone\"></a>backbone</h2><p><strong>Receptive Field:</strong></p>\n<p> encode  long-range </p>\n<p><strong>early &amp; late stage feature:</strong></p>\n<p></p>\n<p><strong>SNet</strong></p>\n<p>SNet  real-time  backboneSNet  ShuffleNetV2  <code>3x3</code> depthwise conv  <code>5x5</code> depthwise conv</p>\n<p>depthwise conv:  $c_{in}$  $k \\times k$  feature  shape  feature shape  $1 \\times 1 \\times c_{in}\\times c_{out}$  feature channel  $c_{out}$ </p>\n<h2 id=\"Detection-Part\"><a href=\"#Detection-Part\" class=\"headerlink\" title=\"Detection Part\"></a>Detection Part</h2><p> RPN  Detection HeadLight-Head R-CNN  detection head  backbone  heavy backbone  dection head  imbalance</p>\n<p> RPN 256-d <code>3x3</code> conv  <code>5x5</code>  depthwise  256-d <code>1x1</code> convanchor  scale<code>&#123;32, 64, 128, 256, 512&#125;</code>aspect ratio<code>&#123;1:2, 3:4, 1:1, 4:3, 2:1&#125;</code></p>\n<p>detection head Light-head R-CNN  thin feature map $\\alpha \\times p \\times p$ $p=7, \\ \\alpha=10$ thundernet  backbone  input image size  $\\alpha=5$ PSRoI PSRoI  feature  245-d R-CNN subnet  fc  1024-d</p>\n<h2 id=\"CEM\"><a href=\"#CEM\" class=\"headerlink\" title=\"CEM\"></a>CEM</h2><p>context enhancement module</p>\n<p>Light-Head R-CNN  global convolutional networkGCN  thin feature mapGCN  large kernel Receptive Field  encode  GCN  SNet thundernet  GCN CEM </p>\n<p> FPN FPN multi-scale   featureCEM merge  layer  feature$C_4, \\ C_5, \\ C_{glb}$ $C_{glb}$  global feature $C_5$  global average pooling  scale  feature  <code>1x1-245</code> conv channel  245 $C_5$  <code>2x</code> upsample $C_4$  feature  size $C_{glb}$  broadcast  $C_4$  feature  size spatial size  feature </p>\n<h2 id=\"SAM\"><a href=\"#SAM\" class=\"headerlink\" title=\"SAM\"></a>SAM</h2><p>spatial attention module</p>\n<p> RoI warping  feature  thin feature maps  region  feature  region  feature  thundernet  feature  SAM </p>\n<p>SAM  RPN  RoI warping  feature RPN  RPN  feature SAM 1. RPN  feature2. CEM  thin feature mapsSAM  feature </p>\n<script type=\"math/tex; mode=display\">\\mathcal F^{SAM}=\\mathcal F^{CEM} \\cdot sigmoid[\\theta(\\mathcal F^{RPN})]</script><p> $\\theta$  $\\mathcal F^{RPN}$  $\\mathcal F^{CEM}$  <code>1x1</code> conv </p>\n<p>SAM  RoI warping </p>\n<p>thunernet  1</p>\n<p><img src=\"/images/obj_det/lightweight_fig1.png\" alt=\"\"><center> 1</center></p>\n<h1 id=\"Light-Head-R-CNN\"><a href=\"#Light-Head-R-CNN\" class=\"headerlink\" title=\"Light-Head R-CNN\"></a>Light-Head R-CNN</h1><p>(two-stage detector)</p>\n<p> detection head</p>\n<ol>\n<li>L large backbone ResNet101</li>\n<li>S small backbone Xception</li>\n</ol>\n<p>backbone  conv block  $C_5$$C_5$  separable conv <code>kx1</code>  <code>1xk</code>  conv channel  $10 \\times p \\times p$ R-FCN  channel  $(C+1) \\times p \\times p$$p \\times p$  bin positive-sensitive R-FCN small</p>\n<p><strong>R-CNN subnet</strong></p>\n<p>PSRoI pooling  2048-d box  C-d  4-d </p>\n<p><strong>RPN</strong></p>\n<p>RPN  $C_4$  anchor box  proposalsanchor  scale  <code>&#123;32,64,128,256,512&#125;</code>aspect ratio  <code>&#123;1:2,1:1,2:1&#125;</code></p>\n<p><br><img src=\"/images/obj_det/lightweight_fig2.png\" alt=\"\"><center> 2 </center></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ThunderNet\"><a href=\"#ThunderNet\" class=\"headerlink\" title=\"ThunderNet\"></a>ThunderNet</h1><p>(two-stage detector)</p>\n<p> CV  real-time  two-stage  real-time  two-stage  ThunderNet</p>\n<p></p>\n<ol>\n<li> backbone  backbone  <code>SNet</code></li>\n<li> Light-Head R-CNN  detection head </li>\n<li> RPN  R-CNN  subnet </li>\n<li>small backbone  <code>Context Enhancement Module</code>  <code>Spatial Attention Module</code>CEM  scale  feature backbone  feature local  global SAM  RPN  RoI warping </li>\n<li>input resolution<code>320x320</code> size  inference </li>\n</ol>\n<h2 id=\"backbone\"><a href=\"#backbone\" class=\"headerlink\" title=\"backbone\"></a>backbone</h2><p><strong>Receptive Field:</strong></p>\n<p> encode  long-range </p>\n<p><strong>early &amp; late stage feature:</strong></p>\n<p></p>\n<p><strong>SNet</strong></p>\n<p>SNet  real-time  backboneSNet  ShuffleNetV2  <code>3x3</code> depthwise conv  <code>5x5</code> depthwise conv</p>\n<p>depthwise conv:  $c_{in}$  $k \\times k$  feature  shape  feature shape  $1 \\times 1 \\times c_{in}\\times c_{out}$  feature channel  $c_{out}$ </p>\n<h2 id=\"Detection-Part\"><a href=\"#Detection-Part\" class=\"headerlink\" title=\"Detection Part\"></a>Detection Part</h2><p> RPN  Detection HeadLight-Head R-CNN  detection head  backbone  heavy backbone  dection head  imbalance</p>\n<p> RPN 256-d <code>3x3</code> conv  <code>5x5</code>  depthwise  256-d <code>1x1</code> convanchor  scale<code>&#123;32, 64, 128, 256, 512&#125;</code>aspect ratio<code>&#123;1:2, 3:4, 1:1, 4:3, 2:1&#125;</code></p>\n<p>detection head Light-head R-CNN  thin feature map $\\alpha \\times p \\times p$ $p=7, \\ \\alpha=10$ thundernet  backbone  input image size  $\\alpha=5$ PSRoI PSRoI  feature  245-d R-CNN subnet  fc  1024-d</p>\n<h2 id=\"CEM\"><a href=\"#CEM\" class=\"headerlink\" title=\"CEM\"></a>CEM</h2><p>context enhancement module</p>\n<p>Light-Head R-CNN  global convolutional networkGCN  thin feature mapGCN  large kernel Receptive Field  encode  GCN  SNet thundernet  GCN CEM </p>\n<p> FPN FPN multi-scale   featureCEM merge  layer  feature$C_4, \\ C_5, \\ C_{glb}$ $C_{glb}$  global feature $C_5$  global average pooling  scale  feature  <code>1x1-245</code> conv channel  245 $C_5$  <code>2x</code> upsample $C_4$  feature  size $C_{glb}$  broadcast  $C_4$  feature  size spatial size  feature </p>\n<h2 id=\"SAM\"><a href=\"#SAM\" class=\"headerlink\" title=\"SAM\"></a>SAM</h2><p>spatial attention module</p>\n<p> RoI warping  feature  thin feature maps  region  feature  region  feature  thundernet  feature  SAM </p>\n<p>SAM  RPN  RoI warping  feature RPN  RPN  feature SAM 1. RPN  feature2. CEM  thin feature mapsSAM  feature </p>\n<script type=\"math/tex; mode=display\">\\mathcal F^{SAM}=\\mathcal F^{CEM} \\cdot sigmoid[\\theta(\\mathcal F^{RPN})]</script><p> $\\theta$  $\\mathcal F^{RPN}$  $\\mathcal F^{CEM}$  <code>1x1</code> conv </p>\n<p>SAM  RoI warping </p>\n<p>thunernet  1</p>\n<p><img src=\"/images/obj_det/lightweight_fig1.png\" alt=\"\"><center> 1</center></p>\n<h1 id=\"Light-Head-R-CNN\"><a href=\"#Light-Head-R-CNN\" class=\"headerlink\" title=\"Light-Head R-CNN\"></a>Light-Head R-CNN</h1><p>(two-stage detector)</p>\n<p> detection head</p>\n<ol>\n<li>L large backbone ResNet101</li>\n<li>S small backbone Xception</li>\n</ol>\n<p>backbone  conv block  $C_5$$C_5$  separable conv <code>kx1</code>  <code>1xk</code>  conv channel  $10 \\times p \\times p$ R-FCN  channel  $(C+1) \\times p \\times p$$p \\times p$  bin positive-sensitive R-FCN small</p>\n<p><strong>R-CNN subnet</strong></p>\n<p>PSRoI pooling  2048-d box  C-d  4-d </p>\n<p><strong>RPN</strong></p>\n<p>RPN  $C_4$  anchor box  proposalsanchor  scale  <code>&#123;32,64,128,256,512&#125;</code>aspect ratio  <code>&#123;1:2,1:1,2:1&#125;</code></p>\n<p><br><img src=\"/images/obj_det/lightweight_fig2.png\" alt=\"\"><center> 2 </center></p>\n"},{"title":"One-stage Object Detection","date":"2021-02-23T02:36:44.000Z","p":"obj_det/one_stage","mathjax":true,"_content":"\n# YOLOv1\n\n1. one-stage detector\n\n2. unified detectionimage  `SxS`  feature map image  `SxS`  grid grid cell grid cell  `S*S*(C+B*5)` C  B  grid cell box  4  1  conf conf  box  box  gt box  IOUC `Pr(Classi|Object)` box  `B`  conf \n    $$Pr(Class_i|Object) * P(conf)$$\n3.  SSD  default box Faster R-CNN  anchor/proposalYOLO  feature map  box  conf box \n\n4. input image size  `448x448`6`7x7`feature fully connectionunit `1470=7*7*30`feature  box conf \n\n5.  feature map  fully connection grid cell  (x,y) <b> cell </b>\n\n# YOLOv2\n\nYOLOv1  fast  SOTA  region proposal-based YOLOv1  recall YOLOv2 \n1. Batch Normalization\n\n2. High Resolution\n    \\\n    YOLOv1 baseline  image size  `224x224`image size  `448x448` 10  batch\n    ```\n    int dim = (rand() % 10 + 10) * 32\n    ```\n     32 YOLOv2  5 YOLOv1  6 feature  higher resolution anchor boxfeature  position  anchor box \n3. Convolution with Anchor Boxes\n    \\\n     Faster R-CNN  RPN anchor boxfeature  position  k  anchor k  anchor gt box k-means IOU\n    ```\n    d(anchor, cluster-center)=1-IOU(anchor, cluster-center)\n    ```\n    \n4. Direct location prediction\n    \\\n     region proposal  $(t_x, t_y)$ offsetanchor boxbox \n    $$x=t_x \\cdot w_a+x_a, \\quad y=t_y \\cdot h_a + y_a$$\n     box  anchor  box <b></b>YOLOv2  YOLOv1  cell cell `(i,j)`  anchor  $t_x, t_y, t_w, t_h$feature  $(w_f, h_f)$anchor  feature  $(w_a,h_a)$ box \n    $$x=(i+t_x)/w_f$$\n    $$y=(j+t_y)/h_f$$\n    $$w=\\exp(t_w) \\cdot w_a/w_f$$\n    $$h=\\exp(t_h) \\cdot h_a/h_f$$\n\n box  5  4  1  conf C  $k \\cdot s \\cdot s \\cdot (5+C)$ k  anchor \n\n# YOLOv3\n idea  YOLO \n\n1.  YOLOv2  anchor box k  anchor anchor  4  offset1  objectness conf C  offset  YOLOv2 \n\n2.  gt box  IOU  anchor  conf target  1 IOU  IOU 0.5 anchor IOU  0.5  anchor anchor  conf  offset \n\n3. YOLOv3  scale  feature YOLOv1  YOLOv2  scale  feature FPN  multi-scale  features feature  position  3  anchor boxes feature size  `NxN` tensor  `NxNx[3*(4+1+C)]` C  foreground \n\n4. Baseline  darknet-53  feature ImageNet  yolov3.cfg  ResNet  shortcut  deep  9  anchor size 3  scale feature  anchor\n\n# SSD\n1. baseline: VGG \n2. one-stage detector Faster R-CNN  proposals  feature map  position  prior boxk  feature maps  `(c+4)k` filters  conv fully connectionposition  `(c+4)k`  c  box  offsets multi scale  feature maps\n3.  300x300  6  scale  feature feature  prior box  `4,6,6,6,4,4` scale  feature  `38, 19, 10, 5, 3, 1` image  prior box  `(38*38+3*3+1*1)*4+(19*19+10*10+5*5)+6=8732`\n4.  multi scale feature maps level  feature  m  scale  feature m=6 level  feature  default box \n    $$s_k=s_{min}+\\frac {s_{max}-s_{min}}{m-1}(k-1), \\ k \\in [1,m]$$\n     `[min, max]=[0.2, 0.9]` scale  s \n5. image default box 3 8732 default box gt  IOU  IOU > 0.5  unbalanced conf  top N  N  3  level  feature  hard negative mining\n\n# DSSD\n\n SSD  deconvolution layer SSD  level  feautre level  feature  prediction module  feature  deconvolution SSD  resolution  feature  prediction module  feature  deconvolution SSD  resolution  feature  SSD  level  feature  hour-glass  encoder-decoder FPN  top-down  upsample  deconvolution\n\n\n# RetinaNet(Focal Loss)\n\n## Loss\none-stage  two-stage one-stage  location  fg-bg  Focal Loss loss  focus on hard examples\n\n>  OHEM  one-stage \n\n### Balanced Cross Entropy\n$$CE(p,y)=\\begin{cases} - \\alpha \\log p & y=1 \\\\ -(1-\\alpha) \\log(1-p) & y=0\\end{cases}$$\n $\\alpha \\in [0, 1]$ Nfg  $N_1$bg  $N_0$$N=N_1+N_0$\n$\\alpha=\\frac {N_0} N$\n\n### Focal Loss\n$$FL(p,y)=\\begin{cases} - 1-p)^{\\gamma} \\log p & y=1 \\\\ -p^{\\gamma} \\log(1-p) & y=0\\end{cases}$$\n $\\gamma>0$\n\n\n$$p_t=\\begin{cases} p & y=1 \\\\ 1-p & y=0\\end{cases}$$\n$$\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0\\end{cases}$$\n\n $\\alpha$ balanced CE \n$$CE(p_t)=-\\alpha_t \\log(p_t)$$\n\nBase Focal Loss \n$$FL(p_t)=-(1-p_t)^{\\gamma} \\log (p_t)$$\n\n$\\alpha$ balanced Focal Loss \n$$FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log (p_t)$$\n\n## RetinaNet\n Focal Loss  RetinaNetFocal Loss  Classification Subnet \n\n__backbone:__ FPN on ResNet $P_3 \\sim P_7$ level  feature $P_3 \\sim P_5$  ResNet  $C_3 \\sim C_5$  $3 \\times 3$-s2  conv ReLU  $P_6$ ReLU + $3 \\times 3$-s2 conv  $P_7$$P_l$ feature  stride  $2^l$ feature  C=256 channelsfeature  anchor  base size  $2^{l+2}$ position  9  anchorsaspect ratio  anchor  K 4 \n\n$IOU \\ge 0.5$   anchor$IOU < 0.4$  anchor$0.4 \\le IOU < 0.5$  anchor  anchor   gt box  offset box regression targetclassification target  one-hot vector anchor  entry  1  entry  0\n\nbackbone  subnetworks box  level  feature \n\n__Classification Subnet:__  FCN  pyramid level  pyramid feature  4  `3x3` conv conv  C=256  filters conv  ReLU `3x3`  conv `KA`  filters K A  anchor  RPN  deep \n\n__Box Regression Subnet:__  Classification Subnet  conv  filters  `4A`\n\n subnet  FPN  RetinaNet\n\n heuristic samplingRPN hard example mining(OHEM, SSD)  mini-batch 256 anchors Focal Loss image  anchor  ~100k anchor   anchor  focal loss  anchor  Focal Loss  anchor \n\n# STDN\nScale-Transferrable Detection Network scale \n\n Faster RCNN  scale  feature receptive field  scale  aspect ratio  SSD  depth  layer  feature anchor  scale  feature  scale  scale  low feature  low feature  FPN top-down  feature  feature FPN  feature pyramids FPN FPN  Faster RCNN  baseline  FPN  two-stage \n\nSTDN  DenseNet  baseline DenseNet  feature concatenation  feature  DenseNet  DenseBlock  Layer  Scale-Transfer ModuleSTM multi scale featuresSTM \n\n1.  DenseNet-169  baseline (growth rate=32)\n2.  stem block  3  `3x3`  conv  `2x2`  mean-pooling `3x3` conv  stride=2 DenseNet  `7x7-s2`  `3x3-s2`  conv\n3.  input size  `300x300`DenseNet   feature size  `9x9`\n4.  stem --> DB1 --> T1 --> DB2 --> T2 --> DB3 --> T3 --> DB4 => STM DB  DenseBlockT  Transition LayerT3  `640x9x9`STM  6  scale  features\n    | output size | layer |\n    | -- | -- |\n    |800x1x1 | 9x9 mean-pool, stride 9 (Input DB4_concat5)|\n    |960x3x3 | 3x3 mean-pool, stride 3 (Input DB4_concat10)|\n    |1120x5x5| 2x2 mean-pool, stride 2 (Input DB4_concat15)|\n    |1280x9x9| Identity layer (Input DB4_concat20) |\n    |360x18x18| 2x scale-transfer layer (Input DB4_concat25)|\n    |104x36x36| 4x scale-transfer layer (Input DB4_concat32)|\n\n     DenseBlock  $l$  layer  output channen  $k_0+l*32$ layer  `9x9`  scale  feature size  `800x1x1` layer  DB4  5  layer  output channel  $640+5\\times 32=800$ layer  DB4  layer \n\n    - Identity layer \n    - scale-transfer layer  channel  $r^2$ $r \\times$ scale-transfer layer $W, H$  $r$ rearrange \n        $$I_{x,y,c}^{SR}=I_{\\lfloor x/r \\rfloor,\\lfloor y/r \\rfloor, r\\cdot mod(y,r)+mod(x,r)+c\\cdot r^2}^{LR}$$\n\n5.  scale  feature  dense anchor anchor  gt box  IOU  IOU > 0.5 anchor  hard negative mining  `1:3`\n\n6.  feature  box  `1x1` conv  `3x3` conv  conv  BN+ReLU conv  channel  `KA` K fg  +  bgA  position  anchor  conv  channel  `4A`","source":"_posts/obj_det/one_stage.md","raw":"---\ntitle: One-stage Object Detection\ndate: 2021-02-23 10:36:44\ntags: Object Detection\np: obj_det/one_stage\nmathjax: true\n---\n\n# YOLOv1\n\n1. one-stage detector\n\n2. unified detectionimage  `SxS`  feature map image  `SxS`  grid grid cell grid cell  `S*S*(C+B*5)` C  B  grid cell box  4  1  conf conf  box  box  gt box  IOUC `Pr(Classi|Object)` box  `B`  conf \n    $$Pr(Class_i|Object) * P(conf)$$\n3.  SSD  default box Faster R-CNN  anchor/proposalYOLO  feature map  box  conf box \n\n4. input image size  `448x448`6`7x7`feature fully connectionunit `1470=7*7*30`feature  box conf \n\n5.  feature map  fully connection grid cell  (x,y) <b> cell </b>\n\n# YOLOv2\n\nYOLOv1  fast  SOTA  region proposal-based YOLOv1  recall YOLOv2 \n1. Batch Normalization\n\n2. High Resolution\n    \\\n    YOLOv1 baseline  image size  `224x224`image size  `448x448` 10  batch\n    ```\n    int dim = (rand() % 10 + 10) * 32\n    ```\n     32 YOLOv2  5 YOLOv1  6 feature  higher resolution anchor boxfeature  position  anchor box \n3. Convolution with Anchor Boxes\n    \\\n     Faster R-CNN  RPN anchor boxfeature  position  k  anchor k  anchor gt box k-means IOU\n    ```\n    d(anchor, cluster-center)=1-IOU(anchor, cluster-center)\n    ```\n    \n4. Direct location prediction\n    \\\n     region proposal  $(t_x, t_y)$ offsetanchor boxbox \n    $$x=t_x \\cdot w_a+x_a, \\quad y=t_y \\cdot h_a + y_a$$\n     box  anchor  box <b></b>YOLOv2  YOLOv1  cell cell `(i,j)`  anchor  $t_x, t_y, t_w, t_h$feature  $(w_f, h_f)$anchor  feature  $(w_a,h_a)$ box \n    $$x=(i+t_x)/w_f$$\n    $$y=(j+t_y)/h_f$$\n    $$w=\\exp(t_w) \\cdot w_a/w_f$$\n    $$h=\\exp(t_h) \\cdot h_a/h_f$$\n\n box  5  4  1  conf C  $k \\cdot s \\cdot s \\cdot (5+C)$ k  anchor \n\n# YOLOv3\n idea  YOLO \n\n1.  YOLOv2  anchor box k  anchor anchor  4  offset1  objectness conf C  offset  YOLOv2 \n\n2.  gt box  IOU  anchor  conf target  1 IOU  IOU 0.5 anchor IOU  0.5  anchor anchor  conf  offset \n\n3. YOLOv3  scale  feature YOLOv1  YOLOv2  scale  feature FPN  multi-scale  features feature  position  3  anchor boxes feature size  `NxN` tensor  `NxNx[3*(4+1+C)]` C  foreground \n\n4. Baseline  darknet-53  feature ImageNet  yolov3.cfg  ResNet  shortcut  deep  9  anchor size 3  scale feature  anchor\n\n# SSD\n1. baseline: VGG \n2. one-stage detector Faster R-CNN  proposals  feature map  position  prior boxk  feature maps  `(c+4)k` filters  conv fully connectionposition  `(c+4)k`  c  box  offsets multi scale  feature maps\n3.  300x300  6  scale  feature feature  prior box  `4,6,6,6,4,4` scale  feature  `38, 19, 10, 5, 3, 1` image  prior box  `(38*38+3*3+1*1)*4+(19*19+10*10+5*5)+6=8732`\n4.  multi scale feature maps level  feature  m  scale  feature m=6 level  feature  default box \n    $$s_k=s_{min}+\\frac {s_{max}-s_{min}}{m-1}(k-1), \\ k \\in [1,m]$$\n     `[min, max]=[0.2, 0.9]` scale  s \n5. image default box 3 8732 default box gt  IOU  IOU > 0.5  unbalanced conf  top N  N  3  level  feature  hard negative mining\n\n# DSSD\n\n SSD  deconvolution layer SSD  level  feautre level  feature  prediction module  feature  deconvolution SSD  resolution  feature  prediction module  feature  deconvolution SSD  resolution  feature  SSD  level  feature  hour-glass  encoder-decoder FPN  top-down  upsample  deconvolution\n\n\n# RetinaNet(Focal Loss)\n\n## Loss\none-stage  two-stage one-stage  location  fg-bg  Focal Loss loss  focus on hard examples\n\n>  OHEM  one-stage \n\n### Balanced Cross Entropy\n$$CE(p,y)=\\begin{cases} - \\alpha \\log p & y=1 \\\\ -(1-\\alpha) \\log(1-p) & y=0\\end{cases}$$\n $\\alpha \\in [0, 1]$ Nfg  $N_1$bg  $N_0$$N=N_1+N_0$\n$\\alpha=\\frac {N_0} N$\n\n### Focal Loss\n$$FL(p,y)=\\begin{cases} - 1-p)^{\\gamma} \\log p & y=1 \\\\ -p^{\\gamma} \\log(1-p) & y=0\\end{cases}$$\n $\\gamma>0$\n\n\n$$p_t=\\begin{cases} p & y=1 \\\\ 1-p & y=0\\end{cases}$$\n$$\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0\\end{cases}$$\n\n $\\alpha$ balanced CE \n$$CE(p_t)=-\\alpha_t \\log(p_t)$$\n\nBase Focal Loss \n$$FL(p_t)=-(1-p_t)^{\\gamma} \\log (p_t)$$\n\n$\\alpha$ balanced Focal Loss \n$$FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log (p_t)$$\n\n## RetinaNet\n Focal Loss  RetinaNetFocal Loss  Classification Subnet \n\n__backbone:__ FPN on ResNet $P_3 \\sim P_7$ level  feature $P_3 \\sim P_5$  ResNet  $C_3 \\sim C_5$  $3 \\times 3$-s2  conv ReLU  $P_6$ ReLU + $3 \\times 3$-s2 conv  $P_7$$P_l$ feature  stride  $2^l$ feature  C=256 channelsfeature  anchor  base size  $2^{l+2}$ position  9  anchorsaspect ratio  anchor  K 4 \n\n$IOU \\ge 0.5$   anchor$IOU < 0.4$  anchor$0.4 \\le IOU < 0.5$  anchor  anchor   gt box  offset box regression targetclassification target  one-hot vector anchor  entry  1  entry  0\n\nbackbone  subnetworks box  level  feature \n\n__Classification Subnet:__  FCN  pyramid level  pyramid feature  4  `3x3` conv conv  C=256  filters conv  ReLU `3x3`  conv `KA`  filters K A  anchor  RPN  deep \n\n__Box Regression Subnet:__  Classification Subnet  conv  filters  `4A`\n\n subnet  FPN  RetinaNet\n\n heuristic samplingRPN hard example mining(OHEM, SSD)  mini-batch 256 anchors Focal Loss image  anchor  ~100k anchor   anchor  focal loss  anchor  Focal Loss  anchor \n\n# STDN\nScale-Transferrable Detection Network scale \n\n Faster RCNN  scale  feature receptive field  scale  aspect ratio  SSD  depth  layer  feature anchor  scale  feature  scale  scale  low feature  low feature  FPN top-down  feature  feature FPN  feature pyramids FPN FPN  Faster RCNN  baseline  FPN  two-stage \n\nSTDN  DenseNet  baseline DenseNet  feature concatenation  feature  DenseNet  DenseBlock  Layer  Scale-Transfer ModuleSTM multi scale featuresSTM \n\n1.  DenseNet-169  baseline (growth rate=32)\n2.  stem block  3  `3x3`  conv  `2x2`  mean-pooling `3x3` conv  stride=2 DenseNet  `7x7-s2`  `3x3-s2`  conv\n3.  input size  `300x300`DenseNet   feature size  `9x9`\n4.  stem --> DB1 --> T1 --> DB2 --> T2 --> DB3 --> T3 --> DB4 => STM DB  DenseBlockT  Transition LayerT3  `640x9x9`STM  6  scale  features\n    | output size | layer |\n    | -- | -- |\n    |800x1x1 | 9x9 mean-pool, stride 9 (Input DB4_concat5)|\n    |960x3x3 | 3x3 mean-pool, stride 3 (Input DB4_concat10)|\n    |1120x5x5| 2x2 mean-pool, stride 2 (Input DB4_concat15)|\n    |1280x9x9| Identity layer (Input DB4_concat20) |\n    |360x18x18| 2x scale-transfer layer (Input DB4_concat25)|\n    |104x36x36| 4x scale-transfer layer (Input DB4_concat32)|\n\n     DenseBlock  $l$  layer  output channen  $k_0+l*32$ layer  `9x9`  scale  feature size  `800x1x1` layer  DB4  5  layer  output channel  $640+5\\times 32=800$ layer  DB4  layer \n\n    - Identity layer \n    - scale-transfer layer  channel  $r^2$ $r \\times$ scale-transfer layer $W, H$  $r$ rearrange \n        $$I_{x,y,c}^{SR}=I_{\\lfloor x/r \\rfloor,\\lfloor y/r \\rfloor, r\\cdot mod(y,r)+mod(x,r)+c\\cdot r^2}^{LR}$$\n\n5.  scale  feature  dense anchor anchor  gt box  IOU  IOU > 0.5 anchor  hard negative mining  `1:3`\n\n6.  feature  box  `1x1` conv  `3x3` conv  conv  BN+ReLU conv  channel  `KA` K fg  +  bgA  position  anchor  conv  channel  `4A`","slug":"obj_det/one_stage","published":1,"updated":"2021-02-26T07:41:20.627Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91f0030p0djcj8jbzwo","content":"<h1 id=\"YOLOv1\"><a href=\"#YOLOv1\" class=\"headerlink\" title=\"YOLOv1\"></a>YOLOv1</h1><ol>\n<li><p>one-stage detector</p>\n</li>\n<li><p>unified detectionimage  <code>SxS</code>  feature map image  <code>SxS</code>  grid grid cell grid cell  <code>S*S*(C+B*5)</code> C  B  grid cell box  4  1  conf conf  box  box  gt box  IOUC <code>Pr(Classi|Object)</code> box  <code>B</code>  conf </p>\n<script type=\"math/tex; mode=display\">Pr(Class_i|Object) * P(conf)</script></li>\n<li><p> SSD  default box Faster R-CNN  anchor/proposalYOLO  feature map  box  conf box </p>\n</li>\n<li><p>input image size  <code>448x448</code>6<code>7x7</code>feature fully connectionunit <code>1470=7*7*30</code>feature  box conf </p>\n</li>\n<li><p> feature map  fully connection grid cell  (x,y) <b> cell </b></p>\n</li>\n</ol>\n<h1 id=\"YOLOv2\"><a href=\"#YOLOv2\" class=\"headerlink\" title=\"YOLOv2\"></a>YOLOv2</h1><p>YOLOv1  fast  SOTA  region proposal-based YOLOv1  recall YOLOv2 </p>\n<ol>\n<li><p>Batch Normalization</p>\n</li>\n<li><p>High Resolution<br> \\<br> YOLOv1 baseline  image size  <code>224x224</code>image size  <code>448x448</code> 10  batch</p>\n <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int dim = (rand() % 10 + 10) * 32</span><br></pre></td></tr></table></figure>\n<p>  32 YOLOv2  5 YOLOv1  6 feature  higher resolution anchor boxfeature  position  anchor box </p>\n</li>\n<li><p>Convolution with Anchor Boxes<br> \\<br>  Faster R-CNN  RPN anchor boxfeature  position  k  anchor k  anchor gt box k-means IOU</p>\n <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d(anchor, cluster-center)=1-IOU(anchor, cluster-center)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Direct location prediction<br> \\<br>  region proposal  $(t_x, t_y)$ offsetanchor boxbox </p>\n<script type=\"math/tex; mode=display\">x=t_x \\cdot w_a+x_a, \\quad y=t_y \\cdot h_a + y_a</script><p>  box  anchor  box <b></b>YOLOv2  YOLOv1  cell cell <code>(i,j)</code>  anchor  $t_x, t_y, t_w, t_h$feature  $(w_f, h_f)$anchor  feature  $(w_a,h_a)$ box </p>\n<script type=\"math/tex; mode=display\">x=(i+t_x)/w_f</script><script type=\"math/tex; mode=display\">y=(j+t_y)/h_f</script><script type=\"math/tex; mode=display\">w=\\exp(t_w) \\cdot w_a/w_f</script><script type=\"math/tex; mode=display\">h=\\exp(t_h) \\cdot h_a/h_f</script></li>\n</ol>\n<p> box  5  4  1  conf C  $k \\cdot s \\cdot s \\cdot (5+C)$ k  anchor </p>\n<h1 id=\"YOLOv3\"><a href=\"#YOLOv3\" class=\"headerlink\" title=\"YOLOv3\"></a>YOLOv3</h1><p> idea  YOLO </p>\n<ol>\n<li><p> YOLOv2  anchor box k  anchor anchor  4  offset1  objectness conf C  offset  YOLOv2 </p>\n</li>\n<li><p> gt box  IOU  anchor  conf target  1 IOU  IOU 0.5 anchor IOU  0.5  anchor anchor  conf  offset </p>\n</li>\n<li><p>YOLOv3  scale  feature YOLOv1  YOLOv2  scale  feature FPN  multi-scale  features feature  position  3  anchor boxes feature size  <code>NxN</code> tensor  <code>NxNx[3*(4+1+C)]</code> C  foreground </p>\n</li>\n<li><p>Baseline  darknet-53  feature ImageNet  yolov3.cfg  ResNet  shortcut  deep  9  anchor size 3  scale feature  anchor</p>\n</li>\n</ol>\n<h1 id=\"SSD\"><a href=\"#SSD\" class=\"headerlink\" title=\"SSD\"></a>SSD</h1><ol>\n<li>baseline: VGG </li>\n<li>one-stage detector Faster R-CNN  proposals  feature map  position  prior boxk  feature maps  <code>(c+4)k</code> filters  conv fully connectionposition  <code>(c+4)k</code>  c  box  offsets multi scale  feature maps</li>\n<li> 300x300  6  scale  feature feature  prior box  <code>4,6,6,6,4,4</code> scale  feature  <code>38, 19, 10, 5, 3, 1</code> image  prior box  <code>(38*38+3*3+1*1)*4+(19*19+10*10+5*5)+6=8732</code></li>\n<li> multi scale feature maps level  feature  m  scale  feature m=6 level  feature  default box <script type=\"math/tex; mode=display\">s_k=s_{min}+\\frac {s_{max}-s_{min}}{m-1}(k-1), \\ k \\in [1,m]</script>  <code>[min, max]=[0.2, 0.9]</code> scale  s </li>\n<li>image default box 3 8732 default box gt  IOU  IOU &gt; 0.5  unbalanced conf  top N  N  3  level  feature  hard negative mining</li>\n</ol>\n<h1 id=\"DSSD\"><a href=\"#DSSD\" class=\"headerlink\" title=\"DSSD\"></a>DSSD</h1><p> SSD  deconvolution layer SSD  level  feautre level  feature  prediction module  feature  deconvolution SSD  resolution  feature  prediction module  feature  deconvolution SSD  resolution  feature  SSD  level  feature  hour-glass  encoder-decoder FPN  top-down  upsample  deconvolution</p>\n<h1 id=\"RetinaNet-Focal-Loss\"><a href=\"#RetinaNet-Focal-Loss\" class=\"headerlink\" title=\"RetinaNet(Focal Loss)\"></a>RetinaNet(Focal Loss)</h1><h2 id=\"Loss\"><a href=\"#Loss\" class=\"headerlink\" title=\"Loss\"></a>Loss</h2><p>one-stage  two-stage one-stage  location  fg-bg  Focal Loss loss  focus on hard examples</p>\n<blockquote>\n<p> OHEM  one-stage </p>\n</blockquote>\n<h3 id=\"Balanced-Cross-Entropy\"><a href=\"#Balanced-Cross-Entropy\" class=\"headerlink\" title=\"Balanced Cross Entropy\"></a>Balanced Cross Entropy</h3><script type=\"math/tex; mode=display\">CE(p,y)=\\begin{cases} - \\alpha \\log p & y=1 \\\\ -(1-\\alpha) \\log(1-p) & y=0\\end{cases}</script><p> $\\alpha \\in [0, 1]$ Nfg  $N_1$bg  $N_0$$N=N_1+N_0$<br>$\\alpha=\\frac {N_0} N$</p>\n<h3 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h3><script type=\"math/tex; mode=display\">FL(p,y)=\\begin{cases} - 1-p)^{\\gamma} \\log p & y=1 \\\\ -p^{\\gamma} \\log(1-p) & y=0\\end{cases}</script><p> $\\gamma&gt;0$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">p_t=\\begin{cases} p & y=1 \\\\ 1-p & y=0\\end{cases}</script><script type=\"math/tex; mode=display\">\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0\\end{cases}</script><p> $\\alpha$ balanced CE </p>\n<script type=\"math/tex; mode=display\">CE(p_t)=-\\alpha_t \\log(p_t)</script><p>Base Focal Loss </p>\n<script type=\"math/tex; mode=display\">FL(p_t)=-(1-p_t)^{\\gamma} \\log (p_t)</script><p>$\\alpha$ balanced Focal Loss </p>\n<script type=\"math/tex; mode=display\">FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log (p_t)</script><h2 id=\"RetinaNet\"><a href=\"#RetinaNet\" class=\"headerlink\" title=\"RetinaNet\"></a>RetinaNet</h2><p> Focal Loss  RetinaNetFocal Loss  Classification Subnet </p>\n<p><strong>backbone:</strong> FPN on ResNet $P_3 \\sim P_7$ level  feature $P_3 \\sim P_5$  ResNet  $C_3 \\sim C_5$  $3 \\times 3$-s2  conv ReLU  $P_6$ ReLU + $3 \\times 3$-s2 conv  $P_7$$P_l$ feature  stride  $2^l$ feature  C=256 channelsfeature  anchor  base size  $2^{l+2}$ position  9  anchorsaspect ratio  anchor  K 4 </p>\n<p>$IOU \\ge 0.5$   anchor$IOU &lt; 0.4$  anchor$0.4 \\le IOU &lt; 0.5$  anchor  anchor   gt box  offset box regression targetclassification target  one-hot vector anchor  entry  1  entry  0</p>\n<p>backbone  subnetworks box  level  feature </p>\n<p><strong>Classification Subnet:</strong>  FCN  pyramid level  pyramid feature  4  <code>3x3</code> conv conv  C=256  filters conv  ReLU <code>3x3</code>  conv <code>KA</code>  filters K A  anchor  RPN  deep </p>\n<p><strong>Box Regression Subnet:</strong>  Classification Subnet  conv  filters  <code>4A</code></p>\n<p> subnet  FPN  RetinaNet</p>\n<p> heuristic samplingRPN hard example mining(OHEM, SSD)  mini-batch 256 anchors Focal Loss image  anchor  ~100k anchor   anchor  focal loss  anchor  Focal Loss  anchor </p>\n<h1 id=\"STDN\"><a href=\"#STDN\" class=\"headerlink\" title=\"STDN\"></a>STDN</h1><p>Scale-Transferrable Detection Network scale </p>\n<p> Faster RCNN  scale  feature receptive field  scale  aspect ratio  SSD  depth  layer  feature anchor  scale  feature  scale  scale  low feature  low feature  FPN top-down  feature  feature FPN  feature pyramids FPN FPN  Faster RCNN  baseline  FPN  two-stage </p>\n<p>STDN  DenseNet  baseline DenseNet  feature concatenation  feature  DenseNet  DenseBlock  Layer  Scale-Transfer ModuleSTM multi scale featuresSTM </p>\n<ol>\n<li> DenseNet-169  baseline (growth rate=32)</li>\n<li> stem block  3  <code>3x3</code>  conv  <code>2x2</code>  mean-pooling <code>3x3</code> conv  stride=2 DenseNet  <code>7x7-s2</code>  <code>3x3-s2</code>  conv</li>\n<li> input size  <code>300x300</code>DenseNet   feature size  <code>9x9</code></li>\n<li><p> stem &gt; DB1 &gt; T1 &gt; DB2 &gt; T2 &gt; DB3 &gt; T3 &gt; DB4 =&gt; STM DB  DenseBlockT  Transition LayerT3  <code>640x9x9</code>STM  6  scale  features<br> | output size | layer |<br> |  |  |<br> |800x1x1 | 9x9 mean-pool, stride 9 (Input DB4_concat5)|<br> |960x3x3 | 3x3 mean-pool, stride 3 (Input DB4_concat10)|<br> |1120x5x5| 2x2 mean-pool, stride 2 (Input DB4_concat15)|<br> |1280x9x9| Identity layer (Input DB4_concat20) |<br> |360x18x18| 2x scale-transfer layer (Input DB4_concat25)|<br> |104x36x36| 4x scale-transfer layer (Input DB4_concat32)|</p>\n<p>  DenseBlock  $l$  layer  output channen  $k_0+l*32$ layer  <code>9x9</code>  scale  feature size  <code>800x1x1</code> layer  DB4  5  layer  output channel  $640+5\\times 32=800$ layer  DB4  layer </p>\n<ul>\n<li>Identity layer </li>\n<li>scale-transfer layer  channel  $r^2$ $r \\times$ scale-transfer layer $W, H$  $r$ rearrange <script type=\"math/tex; mode=display\">I_{x,y,c}^{SR}=I_{\\lfloor x/r \\rfloor,\\lfloor y/r \\rfloor, r\\cdot mod(y,r)+mod(x,r)+c\\cdot r^2}^{LR}</script></li>\n</ul>\n</li>\n<li><p> scale  feature  dense anchor anchor  gt box  IOU  IOU &gt; 0.5 anchor  hard negative mining  <code>1:3</code></p>\n</li>\n<li><p> feature  box  <code>1x1</code> conv  <code>3x3</code> conv  conv  BN+ReLU conv  channel  <code>KA</code> K fg  +  bgA  position  anchor  conv  channel  <code>4A</code></p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"YOLOv1\"><a href=\"#YOLOv1\" class=\"headerlink\" title=\"YOLOv1\"></a>YOLOv1</h1><ol>\n<li><p>one-stage detector</p>\n</li>\n<li><p>unified detectionimage  <code>SxS</code>  feature map image  <code>SxS</code>  grid grid cell grid cell  <code>S*S*(C+B*5)</code> C  B  grid cell box  4  1  conf conf  box  box  gt box  IOUC <code>Pr(Classi|Object)</code> box  <code>B</code>  conf </p>\n<script type=\"math/tex; mode=display\">Pr(Class_i|Object) * P(conf)</script></li>\n<li><p> SSD  default box Faster R-CNN  anchor/proposalYOLO  feature map  box  conf box </p>\n</li>\n<li><p>input image size  <code>448x448</code>6<code>7x7</code>feature fully connectionunit <code>1470=7*7*30</code>feature  box conf </p>\n</li>\n<li><p> feature map  fully connection grid cell  (x,y) <b> cell </b></p>\n</li>\n</ol>\n<h1 id=\"YOLOv2\"><a href=\"#YOLOv2\" class=\"headerlink\" title=\"YOLOv2\"></a>YOLOv2</h1><p>YOLOv1  fast  SOTA  region proposal-based YOLOv1  recall YOLOv2 </p>\n<ol>\n<li><p>Batch Normalization</p>\n</li>\n<li><p>High Resolution<br> \\<br> YOLOv1 baseline  image size  <code>224x224</code>image size  <code>448x448</code> 10  batch</p>\n <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int dim = (rand() % 10 + 10) * 32</span><br></pre></td></tr></table></figure>\n<p>  32 YOLOv2  5 YOLOv1  6 feature  higher resolution anchor boxfeature  position  anchor box </p>\n</li>\n<li><p>Convolution with Anchor Boxes<br> \\<br>  Faster R-CNN  RPN anchor boxfeature  position  k  anchor k  anchor gt box k-means IOU</p>\n <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d(anchor, cluster-center)=1-IOU(anchor, cluster-center)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Direct location prediction<br> \\<br>  region proposal  $(t_x, t_y)$ offsetanchor boxbox </p>\n<script type=\"math/tex; mode=display\">x=t_x \\cdot w_a+x_a, \\quad y=t_y \\cdot h_a + y_a</script><p>  box  anchor  box <b></b>YOLOv2  YOLOv1  cell cell <code>(i,j)</code>  anchor  $t_x, t_y, t_w, t_h$feature  $(w_f, h_f)$anchor  feature  $(w_a,h_a)$ box </p>\n<script type=\"math/tex; mode=display\">x=(i+t_x)/w_f</script><script type=\"math/tex; mode=display\">y=(j+t_y)/h_f</script><script type=\"math/tex; mode=display\">w=\\exp(t_w) \\cdot w_a/w_f</script><script type=\"math/tex; mode=display\">h=\\exp(t_h) \\cdot h_a/h_f</script></li>\n</ol>\n<p> box  5  4  1  conf C  $k \\cdot s \\cdot s \\cdot (5+C)$ k  anchor </p>\n<h1 id=\"YOLOv3\"><a href=\"#YOLOv3\" class=\"headerlink\" title=\"YOLOv3\"></a>YOLOv3</h1><p> idea  YOLO </p>\n<ol>\n<li><p> YOLOv2  anchor box k  anchor anchor  4  offset1  objectness conf C  offset  YOLOv2 </p>\n</li>\n<li><p> gt box  IOU  anchor  conf target  1 IOU  IOU 0.5 anchor IOU  0.5  anchor anchor  conf  offset </p>\n</li>\n<li><p>YOLOv3  scale  feature YOLOv1  YOLOv2  scale  feature FPN  multi-scale  features feature  position  3  anchor boxes feature size  <code>NxN</code> tensor  <code>NxNx[3*(4+1+C)]</code> C  foreground </p>\n</li>\n<li><p>Baseline  darknet-53  feature ImageNet  yolov3.cfg  ResNet  shortcut  deep  9  anchor size 3  scale feature  anchor</p>\n</li>\n</ol>\n<h1 id=\"SSD\"><a href=\"#SSD\" class=\"headerlink\" title=\"SSD\"></a>SSD</h1><ol>\n<li>baseline: VGG </li>\n<li>one-stage detector Faster R-CNN  proposals  feature map  position  prior boxk  feature maps  <code>(c+4)k</code> filters  conv fully connectionposition  <code>(c+4)k</code>  c  box  offsets multi scale  feature maps</li>\n<li> 300x300  6  scale  feature feature  prior box  <code>4,6,6,6,4,4</code> scale  feature  <code>38, 19, 10, 5, 3, 1</code> image  prior box  <code>(38*38+3*3+1*1)*4+(19*19+10*10+5*5)+6=8732</code></li>\n<li> multi scale feature maps level  feature  m  scale  feature m=6 level  feature  default box <script type=\"math/tex; mode=display\">s_k=s_{min}+\\frac {s_{max}-s_{min}}{m-1}(k-1), \\ k \\in [1,m]</script>  <code>[min, max]=[0.2, 0.9]</code> scale  s </li>\n<li>image default box 3 8732 default box gt  IOU  IOU &gt; 0.5  unbalanced conf  top N  N  3  level  feature  hard negative mining</li>\n</ol>\n<h1 id=\"DSSD\"><a href=\"#DSSD\" class=\"headerlink\" title=\"DSSD\"></a>DSSD</h1><p> SSD  deconvolution layer SSD  level  feautre level  feature  prediction module  feature  deconvolution SSD  resolution  feature  prediction module  feature  deconvolution SSD  resolution  feature  SSD  level  feature  hour-glass  encoder-decoder FPN  top-down  upsample  deconvolution</p>\n<h1 id=\"RetinaNet-Focal-Loss\"><a href=\"#RetinaNet-Focal-Loss\" class=\"headerlink\" title=\"RetinaNet(Focal Loss)\"></a>RetinaNet(Focal Loss)</h1><h2 id=\"Loss\"><a href=\"#Loss\" class=\"headerlink\" title=\"Loss\"></a>Loss</h2><p>one-stage  two-stage one-stage  location  fg-bg  Focal Loss loss  focus on hard examples</p>\n<blockquote>\n<p> OHEM  one-stage </p>\n</blockquote>\n<h3 id=\"Balanced-Cross-Entropy\"><a href=\"#Balanced-Cross-Entropy\" class=\"headerlink\" title=\"Balanced Cross Entropy\"></a>Balanced Cross Entropy</h3><script type=\"math/tex; mode=display\">CE(p,y)=\\begin{cases} - \\alpha \\log p & y=1 \\\\ -(1-\\alpha) \\log(1-p) & y=0\\end{cases}</script><p> $\\alpha \\in [0, 1]$ Nfg  $N_1$bg  $N_0$$N=N_1+N_0$<br>$\\alpha=\\frac {N_0} N$</p>\n<h3 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h3><script type=\"math/tex; mode=display\">FL(p,y)=\\begin{cases} - 1-p)^{\\gamma} \\log p & y=1 \\\\ -p^{\\gamma} \\log(1-p) & y=0\\end{cases}</script><p> $\\gamma&gt;0$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">p_t=\\begin{cases} p & y=1 \\\\ 1-p & y=0\\end{cases}</script><script type=\"math/tex; mode=display\">\\alpha_t=\\begin{cases} \\alpha & y=1 \\\\ 1-\\alpha & y=0\\end{cases}</script><p> $\\alpha$ balanced CE </p>\n<script type=\"math/tex; mode=display\">CE(p_t)=-\\alpha_t \\log(p_t)</script><p>Base Focal Loss </p>\n<script type=\"math/tex; mode=display\">FL(p_t)=-(1-p_t)^{\\gamma} \\log (p_t)</script><p>$\\alpha$ balanced Focal Loss </p>\n<script type=\"math/tex; mode=display\">FL(p_t)=-\\alpha_t (1-p_t)^{\\gamma} \\log (p_t)</script><h2 id=\"RetinaNet\"><a href=\"#RetinaNet\" class=\"headerlink\" title=\"RetinaNet\"></a>RetinaNet</h2><p> Focal Loss  RetinaNetFocal Loss  Classification Subnet </p>\n<p><strong>backbone:</strong> FPN on ResNet $P_3 \\sim P_7$ level  feature $P_3 \\sim P_5$  ResNet  $C_3 \\sim C_5$  $3 \\times 3$-s2  conv ReLU  $P_6$ ReLU + $3 \\times 3$-s2 conv  $P_7$$P_l$ feature  stride  $2^l$ feature  C=256 channelsfeature  anchor  base size  $2^{l+2}$ position  9  anchorsaspect ratio  anchor  K 4 </p>\n<p>$IOU \\ge 0.5$   anchor$IOU &lt; 0.4$  anchor$0.4 \\le IOU &lt; 0.5$  anchor  anchor   gt box  offset box regression targetclassification target  one-hot vector anchor  entry  1  entry  0</p>\n<p>backbone  subnetworks box  level  feature </p>\n<p><strong>Classification Subnet:</strong>  FCN  pyramid level  pyramid feature  4  <code>3x3</code> conv conv  C=256  filters conv  ReLU <code>3x3</code>  conv <code>KA</code>  filters K A  anchor  RPN  deep </p>\n<p><strong>Box Regression Subnet:</strong>  Classification Subnet  conv  filters  <code>4A</code></p>\n<p> subnet  FPN  RetinaNet</p>\n<p> heuristic samplingRPN hard example mining(OHEM, SSD)  mini-batch 256 anchors Focal Loss image  anchor  ~100k anchor   anchor  focal loss  anchor  Focal Loss  anchor </p>\n<h1 id=\"STDN\"><a href=\"#STDN\" class=\"headerlink\" title=\"STDN\"></a>STDN</h1><p>Scale-Transferrable Detection Network scale </p>\n<p> Faster RCNN  scale  feature receptive field  scale  aspect ratio  SSD  depth  layer  feature anchor  scale  feature  scale  scale  low feature  low feature  FPN top-down  feature  feature FPN  feature pyramids FPN FPN  Faster RCNN  baseline  FPN  two-stage </p>\n<p>STDN  DenseNet  baseline DenseNet  feature concatenation  feature  DenseNet  DenseBlock  Layer  Scale-Transfer ModuleSTM multi scale featuresSTM </p>\n<ol>\n<li> DenseNet-169  baseline (growth rate=32)</li>\n<li> stem block  3  <code>3x3</code>  conv  <code>2x2</code>  mean-pooling <code>3x3</code> conv  stride=2 DenseNet  <code>7x7-s2</code>  <code>3x3-s2</code>  conv</li>\n<li> input size  <code>300x300</code>DenseNet   feature size  <code>9x9</code></li>\n<li><p> stem &gt; DB1 &gt; T1 &gt; DB2 &gt; T2 &gt; DB3 &gt; T3 &gt; DB4 =&gt; STM DB  DenseBlockT  Transition LayerT3  <code>640x9x9</code>STM  6  scale  features<br> | output size | layer |<br> |  |  |<br> |800x1x1 | 9x9 mean-pool, stride 9 (Input DB4_concat5)|<br> |960x3x3 | 3x3 mean-pool, stride 3 (Input DB4_concat10)|<br> |1120x5x5| 2x2 mean-pool, stride 2 (Input DB4_concat15)|<br> |1280x9x9| Identity layer (Input DB4_concat20) |<br> |360x18x18| 2x scale-transfer layer (Input DB4_concat25)|<br> |104x36x36| 4x scale-transfer layer (Input DB4_concat32)|</p>\n<p>  DenseBlock  $l$  layer  output channen  $k_0+l*32$ layer  <code>9x9</code>  scale  feature size  <code>800x1x1</code> layer  DB4  5  layer  output channel  $640+5\\times 32=800$ layer  DB4  layer </p>\n<ul>\n<li>Identity layer </li>\n<li>scale-transfer layer  channel  $r^2$ $r \\times$ scale-transfer layer $W, H$  $r$ rearrange <script type=\"math/tex; mode=display\">I_{x,y,c}^{SR}=I_{\\lfloor x/r \\rfloor,\\lfloor y/r \\rfloor, r\\cdot mod(y,r)+mod(x,r)+c\\cdot r^2}^{LR}</script></li>\n</ul>\n</li>\n<li><p> scale  feature  dense anchor anchor  gt box  IOU  IOU &gt; 0.5 anchor  hard negative mining  <code>1:3</code></p>\n</li>\n<li><p> feature  box  <code>1x1</code> conv  <code>3x3</code> conv  conv  BN+ReLU conv  channel  <code>KA</code> K fg  +  bgA  position  anchor  conv  channel  <code>4A</code></p>\n</li>\n</ol>\n"},{"title":"Two-stage Object Detection","date":"2021-02-20T06:50:40.000Z","p":"obj_det/two_stage","mathjax":true,"_content":"\n# Faster R-CNN\n1. baseline: VGG, resnet\n2. RPN:  proposals\n3. ROIPooling: RPN  proposals  conv5_3  feature region  Pooling  `7x7`  FC layer\n4. detection head:  Fast R-CNN \n5.  top 256  proposals  mini-batch detection subnetwork\n6.  scale  aspect ratio \n\n\n\n# FPN\n0.  Faster R-CNN  baseline  ResNet/VGG  FPNmulti-scale + top-down feature fused)\n1. in-network feature pyramids level  feature \n2. low-level feature  low-level feature  top-down   high-level feature scale \n3. backbone  resnet FPN  feature pyramids faster rcnn  single feature level  feature  RPN  rcnn head  level feature resnet  conv2conv3conv4conv5 conv5  1x1 conv subsampling 5  level\n4. feature level  P2P3P4P5P6 level  anchor  scale `8`stride  48163264 anchor  input image  size  3264128256512 level  base anchor anchor  aspect ratio  `[0.5, 1, 2]`\n5. RPN  proposals level  `Pk` \n    $$k=\\lfloor 4 + \\log_2(\\sqrt {wh} / 224) \\rfloor$$\n\n\n# Deformable ConvNet\n\n## Deformable Conv\n feature grid  position  2-d offset feature map  $p_0$ feature  grid sampling \n$$\\mathcal R=\\{(-1,-1),(-1,0),...,(0,1),(1,1)\\}$$\n\n$$y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n)$$\n\n feature grid  $p_n$  $\\Delta p_n$\n$$y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n+\\Delta p_n)$$\n\n feature  conv resolution  channal  2N  offset offset \n\n $p=p_0+p_n+\\Delta p_n$ $p$ \n$$x(p)=\\sum_{q} G(q,p) \\cdot x(p)$$\n $q$  feature $G(q,p)$ \n$$G(q,p)=g(q_x, p_x) \\cdot g(q_y, p_y)$$\n$$g(a,b)=\\max(0, 1-|a-b|)$$\n p  4 p q  1$\\Delta p_n$  1\n\n offset  input feature  output feature map\n\n## Deformable ROI Pooling\nRegion proposal-based  ROI Pooling   feature 7x7 ROI Pooling  ROI Pooling  `wxh`  `kxk`  `p_0` output feature map  `(i,j)` \n$$y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p)/n_{ij}$$\n $n_{ij}=|bin(i,j)|$$bin(i,j)$  `(i,j)`  bin  bin \n$$\\lfloor i \\cdot w /k \\rfloor \\le p_x < \\lceil (i+1) \\cdot w / k \\rceil$$\n$$\\lfloor j \\cdot h /k \\rfloor \\le p_y < \\lceil (j+1) \\cdot h / k \\rceil$$\n\n bin  bin  2-d offset $bin(i,j)$  2-d offset  $\\Delta p_{ij}$ ROI Pooling \n$$y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p+\\Delta p_{ij}) / n_{ij}$$\n\n bin ?\n\n input feature  ROI Pooling  feature fc offset $\\Delta \\hat p_{ij}$ element-wise  ROI  w  h bin  offset\n$$\\Delta p_{ij}=\\gamma \\cdot \\Delta \\hat p_{ij} \\ \\circ \\ (w,h)$$\n $\\gamma$  offset  $\\gamma=0.1$\n\n<b>offset  offset  ROI size </b>\n\n### Position-Sentive(PS) ROI Pooling\n Position-Sentive  bin  `(i,j)`  subnet  box  subnet \n\n1. input feature  conv  channel  $k^2(C+1)$ k  C  fg  bin  feature feature bin  feature input feature\n2. box input feature  conv  channel  $2k^2(C+1)$  feature offsetelement-wise  ROI  w  h offset \n\n# Deformable ConvNet v2\n v1  v2DCNv2 conv layer  offset offset feature \n\n\n1. \n2. \n3. \n\n## \nBaseline Faster R-CNN + ResNet + aligned RoIPooling\n\n ____\nRPN  stage4 conv5  conv RoIPooling  RoIPoolingconv5  stride=16 32 feature map  resolution conv5_1  stride  1 \n\nconv5  Fast R-CNN head RoIPooling  fc\n\n## \n conv3conv4  conv5  3x3 conv DCNv1  conv5  3x3 conv \n\n__ conv:__\n\n offset feature  location  feature  0  location \n\nlocation $K$ $k$  location  offset  $w_k, \\ p_k$ `3x3`  $K=9$\n$$p_k \\in \\{(-1,-1), (-1,0),...,(1,1)\\}$$\n\n x  y  p  $x(p), \\ y(p)$\n$$y(p)=\\sum_{k=1}^K w_k \\cdot x(p+p_k+\\Delta p_k)\\cdot \\Delta m_k$$\n $\\Delta p_k$  offset$\\Delta p_k$ $\\Delta m_k \\in [0,1]$ $x(p+p_k+\\Delta p_k)$ \n\n$\\Delta p_k, \\ \\Delta m_k$  feature map  conv layer  `3K` channel  2K  $\\Delta p_k$ K channel  sigmoid $\\Delta m_k$\n\n__RoIPooling:__\n\nRoIPooling  RoI  __K__  bins `7x7` bin  `2x2` bin  RoIPooling  offset  $\\Delta p_k$  $\\Delta m_k$ `k`  bin bin \n$$y(k)=\\sum_{j=1}^n x(p_{kj}+\\Delta p_k) \\cdot \\Delta m_k / n$$\n $n$  bin $p_{kj}$  `k`  bin  `j`  DCNv1  bin  offset $x(p_{kj}+\\Delta p_K)$ \n\n____\n\nRoIPooling  feature maps  RoI feature patch 2x fcdimension  1024 3K channel  fc 2K  offset RoI  offset $\\{\\Delta p_k\\}_{k=1}^K$ K  sigmoid layer  $\\{\\Delta m_k\\}_{k=1}^K$\n\n## R-CNN \n ConvNet  ConvNet node  error-bounded saliency region  RoI  RoI  Image R-CNN  RoI  crop  image  ConvNet  Faster R-CNN Faster R-CNN  R-CNN ConvNet  bin   0 context Faster R-CNN  RoIPooling\n\n feature  R-CNN  cropped image  Faster R-CNN  RoI  RoI \n\n![](/images/obj_det/two_stage_fig2.png)\n<center>2.  Faster R-CNN  R-CNN </center>\n\n RoI `b` feature `b`  image  crop  resize  `224x224`  `14x14`  feature RoIPooling  `7x7` `7x7`  2x fc  RCNN  1024-D  $f_{RCNN}(b)$ `C+1`-way  softmax  `C+1`-D  fc  softmaxFaster R-CNN  1024-D Fast R-CNN head  $f_{FRCNN}(b)$ feature \n$$L_{mimic}=\\sum_{b \\in \\Omega}[1-\\cos (f_{RCNN}(b), f_{FRCNN}(b))]$$\n$\\Omega$  RoI $\\cos(\\cdot, \\cdot)$ \n\n\n# Mask R-CNN\n Faster R-CNN  mask  instance segmentation\n\nmask  ROI  binary maskMask R-CNN  classification  segmentation  K+1 dimension  mask\n\n____\n$$L=L_{cls}+L_{box}+L_{mask}$$\n Faster R-CNN mask  $Km^2$ K  foreground  `mxm`  resolution pixel  sigmoid $L_{mask}$  binary cross-entropy $L_{mask}$  resolution  position  `k`  $L_{mask}$  $m^2$  binary cross-entropy loss \n\n ROI  mask  `mxm`  maskmask  FCN layer  fcFCN \n\n## RoIAlign\nFaster R-CNN  RoIPool  RoI feature conv4  RoI  feature map `7x7` conv4  feature  RoI conv4  feature  stride=16 RoI  conv4  feature  $[x/16]$ $[\\cdot]$ RoI feature  `7x7`  RoI feature  `7x7` bins input image  RoI feature  pixel  mask \n\n $x/16$  $[x /16]$  conv4 feature  RoI  1\n![](/images/obj_det/two_stage_fig1.png)<center>fig1. RoIAlign </center>\n\n1  `2x2` bins `7x7` bins  bin   feature patch  bin  feature patch pooling\n\n bin 4  max  average  pooling 1\n\n## \n__backbone:__\n\nbackbone 1. `ResNet-50-C4` `C4`  ResNet stage 4  feature2. `ResNet-FPN`ResNet  ResNeXt\n\n__detection head:__\n\n C4  RoI  feature  RoIAlign  `7x7x1024`  `res5`ResNet  stage 5 9  layer feature  tensor  box  mask\n\n## \nresize image 800 mini-batch  2  images image  N  RoIs `1:3`\n\n\n# R-FCN\nregion-based fully convolutional networks\n\n backbone  translation invariance  translation variance  proposal box  gt box  IOU\n\nR-FCN  FCN  translation variance position-sensitive score maps score map encode \n![](/images/obj_det/two_stage_fig3.png)\n\nRPN  proposal boxRoIRoI  `kxk` grid cell  score map C+1  channel channel  RoIPooling  cell  score maps\n\nBackbone  ResNet-101 conv  2048-d dimension `1x1` 1024-d  conv $k^2(C+1)$-d  conv  positive-sensitive score maps\n\n## position-sensitive roi pooling\n positive-sensitive score maps  RPN  RoI `kxk` bin bin  score map pooling RoI size  `wxh` bin  size  $\\frac w k \\times \\frac h k$ `(i,j)`  bin RoI pooling  `(i,j)`  score map  average pooling `kxkx(C+1)`  __vote__ averaging `C+1`  vector RoI  softmax \n\n","source":"_posts/obj_det/two_stage.md","raw":"---\ntitle: Two-stage Object Detection\ndate: 2021-02-20 14:50:40\ntags:\np: obj_det/two_stage\nmathjax: true\n---\n\n# Faster R-CNN\n1. baseline: VGG, resnet\n2. RPN:  proposals\n3. ROIPooling: RPN  proposals  conv5_3  feature region  Pooling  `7x7`  FC layer\n4. detection head:  Fast R-CNN \n5.  top 256  proposals  mini-batch detection subnetwork\n6.  scale  aspect ratio \n\n\n\n# FPN\n0.  Faster R-CNN  baseline  ResNet/VGG  FPNmulti-scale + top-down feature fused)\n1. in-network feature pyramids level  feature \n2. low-level feature  low-level feature  top-down   high-level feature scale \n3. backbone  resnet FPN  feature pyramids faster rcnn  single feature level  feature  RPN  rcnn head  level feature resnet  conv2conv3conv4conv5 conv5  1x1 conv subsampling 5  level\n4. feature level  P2P3P4P5P6 level  anchor  scale `8`stride  48163264 anchor  input image  size  3264128256512 level  base anchor anchor  aspect ratio  `[0.5, 1, 2]`\n5. RPN  proposals level  `Pk` \n    $$k=\\lfloor 4 + \\log_2(\\sqrt {wh} / 224) \\rfloor$$\n\n\n# Deformable ConvNet\n\n## Deformable Conv\n feature grid  position  2-d offset feature map  $p_0$ feature  grid sampling \n$$\\mathcal R=\\{(-1,-1),(-1,0),...,(0,1),(1,1)\\}$$\n\n$$y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n)$$\n\n feature grid  $p_n$  $\\Delta p_n$\n$$y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n+\\Delta p_n)$$\n\n feature  conv resolution  channal  2N  offset offset \n\n $p=p_0+p_n+\\Delta p_n$ $p$ \n$$x(p)=\\sum_{q} G(q,p) \\cdot x(p)$$\n $q$  feature $G(q,p)$ \n$$G(q,p)=g(q_x, p_x) \\cdot g(q_y, p_y)$$\n$$g(a,b)=\\max(0, 1-|a-b|)$$\n p  4 p q  1$\\Delta p_n$  1\n\n offset  input feature  output feature map\n\n## Deformable ROI Pooling\nRegion proposal-based  ROI Pooling   feature 7x7 ROI Pooling  ROI Pooling  `wxh`  `kxk`  `p_0` output feature map  `(i,j)` \n$$y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p)/n_{ij}$$\n $n_{ij}=|bin(i,j)|$$bin(i,j)$  `(i,j)`  bin  bin \n$$\\lfloor i \\cdot w /k \\rfloor \\le p_x < \\lceil (i+1) \\cdot w / k \\rceil$$\n$$\\lfloor j \\cdot h /k \\rfloor \\le p_y < \\lceil (j+1) \\cdot h / k \\rceil$$\n\n bin  bin  2-d offset $bin(i,j)$  2-d offset  $\\Delta p_{ij}$ ROI Pooling \n$$y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p+\\Delta p_{ij}) / n_{ij}$$\n\n bin ?\n\n input feature  ROI Pooling  feature fc offset $\\Delta \\hat p_{ij}$ element-wise  ROI  w  h bin  offset\n$$\\Delta p_{ij}=\\gamma \\cdot \\Delta \\hat p_{ij} \\ \\circ \\ (w,h)$$\n $\\gamma$  offset  $\\gamma=0.1$\n\n<b>offset  offset  ROI size </b>\n\n### Position-Sentive(PS) ROI Pooling\n Position-Sentive  bin  `(i,j)`  subnet  box  subnet \n\n1. input feature  conv  channel  $k^2(C+1)$ k  C  fg  bin  feature feature bin  feature input feature\n2. box input feature  conv  channel  $2k^2(C+1)$  feature offsetelement-wise  ROI  w  h offset \n\n# Deformable ConvNet v2\n v1  v2DCNv2 conv layer  offset offset feature \n\n\n1. \n2. \n3. \n\n## \nBaseline Faster R-CNN + ResNet + aligned RoIPooling\n\n ____\nRPN  stage4 conv5  conv RoIPooling  RoIPoolingconv5  stride=16 32 feature map  resolution conv5_1  stride  1 \n\nconv5  Fast R-CNN head RoIPooling  fc\n\n## \n conv3conv4  conv5  3x3 conv DCNv1  conv5  3x3 conv \n\n__ conv:__\n\n offset feature  location  feature  0  location \n\nlocation $K$ $k$  location  offset  $w_k, \\ p_k$ `3x3`  $K=9$\n$$p_k \\in \\{(-1,-1), (-1,0),...,(1,1)\\}$$\n\n x  y  p  $x(p), \\ y(p)$\n$$y(p)=\\sum_{k=1}^K w_k \\cdot x(p+p_k+\\Delta p_k)\\cdot \\Delta m_k$$\n $\\Delta p_k$  offset$\\Delta p_k$ $\\Delta m_k \\in [0,1]$ $x(p+p_k+\\Delta p_k)$ \n\n$\\Delta p_k, \\ \\Delta m_k$  feature map  conv layer  `3K` channel  2K  $\\Delta p_k$ K channel  sigmoid $\\Delta m_k$\n\n__RoIPooling:__\n\nRoIPooling  RoI  __K__  bins `7x7` bin  `2x2` bin  RoIPooling  offset  $\\Delta p_k$  $\\Delta m_k$ `k`  bin bin \n$$y(k)=\\sum_{j=1}^n x(p_{kj}+\\Delta p_k) \\cdot \\Delta m_k / n$$\n $n$  bin $p_{kj}$  `k`  bin  `j`  DCNv1  bin  offset $x(p_{kj}+\\Delta p_K)$ \n\n____\n\nRoIPooling  feature maps  RoI feature patch 2x fcdimension  1024 3K channel  fc 2K  offset RoI  offset $\\{\\Delta p_k\\}_{k=1}^K$ K  sigmoid layer  $\\{\\Delta m_k\\}_{k=1}^K$\n\n## R-CNN \n ConvNet  ConvNet node  error-bounded saliency region  RoI  RoI  Image R-CNN  RoI  crop  image  ConvNet  Faster R-CNN Faster R-CNN  R-CNN ConvNet  bin   0 context Faster R-CNN  RoIPooling\n\n feature  R-CNN  cropped image  Faster R-CNN  RoI  RoI \n\n![](/images/obj_det/two_stage_fig2.png)\n<center>2.  Faster R-CNN  R-CNN </center>\n\n RoI `b` feature `b`  image  crop  resize  `224x224`  `14x14`  feature RoIPooling  `7x7` `7x7`  2x fc  RCNN  1024-D  $f_{RCNN}(b)$ `C+1`-way  softmax  `C+1`-D  fc  softmaxFaster R-CNN  1024-D Fast R-CNN head  $f_{FRCNN}(b)$ feature \n$$L_{mimic}=\\sum_{b \\in \\Omega}[1-\\cos (f_{RCNN}(b), f_{FRCNN}(b))]$$\n$\\Omega$  RoI $\\cos(\\cdot, \\cdot)$ \n\n\n# Mask R-CNN\n Faster R-CNN  mask  instance segmentation\n\nmask  ROI  binary maskMask R-CNN  classification  segmentation  K+1 dimension  mask\n\n____\n$$L=L_{cls}+L_{box}+L_{mask}$$\n Faster R-CNN mask  $Km^2$ K  foreground  `mxm`  resolution pixel  sigmoid $L_{mask}$  binary cross-entropy $L_{mask}$  resolution  position  `k`  $L_{mask}$  $m^2$  binary cross-entropy loss \n\n ROI  mask  `mxm`  maskmask  FCN layer  fcFCN \n\n## RoIAlign\nFaster R-CNN  RoIPool  RoI feature conv4  RoI  feature map `7x7` conv4  feature  RoI conv4  feature  stride=16 RoI  conv4  feature  $[x/16]$ $[\\cdot]$ RoI feature  `7x7`  RoI feature  `7x7` bins input image  RoI feature  pixel  mask \n\n $x/16$  $[x /16]$  conv4 feature  RoI  1\n![](/images/obj_det/two_stage_fig1.png)<center>fig1. RoIAlign </center>\n\n1  `2x2` bins `7x7` bins  bin   feature patch  bin  feature patch pooling\n\n bin 4  max  average  pooling 1\n\n## \n__backbone:__\n\nbackbone 1. `ResNet-50-C4` `C4`  ResNet stage 4  feature2. `ResNet-FPN`ResNet  ResNeXt\n\n__detection head:__\n\n C4  RoI  feature  RoIAlign  `7x7x1024`  `res5`ResNet  stage 5 9  layer feature  tensor  box  mask\n\n## \nresize image 800 mini-batch  2  images image  N  RoIs `1:3`\n\n\n# R-FCN\nregion-based fully convolutional networks\n\n backbone  translation invariance  translation variance  proposal box  gt box  IOU\n\nR-FCN  FCN  translation variance position-sensitive score maps score map encode \n![](/images/obj_det/two_stage_fig3.png)\n\nRPN  proposal boxRoIRoI  `kxk` grid cell  score map C+1  channel channel  RoIPooling  cell  score maps\n\nBackbone  ResNet-101 conv  2048-d dimension `1x1` 1024-d  conv $k^2(C+1)$-d  conv  positive-sensitive score maps\n\n## position-sensitive roi pooling\n positive-sensitive score maps  RPN  RoI `kxk` bin bin  score map pooling RoI size  `wxh` bin  size  $\\frac w k \\times \\frac h k$ `(i,j)`  bin RoI pooling  `(i,j)`  score map  average pooling `kxkx(C+1)`  __vote__ averaging `C+1`  vector RoI  softmax \n\n","slug":"obj_det/two_stage","published":1,"updated":"2021-03-05T11:00:19.491Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91g0033p0dj3peg39jo","content":"<h1 id=\"Faster-R-CNN\"><a href=\"#Faster-R-CNN\" class=\"headerlink\" title=\"Faster R-CNN\"></a>Faster R-CNN</h1><ol>\n<li>baseline: VGG, resnet</li>\n<li>RPN:  proposals</li>\n<li>ROIPooling: RPN  proposals  conv5_3  feature region  Pooling  <code>7x7</code>  FC layer</li>\n<li>detection head:  Fast R-CNN </li>\n<li> top 256  proposals  mini-batch detection subnetwork</li>\n<li> scale  aspect ratio </li>\n</ol>\n<h1 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h1><ol>\n<li> Faster R-CNN  baseline  ResNet/VGG  FPNmulti-scale + top-down feature fused)</li>\n<li>in-network feature pyramids level  feature </li>\n<li>low-level feature  low-level feature  top-down   high-level feature scale </li>\n<li>backbone  resnet FPN  feature pyramids faster rcnn  single feature level  feature  RPN  rcnn head  level feature resnet  conv2conv3conv4conv5 conv5  1x1 conv subsampling 5  level</li>\n<li>feature level  P2P3P4P5P6 level  anchor  scale <code>8</code>stride  48163264 anchor  input image  size  3264128256512 level  base anchor anchor  aspect ratio  <code>[0.5, 1, 2]</code></li>\n<li>RPN  proposals level  <code>Pk</code> <script type=\"math/tex; mode=display\">k=\\lfloor 4 + \\log_2(\\sqrt {wh} / 224) \\rfloor</script></li>\n</ol>\n<h1 id=\"Deformable-ConvNet\"><a href=\"#Deformable-ConvNet\" class=\"headerlink\" title=\"Deformable ConvNet\"></a>Deformable ConvNet</h1><p></p>\n<h2 id=\"Deformable-Conv\"><a href=\"#Deformable-Conv\" class=\"headerlink\" title=\"Deformable Conv\"></a>Deformable Conv</h2><p> feature grid  position  2-d offset feature map  $p_0$ feature  grid sampling </p>\n<script type=\"math/tex; mode=display\">\\mathcal R=\\{(-1,-1),(-1,0),...,(0,1),(1,1)\\}</script><p></p>\n<script type=\"math/tex; mode=display\">y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n)</script><p> feature grid  $p_n$  $\\Delta p_n$</p>\n<script type=\"math/tex; mode=display\">y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n+\\Delta p_n)</script><p> feature  conv resolution  channal  2N  offset offset </p>\n<p> $p=p_0+p_n+\\Delta p_n$ $p$ </p>\n<script type=\"math/tex; mode=display\">x(p)=\\sum_{q} G(q,p) \\cdot x(p)</script><p> $q$  feature $G(q,p)$ </p>\n<script type=\"math/tex; mode=display\">G(q,p)=g(q_x, p_x) \\cdot g(q_y, p_y)</script><script type=\"math/tex; mode=display\">g(a,b)=\\max(0, 1-|a-b|)</script><p> p  4 p q  1$\\Delta p_n$  1</p>\n<p> offset  input feature  output feature map</p>\n<h2 id=\"Deformable-ROI-Pooling\"><a href=\"#Deformable-ROI-Pooling\" class=\"headerlink\" title=\"Deformable ROI Pooling\"></a>Deformable ROI Pooling</h2><p>Region proposal-based  ROI Pooling   feature 7x7 ROI Pooling  ROI Pooling  <code>wxh</code>  <code>kxk</code>  <code>p_0</code> output feature map  <code>(i,j)</code> </p>\n<script type=\"math/tex; mode=display\">y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p)/n_{ij}</script><p> $n_{ij}=|bin(i,j)|$$bin(i,j)$  <code>(i,j)</code>  bin  bin </p>\n<script type=\"math/tex; mode=display\">\\lfloor i \\cdot w /k \\rfloor \\le p_x < \\lceil (i+1) \\cdot w / k \\rceil</script><script type=\"math/tex; mode=display\">\\lfloor j \\cdot h /k \\rfloor \\le p_y < \\lceil (j+1) \\cdot h / k \\rceil</script><p> bin  bin  2-d offset $bin(i,j)$  2-d offset  $\\Delta p_{ij}$ ROI Pooling </p>\n<script type=\"math/tex; mode=display\">y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p+\\Delta p_{ij}) / n_{ij}</script><p> bin ?</p>\n<p> input feature  ROI Pooling  feature fc offset $\\Delta \\hat p_{ij}$ element-wise  ROI  w  h bin  offset</p>\n<script type=\"math/tex; mode=display\">\\Delta p_{ij}=\\gamma \\cdot \\Delta \\hat p_{ij} \\ \\circ \\ (w,h)</script><p> $\\gamma$  offset  $\\gamma=0.1$</p>\n<p><b>offset  offset  ROI size </b></p>\n<h3 id=\"Position-Sentive-PS-ROI-Pooling\"><a href=\"#Position-Sentive-PS-ROI-Pooling\" class=\"headerlink\" title=\"Position-Sentive(PS) ROI Pooling\"></a>Position-Sentive(PS) ROI Pooling</h3><p> Position-Sentive  bin  <code>(i,j)</code>  subnet  box  subnet </p>\n<ol>\n<li>input feature  conv  channel  $k^2(C+1)$ k  C  fg  bin  feature feature bin  feature input feature</li>\n<li>box input feature  conv  channel  $2k^2(C+1)$  feature offsetelement-wise  ROI  w  h offset </li>\n</ol>\n<h1 id=\"Deformable-ConvNet-v2\"><a href=\"#Deformable-ConvNet-v2\" class=\"headerlink\" title=\"Deformable ConvNet v2\"></a>Deformable ConvNet v2</h1><p> v1  v2DCNv2 conv layer  offset offset feature </p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Baseline Faster R-CNN + ResNet + aligned RoIPooling</p>\n<p> <strong></strong><br>RPN  stage4 conv5  conv RoIPooling  RoIPoolingconv5  stride=16 32 feature map  resolution conv5_1  stride  1 </p>\n<p>conv5  Fast R-CNN head RoIPooling  fc</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> conv3conv4  conv5  3x3 conv DCNv1  conv5  3x3 conv </p>\n<p><strong> conv:</strong></p>\n<p> offset feature  location  feature  0  location </p>\n<p>location $K$ $k$  location  offset  $w_k, \\ p_k$ <code>3x3</code>  $K=9$</p>\n<script type=\"math/tex; mode=display\">p_k \\in \\{(-1,-1), (-1,0),...,(1,1)\\}</script><p> x  y  p  $x(p), \\ y(p)$</p>\n<script type=\"math/tex; mode=display\">y(p)=\\sum_{k=1}^K w_k \\cdot x(p+p_k+\\Delta p_k)\\cdot \\Delta m_k</script><p> $\\Delta p_k$  offset$\\Delta p_k$ $\\Delta m_k \\in [0,1]$ $x(p+p_k+\\Delta p_k)$ </p>\n<p>$\\Delta p_k, \\ \\Delta m_k$  feature map  conv layer  <code>3K</code> channel  2K  $\\Delta p_k$ K channel  sigmoid $\\Delta m_k$</p>\n<p><strong>RoIPooling:</strong></p>\n<p>RoIPooling  RoI  <strong>K</strong>  bins <code>7x7</code> bin  <code>2x2</code> bin  RoIPooling  offset  $\\Delta p_k$  $\\Delta m_k$ <code>k</code>  bin bin </p>\n<script type=\"math/tex; mode=display\">y(k)=\\sum_{j=1}^n x(p_{kj}+\\Delta p_k) \\cdot \\Delta m_k / n</script><p> $n$  bin $p_{kj}$  <code>k</code>  bin  <code>j</code>  DCNv1  bin  offset $x(p_{kj}+\\Delta p_K)$ </p>\n<p><strong></strong></p>\n<p>RoIPooling  feature maps  RoI feature patch 2x fcdimension  1024 3K channel  fc 2K  offset RoI  offset $\\{\\Delta p_k\\}_{k=1}^K$ K  sigmoid layer  $\\{\\Delta m_k\\}_{k=1}^K$</p>\n<h2 id=\"R-CNN-\"><a href=\"#R-CNN-\" class=\"headerlink\" title=\"R-CNN \"></a>R-CNN </h2><p> ConvNet  ConvNet node  error-bounded saliency region  RoI  RoI  Image R-CNN  RoI  crop  image  ConvNet  Faster R-CNN Faster R-CNN  R-CNN ConvNet  bin   0 context Faster R-CNN  RoIPooling</p>\n<p> feature  R-CNN  cropped image  Faster R-CNN  RoI  RoI <br><br><img src=\"/images/obj_det/two_stage_fig2.png\" alt=\"\"></p>\n<center>2.  Faster R-CNN  R-CNN </center>\n\n<p> RoI <code>b</code> feature <code>b</code>  image  crop  resize  <code>224x224</code>  <code>14x14</code>  feature RoIPooling  <code>7x7</code> <code>7x7</code>  2x fc  RCNN  1024-D  $f_{RCNN}(b)$ <code>C+1</code>-way  softmax  <code>C+1</code>-D  fc  softmaxFaster R-CNN  1024-D Fast R-CNN head  $f_{FRCNN}(b)$ feature </p>\n<script type=\"math/tex; mode=display\">L_{mimic}=\\sum_{b \\in \\Omega}[1-\\cos (f_{RCNN}(b), f_{FRCNN}(b))]</script><p>$\\Omega$  RoI $\\cos(\\cdot, \\cdot)$ </p>\n<h1 id=\"Mask-R-CNN\"><a href=\"#Mask-R-CNN\" class=\"headerlink\" title=\"Mask R-CNN\"></a>Mask R-CNN</h1><p> Faster R-CNN  mask  instance segmentation</p>\n<p>mask  ROI  binary maskMask R-CNN  classification  segmentation  K+1 dimension  mask</p>\n<p><strong></strong></p>\n<script type=\"math/tex; mode=display\">L=L_{cls}+L_{box}+L_{mask}</script><p> Faster R-CNN mask  $Km^2$ K  foreground  <code>mxm</code>  resolution pixel  sigmoid $L_{mask}$  binary cross-entropy $L_{mask}$  resolution  position  <code>k</code>  $L_{mask}$  $m^2$  binary cross-entropy loss </p>\n<p> ROI  mask  <code>mxm</code>  maskmask  FCN layer  fcFCN </p>\n<h2 id=\"RoIAlign\"><a href=\"#RoIAlign\" class=\"headerlink\" title=\"RoIAlign\"></a>RoIAlign</h2><p>Faster R-CNN  RoIPool  RoI feature conv4  RoI  feature map <code>7x7</code> conv4  feature  RoI conv4  feature  stride=16 RoI  conv4  feature  $[x/16]$ $[\\cdot]$ RoI feature  <code>7x7</code>  RoI feature  <code>7x7</code> bins input image  RoI feature  pixel  mask </p>\n<p> $x/16$  $[x /16]$  conv4 feature  RoI  1<br><img src=\"/images/obj_det/two_stage_fig1.png\" alt=\"\"><center>fig1. RoIAlign </center></p>\n<p>1  <code>2x2</code> bins <code>7x7</code> bins  bin   feature patch  bin  feature patch pooling</p>\n<p> bin 4  max  average  pooling 1</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>backbone:</strong></p>\n<p>backbone 1. <code>ResNet-50-C4</code> <code>C4</code>  ResNet stage 4  feature2. <code>ResNet-FPN</code>ResNet  ResNeXt</p>\n<p><strong>detection head:</strong></p>\n<p> C4  RoI  feature  RoIAlign  <code>7x7x1024</code>  <code>res5</code>ResNet  stage 5 9  layer feature  tensor  box  mask</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>resize image 800 mini-batch  2  images image  N  RoIs <code>1:3</code></p>\n<h1 id=\"R-FCN\"><a href=\"#R-FCN\" class=\"headerlink\" title=\"R-FCN\"></a>R-FCN</h1><p>region-based fully convolutional networks</p>\n<p> backbone  translation invariance  translation variance  proposal box  gt box  IOU</p>\n<p>R-FCN  FCN  translation variance position-sensitive score maps score map encode <br><img src=\"/images/obj_det/two_stage_fig3.png\" alt=\"\"></p>\n<p>RPN  proposal boxRoIRoI  <code>kxk</code> grid cell  score map C+1  channel channel  RoIPooling  cell  score maps</p>\n<p>Backbone  ResNet-101 conv  2048-d dimension <code>1x1</code> 1024-d  conv $k^2(C+1)$-d  conv  positive-sensitive score maps</p>\n<h2 id=\"position-sensitive-roi-pooling\"><a href=\"#position-sensitive-roi-pooling\" class=\"headerlink\" title=\"position-sensitive roi pooling\"></a>position-sensitive roi pooling</h2><p> positive-sensitive score maps  RPN  RoI <code>kxk</code> bin bin  score map pooling RoI size  <code>wxh</code> bin  size  $\\frac w k \\times \\frac h k$ <code>(i,j)</code>  bin RoI pooling  <code>(i,j)</code>  score map  average pooling <code>kxkx(C+1)</code>  <strong>vote</strong> averaging <code>C+1</code>  vector RoI  softmax </p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Faster-R-CNN\"><a href=\"#Faster-R-CNN\" class=\"headerlink\" title=\"Faster R-CNN\"></a>Faster R-CNN</h1><ol>\n<li>baseline: VGG, resnet</li>\n<li>RPN:  proposals</li>\n<li>ROIPooling: RPN  proposals  conv5_3  feature region  Pooling  <code>7x7</code>  FC layer</li>\n<li>detection head:  Fast R-CNN </li>\n<li> top 256  proposals  mini-batch detection subnetwork</li>\n<li> scale  aspect ratio </li>\n</ol>\n<h1 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h1><ol>\n<li> Faster R-CNN  baseline  ResNet/VGG  FPNmulti-scale + top-down feature fused)</li>\n<li>in-network feature pyramids level  feature </li>\n<li>low-level feature  low-level feature  top-down   high-level feature scale </li>\n<li>backbone  resnet FPN  feature pyramids faster rcnn  single feature level  feature  RPN  rcnn head  level feature resnet  conv2conv3conv4conv5 conv5  1x1 conv subsampling 5  level</li>\n<li>feature level  P2P3P4P5P6 level  anchor  scale <code>8</code>stride  48163264 anchor  input image  size  3264128256512 level  base anchor anchor  aspect ratio  <code>[0.5, 1, 2]</code></li>\n<li>RPN  proposals level  <code>Pk</code> <script type=\"math/tex; mode=display\">k=\\lfloor 4 + \\log_2(\\sqrt {wh} / 224) \\rfloor</script></li>\n</ol>\n<h1 id=\"Deformable-ConvNet\"><a href=\"#Deformable-ConvNet\" class=\"headerlink\" title=\"Deformable ConvNet\"></a>Deformable ConvNet</h1><p></p>\n<h2 id=\"Deformable-Conv\"><a href=\"#Deformable-Conv\" class=\"headerlink\" title=\"Deformable Conv\"></a>Deformable Conv</h2><p> feature grid  position  2-d offset feature map  $p_0$ feature  grid sampling </p>\n<script type=\"math/tex; mode=display\">\\mathcal R=\\{(-1,-1),(-1,0),...,(0,1),(1,1)\\}</script><p></p>\n<script type=\"math/tex; mode=display\">y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n)</script><p> feature grid  $p_n$  $\\Delta p_n$</p>\n<script type=\"math/tex; mode=display\">y(p_0)=\\sum_{p_n \\in \\mathcal R} w(p_n) \\cdot x(p_0+p_n+\\Delta p_n)</script><p> feature  conv resolution  channal  2N  offset offset </p>\n<p> $p=p_0+p_n+\\Delta p_n$ $p$ </p>\n<script type=\"math/tex; mode=display\">x(p)=\\sum_{q} G(q,p) \\cdot x(p)</script><p> $q$  feature $G(q,p)$ </p>\n<script type=\"math/tex; mode=display\">G(q,p)=g(q_x, p_x) \\cdot g(q_y, p_y)</script><script type=\"math/tex; mode=display\">g(a,b)=\\max(0, 1-|a-b|)</script><p> p  4 p q  1$\\Delta p_n$  1</p>\n<p> offset  input feature  output feature map</p>\n<h2 id=\"Deformable-ROI-Pooling\"><a href=\"#Deformable-ROI-Pooling\" class=\"headerlink\" title=\"Deformable ROI Pooling\"></a>Deformable ROI Pooling</h2><p>Region proposal-based  ROI Pooling   feature 7x7 ROI Pooling  ROI Pooling  <code>wxh</code>  <code>kxk</code>  <code>p_0</code> output feature map  <code>(i,j)</code> </p>\n<script type=\"math/tex; mode=display\">y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p)/n_{ij}</script><p> $n_{ij}=|bin(i,j)|$$bin(i,j)$  <code>(i,j)</code>  bin  bin </p>\n<script type=\"math/tex; mode=display\">\\lfloor i \\cdot w /k \\rfloor \\le p_x < \\lceil (i+1) \\cdot w / k \\rceil</script><script type=\"math/tex; mode=display\">\\lfloor j \\cdot h /k \\rfloor \\le p_y < \\lceil (j+1) \\cdot h / k \\rceil</script><p> bin  bin  2-d offset $bin(i,j)$  2-d offset  $\\Delta p_{ij}$ ROI Pooling </p>\n<script type=\"math/tex; mode=display\">y(i,j)=\\sum_{p \\in bin(i,j)} x(p_0+p+\\Delta p_{ij}) / n_{ij}</script><p> bin ?</p>\n<p> input feature  ROI Pooling  feature fc offset $\\Delta \\hat p_{ij}$ element-wise  ROI  w  h bin  offset</p>\n<script type=\"math/tex; mode=display\">\\Delta p_{ij}=\\gamma \\cdot \\Delta \\hat p_{ij} \\ \\circ \\ (w,h)</script><p> $\\gamma$  offset  $\\gamma=0.1$</p>\n<p><b>offset  offset  ROI size </b></p>\n<h3 id=\"Position-Sentive-PS-ROI-Pooling\"><a href=\"#Position-Sentive-PS-ROI-Pooling\" class=\"headerlink\" title=\"Position-Sentive(PS) ROI Pooling\"></a>Position-Sentive(PS) ROI Pooling</h3><p> Position-Sentive  bin  <code>(i,j)</code>  subnet  box  subnet </p>\n<ol>\n<li>input feature  conv  channel  $k^2(C+1)$ k  C  fg  bin  feature feature bin  feature input feature</li>\n<li>box input feature  conv  channel  $2k^2(C+1)$  feature offsetelement-wise  ROI  w  h offset </li>\n</ol>\n<h1 id=\"Deformable-ConvNet-v2\"><a href=\"#Deformable-ConvNet-v2\" class=\"headerlink\" title=\"Deformable ConvNet v2\"></a>Deformable ConvNet v2</h1><p> v1  v2DCNv2 conv layer  offset offset feature </p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Baseline Faster R-CNN + ResNet + aligned RoIPooling</p>\n<p> <strong></strong><br>RPN  stage4 conv5  conv RoIPooling  RoIPoolingconv5  stride=16 32 feature map  resolution conv5_1  stride  1 </p>\n<p>conv5  Fast R-CNN head RoIPooling  fc</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> conv3conv4  conv5  3x3 conv DCNv1  conv5  3x3 conv </p>\n<p><strong> conv:</strong></p>\n<p> offset feature  location  feature  0  location </p>\n<p>location $K$ $k$  location  offset  $w_k, \\ p_k$ <code>3x3</code>  $K=9$</p>\n<script type=\"math/tex; mode=display\">p_k \\in \\{(-1,-1), (-1,0),...,(1,1)\\}</script><p> x  y  p  $x(p), \\ y(p)$</p>\n<script type=\"math/tex; mode=display\">y(p)=\\sum_{k=1}^K w_k \\cdot x(p+p_k+\\Delta p_k)\\cdot \\Delta m_k</script><p> $\\Delta p_k$  offset$\\Delta p_k$ $\\Delta m_k \\in [0,1]$ $x(p+p_k+\\Delta p_k)$ </p>\n<p>$\\Delta p_k, \\ \\Delta m_k$  feature map  conv layer  <code>3K</code> channel  2K  $\\Delta p_k$ K channel  sigmoid $\\Delta m_k$</p>\n<p><strong>RoIPooling:</strong></p>\n<p>RoIPooling  RoI  <strong>K</strong>  bins <code>7x7</code> bin  <code>2x2</code> bin  RoIPooling  offset  $\\Delta p_k$  $\\Delta m_k$ <code>k</code>  bin bin </p>\n<script type=\"math/tex; mode=display\">y(k)=\\sum_{j=1}^n x(p_{kj}+\\Delta p_k) \\cdot \\Delta m_k / n</script><p> $n$  bin $p_{kj}$  <code>k</code>  bin  <code>j</code>  DCNv1  bin  offset $x(p_{kj}+\\Delta p_K)$ </p>\n<p><strong></strong></p>\n<p>RoIPooling  feature maps  RoI feature patch 2x fcdimension  1024 3K channel  fc 2K  offset RoI  offset $\\{\\Delta p_k\\}_{k=1}^K$ K  sigmoid layer  $\\{\\Delta m_k\\}_{k=1}^K$</p>\n<h2 id=\"R-CNN-\"><a href=\"#R-CNN-\" class=\"headerlink\" title=\"R-CNN \"></a>R-CNN </h2><p> ConvNet  ConvNet node  error-bounded saliency region  RoI  RoI  Image R-CNN  RoI  crop  image  ConvNet  Faster R-CNN Faster R-CNN  R-CNN ConvNet  bin   0 context Faster R-CNN  RoIPooling</p>\n<p> feature  R-CNN  cropped image  Faster R-CNN  RoI  RoI <br><br><img src=\"/images/obj_det/two_stage_fig2.png\" alt=\"\"></p>\n<center>2.  Faster R-CNN  R-CNN </center>\n\n<p> RoI <code>b</code> feature <code>b</code>  image  crop  resize  <code>224x224</code>  <code>14x14</code>  feature RoIPooling  <code>7x7</code> <code>7x7</code>  2x fc  RCNN  1024-D  $f_{RCNN}(b)$ <code>C+1</code>-way  softmax  <code>C+1</code>-D  fc  softmaxFaster R-CNN  1024-D Fast R-CNN head  $f_{FRCNN}(b)$ feature </p>\n<script type=\"math/tex; mode=display\">L_{mimic}=\\sum_{b \\in \\Omega}[1-\\cos (f_{RCNN}(b), f_{FRCNN}(b))]</script><p>$\\Omega$  RoI $\\cos(\\cdot, \\cdot)$ </p>\n<h1 id=\"Mask-R-CNN\"><a href=\"#Mask-R-CNN\" class=\"headerlink\" title=\"Mask R-CNN\"></a>Mask R-CNN</h1><p> Faster R-CNN  mask  instance segmentation</p>\n<p>mask  ROI  binary maskMask R-CNN  classification  segmentation  K+1 dimension  mask</p>\n<p><strong></strong></p>\n<script type=\"math/tex; mode=display\">L=L_{cls}+L_{box}+L_{mask}</script><p> Faster R-CNN mask  $Km^2$ K  foreground  <code>mxm</code>  resolution pixel  sigmoid $L_{mask}$  binary cross-entropy $L_{mask}$  resolution  position  <code>k</code>  $L_{mask}$  $m^2$  binary cross-entropy loss </p>\n<p> ROI  mask  <code>mxm</code>  maskmask  FCN layer  fcFCN </p>\n<h2 id=\"RoIAlign\"><a href=\"#RoIAlign\" class=\"headerlink\" title=\"RoIAlign\"></a>RoIAlign</h2><p>Faster R-CNN  RoIPool  RoI feature conv4  RoI  feature map <code>7x7</code> conv4  feature  RoI conv4  feature  stride=16 RoI  conv4  feature  $[x/16]$ $[\\cdot]$ RoI feature  <code>7x7</code>  RoI feature  <code>7x7</code> bins input image  RoI feature  pixel  mask </p>\n<p> $x/16$  $[x /16]$  conv4 feature  RoI  1<br><img src=\"/images/obj_det/two_stage_fig1.png\" alt=\"\"><center>fig1. RoIAlign </center></p>\n<p>1  <code>2x2</code> bins <code>7x7</code> bins  bin   feature patch  bin  feature patch pooling</p>\n<p> bin 4  max  average  pooling 1</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>backbone:</strong></p>\n<p>backbone 1. <code>ResNet-50-C4</code> <code>C4</code>  ResNet stage 4  feature2. <code>ResNet-FPN</code>ResNet  ResNeXt</p>\n<p><strong>detection head:</strong></p>\n<p> C4  RoI  feature  RoIAlign  <code>7x7x1024</code>  <code>res5</code>ResNet  stage 5 9  layer feature  tensor  box  mask</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>resize image 800 mini-batch  2  images image  N  RoIs <code>1:3</code></p>\n<h1 id=\"R-FCN\"><a href=\"#R-FCN\" class=\"headerlink\" title=\"R-FCN\"></a>R-FCN</h1><p>region-based fully convolutional networks</p>\n<p> backbone  translation invariance  translation variance  proposal box  gt box  IOU</p>\n<p>R-FCN  FCN  translation variance position-sensitive score maps score map encode <br><img src=\"/images/obj_det/two_stage_fig3.png\" alt=\"\"></p>\n<p>RPN  proposal boxRoIRoI  <code>kxk</code> grid cell  score map C+1  channel channel  RoIPooling  cell  score maps</p>\n<p>Backbone  ResNet-101 conv  2048-d dimension <code>1x1</code> 1024-d  conv $k^2(C+1)$-d  conv  positive-sensitive score maps</p>\n<h2 id=\"position-sensitive-roi-pooling\"><a href=\"#position-sensitive-roi-pooling\" class=\"headerlink\" title=\"position-sensitive roi pooling\"></a>position-sensitive roi pooling</h2><p> positive-sensitive score maps  RPN  RoI <code>kxk</code> bin bin  score map pooling RoI size  <code>wxh</code> bin  size  $\\frac w k \\times \\frac h k$ <code>(i,j)</code>  bin RoI pooling  <code>(i,j)</code>  score map  average pooling <code>kxkx(C+1)</code>  <strong>vote</strong> averaging <code>C+1</code>  vector RoI  softmax </p>\n"},{"title":"python C/C++ Extensions","date":"2021-06-15T06:06:41.000Z","p":"python/ext1","_content":"python  C/C++ \n<!-- more -->\n Python   Python [ The Python Tutorial](https://docs.python.org/3/tutorial/index.html#tutorial-index) [The Python Language Reference](https://docs.python.org/3/reference/index.html#reference-index)  Python [The Python Standard Library](https://docs.python.org/3/library/index.html#library-index)  Python  \n\n Python/C API,  [Python/C API Reference Manual](https://docs.python.org/3/c-api/index.html#c-api-index)\n\n\n python  Cython cffi SWIG  Numba\n\n#  C/C++  Python\n\nPython API    Python Python API  `Python.h` \n\n `spam`  C  `system()`  python  null  `spam` \n```python\n>>> import spam\n>>> status = spam.system(\"ls -l\")\n```\n `spammodule.c` `spam` \n```cpp\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n```\nPython  `<Python.h>` `PY_SSIZE_T_CLEAN` \n\n C  `spam.system(string)`  C \n```cpp\nstatic PyObject *\nspam_system(PyObject *self, PyObject *args)\n{\n    const char *command;\n    int sts;\n\n    if (!PyArg_ParseTuple(args, \"s\", &command))\n        return NULL;\n    sts = system(command);\n    return PyLong_FromLong(sts);\n}\n```\n C  `self`  `args` `self`    `args`  Python  item  Python  C  C  `system()` `PyArg_ParseTuple`  item  true\n\n## \n `NULL` `null` raise `raise expr from expr`  `expr` traceback  Python  `sys.exc_info()`  C \n\nPython API  `PyErr_SetString()` C   `PyExc_ZeroDivisionError`C  python \n\n `PyErr_Occurred()`  `NULL`\n\n  `g`  `f`  `g` `f`  `NULL`  `-1` `PyErr_*()`  `g`  `f`  `PyErr_*()`\n\n `PyErr_Clear()`  `malloc`  `realloc`  `PyErr_NoMemory` `PyLong_FromLong()`   `malloc`  `realloc`  `PyErr_NoMemory`\n\n `PyArg_ParseTuple()`  `-1` Unix \n\n `Py_XDECREF()`  `Py_DECREF()`\n\n \n```cpp\nstatic PyObject *SpamError;\n```\n `PyInit_spam()` \n```cpp\nPyMODINIT_FUNC\nPyInit_spam(void)\n{\n    PyObject *m;\n\n    m = PyModule_Create(&spammodule);\n    if (m == NULL)\n        return NULL;\n\n    SpamError = PyErr_NewException(\"spam.error\", NULL, NULL);\n    Py_XINCREF(SpamError);\n    if (PyModule_AddObject(m, \"error\", SpamError) < 0) {\n        Py_XDECREF(SpamError);\n        Py_CLEAR(SpamError);\n        Py_DECREF(m);\n        return NULL;\n    }\n\n    return m;\n}\n```\n`PyErr_NewException()`  Exception  python  `spam.error``system()` \n```cpp\nstatic PyObject *\nspam_system(PyObject *self, PyObject *args)\n{\n    const char *command;\n    int sts;\n\n    if (!PyArg_ParseTuple(args, \"s\", &command))\n        return NULL;\n    sts = system(command);\n    if (sts < 0) {\n        PyErr_SetString(SpamError, \"System command failed\");\n        return NULL;\n    }\n    return PyLong_FromLong(sts);\n}\n```\n\n void  C  Python  None\n```cpp\nPy_INCREF(Py_None);\nreturn Py_None;\n```\n `Py_RETURN_NONE` \n\n## \n Python  `spam_system()`\n```cpp\nstatic PyMethodDef SpamMethods[] = {\n    ...\n    {\"system\",  spam_system, METH_VARARGS,\n     \"Execute a shell command.\"},\n    ...\n    {NULL, NULL, 0, NULL}        /* Sentinel */\n};\n```\npython  C  python  C  `METH_VARARGS`  `METH_VARARGS | METH_KEYWORDS``METH_VARARGS` python  `PyArg_ParseTuple()`  C  `METH_KEYWORDS`C  `PyObject *`  `PyArg_ParseTupleAndKeywords()` \n\n\n```cpp\nstatic struct PyModuleDef spammodule = {\n    PyModuleDef_HEAD_INIT,\n    \"spam\",   /* name of module */\n    spam_doc, /* module documentation, may be NULL */\n    -1,       /* size of per-interpreter state of the module,\n                 or -1 if the module keeps state in global variables. */\n    SpamMethods\n};\n```\n\n python  `PyInit_<modulename>()` `<modulename>`  python \n```cpp\nPyMODULEINIT_FUNC\nPyInit_spam(void) {\n    return PyModule_Create(&spammodule);\n}\n```\n\n python  import  `spam` `PyInit_spam()`  `PyModule_Create()`\n\n C  Python `PyInit_spam()`  `PyImport_Inittab` \n```cpp\nint\nmain(int argc, char *argv[])\n{\n    wchar_t *program = Py_DecodeLocale(argv[0], NULL);\n    if (program == NULL) {\n        fprintf(stderr, \"Fatal error: cannot decode argv[0]\\n\");\n        exit(1);\n    }\n\n    /* Add a built-in module, before Py_Initialize */\n    if (PyImport_AppendInittab(\"spam\", PyInit_spam) == -1) {\n        fprintf(stderr, \"Error: could not extend in-built modules table\\n\");\n        exit(1);\n    }\n\n    /* Pass argv[0] to the Python interpreter */\n    Py_SetProgramName(program);\n\n    /* Initialize the Python interpreter.  Required.\n       If this step fails, it will be a fatal error. */\n    Py_Initialize();\n\n    /* Optionally import the module; alternatively,\n       import can be deferred until the embedded script\n       imports it. */\n    PyObject *pmodule = PyImport_ImportModule(\"spam\");\n    if (!pmodule) {\n        PyErr_Print();\n        fprintf(stderr, \"Error: could not import module 'spam'\\n\");\n    }\n\n    ...\n\n    PyMem_RawFree(program);\n    return 0;\n}\n```\n python CPython  Python  C  Python \n\n## \n C  C  python \n\n `spammodule.c`  python  `Modules/`  `Modules/Setup.local` \n```\nspam spammodule.o\n```\n\n top-level  `make`  python \n\nC `Modules/Setup.local` \n```\nspam spammodule.o -lX11\n```\n\n\n\n##  C  Python \n Python  C  C  pythonPython  C  \n\n `spammodule.c`  Python \n```cpp\nstatic PyObject *my_callback = NULL;\n\nstatic PyObject *\nmy_set_callback(PyObject *dummy, PyObject *args)\n{\n    PyObject *result = NULL;\n    PyObject *temp;\n\n    if (PyArg_ParseTuple(args, \"O:set_callback\", &temp)) {\n        if (!PyCallable_Check(temp)) {\n            PyErr_SetString(PyExc_TypeError, \"parameter must be callable\");\n            return NULL;\n        }\n        Py_XINCREF(temp);         /* Add a reference to new callback */\n        Py_XDECREF(my_callback);  /* Dispose of previous callback */\n        my_callback = temp;       /* Remember new callback */\n        /* Boilerplate to return \"None\" */\n        Py_INCREF(Py_None);\n        result = Py_None;\n    }\n    return result;\n}\n```\n `spam`  `spam_system()`  \n```\nstatic PyMethodDef SpamMethods[] = {\n    ...\n    {\"set_cb\",  my_set_callback, METH_VARARGS,\n     \"Set a callback function\"},\n    ...\n    {NULL, NULL, 0, NULL}        /* Sentinel */\n};\n```\n Python  `spam.set_cb()`  C   C  `use_cb()` \n```cpp\nint arg;\nPyObject *arglist;\nPyObject *result;\n...\narg = 123;\n...\n/* Time to call the callback */\narglist = Py_BuildValue(\"(i)\", arg);\nresult = PyObject_CallObject(my_callback, arglist);\nPy_DECREF(arglist);\n```\n `PyObject_CallObject()`  tuple  `NULL` empty tuple C  `Py_BuildValue()`  Python\n\n`PyObject_CallObject()`  `PyObject_CallObject()`  `Py_DECREF()`\n\n`PyObject_CallObject()`  `Py_DECREF()` `NULL`\n\n```\nPyObject *arglist;\n...\narglist = Py_BuildValue(\"(l)\", eventcode);\nresult = PyObject_CallObject(my_callback, arglist);\nPy_DECREF(arglist);\nif (result == NULL)\n    return NULL; /* Pass error back */\n/* Here maybe use the result */\nPy_DECREF(result);\n```\n\n `PyObject_Call()` \n```\nPyObject *dict;\n...\ndict = Py_BuildValue(\"{s:i}\", \"name\", val);\nresult = PyObject_Call(my_callback, NULL, dict);\nPy_DECREF(dict);\nif (result == NULL)\n    return NULL; /* Pass error back */\n/* Here maybe use the result */\nPy_DECREF(result);\n```","source":"_posts/python/ext1.md","raw":"---\ntitle: python C/C++ Extensions\ndate: 2021-06-15 14:06:41\ntags:\np: python/ext1\n---\npython  C/C++ \n<!-- more -->\n Python   Python [ The Python Tutorial](https://docs.python.org/3/tutorial/index.html#tutorial-index) [The Python Language Reference](https://docs.python.org/3/reference/index.html#reference-index)  Python [The Python Standard Library](https://docs.python.org/3/library/index.html#library-index)  Python  \n\n Python/C API,  [Python/C API Reference Manual](https://docs.python.org/3/c-api/index.html#c-api-index)\n\n\n python  Cython cffi SWIG  Numba\n\n#  C/C++  Python\n\nPython API    Python Python API  `Python.h` \n\n `spam`  C  `system()`  python  null  `spam` \n```python\n>>> import spam\n>>> status = spam.system(\"ls -l\")\n```\n `spammodule.c` `spam` \n```cpp\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n```\nPython  `<Python.h>` `PY_SSIZE_T_CLEAN` \n\n C  `spam.system(string)`  C \n```cpp\nstatic PyObject *\nspam_system(PyObject *self, PyObject *args)\n{\n    const char *command;\n    int sts;\n\n    if (!PyArg_ParseTuple(args, \"s\", &command))\n        return NULL;\n    sts = system(command);\n    return PyLong_FromLong(sts);\n}\n```\n C  `self`  `args` `self`    `args`  Python  item  Python  C  C  `system()` `PyArg_ParseTuple`  item  true\n\n## \n `NULL` `null` raise `raise expr from expr`  `expr` traceback  Python  `sys.exc_info()`  C \n\nPython API  `PyErr_SetString()` C   `PyExc_ZeroDivisionError`C  python \n\n `PyErr_Occurred()`  `NULL`\n\n  `g`  `f`  `g` `f`  `NULL`  `-1` `PyErr_*()`  `g`  `f`  `PyErr_*()`\n\n `PyErr_Clear()`  `malloc`  `realloc`  `PyErr_NoMemory` `PyLong_FromLong()`   `malloc`  `realloc`  `PyErr_NoMemory`\n\n `PyArg_ParseTuple()`  `-1` Unix \n\n `Py_XDECREF()`  `Py_DECREF()`\n\n \n```cpp\nstatic PyObject *SpamError;\n```\n `PyInit_spam()` \n```cpp\nPyMODINIT_FUNC\nPyInit_spam(void)\n{\n    PyObject *m;\n\n    m = PyModule_Create(&spammodule);\n    if (m == NULL)\n        return NULL;\n\n    SpamError = PyErr_NewException(\"spam.error\", NULL, NULL);\n    Py_XINCREF(SpamError);\n    if (PyModule_AddObject(m, \"error\", SpamError) < 0) {\n        Py_XDECREF(SpamError);\n        Py_CLEAR(SpamError);\n        Py_DECREF(m);\n        return NULL;\n    }\n\n    return m;\n}\n```\n`PyErr_NewException()`  Exception  python  `spam.error``system()` \n```cpp\nstatic PyObject *\nspam_system(PyObject *self, PyObject *args)\n{\n    const char *command;\n    int sts;\n\n    if (!PyArg_ParseTuple(args, \"s\", &command))\n        return NULL;\n    sts = system(command);\n    if (sts < 0) {\n        PyErr_SetString(SpamError, \"System command failed\");\n        return NULL;\n    }\n    return PyLong_FromLong(sts);\n}\n```\n\n void  C  Python  None\n```cpp\nPy_INCREF(Py_None);\nreturn Py_None;\n```\n `Py_RETURN_NONE` \n\n## \n Python  `spam_system()`\n```cpp\nstatic PyMethodDef SpamMethods[] = {\n    ...\n    {\"system\",  spam_system, METH_VARARGS,\n     \"Execute a shell command.\"},\n    ...\n    {NULL, NULL, 0, NULL}        /* Sentinel */\n};\n```\npython  C  python  C  `METH_VARARGS`  `METH_VARARGS | METH_KEYWORDS``METH_VARARGS` python  `PyArg_ParseTuple()`  C  `METH_KEYWORDS`C  `PyObject *`  `PyArg_ParseTupleAndKeywords()` \n\n\n```cpp\nstatic struct PyModuleDef spammodule = {\n    PyModuleDef_HEAD_INIT,\n    \"spam\",   /* name of module */\n    spam_doc, /* module documentation, may be NULL */\n    -1,       /* size of per-interpreter state of the module,\n                 or -1 if the module keeps state in global variables. */\n    SpamMethods\n};\n```\n\n python  `PyInit_<modulename>()` `<modulename>`  python \n```cpp\nPyMODULEINIT_FUNC\nPyInit_spam(void) {\n    return PyModule_Create(&spammodule);\n}\n```\n\n python  import  `spam` `PyInit_spam()`  `PyModule_Create()`\n\n C  Python `PyInit_spam()`  `PyImport_Inittab` \n```cpp\nint\nmain(int argc, char *argv[])\n{\n    wchar_t *program = Py_DecodeLocale(argv[0], NULL);\n    if (program == NULL) {\n        fprintf(stderr, \"Fatal error: cannot decode argv[0]\\n\");\n        exit(1);\n    }\n\n    /* Add a built-in module, before Py_Initialize */\n    if (PyImport_AppendInittab(\"spam\", PyInit_spam) == -1) {\n        fprintf(stderr, \"Error: could not extend in-built modules table\\n\");\n        exit(1);\n    }\n\n    /* Pass argv[0] to the Python interpreter */\n    Py_SetProgramName(program);\n\n    /* Initialize the Python interpreter.  Required.\n       If this step fails, it will be a fatal error. */\n    Py_Initialize();\n\n    /* Optionally import the module; alternatively,\n       import can be deferred until the embedded script\n       imports it. */\n    PyObject *pmodule = PyImport_ImportModule(\"spam\");\n    if (!pmodule) {\n        PyErr_Print();\n        fprintf(stderr, \"Error: could not import module 'spam'\\n\");\n    }\n\n    ...\n\n    PyMem_RawFree(program);\n    return 0;\n}\n```\n python CPython  Python  C  Python \n\n## \n C  C  python \n\n `spammodule.c`  python  `Modules/`  `Modules/Setup.local` \n```\nspam spammodule.o\n```\n\n top-level  `make`  python \n\nC `Modules/Setup.local` \n```\nspam spammodule.o -lX11\n```\n\n\n\n##  C  Python \n Python  C  C  pythonPython  C  \n\n `spammodule.c`  Python \n```cpp\nstatic PyObject *my_callback = NULL;\n\nstatic PyObject *\nmy_set_callback(PyObject *dummy, PyObject *args)\n{\n    PyObject *result = NULL;\n    PyObject *temp;\n\n    if (PyArg_ParseTuple(args, \"O:set_callback\", &temp)) {\n        if (!PyCallable_Check(temp)) {\n            PyErr_SetString(PyExc_TypeError, \"parameter must be callable\");\n            return NULL;\n        }\n        Py_XINCREF(temp);         /* Add a reference to new callback */\n        Py_XDECREF(my_callback);  /* Dispose of previous callback */\n        my_callback = temp;       /* Remember new callback */\n        /* Boilerplate to return \"None\" */\n        Py_INCREF(Py_None);\n        result = Py_None;\n    }\n    return result;\n}\n```\n `spam`  `spam_system()`  \n```\nstatic PyMethodDef SpamMethods[] = {\n    ...\n    {\"set_cb\",  my_set_callback, METH_VARARGS,\n     \"Set a callback function\"},\n    ...\n    {NULL, NULL, 0, NULL}        /* Sentinel */\n};\n```\n Python  `spam.set_cb()`  C   C  `use_cb()` \n```cpp\nint arg;\nPyObject *arglist;\nPyObject *result;\n...\narg = 123;\n...\n/* Time to call the callback */\narglist = Py_BuildValue(\"(i)\", arg);\nresult = PyObject_CallObject(my_callback, arglist);\nPy_DECREF(arglist);\n```\n `PyObject_CallObject()`  tuple  `NULL` empty tuple C  `Py_BuildValue()`  Python\n\n`PyObject_CallObject()`  `PyObject_CallObject()`  `Py_DECREF()`\n\n`PyObject_CallObject()`  `Py_DECREF()` `NULL`\n\n```\nPyObject *arglist;\n...\narglist = Py_BuildValue(\"(l)\", eventcode);\nresult = PyObject_CallObject(my_callback, arglist);\nPy_DECREF(arglist);\nif (result == NULL)\n    return NULL; /* Pass error back */\n/* Here maybe use the result */\nPy_DECREF(result);\n```\n\n `PyObject_Call()` \n```\nPyObject *dict;\n...\ndict = Py_BuildValue(\"{s:i}\", \"name\", val);\nresult = PyObject_Call(my_callback, NULL, dict);\nPy_DECREF(dict);\nif (result == NULL)\n    return NULL; /* Pass error back */\n/* Here maybe use the result */\nPy_DECREF(result);\n```","slug":"python/ext1","published":1,"updated":"2021-09-15T02:05:45.827Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91h0035p0dj23495ud0","content":"<p>python  C/C++ <br><span id=\"more\"></span><br> Python   Python <a href=\"https://docs.python.org/3/tutorial/index.html#tutorial-index\"> The Python Tutorial</a> <a href=\"https://docs.python.org/3/reference/index.html#reference-index\">The Python Language Reference</a>  Python <a href=\"https://docs.python.org/3/library/index.html#library-index\">The Python Standard Library</a>  Python  </p>\n<p> Python/C API,  <a href=\"https://docs.python.org/3/c-api/index.html#c-api-index\">Python/C API Reference Manual</a></p>\n<p> python  Cython cffi SWIG  Numba</p>\n<h1 id=\"-C-C--Python\"><a href=\"#-C-C--Python\" class=\"headerlink\" title=\" C/C++  Python\"></a> C/C++  Python</h1><p>Python API    Python Python API  <code>Python.h</code> </p>\n<p> <code>spam</code>  C  <code>system()</code>  python  null  <code>spam</code> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> spam</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>status = spam.system(<span class=\"string\">&quot;ls -l&quot;</span>)</span><br></pre></td></tr></table></figure><br> <code>spammodule.c</code> <code>spam</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PY_SSIZE_T_CLEAN</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;Python.h&gt;</span></span></span><br></pre></td></tr></table></figure><br>Python  <code>&lt;Python.h&gt;</code> <code>PY_SSIZE_T_CLEAN</code> </p>\n<p> C  <code>spam.system(string)</code>  C <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">spam_system</span><span class=\"params\">(PyObject *self, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> sts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;s&quot;</span>, &amp;command))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    sts = <span class=\"built_in\">system</span>(command);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyLong_FromLong</span>(sts);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> C  <code>self</code>  <code>args</code> <code>self</code>    <code>args</code>  Python  item  Python  C  C  <code>system()</code> <code>PyArg_ParseTuple</code>  item  true</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>NULL</code> <code>null</code> raise <code>raise expr from expr</code>  <code>expr</code> traceback  Python  <code>sys.exc_info()</code>  C </p>\n<p>Python API  <code>PyErr_SetString()</code> C   <code>PyExc_ZeroDivisionError</code>C  python </p>\n<p> <code>PyErr_Occurred()</code>  <code>NULL</code></p>\n<p>  <code>g</code>  <code>f</code>  <code>g</code> <code>f</code>  <code>NULL</code>  <code>-1</code> <code>PyErr_*()</code>  <code>g</code>  <code>f</code>  <code>PyErr_*()</code></p>\n<p> <code>PyErr_Clear()</code>  <code>malloc</code>  <code>realloc</code>  <code>PyErr_NoMemory</code> <code>PyLong_FromLong()</code>   <code>malloc</code>  <code>realloc</code>  <code>PyErr_NoMemory</code></p>\n<p> <code>PyArg_ParseTuple()</code>  <code>-1</code> Unix </p>\n<p> <code>Py_XDECREF()</code>  <code>Py_DECREF()</code></p>\n<p> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyObject *SpamError;</span><br></pre></td></tr></table></figure><br> <code>PyInit_spam()</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;spammodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    SpamError = <span class=\"built_in\">PyErr_NewException</span>(<span class=\"string\">&quot;spam.error&quot;</span>, <span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"built_in\">Py_XINCREF</span>(SpamError);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyModule_AddObject</span>(m, <span class=\"string\">&quot;error&quot;</span>, SpamError) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">Py_XDECREF</span>(SpamError);</span><br><span class=\"line\">        <span class=\"built_in\">Py_CLEAR</span>(SpamError);</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(m);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><code>PyErr_NewException()</code>  Exception  python  <code>spam.error</code><code>system()</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">spam_system</span><span class=\"params\">(PyObject *self, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> sts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;s&quot;</span>, &amp;command))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    sts = <span class=\"built_in\">system</span>(command);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (sts &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">PyErr_SetString</span>(SpamError, <span class=\"string\">&quot;System command failed&quot;</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyLong_FromLong</span>(sts);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> void  C  Python  None<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">Py_INCREF</span>(Py_None);</span><br><span class=\"line\"><span class=\"keyword\">return</span> Py_None;</span><br></pre></td></tr></table></figure><br> <code>Py_RETURN_NONE</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Python  <code>spam_system()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyMethodDef SpamMethods[] = &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;<span class=\"string\">&quot;system&quot;</span>,  spam_system, METH_VARARGS,</span><br><span class=\"line\">     <span class=\"string\">&quot;Execute a shell command.&quot;</span>&#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;<span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>, <span class=\"number\">0</span>, <span class=\"literal\">NULL</span>&#125;        <span class=\"comment\">/* Sentinel */</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>python  C  python  C  <code>METH_VARARGS</code>  <code>METH_VARARGS | METH_KEYWORDS</code><code>METH_VARARGS</code> python  <code>PyArg_ParseTuple()</code>  C  <code>METH_KEYWORDS</code>C  <code>PyObject *</code>  <code>PyArg_ParseTupleAndKeywords()</code> </p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">PyModuleDef</span> <span class=\"title\">spammodule</span> =</span> &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    <span class=\"string\">&quot;spam&quot;</span>,   <span class=\"comment\">/* name of module */</span></span><br><span class=\"line\">    spam_doc, <span class=\"comment\">/* module documentation, may be NULL */</span></span><br><span class=\"line\">    <span class=\"number\">-1</span>,       <span class=\"comment\">/* size of per-interpreter state of the module,</span></span><br><span class=\"line\"><span class=\"comment\">                 or -1 if the module keeps state in global variables. */</span></span><br><span class=\"line\">    SpamMethods</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p> python  <code>PyInit_&lt;modulename&gt;()</code> <code>&lt;modulename&gt;</code>  python <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODULEINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyModule_Create</span>(&amp;spammodule);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> python  import  <code>spam</code> <code>PyInit_spam()</code>  <code>PyModule_Create()</code></p>\n<p> C  Python <code>PyInit_spam()</code>  <code>PyImport_Inittab</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> *program = <span class=\"built_in\">Py_DecodeLocale</span>(argv[<span class=\"number\">0</span>], <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (program == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">fprintf</span>(stderr, <span class=\"string\">&quot;Fatal error: cannot decode argv[0]\\n&quot;</span>);</span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Add a built-in module, before Py_Initialize */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyImport_AppendInittab</span>(<span class=\"string\">&quot;spam&quot;</span>, PyInit_spam) == <span class=\"number\">-1</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">fprintf</span>(stderr, <span class=\"string\">&quot;Error: could not extend in-built modules table\\n&quot;</span>);</span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Pass argv[0] to the Python interpreter */</span></span><br><span class=\"line\">    <span class=\"built_in\">Py_SetProgramName</span>(program);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Initialize the Python interpreter.  Required.</span></span><br><span class=\"line\"><span class=\"comment\">       If this step fails, it will be a fatal error. */</span></span><br><span class=\"line\">    <span class=\"built_in\">Py_Initialize</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Optionally import the module; alternatively,</span></span><br><span class=\"line\"><span class=\"comment\">       import can be deferred until the embedded script</span></span><br><span class=\"line\"><span class=\"comment\">       imports it. */</span></span><br><span class=\"line\">    PyObject *pmodule = <span class=\"built_in\">PyImport_ImportModule</span>(<span class=\"string\">&quot;spam&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!pmodule) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">PyErr_Print</span>();</span><br><span class=\"line\">        <span class=\"built_in\">fprintf</span>(stderr, <span class=\"string\">&quot;Error: could not import module &#x27;spam&#x27;\\n&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">PyMem_RawFree</span>(program);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> python CPython  Python  C  Python </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> C  C  python </p>\n<p> <code>spammodule.c</code>  python  <code>Modules/</code>  <code>Modules/Setup.local</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spam spammodule.o</span><br></pre></td></tr></table></figure></p>\n<p> top-level  <code>make</code>  python </p>\n<p>C <code>Modules/Setup.local</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spam spammodule.o -lX11</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"-C--Python-\"><a href=\"#-C--Python-\" class=\"headerlink\" title=\" C  Python \"></a> C  Python </h2><p> Python  C  C  pythonPython  C  </p>\n<p> <code>spammodule.c</code>  Python <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyObject *my_callback = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">my_set_callback</span><span class=\"params\">(PyObject *dummy, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *result = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject *temp;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;O:set_callback&quot;</span>, &amp;temp)) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyCallable_Check</span>(temp)) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">PyErr_SetString</span>(PyExc_TypeError, <span class=\"string\">&quot;parameter must be callable&quot;</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">Py_XINCREF</span>(temp);         <span class=\"comment\">/* Add a reference to new callback */</span></span><br><span class=\"line\">        <span class=\"built_in\">Py_XDECREF</span>(my_callback);  <span class=\"comment\">/* Dispose of previous callback */</span></span><br><span class=\"line\">        my_callback = temp;       <span class=\"comment\">/* Remember new callback */</span></span><br><span class=\"line\">        <span class=\"comment\">/* Boilerplate to return &quot;None&quot; */</span></span><br><span class=\"line\">        <span class=\"built_in\">Py_INCREF</span>(Py_None);</span><br><span class=\"line\">        result = Py_None;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>spam</code>  <code>spam_system()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyMethodDef SpamMethods[] = &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;&quot;set_cb&quot;,  my_set_callback, METH_VARARGS,</span><br><span class=\"line\">     &quot;Set a callback function&quot;&#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;NULL, NULL, 0, NULL&#125;        /* Sentinel */</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> Python  <code>spam.set_cb()</code>  C   C  <code>use_cb()</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> arg;</span><br><span class=\"line\">PyObject *arglist;</span><br><span class=\"line\">PyObject *result;</span><br><span class=\"line\">...</span><br><span class=\"line\">arg = <span class=\"number\">123</span>;</span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"comment\">/* Time to call the callback */</span></span><br><span class=\"line\">arglist = <span class=\"built_in\">Py_BuildValue</span>(<span class=\"string\">&quot;(i)&quot;</span>, arg);</span><br><span class=\"line\">result = <span class=\"built_in\">PyObject_CallObject</span>(my_callback, arglist);</span><br><span class=\"line\"><span class=\"built_in\">Py_DECREF</span>(arglist);</span><br></pre></td></tr></table></figure><br> <code>PyObject_CallObject()</code>  tuple  <code>NULL</code> empty tuple C  <code>Py_BuildValue()</code>  Python</p>\n<p><code>PyObject_CallObject()</code>  <code>PyObject_CallObject()</code>  <code>Py_DECREF()</code></p>\n<p><code>PyObject_CallObject()</code>  <code>Py_DECREF()</code> <code>NULL</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyObject *arglist;</span><br><span class=\"line\">...</span><br><span class=\"line\">arglist = Py_BuildValue(&quot;(l)&quot;, eventcode);</span><br><span class=\"line\">result = PyObject_CallObject(my_callback, arglist);</span><br><span class=\"line\">Py_DECREF(arglist);</span><br><span class=\"line\">if (result == NULL)</span><br><span class=\"line\">    return NULL; /* Pass error back */</span><br><span class=\"line\">/* Here maybe use the result */</span><br><span class=\"line\">Py_DECREF(result);</span><br></pre></td></tr></table></figure>\n<p> <code>PyObject_Call()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyObject *dict;</span><br><span class=\"line\">...</span><br><span class=\"line\">dict = Py_BuildValue(&quot;&#123;s:i&#125;&quot;, &quot;name&quot;, val);</span><br><span class=\"line\">result = PyObject_Call(my_callback, NULL, dict);</span><br><span class=\"line\">Py_DECREF(dict);</span><br><span class=\"line\">if (result == NULL)</span><br><span class=\"line\">    return NULL; /* Pass error back */</span><br><span class=\"line\">/* Here maybe use the result */</span><br><span class=\"line\">Py_DECREF(result);</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>python  C/C++ <br>","more":"<br> Python   Python <a href=\"https://docs.python.org/3/tutorial/index.html#tutorial-index\"> The Python Tutorial</a> <a href=\"https://docs.python.org/3/reference/index.html#reference-index\">The Python Language Reference</a>  Python <a href=\"https://docs.python.org/3/library/index.html#library-index\">The Python Standard Library</a>  Python  </p>\n<p> Python/C API,  <a href=\"https://docs.python.org/3/c-api/index.html#c-api-index\">Python/C API Reference Manual</a></p>\n<p> python  Cython cffi SWIG  Numba</p>\n<h1 id=\"-C-C--Python\"><a href=\"#-C-C--Python\" class=\"headerlink\" title=\" C/C++  Python\"></a> C/C++  Python</h1><p>Python API    Python Python API  <code>Python.h</code> </p>\n<p> <code>spam</code>  C  <code>system()</code>  python  null  <code>spam</code> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">import</span> spam</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>status = spam.system(<span class=\"string\">&quot;ls -l&quot;</span>)</span><br></pre></td></tr></table></figure><br> <code>spammodule.c</code> <code>spam</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PY_SSIZE_T_CLEAN</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;Python.h&gt;</span></span></span><br></pre></td></tr></table></figure><br>Python  <code>&lt;Python.h&gt;</code> <code>PY_SSIZE_T_CLEAN</code> </p>\n<p> C  <code>spam.system(string)</code>  C <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">spam_system</span><span class=\"params\">(PyObject *self, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> sts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;s&quot;</span>, &amp;command))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    sts = <span class=\"built_in\">system</span>(command);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyLong_FromLong</span>(sts);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> C  <code>self</code>  <code>args</code> <code>self</code>    <code>args</code>  Python  item  Python  C  C  <code>system()</code> <code>PyArg_ParseTuple</code>  item  true</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>NULL</code> <code>null</code> raise <code>raise expr from expr</code>  <code>expr</code> traceback  Python  <code>sys.exc_info()</code>  C </p>\n<p>Python API  <code>PyErr_SetString()</code> C   <code>PyExc_ZeroDivisionError</code>C  python </p>\n<p> <code>PyErr_Occurred()</code>  <code>NULL</code></p>\n<p>  <code>g</code>  <code>f</code>  <code>g</code> <code>f</code>  <code>NULL</code>  <code>-1</code> <code>PyErr_*()</code>  <code>g</code>  <code>f</code>  <code>PyErr_*()</code></p>\n<p> <code>PyErr_Clear()</code>  <code>malloc</code>  <code>realloc</code>  <code>PyErr_NoMemory</code> <code>PyLong_FromLong()</code>   <code>malloc</code>  <code>realloc</code>  <code>PyErr_NoMemory</code></p>\n<p> <code>PyArg_ParseTuple()</code>  <code>-1</code> Unix </p>\n<p> <code>Py_XDECREF()</code>  <code>Py_DECREF()</code></p>\n<p> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyObject *SpamError;</span><br></pre></td></tr></table></figure><br> <code>PyInit_spam()</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;spammodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    SpamError = <span class=\"built_in\">PyErr_NewException</span>(<span class=\"string\">&quot;spam.error&quot;</span>, <span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"built_in\">Py_XINCREF</span>(SpamError);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyModule_AddObject</span>(m, <span class=\"string\">&quot;error&quot;</span>, SpamError) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">Py_XDECREF</span>(SpamError);</span><br><span class=\"line\">        <span class=\"built_in\">Py_CLEAR</span>(SpamError);</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(m);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><code>PyErr_NewException()</code>  Exception  python  <code>spam.error</code><code>system()</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">spam_system</span><span class=\"params\">(PyObject *self, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> sts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;s&quot;</span>, &amp;command))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    sts = <span class=\"built_in\">system</span>(command);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (sts &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">PyErr_SetString</span>(SpamError, <span class=\"string\">&quot;System command failed&quot;</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyLong_FromLong</span>(sts);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> void  C  Python  None<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">Py_INCREF</span>(Py_None);</span><br><span class=\"line\"><span class=\"keyword\">return</span> Py_None;</span><br></pre></td></tr></table></figure><br> <code>Py_RETURN_NONE</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Python  <code>spam_system()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyMethodDef SpamMethods[] = &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;<span class=\"string\">&quot;system&quot;</span>,  spam_system, METH_VARARGS,</span><br><span class=\"line\">     <span class=\"string\">&quot;Execute a shell command.&quot;</span>&#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;<span class=\"literal\">NULL</span>, <span class=\"literal\">NULL</span>, <span class=\"number\">0</span>, <span class=\"literal\">NULL</span>&#125;        <span class=\"comment\">/* Sentinel */</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>python  C  python  C  <code>METH_VARARGS</code>  <code>METH_VARARGS | METH_KEYWORDS</code><code>METH_VARARGS</code> python  <code>PyArg_ParseTuple()</code>  C  <code>METH_KEYWORDS</code>C  <code>PyObject *</code>  <code>PyArg_ParseTupleAndKeywords()</code> </p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">PyModuleDef</span> <span class=\"title\">spammodule</span> =</span> &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    <span class=\"string\">&quot;spam&quot;</span>,   <span class=\"comment\">/* name of module */</span></span><br><span class=\"line\">    spam_doc, <span class=\"comment\">/* module documentation, may be NULL */</span></span><br><span class=\"line\">    <span class=\"number\">-1</span>,       <span class=\"comment\">/* size of per-interpreter state of the module,</span></span><br><span class=\"line\"><span class=\"comment\">                 or -1 if the module keeps state in global variables. */</span></span><br><span class=\"line\">    SpamMethods</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p> python  <code>PyInit_&lt;modulename&gt;()</code> <code>&lt;modulename&gt;</code>  python <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODULEINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyModule_Create</span>(&amp;spammodule);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> python  import  <code>spam</code> <code>PyInit_spam()</code>  <code>PyModule_Create()</code></p>\n<p> C  Python <code>PyInit_spam()</code>  <code>PyImport_Inittab</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> *argv[])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">wchar_t</span> *program = <span class=\"built_in\">Py_DecodeLocale</span>(argv[<span class=\"number\">0</span>], <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (program == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">fprintf</span>(stderr, <span class=\"string\">&quot;Fatal error: cannot decode argv[0]\\n&quot;</span>);</span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Add a built-in module, before Py_Initialize */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyImport_AppendInittab</span>(<span class=\"string\">&quot;spam&quot;</span>, PyInit_spam) == <span class=\"number\">-1</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">fprintf</span>(stderr, <span class=\"string\">&quot;Error: could not extend in-built modules table\\n&quot;</span>);</span><br><span class=\"line\">        <span class=\"built_in\">exit</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Pass argv[0] to the Python interpreter */</span></span><br><span class=\"line\">    <span class=\"built_in\">Py_SetProgramName</span>(program);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Initialize the Python interpreter.  Required.</span></span><br><span class=\"line\"><span class=\"comment\">       If this step fails, it will be a fatal error. */</span></span><br><span class=\"line\">    <span class=\"built_in\">Py_Initialize</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Optionally import the module; alternatively,</span></span><br><span class=\"line\"><span class=\"comment\">       import can be deferred until the embedded script</span></span><br><span class=\"line\"><span class=\"comment\">       imports it. */</span></span><br><span class=\"line\">    PyObject *pmodule = <span class=\"built_in\">PyImport_ImportModule</span>(<span class=\"string\">&quot;spam&quot;</span>);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!pmodule) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">PyErr_Print</span>();</span><br><span class=\"line\">        <span class=\"built_in\">fprintf</span>(stderr, <span class=\"string\">&quot;Error: could not import module &#x27;spam&#x27;\\n&quot;</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">PyMem_RawFree</span>(program);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> python CPython  Python  C  Python </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> C  C  python </p>\n<p> <code>spammodule.c</code>  python  <code>Modules/</code>  <code>Modules/Setup.local</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spam spammodule.o</span><br></pre></td></tr></table></figure></p>\n<p> top-level  <code>make</code>  python </p>\n<p>C <code>Modules/Setup.local</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spam spammodule.o -lX11</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"-C--Python-\"><a href=\"#-C--Python-\" class=\"headerlink\" title=\" C  Python \"></a> C  Python </h2><p> Python  C  C  pythonPython  C  </p>\n<p> <code>spammodule.c</code>  Python <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyObject *my_callback = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">my_set_callback</span><span class=\"params\">(PyObject *dummy, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *result = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    PyObject *temp;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;O:set_callback&quot;</span>, &amp;temp)) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyCallable_Check</span>(temp)) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">PyErr_SetString</span>(PyExc_TypeError, <span class=\"string\">&quot;parameter must be callable&quot;</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">Py_XINCREF</span>(temp);         <span class=\"comment\">/* Add a reference to new callback */</span></span><br><span class=\"line\">        <span class=\"built_in\">Py_XDECREF</span>(my_callback);  <span class=\"comment\">/* Dispose of previous callback */</span></span><br><span class=\"line\">        my_callback = temp;       <span class=\"comment\">/* Remember new callback */</span></span><br><span class=\"line\">        <span class=\"comment\">/* Boilerplate to return &quot;None&quot; */</span></span><br><span class=\"line\">        <span class=\"built_in\">Py_INCREF</span>(Py_None);</span><br><span class=\"line\">        result = Py_None;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>spam</code>  <code>spam_system()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyMethodDef SpamMethods[] = &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;&quot;set_cb&quot;,  my_set_callback, METH_VARARGS,</span><br><span class=\"line\">     &quot;Set a callback function&quot;&#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;NULL, NULL, 0, NULL&#125;        /* Sentinel */</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> Python  <code>spam.set_cb()</code>  C   C  <code>use_cb()</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> arg;</span><br><span class=\"line\">PyObject *arglist;</span><br><span class=\"line\">PyObject *result;</span><br><span class=\"line\">...</span><br><span class=\"line\">arg = <span class=\"number\">123</span>;</span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"comment\">/* Time to call the callback */</span></span><br><span class=\"line\">arglist = <span class=\"built_in\">Py_BuildValue</span>(<span class=\"string\">&quot;(i)&quot;</span>, arg);</span><br><span class=\"line\">result = <span class=\"built_in\">PyObject_CallObject</span>(my_callback, arglist);</span><br><span class=\"line\"><span class=\"built_in\">Py_DECREF</span>(arglist);</span><br></pre></td></tr></table></figure><br> <code>PyObject_CallObject()</code>  tuple  <code>NULL</code> empty tuple C  <code>Py_BuildValue()</code>  Python</p>\n<p><code>PyObject_CallObject()</code>  <code>PyObject_CallObject()</code>  <code>Py_DECREF()</code></p>\n<p><code>PyObject_CallObject()</code>  <code>Py_DECREF()</code> <code>NULL</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyObject *arglist;</span><br><span class=\"line\">...</span><br><span class=\"line\">arglist = Py_BuildValue(&quot;(l)&quot;, eventcode);</span><br><span class=\"line\">result = PyObject_CallObject(my_callback, arglist);</span><br><span class=\"line\">Py_DECREF(arglist);</span><br><span class=\"line\">if (result == NULL)</span><br><span class=\"line\">    return NULL; /* Pass error back */</span><br><span class=\"line\">/* Here maybe use the result */</span><br><span class=\"line\">Py_DECREF(result);</span><br></pre></td></tr></table></figure>\n<p> <code>PyObject_Call()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyObject *dict;</span><br><span class=\"line\">...</span><br><span class=\"line\">dict = Py_BuildValue(&quot;&#123;s:i&#125;&quot;, &quot;name&quot;, val);</span><br><span class=\"line\">result = PyObject_Call(my_callback, NULL, dict);</span><br><span class=\"line\">Py_DECREF(dict);</span><br><span class=\"line\">if (result == NULL)</span><br><span class=\"line\">    return NULL; /* Pass error back */</span><br><span class=\"line\">/* Here maybe use the result */</span><br><span class=\"line\">Py_DECREF(result);</span><br></pre></td></tr></table></figure></p>"},{"title":"python C/C++ Extension","date":"2021-06-16T06:09:08.000Z","p":"python/ext2","_content":"\npython  C/C++ \n<!-- more -->\n# \nC/C++ Python  0\n\n `free()`  C \n\n## Python \n`Py_INCREF(x)`  `Py_DECREF(x)`  0 `Py_DECREF(x)` \n\n `Py_DECREF()` 1. 2. 3.  `Py_DECREF()`\n\n `Py_INCREF()`\n\n## \n `PyLong_FromLong()`  `Py_BuildValue()`\n\n `Py_INCREF()`\n\npython  C C  C \n\n#  C API\n Python  `list`  C \n\nC  static  Python \n\n `static`Python  C level Python  `void *`  C API  Python \n\n C API \n```\nmodulename.attributename\n```\n\n\n```CPP\nstatic int\nPySpam_System(const char *command)\n{\n    return system(command);\n}\n\nstatic PyObject *\nspam_system(PyObject *self, PyObject *args)\n{\n    const char *command;\n    int sts;\n\n    if (!PyArg_ParseTuple(args, \"s\", &command))\n        return NULL;\n    sts = PySpam_System(command);\n    return PyLong_FromLong(sts);\n}\n```\n\n `#include <Python.h>`  \n```\n#define SPAM_MODULE\n#include \"spammodule.h\"\n```\n\n```CPP\nPyMODINIT_FUNC\nPyInit_spam(void)\n{\n    PyObject *m;\n    static void *PySpam_API[PySpam_API_pointers];\n    PyObject *c_api_object;\n\n    m = PyModule_Create(&spammodule);\n    if (m == NULL)\n        return NULL;\n\n    /* Initialize the C API pointer array */\n    PySpam_API[PySpam_System_NUM] = (void *)PySpam_System;\n\n    /* Create a Capsule containing the API pointer array's address */\n    c_api_object = PyCapsule_New((void *)PySpam_API, \"spam._C_API\", NULL);\n\n    if (PyModule_AddObject(m, \"_C_API\", c_api_object) < 0) {\n        Py_XDECREF(c_api_object);\n        Py_DECREF(m);\n        return NULL;\n    }\n\n    return m;\n}\n```\n\n`spammodule.h` \n```cpp\n#ifndef Py_SPAMMODULE_H\n#define Py_SPAMMODULE_H\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n/* Header file for spammodule */\n\n/* C API functions */\n#define PySpam_System_NUM 0\n#define PySpam_System_RETURN int\n#define PySpam_System_PROTO (const char *command)\n\n/* Total number of C API pointers */\n#define PySpam_API_pointers 1\n\n\n#ifdef SPAM_MODULE\n/* This section is used when compiling spammodule.c */\n\nstatic PySpam_System_RETURN PySpam_System PySpam_System_PROTO;\n\n#else\n/* This section is used in modules that use spammodule's API */\n\nstatic void **PySpam_API;\n\n#define PySpam_System \\\n (*(PySpam_System_RETURN (*)PySpam_System_PROTO) PySpam_API[PySpam_System_NUM])\n\n/* Return -1 on error, 0 on success.\n * PyCapsule_Import will set an exception if there's an error.\n */\nstatic int\nimport_spam(void)\n{\n    PySpam_API = (void **)PyCapsule_Import(\"spam._C_API\", 0);\n    return (PySpam_API != NULL) ? 0 : -1;\n}\n\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* !defined(Py_SPAMMODULE_H) */\n```\n\n\n```CPP\nPyMODINIT_FUNC\nPyInit_client(void)\n{\n    PyObject *m;\n\n    m = PyModule_Create(&clientmodule);\n    if (m == NULL)\n        return NULL;\n    if (import_spam() < 0)\n        return NULL;\n    /* additional initialization can happen here */\n    return m;\n}\n```","source":"_posts/python/ext2.md","raw":"---\ntitle: python C/C++ Extension\ndate: 2021-06-16 14:09:08\ntags:\np: python/ext2\n---\n\npython  C/C++ \n<!-- more -->\n# \nC/C++ Python  0\n\n `free()`  C \n\n## Python \n`Py_INCREF(x)`  `Py_DECREF(x)`  0 `Py_DECREF(x)` \n\n `Py_DECREF()` 1. 2. 3.  `Py_DECREF()`\n\n `Py_INCREF()`\n\n## \n `PyLong_FromLong()`  `Py_BuildValue()`\n\n `Py_INCREF()`\n\npython  C C  C \n\n#  C API\n Python  `list`  C \n\nC  static  Python \n\n `static`Python  C level Python  `void *`  C API  Python \n\n C API \n```\nmodulename.attributename\n```\n\n\n```CPP\nstatic int\nPySpam_System(const char *command)\n{\n    return system(command);\n}\n\nstatic PyObject *\nspam_system(PyObject *self, PyObject *args)\n{\n    const char *command;\n    int sts;\n\n    if (!PyArg_ParseTuple(args, \"s\", &command))\n        return NULL;\n    sts = PySpam_System(command);\n    return PyLong_FromLong(sts);\n}\n```\n\n `#include <Python.h>`  \n```\n#define SPAM_MODULE\n#include \"spammodule.h\"\n```\n\n```CPP\nPyMODINIT_FUNC\nPyInit_spam(void)\n{\n    PyObject *m;\n    static void *PySpam_API[PySpam_API_pointers];\n    PyObject *c_api_object;\n\n    m = PyModule_Create(&spammodule);\n    if (m == NULL)\n        return NULL;\n\n    /* Initialize the C API pointer array */\n    PySpam_API[PySpam_System_NUM] = (void *)PySpam_System;\n\n    /* Create a Capsule containing the API pointer array's address */\n    c_api_object = PyCapsule_New((void *)PySpam_API, \"spam._C_API\", NULL);\n\n    if (PyModule_AddObject(m, \"_C_API\", c_api_object) < 0) {\n        Py_XDECREF(c_api_object);\n        Py_DECREF(m);\n        return NULL;\n    }\n\n    return m;\n}\n```\n\n`spammodule.h` \n```cpp\n#ifndef Py_SPAMMODULE_H\n#define Py_SPAMMODULE_H\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n/* Header file for spammodule */\n\n/* C API functions */\n#define PySpam_System_NUM 0\n#define PySpam_System_RETURN int\n#define PySpam_System_PROTO (const char *command)\n\n/* Total number of C API pointers */\n#define PySpam_API_pointers 1\n\n\n#ifdef SPAM_MODULE\n/* This section is used when compiling spammodule.c */\n\nstatic PySpam_System_RETURN PySpam_System PySpam_System_PROTO;\n\n#else\n/* This section is used in modules that use spammodule's API */\n\nstatic void **PySpam_API;\n\n#define PySpam_System \\\n (*(PySpam_System_RETURN (*)PySpam_System_PROTO) PySpam_API[PySpam_System_NUM])\n\n/* Return -1 on error, 0 on success.\n * PyCapsule_Import will set an exception if there's an error.\n */\nstatic int\nimport_spam(void)\n{\n    PySpam_API = (void **)PyCapsule_Import(\"spam._C_API\", 0);\n    return (PySpam_API != NULL) ? 0 : -1;\n}\n\n#endif\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* !defined(Py_SPAMMODULE_H) */\n```\n\n\n```CPP\nPyMODINIT_FUNC\nPyInit_client(void)\n{\n    PyObject *m;\n\n    m = PyModule_Create(&clientmodule);\n    if (m == NULL)\n        return NULL;\n    if (import_spam() < 0)\n        return NULL;\n    /* additional initialization can happen here */\n    return m;\n}\n```","slug":"python/ext2","published":1,"updated":"2021-09-15T02:05:58.273Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91i0037p0dj8i7r5lq6","content":"<p>python  C/C++ <br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>C/C++ Python  0</p>\n<p> <code>free()</code>  C </p>\n<h2 id=\"Python-\"><a href=\"#Python-\" class=\"headerlink\" title=\"Python \"></a>Python </h2><p><code>Py_INCREF(x)</code>  <code>Py_DECREF(x)</code>  0 <code>Py_DECREF(x)</code> </p>\n<p> <code>Py_DECREF()</code> 1. 2. 3.  <code>Py_DECREF()</code></p>\n<p> <code>Py_INCREF()</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>PyLong_FromLong()</code>  <code>Py_BuildValue()</code></p>\n<p> <code>Py_INCREF()</code></p>\n<p>python  C C  C </p>\n<h1 id=\"-C-API\"><a href=\"#-C-API\" class=\"headerlink\" title=\" C API\"></a> C API</h1><p> Python  <code>list</code>  C </p>\n<p>C  static  Python </p>\n<p> <code>static</code>Python  C level Python  <code>void *</code>  C API  Python </p>\n<p> C API <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">modulename.attributename</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PySpam_System</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">system</span>(command);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">spam_system</span><span class=\"params\">(PyObject *self, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> sts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;s&quot;</span>, &amp;command))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    sts = <span class=\"built_in\">PySpam_System</span>(command);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyLong_FromLong</span>(sts);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> <code>#include &lt;Python.h&gt;</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define SPAM_MODULE</span><br><span class=\"line\">#include &quot;spammodule.h&quot;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> *PySpam_API[PySpam_API_pointers];</span><br><span class=\"line\">    PyObject *c_api_object;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;spammodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Initialize the C API pointer array */</span></span><br><span class=\"line\">    PySpam_API[PySpam_System_NUM] = (<span class=\"keyword\">void</span> *)PySpam_System;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Create a Capsule containing the API pointer array&#x27;s address */</span></span><br><span class=\"line\">    c_api_object = <span class=\"built_in\">PyCapsule_New</span>((<span class=\"keyword\">void</span> *)PySpam_API, <span class=\"string\">&quot;spam._C_API&quot;</span>, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyModule_AddObject</span>(m, <span class=\"string\">&quot;_C_API&quot;</span>, c_api_object) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">Py_XDECREF</span>(c_api_object);</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(m);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><code>spammodule.h</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> Py_SPAMMODULE_H</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> Py_SPAMMODULE_H</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"string\">&quot;C&quot;</span> &#123;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Header file for spammodule */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* C API functions */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System_NUM 0</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System_RETURN int</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System_PROTO (const char *command)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Total number of C API pointers */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_API_pointers 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> SPAM_MODULE</span></span><br><span class=\"line\"><span class=\"comment\">/* This section is used when compiling spammodule.c */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PySpam_System_RETURN PySpam_System PySpam_System_PROTO;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></span><br><span class=\"line\"><span class=\"comment\">/* This section is used in modules that use spammodule&#x27;s API */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> **PySpam_API;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System \\</span></span><br><span class=\"line\"><span class=\"meta\"> (*(PySpam_System_RETURN (*)PySpam_System_PROTO) PySpam_API[PySpam_System_NUM])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Return -1 on error, 0 on success.</span></span><br><span class=\"line\"><span class=\"comment\"> * PyCapsule_Import will set an exception if there&#x27;s an error.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">import_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PySpam_API = (<span class=\"keyword\">void</span> **)<span class=\"built_in\">PyCapsule_Import</span>(<span class=\"string\">&quot;spam._C_API&quot;</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (PySpam_API != <span class=\"literal\">NULL</span>) ? <span class=\"number\">0</span> : <span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span> <span class=\"comment\">/* !defined(Py_SPAMMODULE_H) */</span></span></span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_client</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;clientmodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">import_spam</span>() &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">/* additional initialization can happen here */</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p>python  C/C++ <br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>C/C++ Python  0</p>\n<p> <code>free()</code>  C </p>\n<h2 id=\"Python-\"><a href=\"#Python-\" class=\"headerlink\" title=\"Python \"></a>Python </h2><p><code>Py_INCREF(x)</code>  <code>Py_DECREF(x)</code>  0 <code>Py_DECREF(x)</code> </p>\n<p> <code>Py_DECREF()</code> 1. 2. 3.  <code>Py_DECREF()</code></p>\n<p> <code>Py_INCREF()</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>PyLong_FromLong()</code>  <code>Py_BuildValue()</code></p>\n<p> <code>Py_INCREF()</code></p>\n<p>python  C C  C </p>\n<h1 id=\"-C-API\"><a href=\"#-C-API\" class=\"headerlink\" title=\" C API\"></a> C API</h1><p> Python  <code>list</code>  C </p>\n<p>C  static  Python </p>\n<p> <code>static</code>Python  C level Python  <code>void *</code>  C API  Python </p>\n<p> C API <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">modulename.attributename</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PySpam_System</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">system</span>(command);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">spam_system</span><span class=\"params\">(PyObject *self, PyObject *args)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *command;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> sts;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"built_in\">PyArg_ParseTuple</span>(args, <span class=\"string\">&quot;s&quot;</span>, &amp;command))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    sts = <span class=\"built_in\">PySpam_System</span>(command);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">PyLong_FromLong</span>(sts);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> <code>#include &lt;Python.h&gt;</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define SPAM_MODULE</span><br><span class=\"line\">#include &quot;spammodule.h&quot;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> *PySpam_API[PySpam_API_pointers];</span><br><span class=\"line\">    PyObject *c_api_object;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;spammodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Initialize the C API pointer array */</span></span><br><span class=\"line\">    PySpam_API[PySpam_System_NUM] = (<span class=\"keyword\">void</span> *)PySpam_System;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Create a Capsule containing the API pointer array&#x27;s address */</span></span><br><span class=\"line\">    c_api_object = <span class=\"built_in\">PyCapsule_New</span>((<span class=\"keyword\">void</span> *)PySpam_API, <span class=\"string\">&quot;spam._C_API&quot;</span>, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyModule_AddObject</span>(m, <span class=\"string\">&quot;_C_API&quot;</span>, c_api_object) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">Py_XDECREF</span>(c_api_object);</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(m);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><code>spammodule.h</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> Py_SPAMMODULE_H</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> Py_SPAMMODULE_H</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"string\">&quot;C&quot;</span> &#123;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Header file for spammodule */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* C API functions */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System_NUM 0</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System_RETURN int</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System_PROTO (const char *command)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Total number of C API pointers */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_API_pointers 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> SPAM_MODULE</span></span><br><span class=\"line\"><span class=\"comment\">/* This section is used when compiling spammodule.c */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PySpam_System_RETURN PySpam_System PySpam_System_PROTO;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></span><br><span class=\"line\"><span class=\"comment\">/* This section is used in modules that use spammodule&#x27;s API */</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> **PySpam_API;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PySpam_System \\</span></span><br><span class=\"line\"><span class=\"meta\"> (*(PySpam_System_RETURN (*)PySpam_System_PROTO) PySpam_API[PySpam_System_NUM])</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/* Return -1 on error, 0 on success.</span></span><br><span class=\"line\"><span class=\"comment\"> * PyCapsule_Import will set an exception if there&#x27;s an error.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">int</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">import_spam</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PySpam_API = (<span class=\"keyword\">void</span> **)<span class=\"built_in\">PyCapsule_Import</span>(<span class=\"string\">&quot;spam._C_API&quot;</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (PySpam_API != <span class=\"literal\">NULL</span>) ? <span class=\"number\">0</span> : <span class=\"number\">-1</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> __cplusplus</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span> <span class=\"comment\">/* !defined(Py_SPAMMODULE_H) */</span></span></span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_client</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;clientmodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">import_spam</span>() &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">/* additional initialization can happen here */</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>"},{"title":"python C/C++ Extension Type","date":"2021-06-16T10:23:47.000Z","p":"python/ext3","_content":"\npython  C/C++ \n<!-- more -->\n Python  `PyObject*` `PyObject`     Python   Python  \n\n```cpp\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n\ntypedef struct {\n    PyObject_HEAD\n    /* Type-specific fields go here. */\n} CustomObject;\n\nstatic PyTypeObject CustomType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    .tp_name = \"custom.Custom\",\n    .tp_doc = \"Custom objects\",\n    .tp_basicsize = sizeof(CustomObject),\n    .tp_itemsize = 0,\n    .tp_flags = Py_TPFLAGS_DEFAULT,\n    .tp_new = PyType_GenericNew,\n};\n\nstatic PyModuleDef custommodule = {\n    PyModuleDef_HEAD_INIT,\n    .m_name = \"custom\",\n    .m_doc = \"Example module that creates an extension type.\",\n    .m_size = -1,\n};\n\nPyMODINIT_FUNC\nPyInit_custom(void)\n{\n    PyObject *m;\n    if (PyType_Ready(&CustomType) < 0)\n        return NULL;\n\n    m = PyModule_Create(&custommodule);\n    if (m == NULL)\n        return NULL;\n\n    Py_INCREF(&CustomType);\n    if (PyModule_AddObject(m, \"Custom\", (PyObject *) &CustomType) < 0) {\n        Py_DECREF(&CustomType);\n        Py_DECREF(m);\n        return NULL;\n    }\n\n    return m;\n}\n```\n\n`CustomObject` `PyObject_HEAD`  `ob_base`  `PyObject` `ob_type`  `ob_refcnt` `Py_TYPE`  `Py_REFCNT` `PyObject_HEAD` \n```cpp\ntypedef struct {\n    PyObject_HEAD\n    double ob_fval;\n} PyFloatObject;\n```\n\n\n```cpp\nstatic PyTypeObject CustomType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    .tp_name = \"custom.Custom\",\n    .tp_doc = \"Custom objects\",\n    .tp_basicsize = sizeof(CustomObject),\n    .tp_itemsize = 0,\n    .tp_flags = Py_TPFLAGS_DEFAULT,\n    .tp_new = PyType_GenericNew,\n};\n```\n C99  `PyTypeObject`  `0` C99 \n```cpp\nstatic PyTypeObject CustomType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    \"custom.Custom\",\n    \"Custom objects\",\n    sizeof(CustomObject),\n    0,\n    ...\n    Py_TPFLAGS_DEFAULT,\n    PyType_GenericNew,\n    ...\n};\n```\n\n```\nPyVarObject_HEAD_INIT(NULL, 0)\n```\n `ob_base`\n```\n#define PyVarObject_HEAD_INIT(type, size) 1, type, size,\n```\n\n```\n.tp_name = \"custom.Custom\", # \n.tp_basicsize = sizeof(CustomObject),   # \n.tp_itemsize = 0,   #  boolint0\n```\n\n```\n.tp_new = PyType_GenericNew,\n```\n `tp_new`  `__new__()``PyType_GenericNew` \n\n## \n[](https://docs.python.org/3.9/extending/newtypes_tutorial.html)\n\n\n# \n Python   0 \n```python\n>>> l = []\n>>> l.append(l)\n>>> del l\n```\n `l`  0 Python \n\n","source":"_posts/python/ext3.md","raw":"---\ntitle: python C/C++ Extension Type\ndate: 2021-06-16 18:23:47\ntags:\np: python/ext3\n---\n\npython  C/C++ \n<!-- more -->\n Python  `PyObject*` `PyObject`     Python   Python  \n\n```cpp\n#define PY_SSIZE_T_CLEAN\n#include <Python.h>\n\ntypedef struct {\n    PyObject_HEAD\n    /* Type-specific fields go here. */\n} CustomObject;\n\nstatic PyTypeObject CustomType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    .tp_name = \"custom.Custom\",\n    .tp_doc = \"Custom objects\",\n    .tp_basicsize = sizeof(CustomObject),\n    .tp_itemsize = 0,\n    .tp_flags = Py_TPFLAGS_DEFAULT,\n    .tp_new = PyType_GenericNew,\n};\n\nstatic PyModuleDef custommodule = {\n    PyModuleDef_HEAD_INIT,\n    .m_name = \"custom\",\n    .m_doc = \"Example module that creates an extension type.\",\n    .m_size = -1,\n};\n\nPyMODINIT_FUNC\nPyInit_custom(void)\n{\n    PyObject *m;\n    if (PyType_Ready(&CustomType) < 0)\n        return NULL;\n\n    m = PyModule_Create(&custommodule);\n    if (m == NULL)\n        return NULL;\n\n    Py_INCREF(&CustomType);\n    if (PyModule_AddObject(m, \"Custom\", (PyObject *) &CustomType) < 0) {\n        Py_DECREF(&CustomType);\n        Py_DECREF(m);\n        return NULL;\n    }\n\n    return m;\n}\n```\n\n`CustomObject` `PyObject_HEAD`  `ob_base`  `PyObject` `ob_type`  `ob_refcnt` `Py_TYPE`  `Py_REFCNT` `PyObject_HEAD` \n```cpp\ntypedef struct {\n    PyObject_HEAD\n    double ob_fval;\n} PyFloatObject;\n```\n\n\n```cpp\nstatic PyTypeObject CustomType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    .tp_name = \"custom.Custom\",\n    .tp_doc = \"Custom objects\",\n    .tp_basicsize = sizeof(CustomObject),\n    .tp_itemsize = 0,\n    .tp_flags = Py_TPFLAGS_DEFAULT,\n    .tp_new = PyType_GenericNew,\n};\n```\n C99  `PyTypeObject`  `0` C99 \n```cpp\nstatic PyTypeObject CustomType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    \"custom.Custom\",\n    \"Custom objects\",\n    sizeof(CustomObject),\n    0,\n    ...\n    Py_TPFLAGS_DEFAULT,\n    PyType_GenericNew,\n    ...\n};\n```\n\n```\nPyVarObject_HEAD_INIT(NULL, 0)\n```\n `ob_base`\n```\n#define PyVarObject_HEAD_INIT(type, size) 1, type, size,\n```\n\n```\n.tp_name = \"custom.Custom\", # \n.tp_basicsize = sizeof(CustomObject),   # \n.tp_itemsize = 0,   #  boolint0\n```\n\n```\n.tp_new = PyType_GenericNew,\n```\n `tp_new`  `__new__()``PyType_GenericNew` \n\n## \n[](https://docs.python.org/3.9/extending/newtypes_tutorial.html)\n\n\n# \n Python   0 \n```python\n>>> l = []\n>>> l.append(l)\n>>> del l\n```\n `l`  0 Python \n\n","slug":"python/ext3","published":1,"updated":"2021-09-15T02:06:21.724Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91j0039p0dj7e2z2efr","content":"<p>python  C/C++ <br><span id=\"more\"></span><br> Python  <code>PyObject*</code> <code>PyObject</code>     Python   Python  </p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PY_SSIZE_T_CLEAN</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;Python.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">    PyObject_HEAD</span><br><span class=\"line\">    <span class=\"comment\">/* Type-specific fields go here. */</span></span><br><span class=\"line\">&#125; CustomObject;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PyTypeObject CustomType = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">PyVarObject_HEAD_INIT</span>(<span class=\"literal\">NULL</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    .tp_name = <span class=\"string\">&quot;custom.Custom&quot;</span>,</span><br><span class=\"line\">    .tp_doc = <span class=\"string\">&quot;Custom objects&quot;</span>,</span><br><span class=\"line\">    .tp_basicsize = <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(CustomObject),</span><br><span class=\"line\">    .tp_itemsize = <span class=\"number\">0</span>,</span><br><span class=\"line\">    .tp_flags = Py_TPFLAGS_DEFAULT,</span><br><span class=\"line\">    .tp_new = PyType_GenericNew,</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PyModuleDef custommodule = &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    .m_name = <span class=\"string\">&quot;custom&quot;</span>,</span><br><span class=\"line\">    .m_doc = <span class=\"string\">&quot;Example module that creates an extension type.&quot;</span>,</span><br><span class=\"line\">    .m_size = <span class=\"number\">-1</span>,</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_custom</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyType_Ready</span>(&amp;CustomType) &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;custommodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">Py_INCREF</span>(&amp;CustomType);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyModule_AddObject</span>(m, <span class=\"string\">&quot;Custom&quot;</span>, (PyObject *) &amp;CustomType) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(&amp;CustomType);</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(m);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><br><code>CustomObject</code> <code>PyObject_HEAD</code>  <code>ob_base</code>  <code>PyObject</code> <code>ob_type</code>  <code>ob_refcnt</code> <code>Py_TYPE</code>  <code>Py_REFCNT</code> <code>PyObject_HEAD</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">    PyObject_HEAD</span><br><span class=\"line\">    <span class=\"keyword\">double</span> ob_fval;</span><br><span class=\"line\">&#125; PyFloatObject;</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyTypeObject CustomType = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">PyVarObject_HEAD_INIT</span>(<span class=\"literal\">NULL</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    .tp_name = <span class=\"string\">&quot;custom.Custom&quot;</span>,</span><br><span class=\"line\">    .tp_doc = <span class=\"string\">&quot;Custom objects&quot;</span>,</span><br><span class=\"line\">    .tp_basicsize = <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(CustomObject),</span><br><span class=\"line\">    .tp_itemsize = <span class=\"number\">0</span>,</span><br><span class=\"line\">    .tp_flags = Py_TPFLAGS_DEFAULT,</span><br><span class=\"line\">    .tp_new = PyType_GenericNew,</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> C99  <code>PyTypeObject</code>  <code>0</code> C99 <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyTypeObject CustomType = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">PyVarObject_HEAD_INIT</span>(<span class=\"literal\">NULL</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"string\">&quot;custom.Custom&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;Custom objects&quot;</span>,</span><br><span class=\"line\">    <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(CustomObject),</span><br><span class=\"line\">    <span class=\"number\">0</span>,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    Py_TPFLAGS_DEFAULT,</span><br><span class=\"line\">    PyType_GenericNew,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyVarObject_HEAD_INIT(NULL, 0)</span><br></pre></td></tr></table></figure><br> <code>ob_base</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define PyVarObject_HEAD_INIT(type, size) 1, type, size,</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.tp_name = &quot;custom.Custom&quot;, # </span><br><span class=\"line\">.tp_basicsize = sizeof(CustomObject),   # </span><br><span class=\"line\">.tp_itemsize = 0,   #  boolint0</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.tp_new = PyType_GenericNew,</span><br></pre></td></tr></table></figure>\n<p> <code>tp_new</code>  <code>__new__()</code><code>PyType_GenericNew</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://docs.python.org/3.9/extending/newtypes_tutorial.html\"></a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Python   0 <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>l = []</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>l.append(l)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">del</span> l</span><br></pre></td></tr></table></figure><br> <code>l</code>  0 Python </p>\n","site":{"data":{}},"excerpt":"<p>python  C/C++ <br>","more":"<br> Python  <code>PyObject*</code> <code>PyObject</code>     Python   Python  </p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PY_SSIZE_T_CLEAN</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;Python.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">    PyObject_HEAD</span><br><span class=\"line\">    <span class=\"comment\">/* Type-specific fields go here. */</span></span><br><span class=\"line\">&#125; CustomObject;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PyTypeObject CustomType = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">PyVarObject_HEAD_INIT</span>(<span class=\"literal\">NULL</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    .tp_name = <span class=\"string\">&quot;custom.Custom&quot;</span>,</span><br><span class=\"line\">    .tp_doc = <span class=\"string\">&quot;Custom objects&quot;</span>,</span><br><span class=\"line\">    .tp_basicsize = <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(CustomObject),</span><br><span class=\"line\">    .tp_itemsize = <span class=\"number\">0</span>,</span><br><span class=\"line\">    .tp_flags = Py_TPFLAGS_DEFAULT,</span><br><span class=\"line\">    .tp_new = PyType_GenericNew,</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">static</span> PyModuleDef custommodule = &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    .m_name = <span class=\"string\">&quot;custom&quot;</span>,</span><br><span class=\"line\">    .m_doc = <span class=\"string\">&quot;Example module that creates an extension type.&quot;</span>,</span><br><span class=\"line\">    .m_size = <span class=\"number\">-1</span>,</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">PyMODINIT_FUNC</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">PyInit_custom</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    PyObject *m;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyType_Ready</span>(&amp;CustomType) &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    m = <span class=\"built_in\">PyModule_Create</span>(&amp;custommodule);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m == <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">Py_INCREF</span>(&amp;CustomType);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">PyModule_AddObject</span>(m, <span class=\"string\">&quot;Custom&quot;</span>, (PyObject *) &amp;CustomType) &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(&amp;CustomType);</span><br><span class=\"line\">        <span class=\"built_in\">Py_DECREF</span>(m);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><br><code>CustomObject</code> <code>PyObject_HEAD</code>  <code>ob_base</code>  <code>PyObject</code> <code>ob_type</code>  <code>ob_refcnt</code> <code>Py_TYPE</code>  <code>Py_REFCNT</code> <code>PyObject_HEAD</code> <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">    PyObject_HEAD</span><br><span class=\"line\">    <span class=\"keyword\">double</span> ob_fval;</span><br><span class=\"line\">&#125; PyFloatObject;</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyTypeObject CustomType = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">PyVarObject_HEAD_INIT</span>(<span class=\"literal\">NULL</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    .tp_name = <span class=\"string\">&quot;custom.Custom&quot;</span>,</span><br><span class=\"line\">    .tp_doc = <span class=\"string\">&quot;Custom objects&quot;</span>,</span><br><span class=\"line\">    .tp_basicsize = <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(CustomObject),</span><br><span class=\"line\">    .tp_itemsize = <span class=\"number\">0</span>,</span><br><span class=\"line\">    .tp_flags = Py_TPFLAGS_DEFAULT,</span><br><span class=\"line\">    .tp_new = PyType_GenericNew,</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> C99  <code>PyTypeObject</code>  <code>0</code> C99 <br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> PyTypeObject CustomType = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">PyVarObject_HEAD_INIT</span>(<span class=\"literal\">NULL</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"string\">&quot;custom.Custom&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;Custom objects&quot;</span>,</span><br><span class=\"line\">    <span class=\"built_in\"><span class=\"keyword\">sizeof</span></span>(CustomObject),</span><br><span class=\"line\">    <span class=\"number\">0</span>,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    Py_TPFLAGS_DEFAULT,</span><br><span class=\"line\">    PyType_GenericNew,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyVarObject_HEAD_INIT(NULL, 0)</span><br></pre></td></tr></table></figure><br> <code>ob_base</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define PyVarObject_HEAD_INIT(type, size) 1, type, size,</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.tp_name = &quot;custom.Custom&quot;, # </span><br><span class=\"line\">.tp_basicsize = sizeof(CustomObject),   # </span><br><span class=\"line\">.tp_itemsize = 0,   #  boolint0</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.tp_new = PyType_GenericNew,</span><br></pre></td></tr></table></figure>\n<p> <code>tp_new</code>  <code>__new__()</code><code>PyType_GenericNew</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://docs.python.org/3.9/extending/newtypes_tutorial.html\"></a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Python   0 <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>l = []</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>l.append(l)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">del</span> l</span><br></pre></td></tr></table></figure><br> <code>l</code>  0 Python </p>"},{"title":"python setup","date":"2021-06-12T09:03:32.000Z","p":"python/setup","_content":"\npython  setup \n<!-- more -->\n\n python setup.py  setup \n\n\n```\nfrom distutils.core import setup\n\nsetup(name='Distutils',\n      version='1.0',\n      description='Python Distribution Utilities',\n      author='Greg Ward',\n      author_email='gward@python.net',\n      url='https://www.python.org/sigs/distutils-sig/',\n      packages=['distutils', 'distutils.command'],\n     )\n```\n\n\n\n## packages\npackages  python  `distutils`  root  `distutils` root  `setup.py`  `packages=['foo']` root  `foo/__init__.py` \n\n `package_dir` \n\n## package_dir\n python  root  `lib`  \"root package\"  `lib`  `foo`  `lib/foo`\n```\npackage_dir = {'': 'lib'}\n```\nkey empty string  \"root package\"value  setup.py  `packages=['foo']` `lib/foo/__init__.py` \n\n `package_dir = {'foo': 'lib'}` `foo`  root  `foo`  `lib`  `lib/__init__.py` package_dir  `foo.bar`  `lib/bar` `lib/bar/__init__.py` \n\n`packages` \n\n## py_modules\n\n```\npy_modules = ['mod1', 'pkg.mod2']\n```\n `pkg`  `pkg/__init__.py` \n\n `package_dir`   -  \n\n## ext_modules\n\n python   python     python flags \n\next_modules  `Extension`  `Extension` \n```\nExtension('foo', ['foo.c'])\n```\n `foo` `foo.c`\n\n### \n`Extension` \n```\nExtension('foo', ['src/foo1.c', 'src/foo2.c'])\n```\n `foo`  root package \n```\nExtension('pkg.foo', ['src/foo1.c', 'src/foo2.c'])\n```\n `pkg` \n\n### \n`Extension`  C/C++/Objective-C SWIG  (`.i` )\n\n### \n`Extension` 1. `include_dirs`2. `define_macros`3. `undef_macros`\n\n root  `include` \n```\nExtension('foo', ['foo.c'], include_dirs=['include'])\n```\n\n\n\n python Python  python  \n```\n~/tool/miniconda3/include/python3.8\n```\n `include_dirs` \n\n sysconfig \n\n`define_macros`  `(name, value)`  `name` `value`  `None` `value`  `None`  C  `#define FOO` `FOO`  `1` \n\n`undef_macros` \n```\nExtension(...,\n          define_macros=[('NDEBUG', '1'),\n                         ('HAVE_STRFTIME', None)],\n          undef_macros=['HAVE_FOO', 'HAVE_BAR'])\n```\n\n C \n```\n#define NDEBUG 1\n#define HAVE_STRFTIME\n#undef HAVE_FOO\n#undef HAVE_BAR\n```\n\n### \n`Extension`  `libraries` `library_dirs` `runtime_library_dirs`\n\n### \n\n`Extension` \n\n1. `optional` bool  true \n\n2. `extra_objects` \n\n3. `extra_compile_args` `extra_link_args` \n\n4. `export_symbols` Windows \n\n5. `depends` \n\n `Extension` \n\n## \n //  `distutils.core.setup()` \n\n python /  `setup()`  `requires`  version version  `mymodule`  `xml.parsers.expat` `,` \n```\n<   >   ==\n<=  >=  !=\n```\n\n|| |\n|--|--|\n|==1.0|  1.0 |\n|>1.0, !=1.5.1, <2.0| 1.0  2.0  1.5.1 |\n\n/`setup()`  `provides`  python \n|||\n|--|--|\n|mypkg|  `mypkg`|\n|mypkg (1.1)|  `mypkg` 1.1|\n\n `obsoletes` / `requires`  /  `()` \n\n## \n\n python \n\n python `scripts`  `PATH` \n```\nsetup(...,\n      scripts=['scripts/xmlproc_parse', 'scripts/xmlproc_val']\n      )\n```\n root `PATH` \n```\n$ xmlproc_parse\n...\n\n$ xmlproc_val\n...\n```\n\n## \n \n\n `package_data`    `package_dir` \n\n\n```\nsetup.py\nsrc/\n    mypkg/\n        __init__.py\n        module.py\n        data/\n            tables.dat\n            spoons.dat\n            forks.dat\n```\n\n`setup()` \n```\n setup(...,\n      packages=['mypkg'],\n      package_dir={'mypkg': 'src/mypkg'},\n      package_data={'mypkg': ['data/*.dat']},\n      )\n```\n\n## \n `data_files`  `(directory, files)` \n```\nsetup(...,\n      data_files=[('bitmaps', ['bm/b1.gif', 'bm/b2.gif']),\n                  ('config', ['cfg/data.cfg'])],\n     )\n```\n\n`files`  `setup.py` \n\n`directory`  prefix `sys.prefix` `site.USER_BASE` `directory`  wheel ","source":"_posts/python/setup.md","raw":"---\ntitle: python setup\ndate: 2021-06-12 17:03:32\ntags: cmake, C++\np: python/setup\n---\n\npython  setup \n<!-- more -->\n\n python setup.py  setup \n\n\n```\nfrom distutils.core import setup\n\nsetup(name='Distutils',\n      version='1.0',\n      description='Python Distribution Utilities',\n      author='Greg Ward',\n      author_email='gward@python.net',\n      url='https://www.python.org/sigs/distutils-sig/',\n      packages=['distutils', 'distutils.command'],\n     )\n```\n\n\n\n## packages\npackages  python  `distutils`  root  `distutils` root  `setup.py`  `packages=['foo']` root  `foo/__init__.py` \n\n `package_dir` \n\n## package_dir\n python  root  `lib`  \"root package\"  `lib`  `foo`  `lib/foo`\n```\npackage_dir = {'': 'lib'}\n```\nkey empty string  \"root package\"value  setup.py  `packages=['foo']` `lib/foo/__init__.py` \n\n `package_dir = {'foo': 'lib'}` `foo`  root  `foo`  `lib`  `lib/__init__.py` package_dir  `foo.bar`  `lib/bar` `lib/bar/__init__.py` \n\n`packages` \n\n## py_modules\n\n```\npy_modules = ['mod1', 'pkg.mod2']\n```\n `pkg`  `pkg/__init__.py` \n\n `package_dir`   -  \n\n## ext_modules\n\n python   python     python flags \n\next_modules  `Extension`  `Extension` \n```\nExtension('foo', ['foo.c'])\n```\n `foo` `foo.c`\n\n### \n`Extension` \n```\nExtension('foo', ['src/foo1.c', 'src/foo2.c'])\n```\n `foo`  root package \n```\nExtension('pkg.foo', ['src/foo1.c', 'src/foo2.c'])\n```\n `pkg` \n\n### \n`Extension`  C/C++/Objective-C SWIG  (`.i` )\n\n### \n`Extension` 1. `include_dirs`2. `define_macros`3. `undef_macros`\n\n root  `include` \n```\nExtension('foo', ['foo.c'], include_dirs=['include'])\n```\n\n\n\n python Python  python  \n```\n~/tool/miniconda3/include/python3.8\n```\n `include_dirs` \n\n sysconfig \n\n`define_macros`  `(name, value)`  `name` `value`  `None` `value`  `None`  C  `#define FOO` `FOO`  `1` \n\n`undef_macros` \n```\nExtension(...,\n          define_macros=[('NDEBUG', '1'),\n                         ('HAVE_STRFTIME', None)],\n          undef_macros=['HAVE_FOO', 'HAVE_BAR'])\n```\n\n C \n```\n#define NDEBUG 1\n#define HAVE_STRFTIME\n#undef HAVE_FOO\n#undef HAVE_BAR\n```\n\n### \n`Extension`  `libraries` `library_dirs` `runtime_library_dirs`\n\n### \n\n`Extension` \n\n1. `optional` bool  true \n\n2. `extra_objects` \n\n3. `extra_compile_args` `extra_link_args` \n\n4. `export_symbols` Windows \n\n5. `depends` \n\n `Extension` \n\n## \n //  `distutils.core.setup()` \n\n python /  `setup()`  `requires`  version version  `mymodule`  `xml.parsers.expat` `,` \n```\n<   >   ==\n<=  >=  !=\n```\n\n|| |\n|--|--|\n|==1.0|  1.0 |\n|>1.0, !=1.5.1, <2.0| 1.0  2.0  1.5.1 |\n\n/`setup()`  `provides`  python \n|||\n|--|--|\n|mypkg|  `mypkg`|\n|mypkg (1.1)|  `mypkg` 1.1|\n\n `obsoletes` / `requires`  /  `()` \n\n## \n\n python \n\n python `scripts`  `PATH` \n```\nsetup(...,\n      scripts=['scripts/xmlproc_parse', 'scripts/xmlproc_val']\n      )\n```\n root `PATH` \n```\n$ xmlproc_parse\n...\n\n$ xmlproc_val\n...\n```\n\n## \n \n\n `package_data`    `package_dir` \n\n\n```\nsetup.py\nsrc/\n    mypkg/\n        __init__.py\n        module.py\n        data/\n            tables.dat\n            spoons.dat\n            forks.dat\n```\n\n`setup()` \n```\n setup(...,\n      packages=['mypkg'],\n      package_dir={'mypkg': 'src/mypkg'},\n      package_data={'mypkg': ['data/*.dat']},\n      )\n```\n\n## \n `data_files`  `(directory, files)` \n```\nsetup(...,\n      data_files=[('bitmaps', ['bm/b1.gif', 'bm/b2.gif']),\n                  ('config', ['cfg/data.cfg'])],\n     )\n```\n\n`files`  `setup.py` \n\n`directory`  prefix `sys.prefix` `site.USER_BASE` `directory`  wheel ","slug":"python/setup","published":1,"updated":"2021-09-15T02:06:40.634Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91j003bp0djbglnclng","content":"<p>python  setup <br><span id=\"more\"></span></p>\n<p> python setup.py  setup </p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from distutils.core import setup</span><br><span class=\"line\"></span><br><span class=\"line\">setup(name=&#x27;Distutils&#x27;,</span><br><span class=\"line\">      version=&#x27;1.0&#x27;,</span><br><span class=\"line\">      description=&#x27;Python Distribution Utilities&#x27;,</span><br><span class=\"line\">      author=&#x27;Greg Ward&#x27;,</span><br><span class=\"line\">      author_email=&#x27;gward@python.net&#x27;,</span><br><span class=\"line\">      url=&#x27;https://www.python.org/sigs/distutils-sig/&#x27;,</span><br><span class=\"line\">      packages=[&#x27;distutils&#x27;, &#x27;distutils.command&#x27;],</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"packages\"><a href=\"#packages\" class=\"headerlink\" title=\"packages\"></a>packages</h2><p>packages  python  <code>distutils</code>  root  <code>distutils</code> root  <code>setup.py</code>  <code>packages=[&#39;foo&#39;]</code> root  <code>foo/__init__.py</code> </p>\n<p> <code>package_dir</code> </p>\n<h2 id=\"package-dir\"><a href=\"#package-dir\" class=\"headerlink\" title=\"package_dir\"></a>package_dir</h2><p> python  root  <code>lib</code>  root package  <code>lib</code>  <code>foo</code>  <code>lib/foo</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package_dir = &#123;&#x27;&#x27;: &#x27;lib&#x27;&#125;</span><br></pre></td></tr></table></figure><br>key empty string  root packagevalue  setup.py  <code>packages=[&#39;foo&#39;]</code> <code>lib/foo/__init__.py</code> </p>\n<p> <code>package_dir = &#123;&#39;foo&#39;: &#39;lib&#39;&#125;</code> <code>foo</code>  root  <code>foo</code>  <code>lib</code>  <code>lib/__init__.py</code> package_dir  <code>foo.bar</code>  <code>lib/bar</code> <code>lib/bar/__init__.py</code> </p>\n<p><code>packages</code> </p>\n<h2 id=\"py-modules\"><a href=\"#py-modules\" class=\"headerlink\" title=\"py_modules\"></a>py_modules</h2><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">py_modules = [&#x27;mod1&#x27;, &#x27;pkg.mod2&#x27;]</span><br></pre></td></tr></table></figure><br> <code>pkg</code>  <code>pkg/__init__.py</code> </p>\n<p> <code>package_dir</code>   -  </p>\n<h2 id=\"ext-modules\"><a href=\"#ext-modules\" class=\"headerlink\" title=\"ext_modules\"></a>ext_modules</h2><p> python   python     python flags </p>\n<p>ext_modules  <code>Extension</code>  <code>Extension</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;foo&#x27;, [&#x27;foo.c&#x27;])</span><br></pre></td></tr></table></figure><br> <code>foo</code> <code>foo.c</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;foo&#x27;, [&#x27;src/foo1.c&#x27;, &#x27;src/foo2.c&#x27;])</span><br></pre></td></tr></table></figure><br> <code>foo</code>  root package <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;pkg.foo&#x27;, [&#x27;src/foo1.c&#x27;, &#x27;src/foo2.c&#x27;])</span><br></pre></td></tr></table></figure><br> <code>pkg</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code>  C/C++/Objective-C SWIG  (<code>.i</code> )</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code> 1. <code>include_dirs</code>2. <code>define_macros</code>3. <code>undef_macros</code></p>\n<p> root  <code>include</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;foo&#x27;, [&#x27;foo.c&#x27;], include_dirs=[&#x27;include&#x27;])</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<p> python Python  python <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/tool/miniconda3/include/python3.8</span><br></pre></td></tr></table></figure><br> <code>include_dirs</code> </p>\n<p> sysconfig </p>\n<p><code>define_macros</code>  <code>(name, value)</code>  <code>name</code> <code>value</code>  <code>None</code> <code>value</code>  <code>None</code>  C  <code>#define FOO</code> <code>FOO</code>  <code>1</code> </p>\n<p><code>undef_macros</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(...,</span><br><span class=\"line\">          define_macros=[(&#x27;NDEBUG&#x27;, &#x27;1&#x27;),</span><br><span class=\"line\">                         (&#x27;HAVE_STRFTIME&#x27;, None)],</span><br><span class=\"line\">          undef_macros=[&#x27;HAVE_FOO&#x27;, &#x27;HAVE_BAR&#x27;])</span><br></pre></td></tr></table></figure></p>\n<p> C <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define NDEBUG 1</span><br><span class=\"line\">#define HAVE_STRFTIME</span><br><span class=\"line\">#undef HAVE_FOO</span><br><span class=\"line\">#undef HAVE_BAR</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code>  <code>libraries</code> <code>library_dirs</code> <code>runtime_library_dirs</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code> </p>\n<ol>\n<li><p><code>optional</code> bool  true </p>\n</li>\n<li><p><code>extra_objects</code> </p>\n</li>\n<li><p><code>extra_compile_args</code> <code>extra_link_args</code> </p>\n</li>\n<li><p><code>export_symbols</code> Windows </p>\n</li>\n<li><p><code>depends</code> </p>\n</li>\n</ol>\n<p> <code>Extension</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> //  <code>distutils.core.setup()</code> </p>\n<p> python /  <code>setup()</code>  <code>requires</code>  version version  <code>mymodule</code>  <code>xml.parsers.expat</code> <code>,</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;   &gt;   ==</span><br><span class=\"line\">&lt;=  &gt;=  !=</span><br></pre></td></tr></table></figure><br><br>|| |<br>|||<br>|==1.0|  1.0 |<br>|&gt;1.0, !=1.5.1, &lt;2.0| 1.0  2.0  1.5.1 |</p>\n<p>/<code>setup()</code>  <code>provides</code>  python <br>|||<br>|||<br>|mypkg|  <code>mypkg</code>|<br>|mypkg (1.1)|  <code>mypkg</code> 1.1|</p>\n<p> <code>obsoletes</code> / <code>requires</code>  /  <code>()</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> python </p>\n<p> python <code>scripts</code>  <code>PATH</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup(...,</span><br><span class=\"line\">      scripts=[&#x27;scripts/xmlproc_parse&#x27;, &#x27;scripts/xmlproc_val&#x27;]</span><br><span class=\"line\">      )</span><br></pre></td></tr></table></figure><br> root <code>PATH</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ xmlproc_parse</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">$ xmlproc_val</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> </p>\n<p> <code>package_data</code>    <code>package_dir</code> </p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup.py</span><br><span class=\"line\">src/</span><br><span class=\"line\">    mypkg/</span><br><span class=\"line\">        __init__.py</span><br><span class=\"line\">        module.py</span><br><span class=\"line\">        data/</span><br><span class=\"line\">            tables.dat</span><br><span class=\"line\">            spoons.dat</span><br><span class=\"line\">            forks.dat</span><br></pre></td></tr></table></figure></p>\n<p><code>setup()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup(...,</span><br><span class=\"line\">     packages=[&#x27;mypkg&#x27;],</span><br><span class=\"line\">     package_dir=&#123;&#x27;mypkg&#x27;: &#x27;src/mypkg&#x27;&#125;,</span><br><span class=\"line\">     package_data=&#123;&#x27;mypkg&#x27;: [&#x27;data/*.dat&#x27;]&#125;,</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>data_files</code>  <code>(directory, files)</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup(...,</span><br><span class=\"line\">      data_files=[(&#x27;bitmaps&#x27;, [&#x27;bm/b1.gif&#x27;, &#x27;bm/b2.gif&#x27;]),</span><br><span class=\"line\">                  (&#x27;config&#x27;, [&#x27;cfg/data.cfg&#x27;])],</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure></p>\n<p><code>files</code>  <code>setup.py</code> </p>\n<p><code>directory</code>  prefix <code>sys.prefix</code> <code>site.USER_BASE</code> <code>directory</code>  wheel </p>\n","site":{"data":{}},"excerpt":"<p>python  setup <br>","more":"</p>\n<p> python setup.py  setup </p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from distutils.core import setup</span><br><span class=\"line\"></span><br><span class=\"line\">setup(name=&#x27;Distutils&#x27;,</span><br><span class=\"line\">      version=&#x27;1.0&#x27;,</span><br><span class=\"line\">      description=&#x27;Python Distribution Utilities&#x27;,</span><br><span class=\"line\">      author=&#x27;Greg Ward&#x27;,</span><br><span class=\"line\">      author_email=&#x27;gward@python.net&#x27;,</span><br><span class=\"line\">      url=&#x27;https://www.python.org/sigs/distutils-sig/&#x27;,</span><br><span class=\"line\">      packages=[&#x27;distutils&#x27;, &#x27;distutils.command&#x27;],</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"packages\"><a href=\"#packages\" class=\"headerlink\" title=\"packages\"></a>packages</h2><p>packages  python  <code>distutils</code>  root  <code>distutils</code> root  <code>setup.py</code>  <code>packages=[&#39;foo&#39;]</code> root  <code>foo/__init__.py</code> </p>\n<p> <code>package_dir</code> </p>\n<h2 id=\"package-dir\"><a href=\"#package-dir\" class=\"headerlink\" title=\"package_dir\"></a>package_dir</h2><p> python  root  <code>lib</code>  root package  <code>lib</code>  <code>foo</code>  <code>lib/foo</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package_dir = &#123;&#x27;&#x27;: &#x27;lib&#x27;&#125;</span><br></pre></td></tr></table></figure><br>key empty string  root packagevalue  setup.py  <code>packages=[&#39;foo&#39;]</code> <code>lib/foo/__init__.py</code> </p>\n<p> <code>package_dir = &#123;&#39;foo&#39;: &#39;lib&#39;&#125;</code> <code>foo</code>  root  <code>foo</code>  <code>lib</code>  <code>lib/__init__.py</code> package_dir  <code>foo.bar</code>  <code>lib/bar</code> <code>lib/bar/__init__.py</code> </p>\n<p><code>packages</code> </p>\n<h2 id=\"py-modules\"><a href=\"#py-modules\" class=\"headerlink\" title=\"py_modules\"></a>py_modules</h2><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">py_modules = [&#x27;mod1&#x27;, &#x27;pkg.mod2&#x27;]</span><br></pre></td></tr></table></figure><br> <code>pkg</code>  <code>pkg/__init__.py</code> </p>\n<p> <code>package_dir</code>   -  </p>\n<h2 id=\"ext-modules\"><a href=\"#ext-modules\" class=\"headerlink\" title=\"ext_modules\"></a>ext_modules</h2><p> python   python     python flags </p>\n<p>ext_modules  <code>Extension</code>  <code>Extension</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;foo&#x27;, [&#x27;foo.c&#x27;])</span><br></pre></td></tr></table></figure><br> <code>foo</code> <code>foo.c</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;foo&#x27;, [&#x27;src/foo1.c&#x27;, &#x27;src/foo2.c&#x27;])</span><br></pre></td></tr></table></figure><br> <code>foo</code>  root package <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;pkg.foo&#x27;, [&#x27;src/foo1.c&#x27;, &#x27;src/foo2.c&#x27;])</span><br></pre></td></tr></table></figure><br> <code>pkg</code> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code>  C/C++/Objective-C SWIG  (<code>.i</code> )</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code> 1. <code>include_dirs</code>2. <code>define_macros</code>3. <code>undef_macros</code></p>\n<p> root  <code>include</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(&#x27;foo&#x27;, [&#x27;foo.c&#x27;], include_dirs=[&#x27;include&#x27;])</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<p> python Python  python <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/tool/miniconda3/include/python3.8</span><br></pre></td></tr></table></figure><br> <code>include_dirs</code> </p>\n<p> sysconfig </p>\n<p><code>define_macros</code>  <code>(name, value)</code>  <code>name</code> <code>value</code>  <code>None</code> <code>value</code>  <code>None</code>  C  <code>#define FOO</code> <code>FOO</code>  <code>1</code> </p>\n<p><code>undef_macros</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Extension(...,</span><br><span class=\"line\">          define_macros=[(&#x27;NDEBUG&#x27;, &#x27;1&#x27;),</span><br><span class=\"line\">                         (&#x27;HAVE_STRFTIME&#x27;, None)],</span><br><span class=\"line\">          undef_macros=[&#x27;HAVE_FOO&#x27;, &#x27;HAVE_BAR&#x27;])</span><br></pre></td></tr></table></figure></p>\n<p> C <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define NDEBUG 1</span><br><span class=\"line\">#define HAVE_STRFTIME</span><br><span class=\"line\">#undef HAVE_FOO</span><br><span class=\"line\">#undef HAVE_BAR</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code>  <code>libraries</code> <code>library_dirs</code> <code>runtime_library_dirs</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>Extension</code> </p>\n<ol>\n<li><p><code>optional</code> bool  true </p>\n</li>\n<li><p><code>extra_objects</code> </p>\n</li>\n<li><p><code>extra_compile_args</code> <code>extra_link_args</code> </p>\n</li>\n<li><p><code>export_symbols</code> Windows </p>\n</li>\n<li><p><code>depends</code> </p>\n</li>\n</ol>\n<p> <code>Extension</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> //  <code>distutils.core.setup()</code> </p>\n<p> python /  <code>setup()</code>  <code>requires</code>  version version  <code>mymodule</code>  <code>xml.parsers.expat</code> <code>,</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;   &gt;   ==</span><br><span class=\"line\">&lt;=  &gt;=  !=</span><br></pre></td></tr></table></figure><br><br>|| |<br>|||<br>|==1.0|  1.0 |<br>|&gt;1.0, !=1.5.1, &lt;2.0| 1.0  2.0  1.5.1 |</p>\n<p>/<code>setup()</code>  <code>provides</code>  python <br>|||<br>|||<br>|mypkg|  <code>mypkg</code>|<br>|mypkg (1.1)|  <code>mypkg</code> 1.1|</p>\n<p> <code>obsoletes</code> / <code>requires</code>  /  <code>()</code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> python </p>\n<p> python <code>scripts</code>  <code>PATH</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup(...,</span><br><span class=\"line\">      scripts=[&#x27;scripts/xmlproc_parse&#x27;, &#x27;scripts/xmlproc_val&#x27;]</span><br><span class=\"line\">      )</span><br></pre></td></tr></table></figure><br> root <code>PATH</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ xmlproc_parse</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">$ xmlproc_val</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> </p>\n<p> <code>package_data</code>    <code>package_dir</code> </p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup.py</span><br><span class=\"line\">src/</span><br><span class=\"line\">    mypkg/</span><br><span class=\"line\">        __init__.py</span><br><span class=\"line\">        module.py</span><br><span class=\"line\">        data/</span><br><span class=\"line\">            tables.dat</span><br><span class=\"line\">            spoons.dat</span><br><span class=\"line\">            forks.dat</span><br></pre></td></tr></table></figure></p>\n<p><code>setup()</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup(...,</span><br><span class=\"line\">     packages=[&#x27;mypkg&#x27;],</span><br><span class=\"line\">     package_dir=&#123;&#x27;mypkg&#x27;: &#x27;src/mypkg&#x27;&#125;,</span><br><span class=\"line\">     package_data=&#123;&#x27;mypkg&#x27;: [&#x27;data/*.dat&#x27;]&#125;,</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>data_files</code>  <code>(directory, files)</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setup(...,</span><br><span class=\"line\">      data_files=[(&#x27;bitmaps&#x27;, [&#x27;bm/b1.gif&#x27;, &#x27;bm/b2.gif&#x27;]),</span><br><span class=\"line\">                  (&#x27;config&#x27;, [&#x27;cfg/data.cfg&#x27;])],</span><br><span class=\"line\">     )</span><br></pre></td></tr></table></figure></p>\n<p><code>files</code>  <code>setup.py</code> </p>\n<p><code>directory</code>  prefix <code>sys.prefix</code> <code>site.USER_BASE</code> <code>directory</code>  wheel </p>"},{"title":"","p":"pytorch/DL-env","date":"2019-09-09T08:38:11.000Z","_content":" ubuntu \n\n tensorflowpytorch  GPU  \n<!-- more -->\nNVIDIA cuda \n1. NVIDIA driver\n2. cuda\n3. cudnn\n\n# NVIDIA driver\n NVIDIA  close nouveau `NVIDIA-Linux-x86_64-xxx.xxx.run` ubuntu  Software & Updates Additional Drivers `Using NVIDIA driver metapackage from nvidia-driver-xxx`  `Apply Changes` \n\n# cuda & cudnn\n conda  pytorch\n```\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n```\n\n\n```\nconda config\nconda config --set show_channel_urls yes\n\ncd ~\nvi .condarc\n```\n `.condarc` \n```\nchannels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n```\n\n\n```\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n```\n\n#  tensorflow\n```\nconda install tensorflow-gpu\n```\n cuda  cudnn\n\n# PyTorch\n\n```\ngit clone https://github.com/pytorch/pytorch.git\n```\n\n```\ngit reset --hard\ngit pull origin master\ngit submodule sync\ngit submodule update --init --recursive\n```\n\n\n```\npython setup.py install\n```\n\n```\npython setup.py build\n```\n Clang  llvm `CPLUS_INCLUDE_PATH` include  llvm  llvm \n```\nexport CPLUS_INCLUDE_PATH='' && python setup.py build\n```\n\n develop conda \n```\ncd [pytorch github project root path]\npython setup.py develop\n```\n site-packages  torch  egg-link pytorch  pytorch\n\n pytorch-gpu\n```\ndocker pull pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level\ndocker run -p 9527:22 --gpus all -rm -itd --ipc=host -v /home/xx/xx:/home/xx/xx --name pytorch pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level\n```\n\n#  mmdetection\n conda  `base`  PyTorchcudatoolkit `matplotlib, pillow, opencv` \n```\nconda list\n```\n mmdetection\n\n1.  mmcv open-mmlab \n```\ngit clone https://github.com/open-mmlab/mmcv.git\n```\n\n\n```\ncd mmcv\n```\n\n```\nMMCV_WITH_OPS=1 pip install -e .\n```\nMMCV_WITH_OPS  0 cpu  mmcv 1   cuda `pip install -e .`  `python setup.py develop`\n\n mmdetection \n```\ngit clone https://github.com/open-mmlab/mmdetection.git\n```\n\n```\ncd mmdetection\npip install -r requirements/build.txt\npython setup.py develop\n```\n","source":"_posts/pytorch/DL-env.md","raw":"---\ntitle: \np: pytorch/DL-env\ndate: 2019-09-09 16:38:11\ntags: DL\n---\n ubuntu \n\n tensorflowpytorch  GPU  \n<!-- more -->\nNVIDIA cuda \n1. NVIDIA driver\n2. cuda\n3. cudnn\n\n# NVIDIA driver\n NVIDIA  close nouveau `NVIDIA-Linux-x86_64-xxx.xxx.run` ubuntu  Software & Updates Additional Drivers `Using NVIDIA driver metapackage from nvidia-driver-xxx`  `Apply Changes` \n\n# cuda & cudnn\n conda  pytorch\n```\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n```\n\n\n```\nconda config\nconda config --set show_channel_urls yes\n\ncd ~\nvi .condarc\n```\n `.condarc` \n```\nchannels:\n  - defaults\nshow_channel_urls: true\ndefault_channels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r\ncustom_channels:\n  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n```\n\n\n```\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n```\n\n#  tensorflow\n```\nconda install tensorflow-gpu\n```\n cuda  cudnn\n\n# PyTorch\n\n```\ngit clone https://github.com/pytorch/pytorch.git\n```\n\n```\ngit reset --hard\ngit pull origin master\ngit submodule sync\ngit submodule update --init --recursive\n```\n\n\n```\npython setup.py install\n```\n\n```\npython setup.py build\n```\n Clang  llvm `CPLUS_INCLUDE_PATH` include  llvm  llvm \n```\nexport CPLUS_INCLUDE_PATH='' && python setup.py build\n```\n\n develop conda \n```\ncd [pytorch github project root path]\npython setup.py develop\n```\n site-packages  torch  egg-link pytorch  pytorch\n\n pytorch-gpu\n```\ndocker pull pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level\ndocker run -p 9527:22 --gpus all -rm -itd --ipc=host -v /home/xx/xx:/home/xx/xx --name pytorch pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level\n```\n\n#  mmdetection\n conda  `base`  PyTorchcudatoolkit `matplotlib, pillow, opencv` \n```\nconda list\n```\n mmdetection\n\n1.  mmcv open-mmlab \n```\ngit clone https://github.com/open-mmlab/mmcv.git\n```\n\n\n```\ncd mmcv\n```\n\n```\nMMCV_WITH_OPS=1 pip install -e .\n```\nMMCV_WITH_OPS  0 cpu  mmcv 1   cuda `pip install -e .`  `python setup.py develop`\n\n mmdetection \n```\ngit clone https://github.com/open-mmlab/mmdetection.git\n```\n\n```\ncd mmdetection\npip install -r requirements/build.txt\npython setup.py develop\n```\n","slug":"pytorch/DL-env","published":1,"updated":"2021-02-09T01:22:35.061Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91k003dp0dj4e7zg7p4","content":"<p> ubuntu </p>\n<p> tensorflowpytorch  GPU <br><span id=\"more\"></span><br>NVIDIA cuda </p>\n<ol>\n<li>NVIDIA driver</li>\n<li>cuda</li>\n<li>cudnn</li>\n</ol>\n<h1 id=\"NVIDIA-driver\"><a href=\"#NVIDIA-driver\" class=\"headerlink\" title=\"NVIDIA driver\"></a>NVIDIA driver</h1><p> NVIDIA  close nouveau <code>NVIDIA-Linux-x86_64-xxx.xxx.run</code> ubuntu  Software &amp; Updates Additional Drivers <code>Using NVIDIA driver metapackage from nvidia-driver-xxx</code>  <code>Apply Changes</code> </p>\n<h1 id=\"cuda-amp-cudnn\"><a href=\"#cuda-amp-cudnn\" class=\"headerlink\" title=\"cuda &amp; cudnn\"></a>cuda &amp; cudnn</h1><p> conda  pytorch<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda config</span><br><span class=\"line\">conda config --set show_channel_urls yes</span><br><span class=\"line\"></span><br><span class=\"line\">cd ~</span><br><span class=\"line\">vi .condarc</span><br></pre></td></tr></table></figure><br> <code>.condarc</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">channels:</span><br><span class=\"line\">  - defaults</span><br><span class=\"line\">show_channel_urls: true</span><br><span class=\"line\">default_channels:</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class=\"line\">custom_channels:</span><br><span class=\"line\">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"-tensorflow\"><a href=\"#-tensorflow\" class=\"headerlink\" title=\" tensorflow\"></a> tensorflow</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install tensorflow-gpu</span><br></pre></td></tr></table></figure>\n<p> cuda  cudnn</p>\n<h1 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/pytorch/pytorch.git</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --hard</span><br><span class=\"line\">git pull origin master</span><br><span class=\"line\">git submodule sync</span><br><span class=\"line\">git submodule update --init --recursive</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py build</span><br></pre></td></tr></table></figure><br> Clang  llvm <code>CPLUS_INCLUDE_PATH</code> include  llvm  llvm <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export CPLUS_INCLUDE_PATH=&#x27;&#x27; &amp;&amp; python setup.py build</span><br></pre></td></tr></table></figure></p>\n<p> develop conda <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd [pytorch github project root path]</span><br><span class=\"line\">python setup.py develop</span><br></pre></td></tr></table></figure><br> site-packages  torch  egg-link pytorch  pytorch</p>\n<p> pytorch-gpu<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level</span><br><span class=\"line\">docker run -p 9527:22 --gpus all -rm -itd --ipc=host -v /home/xx/xx:/home/xx/xx --name pytorch pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"-mmdetection\"><a href=\"#-mmdetection\" class=\"headerlink\" title=\" mmdetection\"></a> mmdetection</h1><p> conda  <code>base</code>  PyTorchcudatoolkit <code>matplotlib, pillow, opencv</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda list</span><br></pre></td></tr></table></figure><br> mmdetection</p>\n<ol>\n<li> mmcv open-mmlab <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/open-mmlab/mmcv.git</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd mmcv</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MMCV_WITH_OPS=1 pip install -e .</span><br></pre></td></tr></table></figure><br>MMCV_WITH_OPS  0 cpu  mmcv 1   cuda <code>pip install -e .</code>  <code>python setup.py develop</code></p>\n<p> mmdetection <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/open-mmlab/mmdetection.git</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd mmdetection</span><br><span class=\"line\">pip install -r requirements/build.txt</span><br><span class=\"line\">python setup.py develop</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p> ubuntu </p>\n<p> tensorflowpytorch  GPU <br>","more":"<br>NVIDIA cuda </p>\n<ol>\n<li>NVIDIA driver</li>\n<li>cuda</li>\n<li>cudnn</li>\n</ol>\n<h1 id=\"NVIDIA-driver\"><a href=\"#NVIDIA-driver\" class=\"headerlink\" title=\"NVIDIA driver\"></a>NVIDIA driver</h1><p> NVIDIA  close nouveau <code>NVIDIA-Linux-x86_64-xxx.xxx.run</code> ubuntu  Software &amp; Updates Additional Drivers <code>Using NVIDIA driver metapackage from nvidia-driver-xxx</code>  <code>Apply Changes</code> </p>\n<h1 id=\"cuda-amp-cudnn\"><a href=\"#cuda-amp-cudnn\" class=\"headerlink\" title=\"cuda &amp; cudnn\"></a>cuda &amp; cudnn</h1><p> conda  pytorch<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda config</span><br><span class=\"line\">conda config --set show_channel_urls yes</span><br><span class=\"line\"></span><br><span class=\"line\">cd ~</span><br><span class=\"line\">vi .condarc</span><br></pre></td></tr></table></figure><br> <code>.condarc</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">channels:</span><br><span class=\"line\">  - defaults</span><br><span class=\"line\">show_channel_urls: true</span><br><span class=\"line\">default_channels:</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class=\"line\">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class=\"line\">custom_channels:</span><br><span class=\"line\">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class=\"line\">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install pytorch torchvision cudatoolkit=10.0 -c pytorch</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"-tensorflow\"><a href=\"#-tensorflow\" class=\"headerlink\" title=\" tensorflow\"></a> tensorflow</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install tensorflow-gpu</span><br></pre></td></tr></table></figure>\n<p> cuda  cudnn</p>\n<h1 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h1><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/pytorch/pytorch.git</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git reset --hard</span><br><span class=\"line\">git pull origin master</span><br><span class=\"line\">git submodule sync</span><br><span class=\"line\">git submodule update --init --recursive</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py build</span><br></pre></td></tr></table></figure><br> Clang  llvm <code>CPLUS_INCLUDE_PATH</code> include  llvm  llvm <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export CPLUS_INCLUDE_PATH=&#x27;&#x27; &amp;&amp; python setup.py build</span><br></pre></td></tr></table></figure></p>\n<p> develop conda <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd [pytorch github project root path]</span><br><span class=\"line\">python setup.py develop</span><br></pre></td></tr></table></figure><br> site-packages  torch  egg-link pytorch  pytorch</p>\n<p> pytorch-gpu<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level</span><br><span class=\"line\">docker run -p 9527:22 --gpus all -rm -itd --ipc=host -v /home/xx/xx:/home/xx/xx --name pytorch pytorch/pytorch:1.7.1-cuda11.0-cudnn8-level</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"-mmdetection\"><a href=\"#-mmdetection\" class=\"headerlink\" title=\" mmdetection\"></a> mmdetection</h1><p> conda  <code>base</code>  PyTorchcudatoolkit <code>matplotlib, pillow, opencv</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda list</span><br></pre></td></tr></table></figure><br> mmdetection</p>\n<ol>\n<li> mmcv open-mmlab <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/open-mmlab/mmcv.git</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd mmcv</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MMCV_WITH_OPS=1 pip install -e .</span><br></pre></td></tr></table></figure><br>MMCV_WITH_OPS  0 cpu  mmcv 1   cuda <code>pip install -e .</code>  <code>python setup.py develop</code></p>\n<p> mmdetection <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/open-mmlab/mmdetection.git</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd mmdetection</span><br><span class=\"line\">pip install -r requirements/build.txt</span><br><span class=\"line\">python setup.py develop</span><br></pre></td></tr></table></figure></p>"},{"title":"PyTorch-4","p":"pytorch/PyTorch-4","date":"2019-08-22T06:34:33.000Z","_content":"## Tensor\ntorch  TensorFloatTensorDoubleTensorHalfTensorByteTensor  Tensor  `torch/__init__.py`  `_C._initExtension(manager_path())` manager_path  torch_shm_manager shm Domain Socket_initExtension  torch/csrc/Module.cpp  _C  _C  c++  THPModule_initExtension\n<!-- more -->\n### initializeLayouts\n c10/core/Layout.h \n1. Strided\n2. Sparse\n3. Mkldnn Intel  Mkldnn  CPU  Mkldnn \n\n Strided  THPLayout_New  THPLayoutType/THPLayout  layout  Stridedname  \"torch.strided\" __ torch __\n- CPU, CUDA, MSNPU, XLA, QuantizedCPU -> strided_layout\n- SparseCPU, SparseCUDA -> sparse_coo_layout\n- MkldnnCPU -> mkldnn_layout\n  \n Backend  Layout  Backend  Layout\n\n### initializeMemoryFormats\n Tensor Preserve, Contiguous  ChannelsLast ChannelsLast  NHWC NCHW  sizes ChannelsLast  strides \n```c++\nstrides[1]=1;           // ChannelsLast  C  1\nstrides[3]=sizes[1];    // ChannelsLast  W  C  sizes[1]\nstrides[2]=strides[3]*sizes[3]; // ChannelsLast  H  W*C\nstrides[0]=strides[2]*sizes[2]; // ChannelsLast  N  H*W*C\n```\n strides  sizes  NCHW\n preserve_format, contiguous_format, channels_last  __ torch __\n\n### initializeQScheme\n inference  [Introducing-Quantized-Tensor](https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor) 5  __ torch __\n\n### initializeDtypes\n\n```c++\n#define DEFINE_SCALAR_TYPE(_1, n) at::ScalarType::n,\nat:ScalarType all_scalar_type[] = {\n    AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS(DEFINE_SCALAR_TYPE)};\n```\n AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS  complex  quantization \n```\nat::ScalarType::Byte,\nat::ScalarType::Char,\nat::ScalarType::Short,\nat::ScalarType::Int,\nat::ScalarType::Long,\nat::ScalarType::Half,\nat::ScalarType::Float,\nat::ScalarType::Double,\nat::ScalarType::ComplexHalf,\nat::ScalarType::ComplexFloat,\nat::ScalarType::ComplexDouble,\nat::ScalarType::Bool,\nat::ScalarType::QInt8,\nat::ScalarType::QUInt8,\nat::ScalarType::QInt32\nat::ScalarType::BFloat16\n```\n `\"\"` at::ScalarType  at::ScalarType \n```c++\nstd::tie(primary_name, legacy_name) = getDtypeName(scalarType);\nPyObject *dtype = THPDtype_New(scalarType, primary_name);\ntorch::registerDtypeObject((THPDtype*)dtype, scalarType);\n```\nTHPDtypeType/THPDtype __ torch __ torch \n\n### initialize_python_bindings\n python \n#### initialize_aten_types\n all_declared_types Backend  `CPU, CUDA, SparseCPU, SparseCUDA` ScalarType  Complex  Quantization \n```\nByte, Char, Double, Float, Int, Long, Short, Half, Bool, BFloat16\n```\n Backend  ScalarType  (SparseCUDA|SparseCPU,Bool)  4*10-2=38  38  PyTensorType  PyTensorType \n```c++\nstruct PyTensorType {\n    PyTypeObject py_type;   // python \n    THPDtype* dtype;        //  initializeDtypes \n    THPLayout* layout;      //  initializeLayouts \n    bool is_cuda;           //  cuda  cpu\n    char name[64];          // tensor \n    int backend;            // CPU, CUDA, SparseCPU, SparseCUDA \n    int scalar_type;        // Byte \n};\n```\n 38  PyTensorType Python  Tensor FloatTensor  PyTensorType \n- layout backend initializeLayouts  Backend  Layout \n- is_cuda backend = CUDA|SparseCUD  true\n- name `[].[ScalarType]Tensor`  \n  \n  ```\n  CPU -> torch\n  CUDA -> torch.cuda\n  SparseCPU -> torch.sparse\n  SparseCUDA -> torch.cuda.sparse\n  ```\n  ScalarType  ScalarType  Byte -> \"Byte\", Float -> \"Float\"  (CPU, Float)  PyTensorType  \"torch.FloatTensor\"(SparseCUDA, Double)  PyTensorType  \"torch.cuda.sparse.DoubleTensor\"\n\n\n```c++\nif (backend==Backend::CPU && scalar_type==at::kFloat) {\n    set_default_tensor_type(&tensor_type);\n}\n```\n Tensor  torch.FloatTensor Backend  CPU CUDA  torch.cuda.FloatTensor\n\ninitialize_aten_types  38  PyTensorType  tensor_types  vector \n\n#### py_initialize_metaclass(metaclass)\n python  PyTypeObject python  \"torch.tensortype\" tensor tensor  torch.FloatTensor \n- dtype  \n     initializeDtypes  THPDtype \n- layout  \n     initializeLayouts  THPLayout \n- is_cuda  \n     cuda\n- is_sparse  \n    \n\n\n- `__instancecheck__`  Tensor  tensor  type_id  scalar_type \n\nPyTensorType  python  Tensor  python  metaclass\n\n PyTypeObject  metaclass tensor \n\n#### get_tensor_dict\n torch.Tensor  _C._TensorBase \n\n#### py_initialize_tensor_type\n 38  PyTensorType  py_type py_type  PyTypeObject python  metaclass torch.Tensor \n```\ndir(torch.Tensor)\ndir(torch.FloatTensor)\n```\n\n\n#### py_bind_tensor_types\n 38  PyTensorType  \" torch \" PyTensorType  \"\" \"torch.FloatTensor\" PyTensorType  FloatTensor  python  torch \"torch.cuda.sparse.DoubleTensor\"  PyTensorType  DoubleTensor  python  torch.cuda.sparse  `.` \n\n torch.FloatTensor, torch.IntTensor  torch.Tensor \n```python\na=torch.empty(1,2,dtype=torch.int)\nisinstance(a, torch.IntTensor)  # True\nisinstance(a, torch.Tensor)     # True\nissubclass(torch.IntTensor, torch.Tensor)   # False\nissubclass(torch.Tensor, torch.IntTensor)   # False\n```\n [Pytorch-3](2019/06/18/Pytorch-3)  torch.empty  THPVariable_Wrap  c++ Variable  python  torch.Tensor  torch.IntTensor  THPVariable_Wrap  torch.Tensor \n```\n>>> type(torch.IntTensor([1,2]))\n<class 'torch.Tensor'>\n```\n torch.Tensor  torch.IntTensor torch.IntTensor  38  Tensor  torch.Tensor \n```\n>>> torch.IntTensor.__bases__\n(<class 'object'>)\n>>> torch.Tensor.__bases__\n(<class 'torch._C._TensorBases'>)\n```\n Tensor  torch.Tensor `isinstance(a, torch.IntTensor)`  True  `isinstance`  `__instancecheck__`  metaclass  c++  Tensor_instancecheck\n```c++\nstatic PyObject *Tensor_instancecheck(PyTensorType *self, PyObject * arg) {\n    try{\n        if(THPVariable_Check(arg)) {    //  THPVariable \n            auto& var = ((THPVariable*)arg)->cdata; //  Variable \n            if (var.type_id() == self->get_type_id() &&\n                var.scalar_type() == static_cast<ScalarType>(self->scalar_type)) {\n                Py_RETURN_TRUE;     //  type_id  ScalarType  True\n            }\n        }\n        Py_RETURN_FALSE;\n    } catch(python_error & e){\n        return nullptr;\n    }\n}\n```\n `isinstance(a, torch.IntTensor)=True`\n\n__ [PyTorch-2]()  PyTorch  Tensor  torch.Tensor `torch._C.Tensor` Tensor  `torch._C.Tensor` __\n\n THPxxxStorage_postInit  [PyTorch-2](2019/06/13/PyTorch-2) THPxxxStorage_init\n1. \n    ```c++\n    #define THPStorage_(NAME) TH_CONCAT_4(THP,Real,Storage_,NAME) //torch/csrc/Storage.h\n    bool THPStorage_(postInit)(PyObject *module);   // torch/csrc/generic/Storage.h\n    ```\n    THPStorage_(NAME)  THPxxxStorage_init  Real  ScalarTypeNAME  init THPxxxStorage_init(PyObject *module);\n\n2. torch/csrc/generic/Storage.cpp \n   ```c++\n   PyObject *THPStorageClass = nullptr;\n   bool THPStorage_(postInit)(PyObject *module){\n       //  torch  RealStorage  Real  Float, Bool, Double  ScalarType\n       THPStorageClass = PyObject_GetAttrString(module, (char*)TH_CONCAT_STRING_2(Real, Storage));\n       at::Backend backend = at::Backend::CPU;\n       #ifdef THC_GENERIC_FILE\n       backend = at::Backend::CUDA;\n       #endif\n       #ifdef THQUANTIZED\n       backend = at::Backend::QuantizedCPU;\n       #endif\n       torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, TH_CONCAT_2(at::k, Real));\n   }\n   ```\n    `torch/__init__.py`  FloatStorage \n   ```python\n   class FloatStorage(_C.FloatStorageBase, _StorageBase):\n       pass\n   ```\n   torch._C.FloatStorageBase  THPxxxStorage_init  torch._C THPxxxStorage_postInit  torch  RealStorage  RealStorage  (Backend, ScalarType)  (Backend, ScalarType)  RealStorage \n\n","source":"_posts/pytorch/PyTorch-4.md","raw":"---\ntitle: PyTorch-4\np: pytorch/PyTorch-4\ndate: 2019-08-22 14:34:33\ntags: PyTorch\ncategories: DL Framework\n---\n## Tensor\ntorch  TensorFloatTensorDoubleTensorHalfTensorByteTensor  Tensor  `torch/__init__.py`  `_C._initExtension(manager_path())` manager_path  torch_shm_manager shm Domain Socket_initExtension  torch/csrc/Module.cpp  _C  _C  c++  THPModule_initExtension\n<!-- more -->\n### initializeLayouts\n c10/core/Layout.h \n1. Strided\n2. Sparse\n3. Mkldnn Intel  Mkldnn  CPU  Mkldnn \n\n Strided  THPLayout_New  THPLayoutType/THPLayout  layout  Stridedname  \"torch.strided\" __ torch __\n- CPU, CUDA, MSNPU, XLA, QuantizedCPU -> strided_layout\n- SparseCPU, SparseCUDA -> sparse_coo_layout\n- MkldnnCPU -> mkldnn_layout\n  \n Backend  Layout  Backend  Layout\n\n### initializeMemoryFormats\n Tensor Preserve, Contiguous  ChannelsLast ChannelsLast  NHWC NCHW  sizes ChannelsLast  strides \n```c++\nstrides[1]=1;           // ChannelsLast  C  1\nstrides[3]=sizes[1];    // ChannelsLast  W  C  sizes[1]\nstrides[2]=strides[3]*sizes[3]; // ChannelsLast  H  W*C\nstrides[0]=strides[2]*sizes[2]; // ChannelsLast  N  H*W*C\n```\n strides  sizes  NCHW\n preserve_format, contiguous_format, channels_last  __ torch __\n\n### initializeQScheme\n inference  [Introducing-Quantized-Tensor](https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor) 5  __ torch __\n\n### initializeDtypes\n\n```c++\n#define DEFINE_SCALAR_TYPE(_1, n) at::ScalarType::n,\nat:ScalarType all_scalar_type[] = {\n    AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS(DEFINE_SCALAR_TYPE)};\n```\n AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS  complex  quantization \n```\nat::ScalarType::Byte,\nat::ScalarType::Char,\nat::ScalarType::Short,\nat::ScalarType::Int,\nat::ScalarType::Long,\nat::ScalarType::Half,\nat::ScalarType::Float,\nat::ScalarType::Double,\nat::ScalarType::ComplexHalf,\nat::ScalarType::ComplexFloat,\nat::ScalarType::ComplexDouble,\nat::ScalarType::Bool,\nat::ScalarType::QInt8,\nat::ScalarType::QUInt8,\nat::ScalarType::QInt32\nat::ScalarType::BFloat16\n```\n `\"\"` at::ScalarType  at::ScalarType \n```c++\nstd::tie(primary_name, legacy_name) = getDtypeName(scalarType);\nPyObject *dtype = THPDtype_New(scalarType, primary_name);\ntorch::registerDtypeObject((THPDtype*)dtype, scalarType);\n```\nTHPDtypeType/THPDtype __ torch __ torch \n\n### initialize_python_bindings\n python \n#### initialize_aten_types\n all_declared_types Backend  `CPU, CUDA, SparseCPU, SparseCUDA` ScalarType  Complex  Quantization \n```\nByte, Char, Double, Float, Int, Long, Short, Half, Bool, BFloat16\n```\n Backend  ScalarType  (SparseCUDA|SparseCPU,Bool)  4*10-2=38  38  PyTensorType  PyTensorType \n```c++\nstruct PyTensorType {\n    PyTypeObject py_type;   // python \n    THPDtype* dtype;        //  initializeDtypes \n    THPLayout* layout;      //  initializeLayouts \n    bool is_cuda;           //  cuda  cpu\n    char name[64];          // tensor \n    int backend;            // CPU, CUDA, SparseCPU, SparseCUDA \n    int scalar_type;        // Byte \n};\n```\n 38  PyTensorType Python  Tensor FloatTensor  PyTensorType \n- layout backend initializeLayouts  Backend  Layout \n- is_cuda backend = CUDA|SparseCUD  true\n- name `[].[ScalarType]Tensor`  \n  \n  ```\n  CPU -> torch\n  CUDA -> torch.cuda\n  SparseCPU -> torch.sparse\n  SparseCUDA -> torch.cuda.sparse\n  ```\n  ScalarType  ScalarType  Byte -> \"Byte\", Float -> \"Float\"  (CPU, Float)  PyTensorType  \"torch.FloatTensor\"(SparseCUDA, Double)  PyTensorType  \"torch.cuda.sparse.DoubleTensor\"\n\n\n```c++\nif (backend==Backend::CPU && scalar_type==at::kFloat) {\n    set_default_tensor_type(&tensor_type);\n}\n```\n Tensor  torch.FloatTensor Backend  CPU CUDA  torch.cuda.FloatTensor\n\ninitialize_aten_types  38  PyTensorType  tensor_types  vector \n\n#### py_initialize_metaclass(metaclass)\n python  PyTypeObject python  \"torch.tensortype\" tensor tensor  torch.FloatTensor \n- dtype  \n     initializeDtypes  THPDtype \n- layout  \n     initializeLayouts  THPLayout \n- is_cuda  \n     cuda\n- is_sparse  \n    \n\n\n- `__instancecheck__`  Tensor  tensor  type_id  scalar_type \n\nPyTensorType  python  Tensor  python  metaclass\n\n PyTypeObject  metaclass tensor \n\n#### get_tensor_dict\n torch.Tensor  _C._TensorBase \n\n#### py_initialize_tensor_type\n 38  PyTensorType  py_type py_type  PyTypeObject python  metaclass torch.Tensor \n```\ndir(torch.Tensor)\ndir(torch.FloatTensor)\n```\n\n\n#### py_bind_tensor_types\n 38  PyTensorType  \" torch \" PyTensorType  \"\" \"torch.FloatTensor\" PyTensorType  FloatTensor  python  torch \"torch.cuda.sparse.DoubleTensor\"  PyTensorType  DoubleTensor  python  torch.cuda.sparse  `.` \n\n torch.FloatTensor, torch.IntTensor  torch.Tensor \n```python\na=torch.empty(1,2,dtype=torch.int)\nisinstance(a, torch.IntTensor)  # True\nisinstance(a, torch.Tensor)     # True\nissubclass(torch.IntTensor, torch.Tensor)   # False\nissubclass(torch.Tensor, torch.IntTensor)   # False\n```\n [Pytorch-3](2019/06/18/Pytorch-3)  torch.empty  THPVariable_Wrap  c++ Variable  python  torch.Tensor  torch.IntTensor  THPVariable_Wrap  torch.Tensor \n```\n>>> type(torch.IntTensor([1,2]))\n<class 'torch.Tensor'>\n```\n torch.Tensor  torch.IntTensor torch.IntTensor  38  Tensor  torch.Tensor \n```\n>>> torch.IntTensor.__bases__\n(<class 'object'>)\n>>> torch.Tensor.__bases__\n(<class 'torch._C._TensorBases'>)\n```\n Tensor  torch.Tensor `isinstance(a, torch.IntTensor)`  True  `isinstance`  `__instancecheck__`  metaclass  c++  Tensor_instancecheck\n```c++\nstatic PyObject *Tensor_instancecheck(PyTensorType *self, PyObject * arg) {\n    try{\n        if(THPVariable_Check(arg)) {    //  THPVariable \n            auto& var = ((THPVariable*)arg)->cdata; //  Variable \n            if (var.type_id() == self->get_type_id() &&\n                var.scalar_type() == static_cast<ScalarType>(self->scalar_type)) {\n                Py_RETURN_TRUE;     //  type_id  ScalarType  True\n            }\n        }\n        Py_RETURN_FALSE;\n    } catch(python_error & e){\n        return nullptr;\n    }\n}\n```\n `isinstance(a, torch.IntTensor)=True`\n\n__ [PyTorch-2]()  PyTorch  Tensor  torch.Tensor `torch._C.Tensor` Tensor  `torch._C.Tensor` __\n\n THPxxxStorage_postInit  [PyTorch-2](2019/06/13/PyTorch-2) THPxxxStorage_init\n1. \n    ```c++\n    #define THPStorage_(NAME) TH_CONCAT_4(THP,Real,Storage_,NAME) //torch/csrc/Storage.h\n    bool THPStorage_(postInit)(PyObject *module);   // torch/csrc/generic/Storage.h\n    ```\n    THPStorage_(NAME)  THPxxxStorage_init  Real  ScalarTypeNAME  init THPxxxStorage_init(PyObject *module);\n\n2. torch/csrc/generic/Storage.cpp \n   ```c++\n   PyObject *THPStorageClass = nullptr;\n   bool THPStorage_(postInit)(PyObject *module){\n       //  torch  RealStorage  Real  Float, Bool, Double  ScalarType\n       THPStorageClass = PyObject_GetAttrString(module, (char*)TH_CONCAT_STRING_2(Real, Storage));\n       at::Backend backend = at::Backend::CPU;\n       #ifdef THC_GENERIC_FILE\n       backend = at::Backend::CUDA;\n       #endif\n       #ifdef THQUANTIZED\n       backend = at::Backend::QuantizedCPU;\n       #endif\n       torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, TH_CONCAT_2(at::k, Real));\n   }\n   ```\n    `torch/__init__.py`  FloatStorage \n   ```python\n   class FloatStorage(_C.FloatStorageBase, _StorageBase):\n       pass\n   ```\n   torch._C.FloatStorageBase  THPxxxStorage_init  torch._C THPxxxStorage_postInit  torch  RealStorage  RealStorage  (Backend, ScalarType)  (Backend, ScalarType)  RealStorage \n\n","slug":"pytorch/PyTorch-4","published":1,"updated":"2020-04-24T10:34:45.043Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91l003fp0djf0eweqym","content":"<h2 id=\"Tensor\"><a href=\"#Tensor\" class=\"headerlink\" title=\"Tensor\"></a>Tensor</h2><p>torch  TensorFloatTensorDoubleTensorHalfTensorByteTensor  Tensor  <code>torch/__init__.py</code>  <code>_C._initExtension(manager_path())</code> manager_path  torch_shm_manager shm Domain Socket_initExtension  torch/csrc/Module.cpp  _C  _C  c++  THPModule_initExtension<br><span id=\"more\"></span></p>\n<h3 id=\"initializeLayouts\"><a href=\"#initializeLayouts\" class=\"headerlink\" title=\"initializeLayouts\"></a>initializeLayouts</h3><p> c10/core/Layout.h </p>\n<ol>\n<li>Strided</li>\n<li>Sparse</li>\n<li>Mkldnn Intel  Mkldnn  CPU  Mkldnn </li>\n</ol>\n<p> Strided  THPLayout_New  THPLayoutType/THPLayout  layout  Stridedname  torch.strided <strong> torch </strong></p>\n<ul>\n<li>CPU, CUDA, MSNPU, XLA, QuantizedCPU -&gt; strided_layout</li>\n<li>SparseCPU, SparseCUDA -&gt; sparse_coo_layout</li>\n<li>MkldnnCPU -&gt; mkldnn_layout</li>\n</ul>\n<p> Backend  Layout  Backend  Layout</p>\n<h3 id=\"initializeMemoryFormats\"><a href=\"#initializeMemoryFormats\" class=\"headerlink\" title=\"initializeMemoryFormats\"></a>initializeMemoryFormats</h3><p> Tensor Preserve, Contiguous  ChannelsLast ChannelsLast  NHWC NCHW  sizes ChannelsLast  strides <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">strides[<span class=\"number\">1</span>]=<span class=\"number\">1</span>;           <span class=\"comment\">// ChannelsLast  C  1</span></span><br><span class=\"line\">strides[<span class=\"number\">3</span>]=sizes[<span class=\"number\">1</span>];    <span class=\"comment\">// ChannelsLast  W  C  sizes[1]</span></span><br><span class=\"line\">strides[<span class=\"number\">2</span>]=strides[<span class=\"number\">3</span>]*sizes[<span class=\"number\">3</span>]; <span class=\"comment\">// ChannelsLast  H  W*C</span></span><br><span class=\"line\">strides[<span class=\"number\">0</span>]=strides[<span class=\"number\">2</span>]*sizes[<span class=\"number\">2</span>]; <span class=\"comment\">// ChannelsLast  N  H*W*C</span></span><br></pre></td></tr></table></figure><br> strides  sizes  NCHW<br> preserve_format, contiguous_format, channels_last  <strong> torch </strong></p>\n<h3 id=\"initializeQScheme\"><a href=\"#initializeQScheme\" class=\"headerlink\" title=\"initializeQScheme\"></a>initializeQScheme</h3><p> inference  <a href=\"https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor\">Introducing-Quantized-Tensor</a> 5  <strong> torch </strong></p>\n<h3 id=\"initializeDtypes\"><a href=\"#initializeDtypes\" class=\"headerlink\" title=\"initializeDtypes\"></a>initializeDtypes</h3><p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> DEFINE_SCALAR_TYPE(_1, n) at::ScalarType::n,</span></span><br><span class=\"line\">at:ScalarType all_scalar_type[] = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS</span>(DEFINE_SCALAR_TYPE)&#125;;</span><br></pre></td></tr></table></figure><br> AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS  complex  quantization <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">at::ScalarType::Byte,</span><br><span class=\"line\">at::ScalarType::Char,</span><br><span class=\"line\">at::ScalarType::Short,</span><br><span class=\"line\">at::ScalarType::Int,</span><br><span class=\"line\">at::ScalarType::Long,</span><br><span class=\"line\">at::ScalarType::Half,</span><br><span class=\"line\">at::ScalarType::Float,</span><br><span class=\"line\">at::ScalarType::Double,</span><br><span class=\"line\">at::ScalarType::ComplexHalf,</span><br><span class=\"line\">at::ScalarType::ComplexFloat,</span><br><span class=\"line\">at::ScalarType::ComplexDouble,</span><br><span class=\"line\">at::ScalarType::Bool,</span><br><span class=\"line\">at::ScalarType::QInt8,</span><br><span class=\"line\">at::ScalarType::QUInt8,</span><br><span class=\"line\">at::ScalarType::QInt32</span><br><span class=\"line\">at::ScalarType::BFloat16</span><br></pre></td></tr></table></figure><br> <code>&quot;&quot;</code> at::ScalarType  at::ScalarType <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">std::<span class=\"built_in\">tie</span>(primary_name, legacy_name) = <span class=\"built_in\">getDtypeName</span>(scalarType);</span><br><span class=\"line\">PyObject *dtype = <span class=\"built_in\">THPDtype_New</span>(scalarType, primary_name);</span><br><span class=\"line\">torch::<span class=\"built_in\">registerDtypeObject</span>((THPDtype*)dtype, scalarType);</span><br></pre></td></tr></table></figure><br>THPDtypeType/THPDtype <strong> torch </strong> torch </p>\n<h3 id=\"initialize-python-bindings\"><a href=\"#initialize-python-bindings\" class=\"headerlink\" title=\"initialize_python_bindings\"></a>initialize_python_bindings</h3><p> python </p>\n<h4 id=\"initialize-aten-types\"><a href=\"#initialize-aten-types\" class=\"headerlink\" title=\"initialize_aten_types\"></a>initialize_aten_types</h4><p> all_declared_types Backend  <code>CPU, CUDA, SparseCPU, SparseCUDA</code> ScalarType  Complex  Quantization <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Byte, Char, Double, Float, Int, Long, Short, Half, Bool, BFloat16</span><br></pre></td></tr></table></figure><br> Backend  ScalarType  (SparseCUDA|SparseCPU,Bool)  4*10-2=38  38  PyTensorType  PyTensorType <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">PyTensorType</span> &#123;</span></span><br><span class=\"line\">    PyTypeObject py_type;   <span class=\"comment\">// python </span></span><br><span class=\"line\">    THPDtype* dtype;        <span class=\"comment\">//  initializeDtypes </span></span><br><span class=\"line\">    THPLayout* layout;      <span class=\"comment\">//  initializeLayouts </span></span><br><span class=\"line\">    <span class=\"keyword\">bool</span> is_cuda;           <span class=\"comment\">//  cuda  cpu</span></span><br><span class=\"line\">    <span class=\"keyword\">char</span> name[<span class=\"number\">64</span>];          <span class=\"comment\">// tensor </span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> backend;            <span class=\"comment\">// CPU, CUDA, SparseCPU, SparseCUDA </span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> scalar_type;        <span class=\"comment\">// Byte </span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> 38  PyTensorType Python  Tensor FloatTensor  PyTensorType </p>\n<ul>\n<li>layout backend initializeLayouts  Backend  Layout </li>\n<li>is_cuda backend = CUDA|SparseCUD  true</li>\n<li>name <code>[].[ScalarType]Tensor</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPU -&gt; torch</span><br><span class=\"line\">CUDA -&gt; torch.cuda</span><br><span class=\"line\">SparseCPU -&gt; torch.sparse</span><br><span class=\"line\">SparseCUDA -&gt; torch.cuda.sparse</span><br></pre></td></tr></table></figure>\nScalarType  ScalarType  Byte -&gt; Byte, Float -&gt; Float  (CPU, Float)  PyTensorType  torch.FloatTensor(SparseCUDA, Double)  PyTensorType  torch.cuda.sparse.DoubleTensor</li>\n</ul>\n<p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (backend==Backend::CPU &amp;&amp; scalar_type==at::kFloat) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">set_default_tensor_type</span>(&amp;tensor_type);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Tensor  torch.FloatTensor Backend  CPU CUDA  torch.cuda.FloatTensor</p>\n<p>initialize_aten_types  38  PyTensorType  tensor_types  vector </p>\n<h4 id=\"py-initialize-metaclass-metaclass\"><a href=\"#py-initialize-metaclass-metaclass\" class=\"headerlink\" title=\"py_initialize_metaclass(metaclass)\"></a>py_initialize_metaclass(metaclass)</h4><p> python  PyTypeObject python  torch.tensortype tensor tensor  torch.FloatTensor </p>\n<ul>\n<li>dtype<br>   initializeDtypes  THPDtype </li>\n<li>layout<br>   initializeLayouts  THPLayout </li>\n<li>is_cuda<br>   cuda</li>\n<li>is_sparse<br>  </li>\n</ul>\n<p></p>\n<ul>\n<li><code>__instancecheck__</code>  Tensor  tensor  type_id  scalar_type </li>\n</ul>\n<p>PyTensorType  python  Tensor  python  metaclass</p>\n<p> PyTypeObject  metaclass tensor </p>\n<h4 id=\"get-tensor-dict\"><a href=\"#get-tensor-dict\" class=\"headerlink\" title=\"get_tensor_dict\"></a>get_tensor_dict</h4><p> torch.Tensor  _C._TensorBase </p>\n<h4 id=\"py-initialize-tensor-type\"><a href=\"#py-initialize-tensor-type\" class=\"headerlink\" title=\"py_initialize_tensor_type\"></a>py_initialize_tensor_type</h4><p> 38  PyTensorType  py_type py_type  PyTypeObject python  metaclass torch.Tensor <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dir(torch.Tensor)</span><br><span class=\"line\">dir(torch.FloatTensor)</span><br></pre></td></tr></table></figure><br></p>\n<h4 id=\"py-bind-tensor-types\"><a href=\"#py-bind-tensor-types\" class=\"headerlink\" title=\"py_bind_tensor_types\"></a>py_bind_tensor_types</h4><p> 38  PyTensorType   torch  PyTensorType   torch.FloatTensor PyTensorType  FloatTensor  python  torch torch.cuda.sparse.DoubleTensor  PyTensorType  DoubleTensor  python  torch.cuda.sparse  <code>.</code> </p>\n<p> torch.FloatTensor, torch.IntTensor  torch.Tensor <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.empty(<span class=\"number\">1</span>,<span class=\"number\">2</span>,dtype=torch.<span class=\"built_in\">int</span>)</span><br><span class=\"line\"><span class=\"built_in\">isinstance</span>(a, torch.IntTensor)  <span class=\"comment\"># True</span></span><br><span class=\"line\"><span class=\"built_in\">isinstance</span>(a, torch.Tensor)     <span class=\"comment\"># True</span></span><br><span class=\"line\"><span class=\"built_in\">issubclass</span>(torch.IntTensor, torch.Tensor)   <span class=\"comment\"># False</span></span><br><span class=\"line\"><span class=\"built_in\">issubclass</span>(torch.Tensor, torch.IntTensor)   <span class=\"comment\"># False</span></span><br></pre></td></tr></table></figure><br> <a href=\"2019/06/18/Pytorch-3\">Pytorch-3</a>  torch.empty  THPVariable_Wrap  c++ Variable  python  torch.Tensor  torch.IntTensor  THPVariable_Wrap  torch.Tensor <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; type(torch.IntTensor([1,2]))</span><br><span class=\"line\">&lt;class &#x27;torch.Tensor&#x27;&gt;</span><br></pre></td></tr></table></figure><br> torch.Tensor  torch.IntTensor torch.IntTensor  38  Tensor  torch.Tensor <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; torch.IntTensor.__bases__</span><br><span class=\"line\">(&lt;class &#x27;object&#x27;&gt;)</span><br><span class=\"line\">&gt;&gt;&gt; torch.Tensor.__bases__</span><br><span class=\"line\">(&lt;class &#x27;torch._C._TensorBases&#x27;&gt;)</span><br></pre></td></tr></table></figure><br> Tensor  torch.Tensor <code>isinstance(a, torch.IntTensor)</code>  True  <code>isinstance</code>  <code>__instancecheck__</code>  metaclass  c++  Tensor_instancecheck<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *<span class=\"title\">Tensor_instancecheck</span><span class=\"params\">(PyTensorType *self, PyObject * arg)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">THPVariable_Check</span>(arg)) &#123;    <span class=\"comment\">//  THPVariable </span></span><br><span class=\"line\">            <span class=\"keyword\">auto</span>&amp; var = ((THPVariable*)arg)-&gt;cdata; <span class=\"comment\">//  Variable </span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (var.<span class=\"built_in\">type_id</span>() == self-&gt;<span class=\"built_in\">get_type_id</span>() &amp;&amp;</span><br><span class=\"line\">                var.<span class=\"built_in\">scalar_type</span>() == <span class=\"keyword\">static_cast</span>&lt;ScalarType&gt;(self-&gt;scalar_type)) &#123;</span><br><span class=\"line\">                Py_RETURN_TRUE;     <span class=\"comment\">//  type_id  ScalarType  True</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Py_RETURN_FALSE;</span><br><span class=\"line\">    &#125; <span class=\"built_in\"><span class=\"keyword\">catch</span></span>(python_error &amp; e)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>isinstance(a, torch.IntTensor)=True</code></p>\n<p><strong> <a href=\"\">PyTorch-2</a>  PyTorch  Tensor  torch.Tensor <code>torch._C.Tensor</code> Tensor  <code>torch._C.Tensor</code> </strong></p>\n<p> THPxxxStorage_postInit  <a href=\"2019/06/13/PyTorch-2\">PyTorch-2</a> THPxxxStorage_init</p>\n<ol>\n<li><p></p>\n <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> THPStorage_(NAME) TH_CONCAT_4(THP,Real,Storage_,NAME) <span class=\"comment\">//torch/csrc/Storage.h</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">THPStorage_</span><span class=\"params\">(postInit)</span><span class=\"params\">(PyObject *<span class=\"keyword\">module</span>)</span></span>;   <span class=\"comment\">// torch/csrc/generic/Storage.h</span></span><br></pre></td></tr></table></figure>\n<p> THPStorage_(NAME)  THPxxxStorage_init  Real  ScalarTypeNAME  init THPxxxStorage_init(PyObject *module);</p>\n</li>\n<li><p>torch/csrc/generic/Storage.cpp </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyObject *THPStorageClass = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">THPStorage_</span><span class=\"params\">(postInit)</span><span class=\"params\">(PyObject *<span class=\"keyword\">module</span>)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//  torch  RealStorage  Real  Float, Bool, Double  ScalarType</span></span><br><span class=\"line\">    THPStorageClass = <span class=\"built_in\">PyObject_GetAttrString</span>(<span class=\"keyword\">module</span>, (<span class=\"keyword\">char</span>*)<span class=\"built_in\">TH_CONCAT_STRING_2</span>(Real, Storage));</span><br><span class=\"line\">    at::Backend backend = at::Backend::CPU;</span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> THC_GENERIC_FILE</span></span><br><span class=\"line\">    backend = at::Backend::CUDA;</span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> THQUANTIZED</span></span><br><span class=\"line\">    backend = at::Backend::QuantizedCPU;</span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\">    torch::<span class=\"built_in\">registerStoragePyTypeObject</span>((PyTypeObject*)THPStorageClass, backend, <span class=\"built_in\">TH_CONCAT_2</span>(at::k, Real));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> <code>torch/__init__.py</code>  FloatStorage </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FloatStorage</span>(<span class=\"params\">_C.FloatStorageBase, _StorageBase</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n<p>torch._C.FloatStorageBase  THPxxxStorage_init  torch._C THPxxxStorage_postInit  torch  RealStorage  RealStorage  (Backend, ScalarType)  (Backend, ScalarType)  RealStorage </p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h2 id=\"Tensor\"><a href=\"#Tensor\" class=\"headerlink\" title=\"Tensor\"></a>Tensor</h2><p>torch  TensorFloatTensorDoubleTensorHalfTensorByteTensor  Tensor  <code>torch/__init__.py</code>  <code>_C._initExtension(manager_path())</code> manager_path  torch_shm_manager shm Domain Socket_initExtension  torch/csrc/Module.cpp  _C  _C  c++  THPModule_initExtension<br>","more":"</p>\n<h3 id=\"initializeLayouts\"><a href=\"#initializeLayouts\" class=\"headerlink\" title=\"initializeLayouts\"></a>initializeLayouts</h3><p> c10/core/Layout.h </p>\n<ol>\n<li>Strided</li>\n<li>Sparse</li>\n<li>Mkldnn Intel  Mkldnn  CPU  Mkldnn </li>\n</ol>\n<p> Strided  THPLayout_New  THPLayoutType/THPLayout  layout  Stridedname  torch.strided <strong> torch </strong></p>\n<ul>\n<li>CPU, CUDA, MSNPU, XLA, QuantizedCPU -&gt; strided_layout</li>\n<li>SparseCPU, SparseCUDA -&gt; sparse_coo_layout</li>\n<li>MkldnnCPU -&gt; mkldnn_layout</li>\n</ul>\n<p> Backend  Layout  Backend  Layout</p>\n<h3 id=\"initializeMemoryFormats\"><a href=\"#initializeMemoryFormats\" class=\"headerlink\" title=\"initializeMemoryFormats\"></a>initializeMemoryFormats</h3><p> Tensor Preserve, Contiguous  ChannelsLast ChannelsLast  NHWC NCHW  sizes ChannelsLast  strides <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">strides[<span class=\"number\">1</span>]=<span class=\"number\">1</span>;           <span class=\"comment\">// ChannelsLast  C  1</span></span><br><span class=\"line\">strides[<span class=\"number\">3</span>]=sizes[<span class=\"number\">1</span>];    <span class=\"comment\">// ChannelsLast  W  C  sizes[1]</span></span><br><span class=\"line\">strides[<span class=\"number\">2</span>]=strides[<span class=\"number\">3</span>]*sizes[<span class=\"number\">3</span>]; <span class=\"comment\">// ChannelsLast  H  W*C</span></span><br><span class=\"line\">strides[<span class=\"number\">0</span>]=strides[<span class=\"number\">2</span>]*sizes[<span class=\"number\">2</span>]; <span class=\"comment\">// ChannelsLast  N  H*W*C</span></span><br></pre></td></tr></table></figure><br> strides  sizes  NCHW<br> preserve_format, contiguous_format, channels_last  <strong> torch </strong></p>\n<h3 id=\"initializeQScheme\"><a href=\"#initializeQScheme\" class=\"headerlink\" title=\"initializeQScheme\"></a>initializeQScheme</h3><p> inference  <a href=\"https://github.com/pytorch/pytorch/wiki/Introducing-Quantized-Tensor\">Introducing-Quantized-Tensor</a> 5  <strong> torch </strong></p>\n<h3 id=\"initializeDtypes\"><a href=\"#initializeDtypes\" class=\"headerlink\" title=\"initializeDtypes\"></a>initializeDtypes</h3><p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> DEFINE_SCALAR_TYPE(_1, n) at::ScalarType::n,</span></span><br><span class=\"line\">at:ScalarType all_scalar_type[] = &#123;</span><br><span class=\"line\">    <span class=\"built_in\">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS</span>(DEFINE_SCALAR_TYPE)&#125;;</span><br></pre></td></tr></table></figure><br> AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS  complex  quantization <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">at::ScalarType::Byte,</span><br><span class=\"line\">at::ScalarType::Char,</span><br><span class=\"line\">at::ScalarType::Short,</span><br><span class=\"line\">at::ScalarType::Int,</span><br><span class=\"line\">at::ScalarType::Long,</span><br><span class=\"line\">at::ScalarType::Half,</span><br><span class=\"line\">at::ScalarType::Float,</span><br><span class=\"line\">at::ScalarType::Double,</span><br><span class=\"line\">at::ScalarType::ComplexHalf,</span><br><span class=\"line\">at::ScalarType::ComplexFloat,</span><br><span class=\"line\">at::ScalarType::ComplexDouble,</span><br><span class=\"line\">at::ScalarType::Bool,</span><br><span class=\"line\">at::ScalarType::QInt8,</span><br><span class=\"line\">at::ScalarType::QUInt8,</span><br><span class=\"line\">at::ScalarType::QInt32</span><br><span class=\"line\">at::ScalarType::BFloat16</span><br></pre></td></tr></table></figure><br> <code>&quot;&quot;</code> at::ScalarType  at::ScalarType <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">std::<span class=\"built_in\">tie</span>(primary_name, legacy_name) = <span class=\"built_in\">getDtypeName</span>(scalarType);</span><br><span class=\"line\">PyObject *dtype = <span class=\"built_in\">THPDtype_New</span>(scalarType, primary_name);</span><br><span class=\"line\">torch::<span class=\"built_in\">registerDtypeObject</span>((THPDtype*)dtype, scalarType);</span><br></pre></td></tr></table></figure><br>THPDtypeType/THPDtype <strong> torch </strong> torch </p>\n<h3 id=\"initialize-python-bindings\"><a href=\"#initialize-python-bindings\" class=\"headerlink\" title=\"initialize_python_bindings\"></a>initialize_python_bindings</h3><p> python </p>\n<h4 id=\"initialize-aten-types\"><a href=\"#initialize-aten-types\" class=\"headerlink\" title=\"initialize_aten_types\"></a>initialize_aten_types</h4><p> all_declared_types Backend  <code>CPU, CUDA, SparseCPU, SparseCUDA</code> ScalarType  Complex  Quantization <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Byte, Char, Double, Float, Int, Long, Short, Half, Bool, BFloat16</span><br></pre></td></tr></table></figure><br> Backend  ScalarType  (SparseCUDA|SparseCPU,Bool)  4*10-2=38  38  PyTensorType  PyTensorType <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">PyTensorType</span> &#123;</span></span><br><span class=\"line\">    PyTypeObject py_type;   <span class=\"comment\">// python </span></span><br><span class=\"line\">    THPDtype* dtype;        <span class=\"comment\">//  initializeDtypes </span></span><br><span class=\"line\">    THPLayout* layout;      <span class=\"comment\">//  initializeLayouts </span></span><br><span class=\"line\">    <span class=\"keyword\">bool</span> is_cuda;           <span class=\"comment\">//  cuda  cpu</span></span><br><span class=\"line\">    <span class=\"keyword\">char</span> name[<span class=\"number\">64</span>];          <span class=\"comment\">// tensor </span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> backend;            <span class=\"comment\">// CPU, CUDA, SparseCPU, SparseCUDA </span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> scalar_type;        <span class=\"comment\">// Byte </span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> 38  PyTensorType Python  Tensor FloatTensor  PyTensorType </p>\n<ul>\n<li>layout backend initializeLayouts  Backend  Layout </li>\n<li>is_cuda backend = CUDA|SparseCUD  true</li>\n<li>name <code>[].[ScalarType]Tensor</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPU -&gt; torch</span><br><span class=\"line\">CUDA -&gt; torch.cuda</span><br><span class=\"line\">SparseCPU -&gt; torch.sparse</span><br><span class=\"line\">SparseCUDA -&gt; torch.cuda.sparse</span><br></pre></td></tr></table></figure>\nScalarType  ScalarType  Byte -&gt; Byte, Float -&gt; Float  (CPU, Float)  PyTensorType  torch.FloatTensor(SparseCUDA, Double)  PyTensorType  torch.cuda.sparse.DoubleTensor</li>\n</ul>\n<p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (backend==Backend::CPU &amp;&amp; scalar_type==at::kFloat) &#123;</span><br><span class=\"line\">    <span class=\"built_in\">set_default_tensor_type</span>(&amp;tensor_type);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Tensor  torch.FloatTensor Backend  CPU CUDA  torch.cuda.FloatTensor</p>\n<p>initialize_aten_types  38  PyTensorType  tensor_types  vector </p>\n<h4 id=\"py-initialize-metaclass-metaclass\"><a href=\"#py-initialize-metaclass-metaclass\" class=\"headerlink\" title=\"py_initialize_metaclass(metaclass)\"></a>py_initialize_metaclass(metaclass)</h4><p> python  PyTypeObject python  torch.tensortype tensor tensor  torch.FloatTensor </p>\n<ul>\n<li>dtype<br>   initializeDtypes  THPDtype </li>\n<li>layout<br>   initializeLayouts  THPLayout </li>\n<li>is_cuda<br>   cuda</li>\n<li>is_sparse<br>  </li>\n</ul>\n<p></p>\n<ul>\n<li><code>__instancecheck__</code>  Tensor  tensor  type_id  scalar_type </li>\n</ul>\n<p>PyTensorType  python  Tensor  python  metaclass</p>\n<p> PyTypeObject  metaclass tensor </p>\n<h4 id=\"get-tensor-dict\"><a href=\"#get-tensor-dict\" class=\"headerlink\" title=\"get_tensor_dict\"></a>get_tensor_dict</h4><p> torch.Tensor  _C._TensorBase </p>\n<h4 id=\"py-initialize-tensor-type\"><a href=\"#py-initialize-tensor-type\" class=\"headerlink\" title=\"py_initialize_tensor_type\"></a>py_initialize_tensor_type</h4><p> 38  PyTensorType  py_type py_type  PyTypeObject python  metaclass torch.Tensor <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dir(torch.Tensor)</span><br><span class=\"line\">dir(torch.FloatTensor)</span><br></pre></td></tr></table></figure><br></p>\n<h4 id=\"py-bind-tensor-types\"><a href=\"#py-bind-tensor-types\" class=\"headerlink\" title=\"py_bind_tensor_types\"></a>py_bind_tensor_types</h4><p> 38  PyTensorType   torch  PyTensorType   torch.FloatTensor PyTensorType  FloatTensor  python  torch torch.cuda.sparse.DoubleTensor  PyTensorType  DoubleTensor  python  torch.cuda.sparse  <code>.</code> </p>\n<p> torch.FloatTensor, torch.IntTensor  torch.Tensor <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=torch.empty(<span class=\"number\">1</span>,<span class=\"number\">2</span>,dtype=torch.<span class=\"built_in\">int</span>)</span><br><span class=\"line\"><span class=\"built_in\">isinstance</span>(a, torch.IntTensor)  <span class=\"comment\"># True</span></span><br><span class=\"line\"><span class=\"built_in\">isinstance</span>(a, torch.Tensor)     <span class=\"comment\"># True</span></span><br><span class=\"line\"><span class=\"built_in\">issubclass</span>(torch.IntTensor, torch.Tensor)   <span class=\"comment\"># False</span></span><br><span class=\"line\"><span class=\"built_in\">issubclass</span>(torch.Tensor, torch.IntTensor)   <span class=\"comment\"># False</span></span><br></pre></td></tr></table></figure><br> <a href=\"2019/06/18/Pytorch-3\">Pytorch-3</a>  torch.empty  THPVariable_Wrap  c++ Variable  python  torch.Tensor  torch.IntTensor  THPVariable_Wrap  torch.Tensor <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; type(torch.IntTensor([1,2]))</span><br><span class=\"line\">&lt;class &#x27;torch.Tensor&#x27;&gt;</span><br></pre></td></tr></table></figure><br> torch.Tensor  torch.IntTensor torch.IntTensor  38  Tensor  torch.Tensor <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; torch.IntTensor.__bases__</span><br><span class=\"line\">(&lt;class &#x27;object&#x27;&gt;)</span><br><span class=\"line\">&gt;&gt;&gt; torch.Tensor.__bases__</span><br><span class=\"line\">(&lt;class &#x27;torch._C._TensorBases&#x27;&gt;)</span><br></pre></td></tr></table></figure><br> Tensor  torch.Tensor <code>isinstance(a, torch.IntTensor)</code>  True  <code>isinstance</code>  <code>__instancecheck__</code>  metaclass  c++  Tensor_instancecheck<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject *<span class=\"title\">Tensor_instancecheck</span><span class=\"params\">(PyTensorType *self, PyObject * arg)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">THPVariable_Check</span>(arg)) &#123;    <span class=\"comment\">//  THPVariable </span></span><br><span class=\"line\">            <span class=\"keyword\">auto</span>&amp; var = ((THPVariable*)arg)-&gt;cdata; <span class=\"comment\">//  Variable </span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (var.<span class=\"built_in\">type_id</span>() == self-&gt;<span class=\"built_in\">get_type_id</span>() &amp;&amp;</span><br><span class=\"line\">                var.<span class=\"built_in\">scalar_type</span>() == <span class=\"keyword\">static_cast</span>&lt;ScalarType&gt;(self-&gt;scalar_type)) &#123;</span><br><span class=\"line\">                Py_RETURN_TRUE;     <span class=\"comment\">//  type_id  ScalarType  True</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        Py_RETURN_FALSE;</span><br><span class=\"line\">    &#125; <span class=\"built_in\"><span class=\"keyword\">catch</span></span>(python_error &amp; e)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> <code>isinstance(a, torch.IntTensor)=True</code></p>\n<p><strong> <a href=\"\">PyTorch-2</a>  PyTorch  Tensor  torch.Tensor <code>torch._C.Tensor</code> Tensor  <code>torch._C.Tensor</code> </strong></p>\n<p> THPxxxStorage_postInit  <a href=\"2019/06/13/PyTorch-2\">PyTorch-2</a> THPxxxStorage_init</p>\n<ol>\n<li><p></p>\n <figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> THPStorage_(NAME) TH_CONCAT_4(THP,Real,Storage_,NAME) <span class=\"comment\">//torch/csrc/Storage.h</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">THPStorage_</span><span class=\"params\">(postInit)</span><span class=\"params\">(PyObject *<span class=\"keyword\">module</span>)</span></span>;   <span class=\"comment\">// torch/csrc/generic/Storage.h</span></span><br></pre></td></tr></table></figure>\n<p> THPStorage_(NAME)  THPxxxStorage_init  Real  ScalarTypeNAME  init THPxxxStorage_init(PyObject *module);</p>\n</li>\n<li><p>torch/csrc/generic/Storage.cpp </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyObject *THPStorageClass = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">THPStorage_</span><span class=\"params\">(postInit)</span><span class=\"params\">(PyObject *<span class=\"keyword\">module</span>)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//  torch  RealStorage  Real  Float, Bool, Double  ScalarType</span></span><br><span class=\"line\">    THPStorageClass = <span class=\"built_in\">PyObject_GetAttrString</span>(<span class=\"keyword\">module</span>, (<span class=\"keyword\">char</span>*)<span class=\"built_in\">TH_CONCAT_STRING_2</span>(Real, Storage));</span><br><span class=\"line\">    at::Backend backend = at::Backend::CPU;</span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> THC_GENERIC_FILE</span></span><br><span class=\"line\">    backend = at::Backend::CUDA;</span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> THQUANTIZED</span></span><br><span class=\"line\">    backend = at::Backend::QuantizedCPU;</span><br><span class=\"line\">    <span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\">    torch::<span class=\"built_in\">registerStoragePyTypeObject</span>((PyTypeObject*)THPStorageClass, backend, <span class=\"built_in\">TH_CONCAT_2</span>(at::k, Real));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> <code>torch/__init__.py</code>  FloatStorage </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FloatStorage</span>(<span class=\"params\">_C.FloatStorageBase, _StorageBase</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n<p>torch._C.FloatStorageBase  THPxxxStorage_init  torch._C THPxxxStorage_postInit  torch  RealStorage  RealStorage  (Backend, ScalarType)  (Backend, ScalarType)  RealStorage </p>\n</li>\n</ol>"},{"title":"PyTorch-5","p":"pytorch/PyTorch-5","date":"2019-08-27T06:07:27.000Z","_content":" PyTorch  Tensor  `requires_grad=True`\n<!-- more -->\n```python\nx=torch.ones(1, requires_grad=True)\n```\n torch.empty  C++  torch.ones  C++  torch/csrc/autograd/generated/python_torch_functions.cpp  THPVariable_ones \n```c++\nauto size = r.intlist(0);\nauto dtype = r.scalartype(2);\nauto device = r.device(4);\nconst auto options = TensorOptions()\n    .dtype(dtype)\n    .device(device)\n    .layout(r.layout(3).layout)\n    .requires_grad(r.toBool(5));\nreturn wrap(dispatch_ones(size, options));\n```\n`wrap`  C++  Tensor  python  Tensor  `torch.Tensor`dispatch_ones  torch::ones \n```c++\nat::Tensor tensor = at::ones(size, at::TensorOptions(options).is_variable(false));\nauto result = autograd::make_variable(tensor, options.requires_grad());\n```\n 1  Tensor Tensor  VariableVariable  TensorTensor  c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>  `impl_`Variable::Impl  TensorImpl Variable  `impl_`  Variable::Impl  Variable::Impl  `requires_grad_`  Variable \n\n```python\ny=torch.ones(1) # y.requires_grad False\nz=x+y           # z.requires_grad True\n```\n\ntorch.Tensor  torch._C._TensorBase  torch/csrc/autograd/generated/python_variable_methods.cpp  variable_methods `__add__`  THPVariable_add\n```\nTHPVariable_add -> dispatch_add -> Tensor::add -> TypeDefault::add -> native::add -> native::add_out\n```\n\n\n","source":"_posts/pytorch/PyTorch-5.md","raw":"---\ntitle: PyTorch-5\np: pytorch/PyTorch-5\ndate: 2019-08-27 14:07:27\ntags: PyTorch\ncategories: DL Framework\n---\n PyTorch  Tensor  `requires_grad=True`\n<!-- more -->\n```python\nx=torch.ones(1, requires_grad=True)\n```\n torch.empty  C++  torch.ones  C++  torch/csrc/autograd/generated/python_torch_functions.cpp  THPVariable_ones \n```c++\nauto size = r.intlist(0);\nauto dtype = r.scalartype(2);\nauto device = r.device(4);\nconst auto options = TensorOptions()\n    .dtype(dtype)\n    .device(device)\n    .layout(r.layout(3).layout)\n    .requires_grad(r.toBool(5));\nreturn wrap(dispatch_ones(size, options));\n```\n`wrap`  C++  Tensor  python  Tensor  `torch.Tensor`dispatch_ones  torch::ones \n```c++\nat::Tensor tensor = at::ones(size, at::TensorOptions(options).is_variable(false));\nauto result = autograd::make_variable(tensor, options.requires_grad());\n```\n 1  Tensor Tensor  VariableVariable  TensorTensor  c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>  `impl_`Variable::Impl  TensorImpl Variable  `impl_`  Variable::Impl  Variable::Impl  `requires_grad_`  Variable \n\n```python\ny=torch.ones(1) # y.requires_grad False\nz=x+y           # z.requires_grad True\n```\n\ntorch.Tensor  torch._C._TensorBase  torch/csrc/autograd/generated/python_variable_methods.cpp  variable_methods `__add__`  THPVariable_add\n```\nTHPVariable_add -> dispatch_add -> Tensor::add -> TypeDefault::add -> native::add -> native::add_out\n```\n\n\n","slug":"pytorch/PyTorch-5","published":1,"updated":"2020-04-24T10:34:51.985Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91m003hp0dj9r5nbwc2","content":"<p> PyTorch  Tensor  <code>requires_grad=True</code><br><span id=\"more\"></span><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=torch.ones(<span class=\"number\">1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure><br> torch.empty  C++  torch.ones  C++  torch/csrc/autograd/generated/python_torch_functions.cpp  THPVariable_ones <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">auto</span> size = r.<span class=\"built_in\">intlist</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\"><span class=\"keyword\">auto</span> dtype = r.<span class=\"built_in\">scalartype</span>(<span class=\"number\">2</span>);</span><br><span class=\"line\"><span class=\"keyword\">auto</span> device = r.<span class=\"built_in\">device</span>(<span class=\"number\">4</span>);</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">auto</span> options = <span class=\"built_in\">TensorOptions</span>()</span><br><span class=\"line\">    .<span class=\"built_in\">dtype</span>(dtype)</span><br><span class=\"line\">    .<span class=\"built_in\">device</span>(device)</span><br><span class=\"line\">    .<span class=\"built_in\">layout</span>(r.<span class=\"built_in\">layout</span>(<span class=\"number\">3</span>).layout)</span><br><span class=\"line\">    .<span class=\"built_in\">requires_grad</span>(r.<span class=\"built_in\">toBool</span>(<span class=\"number\">5</span>));</span><br><span class=\"line\"><span class=\"keyword\">return</span> <span class=\"built_in\">wrap</span>(<span class=\"built_in\">dispatch_ones</span>(size, options));</span><br></pre></td></tr></table></figure><br><code>wrap</code>  C++  Tensor  python  Tensor  <code>torch.Tensor</code>dispatch_ones  torch::ones <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">at::Tensor tensor = at::<span class=\"built_in\">ones</span>(size, at::<span class=\"built_in\">TensorOptions</span>(options).<span class=\"built_in\">is_variable</span>(<span class=\"literal\">false</span>));</span><br><span class=\"line\"><span class=\"keyword\">auto</span> result = autograd::<span class=\"built_in\">make_variable</span>(tensor, options.<span class=\"built_in\">requires_grad</span>());</span><br></pre></td></tr></table></figure><br> 1  Tensor Tensor  VariableVariable  TensorTensor  c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>  <code>impl_</code>Variable::Impl  TensorImpl Variable  <code>impl_</code>  Variable::Impl  Variable::Impl  <code>requires_grad_</code>  Variable </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y=torch.ones(<span class=\"number\">1</span>) <span class=\"comment\"># y.requires_grad False</span></span><br><span class=\"line\">z=x+y           <span class=\"comment\"># z.requires_grad True</span></span><br></pre></td></tr></table></figure>\n<p>torch.Tensor  torch._C._TensorBase  torch/csrc/autograd/generated/python_variable_methods.cpp  variable_methods <code>__add__</code>  THPVariable_add<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPVariable_add -&gt; dispatch_add -&gt; Tensor::add -&gt; TypeDefault::add -&gt; native::add -&gt; native::add_out</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p> PyTorch  Tensor  <code>requires_grad=True</code><br>","more":"<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=torch.ones(<span class=\"number\">1</span>, requires_grad=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure><br> torch.empty  C++  torch.ones  C++  torch/csrc/autograd/generated/python_torch_functions.cpp  THPVariable_ones <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">auto</span> size = r.<span class=\"built_in\">intlist</span>(<span class=\"number\">0</span>);</span><br><span class=\"line\"><span class=\"keyword\">auto</span> dtype = r.<span class=\"built_in\">scalartype</span>(<span class=\"number\">2</span>);</span><br><span class=\"line\"><span class=\"keyword\">auto</span> device = r.<span class=\"built_in\">device</span>(<span class=\"number\">4</span>);</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">auto</span> options = <span class=\"built_in\">TensorOptions</span>()</span><br><span class=\"line\">    .<span class=\"built_in\">dtype</span>(dtype)</span><br><span class=\"line\">    .<span class=\"built_in\">device</span>(device)</span><br><span class=\"line\">    .<span class=\"built_in\">layout</span>(r.<span class=\"built_in\">layout</span>(<span class=\"number\">3</span>).layout)</span><br><span class=\"line\">    .<span class=\"built_in\">requires_grad</span>(r.<span class=\"built_in\">toBool</span>(<span class=\"number\">5</span>));</span><br><span class=\"line\"><span class=\"keyword\">return</span> <span class=\"built_in\">wrap</span>(<span class=\"built_in\">dispatch_ones</span>(size, options));</span><br></pre></td></tr></table></figure><br><code>wrap</code>  C++  Tensor  python  Tensor  <code>torch.Tensor</code>dispatch_ones  torch::ones <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">at::Tensor tensor = at::<span class=\"built_in\">ones</span>(size, at::<span class=\"built_in\">TensorOptions</span>(options).<span class=\"built_in\">is_variable</span>(<span class=\"literal\">false</span>));</span><br><span class=\"line\"><span class=\"keyword\">auto</span> result = autograd::<span class=\"built_in\">make_variable</span>(tensor, options.<span class=\"built_in\">requires_grad</span>());</span><br></pre></td></tr></table></figure><br> 1  Tensor Tensor  VariableVariable  TensorTensor  c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl>  <code>impl_</code>Variable::Impl  TensorImpl Variable  <code>impl_</code>  Variable::Impl  Variable::Impl  <code>requires_grad_</code>  Variable </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">y=torch.ones(<span class=\"number\">1</span>) <span class=\"comment\"># y.requires_grad False</span></span><br><span class=\"line\">z=x+y           <span class=\"comment\"># z.requires_grad True</span></span><br></pre></td></tr></table></figure>\n<p>torch.Tensor  torch._C._TensorBase  torch/csrc/autograd/generated/python_variable_methods.cpp  variable_methods <code>__add__</code>  THPVariable_add<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPVariable_add -&gt; dispatch_add -&gt; Tensor::add -&gt; TypeDefault::add -&gt; native::add -&gt; native::add_out</span><br></pre></td></tr></table></figure></p>"},{"title":"Loss 1","p":"pytorch/loss_1","date":"2021-01-12T09:35:17.000Z","mathjax":true,"_content":"\n [](2021/1/12/dl/x_ent_loss) PyTorch  [Loss](https://pytorch.org/docs/stable/nn.html#loss-functions) \n<!-- more -->\n\n# L1Loss\nL1 L1 $l_n=|x_n-y_n|$ `n` $x_n$ $y_n$  GTL1 <b></b>\n\n# MSELoss\nL2 $l_n=(x_n-y_n)^2$<b></b>\n\n# NLLLoss\n<b></b>\n$$\\mathcal L=\\prod_{i=1}^C x_i^{y_i}$$\n $\\mathbf x = (x_1,...,x_C)$ GT  $\\mathbf y=(y_1,...,y_C)$$\\mathbf y$  one-hot$\\mathbf y$  1\n$$l=-\\sum_{i=1}^C y_i \\log x_i$$\n\n PyTorch NLLLoss  Tensor  shape  GT target  shape  Tensor  shape  $(N,C)$ N C GT target  shape  `N` `[0,C-1]`NLLoss `LogSoftmax`\n$$L=(l_1,...,l_N), \\quad l_n=- x_{n,y_n}$$\n\n`weight` 1-D tensor`C`  [](2021/1/12/dl/x_ent_loss)  [$\\alpha$ ](2021/1/12/dl/x_ent_loss#Balanced-Cross-Entropy)\n$$l_n=- w_{y_n}  x_{n,y_n}$$\n\n\n```python\ntorch.nn.NLLLoss(weight: Optional[torch.Tensor]=None, size_average=None, ignore_index: int=-100, reduce=None, reduction: str='mean')\n```\n\n`size_average`  `reduce` `reduction `\n\n`ignore_index`  GT target  `ignore_index` \n\ninput  forward input  `LogSoftmax` input  shape  $(N,C)$ $(N,C,d_1,...,d_K)$ target  shape  $(N,d_1,...,d_K)$ shape  $(N,d_1,...,d_K)$ $(d_1,...d_K)$ \n\n\n# CrossEntropyLoss\nPyTorch layer `LogSoftmax`  `NLLLoss` layer  input input  shape  $(N,C)$  $(N,C,d_1,...,d_K)$target  shape  $(N,)$  $(N,d_1,...,d_K)$\n input  shape  $(N,C)$  layer \n$$l_n=-\\log \\left(\\frac {\\exp x_{n,y_n}}{\\sum_j \\exp x_{n,j}}\\right)$$\n $y_n \\in [0,C-1]$  n $\\sum_j$  C \n\n `LogSoftmax`  NLLoss \n\n# PoissonNLLLoss\nPoisson  poisson Poisson \n$$P(X=k)=\\frac {\\lambda^k e^{-\\lambda}} {k!}$$\n X  $E[X]=\\lambda$ $x$  $\\lambda$ target target  $y$  $k$\n$$l= -\\log P(y|x) =-\\log \\frac {x^{y} e^{-x}} {y!}=x-y \\log x+ \\log(y!)$$\n Stirling \n\n\n```python\nPoissonNLLLoss(log_input: bool=True, full: bool=False, size_average=None, eps: float=1e-8, reduce=None, reduction: str='mean')\n```\n`log_input`  forward  input  log  True $l=e^x - yx$ $l=x-y \\log(x+eps)$ Poisson  log  `log_input=True` target  log \n\n>  log \n\n`full`  $\\log(y!)$ Stirling Stirling \n$$n! \\sim \\sqrt{2 \\pi} n^{n+1/2} e^{-n}$$\n\n$$\\log(n!)=\\frac 1 2 \\log(2 \\pi n)+ n \\log n - n$$\n\nforward  input  shape  $(N, *)$ $*$  $*$  target  shape  $(N, *)$ `reduction`  `none` shape  $(N, *)$ Tensor   \n\n# KLDivLoss\nKL KL <b></b>\n\n KL KL \n$$D(P||Q)=\\sum P(x) \\cdot \\log \\frac {P(x)}{Q(x)}$$\n$$D(P||Q) = \\int_x p(x) \\log \\frac {p(x)}{q(x)} dx$$\n\n KL  KL \nPyTorch \n```python\nKLDivLoss(size_average=None, reduce=None, reduction: str='mean', log_target: bool=False)\n```\n`log_target`  target  log \n\nforward  input  log input  shape  $(N,*)$ $*$ KL \n$$l=y \\cdot (\\log y - x)$$\n $x$  log $y$ \n\nforward  shape  input  $(N,*)$ `reduction`  `none`  \n\n# BCEWithLogitsLoss\nPyTorch  layer  Sigmoid  BCELoss  BCELoss  BCE \n$$l=y \\log x + (1-y) \\log (1-x)$$\n $y \\in \\{0,1\\}$ $x\\in [0,1]$  Sigmoid  layer  $[0,1]$  Sigmoid  layer `BCEWithLogitsLoss` layer \n$$l_n=-w_n [y_n \\log \\sigma(x_n) +(1-y_n) \\log (1-\\sigma(x_n))]$$\n $w_n$\n\n $c$\n$$l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]$$\n $y_{n,c} \\in \\{0,1\\}$$x_{n,c} \\in \\mathbb R$\n\n $p_c$\n$$l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [p_c y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]$$\n $p_c >1$ $p_c<1$  $p_c$  $c$  \n\nforward  input  shape  $(N,*)$ $N$ $*$  target  output  shape  $(N,*)$ output  output \n\n>  layer  Sigmoid  BCELoss  layer `log-sum-exp` \n\n<b></b>\n# SmoothL1Loss\n L1Loss  L1 SmoothL1Loss \n$$l_i=\\begin{cases} \\frac 1 {2 \\beta} (x_i-y_i)^2 & |x_i - y_i| < \\beta \\\\ |x_i-y_i|-\\frac 1 {2 \\beta} & \\text{otherwise}  \\end{cases}$$\n<b></b>","source":"_posts/pytorch/loss_1.md","raw":"---\ntitle: Loss 1\np: pytorch/loss_1\ndate: 2021-01-12 17:35:17\ntags: PyTorch\nmathjax: true\n---\n\n [](2021/1/12/dl/x_ent_loss) PyTorch  [Loss](https://pytorch.org/docs/stable/nn.html#loss-functions) \n<!-- more -->\n\n# L1Loss\nL1 L1 $l_n=|x_n-y_n|$ `n` $x_n$ $y_n$  GTL1 <b></b>\n\n# MSELoss\nL2 $l_n=(x_n-y_n)^2$<b></b>\n\n# NLLLoss\n<b></b>\n$$\\mathcal L=\\prod_{i=1}^C x_i^{y_i}$$\n $\\mathbf x = (x_1,...,x_C)$ GT  $\\mathbf y=(y_1,...,y_C)$$\\mathbf y$  one-hot$\\mathbf y$  1\n$$l=-\\sum_{i=1}^C y_i \\log x_i$$\n\n PyTorch NLLLoss  Tensor  shape  GT target  shape  Tensor  shape  $(N,C)$ N C GT target  shape  `N` `[0,C-1]`NLLoss `LogSoftmax`\n$$L=(l_1,...,l_N), \\quad l_n=- x_{n,y_n}$$\n\n`weight` 1-D tensor`C`  [](2021/1/12/dl/x_ent_loss)  [$\\alpha$ ](2021/1/12/dl/x_ent_loss#Balanced-Cross-Entropy)\n$$l_n=- w_{y_n}  x_{n,y_n}$$\n\n\n```python\ntorch.nn.NLLLoss(weight: Optional[torch.Tensor]=None, size_average=None, ignore_index: int=-100, reduce=None, reduction: str='mean')\n```\n\n`size_average`  `reduce` `reduction `\n\n`ignore_index`  GT target  `ignore_index` \n\ninput  forward input  `LogSoftmax` input  shape  $(N,C)$ $(N,C,d_1,...,d_K)$ target  shape  $(N,d_1,...,d_K)$ shape  $(N,d_1,...,d_K)$ $(d_1,...d_K)$ \n\n\n# CrossEntropyLoss\nPyTorch layer `LogSoftmax`  `NLLLoss` layer  input input  shape  $(N,C)$  $(N,C,d_1,...,d_K)$target  shape  $(N,)$  $(N,d_1,...,d_K)$\n input  shape  $(N,C)$  layer \n$$l_n=-\\log \\left(\\frac {\\exp x_{n,y_n}}{\\sum_j \\exp x_{n,j}}\\right)$$\n $y_n \\in [0,C-1]$  n $\\sum_j$  C \n\n `LogSoftmax`  NLLoss \n\n# PoissonNLLLoss\nPoisson  poisson Poisson \n$$P(X=k)=\\frac {\\lambda^k e^{-\\lambda}} {k!}$$\n X  $E[X]=\\lambda$ $x$  $\\lambda$ target target  $y$  $k$\n$$l= -\\log P(y|x) =-\\log \\frac {x^{y} e^{-x}} {y!}=x-y \\log x+ \\log(y!)$$\n Stirling \n\n\n```python\nPoissonNLLLoss(log_input: bool=True, full: bool=False, size_average=None, eps: float=1e-8, reduce=None, reduction: str='mean')\n```\n`log_input`  forward  input  log  True $l=e^x - yx$ $l=x-y \\log(x+eps)$ Poisson  log  `log_input=True` target  log \n\n>  log \n\n`full`  $\\log(y!)$ Stirling Stirling \n$$n! \\sim \\sqrt{2 \\pi} n^{n+1/2} e^{-n}$$\n\n$$\\log(n!)=\\frac 1 2 \\log(2 \\pi n)+ n \\log n - n$$\n\nforward  input  shape  $(N, *)$ $*$  $*$  target  shape  $(N, *)$ `reduction`  `none` shape  $(N, *)$ Tensor   \n\n# KLDivLoss\nKL KL <b></b>\n\n KL KL \n$$D(P||Q)=\\sum P(x) \\cdot \\log \\frac {P(x)}{Q(x)}$$\n$$D(P||Q) = \\int_x p(x) \\log \\frac {p(x)}{q(x)} dx$$\n\n KL  KL \nPyTorch \n```python\nKLDivLoss(size_average=None, reduce=None, reduction: str='mean', log_target: bool=False)\n```\n`log_target`  target  log \n\nforward  input  log input  shape  $(N,*)$ $*$ KL \n$$l=y \\cdot (\\log y - x)$$\n $x$  log $y$ \n\nforward  shape  input  $(N,*)$ `reduction`  `none`  \n\n# BCEWithLogitsLoss\nPyTorch  layer  Sigmoid  BCELoss  BCELoss  BCE \n$$l=y \\log x + (1-y) \\log (1-x)$$\n $y \\in \\{0,1\\}$ $x\\in [0,1]$  Sigmoid  layer  $[0,1]$  Sigmoid  layer `BCEWithLogitsLoss` layer \n$$l_n=-w_n [y_n \\log \\sigma(x_n) +(1-y_n) \\log (1-\\sigma(x_n))]$$\n $w_n$\n\n $c$\n$$l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]$$\n $y_{n,c} \\in \\{0,1\\}$$x_{n,c} \\in \\mathbb R$\n\n $p_c$\n$$l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [p_c y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]$$\n $p_c >1$ $p_c<1$  $p_c$  $c$  \n\nforward  input  shape  $(N,*)$ $N$ $*$  target  output  shape  $(N,*)$ output  output \n\n>  layer  Sigmoid  BCELoss  layer `log-sum-exp` \n\n<b></b>\n# SmoothL1Loss\n L1Loss  L1 SmoothL1Loss \n$$l_i=\\begin{cases} \\frac 1 {2 \\beta} (x_i-y_i)^2 & |x_i - y_i| < \\beta \\\\ |x_i-y_i|-\\frac 1 {2 \\beta} & \\text{otherwise}  \\end{cases}$$\n<b></b>","slug":"pytorch/loss_1","published":1,"updated":"2021-01-15T03:59:35.833Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91n003kp0djfng7c5dv","content":"<p> <a href=\"2021/1/12/dl/x_ent_loss\"></a> PyTorch  <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">Loss</a> <br><span id=\"more\"></span></p>\n<h1 id=\"L1Loss\"><a href=\"#L1Loss\" class=\"headerlink\" title=\"L1Loss\"></a>L1Loss</h1><p>L1 L1 $l_n=|x_n-y_n|$ <code>n</code> $x_n$ $y_n$  GTL1 <b></b></p>\n<h1 id=\"MSELoss\"><a href=\"#MSELoss\" class=\"headerlink\" title=\"MSELoss\"></a>MSELoss</h1><p>L2 $l_n=(x_n-y_n)^2$<b></b></p>\n<h1 id=\"NLLLoss\"><a href=\"#NLLLoss\" class=\"headerlink\" title=\"NLLLoss\"></a>NLLLoss</h1><p><b></b></p>\n<script type=\"math/tex; mode=display\">\\mathcal L=\\prod_{i=1}^C x_i^{y_i}</script><p> $\\mathbf x = (x_1,,x_C)$ GT  $\\mathbf y=(y_1,,y_C)$$\\mathbf y$  one-hot$\\mathbf y$  1</p>\n<script type=\"math/tex; mode=display\">l=-\\sum_{i=1}^C y_i \\log x_i</script><p> PyTorch NLLLoss  Tensor  shape  GT target  shape  Tensor  shape  $(N,C)$ N C GT target  shape  <code>N</code> <code>[0,C-1]</code>NLLoss <code>LogSoftmax</code></p>\n<script type=\"math/tex; mode=display\">L=(l_1,...,l_N), \\quad l_n=- x_{n,y_n}</script><p><code>weight</code> 1-D tensor<code>C</code>  <a href=\"2021/1/12/dl/x_ent_loss\"></a>  <a href=\"2021/1/12/dl/x_ent_loss#Balanced-Cross-Entropy\">$\\alpha$ </a></p>\n<script type=\"math/tex; mode=display\">l_n=- w_{y_n}  x_{n,y_n}</script><p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.NLLLoss(weight: <span class=\"type\">Optional</span>[torch.Tensor]=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, ignore_index: <span class=\"built_in\">int</span>=-<span class=\"number\">100</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure></p>\n<p><code>size_average</code>  <code>reduce</code> <code>reduction</code></p>\n<p><code>ignore_index</code>  GT target  <code>ignore_index</code> </p>\n<p>input  forward input  <code>LogSoftmax</code> input  shape  $(N,C)$ $(N,C,d_1,,d_K)$ target  shape  $(N,d_1,,d_K)$ shape  $(N,d_1,,d_K)$ $(d_1,d_K)$ </p>\n<h1 id=\"CrossEntropyLoss\"><a href=\"#CrossEntropyLoss\" class=\"headerlink\" title=\"CrossEntropyLoss\"></a>CrossEntropyLoss</h1><p>PyTorch layer <code>LogSoftmax</code>  <code>NLLLoss</code> layer  input input  shape  $(N,C)$  $(N,C,d_1,,d_K)$target  shape  $(N,)$  $(N,d_1,,d_K)$<br> input  shape  $(N,C)$  layer </p>\n<script type=\"math/tex; mode=display\">l_n=-\\log \\left(\\frac {\\exp x_{n,y_n}}{\\sum_j \\exp x_{n,j}}\\right)</script><p> $y_n \\in [0,C-1]$  n $\\sum_j$  C </p>\n<p> <code>LogSoftmax</code>  NLLoss </p>\n<h1 id=\"PoissonNLLLoss\"><a href=\"#PoissonNLLLoss\" class=\"headerlink\" title=\"PoissonNLLLoss\"></a>PoissonNLLLoss</h1><p>Poisson  poisson Poisson </p>\n<script type=\"math/tex; mode=display\">P(X=k)=\\frac {\\lambda^k e^{-\\lambda}} {k!}</script><p> X  $E[X]=\\lambda$ $x$  $\\lambda$ target target  $y$  $k$</p>\n<script type=\"math/tex; mode=display\">l= -\\log P(y|x) =-\\log \\frac {x^{y} e^{-x}} {y!}=x-y \\log x+ \\log(y!)</script><p> Stirling </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PoissonNLLLoss(log_input: <span class=\"built_in\">bool</span>=<span class=\"literal\">True</span>, full: <span class=\"built_in\">bool</span>=<span class=\"literal\">False</span>, size_average=<span class=\"literal\">None</span>, eps: <span class=\"built_in\">float</span>=<span class=\"number\">1e-8</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>log_input</code>  forward  input  log  True $l=e^x - yx$ $l=x-y \\log(x+eps)$ Poisson  log  <code>log_input=True</code> target  log </p>\n<blockquote>\n<p> log </p>\n</blockquote>\n<p><code>full</code>  $\\log(y!)$ Stirling Stirling </p>\n<script type=\"math/tex; mode=display\">n! \\sim \\sqrt{2 \\pi} n^{n+1/2} e^{-n}</script><p></p>\n<script type=\"math/tex; mode=display\">\\log(n!)=\\frac 1 2 \\log(2 \\pi n)+ n \\log n - n</script><p>forward  input  shape  $(N, <em>)$ $</em>$  $<em>$  target  shape  $(N, </em>)$ <code>reduction</code>  <code>none</code> shape  $(N, *)$ Tensor   </p>\n<h1 id=\"KLDivLoss\"><a href=\"#KLDivLoss\" class=\"headerlink\" title=\"KLDivLoss\"></a>KLDivLoss</h1><p>KL KL <b></b></p>\n<p> KL KL </p>\n<script type=\"math/tex; mode=display\">D(P||Q)=\\sum P(x) \\cdot \\log \\frac {P(x)}{Q(x)}</script><script type=\"math/tex; mode=display\">D(P||Q) = \\int_x p(x) \\log \\frac {p(x)}{q(x)} dx</script><p> KL  KL <br>PyTorch <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">KLDivLoss(size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>, log_target: <span class=\"built_in\">bool</span>=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure><br><code>log_target</code>  target  log </p>\n<p>forward  input  log input  shape  $(N,<em>)$ $</em>$ KL </p>\n<script type=\"math/tex; mode=display\">l=y \\cdot (\\log y - x)</script><p> $x$  log $y$ </p>\n<p>forward  shape  input  $(N,*)$ <code>reduction</code>  <code>none</code>  </p>\n<h1 id=\"BCEWithLogitsLoss\"><a href=\"#BCEWithLogitsLoss\" class=\"headerlink\" title=\"BCEWithLogitsLoss\"></a>BCEWithLogitsLoss</h1><p>PyTorch  layer  Sigmoid  BCELoss  BCELoss  BCE </p>\n<script type=\"math/tex; mode=display\">l=y \\log x + (1-y) \\log (1-x)</script><p> $y \\in \\{0,1\\}$ $x\\in [0,1]$  Sigmoid  layer  $[0,1]$  Sigmoid  layer <code>BCEWithLogitsLoss</code> layer </p>\n<script type=\"math/tex; mode=display\">l_n=-w_n [y_n \\log \\sigma(x_n) +(1-y_n) \\log (1-\\sigma(x_n))]</script><p> $w_n$</p>\n<p> $c$</p>\n<script type=\"math/tex; mode=display\">l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]</script><p> $y_{n,c} \\in \\{0,1\\}$$x_{n,c} \\in \\mathbb R$</p>\n<p> $p_c$</p>\n<script type=\"math/tex; mode=display\">l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [p_c y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]</script><p> $p_c &gt;1$ $p_c&lt;1$  $p_c$  $c$  </p>\n<p>forward  input  shape  $(N,<em>)$ $N$ $</em>$  target  output  shape  $(N,*)$ output  output </p>\n<blockquote>\n<p> layer  Sigmoid  BCELoss  layer <code>log-sum-exp</code> </p>\n</blockquote>\n<p><b></b></p>\n<h1 id=\"SmoothL1Loss\"><a href=\"#SmoothL1Loss\" class=\"headerlink\" title=\"SmoothL1Loss\"></a>SmoothL1Loss</h1><p> L1Loss  L1 SmoothL1Loss </p>\n<script type=\"math/tex; mode=display\">l_i=\\begin{cases} \\frac 1 {2 \\beta} (x_i-y_i)^2 & |x_i - y_i| < \\beta \\\\ |x_i-y_i|-\\frac 1 {2 \\beta} & \\text{otherwise}  \\end{cases}</script><p><b></b></p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"2021/1/12/dl/x_ent_loss\"></a> PyTorch  <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">Loss</a> <br>","more":"</p>\n<h1 id=\"L1Loss\"><a href=\"#L1Loss\" class=\"headerlink\" title=\"L1Loss\"></a>L1Loss</h1><p>L1 L1 $l_n=|x_n-y_n|$ <code>n</code> $x_n$ $y_n$  GTL1 <b></b></p>\n<h1 id=\"MSELoss\"><a href=\"#MSELoss\" class=\"headerlink\" title=\"MSELoss\"></a>MSELoss</h1><p>L2 $l_n=(x_n-y_n)^2$<b></b></p>\n<h1 id=\"NLLLoss\"><a href=\"#NLLLoss\" class=\"headerlink\" title=\"NLLLoss\"></a>NLLLoss</h1><p><b></b></p>\n<script type=\"math/tex; mode=display\">\\mathcal L=\\prod_{i=1}^C x_i^{y_i}</script><p> $\\mathbf x = (x_1,,x_C)$ GT  $\\mathbf y=(y_1,,y_C)$$\\mathbf y$  one-hot$\\mathbf y$  1</p>\n<script type=\"math/tex; mode=display\">l=-\\sum_{i=1}^C y_i \\log x_i</script><p> PyTorch NLLLoss  Tensor  shape  GT target  shape  Tensor  shape  $(N,C)$ N C GT target  shape  <code>N</code> <code>[0,C-1]</code>NLLoss <code>LogSoftmax</code></p>\n<script type=\"math/tex; mode=display\">L=(l_1,...,l_N), \\quad l_n=- x_{n,y_n}</script><p><code>weight</code> 1-D tensor<code>C</code>  <a href=\"2021/1/12/dl/x_ent_loss\"></a>  <a href=\"2021/1/12/dl/x_ent_loss#Balanced-Cross-Entropy\">$\\alpha$ </a></p>\n<script type=\"math/tex; mode=display\">l_n=- w_{y_n}  x_{n,y_n}</script><p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.nn.NLLLoss(weight: <span class=\"type\">Optional</span>[torch.Tensor]=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, ignore_index: <span class=\"built_in\">int</span>=-<span class=\"number\">100</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure></p>\n<p><code>size_average</code>  <code>reduce</code> <code>reduction</code></p>\n<p><code>ignore_index</code>  GT target  <code>ignore_index</code> </p>\n<p>input  forward input  <code>LogSoftmax</code> input  shape  $(N,C)$ $(N,C,d_1,,d_K)$ target  shape  $(N,d_1,,d_K)$ shape  $(N,d_1,,d_K)$ $(d_1,d_K)$ </p>\n<h1 id=\"CrossEntropyLoss\"><a href=\"#CrossEntropyLoss\" class=\"headerlink\" title=\"CrossEntropyLoss\"></a>CrossEntropyLoss</h1><p>PyTorch layer <code>LogSoftmax</code>  <code>NLLLoss</code> layer  input input  shape  $(N,C)$  $(N,C,d_1,,d_K)$target  shape  $(N,)$  $(N,d_1,,d_K)$<br> input  shape  $(N,C)$  layer </p>\n<script type=\"math/tex; mode=display\">l_n=-\\log \\left(\\frac {\\exp x_{n,y_n}}{\\sum_j \\exp x_{n,j}}\\right)</script><p> $y_n \\in [0,C-1]$  n $\\sum_j$  C </p>\n<p> <code>LogSoftmax</code>  NLLoss </p>\n<h1 id=\"PoissonNLLLoss\"><a href=\"#PoissonNLLLoss\" class=\"headerlink\" title=\"PoissonNLLLoss\"></a>PoissonNLLLoss</h1><p>Poisson  poisson Poisson </p>\n<script type=\"math/tex; mode=display\">P(X=k)=\\frac {\\lambda^k e^{-\\lambda}} {k!}</script><p> X  $E[X]=\\lambda$ $x$  $\\lambda$ target target  $y$  $k$</p>\n<script type=\"math/tex; mode=display\">l= -\\log P(y|x) =-\\log \\frac {x^{y} e^{-x}} {y!}=x-y \\log x+ \\log(y!)</script><p> Stirling </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PoissonNLLLoss(log_input: <span class=\"built_in\">bool</span>=<span class=\"literal\">True</span>, full: <span class=\"built_in\">bool</span>=<span class=\"literal\">False</span>, size_average=<span class=\"literal\">None</span>, eps: <span class=\"built_in\">float</span>=<span class=\"number\">1e-8</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>log_input</code>  forward  input  log  True $l=e^x - yx$ $l=x-y \\log(x+eps)$ Poisson  log  <code>log_input=True</code> target  log </p>\n<blockquote>\n<p> log </p>\n</blockquote>\n<p><code>full</code>  $\\log(y!)$ Stirling Stirling </p>\n<script type=\"math/tex; mode=display\">n! \\sim \\sqrt{2 \\pi} n^{n+1/2} e^{-n}</script><p></p>\n<script type=\"math/tex; mode=display\">\\log(n!)=\\frac 1 2 \\log(2 \\pi n)+ n \\log n - n</script><p>forward  input  shape  $(N, <em>)$ $</em>$  $<em>$  target  shape  $(N, </em>)$ <code>reduction</code>  <code>none</code> shape  $(N, *)$ Tensor   </p>\n<h1 id=\"KLDivLoss\"><a href=\"#KLDivLoss\" class=\"headerlink\" title=\"KLDivLoss\"></a>KLDivLoss</h1><p>KL KL <b></b></p>\n<p> KL KL </p>\n<script type=\"math/tex; mode=display\">D(P||Q)=\\sum P(x) \\cdot \\log \\frac {P(x)}{Q(x)}</script><script type=\"math/tex; mode=display\">D(P||Q) = \\int_x p(x) \\log \\frac {p(x)}{q(x)} dx</script><p> KL  KL <br>PyTorch <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">KLDivLoss(size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>, log_target: <span class=\"built_in\">bool</span>=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure><br><code>log_target</code>  target  log </p>\n<p>forward  input  log input  shape  $(N,<em>)$ $</em>$ KL </p>\n<script type=\"math/tex; mode=display\">l=y \\cdot (\\log y - x)</script><p> $x$  log $y$ </p>\n<p>forward  shape  input  $(N,*)$ <code>reduction</code>  <code>none</code>  </p>\n<h1 id=\"BCEWithLogitsLoss\"><a href=\"#BCEWithLogitsLoss\" class=\"headerlink\" title=\"BCEWithLogitsLoss\"></a>BCEWithLogitsLoss</h1><p>PyTorch  layer  Sigmoid  BCELoss  BCELoss  BCE </p>\n<script type=\"math/tex; mode=display\">l=y \\log x + (1-y) \\log (1-x)</script><p> $y \\in \\{0,1\\}$ $x\\in [0,1]$  Sigmoid  layer  $[0,1]$  Sigmoid  layer <code>BCEWithLogitsLoss</code> layer </p>\n<script type=\"math/tex; mode=display\">l_n=-w_n [y_n \\log \\sigma(x_n) +(1-y_n) \\log (1-\\sigma(x_n))]</script><p> $w_n$</p>\n<p> $c$</p>\n<script type=\"math/tex; mode=display\">l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]</script><p> $y_{n,c} \\in \\{0,1\\}$$x_{n,c} \\in \\mathbb R$</p>\n<p> $p_c$</p>\n<script type=\"math/tex; mode=display\">l_n=\\sum_{c=1}^C l_{n,c}=-\\sum_{c=1}^C w_n [p_c y_{n,c} \\log \\sigma(x_{n,c}) +(1-y_{n,c}) \\log (1-\\sigma(x_{n,c}))]</script><p> $p_c &gt;1$ $p_c&lt;1$  $p_c$  $c$  </p>\n<p>forward  input  shape  $(N,<em>)$ $N$ $</em>$  target  output  shape  $(N,*)$ output  output </p>\n<blockquote>\n<p> layer  Sigmoid  BCELoss  layer <code>log-sum-exp</code> </p>\n</blockquote>\n<p><b></b></p>\n<h1 id=\"SmoothL1Loss\"><a href=\"#SmoothL1Loss\" class=\"headerlink\" title=\"SmoothL1Loss\"></a>SmoothL1Loss</h1><p> L1Loss  L1 SmoothL1Loss </p>\n<script type=\"math/tex; mode=display\">l_i=\\begin{cases} \\frac 1 {2 \\beta} (x_i-y_i)^2 & |x_i - y_i| < \\beta \\\\ |x_i-y_i|-\\frac 1 {2 \\beta} & \\text{otherwise}  \\end{cases}</script><p><b></b></p>"},{"title":"Loss 2","p":"pytorch/loss_2","date":"2021-01-13T08:54:38.000Z","mathjax":true,"_content":" [loss 1](2021/1/12/pytorch/loss_1) PyTorch \n<!-- more -->\n\n\n# MarginRankingLoss\n $x_1, \\ x_2$ label  $y \\in \\{1,-1\\}$ $y=1$ $x_1$  $x_2$  $y=-1$ $x_1$  $x_2$ \n$$l=\\max(0, -y(x_1-x_2) + \\text{margin})$$\n `margin` \n$$-y(x_1-x_2)+\\text{margin} \\le 0$$\n\n $y=1$  $x_1\\ge x_2+\\text{margin}$  0\n\n $y=-1$  $x_1+\\text{margin} \\le x_2$  0\n\n<b></b>\n# MultiLabelMarginLoss\n or  x  2D tensorshape  $(N,C)$ $N$ $C$ target  x  shape x  target  `C` x target  y  $y=(3,0,-1,1)$ `0`  `3`  `MarginRankingLoss`  x<b></b> $\\{0,3\\}$ $x_0,\\ x_3 > x_1,\\ x_2$\n$$l=\\sum_{i,j} \\frac {\\max[0, 1-(x_{y_j} - x_i)]} C$$\n$j \\in \\mathcal J=\\{0,1,...,k-1\\}$ $y_k<0$$i \\in \\{0,1,...,C-1\\}-\\{y_j|j \\in \\mathcal J\\}$ $j$  target $y_j$ i \n\n0 $1-(x_{y_j}-x_i)\\le 0 \\Rightarrow x_{y_j}\\ge 1+x_i$ $x_{y_j} \\rightarrow 0$ $x_i \\rightarrow 0$ test  x \n\n# SoftMarginLoss\n MarginLoss  `max(0,x)`  `x=0` `SoftMarginLoss`  logistic Logistic \n$$\\sigma(x)=\\frac 1 {1+\\exp (-x)}$$\n x $y\\in \\{1,-1\\}$\n$$\\mathcal L =\\mathbb I(y=1)f(x)+\\mathbb I(y=-1)(1-f(x))=[1+\\exp(-yx)]^{-1}$$\n \n$$l= \\log(1+\\exp(-yx))$$\n `SoftMarginLoss` <b> logistic </b> input tensor  shape  $(*)$ $*$ target  input  shape  input  shape\n\n# MultiLabelSoftMarginLoss\ninput  target  shape$(N,C)$target  0  1 SoftMarginLoss  1  -1 \n$$l=-\\frac 1 C \\sum_{i=1}^C y_i \\log \\left(\\frac 1 {1+\\exp(-x_i)}\\right )+(1-y_i)\\log \\left(\\frac {\\exp(-x_i)} {1+\\exp(-x_i)}\\right)$$\n $x, \\ y$  $C$  y  `SoftMarginLoss`  logistic \n\n tensor  shape  $(N,)$ tensor \n\n\n```python\nMultiLabelSoftMarginLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str='mean')\n```\n`weight`  shape  $(C,)$   tensor channel/ \n\n# MultiMarginLoss\ninput  2D tensor $(N,C)$target shape  $(N,)$ $y_i \\in \\{0,1,...,C-1\\}$ C  xtarget  y $x_y > x_i$ $i \\neq y$margin-based \n$$l=\\frac {\\sum_{i \\neq y} \\max(0, d-(x_y-x_i))^p} C$$\n $d$  margin $x_y \\ge x_i+d$ $d$ 0\n\np  1  2\n$$l=\\frac {\\sum_{i \\neq y} \\max[0, w_y(d-(x_y-x_i))^p]} C$$\n $w_y$ \n\n\n```python\nMultiMarginLoss(p: int=1, margin: float=1.0, weight: Optional[torch.Tensor]=None, size_average=None, reduce=None, reduction: str='mean')\n```\ninput shape  $(N,C)$target shape  $(N,)$output  shape  $(N,)$ output \n\n# TripletMarginLoss\ntensor$a, \\ p, \\ n$ anchorshape  $(N,D)$ $N$ $D$ p  a n  a  p  a n  a \n pair  $(p,a)$ $(n,a)$  $(x_1, x_2 l)$ $l=1$ $l=-1$ \n$$l=\\begin{cases} \\Vert \\mathbf x_1-\\mathbf x_2 \\Vert_2 & l=1 \\\\ \\max(0, d-\\Vert \\mathbf x_1- \\mathbf x_2\\Vert_2) & l=-1 \\end{cases}$$\n$l=1$  $\\mathbf x_1$  $\\mathbf x_2$$l=-1$ $\\mathbf x_1$  $\\mathbf x_2$ $d$ \n\n `TripletMarginLoss`  `(a,p,n)` margin ranking-based \n$$l=\\max[d(a,p) - d(a,n)+d_0, 0]$$\n$$d(\\mathbf x_1, \\mathbf x_2)=\\Vert \\mathbf x_1 - \\mathbf x_2 \\Vert_p$$\n$d_0$  margin p  p  p \n\n\n```python\nTripletMarginLoss(margin: float=1.0, p: float=2.0, eps: float=1e-06, swap: bool=False, size_average=None, reduce=None, reduction: str='mean')\n```\n`swap`  anchor  positive hard negative mining `swap=True` $d(a,n) = d(p,n)$ `(p,n)`  negative  anchor \n\nforward  anchor, positive  negative  tensorshape  $(N,D)$ tensor  shape  $(N,)$\n\n [`Learning local feature descriptors with triplets and shallow convolutional neural networks`](www.bmva.org/bmvc/2016/papers/paper119/paper119.pdf)\n\n# TripletMarginWithDistanceLoss\n`TripletMarginLoss`  p anchorpositive  negative  tensor  shape  $(N,*)$  $*$  tensor  shape  $(N,)$\n\n# HingeEmbeddingLoss\n$x$  L1 $y \\in \\{1,-1\\}$ \n$$l = \\begin{cases} x & y=1 \\\\ \\max(0, d-x) & y=-1 \\end{cases}$$\n $d$  margin\n\n x  y  shape  $(*)$ shape  $(*)$\n\n# CosineEmbeddingLoss\n`y=1` `y=-1` \n\n$$l=\\begin{cases} 1- \\cos(x_1,x_2) & y=1 \\\\ \\max[0, \\cos(x_1,x_2) - d] & y=-1 \\end{cases}$$\n $d$  margin 0\n\n# CTCLoss\n [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)\nRNN ","source":"_posts/pytorch/loss_2.md","raw":"---\ntitle: Loss 2\np: pytorch/loss_2\ndate: 2021-01-13 16:54:38\ntags: PyTorch\nmathjax: true\n---\n [loss 1](2021/1/12/pytorch/loss_1) PyTorch \n<!-- more -->\n\n\n# MarginRankingLoss\n $x_1, \\ x_2$ label  $y \\in \\{1,-1\\}$ $y=1$ $x_1$  $x_2$  $y=-1$ $x_1$  $x_2$ \n$$l=\\max(0, -y(x_1-x_2) + \\text{margin})$$\n `margin` \n$$-y(x_1-x_2)+\\text{margin} \\le 0$$\n\n $y=1$  $x_1\\ge x_2+\\text{margin}$  0\n\n $y=-1$  $x_1+\\text{margin} \\le x_2$  0\n\n<b></b>\n# MultiLabelMarginLoss\n or  x  2D tensorshape  $(N,C)$ $N$ $C$ target  x  shape x  target  `C` x target  y  $y=(3,0,-1,1)$ `0`  `3`  `MarginRankingLoss`  x<b></b> $\\{0,3\\}$ $x_0,\\ x_3 > x_1,\\ x_2$\n$$l=\\sum_{i,j} \\frac {\\max[0, 1-(x_{y_j} - x_i)]} C$$\n$j \\in \\mathcal J=\\{0,1,...,k-1\\}$ $y_k<0$$i \\in \\{0,1,...,C-1\\}-\\{y_j|j \\in \\mathcal J\\}$ $j$  target $y_j$ i \n\n0 $1-(x_{y_j}-x_i)\\le 0 \\Rightarrow x_{y_j}\\ge 1+x_i$ $x_{y_j} \\rightarrow 0$ $x_i \\rightarrow 0$ test  x \n\n# SoftMarginLoss\n MarginLoss  `max(0,x)`  `x=0` `SoftMarginLoss`  logistic Logistic \n$$\\sigma(x)=\\frac 1 {1+\\exp (-x)}$$\n x $y\\in \\{1,-1\\}$\n$$\\mathcal L =\\mathbb I(y=1)f(x)+\\mathbb I(y=-1)(1-f(x))=[1+\\exp(-yx)]^{-1}$$\n \n$$l= \\log(1+\\exp(-yx))$$\n `SoftMarginLoss` <b> logistic </b> input tensor  shape  $(*)$ $*$ target  input  shape  input  shape\n\n# MultiLabelSoftMarginLoss\ninput  target  shape$(N,C)$target  0  1 SoftMarginLoss  1  -1 \n$$l=-\\frac 1 C \\sum_{i=1}^C y_i \\log \\left(\\frac 1 {1+\\exp(-x_i)}\\right )+(1-y_i)\\log \\left(\\frac {\\exp(-x_i)} {1+\\exp(-x_i)}\\right)$$\n $x, \\ y$  $C$  y  `SoftMarginLoss`  logistic \n\n tensor  shape  $(N,)$ tensor \n\n\n```python\nMultiLabelSoftMarginLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str='mean')\n```\n`weight`  shape  $(C,)$   tensor channel/ \n\n# MultiMarginLoss\ninput  2D tensor $(N,C)$target shape  $(N,)$ $y_i \\in \\{0,1,...,C-1\\}$ C  xtarget  y $x_y > x_i$ $i \\neq y$margin-based \n$$l=\\frac {\\sum_{i \\neq y} \\max(0, d-(x_y-x_i))^p} C$$\n $d$  margin $x_y \\ge x_i+d$ $d$ 0\n\np  1  2\n$$l=\\frac {\\sum_{i \\neq y} \\max[0, w_y(d-(x_y-x_i))^p]} C$$\n $w_y$ \n\n\n```python\nMultiMarginLoss(p: int=1, margin: float=1.0, weight: Optional[torch.Tensor]=None, size_average=None, reduce=None, reduction: str='mean')\n```\ninput shape  $(N,C)$target shape  $(N,)$output  shape  $(N,)$ output \n\n# TripletMarginLoss\ntensor$a, \\ p, \\ n$ anchorshape  $(N,D)$ $N$ $D$ p  a n  a  p  a n  a \n pair  $(p,a)$ $(n,a)$  $(x_1, x_2 l)$ $l=1$ $l=-1$ \n$$l=\\begin{cases} \\Vert \\mathbf x_1-\\mathbf x_2 \\Vert_2 & l=1 \\\\ \\max(0, d-\\Vert \\mathbf x_1- \\mathbf x_2\\Vert_2) & l=-1 \\end{cases}$$\n$l=1$  $\\mathbf x_1$  $\\mathbf x_2$$l=-1$ $\\mathbf x_1$  $\\mathbf x_2$ $d$ \n\n `TripletMarginLoss`  `(a,p,n)` margin ranking-based \n$$l=\\max[d(a,p) - d(a,n)+d_0, 0]$$\n$$d(\\mathbf x_1, \\mathbf x_2)=\\Vert \\mathbf x_1 - \\mathbf x_2 \\Vert_p$$\n$d_0$  margin p  p  p \n\n\n```python\nTripletMarginLoss(margin: float=1.0, p: float=2.0, eps: float=1e-06, swap: bool=False, size_average=None, reduce=None, reduction: str='mean')\n```\n`swap`  anchor  positive hard negative mining `swap=True` $d(a,n) = d(p,n)$ `(p,n)`  negative  anchor \n\nforward  anchor, positive  negative  tensorshape  $(N,D)$ tensor  shape  $(N,)$\n\n [`Learning local feature descriptors with triplets and shallow convolutional neural networks`](www.bmva.org/bmvc/2016/papers/paper119/paper119.pdf)\n\n# TripletMarginWithDistanceLoss\n`TripletMarginLoss`  p anchorpositive  negative  tensor  shape  $(N,*)$  $*$  tensor  shape  $(N,)$\n\n# HingeEmbeddingLoss\n$x$  L1 $y \\in \\{1,-1\\}$ \n$$l = \\begin{cases} x & y=1 \\\\ \\max(0, d-x) & y=-1 \\end{cases}$$\n $d$  margin\n\n x  y  shape  $(*)$ shape  $(*)$\n\n# CosineEmbeddingLoss\n`y=1` `y=-1` \n\n$$l=\\begin{cases} 1- \\cos(x_1,x_2) & y=1 \\\\ \\max[0, \\cos(x_1,x_2) - d] & y=-1 \\end{cases}$$\n $d$  margin 0\n\n# CTCLoss\n [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)\nRNN ","slug":"pytorch/loss_2","published":1,"updated":"2021-01-15T07:12:11.771Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91o003mp0dj1ylzbkon","content":"<p> <a href=\"2021/1/12/pytorch/loss_1\">loss 1</a> PyTorch <br><span id=\"more\"></span></p>\n<h1 id=\"MarginRankingLoss\"><a href=\"#MarginRankingLoss\" class=\"headerlink\" title=\"MarginRankingLoss\"></a>MarginRankingLoss</h1><p> $x_1, \\ x_2$ label  $y \\in \\{1,-1\\}$ $y=1$ $x_1$  $x_2$  $y=-1$ $x_1$  $x_2$ </p>\n<script type=\"math/tex; mode=display\">l=\\max(0, -y(x_1-x_2) + \\text{margin})</script><p> <code>margin</code> </p>\n<script type=\"math/tex; mode=display\">-y(x_1-x_2)+\\text{margin} \\le 0</script><p> $y=1$  $x_1\\ge x_2+\\text{margin}$  0</p>\n<p> $y=-1$  $x_1+\\text{margin} \\le x_2$  0</p>\n<p><b></b></p>\n<h1 id=\"MultiLabelMarginLoss\"><a href=\"#MultiLabelMarginLoss\" class=\"headerlink\" title=\"MultiLabelMarginLoss\"></a>MultiLabelMarginLoss</h1><p> or  x  2D tensorshape  $(N,C)$ $N$ $C$ target  x  shape x  target  <code>C</code> x target  y  $y=(3,0,-1,1)$ <code>0</code>  <code>3</code>  <code>MarginRankingLoss</code>  x<b></b> $\\{0,3\\}$ $x_0,\\ x_3 &gt; x_1,\\ x_2$</p>\n<script type=\"math/tex; mode=display\">l=\\sum_{i,j} \\frac {\\max[0, 1-(x_{y_j} - x_i)]} C</script><p>$j \\in \\mathcal J=\\{0,1,,k-1\\}$ $y_k&lt;0$$i \\in \\{0,1,,C-1\\}-\\{y_j|j \\in \\mathcal J\\}$ $j$  target $y_j$ i </p>\n<p>0 $1-(x_{y_j}-x_i)\\le 0 \\Rightarrow x_{y_j}\\ge 1+x_i$ $x_{y_j} \\rightarrow 0$ $x_i \\rightarrow 0$ test  x </p>\n<h1 id=\"SoftMarginLoss\"><a href=\"#SoftMarginLoss\" class=\"headerlink\" title=\"SoftMarginLoss\"></a>SoftMarginLoss</h1><p> MarginLoss  <code>max(0,x)</code>  <code>x=0</code> <code>SoftMarginLoss</code>  logistic Logistic </p>\n<script type=\"math/tex; mode=display\">\\sigma(x)=\\frac 1 {1+\\exp (-x)}</script><p> x $y\\in \\{1,-1\\}$</p>\n<script type=\"math/tex; mode=display\">\\mathcal L =\\mathbb I(y=1)f(x)+\\mathbb I(y=-1)(1-f(x))=[1+\\exp(-yx)]^{-1}</script><p> </p>\n<script type=\"math/tex; mode=display\">l= \\log(1+\\exp(-yx))</script><p> <code>SoftMarginLoss</code> <b> logistic </b> input tensor  shape  $(<em>)$ $</em>$ target  input  shape  input  shape</p>\n<h1 id=\"MultiLabelSoftMarginLoss\"><a href=\"#MultiLabelSoftMarginLoss\" class=\"headerlink\" title=\"MultiLabelSoftMarginLoss\"></a>MultiLabelSoftMarginLoss</h1><p>input  target  shape$(N,C)$target  0  1 SoftMarginLoss  1  -1 </p>\n<script type=\"math/tex; mode=display\">l=-\\frac 1 C \\sum_{i=1}^C y_i \\log \\left(\\frac 1 {1+\\exp(-x_i)}\\right )+(1-y_i)\\log \\left(\\frac {\\exp(-x_i)} {1+\\exp(-x_i)}\\right)</script><p> $x, \\ y$  $C$  y  <code>SoftMarginLoss</code>  logistic </p>\n<p> tensor  shape  $(N,)$ tensor </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MultiLabelSoftMarginLoss(weight: <span class=\"type\">Optional</span>[torch.Tensor] = <span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>weight</code>  shape  $(C,)$   tensor channel/ </p>\n<h1 id=\"MultiMarginLoss\"><a href=\"#MultiMarginLoss\" class=\"headerlink\" title=\"MultiMarginLoss\"></a>MultiMarginLoss</h1><p>input  2D tensor $(N,C)$target shape  $(N,)$ $y_i \\in \\{0,1,,C-1\\}$ C  xtarget  y $x_y &gt; x_i$ $i \\neq y$margin-based </p>\n<script type=\"math/tex; mode=display\">l=\\frac {\\sum_{i \\neq y} \\max(0, d-(x_y-x_i))^p} C</script><p> $d$  margin $x_y \\ge x_i+d$ $d$ 0</p>\n<p>p  1  2</p>\n<script type=\"math/tex; mode=display\">l=\\frac {\\sum_{i \\neq y} \\max[0, w_y(d-(x_y-x_i))^p]} C</script><p> $w_y$ </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MultiMarginLoss(p: <span class=\"built_in\">int</span>=<span class=\"number\">1</span>, margin: <span class=\"built_in\">float</span>=<span class=\"number\">1.0</span>, weight: <span class=\"type\">Optional</span>[torch.Tensor]=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br>input shape  $(N,C)$target shape  $(N,)$output  shape  $(N,)$ output </p>\n<h1 id=\"TripletMarginLoss\"><a href=\"#TripletMarginLoss\" class=\"headerlink\" title=\"TripletMarginLoss\"></a>TripletMarginLoss</h1><p>tensor$a, \\ p, \\ n$ anchorshape  $(N,D)$ $N$ $D$ p  a n  a  p  a n  a <br> pair  $(p,a)$ $(n,a)$  $(x_1, x_2 l)$ $l=1$ $l=-1$ </p>\n<script type=\"math/tex; mode=display\">l=\\begin{cases} \\Vert \\mathbf x_1-\\mathbf x_2 \\Vert_2 & l=1 \\\\ \\max(0, d-\\Vert \\mathbf x_1- \\mathbf x_2\\Vert_2) & l=-1 \\end{cases}</script><p>$l=1$  $\\mathbf x_1$  $\\mathbf x_2$$l=-1$ $\\mathbf x_1$  $\\mathbf x_2$ $d$ </p>\n<p> <code>TripletMarginLoss</code>  <code>(a,p,n)</code> margin ranking-based </p>\n<script type=\"math/tex; mode=display\">l=\\max[d(a,p) - d(a,n)+d_0, 0]</script><script type=\"math/tex; mode=display\">d(\\mathbf x_1, \\mathbf x_2)=\\Vert \\mathbf x_1 - \\mathbf x_2 \\Vert_p</script><p>$d_0$  margin p  p  p </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TripletMarginLoss(margin: <span class=\"built_in\">float</span>=<span class=\"number\">1.0</span>, p: <span class=\"built_in\">float</span>=<span class=\"number\">2.0</span>, eps: <span class=\"built_in\">float</span>=<span class=\"number\">1e-06</span>, swap: <span class=\"built_in\">bool</span>=<span class=\"literal\">False</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>swap</code>  anchor  positive hard negative mining <code>swap=True</code> $d(a,n) = d(p,n)$ <code>(p,n)</code>  negative  anchor </p>\n<p>forward  anchor, positive  negative  tensorshape  $(N,D)$ tensor  shape  $(N,)$</p>\n<p> <a href=\"www.bmva.org/bmvc/2016/papers/paper119/paper119.pdf\"><code>Learning local feature descriptors with triplets and shallow convolutional neural networks</code></a></p>\n<h1 id=\"TripletMarginWithDistanceLoss\"><a href=\"#TripletMarginWithDistanceLoss\" class=\"headerlink\" title=\"TripletMarginWithDistanceLoss\"></a>TripletMarginWithDistanceLoss</h1><p><code>TripletMarginLoss</code>  p anchorpositive  negative  tensor  shape  $(N,<em>)$  $</em>$  tensor  shape  $(N,)$</p>\n<h1 id=\"HingeEmbeddingLoss\"><a href=\"#HingeEmbeddingLoss\" class=\"headerlink\" title=\"HingeEmbeddingLoss\"></a>HingeEmbeddingLoss</h1><p>$x$  L1 $y \\in \\{1,-1\\}$ </p>\n<script type=\"math/tex; mode=display\">l = \\begin{cases} x & y=1 \\\\ \\max(0, d-x) & y=-1 \\end{cases}</script><p> $d$  margin</p>\n<p> x  y  shape  $(<em>)$ shape  $(</em>)$</p>\n<h1 id=\"CosineEmbeddingLoss\"><a href=\"#CosineEmbeddingLoss\" class=\"headerlink\" title=\"CosineEmbeddingLoss\"></a>CosineEmbeddingLoss</h1><p><code>y=1</code> <code>y=-1</code> <br></p>\n<script type=\"math/tex; mode=display\">l=\\begin{cases} 1- \\cos(x_1,x_2) & y=1 \\\\ \\max[0, \\cos(x_1,x_2) - d] & y=-1 \\end{cases}</script><p> $d$  margin 0</p>\n<h1 id=\"CTCLoss\"><a href=\"#CTCLoss\" class=\"headerlink\" title=\"CTCLoss\"></a>CTCLoss</h1><p> <a href=\"https://www.cs.toronto.edu/~graves/icml_2006.pdf\">Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</a><br>RNN </p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"2021/1/12/pytorch/loss_1\">loss 1</a> PyTorch <br>","more":"</p>\n<h1 id=\"MarginRankingLoss\"><a href=\"#MarginRankingLoss\" class=\"headerlink\" title=\"MarginRankingLoss\"></a>MarginRankingLoss</h1><p> $x_1, \\ x_2$ label  $y \\in \\{1,-1\\}$ $y=1$ $x_1$  $x_2$  $y=-1$ $x_1$  $x_2$ </p>\n<script type=\"math/tex; mode=display\">l=\\max(0, -y(x_1-x_2) + \\text{margin})</script><p> <code>margin</code> </p>\n<script type=\"math/tex; mode=display\">-y(x_1-x_2)+\\text{margin} \\le 0</script><p> $y=1$  $x_1\\ge x_2+\\text{margin}$  0</p>\n<p> $y=-1$  $x_1+\\text{margin} \\le x_2$  0</p>\n<p><b></b></p>\n<h1 id=\"MultiLabelMarginLoss\"><a href=\"#MultiLabelMarginLoss\" class=\"headerlink\" title=\"MultiLabelMarginLoss\"></a>MultiLabelMarginLoss</h1><p> or  x  2D tensorshape  $(N,C)$ $N$ $C$ target  x  shape x  target  <code>C</code> x target  y  $y=(3,0,-1,1)$ <code>0</code>  <code>3</code>  <code>MarginRankingLoss</code>  x<b></b> $\\{0,3\\}$ $x_0,\\ x_3 &gt; x_1,\\ x_2$</p>\n<script type=\"math/tex; mode=display\">l=\\sum_{i,j} \\frac {\\max[0, 1-(x_{y_j} - x_i)]} C</script><p>$j \\in \\mathcal J=\\{0,1,,k-1\\}$ $y_k&lt;0$$i \\in \\{0,1,,C-1\\}-\\{y_j|j \\in \\mathcal J\\}$ $j$  target $y_j$ i </p>\n<p>0 $1-(x_{y_j}-x_i)\\le 0 \\Rightarrow x_{y_j}\\ge 1+x_i$ $x_{y_j} \\rightarrow 0$ $x_i \\rightarrow 0$ test  x </p>\n<h1 id=\"SoftMarginLoss\"><a href=\"#SoftMarginLoss\" class=\"headerlink\" title=\"SoftMarginLoss\"></a>SoftMarginLoss</h1><p> MarginLoss  <code>max(0,x)</code>  <code>x=0</code> <code>SoftMarginLoss</code>  logistic Logistic </p>\n<script type=\"math/tex; mode=display\">\\sigma(x)=\\frac 1 {1+\\exp (-x)}</script><p> x $y\\in \\{1,-1\\}$</p>\n<script type=\"math/tex; mode=display\">\\mathcal L =\\mathbb I(y=1)f(x)+\\mathbb I(y=-1)(1-f(x))=[1+\\exp(-yx)]^{-1}</script><p> </p>\n<script type=\"math/tex; mode=display\">l= \\log(1+\\exp(-yx))</script><p> <code>SoftMarginLoss</code> <b> logistic </b> input tensor  shape  $(<em>)$ $</em>$ target  input  shape  input  shape</p>\n<h1 id=\"MultiLabelSoftMarginLoss\"><a href=\"#MultiLabelSoftMarginLoss\" class=\"headerlink\" title=\"MultiLabelSoftMarginLoss\"></a>MultiLabelSoftMarginLoss</h1><p>input  target  shape$(N,C)$target  0  1 SoftMarginLoss  1  -1 </p>\n<script type=\"math/tex; mode=display\">l=-\\frac 1 C \\sum_{i=1}^C y_i \\log \\left(\\frac 1 {1+\\exp(-x_i)}\\right )+(1-y_i)\\log \\left(\\frac {\\exp(-x_i)} {1+\\exp(-x_i)}\\right)</script><p> $x, \\ y$  $C$  y  <code>SoftMarginLoss</code>  logistic </p>\n<p> tensor  shape  $(N,)$ tensor </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MultiLabelSoftMarginLoss(weight: <span class=\"type\">Optional</span>[torch.Tensor] = <span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>weight</code>  shape  $(C,)$   tensor channel/ </p>\n<h1 id=\"MultiMarginLoss\"><a href=\"#MultiMarginLoss\" class=\"headerlink\" title=\"MultiMarginLoss\"></a>MultiMarginLoss</h1><p>input  2D tensor $(N,C)$target shape  $(N,)$ $y_i \\in \\{0,1,,C-1\\}$ C  xtarget  y $x_y &gt; x_i$ $i \\neq y$margin-based </p>\n<script type=\"math/tex; mode=display\">l=\\frac {\\sum_{i \\neq y} \\max(0, d-(x_y-x_i))^p} C</script><p> $d$  margin $x_y \\ge x_i+d$ $d$ 0</p>\n<p>p  1  2</p>\n<script type=\"math/tex; mode=display\">l=\\frac {\\sum_{i \\neq y} \\max[0, w_y(d-(x_y-x_i))^p]} C</script><p> $w_y$ </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MultiMarginLoss(p: <span class=\"built_in\">int</span>=<span class=\"number\">1</span>, margin: <span class=\"built_in\">float</span>=<span class=\"number\">1.0</span>, weight: <span class=\"type\">Optional</span>[torch.Tensor]=<span class=\"literal\">None</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br>input shape  $(N,C)$target shape  $(N,)$output  shape  $(N,)$ output </p>\n<h1 id=\"TripletMarginLoss\"><a href=\"#TripletMarginLoss\" class=\"headerlink\" title=\"TripletMarginLoss\"></a>TripletMarginLoss</h1><p>tensor$a, \\ p, \\ n$ anchorshape  $(N,D)$ $N$ $D$ p  a n  a  p  a n  a <br> pair  $(p,a)$ $(n,a)$  $(x_1, x_2 l)$ $l=1$ $l=-1$ </p>\n<script type=\"math/tex; mode=display\">l=\\begin{cases} \\Vert \\mathbf x_1-\\mathbf x_2 \\Vert_2 & l=1 \\\\ \\max(0, d-\\Vert \\mathbf x_1- \\mathbf x_2\\Vert_2) & l=-1 \\end{cases}</script><p>$l=1$  $\\mathbf x_1$  $\\mathbf x_2$$l=-1$ $\\mathbf x_1$  $\\mathbf x_2$ $d$ </p>\n<p> <code>TripletMarginLoss</code>  <code>(a,p,n)</code> margin ranking-based </p>\n<script type=\"math/tex; mode=display\">l=\\max[d(a,p) - d(a,n)+d_0, 0]</script><script type=\"math/tex; mode=display\">d(\\mathbf x_1, \\mathbf x_2)=\\Vert \\mathbf x_1 - \\mathbf x_2 \\Vert_p</script><p>$d_0$  margin p  p  p </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TripletMarginLoss(margin: <span class=\"built_in\">float</span>=<span class=\"number\">1.0</span>, p: <span class=\"built_in\">float</span>=<span class=\"number\">2.0</span>, eps: <span class=\"built_in\">float</span>=<span class=\"number\">1e-06</span>, swap: <span class=\"built_in\">bool</span>=<span class=\"literal\">False</span>, size_average=<span class=\"literal\">None</span>, reduce=<span class=\"literal\">None</span>, reduction: <span class=\"built_in\">str</span>=<span class=\"string\">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><br><code>swap</code>  anchor  positive hard negative mining <code>swap=True</code> $d(a,n) = d(p,n)$ <code>(p,n)</code>  negative  anchor </p>\n<p>forward  anchor, positive  negative  tensorshape  $(N,D)$ tensor  shape  $(N,)$</p>\n<p> <a href=\"www.bmva.org/bmvc/2016/papers/paper119/paper119.pdf\"><code>Learning local feature descriptors with triplets and shallow convolutional neural networks</code></a></p>\n<h1 id=\"TripletMarginWithDistanceLoss\"><a href=\"#TripletMarginWithDistanceLoss\" class=\"headerlink\" title=\"TripletMarginWithDistanceLoss\"></a>TripletMarginWithDistanceLoss</h1><p><code>TripletMarginLoss</code>  p anchorpositive  negative  tensor  shape  $(N,<em>)$  $</em>$  tensor  shape  $(N,)$</p>\n<h1 id=\"HingeEmbeddingLoss\"><a href=\"#HingeEmbeddingLoss\" class=\"headerlink\" title=\"HingeEmbeddingLoss\"></a>HingeEmbeddingLoss</h1><p>$x$  L1 $y \\in \\{1,-1\\}$ </p>\n<script type=\"math/tex; mode=display\">l = \\begin{cases} x & y=1 \\\\ \\max(0, d-x) & y=-1 \\end{cases}</script><p> $d$  margin</p>\n<p> x  y  shape  $(<em>)$ shape  $(</em>)$</p>\n<h1 id=\"CosineEmbeddingLoss\"><a href=\"#CosineEmbeddingLoss\" class=\"headerlink\" title=\"CosineEmbeddingLoss\"></a>CosineEmbeddingLoss</h1><p><code>y=1</code> <code>y=-1</code> <br></p>\n<script type=\"math/tex; mode=display\">l=\\begin{cases} 1- \\cos(x_1,x_2) & y=1 \\\\ \\max[0, \\cos(x_1,x_2) - d] & y=-1 \\end{cases}</script><p> $d$  margin 0</p>\n<h1 id=\"CTCLoss\"><a href=\"#CTCLoss\" class=\"headerlink\" title=\"CTCLoss\"></a>CTCLoss</h1><p> <a href=\"https://www.cs.toronto.edu/~graves/icml_2006.pdf\">Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</a><br>RNN </p>"},{"title":"PyTorch.optim","p":"pytorch/optim-1","date":"2020-01-06T06:38:40.000Z","mathjax":true,"_content":"\n# 1. Adagrad\n<!-- more -->\n## 1.1 \n `t` `i`  $\\theta_i$  $g_{t,i}$\n$$g_{t,i} = \\nabla_{\\theta}J(\\theta_{t,i})$$\nSGD \n$$\\theta_{t+1,i}=\\theta_{t,i}-\\eta \\cdot g_{t,i}$$\n $\\eta$ \n\nAdagrad \n$$\\theta_{t+1,i}=\\theta_{t,i}-\\frac {\\eta} {\\sqrt{G_{t,ii}+\\epsilon}} \\cdot g_{t,i} \\qquad(1)$$\n\n $G_t \\in \\mathbb R^{d \\times d}$  $G_{t,ii}$  $\\theta_i$  `0`  `t` \n$$G_{t,ii}=\\sum_{\\tau=0}^t g_{\\tau,i}^2 \\qquad(2)$$\n\n$\\epsilon$  0 `1e-8`\n\n (1) \n$$\\theta_{t+1}=\\theta_t - \\frac \\eta {\\sqrt {G_t+\\epsilon}} \\odot g_t \\qquad(3)$$\n\n $\\odot$ $\\eta=0.01$\n\nAdagrad \n\n Adagrad  [1]\n\n## 1.2 PyTorch \nPyTorch  Adagrad  `lr`  `eps`\n1.  `lr_decay`\n2.  `weight_decay`\n3.  `G` (2) \n\n\n\n\n$$G_0=[G,...,G]$$\n $G_0$ \n\n `t`\n\n1. \n   \n   $$g_t := g_t + \\lambda_{\\theta} \\cdot \\theta_t$$\n\n2.  \n   \n   $$\\eta := \\frac {\\eta} {1+ t \\cdot \\lambda_{\\eta}}  $$\n\n3. \n   \n   $$G_{t+1} = G_t+ g_t \\cdot g_t$$\n\n4. \n   \n   $$\\theta_{t+1} = \\theta_t - \\frac \\eta {\\sqrt{G_t} + \\epsilon}\\cdot g_t$$\n\n\n\n# 2. Adadelta\n## 2.1 \nAdadelta  Adagrad  `w`\n\n `w` \n$$E[g^2]_t = \\gamma E[g^2]_{t-1} + (1- \\gamma)g_t^2$$\n RMS `1/n` \n$$\\text{RMS}[g]_t = \\sqrt{E[g^2]_t + \\epsilon}$$\n$\\gamma$  `0.9`\n\n\n$$\\Delta \\theta_t = -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t \\qquad(4)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t$$\n\n $\\Delta \\theta$  $\\theta$  SGDmomentum  Adagrad \n$$\\Delta x  \\propto g  \\propto \\frac {\\partial f} {\\partial x} \\propto  \\frac 1 {x }$$\n `f`  `x`   $m$ `f`  `x`  $m^{-1}$ $g^2$ \n$$E[\\Delta \\theta^2]_t = \\gamma \\cdot E[\\Delta \\theta^2]_{t-1} + (1-\\gamma)\\Delta \\theta_t^2$$\n\n\n$$\\text{RMS}[\\Delta\\theta]_t=\\sqrt {E[\\Delta \\theta^2]_t+\\epsilon}$$\n $\\Delta \\theta_t$  $\\text{RMS}[\\Delta\\theta]_{t-1}$  (4)  $\\eta$\n\n\n$$\\Delta \\theta_t = -\\frac {\\text{RMS}[\\Delta\\theta]_{t-1}} {\\text{RMS}[g]_t}\\cdot g_t \\qquad(5)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t$$\n `RMS` $\\text{RMS}[\\Delta\\theta]_{t-1}$  $\\theta$  $\\text{RMS}[g]_t$  $g$  (5)  $\\Delta \\theta$  $\\theta$ \n\n## 2.2 PyTorch \nPyTorch  Adadelta  (5) \n\n# 3. RMSprop\nRMSprop  Adadelta  (4)  $\\gamma=0.9$$\\eta=0.001$ PyTorch \n\n## 3.1 PyTorch \nRMSprop  `step` \n```python\n# \nsquare_avg = state['square_avg']    #  moving average\nalpha = group['alpha']              #  gamma\n\nif group['weight_decay'] != 0:\n    grad = grad.add(group['weight_decay'], p.data)  # \n\nsquare_avg.mul_(alpha).addcmul_(1-alpha, grad, grad)    #  E[g^2]\n\nif group['centered']:               #  centered  RMSprop\n    grad_avg = state['grad_avg']    #  \n    grad_avg.mul_(alpha).add_(1-alpha, grad)    #  \n    #  RMS[g]\n    avg = square_avg.addcmul_(-1, grad_avg, grad_avg).sqrt_().add_(group['eps'])\nelse:\n    #  RMS[g]\n    avg = square_avg.sqrt_().add_(group['eps'])\n\nif group['momentum'] > 0:       # \n    buf = state['momentum_buffer']  # \n    buf.mul_(group'momentum').addcdiv_(grad, avg)   #  velocity (6) \n    p.data.add_(-group['lr'], buf)\nelse:\n    p.data.addcdiv_(-group['lr'], grad, avg)\n```\n `centered`  `momentum` (4)  `centered`  `momentum` \n### centered\n  $g$   \n$$E\\{[g-E(g)]^2\\}=E(g^2)-[E(g)]^2$$\n $E(\\cdot)$ \n$$RMS[g]=\\sqrt{E\\{[g-E(g)]^2\\}}+\\epsilon=\\sqrt{E(g^2)-[E(g)]^2}+\\epsilon$$\n\n### momentum\n SGD \n$$\\theta_{t+1}=\\theta_t - \\eta \\cdot \\nabla f(\\theta_t)$$\n momentum  SGD \n$$v_{t+1}=\\mu \\cdot v_t + \\nabla f(\\theta_t)\n\\\\\\\\\\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}$$\n\n (4)  RMSprop \n$$\\theta_{t+1}=\\theta_t -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t$$\n SGD momentum  RMSprop \n$$v_{t+1}=\\mu \\cdot v_t + \\frac {g_t} {\\text{RMS}[g]_t} \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}$$\n\n# 4. Rprop\n## 4.1 \nRprop  resilient propagation\n\n SGD  [2]\n![]()<center> 1.  `f'(x)` </center>\n     \n\nRprop \n$$\\theta_{t+1} = \\theta_t + \\Delta \\theta_t=\\theta_t - \\Delta_t \\cdot \\text{sign}[\\nabla f(\\theta_t)] \\qquad(7)$$\n $\\Delta_t$  `t`  `i`  `t`  $\\Delta_{t,i}$\n\n\n- \n- \n  \n\n$$\\Delta_t=\\begin{cases}\\min(\\Delta_{t-1} \\cdot \\eta^+, \\ \\Delta_{max}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) > 0 \\\\\\\\ \\max(\\Delta_{t-1} \\cdot \\eta^-, \\Delta_{min}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) < 0 \\\\\\\\ \\Delta_{t-1} & \\text{otherwise} \\end{cases}$$\n\n $\\eta^+ > 1 > \\eta^->0$$\\eta^+, \\ \\eta^-$  $\\Delta_{min}, \\ \\Delta_{max}$ $\\Delta_{min}$   $\\Delta_{max}$  $\\alpha$  `1.2`$\\beta$  `0.5`$\\Delta_0$  PyTorch  `0.01`\n\n [3] `Rprop+``Rprop-``iRprop+``iRprop-` `Rprop-` [3][3] `iRprop-` PyTorch  `iRprop-`\n\n# \n[1] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. John Duchi.\n\n[2] [RProp](https://florian.github.io/rprop/) \n\n[3] Improving the Rprop Learning Algorithm. Christian Igel.","source":"_posts/pytorch/optim-1.md","raw":"---\ntitle: PyTorch.optim\np: pytorch/optim-1\ndate: 2020-01-06 14:38:40\ntags: PyTorch\nmathjax: true\n---\n\n# 1. Adagrad\n<!-- more -->\n## 1.1 \n `t` `i`  $\\theta_i$  $g_{t,i}$\n$$g_{t,i} = \\nabla_{\\theta}J(\\theta_{t,i})$$\nSGD \n$$\\theta_{t+1,i}=\\theta_{t,i}-\\eta \\cdot g_{t,i}$$\n $\\eta$ \n\nAdagrad \n$$\\theta_{t+1,i}=\\theta_{t,i}-\\frac {\\eta} {\\sqrt{G_{t,ii}+\\epsilon}} \\cdot g_{t,i} \\qquad(1)$$\n\n $G_t \\in \\mathbb R^{d \\times d}$  $G_{t,ii}$  $\\theta_i$  `0`  `t` \n$$G_{t,ii}=\\sum_{\\tau=0}^t g_{\\tau,i}^2 \\qquad(2)$$\n\n$\\epsilon$  0 `1e-8`\n\n (1) \n$$\\theta_{t+1}=\\theta_t - \\frac \\eta {\\sqrt {G_t+\\epsilon}} \\odot g_t \\qquad(3)$$\n\n $\\odot$ $\\eta=0.01$\n\nAdagrad \n\n Adagrad  [1]\n\n## 1.2 PyTorch \nPyTorch  Adagrad  `lr`  `eps`\n1.  `lr_decay`\n2.  `weight_decay`\n3.  `G` (2) \n\n\n\n\n$$G_0=[G,...,G]$$\n $G_0$ \n\n `t`\n\n1. \n   \n   $$g_t := g_t + \\lambda_{\\theta} \\cdot \\theta_t$$\n\n2.  \n   \n   $$\\eta := \\frac {\\eta} {1+ t \\cdot \\lambda_{\\eta}}  $$\n\n3. \n   \n   $$G_{t+1} = G_t+ g_t \\cdot g_t$$\n\n4. \n   \n   $$\\theta_{t+1} = \\theta_t - \\frac \\eta {\\sqrt{G_t} + \\epsilon}\\cdot g_t$$\n\n\n\n# 2. Adadelta\n## 2.1 \nAdadelta  Adagrad  `w`\n\n `w` \n$$E[g^2]_t = \\gamma E[g^2]_{t-1} + (1- \\gamma)g_t^2$$\n RMS `1/n` \n$$\\text{RMS}[g]_t = \\sqrt{E[g^2]_t + \\epsilon}$$\n$\\gamma$  `0.9`\n\n\n$$\\Delta \\theta_t = -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t \\qquad(4)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t$$\n\n $\\Delta \\theta$  $\\theta$  SGDmomentum  Adagrad \n$$\\Delta x  \\propto g  \\propto \\frac {\\partial f} {\\partial x} \\propto  \\frac 1 {x }$$\n `f`  `x`   $m$ `f`  `x`  $m^{-1}$ $g^2$ \n$$E[\\Delta \\theta^2]_t = \\gamma \\cdot E[\\Delta \\theta^2]_{t-1} + (1-\\gamma)\\Delta \\theta_t^2$$\n\n\n$$\\text{RMS}[\\Delta\\theta]_t=\\sqrt {E[\\Delta \\theta^2]_t+\\epsilon}$$\n $\\Delta \\theta_t$  $\\text{RMS}[\\Delta\\theta]_{t-1}$  (4)  $\\eta$\n\n\n$$\\Delta \\theta_t = -\\frac {\\text{RMS}[\\Delta\\theta]_{t-1}} {\\text{RMS}[g]_t}\\cdot g_t \\qquad(5)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t$$\n `RMS` $\\text{RMS}[\\Delta\\theta]_{t-1}$  $\\theta$  $\\text{RMS}[g]_t$  $g$  (5)  $\\Delta \\theta$  $\\theta$ \n\n## 2.2 PyTorch \nPyTorch  Adadelta  (5) \n\n# 3. RMSprop\nRMSprop  Adadelta  (4)  $\\gamma=0.9$$\\eta=0.001$ PyTorch \n\n## 3.1 PyTorch \nRMSprop  `step` \n```python\n# \nsquare_avg = state['square_avg']    #  moving average\nalpha = group['alpha']              #  gamma\n\nif group['weight_decay'] != 0:\n    grad = grad.add(group['weight_decay'], p.data)  # \n\nsquare_avg.mul_(alpha).addcmul_(1-alpha, grad, grad)    #  E[g^2]\n\nif group['centered']:               #  centered  RMSprop\n    grad_avg = state['grad_avg']    #  \n    grad_avg.mul_(alpha).add_(1-alpha, grad)    #  \n    #  RMS[g]\n    avg = square_avg.addcmul_(-1, grad_avg, grad_avg).sqrt_().add_(group['eps'])\nelse:\n    #  RMS[g]\n    avg = square_avg.sqrt_().add_(group['eps'])\n\nif group['momentum'] > 0:       # \n    buf = state['momentum_buffer']  # \n    buf.mul_(group'momentum').addcdiv_(grad, avg)   #  velocity (6) \n    p.data.add_(-group['lr'], buf)\nelse:\n    p.data.addcdiv_(-group['lr'], grad, avg)\n```\n `centered`  `momentum` (4)  `centered`  `momentum` \n### centered\n  $g$   \n$$E\\{[g-E(g)]^2\\}=E(g^2)-[E(g)]^2$$\n $E(\\cdot)$ \n$$RMS[g]=\\sqrt{E\\{[g-E(g)]^2\\}}+\\epsilon=\\sqrt{E(g^2)-[E(g)]^2}+\\epsilon$$\n\n### momentum\n SGD \n$$\\theta_{t+1}=\\theta_t - \\eta \\cdot \\nabla f(\\theta_t)$$\n momentum  SGD \n$$v_{t+1}=\\mu \\cdot v_t + \\nabla f(\\theta_t)\n\\\\\\\\\\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}$$\n\n (4)  RMSprop \n$$\\theta_{t+1}=\\theta_t -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t$$\n SGD momentum  RMSprop \n$$v_{t+1}=\\mu \\cdot v_t + \\frac {g_t} {\\text{RMS}[g]_t} \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}$$\n\n# 4. Rprop\n## 4.1 \nRprop  resilient propagation\n\n SGD  [2]\n![]()<center> 1.  `f'(x)` </center>\n     \n\nRprop \n$$\\theta_{t+1} = \\theta_t + \\Delta \\theta_t=\\theta_t - \\Delta_t \\cdot \\text{sign}[\\nabla f(\\theta_t)] \\qquad(7)$$\n $\\Delta_t$  `t`  `i`  `t`  $\\Delta_{t,i}$\n\n\n- \n- \n  \n\n$$\\Delta_t=\\begin{cases}\\min(\\Delta_{t-1} \\cdot \\eta^+, \\ \\Delta_{max}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) > 0 \\\\\\\\ \\max(\\Delta_{t-1} \\cdot \\eta^-, \\Delta_{min}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) < 0 \\\\\\\\ \\Delta_{t-1} & \\text{otherwise} \\end{cases}$$\n\n $\\eta^+ > 1 > \\eta^->0$$\\eta^+, \\ \\eta^-$  $\\Delta_{min}, \\ \\Delta_{max}$ $\\Delta_{min}$   $\\Delta_{max}$  $\\alpha$  `1.2`$\\beta$  `0.5`$\\Delta_0$  PyTorch  `0.01`\n\n [3] `Rprop+``Rprop-``iRprop+``iRprop-` `Rprop-` [3][3] `iRprop-` PyTorch  `iRprop-`\n\n# \n[1] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. John Duchi.\n\n[2] [RProp](https://florian.github.io/rprop/) \n\n[3] Improving the Rprop Learning Algorithm. Christian Igel.","slug":"pytorch/optim-1","published":1,"updated":"2020-04-24T10:34:05.306Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91p003op0dj1brc324q","content":"<h1 id=\"1-Adagrad\"><a href=\"#1-Adagrad\" class=\"headerlink\" title=\"1. Adagrad\"></a>1. Adagrad</h1><span id=\"more\"></span>\n<h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p> <code>t</code> <code>i</code>  $\\theta_i$  $g_{t,i}$</p>\n<script type=\"math/tex; mode=display\">g_{t,i} = \\nabla_{\\theta}J(\\theta_{t,i})</script><p>SGD </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1,i}=\\theta_{t,i}-\\eta \\cdot g_{t,i}</script><p> $\\eta$ </p>\n<p>Adagrad </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1,i}=\\theta_{t,i}-\\frac {\\eta} {\\sqrt{G_{t,ii}+\\epsilon}} \\cdot g_{t,i} \\qquad(1)</script><p> $G_t \\in \\mathbb R^{d \\times d}$  $G_{t,ii}$  $\\theta_i$  <code>0</code>  <code>t</code> </p>\n<script type=\"math/tex; mode=display\">G_{t,ii}=\\sum_{\\tau=0}^t g_{\\tau,i}^2 \\qquad(2)</script><p>$\\epsilon$  0 <code>1e-8</code></p>\n<p> (1) </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac \\eta {\\sqrt {G_t+\\epsilon}} \\odot g_t \\qquad(3)</script><p> $\\odot$ $\\eta=0.01$</p>\n<p>Adagrad </p>\n<p> Adagrad  [1]</p>\n<h2 id=\"1-2-PyTorch-\"><a href=\"#1-2-PyTorch-\" class=\"headerlink\" title=\"1.2 PyTorch \"></a>1.2 PyTorch </h2><p>PyTorch  Adagrad  <code>lr</code>  <code>eps</code></p>\n<ol>\n<li> <code>lr_decay</code></li>\n<li> <code>weight_decay</code></li>\n<li> <code>G</code> (2) </li>\n</ol>\n<p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">G_0=[G,...,G]</script><p> $G_0$ </p>\n<p> <code>t</code></p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">g_t := g_t + \\lambda_{\\theta} \\cdot \\theta_t</script></li>\n<li><p> </p>\n<script type=\"math/tex; mode=display\">\\eta := \\frac {\\eta} {1+ t \\cdot \\lambda_{\\eta}}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">G_{t+1} = G_t+ g_t \\cdot g_t</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac \\eta {\\sqrt{G_t} + \\epsilon}\\cdot g_t</script></li>\n</ol>\n<p></p>\n<h1 id=\"2-Adadelta\"><a href=\"#2-Adadelta\" class=\"headerlink\" title=\"2. Adadelta\"></a>2. Adadelta</h1><h2 id=\"2-1-\"><a href=\"#2-1-\" class=\"headerlink\" title=\"2.1 \"></a>2.1 </h2><p>Adadelta  Adagrad  <code>w</code></p>\n<p> <code>w</code> </p>\n<script type=\"math/tex; mode=display\">E[g^2]_t = \\gamma E[g^2]_{t-1} + (1- \\gamma)g_t^2</script><p> RMS <code>1/n</code> </p>\n<script type=\"math/tex; mode=display\">\\text{RMS}[g]_t = \\sqrt{E[g^2]_t + \\epsilon}</script><p>$\\gamma$  <code>0.9</code></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\Delta \\theta_t = -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t \\qquad(4)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t</script><p> $\\Delta \\theta$  $\\theta$  SGDmomentum  Adagrad </p>\n<script type=\"math/tex; mode=display\">\\Delta x  \\propto g  \\propto \\frac {\\partial f} {\\partial x} \\propto  \\frac 1 {x }</script><p> <code>f</code>  <code>x</code>   $m$ <code>f</code>  <code>x</code>  $m^{-1}$ $g^2$ </p>\n<script type=\"math/tex; mode=display\">E[\\Delta \\theta^2]_t = \\gamma \\cdot E[\\Delta \\theta^2]_{t-1} + (1-\\gamma)\\Delta \\theta_t^2</script><p></p>\n<script type=\"math/tex; mode=display\">\\text{RMS}[\\Delta\\theta]_t=\\sqrt {E[\\Delta \\theta^2]_t+\\epsilon}</script><p> $\\Delta \\theta_t$  $\\text{RMS}[\\Delta\\theta]_{t-1}$  (4)  $\\eta$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\Delta \\theta_t = -\\frac {\\text{RMS}[\\Delta\\theta]_{t-1}} {\\text{RMS}[g]_t}\\cdot g_t \\qquad(5)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t</script><p> <code>RMS</code> $\\text{RMS}[\\Delta\\theta]_{t-1}$  $\\theta$  $\\text{RMS}[g]_t$  $g$  (5)  $\\Delta \\theta$  $\\theta$ </p>\n<h2 id=\"2-2-PyTorch-\"><a href=\"#2-2-PyTorch-\" class=\"headerlink\" title=\"2.2 PyTorch \"></a>2.2 PyTorch </h2><p>PyTorch  Adadelta  (5) </p>\n<h1 id=\"3-RMSprop\"><a href=\"#3-RMSprop\" class=\"headerlink\" title=\"3. RMSprop\"></a>3. RMSprop</h1><p>RMSprop  Adadelta  (4)  $\\gamma=0.9$$\\eta=0.001$ PyTorch </p>\n<h2 id=\"3-1-PyTorch-\"><a href=\"#3-1-PyTorch-\" class=\"headerlink\" title=\"3.1 PyTorch \"></a>3.1 PyTorch </h2><p>RMSprop  <code>step</code> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">square_avg = state[<span class=\"string\">&#x27;square_avg&#x27;</span>]    <span class=\"comment\">#  moving average</span></span><br><span class=\"line\">alpha = group[<span class=\"string\">&#x27;alpha&#x27;</span>]              <span class=\"comment\">#  gamma</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> group[<span class=\"string\">&#x27;weight_decay&#x27;</span>] != <span class=\"number\">0</span>:</span><br><span class=\"line\">    grad = grad.add(group[<span class=\"string\">&#x27;weight_decay&#x27;</span>], p.data)  <span class=\"comment\"># </span></span><br><span class=\"line\"></span><br><span class=\"line\">square_avg.mul_(alpha).addcmul_(<span class=\"number\">1</span>-alpha, grad, grad)    <span class=\"comment\">#  E[g^2]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> group[<span class=\"string\">&#x27;centered&#x27;</span>]:               <span class=\"comment\">#  centered  RMSprop</span></span><br><span class=\"line\">    grad_avg = state[<span class=\"string\">&#x27;grad_avg&#x27;</span>]    <span class=\"comment\">#  </span></span><br><span class=\"line\">    grad_avg.mul_(alpha).add_(<span class=\"number\">1</span>-alpha, grad)    <span class=\"comment\">#  </span></span><br><span class=\"line\">    <span class=\"comment\">#  RMS[g]</span></span><br><span class=\"line\">    avg = square_avg.addcmul_(-<span class=\"number\">1</span>, grad_avg, grad_avg).sqrt_().add_(group[<span class=\"string\">&#x27;eps&#x27;</span>])</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    <span class=\"comment\">#  RMS[g]</span></span><br><span class=\"line\">    avg = square_avg.sqrt_().add_(group[<span class=\"string\">&#x27;eps&#x27;</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> group[<span class=\"string\">&#x27;momentum&#x27;</span>] &gt; <span class=\"number\">0</span>:       <span class=\"comment\"># </span></span><br><span class=\"line\">    buf = state[<span class=\"string\">&#x27;momentum_buffer&#x27;</span>]  <span class=\"comment\"># </span></span><br><span class=\"line\">    buf.mul_(group<span class=\"string\">&#x27;momentum&#x27;</span>).addcdiv_(grad, avg)   <span class=\"comment\">#  velocity (6) </span></span><br><span class=\"line\">    p.data.add_(-group[<span class=\"string\">&#x27;lr&#x27;</span>], buf)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    p.data.addcdiv_(-group[<span class=\"string\">&#x27;lr&#x27;</span>], grad, avg)</span><br></pre></td></tr></table></figure><br> <code>centered</code>  <code>momentum</code> (4)  <code>centered</code>  <code>momentum</code> </p>\n<h3 id=\"centered\"><a href=\"#centered\" class=\"headerlink\" title=\"centered\"></a>centered</h3><p>  $g$   </p>\n<script type=\"math/tex; mode=display\">E\\{[g-E(g)]^2\\}=E(g^2)-[E(g)]^2</script><p> $E(\\cdot)$ </p>\n<script type=\"math/tex; mode=display\">RMS[g]=\\sqrt{E\\{[g-E(g)]^2\\}}+\\epsilon=\\sqrt{E(g^2)-[E(g)]^2}+\\epsilon</script><h3 id=\"momentum\"><a href=\"#momentum\" class=\"headerlink\" title=\"momentum\"></a>momentum</h3><p> SGD </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\eta \\cdot \\nabla f(\\theta_t)</script><p> momentum  SGD </p>\n<script type=\"math/tex; mode=display\">v_{t+1}=\\mu \\cdot v_t + \\nabla f(\\theta_t)\n\\\\\\\\\\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}</script><p> (4)  RMSprop </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t</script><p> SGD momentum  RMSprop </p>\n<script type=\"math/tex; mode=display\">v_{t+1}=\\mu \\cdot v_t + \\frac {g_t} {\\text{RMS}[g]_t} \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}</script><h1 id=\"4-Rprop\"><a href=\"#4-Rprop\" class=\"headerlink\" title=\"4. Rprop\"></a>4. Rprop</h1><h2 id=\"4-1-\"><a href=\"#4-1-\" class=\"headerlink\" title=\"4.1 \"></a>4.1 </h2><p>Rprop  resilient propagation</p>\n<p> SGD  [2]<br><img src=\"\" alt=\"\"><center> 1.  `f'(x)` </center><br>     </p>\n<p>Rprop </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t + \\Delta \\theta_t=\\theta_t - \\Delta_t \\cdot \\text{sign}[\\nabla f(\\theta_t)] \\qquad(7)</script><p> $\\Delta_t$  <code>t</code>  <code>i</code>  <code>t</code>  $\\Delta_{t,i}$</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<script type=\"math/tex; mode=display\">\\Delta_t=\\begin{cases}\\min(\\Delta_{t-1} \\cdot \\eta^+, \\ \\Delta_{max}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) > 0 \\\\\\\\ \\max(\\Delta_{t-1} \\cdot \\eta^-, \\Delta_{min}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) < 0 \\\\\\\\ \\Delta_{t-1} & \\text{otherwise} \\end{cases}</script><p> $\\eta^+ &gt; 1 &gt; \\eta^-&gt;0$$\\eta^+, \\ \\eta^-$  $\\Delta_{min}, \\ \\Delta_{max}$ $\\Delta_{min}$   $\\Delta_{max}$  $\\alpha$  <code>1.2</code>$\\beta$  <code>0.5</code>$\\Delta_0$  PyTorch  <code>0.01</code></p>\n<p> [3] <code>Rprop+</code><code>Rprop-</code><code>iRprop+</code><code>iRprop-</code> <code>Rprop-</code> [3][3] <code>iRprop-</code> PyTorch  <code>iRprop-</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>[1] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. John Duchi.</p>\n<p>[2] <a href=\"https://florian.github.io/rprop/\">RProp</a> </p>\n<p>[3] Improving the Rprop Learning Algorithm. Christian Igel.</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-Adagrad\"><a href=\"#1-Adagrad\" class=\"headerlink\" title=\"1. Adagrad\"></a>1. Adagrad</h1>","more":"<h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p> <code>t</code> <code>i</code>  $\\theta_i$  $g_{t,i}$</p>\n<script type=\"math/tex; mode=display\">g_{t,i} = \\nabla_{\\theta}J(\\theta_{t,i})</script><p>SGD </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1,i}=\\theta_{t,i}-\\eta \\cdot g_{t,i}</script><p> $\\eta$ </p>\n<p>Adagrad </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1,i}=\\theta_{t,i}-\\frac {\\eta} {\\sqrt{G_{t,ii}+\\epsilon}} \\cdot g_{t,i} \\qquad(1)</script><p> $G_t \\in \\mathbb R^{d \\times d}$  $G_{t,ii}$  $\\theta_i$  <code>0</code>  <code>t</code> </p>\n<script type=\"math/tex; mode=display\">G_{t,ii}=\\sum_{\\tau=0}^t g_{\\tau,i}^2 \\qquad(2)</script><p>$\\epsilon$  0 <code>1e-8</code></p>\n<p> (1) </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac \\eta {\\sqrt {G_t+\\epsilon}} \\odot g_t \\qquad(3)</script><p> $\\odot$ $\\eta=0.01$</p>\n<p>Adagrad </p>\n<p> Adagrad  [1]</p>\n<h2 id=\"1-2-PyTorch-\"><a href=\"#1-2-PyTorch-\" class=\"headerlink\" title=\"1.2 PyTorch \"></a>1.2 PyTorch </h2><p>PyTorch  Adagrad  <code>lr</code>  <code>eps</code></p>\n<ol>\n<li> <code>lr_decay</code></li>\n<li> <code>weight_decay</code></li>\n<li> <code>G</code> (2) </li>\n</ol>\n<p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">G_0=[G,...,G]</script><p> $G_0$ </p>\n<p> <code>t</code></p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">g_t := g_t + \\lambda_{\\theta} \\cdot \\theta_t</script></li>\n<li><p> </p>\n<script type=\"math/tex; mode=display\">\\eta := \\frac {\\eta} {1+ t \\cdot \\lambda_{\\eta}}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">G_{t+1} = G_t+ g_t \\cdot g_t</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac \\eta {\\sqrt{G_t} + \\epsilon}\\cdot g_t</script></li>\n</ol>\n<p></p>\n<h1 id=\"2-Adadelta\"><a href=\"#2-Adadelta\" class=\"headerlink\" title=\"2. Adadelta\"></a>2. Adadelta</h1><h2 id=\"2-1-\"><a href=\"#2-1-\" class=\"headerlink\" title=\"2.1 \"></a>2.1 </h2><p>Adadelta  Adagrad  <code>w</code></p>\n<p> <code>w</code> </p>\n<script type=\"math/tex; mode=display\">E[g^2]_t = \\gamma E[g^2]_{t-1} + (1- \\gamma)g_t^2</script><p> RMS <code>1/n</code> </p>\n<script type=\"math/tex; mode=display\">\\text{RMS}[g]_t = \\sqrt{E[g^2]_t + \\epsilon}</script><p>$\\gamma$  <code>0.9</code></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\Delta \\theta_t = -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t \\qquad(4)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t</script><p> $\\Delta \\theta$  $\\theta$  SGDmomentum  Adagrad </p>\n<script type=\"math/tex; mode=display\">\\Delta x  \\propto g  \\propto \\frac {\\partial f} {\\partial x} \\propto  \\frac 1 {x }</script><p> <code>f</code>  <code>x</code>   $m$ <code>f</code>  <code>x</code>  $m^{-1}$ $g^2$ </p>\n<script type=\"math/tex; mode=display\">E[\\Delta \\theta^2]_t = \\gamma \\cdot E[\\Delta \\theta^2]_{t-1} + (1-\\gamma)\\Delta \\theta_t^2</script><p></p>\n<script type=\"math/tex; mode=display\">\\text{RMS}[\\Delta\\theta]_t=\\sqrt {E[\\Delta \\theta^2]_t+\\epsilon}</script><p> $\\Delta \\theta_t$  $\\text{RMS}[\\Delta\\theta]_{t-1}$  (4)  $\\eta$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\Delta \\theta_t = -\\frac {\\text{RMS}[\\Delta\\theta]_{t-1}} {\\text{RMS}[g]_t}\\cdot g_t \\qquad(5)\n\\\\\\\\\\theta_{t+1}=\\theta_t + \\Delta \\theta_t</script><p> <code>RMS</code> $\\text{RMS}[\\Delta\\theta]_{t-1}$  $\\theta$  $\\text{RMS}[g]_t$  $g$  (5)  $\\Delta \\theta$  $\\theta$ </p>\n<h2 id=\"2-2-PyTorch-\"><a href=\"#2-2-PyTorch-\" class=\"headerlink\" title=\"2.2 PyTorch \"></a>2.2 PyTorch </h2><p>PyTorch  Adadelta  (5) </p>\n<h1 id=\"3-RMSprop\"><a href=\"#3-RMSprop\" class=\"headerlink\" title=\"3. RMSprop\"></a>3. RMSprop</h1><p>RMSprop  Adadelta  (4)  $\\gamma=0.9$$\\eta=0.001$ PyTorch </p>\n<h2 id=\"3-1-PyTorch-\"><a href=\"#3-1-PyTorch-\" class=\"headerlink\" title=\"3.1 PyTorch \"></a>3.1 PyTorch </h2><p>RMSprop  <code>step</code> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">square_avg = state[<span class=\"string\">&#x27;square_avg&#x27;</span>]    <span class=\"comment\">#  moving average</span></span><br><span class=\"line\">alpha = group[<span class=\"string\">&#x27;alpha&#x27;</span>]              <span class=\"comment\">#  gamma</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> group[<span class=\"string\">&#x27;weight_decay&#x27;</span>] != <span class=\"number\">0</span>:</span><br><span class=\"line\">    grad = grad.add(group[<span class=\"string\">&#x27;weight_decay&#x27;</span>], p.data)  <span class=\"comment\"># </span></span><br><span class=\"line\"></span><br><span class=\"line\">square_avg.mul_(alpha).addcmul_(<span class=\"number\">1</span>-alpha, grad, grad)    <span class=\"comment\">#  E[g^2]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> group[<span class=\"string\">&#x27;centered&#x27;</span>]:               <span class=\"comment\">#  centered  RMSprop</span></span><br><span class=\"line\">    grad_avg = state[<span class=\"string\">&#x27;grad_avg&#x27;</span>]    <span class=\"comment\">#  </span></span><br><span class=\"line\">    grad_avg.mul_(alpha).add_(<span class=\"number\">1</span>-alpha, grad)    <span class=\"comment\">#  </span></span><br><span class=\"line\">    <span class=\"comment\">#  RMS[g]</span></span><br><span class=\"line\">    avg = square_avg.addcmul_(-<span class=\"number\">1</span>, grad_avg, grad_avg).sqrt_().add_(group[<span class=\"string\">&#x27;eps&#x27;</span>])</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    <span class=\"comment\">#  RMS[g]</span></span><br><span class=\"line\">    avg = square_avg.sqrt_().add_(group[<span class=\"string\">&#x27;eps&#x27;</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> group[<span class=\"string\">&#x27;momentum&#x27;</span>] &gt; <span class=\"number\">0</span>:       <span class=\"comment\"># </span></span><br><span class=\"line\">    buf = state[<span class=\"string\">&#x27;momentum_buffer&#x27;</span>]  <span class=\"comment\"># </span></span><br><span class=\"line\">    buf.mul_(group<span class=\"string\">&#x27;momentum&#x27;</span>).addcdiv_(grad, avg)   <span class=\"comment\">#  velocity (6) </span></span><br><span class=\"line\">    p.data.add_(-group[<span class=\"string\">&#x27;lr&#x27;</span>], buf)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    p.data.addcdiv_(-group[<span class=\"string\">&#x27;lr&#x27;</span>], grad, avg)</span><br></pre></td></tr></table></figure><br> <code>centered</code>  <code>momentum</code> (4)  <code>centered</code>  <code>momentum</code> </p>\n<h3 id=\"centered\"><a href=\"#centered\" class=\"headerlink\" title=\"centered\"></a>centered</h3><p>  $g$   </p>\n<script type=\"math/tex; mode=display\">E\\{[g-E(g)]^2\\}=E(g^2)-[E(g)]^2</script><p> $E(\\cdot)$ </p>\n<script type=\"math/tex; mode=display\">RMS[g]=\\sqrt{E\\{[g-E(g)]^2\\}}+\\epsilon=\\sqrt{E(g^2)-[E(g)]^2}+\\epsilon</script><h3 id=\"momentum\"><a href=\"#momentum\" class=\"headerlink\" title=\"momentum\"></a>momentum</h3><p> SGD </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\eta \\cdot \\nabla f(\\theta_t)</script><p> momentum  SGD </p>\n<script type=\"math/tex; mode=display\">v_{t+1}=\\mu \\cdot v_t + \\nabla f(\\theta_t)\n\\\\\\\\\\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}</script><p> (4)  RMSprop </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t -\\frac \\eta {\\text{RMS}[g]_t}\\cdot g_t</script><p> SGD momentum  RMSprop </p>\n<script type=\"math/tex; mode=display\">v_{t+1}=\\mu \\cdot v_t + \\frac {g_t} {\\text{RMS}[g]_t} \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=\\theta_t - \\eta \\cdot v_{t+1}</script><h1 id=\"4-Rprop\"><a href=\"#4-Rprop\" class=\"headerlink\" title=\"4. Rprop\"></a>4. Rprop</h1><h2 id=\"4-1-\"><a href=\"#4-1-\" class=\"headerlink\" title=\"4.1 \"></a>4.1 </h2><p>Rprop  resilient propagation</p>\n<p> SGD  [2]<br><img src=\"\" alt=\"\"><center> 1.  `f'(x)` </center><br>     </p>\n<p>Rprop </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t + \\Delta \\theta_t=\\theta_t - \\Delta_t \\cdot \\text{sign}[\\nabla f(\\theta_t)] \\qquad(7)</script><p> $\\Delta_t$  <code>t</code>  <code>i</code>  <code>t</code>  $\\Delta_{t,i}$</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<script type=\"math/tex; mode=display\">\\Delta_t=\\begin{cases}\\min(\\Delta_{t-1} \\cdot \\eta^+, \\ \\Delta_{max}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) > 0 \\\\\\\\ \\max(\\Delta_{t-1} \\cdot \\eta^-, \\Delta_{min}) & \\nabla f(\\theta_t) \\cdot \\nabla f(\\theta_{t-1}) < 0 \\\\\\\\ \\Delta_{t-1} & \\text{otherwise} \\end{cases}</script><p> $\\eta^+ &gt; 1 &gt; \\eta^-&gt;0$$\\eta^+, \\ \\eta^-$  $\\Delta_{min}, \\ \\Delta_{max}$ $\\Delta_{min}$   $\\Delta_{max}$  $\\alpha$  <code>1.2</code>$\\beta$  <code>0.5</code>$\\Delta_0$  PyTorch  <code>0.01</code></p>\n<p> [3] <code>Rprop+</code><code>Rprop-</code><code>iRprop+</code><code>iRprop-</code> <code>Rprop-</code> [3][3] <code>iRprop-</code> PyTorch  <code>iRprop-</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>[1] Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. John Duchi.</p>\n<p>[2] <a href=\"https://florian.github.io/rprop/\">RProp</a> </p>\n<p>[3] Improving the Rprop Learning Algorithm. Christian Igel.</p>"},{"title":"PyTorch.optim","p":"pytorch/optim-2","date":"2020-01-08T10:19:54.000Z","mathjax":true,"_content":"\n# 1. Adam\nAdam  Adaptive Moment Estimation\n<!-- more -->\n## 1.1 \n\n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\n\\\\\\\\ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 \\qquad(1)$$\n $\\beta_1 < 1, \\ \\beta_2 < 1$$m_t$  $v_t$  $g$ $g$  $m$  $v$  0 $m_0=0, \\ v_0 = 0$ 0t $1-\\beta$ $\\beta$  1\n\n $E(g)=\\mu$$g_1, g_2, ...$  $g$ \n$$E(m_t)=E\\left(\\sum_{\\tau=1}^t \\beta_1^{t-\\tau} (1-\\beta_1) g_{\\tau}\\right)=(1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}E(g_{\\tau})=\\mu (1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}=\\mu(1-\\beta_1^t)$$ \n t  $\\beta_1 \\rightarrow 1$$E(m_t) \\rightarrow 0$\n\n\n$$\\hat m_t=\\frac {m_t} {1-\\beta_1^t}\n\\\\\\\\ \\hat v_t = \\frac {v_t} {1-\\beta_2^t}$$\n\n  `t`  `t`  $\\beta$   $1-\\beta^t$ $E(\\hat m_t)=\\mu$\n\n Adadelta  RMSprop \n$$\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t \\qquad(2)$$\n $\\eta$ \n\n## 1.2 AMSGrad \n $v$ \n$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\n\\\\\\\\ v_{t,m} = \\max\\left(v_{t-1,m}, \\ \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\right)$$\n $v_{0,m}=0$\n\n $v$ \n$$\\hat v_{t,m}=\\frac {v_{t,m}} {1-\\beta_2^t}$$\n\n$$\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_{t,m}}+\\epsilon} \\hat m_t \\qquad(3)$$\n $\\hat m_t$ \n\nAMSGrad  Adam \n\n# 2. Adamax\n Adam  (1)  $l_2$ \n$$v_t = \\beta_2^p v_{t-1} + (1-\\beta_2^p)|g_t|^p$$\n $p$ \n\n $v_{t-1}$ \n$$\\begin{aligned} v_t  &= (1-\\beta_2^p)|g_t|^p + \\beta_2^p[(1-\\beta_2^p)|g_{t-1}|^p+\\beta_2^p v_{t-2}]\n\\\\\\\\ & = (1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\n\\end{aligned}$$\n\n $p \\rightarrow \\infin$ $u_t = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p}$\n$$\\begin{aligned} u_t  = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p} &= \\lim_{p \\rightarrow \\infin}\\left((1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} (1-\\beta_2^p)^{1/p} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &=\\max (\\beta_2^{t-1}|g_1|,\\beta_2^{t-2}|g_2|,...,\\beta_2^{0}|g_t|)\\end{aligned}$$\n\n\n$$u_t = \\max(\\beta_2 u_{t-1}, \\ |g_t|)$$\n $u_0=0$\n\n $u_t$  Adam  $\\sqrt{\\hat v_t}+\\epsilon$ \n$$\\theta_{t+1} = \\theta_t - \\frac \\eta {u_t} \\hat m_t \\qquad(4)$$\n $\\hat m_t$  Adam \n\n# 3. AdamW\nAdam \n$$g := g+\\lambda \\theta$$\n $g$  $\\theta$  (2)  AdamW \n$$\\theta_{t+1}=\\theta_t - \\lambda \\eta \\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t$$\n\n# 4. Nadam\n momentum  SGD \n$$v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ \\theta_{t+1}=\\theta_t - v_{t+1}$$\n NAG  momentum  (5) (6, 7) \n$$y_t = \\theta_t + \\mu v_t  \\qquad(5)\n\\\\\\\\ g_t = \\nabla f(y_t)    \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=y_t - \\gamma g_t \\qquad(7)$$\n\n\n$$v_{t+1}=\\theta_{t+1}-\\theta_t=\\mu v_t - \\gamma g_t$$\n$t=0, \\ v_0=0 \\Rightarrow y_0=\\theta_0$\n\n [PyTorch.optim.SGD](2020/01/02/pytorch/optim_SGD)  (8)(9)(10) NAG \n$$\\begin{cases}g_t = \\nabla f(\\theta_t)\n\\\\\\\\ v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ v_{t+1}' = \\gamma v_{t+1} + \\eta g_t\n\\\\\\\\ \\theta_{t+1} = \\theta_t - v_{t+1}'\\end{cases} \\qquad(8)$$\n momentum  momentum  SGD look ahead  momentum$v_{t+1}'$  $v_{t+2}$ \n\n Adam  (2) \n$$\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\frac {m_t} {1-\\beta_1^t}\\qquad(9)$$\n $m_t$  momentum \n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$$\n momentum \n$$m_t'=\\beta_1 m_t + (1-\\beta_1) g_t$$\n (9) \n$$\\begin{aligned}\\theta_{t+1}&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {m_t'} {1-\\beta_1^t}\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {\\beta_1 m_t + (1-\\beta_1) g_t} {1-\\beta_1^t}\n\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\left(\\beta_1 \\hat m_t+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t \\right)\\end{aligned} \\qquad(10)$$\n\n(10)  Nadam \n\n\n$$\\hat m_t = \\frac {m_t} {1-\\beta_1^t}=\\frac {\\beta_1 m_{t-1} + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\frac {\\beta_1 \\hat m_{t-1}(1-\\beta_1^{t-1}) + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\beta_1 \\hat m_{t-1}+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t$$\n (10)  $m_t$  $m_t'$  $1-\\beta_1^{t+1}$ $m_t'$  $1-\\beta_1^{t+1}$\n\n\n$$\\hat m_t'=\\beta_1 \\hat m_t + \\frac {1-\\beta_1}{1-\\beta_1^t} g_t$$\n (2)  Nesterov momentum  Adam   (10)  ","source":"_posts/pytorch/optim-2.md","raw":"---\ntitle: PyTorch.optim\np: pytorch/optim-2\ndate: 2020-01-08 18:19:54\ntags: \n    - PyTorch\n    - DL\nmathjax: true\n---\n\n# 1. Adam\nAdam  Adaptive Moment Estimation\n<!-- more -->\n## 1.1 \n\n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\n\\\\\\\\ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 \\qquad(1)$$\n $\\beta_1 < 1, \\ \\beta_2 < 1$$m_t$  $v_t$  $g$ $g$  $m$  $v$  0 $m_0=0, \\ v_0 = 0$ 0t $1-\\beta$ $\\beta$  1\n\n $E(g)=\\mu$$g_1, g_2, ...$  $g$ \n$$E(m_t)=E\\left(\\sum_{\\tau=1}^t \\beta_1^{t-\\tau} (1-\\beta_1) g_{\\tau}\\right)=(1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}E(g_{\\tau})=\\mu (1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}=\\mu(1-\\beta_1^t)$$ \n t  $\\beta_1 \\rightarrow 1$$E(m_t) \\rightarrow 0$\n\n\n$$\\hat m_t=\\frac {m_t} {1-\\beta_1^t}\n\\\\\\\\ \\hat v_t = \\frac {v_t} {1-\\beta_2^t}$$\n\n  `t`  `t`  $\\beta$   $1-\\beta^t$ $E(\\hat m_t)=\\mu$\n\n Adadelta  RMSprop \n$$\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t \\qquad(2)$$\n $\\eta$ \n\n## 1.2 AMSGrad \n $v$ \n$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\n\\\\\\\\ v_{t,m} = \\max\\left(v_{t-1,m}, \\ \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\right)$$\n $v_{0,m}=0$\n\n $v$ \n$$\\hat v_{t,m}=\\frac {v_{t,m}} {1-\\beta_2^t}$$\n\n$$\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_{t,m}}+\\epsilon} \\hat m_t \\qquad(3)$$\n $\\hat m_t$ \n\nAMSGrad  Adam \n\n# 2. Adamax\n Adam  (1)  $l_2$ \n$$v_t = \\beta_2^p v_{t-1} + (1-\\beta_2^p)|g_t|^p$$\n $p$ \n\n $v_{t-1}$ \n$$\\begin{aligned} v_t  &= (1-\\beta_2^p)|g_t|^p + \\beta_2^p[(1-\\beta_2^p)|g_{t-1}|^p+\\beta_2^p v_{t-2}]\n\\\\\\\\ & = (1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\n\\end{aligned}$$\n\n $p \\rightarrow \\infin$ $u_t = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p}$\n$$\\begin{aligned} u_t  = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p} &= \\lim_{p \\rightarrow \\infin}\\left((1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} (1-\\beta_2^p)^{1/p} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &=\\max (\\beta_2^{t-1}|g_1|,\\beta_2^{t-2}|g_2|,...,\\beta_2^{0}|g_t|)\\end{aligned}$$\n\n\n$$u_t = \\max(\\beta_2 u_{t-1}, \\ |g_t|)$$\n $u_0=0$\n\n $u_t$  Adam  $\\sqrt{\\hat v_t}+\\epsilon$ \n$$\\theta_{t+1} = \\theta_t - \\frac \\eta {u_t} \\hat m_t \\qquad(4)$$\n $\\hat m_t$  Adam \n\n# 3. AdamW\nAdam \n$$g := g+\\lambda \\theta$$\n $g$  $\\theta$  (2)  AdamW \n$$\\theta_{t+1}=\\theta_t - \\lambda \\eta \\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t$$\n\n# 4. Nadam\n momentum  SGD \n$$v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ \\theta_{t+1}=\\theta_t - v_{t+1}$$\n NAG  momentum  (5) (6, 7) \n$$y_t = \\theta_t + \\mu v_t  \\qquad(5)\n\\\\\\\\ g_t = \\nabla f(y_t)    \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=y_t - \\gamma g_t \\qquad(7)$$\n\n\n$$v_{t+1}=\\theta_{t+1}-\\theta_t=\\mu v_t - \\gamma g_t$$\n$t=0, \\ v_0=0 \\Rightarrow y_0=\\theta_0$\n\n [PyTorch.optim.SGD](2020/01/02/pytorch/optim_SGD)  (8)(9)(10) NAG \n$$\\begin{cases}g_t = \\nabla f(\\theta_t)\n\\\\\\\\ v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ v_{t+1}' = \\gamma v_{t+1} + \\eta g_t\n\\\\\\\\ \\theta_{t+1} = \\theta_t - v_{t+1}'\\end{cases} \\qquad(8)$$\n momentum  momentum  SGD look ahead  momentum$v_{t+1}'$  $v_{t+2}$ \n\n Adam  (2) \n$$\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\frac {m_t} {1-\\beta_1^t}\\qquad(9)$$\n $m_t$  momentum \n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$$\n momentum \n$$m_t'=\\beta_1 m_t + (1-\\beta_1) g_t$$\n (9) \n$$\\begin{aligned}\\theta_{t+1}&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {m_t'} {1-\\beta_1^t}\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {\\beta_1 m_t + (1-\\beta_1) g_t} {1-\\beta_1^t}\n\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\left(\\beta_1 \\hat m_t+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t \\right)\\end{aligned} \\qquad(10)$$\n\n(10)  Nadam \n\n\n$$\\hat m_t = \\frac {m_t} {1-\\beta_1^t}=\\frac {\\beta_1 m_{t-1} + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\frac {\\beta_1 \\hat m_{t-1}(1-\\beta_1^{t-1}) + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\beta_1 \\hat m_{t-1}+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t$$\n (10)  $m_t$  $m_t'$  $1-\\beta_1^{t+1}$ $m_t'$  $1-\\beta_1^{t+1}$\n\n\n$$\\hat m_t'=\\beta_1 \\hat m_t + \\frac {1-\\beta_1}{1-\\beta_1^t} g_t$$\n (2)  Nesterov momentum  Adam   (10)  ","slug":"pytorch/optim-2","published":1,"updated":"2020-04-24T10:34:13.810Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91q003rp0dj1628dj5p","content":"<h1 id=\"1-Adam\"><a href=\"#1-Adam\" class=\"headerlink\" title=\"1. Adam\"></a>1. Adam</h1><p>Adam  Adaptive Moment Estimation<br><span id=\"more\"></span></p>\n<h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p></p>\n<script type=\"math/tex; mode=display\">m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\n\\\\\\\\ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 \\qquad(1)</script><p> $\\beta_1 &lt; 1, \\ \\beta_2 &lt; 1$$m_t$  $v_t$  $g$ $g$  $m$  $v$  0 $m_0=0, \\ v_0 = 0$ 0t $1-\\beta$ $\\beta$  1</p>\n<p> $E(g)=\\mu$$g_1, g_2, $  $g$ </p>\n<script type=\"math/tex; mode=display\">E(m_t)=E\\left(\\sum_{\\tau=1}^t \\beta_1^{t-\\tau} (1-\\beta_1) g_{\\tau}\\right)=(1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}E(g_{\\tau})=\\mu (1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}=\\mu(1-\\beta_1^t)</script><p> t  $\\beta_1 \\rightarrow 1$$E(m_t) \\rightarrow 0$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\hat m_t=\\frac {m_t} {1-\\beta_1^t}\n\\\\\\\\ \\hat v_t = \\frac {v_t} {1-\\beta_2^t}</script><p>  <code>t</code>  <code>t</code>  $\\beta$   $1-\\beta^t$ $E(\\hat m_t)=\\mu$</p>\n<p> Adadelta  RMSprop </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t \\qquad(2)</script><p> $\\eta$ </p>\n<h2 id=\"1-2-AMSGrad-\"><a href=\"#1-2-AMSGrad-\" class=\"headerlink\" title=\"1.2 AMSGrad \"></a>1.2 AMSGrad </h2><p> $v$ </p>\n<script type=\"math/tex; mode=display\">v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\n\\\\\\\\ v_{t,m} = \\max\\left(v_{t-1,m}, \\ \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\right)</script><p> $v_{0,m}=0$</p>\n<p> $v$ </p>\n<script type=\"math/tex; mode=display\">\\hat v_{t,m}=\\frac {v_{t,m}} {1-\\beta_2^t}</script><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_{t,m}}+\\epsilon} \\hat m_t \\qquad(3)</script><p> $\\hat m_t$ </p>\n<p>AMSGrad  Adam </p>\n<h1 id=\"2-Adamax\"><a href=\"#2-Adamax\" class=\"headerlink\" title=\"2. Adamax\"></a>2. Adamax</h1><p> Adam  (1)  $l_2$ </p>\n<script type=\"math/tex; mode=display\">v_t = \\beta_2^p v_{t-1} + (1-\\beta_2^p)|g_t|^p</script><p> $p$ </p>\n<p> $v_{t-1}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} v_t  &= (1-\\beta_2^p)|g_t|^p + \\beta_2^p[(1-\\beta_2^p)|g_{t-1}|^p+\\beta_2^p v_{t-2}]\n\\\\\\\\ & = (1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\n\\end{aligned}</script><p> $p \\rightarrow \\infin$ $u_t = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p}$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} u_t  = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p} &= \\lim_{p \\rightarrow \\infin}\\left((1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} (1-\\beta_2^p)^{1/p} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &=\\max (\\beta_2^{t-1}|g_1|,\\beta_2^{t-2}|g_2|,...,\\beta_2^{0}|g_t|)\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">u_t = \\max(\\beta_2 u_{t-1}, \\ |g_t|)</script><p> $u_0=0$</p>\n<p> $u_t$  Adam  $\\sqrt{\\hat v_t}+\\epsilon$ </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac \\eta {u_t} \\hat m_t \\qquad(4)</script><p> $\\hat m_t$  Adam </p>\n<h1 id=\"3-AdamW\"><a href=\"#3-AdamW\" class=\"headerlink\" title=\"3. AdamW\"></a>3. AdamW</h1><p>Adam </p>\n<script type=\"math/tex; mode=display\">g := g+\\lambda \\theta</script><p> $g$  $\\theta$  (2)  AdamW </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\lambda \\eta \\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t</script><h1 id=\"4-Nadam\"><a href=\"#4-Nadam\" class=\"headerlink\" title=\"4. Nadam\"></a>4. Nadam</h1><p> momentum  SGD </p>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ \\theta_{t+1}=\\theta_t - v_{t+1}</script><p> NAG  momentum  (5) (6, 7) </p>\n<script type=\"math/tex; mode=display\">y_t = \\theta_t + \\mu v_t  \\qquad(5)\n\\\\\\\\ g_t = \\nabla f(y_t)    \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=y_t - \\gamma g_t \\qquad(7)</script><p></p>\n<script type=\"math/tex; mode=display\">v_{t+1}=\\theta_{t+1}-\\theta_t=\\mu v_t - \\gamma g_t</script><p>$t=0, \\ v_0=0 \\Rightarrow y_0=\\theta_0$</p>\n<p> <a href=\"2020/01/02/pytorch/optim_SGD\">PyTorch.optim.SGD</a>  (8)(9)(10) NAG </p>\n<script type=\"math/tex; mode=display\">\\begin{cases}g_t = \\nabla f(\\theta_t)\n\\\\\\\\ v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ v_{t+1}' = \\gamma v_{t+1} + \\eta g_t\n\\\\\\\\ \\theta_{t+1} = \\theta_t - v_{t+1}'\\end{cases} \\qquad(8)</script><p> momentum  momentum  SGD look ahead  momentum$v_{t+1}$  $v_{t+2}$ </p>\n<p> Adam  (2) </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\frac {m_t} {1-\\beta_1^t}\\qquad(9)</script><p> $m_t$  momentum </p>\n<script type=\"math/tex; mode=display\">m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t</script><p> momentum </p>\n<script type=\"math/tex; mode=display\">m_t'=\\beta_1 m_t + (1-\\beta_1) g_t</script><p> (9) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\theta_{t+1}&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {m_t'} {1-\\beta_1^t}\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {\\beta_1 m_t + (1-\\beta_1) g_t} {1-\\beta_1^t}\n\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\left(\\beta_1 \\hat m_t+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t \\right)\\end{aligned} \\qquad(10)</script><p>(10)  Nadam </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\hat m_t = \\frac {m_t} {1-\\beta_1^t}=\\frac {\\beta_1 m_{t-1} + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\frac {\\beta_1 \\hat m_{t-1}(1-\\beta_1^{t-1}) + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\beta_1 \\hat m_{t-1}+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t</script><p> (10)  $m_t$  $m_t$  $1-\\beta_1^{t+1}$ $m_t$  $1-\\beta_1^{t+1}$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\hat m_t'=\\beta_1 \\hat m_t + \\frac {1-\\beta_1}{1-\\beta_1^t} g_t</script><p> (2)  Nesterov momentum  Adam   (10)  </p>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-Adam\"><a href=\"#1-Adam\" class=\"headerlink\" title=\"1. Adam\"></a>1. Adam</h1><p>Adam  Adaptive Moment Estimation<br>","more":"</p>\n<h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p></p>\n<script type=\"math/tex; mode=display\">m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\n\\\\\\\\ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 \\qquad(1)</script><p> $\\beta_1 &lt; 1, \\ \\beta_2 &lt; 1$$m_t$  $v_t$  $g$ $g$  $m$  $v$  0 $m_0=0, \\ v_0 = 0$ 0t $1-\\beta$ $\\beta$  1</p>\n<p> $E(g)=\\mu$$g_1, g_2, $  $g$ </p>\n<script type=\"math/tex; mode=display\">E(m_t)=E\\left(\\sum_{\\tau=1}^t \\beta_1^{t-\\tau} (1-\\beta_1) g_{\\tau}\\right)=(1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}E(g_{\\tau})=\\mu (1-\\beta_1)\\sum_{\\tau=1}^t \\beta_1^{t-\\tau}=\\mu(1-\\beta_1^t)</script><p> t  $\\beta_1 \\rightarrow 1$$E(m_t) \\rightarrow 0$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\hat m_t=\\frac {m_t} {1-\\beta_1^t}\n\\\\\\\\ \\hat v_t = \\frac {v_t} {1-\\beta_2^t}</script><p>  <code>t</code>  <code>t</code>  $\\beta$   $1-\\beta^t$ $E(\\hat m_t)=\\mu$</p>\n<p> Adadelta  RMSprop </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t \\qquad(2)</script><p> $\\eta$ </p>\n<h2 id=\"1-2-AMSGrad-\"><a href=\"#1-2-AMSGrad-\" class=\"headerlink\" title=\"1.2 AMSGrad \"></a>1.2 AMSGrad </h2><p> $v$ </p>\n<script type=\"math/tex; mode=display\">v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\n\\\\\\\\ v_{t,m} = \\max\\left(v_{t-1,m}, \\ \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\right)</script><p> $v_{0,m}=0$</p>\n<p> $v$ </p>\n<script type=\"math/tex; mode=display\">\\hat v_{t,m}=\\frac {v_{t,m}} {1-\\beta_2^t}</script><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_{t,m}}+\\epsilon} \\hat m_t \\qquad(3)</script><p> $\\hat m_t$ </p>\n<p>AMSGrad  Adam </p>\n<h1 id=\"2-Adamax\"><a href=\"#2-Adamax\" class=\"headerlink\" title=\"2. Adamax\"></a>2. Adamax</h1><p> Adam  (1)  $l_2$ </p>\n<script type=\"math/tex; mode=display\">v_t = \\beta_2^p v_{t-1} + (1-\\beta_2^p)|g_t|^p</script><p> $p$ </p>\n<p> $v_{t-1}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} v_t  &= (1-\\beta_2^p)|g_t|^p + \\beta_2^p[(1-\\beta_2^p)|g_{t-1}|^p+\\beta_2^p v_{t-2}]\n\\\\\\\\ & = (1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\n\\end{aligned}</script><p> $p \\rightarrow \\infin$ $u_t = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p}$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} u_t  = \\lim_{p \\rightarrow \\infin}(v_t)^{1/p} &= \\lim_{p \\rightarrow \\infin}\\left((1-\\beta_2^p)\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} (1-\\beta_2^p)^{1/p} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &= \\lim_{p \\rightarrow \\infin} \\left(\\sum_{i=1}^t \\beta_2^{p(t-i)} |g_i|^p\\right)^{1/p}\n\\\\\\\\ &=\\max (\\beta_2^{t-1}|g_1|,\\beta_2^{t-2}|g_2|,...,\\beta_2^{0}|g_t|)\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">u_t = \\max(\\beta_2 u_{t-1}, \\ |g_t|)</script><p> $u_0=0$</p>\n<p> $u_t$  Adam  $\\sqrt{\\hat v_t}+\\epsilon$ </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac \\eta {u_t} \\hat m_t \\qquad(4)</script><p> $\\hat m_t$  Adam </p>\n<h1 id=\"3-AdamW\"><a href=\"#3-AdamW\" class=\"headerlink\" title=\"3. AdamW\"></a>3. AdamW</h1><p>Adam </p>\n<script type=\"math/tex; mode=display\">g := g+\\lambda \\theta</script><p> $g$  $\\theta$  (2)  AdamW </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\lambda \\eta \\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\hat m_t</script><h1 id=\"4-Nadam\"><a href=\"#4-Nadam\" class=\"headerlink\" title=\"4. Nadam\"></a>4. Nadam</h1><p> momentum  SGD </p>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ \\theta_{t+1}=\\theta_t - v_{t+1}</script><p> NAG  momentum  (5) (6, 7) </p>\n<script type=\"math/tex; mode=display\">y_t = \\theta_t + \\mu v_t  \\qquad(5)\n\\\\\\\\ g_t = \\nabla f(y_t)    \\qquad(6)\n\\\\\\\\ \\theta_{t+1}=y_t - \\gamma g_t \\qquad(7)</script><p></p>\n<script type=\"math/tex; mode=display\">v_{t+1}=\\theta_{t+1}-\\theta_t=\\mu v_t - \\gamma g_t</script><p>$t=0, \\ v_0=0 \\Rightarrow y_0=\\theta_0$</p>\n<p> <a href=\"2020/01/02/pytorch/optim_SGD\">PyTorch.optim.SGD</a>  (8)(9)(10) NAG </p>\n<script type=\"math/tex; mode=display\">\\begin{cases}g_t = \\nabla f(\\theta_t)\n\\\\\\\\ v_{t+1} = \\gamma v_t + \\eta g_t\n\\\\\\\\ v_{t+1}' = \\gamma v_{t+1} + \\eta g_t\n\\\\\\\\ \\theta_{t+1} = \\theta_t - v_{t+1}'\\end{cases} \\qquad(8)</script><p> momentum  momentum  SGD look ahead  momentum$v_{t+1}$  $v_{t+2}$ </p>\n<p> Adam  (2) </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t - \\frac {\\eta} {\\sqrt{\\hat v_t}+\\epsilon} \\frac {m_t} {1-\\beta_1^t}\\qquad(9)</script><p> $m_t$  momentum </p>\n<script type=\"math/tex; mode=display\">m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t</script><p> momentum </p>\n<script type=\"math/tex; mode=display\">m_t'=\\beta_1 m_t + (1-\\beta_1) g_t</script><p> (9) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\theta_{t+1}&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {m_t'} {1-\\beta_1^t}\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\frac {\\beta_1 m_t + (1-\\beta_1) g_t} {1-\\beta_1^t}\n\\\\\\\\&=\\theta_t - \\frac \\eta {\\sqrt {\\hat v_t} + \\epsilon}\\left(\\beta_1 \\hat m_t+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t \\right)\\end{aligned} \\qquad(10)</script><p>(10)  Nadam </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\hat m_t = \\frac {m_t} {1-\\beta_1^t}=\\frac {\\beta_1 m_{t-1} + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\frac {\\beta_1 \\hat m_{t-1}(1-\\beta_1^{t-1}) + (1-\\beta_1) g_t} {1-\\beta_1^t}=\\beta_1 \\hat m_{t-1}+\\frac {1-\\beta_1}{1-\\beta_1^t} g_t</script><p> (10)  $m_t$  $m_t$  $1-\\beta_1^{t+1}$ $m_t$  $1-\\beta_1^{t+1}$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\hat m_t'=\\beta_1 \\hat m_t + \\frac {1-\\beta_1}{1-\\beta_1^t} g_t</script><p> (2)  Nesterov momentum  Adam   (10)  </p>"},{"title":"PyTorch.optim.SGD","p":"pytorch/optim_SGD","date":"2020-01-02T08:25:32.000Z","mathjax":true,"_content":"\n# 1. SGD\n<!-- more -->\n\n## 1.1 weight decay\nMSE  CE  $L_0$\n\n$$L=L_0+\\frac 1 2 \\lambda \\cdot \\|\\mathbf \\theta\\|_2^2$$\n 1 \n![](/images/pytorch/overfitting.png) <center> 1 Deep Learning with PyTorch</center>\n $\\mathbf \\theta$  $|\\mathbf \\theta_i|$  $\\lambda$  `weight decay`\n$$\\frac {\\partial L}{\\partial \\mathbf \\theta_i}=\\frac {\\partial L_0}{\\partial \\mathbf \\theta_i}+\\lambda \\cdot \\mathbf \\theta_i$$\n\n## 1.2 momentum\n SGD  2  momentum  SGD \n$$\\theta_{t+1} = \\theta_t -\\epsilon \\cdot d\\theta_t$$\n momentum \n$$\\begin{aligned} v_{t+1} & = \\mu \\cdot v_t + d\\theta_t\n\\\\\\\\ \\theta_{t+1} &= \\theta_t - \\epsilon \\cdot v_{t+1}=\\theta_t-\\epsilon \\cdot \\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t \\end{aligned} \\qquad(1)$$\n $\\theta_0$ $v_0=0$$\\epsilon$ $\\mu$  momentum  velocityv   2 velocity \n![](/images/pytorch/momentum.png) <center> 2</center>\n\n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - d\\theta_t\n\\\\\\\\\\theta_{t+1}&=\\theta_t+\\epsilon \\cdot v_{t+1}=\\theta_t +\\epsilon \\cdot \\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t \\end{aligned}\\qquad(2)$$\n $v_0=0$ \n\ncaffe  Sutskever. [1] \n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t + \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t - v_{t+1}=\\theta_t-\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3)$$\n\n \n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + v_{t+1}=\\theta_t+\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3')$$\n\n $\\epsilon$  $v_0=0$ (3)  $v_{t+1}$  (1)  $\\epsilon$ \n$$\\begin{aligned}v_1^{(3)}&=\\epsilon \\cdot d\\theta_0 = \\epsilon \\cdot v_1^{(1)}\n\\\\\\\\ v_2^{(3)}& = \\mu \\cdot v_1^{(3)}+\\epsilon \\cdot d\\theta_1=\\epsilon \\cdot [\\mu \\cdot v_1^{(1)}+d\\theta_1]=\\epsilon \\cdot v_2^{(1)}\n\\\\\\\\ &\\cdots \\end{aligned}$$\n\n (1)  $\\theta_{t+1}$  $v_{t+1}$  $\\epsilon$ (1)  (3) : 1. $v_0=0$2.  $\\epsilon$ \n\n epoch  10% (1)  (3)   t+1  $\\epsilon$  $\\epsilon_1, \\ \\epsilon_2$ $\\epsilon_2 = 0.1 \\epsilon_1$\n$$\\begin{aligned}v_t^{(3)} &= \\epsilon_1 \\cdot v_t^{(1)}\n\\\\\\\\ \\theta_{t+1}^{(3)}&=\\theta_t- \\mu \\cdot v_t^{(3)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t- \\epsilon_1 \\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}^{(1)}&=\\theta_t-\\epsilon_2\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t-0.1\\epsilon_1\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\\end{aligned}$$\n\n(1)  (3)  velocity (3)  velocity  $\\epsilon_2 \\cdot d\\theta$  $v_t^{(3)}$ \n$$\\begin{aligned} v_{t+n}&=\\mu \\cdot v_{t+n-1}+\\epsilon_2 d\\theta_{t+n-1}\\\\\\\\ &=\\mu^2 \\cdot v_{t+n-2}+\\mu \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-2}+\\epsilon_2 \\cdot d\\theta_{t+n-1}\n\\\\\\\\&=\\cdots\n\\\\\\\\&=\\mu^n \\cdot v_t + \\mu^{n-1} \\cdot \\epsilon_2 \\cdot d\\theta_{t}+\\mu^{n-2} \\cdot \\epsilon_2 \\cdot  d\\theta_{t+1} + \\cdots + \\mu^0 \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-1}\\end{aligned}$$\n $\\mu <1$ $n$  $v_t$  velocity \n\n### 1.2.1 dampening\n\n PyTorch [](https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71) `dampening` momentum  (1)  velocity \n$$v_{t+1} = \\mu \\cdot v_t + \\text{dampening} \\cdot d\\theta_t$$\n $v_{t+1} = \\mu \\cdot v_t + (1-\\mu) \\cdot d\\theta_t$ $0 \\le \\mu < 1$ $v_{t+1}$  $\\min (v_t, d\\theta_t)$  $\\max (v_t, d\\theta_t)$ `dampening`  `0`\n\n## 1.3 Nesterov\n momentum  (1) (3)  PyTorch [](https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71)  [](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)  (3')  $v_{t+1}$ \n$$\\theta_{t+1}=\\theta_t+v_{t+1}$$\n$v_{t+1}$  momentumNAG (Nesterov Accelerated Gradient) \n\n### 1.3.1  momentumCE\n\n momentum  2\n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + \\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\\end{aligned}$$\n\n### 1.3.2 NAG\nNAG \n1. \n   \n   $$\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t) \\qquad(4)$$\n2. momentum\n   \n   $$ y_{t+1}=\\theta_{t+1} + \\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t) \\qquad(5)$$\n   \n $y_0=\\theta_0$\n\nNAG  $y$  $\\theta$  $y$ $y$  $\\theta$  $\\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t)$  3\n![](/images/pytorch/NAS_0.png) <center> 3. NAG </center>\n $\\mu \\equiv 0$NAG  SD\n\n\n $\\mu, \\ \\epsilon$  velocity \n\n\n### 1.3.3 Sutskever Nesterov Momentum\nNAG  $\\theta$  momentum  NAG  velocity  NAG  `momentum-GD-momentum-GD-...` \n\n\n$$y_t=\\theta_t+\\mu_t \\cdot(\\theta_t-\\theta_{t-1})$$\n\n\n$$y_t=\\theta_t + \\mu_t \\cdot v_t$$\n\n (4)  $y_t$(4)  t  Sutskever Nesterov Momentum  t-1  momentum  $\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t)$ $y_t$ \n$$\\theta_{t+1} = \\theta_t+\\mu_t \\cdot v_t-\\epsilon_t \\cdot \\nabla f(\\theta_t + \\mu_t \\cdot v_t) \\qquad(6)$$\n\n\n\n$$v_{t+1} = \\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\theta_t+\\mu_t \\cdot v_t)  \\qquad(7) $$\n\n 4  momentum  NAG \n![](/images/pytorch/NAG.png) <center> 4 </center>\n\n\n### 1.3.4 Bengio Nesterov Momentum\nNAG  $\\theta$ $y$ $y$  $\\theta$  momentum\n\n momentum  $\\theta$  momentum \n\n$$\\Theta_{t-1}=\\theta_{t-1} + \\mu_{t-1} \\cdot v_{t-1}$$\n $\\theta$ $\\Theta$ $\\theta_0$$\\Theta$ $\\theta$ \n\n\n velocity  (7) \n$$v_t=\\mu_{t-1} \\cdot v_{t-1} - \\epsilon_{t-1} \\cdot \\nabla f(\\Theta_{t-1})$$\n\n$v_t$  $\\theta$ \n\n $\\Theta$ \n$$\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}= \\theta_{t+1}\n\\\\\\\\ \\Theta_t-\\mu_t \\cdot v_t= \\theta_t$$\n (6) \n$$\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}=\\Theta_t-\\mu_t \\cdot v_t+\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n\n$$\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot v_{t+1}-\\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n\n (7) \n$$\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot[\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)]-\\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n\n\n$$\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t) \\qquad(8)$$\n\n $\\Theta_{t+1}=\\Theta_t + V_{t+1}$ \n$$V_{t+1}=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n  $\\Theta$  `(3')`  $v_{t+1}$ (1)  $v_{t+1}$  $\\epsilon$ $-$  $+$ \n$$\\begin{aligned} V_{t+1}&=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t+\\mu_{t+1} \\cdot \\nabla f(\\Theta_t)+ \\nabla f(\\Theta_t) \n\\\\\\\\ &=\\mu_{t+1} \\cdot [\\mu_t \\cdot v_t+ \\nabla f(\\Theta_t)] + \\nabla f(\\Theta_t)  \\end{aligned} \\qquad(9)$$\n $\\Theta$ \n$$\\Theta_{t+1}=\\Theta_t - \\epsilon_t \\cdot V_{t+1} \\qquad(10)$$\n\n__(9)  (10)  PyTorch  `SGD.step`  `nesterov=True` __\n\n\n# \n\n[1] On the importance of initialization and momentum in deep learning. Ilya Sutskever\n\n[2] [Nesterov Accelerated Gradient and Momentum](https://jlmelville.github.io/mize/mesterov.html)\n\n# \n[1] [ORF523: Nesterov's Accelerated Gradient Descent](https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/)","source":"_posts/pytorch/optim_SGD.md","raw":"---\ntitle: PyTorch.optim.SGD\np: pytorch/optim_SGD\ndate: 2020-01-02 16:25:32\ntags: PyTorch\nmathjax: true\n---\n\n# 1. SGD\n<!-- more -->\n\n## 1.1 weight decay\nMSE  CE  $L_0$\n\n$$L=L_0+\\frac 1 2 \\lambda \\cdot \\|\\mathbf \\theta\\|_2^2$$\n 1 \n![](/images/pytorch/overfitting.png) <center> 1 Deep Learning with PyTorch</center>\n $\\mathbf \\theta$  $|\\mathbf \\theta_i|$  $\\lambda$  `weight decay`\n$$\\frac {\\partial L}{\\partial \\mathbf \\theta_i}=\\frac {\\partial L_0}{\\partial \\mathbf \\theta_i}+\\lambda \\cdot \\mathbf \\theta_i$$\n\n## 1.2 momentum\n SGD  2  momentum  SGD \n$$\\theta_{t+1} = \\theta_t -\\epsilon \\cdot d\\theta_t$$\n momentum \n$$\\begin{aligned} v_{t+1} & = \\mu \\cdot v_t + d\\theta_t\n\\\\\\\\ \\theta_{t+1} &= \\theta_t - \\epsilon \\cdot v_{t+1}=\\theta_t-\\epsilon \\cdot \\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t \\end{aligned} \\qquad(1)$$\n $\\theta_0$ $v_0=0$$\\epsilon$ $\\mu$  momentum  velocityv   2 velocity \n![](/images/pytorch/momentum.png) <center> 2</center>\n\n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - d\\theta_t\n\\\\\\\\\\theta_{t+1}&=\\theta_t+\\epsilon \\cdot v_{t+1}=\\theta_t +\\epsilon \\cdot \\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t \\end{aligned}\\qquad(2)$$\n $v_0=0$ \n\ncaffe  Sutskever. [1] \n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t + \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t - v_{t+1}=\\theta_t-\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3)$$\n\n \n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + v_{t+1}=\\theta_t+\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3')$$\n\n $\\epsilon$  $v_0=0$ (3)  $v_{t+1}$  (1)  $\\epsilon$ \n$$\\begin{aligned}v_1^{(3)}&=\\epsilon \\cdot d\\theta_0 = \\epsilon \\cdot v_1^{(1)}\n\\\\\\\\ v_2^{(3)}& = \\mu \\cdot v_1^{(3)}+\\epsilon \\cdot d\\theta_1=\\epsilon \\cdot [\\mu \\cdot v_1^{(1)}+d\\theta_1]=\\epsilon \\cdot v_2^{(1)}\n\\\\\\\\ &\\cdots \\end{aligned}$$\n\n (1)  $\\theta_{t+1}$  $v_{t+1}$  $\\epsilon$ (1)  (3) : 1. $v_0=0$2.  $\\epsilon$ \n\n epoch  10% (1)  (3)   t+1  $\\epsilon$  $\\epsilon_1, \\ \\epsilon_2$ $\\epsilon_2 = 0.1 \\epsilon_1$\n$$\\begin{aligned}v_t^{(3)} &= \\epsilon_1 \\cdot v_t^{(1)}\n\\\\\\\\ \\theta_{t+1}^{(3)}&=\\theta_t- \\mu \\cdot v_t^{(3)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t- \\epsilon_1 \\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}^{(1)}&=\\theta_t-\\epsilon_2\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t-0.1\\epsilon_1\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\\end{aligned}$$\n\n(1)  (3)  velocity (3)  velocity  $\\epsilon_2 \\cdot d\\theta$  $v_t^{(3)}$ \n$$\\begin{aligned} v_{t+n}&=\\mu \\cdot v_{t+n-1}+\\epsilon_2 d\\theta_{t+n-1}\\\\\\\\ &=\\mu^2 \\cdot v_{t+n-2}+\\mu \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-2}+\\epsilon_2 \\cdot d\\theta_{t+n-1}\n\\\\\\\\&=\\cdots\n\\\\\\\\&=\\mu^n \\cdot v_t + \\mu^{n-1} \\cdot \\epsilon_2 \\cdot d\\theta_{t}+\\mu^{n-2} \\cdot \\epsilon_2 \\cdot  d\\theta_{t+1} + \\cdots + \\mu^0 \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-1}\\end{aligned}$$\n $\\mu <1$ $n$  $v_t$  velocity \n\n### 1.2.1 dampening\n\n PyTorch [](https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71) `dampening` momentum  (1)  velocity \n$$v_{t+1} = \\mu \\cdot v_t + \\text{dampening} \\cdot d\\theta_t$$\n $v_{t+1} = \\mu \\cdot v_t + (1-\\mu) \\cdot d\\theta_t$ $0 \\le \\mu < 1$ $v_{t+1}$  $\\min (v_t, d\\theta_t)$  $\\max (v_t, d\\theta_t)$ `dampening`  `0`\n\n## 1.3 Nesterov\n momentum  (1) (3)  PyTorch [](https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71)  [](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)  (3')  $v_{t+1}$ \n$$\\theta_{t+1}=\\theta_t+v_{t+1}$$\n$v_{t+1}$  momentumNAG (Nesterov Accelerated Gradient) \n\n### 1.3.1  momentumCE\n\n momentum  2\n$$\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + \\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\\end{aligned}$$\n\n### 1.3.2 NAG\nNAG \n1. \n   \n   $$\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t) \\qquad(4)$$\n2. momentum\n   \n   $$ y_{t+1}=\\theta_{t+1} + \\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t) \\qquad(5)$$\n   \n $y_0=\\theta_0$\n\nNAG  $y$  $\\theta$  $y$ $y$  $\\theta$  $\\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t)$  3\n![](/images/pytorch/NAS_0.png) <center> 3. NAG </center>\n $\\mu \\equiv 0$NAG  SD\n\n\n $\\mu, \\ \\epsilon$  velocity \n\n\n### 1.3.3 Sutskever Nesterov Momentum\nNAG  $\\theta$  momentum  NAG  velocity  NAG  `momentum-GD-momentum-GD-...` \n\n\n$$y_t=\\theta_t+\\mu_t \\cdot(\\theta_t-\\theta_{t-1})$$\n\n\n$$y_t=\\theta_t + \\mu_t \\cdot v_t$$\n\n (4)  $y_t$(4)  t  Sutskever Nesterov Momentum  t-1  momentum  $\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t)$ $y_t$ \n$$\\theta_{t+1} = \\theta_t+\\mu_t \\cdot v_t-\\epsilon_t \\cdot \\nabla f(\\theta_t + \\mu_t \\cdot v_t) \\qquad(6)$$\n\n\n\n$$v_{t+1} = \\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\theta_t+\\mu_t \\cdot v_t)  \\qquad(7) $$\n\n 4  momentum  NAG \n![](/images/pytorch/NAG.png) <center> 4 </center>\n\n\n### 1.3.4 Bengio Nesterov Momentum\nNAG  $\\theta$ $y$ $y$  $\\theta$  momentum\n\n momentum  $\\theta$  momentum \n\n$$\\Theta_{t-1}=\\theta_{t-1} + \\mu_{t-1} \\cdot v_{t-1}$$\n $\\theta$ $\\Theta$ $\\theta_0$$\\Theta$ $\\theta$ \n\n\n velocity  (7) \n$$v_t=\\mu_{t-1} \\cdot v_{t-1} - \\epsilon_{t-1} \\cdot \\nabla f(\\Theta_{t-1})$$\n\n$v_t$  $\\theta$ \n\n $\\Theta$ \n$$\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}= \\theta_{t+1}\n\\\\\\\\ \\Theta_t-\\mu_t \\cdot v_t= \\theta_t$$\n (6) \n$$\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}=\\Theta_t-\\mu_t \\cdot v_t+\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n\n$$\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot v_{t+1}-\\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n\n (7) \n$$\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot[\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)]-\\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n\n\n$$\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t) \\qquad(8)$$\n\n $\\Theta_{t+1}=\\Theta_t + V_{t+1}$ \n$$V_{t+1}=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t)$$\n  $\\Theta$  `(3')`  $v_{t+1}$ (1)  $v_{t+1}$  $\\epsilon$ $-$  $+$ \n$$\\begin{aligned} V_{t+1}&=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t+\\mu_{t+1} \\cdot \\nabla f(\\Theta_t)+ \\nabla f(\\Theta_t) \n\\\\\\\\ &=\\mu_{t+1} \\cdot [\\mu_t \\cdot v_t+ \\nabla f(\\Theta_t)] + \\nabla f(\\Theta_t)  \\end{aligned} \\qquad(9)$$\n $\\Theta$ \n$$\\Theta_{t+1}=\\Theta_t - \\epsilon_t \\cdot V_{t+1} \\qquad(10)$$\n\n__(9)  (10)  PyTorch  `SGD.step`  `nesterov=True` __\n\n\n# \n\n[1] On the importance of initialization and momentum in deep learning. Ilya Sutskever\n\n[2] [Nesterov Accelerated Gradient and Momentum](https://jlmelville.github.io/mize/mesterov.html)\n\n# \n[1] [ORF523: Nesterov's Accelerated Gradient Descent](https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/)","slug":"pytorch/optim_SGD","published":1,"updated":"2020-04-24T10:33:35.048Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91r003tp0dja8k7hvdq","content":"<h1 id=\"1-SGD\"><a href=\"#1-SGD\" class=\"headerlink\" title=\"1. SGD\"></a>1. SGD</h1><span id=\"more\"></span>\n<h2 id=\"1-1-weight-decay\"><a href=\"#1-1-weight-decay\" class=\"headerlink\" title=\"1.1 weight decay\"></a>1.1 weight decay</h2><p>MSE  CE  $L_0$</p>\n<script type=\"math/tex; mode=display\">L=L_0+\\frac 1 2 \\lambda \\cdot \\|\\mathbf \\theta\\|_2^2</script><p> 1 <br><img src=\"/images/pytorch/overfitting.png\" alt=\"\"> <center> 1 Deep Learning with PyTorch</center><br> $\\mathbf \\theta$  $|\\mathbf \\theta_i|$  $\\lambda$  <code>weight decay</code></p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L}{\\partial \\mathbf \\theta_i}=\\frac {\\partial L_0}{\\partial \\mathbf \\theta_i}+\\lambda \\cdot \\mathbf \\theta_i</script><h2 id=\"1-2-momentum\"><a href=\"#1-2-momentum\" class=\"headerlink\" title=\"1.2 momentum\"></a>1.2 momentum</h2><p> SGD  2  momentum  SGD </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t -\\epsilon \\cdot d\\theta_t</script><p> momentum </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} v_{t+1} & = \\mu \\cdot v_t + d\\theta_t\n\\\\\\\\ \\theta_{t+1} &= \\theta_t - \\epsilon \\cdot v_{t+1}=\\theta_t-\\epsilon \\cdot \\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t \\end{aligned} \\qquad(1)</script><p> $\\theta_0$ $v_0=0$$\\epsilon$ $\\mu$  momentum  velocityv   2 velocity <br><img src=\"/images/pytorch/momentum.png\" alt=\"\"> <center> 2</center><br></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - d\\theta_t\n\\\\\\\\\\theta_{t+1}&=\\theta_t+\\epsilon \\cdot v_{t+1}=\\theta_t +\\epsilon \\cdot \\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t \\end{aligned}\\qquad(2)</script><p> $v_0=0$ </p>\n<p>caffe  Sutskever. [1] </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t + \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t - v_{t+1}=\\theta_t-\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3)</script><p> </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + v_{t+1}=\\theta_t+\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3')</script><p> $\\epsilon$  $v_0=0$ (3)  $v_{t+1}$  (1)  $\\epsilon$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_1^{(3)}&=\\epsilon \\cdot d\\theta_0 = \\epsilon \\cdot v_1^{(1)}\n\\\\\\\\ v_2^{(3)}& = \\mu \\cdot v_1^{(3)}+\\epsilon \\cdot d\\theta_1=\\epsilon \\cdot [\\mu \\cdot v_1^{(1)}+d\\theta_1]=\\epsilon \\cdot v_2^{(1)}\n\\\\\\\\ &\\cdots \\end{aligned}</script><p> (1)  $\\theta_{t+1}$  $v_{t+1}$  $\\epsilon$ (1)  (3) : 1. $v_0=0$2.  $\\epsilon$ </p>\n<p> epoch  10% (1)  (3)   t+1  $\\epsilon$  $\\epsilon_1, \\ \\epsilon_2$ $\\epsilon_2 = 0.1 \\epsilon_1$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_t^{(3)} &= \\epsilon_1 \\cdot v_t^{(1)}\n\\\\\\\\ \\theta_{t+1}^{(3)}&=\\theta_t- \\mu \\cdot v_t^{(3)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t- \\epsilon_1 \\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}^{(1)}&=\\theta_t-\\epsilon_2\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t-0.1\\epsilon_1\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\\end{aligned}</script><p>(1)  (3)  velocity (3)  velocity  $\\epsilon_2 \\cdot d\\theta$  $v_t^{(3)}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} v_{t+n}&=\\mu \\cdot v_{t+n-1}+\\epsilon_2 d\\theta_{t+n-1}\\\\\\\\ &=\\mu^2 \\cdot v_{t+n-2}+\\mu \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-2}+\\epsilon_2 \\cdot d\\theta_{t+n-1}\n\\\\\\\\&=\\cdots\n\\\\\\\\&=\\mu^n \\cdot v_t + \\mu^{n-1} \\cdot \\epsilon_2 \\cdot d\\theta_{t}+\\mu^{n-2} \\cdot \\epsilon_2 \\cdot  d\\theta_{t+1} + \\cdots + \\mu^0 \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-1}\\end{aligned}</script><p> $\\mu &lt;1$ $n$  $v_t$  velocity </p>\n<h3 id=\"1-2-1-dampening\"><a href=\"#1-2-1-dampening\" class=\"headerlink\" title=\"1.2.1 dampening\"></a>1.2.1 dampening</h3><p> PyTorch <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71\"></a> <code>dampening</code> momentum  (1)  velocity </p>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\mu \\cdot v_t + \\text{dampening} \\cdot d\\theta_t</script><p> $v_{t+1} = \\mu \\cdot v_t + (1-\\mu) \\cdot d\\theta_t$ $0 \\le \\mu &lt; 1$ $v_{t+1}$  $\\min (v_t, d\\theta_t)$  $\\max (v_t, d\\theta_t)$ <code>dampening</code>  <code>0</code></p>\n<h2 id=\"1-3-Nesterov\"><a href=\"#1-3-Nesterov\" class=\"headerlink\" title=\"1.3 Nesterov\"></a>1.3 Nesterov</h2><p> momentum  (1) (3)  PyTorch <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71\"></a>  <a href=\"https://pytorch.org/docs/stable/optim.html#torch.optim.SGD\"></a>  (3)  $v_{t+1}$ </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t+v_{t+1}</script><p>$v_{t+1}$  momentumNAG (Nesterov Accelerated Gradient) </p>\n<h3 id=\"1-3-1--momentumCE\"><a href=\"#1-3-1--momentumCE\" class=\"headerlink\" title=\"1.3.1  momentumCE\"></a>1.3.1  momentumCE</h3><p> momentum  2</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + \\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\\end{aligned}</script><h3 id=\"1-3-2-NAG\"><a href=\"#1-3-2-NAG\" class=\"headerlink\" title=\"1.3.2 NAG\"></a>1.3.2 NAG</h3><p>NAG </p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t) \\qquad(4)</script></li>\n<li><p>momentum</p>\n<script type=\"math/tex; mode=display\">y_{t+1}=\\theta_{t+1} + \\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t) \\qquad(5)</script></li>\n</ol>\n<p> $y_0=\\theta_0$</p>\n<p>NAG  $y$  $\\theta$  $y$ $y$  $\\theta$  $\\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t)$  3<br><img src=\"/images/pytorch/NAS_0.png\" alt=\"\"> <center> 3. NAG </center><br> $\\mu \\equiv 0$NAG  SD</p>\n<p> $\\mu, \\ \\epsilon$  velocity </p>\n<h3 id=\"1-3-3-Sutskever-Nesterov-Momentum\"><a href=\"#1-3-3-Sutskever-Nesterov-Momentum\" class=\"headerlink\" title=\"1.3.3 Sutskever Nesterov Momentum\"></a>1.3.3 Sutskever Nesterov Momentum</h3><p>NAG  $\\theta$  momentum  NAG  velocity  NAG  <code>momentum-GD-momentum-GD-...</code> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">y_t=\\theta_t+\\mu_t \\cdot(\\theta_t-\\theta_{t-1})</script><p></p>\n<script type=\"math/tex; mode=display\">y_t=\\theta_t + \\mu_t \\cdot v_t</script><p> (4)  $y_t$(4)  t  Sutskever Nesterov Momentum  t-1  momentum  $\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t)$ $y_t$ </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t+\\mu_t \\cdot v_t-\\epsilon_t \\cdot \\nabla f(\\theta_t + \\mu_t \\cdot v_t) \\qquad(6)</script><p></p>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\theta_t+\\mu_t \\cdot v_t)  \\qquad(7)</script><p> 4  momentum  NAG <br><img src=\"/images/pytorch/NAG.png\" alt=\"\"> <center> 4 </center></p>\n<h3 id=\"1-3-4-Bengio-Nesterov-Momentum\"><a href=\"#1-3-4-Bengio-Nesterov-Momentum\" class=\"headerlink\" title=\"1.3.4 Bengio Nesterov Momentum\"></a>1.3.4 Bengio Nesterov Momentum</h3><p>NAG  $\\theta$ $y$ $y$  $\\theta$  momentum</p>\n<p> momentum  $\\theta$  momentum </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t-1}=\\theta_{t-1} + \\mu_{t-1} \\cdot v_{t-1}</script><p> $\\theta$ $\\Theta$ $\\theta_0$$\\Theta$ $\\theta$ </p>\n<p> velocity  (7) </p>\n<script type=\"math/tex; mode=display\">v_t=\\mu_{t-1} \\cdot v_{t-1} - \\epsilon_{t-1} \\cdot \\nabla f(\\Theta_{t-1})</script><p>$v_t$  $\\theta$ </p>\n<p> $\\Theta$ </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}= \\theta_{t+1}\n\\\\\\\\ \\Theta_t-\\mu_t \\cdot v_t= \\theta_t</script><p> (6) </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}=\\Theta_t-\\mu_t \\cdot v_t+\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p></p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot v_{t+1}-\\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p> (7) </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot[\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)]-\\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p></p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t) \\qquad(8)</script><p> $\\Theta_{t+1}=\\Theta_t + V_{t+1}$ </p>\n<script type=\"math/tex; mode=display\">V_{t+1}=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p>  $\\Theta$  <code>(3&#39;)</code>  $v_{t+1}$ (1)  $v_{t+1}$  $\\epsilon$ $-$  $+$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} V_{t+1}&=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t+\\mu_{t+1} \\cdot \\nabla f(\\Theta_t)+ \\nabla f(\\Theta_t) \n\\\\\\\\ &=\\mu_{t+1} \\cdot [\\mu_t \\cdot v_t+ \\nabla f(\\Theta_t)] + \\nabla f(\\Theta_t)  \\end{aligned} \\qquad(9)</script><p> $\\Theta$ </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t - \\epsilon_t \\cdot V_{t+1} \\qquad(10)</script><p><strong>(9)  (10)  PyTorch  <code>SGD.step</code>  <code>nesterov=True</code> </strong></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>[1] On the importance of initialization and momentum in deep learning. Ilya Sutskever</p>\n<p>[2] <a href=\"https://jlmelville.github.io/mize/mesterov.html\">Nesterov Accelerated Gradient and Momentum</a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>[1] <a href=\"https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/\">ORF523: Nesterovs Accelerated Gradient Descent</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-SGD\"><a href=\"#1-SGD\" class=\"headerlink\" title=\"1. SGD\"></a>1. SGD</h1>","more":"<h2 id=\"1-1-weight-decay\"><a href=\"#1-1-weight-decay\" class=\"headerlink\" title=\"1.1 weight decay\"></a>1.1 weight decay</h2><p>MSE  CE  $L_0$</p>\n<script type=\"math/tex; mode=display\">L=L_0+\\frac 1 2 \\lambda \\cdot \\|\\mathbf \\theta\\|_2^2</script><p> 1 <br><img src=\"/images/pytorch/overfitting.png\" alt=\"\"> <center> 1 Deep Learning with PyTorch</center><br> $\\mathbf \\theta$  $|\\mathbf \\theta_i|$  $\\lambda$  <code>weight decay</code></p>\n<script type=\"math/tex; mode=display\">\\frac {\\partial L}{\\partial \\mathbf \\theta_i}=\\frac {\\partial L_0}{\\partial \\mathbf \\theta_i}+\\lambda \\cdot \\mathbf \\theta_i</script><h2 id=\"1-2-momentum\"><a href=\"#1-2-momentum\" class=\"headerlink\" title=\"1.2 momentum\"></a>1.2 momentum</h2><p> SGD  2  momentum  SGD </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t -\\epsilon \\cdot d\\theta_t</script><p> momentum </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} v_{t+1} & = \\mu \\cdot v_t + d\\theta_t\n\\\\\\\\ \\theta_{t+1} &= \\theta_t - \\epsilon \\cdot v_{t+1}=\\theta_t-\\epsilon \\cdot \\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t \\end{aligned} \\qquad(1)</script><p> $\\theta_0$ $v_0=0$$\\epsilon$ $\\mu$  momentum  velocityv   2 velocity <br><img src=\"/images/pytorch/momentum.png\" alt=\"\"> <center> 2</center><br></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - d\\theta_t\n\\\\\\\\\\theta_{t+1}&=\\theta_t+\\epsilon \\cdot v_{t+1}=\\theta_t +\\epsilon \\cdot \\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t \\end{aligned}\\qquad(2)</script><p> $v_0=0$ </p>\n<p>caffe  Sutskever. [1] </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t + \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t - v_{t+1}=\\theta_t-\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3)</script><p> </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + v_{t+1}=\\theta_t+\\mu \\cdot v_t-\\epsilon \\cdot d\\theta_t\\end{aligned} \\qquad(3')</script><p> $\\epsilon$  $v_0=0$ (3)  $v_{t+1}$  (1)  $\\epsilon$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_1^{(3)}&=\\epsilon \\cdot d\\theta_0 = \\epsilon \\cdot v_1^{(1)}\n\\\\\\\\ v_2^{(3)}& = \\mu \\cdot v_1^{(3)}+\\epsilon \\cdot d\\theta_1=\\epsilon \\cdot [\\mu \\cdot v_1^{(1)}+d\\theta_1]=\\epsilon \\cdot v_2^{(1)}\n\\\\\\\\ &\\cdots \\end{aligned}</script><p> (1)  $\\theta_{t+1}$  $v_{t+1}$  $\\epsilon$ (1)  (3) : 1. $v_0=0$2.  $\\epsilon$ </p>\n<p> epoch  10% (1)  (3)   t+1  $\\epsilon$  $\\epsilon_1, \\ \\epsilon_2$ $\\epsilon_2 = 0.1 \\epsilon_1$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_t^{(3)} &= \\epsilon_1 \\cdot v_t^{(1)}\n\\\\\\\\ \\theta_{t+1}^{(3)}&=\\theta_t- \\mu \\cdot v_t^{(3)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t- \\epsilon_1 \\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\n\\\\\\\\ \\theta_{t+1}^{(1)}&=\\theta_t-\\epsilon_2\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t=\\theta_t-0.1\\epsilon_1\\cdot \\mu \\cdot v_t^{(1)} - \\epsilon_2 \\cdot d\\theta_t\\end{aligned}</script><p>(1)  (3)  velocity (3)  velocity  $\\epsilon_2 \\cdot d\\theta$  $v_t^{(3)}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} v_{t+n}&=\\mu \\cdot v_{t+n-1}+\\epsilon_2 d\\theta_{t+n-1}\\\\\\\\ &=\\mu^2 \\cdot v_{t+n-2}+\\mu \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-2}+\\epsilon_2 \\cdot d\\theta_{t+n-1}\n\\\\\\\\&=\\cdots\n\\\\\\\\&=\\mu^n \\cdot v_t + \\mu^{n-1} \\cdot \\epsilon_2 \\cdot d\\theta_{t}+\\mu^{n-2} \\cdot \\epsilon_2 \\cdot  d\\theta_{t+1} + \\cdots + \\mu^0 \\cdot \\epsilon_2 \\cdot d\\theta_{t+n-1}\\end{aligned}</script><p> $\\mu &lt;1$ $n$  $v_t$  velocity </p>\n<h3 id=\"1-2-1-dampening\"><a href=\"#1-2-1-dampening\" class=\"headerlink\" title=\"1.2.1 dampening\"></a>1.2.1 dampening</h3><p> PyTorch <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71\"></a> <code>dampening</code> momentum  (1)  velocity </p>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\mu \\cdot v_t + \\text{dampening} \\cdot d\\theta_t</script><p> $v_{t+1} = \\mu \\cdot v_t + (1-\\mu) \\cdot d\\theta_t$ $0 \\le \\mu &lt; 1$ $v_{t+1}$  $\\min (v_t, d\\theta_t)$  $\\max (v_t, d\\theta_t)$ <code>dampening</code>  <code>0</code></p>\n<h2 id=\"1-3-Nesterov\"><a href=\"#1-3-Nesterov\" class=\"headerlink\" title=\"1.3 Nesterov\"></a>1.3 Nesterov</h2><p> momentum  (1) (3)  PyTorch <a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/sgd.py#L71\"></a>  <a href=\"https://pytorch.org/docs/stable/optim.html#torch.optim.SGD\"></a>  (3)  $v_{t+1}$ </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1}=\\theta_t+v_{t+1}</script><p>$v_{t+1}$  momentumNAG (Nesterov Accelerated Gradient) </p>\n<h3 id=\"1-3-1--momentumCE\"><a href=\"#1-3-1--momentumCE\" class=\"headerlink\" title=\"1.3.1  momentumCE\"></a>1.3.1  momentumCE</h3><p> momentum  2</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}v_{t+1}&=\\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\n\\\\\\\\ \\theta_{t+1}&=\\theta_t + \\mu \\cdot v_t - \\epsilon \\cdot \\nabla f(\\theta_t)\\end{aligned}</script><h3 id=\"1-3-2-NAG\"><a href=\"#1-3-2-NAG\" class=\"headerlink\" title=\"1.3.2 NAG\"></a>1.3.2 NAG</h3><p>NAG </p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t) \\qquad(4)</script></li>\n<li><p>momentum</p>\n<script type=\"math/tex; mode=display\">y_{t+1}=\\theta_{t+1} + \\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t) \\qquad(5)</script></li>\n</ol>\n<p> $y_0=\\theta_0$</p>\n<p>NAG  $y$  $\\theta$  $y$ $y$  $\\theta$  $\\mu_{t+1} \\cdot (\\theta_{t+1}-\\theta_t)$  3<br><img src=\"/images/pytorch/NAS_0.png\" alt=\"\"> <center> 3. NAG </center><br> $\\mu \\equiv 0$NAG  SD</p>\n<p> $\\mu, \\ \\epsilon$  velocity </p>\n<h3 id=\"1-3-3-Sutskever-Nesterov-Momentum\"><a href=\"#1-3-3-Sutskever-Nesterov-Momentum\" class=\"headerlink\" title=\"1.3.3 Sutskever Nesterov Momentum\"></a>1.3.3 Sutskever Nesterov Momentum</h3><p>NAG  $\\theta$  momentum  NAG  velocity  NAG  <code>momentum-GD-momentum-GD-...</code> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">y_t=\\theta_t+\\mu_t \\cdot(\\theta_t-\\theta_{t-1})</script><p></p>\n<script type=\"math/tex; mode=display\">y_t=\\theta_t + \\mu_t \\cdot v_t</script><p> (4)  $y_t$(4)  t  Sutskever Nesterov Momentum  t-1  momentum  $\\theta_{t+1} = y_t - \\epsilon_t \\cdot \\nabla f(y_t)$ $y_t$ </p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t+\\mu_t \\cdot v_t-\\epsilon_t \\cdot \\nabla f(\\theta_t + \\mu_t \\cdot v_t) \\qquad(6)</script><p></p>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\theta_t+\\mu_t \\cdot v_t)  \\qquad(7)</script><p> 4  momentum  NAG <br><img src=\"/images/pytorch/NAG.png\" alt=\"\"> <center> 4 </center></p>\n<h3 id=\"1-3-4-Bengio-Nesterov-Momentum\"><a href=\"#1-3-4-Bengio-Nesterov-Momentum\" class=\"headerlink\" title=\"1.3.4 Bengio Nesterov Momentum\"></a>1.3.4 Bengio Nesterov Momentum</h3><p>NAG  $\\theta$ $y$ $y$  $\\theta$  momentum</p>\n<p> momentum  $\\theta$  momentum </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t-1}=\\theta_{t-1} + \\mu_{t-1} \\cdot v_{t-1}</script><p> $\\theta$ $\\Theta$ $\\theta_0$$\\Theta$ $\\theta$ </p>\n<p> velocity  (7) </p>\n<script type=\"math/tex; mode=display\">v_t=\\mu_{t-1} \\cdot v_{t-1} - \\epsilon_{t-1} \\cdot \\nabla f(\\Theta_{t-1})</script><p>$v_t$  $\\theta$ </p>\n<p> $\\Theta$ </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}= \\theta_{t+1}\n\\\\\\\\ \\Theta_t-\\mu_t \\cdot v_t= \\theta_t</script><p> (6) </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}-\\mu_{t+1} \\cdot v_{t+1}=\\Theta_t-\\mu_t \\cdot v_t+\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p></p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot v_{t+1}-\\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p> (7) </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot[\\mu_t \\cdot v_t - \\epsilon_t \\cdot \\nabla f(\\Theta_t)]-\\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p></p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t+\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t) \\qquad(8)</script><p> $\\Theta_{t+1}=\\Theta_t + V_{t+1}$ </p>\n<script type=\"math/tex; mode=display\">V_{t+1}=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t-\\mu_{t+1} \\cdot \\epsilon_t \\cdot \\nabla f(\\Theta_t)-\\epsilon_t \\cdot \\nabla f(\\Theta_t)</script><p>  $\\Theta$  <code>(3&#39;)</code>  $v_{t+1}$ (1)  $v_{t+1}$  $\\epsilon$ $-$  $+$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} V_{t+1}&=\\mu_{t+1} \\cdot \\mu_t \\cdot v_t+\\mu_{t+1} \\cdot \\nabla f(\\Theta_t)+ \\nabla f(\\Theta_t) \n\\\\\\\\ &=\\mu_{t+1} \\cdot [\\mu_t \\cdot v_t+ \\nabla f(\\Theta_t)] + \\nabla f(\\Theta_t)  \\end{aligned} \\qquad(9)</script><p> $\\Theta$ </p>\n<script type=\"math/tex; mode=display\">\\Theta_{t+1}=\\Theta_t - \\epsilon_t \\cdot V_{t+1} \\qquad(10)</script><p><strong>(9)  (10)  PyTorch  <code>SGD.step</code>  <code>nesterov=True</code> </strong></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>[1] On the importance of initialization and momentum in deep learning. Ilya Sutskever</p>\n<p>[2] <a href=\"https://jlmelville.github.io/mize/mesterov.html\">Nesterov Accelerated Gradient and Momentum</a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>[1] <a href=\"https://blogs.princeton.edu/imabandit/2013/04/01/acceleratedgradientdescent/\">ORF523: Nesterovs Accelerated Gradient Descent</a></p>"},{"title":"pytorch 1","p":"pytorch/tricks_1","date":"2021-01-08T01:45:15.000Z","_content":" input shape  (N,H,W) loss  input  shape  (N,H,W) input Tensor  shape  input shape  (N',H',W')\ninput  shape  (N,H,W) output  shape  (N',H',W') batch output  shape  output output  input  shape \n(N',H',W',N,H,W) ","source":"_posts/pytorch/tricks_1.md","raw":"---\ntitle: pytorch 1\np: pytorch/tricks_1\ndate: 2021-01-08 09:45:15\ntags: PyTorch\n---\n input shape  (N,H,W) loss  input  shape  (N,H,W) input Tensor  shape  input shape  (N',H',W')\ninput  shape  (N,H,W) output  shape  (N',H',W') batch output  shape  output output  input  shape \n(N',H',W',N,H,W) ","slug":"pytorch/tricks_1","published":1,"updated":"2021-01-08T07:22:19.103Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or91s003wp0dj28xpd876","content":"<p> input shape  (N,H,W) loss  input  shape  (N,H,W) input Tensor  shape  input shape  (N,H,W)<br>input  shape  (N,H,W) output  shape  (N,H,W) batch output  shape  output output  input  shape <br>(N,H,W,N,H,W) </p>\n","site":{"data":{}},"excerpt":"","more":"<p> input shape  (N,H,W) loss  input  shape  (N,H,W) input Tensor  shape  input shape  (N,H,W)<br>input  shape  (N,H,W) output  shape  (N,H,W) batch output  shape  output output  input  shape <br>(N,H,W,N,H,W) </p>\n"},{"title":"Hexo Sync","date":"2019-06-13T01:57:11.000Z","p":"tools/Hexo-Sync","_content":"\n\n```\nA, BHexo\n```\n<!-- more -->\n computer B hexo https://shajian.github.io computer B hexo path/to/myblog/\n```\n_config.yml\ndb.json\nnode_modules\npackage.json\npackage-lock.json\npublic\nscaffolds\nsource\nthemes\n```\ngithub shajian.github.io branch\"hexo\"\"mater\"hexo/\"hexo\"hexo/\n\n computer A  clone  hexo \n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n$ git branch\n* hexo\n  master\n```\n shajian.github.io / path/to/myblog\n```\n$ rm -rf .\n# do not use \"cp -R path/to/myblog/* ./\" which ignores hidden files/directories\n$ cp -R path/to/myblog/. ./\n```\n\n```\nhexo new \"<title>\"\n```\nsource/_posts\n\n```\nhexo g -d\n```\n github  master \n\nhexo `hexo` \n```\n$ git add .\n$ git commit -m \"new post 'title'\"\n$ git push origin hexo\n```\n\n https://shajian.github.io /\n\n `hexo`  git  `hexo g -d`  `hexo` \n\n computer B  path/to/myblog  clone  hexo \n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n```\n .gitignore  node_modules \n```\n$ npm install\n```\n computer A\n\ncomputer A  B \n```\n$ git checkout master\n$ git pull origin master\n$ git checkout hexo\n$ git pull origin hexo\n```\n hexo \n\n .depoly_git  master git  .git  .deploy_git / computer B  clone \n```\nhexo g -d\n```\n hexo  .deploy_git / hexo \n\n## hexo \n\n```\nhexo new -p pytorch/optim_Adadelta \"PyTorch.optim.Adadelta\"\n```\n `PyTorch.optim.Adadelta` `source/_posts/pytorch/optim_Adadelta.md`","source":"_posts/tools/Hexo-Sync.md","raw":"---\ntitle: Hexo Sync\ndate: 2019-06-13 9:57:11\np: tools/Hexo-Sync\ntags: tool\n---\n\n\n```\nA, BHexo\n```\n<!-- more -->\n computer B hexo https://shajian.github.io computer B hexo path/to/myblog/\n```\n_config.yml\ndb.json\nnode_modules\npackage.json\npackage-lock.json\npublic\nscaffolds\nsource\nthemes\n```\ngithub shajian.github.io branch\"hexo\"\"mater\"hexo/\"hexo\"hexo/\n\n computer A  clone  hexo \n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n$ git branch\n* hexo\n  master\n```\n shajian.github.io / path/to/myblog\n```\n$ rm -rf .\n# do not use \"cp -R path/to/myblog/* ./\" which ignores hidden files/directories\n$ cp -R path/to/myblog/. ./\n```\n\n```\nhexo new \"<title>\"\n```\nsource/_posts\n\n```\nhexo g -d\n```\n github  master \n\nhexo `hexo` \n```\n$ git add .\n$ git commit -m \"new post 'title'\"\n$ git push origin hexo\n```\n\n https://shajian.github.io /\n\n `hexo`  git  `hexo g -d`  `hexo` \n\n computer B  path/to/myblog  clone  hexo \n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n```\n .gitignore  node_modules \n```\n$ npm install\n```\n computer A\n\ncomputer A  B \n```\n$ git checkout master\n$ git pull origin master\n$ git checkout hexo\n$ git pull origin hexo\n```\n hexo \n\n .depoly_git  master git  .git  .deploy_git / computer B  clone \n```\nhexo g -d\n```\n hexo  .deploy_git / hexo \n\n## hexo \n\n```\nhexo new -p pytorch/optim_Adadelta \"PyTorch.optim.Adadelta\"\n```\n `PyTorch.optim.Adadelta` `source/_posts/pytorch/optim_Adadelta.md`","slug":"tools/Hexo-Sync","published":1,"updated":"2021-09-15T02:18:18.552Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or925004rp0djbj7f5d6u","content":"<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A, BHexo</span><br></pre></td></tr></table></figure><br><span id=\"more\"></span><br> computer B hexo <a href=\"https://shajian.github.io\">https://shajian.github.io</a> computer B hexo path/to/myblog/<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_config.yml</span><br><span class=\"line\">db.json</span><br><span class=\"line\">node_modules</span><br><span class=\"line\">package.json</span><br><span class=\"line\">package-lock.json</span><br><span class=\"line\">public</span><br><span class=\"line\">scaffolds</span><br><span class=\"line\">source</span><br><span class=\"line\">themes</span><br></pre></td></tr></table></figure><br>github shajian.github.io branchhexomaterhexo/hexohexo/</p>\n<p> computer A  clone  hexo <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git branch</span><br><span class=\"line\">* hexo</span><br><span class=\"line\">  master</span><br></pre></td></tr></table></figure><br> shajian.github.io / path/to/myblog<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf .</span><br><span class=\"line\"># do not use &quot;cp -R path/to/myblog/* ./&quot; which ignores hidden files/directories</span><br><span class=\"line\">$ cp -R path/to/myblog/. ./</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new &quot;&lt;title&gt;&quot;</span><br></pre></td></tr></table></figure><br>source/_posts<br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure><br> github  master </p>\n<p>hexo <code>hexo</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git add .</span><br><span class=\"line\">$ git commit -m &quot;new post &#x27;title&#x27;&quot;</span><br><span class=\"line\">$ git push origin hexo</span><br></pre></td></tr></table></figure></p>\n<p> <a href=\"https://shajian.github.io\">https://shajian.github.io</a> /</p>\n<p> <code>hexo</code>  git  <code>hexo g -d</code>  <code>hexo</code> </p>\n<p> computer B  path/to/myblog  clone  hexo <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br></pre></td></tr></table></figure><br> .gitignore  node_modules <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install</span><br></pre></td></tr></table></figure><br> computer A</p>\n<p>computer A  B <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">$ git pull origin master</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git pull origin hexo</span><br></pre></td></tr></table></figure><br> hexo </p>\n<p> .depoly_git  master git  .git  .deploy_git / computer B  clone <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure><br> hexo  .deploy_git / hexo </p>\n<h2 id=\"hexo-\"><a href=\"#hexo-\" class=\"headerlink\" title=\"hexo \"></a>hexo </h2><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new -p pytorch/optim_Adadelta &quot;PyTorch.optim.Adadelta&quot;</span><br></pre></td></tr></table></figure><br> <code>PyTorch.optim.Adadelta</code> <code>source/_posts/pytorch/optim_Adadelta.md</code></p>\n","site":{"data":{}},"excerpt":"<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A, BHexo</span><br></pre></td></tr></table></figure><br>","more":"<br> computer B hexo <a href=\"https://shajian.github.io\">https://shajian.github.io</a> computer B hexo path/to/myblog/<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_config.yml</span><br><span class=\"line\">db.json</span><br><span class=\"line\">node_modules</span><br><span class=\"line\">package.json</span><br><span class=\"line\">package-lock.json</span><br><span class=\"line\">public</span><br><span class=\"line\">scaffolds</span><br><span class=\"line\">source</span><br><span class=\"line\">themes</span><br></pre></td></tr></table></figure><br>github shajian.github.io branchhexomaterhexo/hexohexo/</p>\n<p> computer A  clone  hexo <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git branch</span><br><span class=\"line\">* hexo</span><br><span class=\"line\">  master</span><br></pre></td></tr></table></figure><br> shajian.github.io / path/to/myblog<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf .</span><br><span class=\"line\"># do not use &quot;cp -R path/to/myblog/* ./&quot; which ignores hidden files/directories</span><br><span class=\"line\">$ cp -R path/to/myblog/. ./</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new &quot;&lt;title&gt;&quot;</span><br></pre></td></tr></table></figure><br>source/_posts<br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure><br> github  master </p>\n<p>hexo <code>hexo</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git add .</span><br><span class=\"line\">$ git commit -m &quot;new post &#x27;title&#x27;&quot;</span><br><span class=\"line\">$ git push origin hexo</span><br></pre></td></tr></table></figure></p>\n<p> <a href=\"https://shajian.github.io\">https://shajian.github.io</a> /</p>\n<p> <code>hexo</code>  git  <code>hexo g -d</code>  <code>hexo</code> </p>\n<p> computer B  path/to/myblog  clone  hexo <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br></pre></td></tr></table></figure><br> .gitignore  node_modules <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install</span><br></pre></td></tr></table></figure><br> computer A</p>\n<p>computer A  B <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">$ git pull origin master</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git pull origin hexo</span><br></pre></td></tr></table></figure><br> hexo </p>\n<p> .depoly_git  master git  .git  .deploy_git / computer B  clone <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure><br> hexo  .deploy_git / hexo </p>\n<h2 id=\"hexo-\"><a href=\"#hexo-\" class=\"headerlink\" title=\"hexo \"></a>hexo </h2><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new -p pytorch/optim_Adadelta &quot;PyTorch.optim.Adadelta&quot;</span><br></pre></td></tr></table></figure><br> <code>PyTorch.optim.Adadelta</code> <code>source/_posts/pytorch/optim_Adadelta.md</code></p>"},{"title":"jupyter-book","date":"2021-08-24T02:40:39.000Z","_content":" jupyter-book \n<!-- more -->\n\nJupyter Book [](https://jupyterbook.org/start/overview.html)\n\n[](https://predictablynoisy.com/jupyter-book/guide/01_overview)\n\n Jupyter Book  markdown  `jupyter-book`  web github\n\n\n```sh\nconda create -n jupyter python=3.9 #  env\nconda activate jupyter\npip install jupyter-book\n```\n\n# \n Jupyter Book\n```sh\njupyter-book create mybookname/\n```\n\n# \n## \n `.md`  `.ipynb`\n\n## \n`_config.yml`\n\n## \n Table of Content`_toc.yml`\n\n\n# \n `mybookname` \n```sh\njupyter-book build mybookname/\n```\n `mybookname/_build` \n\n `mybookname`\n```sh\njupyter-book build .\n```\n cache source \n```sh\njupyter-book build --all .\n```\n\n\n```\nImportError: DLL load failed while importing win32api: The specified module could not be found\n```\n\n```sh\npython C:\\path\\to\\miniconda3\\Scripts\\pywin32_postinstall.py -install\n```\n\n source  `_build`  build   git main  ignore `_build`  `_build`  push   `gh-pages` web \n\n# \n`_build/html/index.html`   `file://Users/my_path_to_book/_build/html/index.html`\n\n# \n\n## \n github  `mybook` `README`  clone \n```sh\ngit clone https://github.com/<my-account>/mybook\n```\n\n book \n```sh\ncp -r mybookname/* mybook/\n```\n\n `.gitignore` \n```\nmybook/_build/*\n.ipynb_checkpoints\n.DS_Store\n__pycache__/\n```\n\n\n```sh\ncd mybook\ngit add ./*\ngit commit -m \"adding my first book\"\ngit push\n```\n\n##  Github Page  book \n github  web  `ghp-import` \n\n`ghp-import`  `_build/html`  `gh-pages` github`ghp-import` `gh-pages` \n\n\n\n1. \n    ```sh\n    pip install ghp-import\n    ```\n\n2.  Github pages \n    -  `gh-pages`\n\n3.  `main`  `master`  `_build/html` \n    ```sh\n    ghp-import -n -p -f _build/html\n    ```\n    `-n`  Github  `Jekyll`  book HTML \n\nbook  `https://<user>.github.io/mybook/` \n\n##  book\ncheckout  `main`  book  re-build `jupyter-book build .` `ghp-import -n -p -f _build/html`  `gh-pages`","source":"_posts/tools/jupyter-book.md","raw":"---\ntitle: jupyter-book\ndate: 2021-08-24 10:40:39\ntags:\n---\n jupyter-book \n<!-- more -->\n\nJupyter Book [](https://jupyterbook.org/start/overview.html)\n\n[](https://predictablynoisy.com/jupyter-book/guide/01_overview)\n\n Jupyter Book  markdown  `jupyter-book`  web github\n\n\n```sh\nconda create -n jupyter python=3.9 #  env\nconda activate jupyter\npip install jupyter-book\n```\n\n# \n Jupyter Book\n```sh\njupyter-book create mybookname/\n```\n\n# \n## \n `.md`  `.ipynb`\n\n## \n`_config.yml`\n\n## \n Table of Content`_toc.yml`\n\n\n# \n `mybookname` \n```sh\njupyter-book build mybookname/\n```\n `mybookname/_build` \n\n `mybookname`\n```sh\njupyter-book build .\n```\n cache source \n```sh\njupyter-book build --all .\n```\n\n\n```\nImportError: DLL load failed while importing win32api: The specified module could not be found\n```\n\n```sh\npython C:\\path\\to\\miniconda3\\Scripts\\pywin32_postinstall.py -install\n```\n\n source  `_build`  build   git main  ignore `_build`  `_build`  push   `gh-pages` web \n\n# \n`_build/html/index.html`   `file://Users/my_path_to_book/_build/html/index.html`\n\n# \n\n## \n github  `mybook` `README`  clone \n```sh\ngit clone https://github.com/<my-account>/mybook\n```\n\n book \n```sh\ncp -r mybookname/* mybook/\n```\n\n `.gitignore` \n```\nmybook/_build/*\n.ipynb_checkpoints\n.DS_Store\n__pycache__/\n```\n\n\n```sh\ncd mybook\ngit add ./*\ngit commit -m \"adding my first book\"\ngit push\n```\n\n##  Github Page  book \n github  web  `ghp-import` \n\n`ghp-import`  `_build/html`  `gh-pages` github`ghp-import` `gh-pages` \n\n\n\n1. \n    ```sh\n    pip install ghp-import\n    ```\n\n2.  Github pages \n    -  `gh-pages`\n\n3.  `main`  `master`  `_build/html` \n    ```sh\n    ghp-import -n -p -f _build/html\n    ```\n    `-n`  Github  `Jekyll`  book HTML \n\nbook  `https://<user>.github.io/mybook/` \n\n##  book\ncheckout  `main`  book  re-build `jupyter-book build .` `ghp-import -n -p -f _build/html`  `gh-pages`","slug":"tools/jupyter-book","published":1,"updated":"2021-09-15T02:11:42.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or926004sp0dj2g595ufv","content":"<p> jupyter-book <br><span id=\"more\"></span></p>\n<p>Jupyter Book <a href=\"https://jupyterbook.org/start/overview.html\"></a></p>\n<p><a href=\"https://predictablynoisy.com/jupyter-book/guide/01_overview\"></a></p>\n<p> Jupyter Book  markdown  <code>jupyter-book</code>  web github</p>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n jupyter python=3.9 <span class=\"comment\">#  env</span></span><br><span class=\"line\">conda activate jupyter</span><br><span class=\"line\">pip install jupyter-book</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Jupyter Book<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book create mybookname/</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>.md</code>  <code>.ipynb</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>_config.yml</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Table of Content<code>_toc.yml</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>mybookname</code> <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book build mybookname/</span><br></pre></td></tr></table></figure><br> <code>mybookname/_build</code> </p>\n<p> <code>mybookname</code><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book build .</span><br></pre></td></tr></table></figure><br> cache source <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book build --all .</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ImportError: DLL load failed while importing win32api: The specified module could not be found</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python C:\\path\\to\\miniconda3\\Scripts\\pywin32_postinstall.py -install</span><br></pre></td></tr></table></figure></p>\n<p> source  <code>_build</code>  build   git main  ignore <code>_build</code>  <code>_build</code>  push   <code>gh-pages</code> web </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><code>_build/html/index.html</code>   <code>file://Users/my_path_to_book/_build/html/index.html</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> github  <code>mybook</code> <code>README</code>  clone <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/&lt;my-account&gt;/mybook</span><br></pre></td></tr></table></figure></p>\n<p> book <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp -r mybookname/* mybook/</span><br></pre></td></tr></table></figure></p>\n<p> <code>.gitignore</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mybook/_build/*</span><br><span class=\"line\">.ipynb_checkpoints</span><br><span class=\"line\">.DS_Store</span><br><span class=\"line\">__pycache__/</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> mybook</span><br><span class=\"line\">git add ./*</span><br><span class=\"line\">git commit -m <span class=\"string\">&quot;adding my first book&quot;</span></span><br><span class=\"line\">git push</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-Github-Page--book-\"><a href=\"#-Github-Page--book-\" class=\"headerlink\" title=\" Github Page  book \"></a> Github Page  book </h2><p> github  web  <code>ghp-import</code> </p>\n<p><code>ghp-import</code>  <code>_build/html</code>  <code>gh-pages</code> github<code>ghp-import</code> <code>gh-pages</code> </p>\n<p></p>\n<ol>\n<li><p></p>\n <figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install ghp-import</span><br></pre></td></tr></table></figure>\n</li>\n<li><p> Github pages </p>\n<ul>\n<li> <code>gh-pages</code></li>\n</ul>\n</li>\n<li><p> <code>main</code>  <code>master</code>  <code>_build/html</code> </p>\n <figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ghp-import -n -p -f _build/html</span><br></pre></td></tr></table></figure>\n<p> <code>-n</code>  Github  <code>Jekyll</code>  book HTML </p>\n</li>\n</ol>\n<p>book  <code>https://&lt;user&gt;.github.io/mybook/</code> </p>\n<h2 id=\"-book\"><a href=\"#-book\" class=\"headerlink\" title=\" book\"></a> book</h2><p>checkout  <code>main</code>  book  re-build <code>jupyter-book build .</code> <code>ghp-import -n -p -f _build/html</code>  <code>gh-pages</code></p>\n","site":{"data":{}},"excerpt":"<p> jupyter-book <br>","more":"</p>\n<p>Jupyter Book <a href=\"https://jupyterbook.org/start/overview.html\"></a></p>\n<p><a href=\"https://predictablynoisy.com/jupyter-book/guide/01_overview\"></a></p>\n<p> Jupyter Book  markdown  <code>jupyter-book</code>  web github</p>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n jupyter python=3.9 <span class=\"comment\">#  env</span></span><br><span class=\"line\">conda activate jupyter</span><br><span class=\"line\">pip install jupyter-book</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> Jupyter Book<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book create mybookname/</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <code>.md</code>  <code>.ipynb</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>_config.yml</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Table of Content<code>_toc.yml</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> <code>mybookname</code> <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book build mybookname/</span><br></pre></td></tr></table></figure><br> <code>mybookname/_build</code> </p>\n<p> <code>mybookname</code><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book build .</span><br></pre></td></tr></table></figure><br> cache source <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter-book build --all .</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ImportError: DLL load failed while importing win32api: The specified module could not be found</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python C:\\path\\to\\miniconda3\\Scripts\\pywin32_postinstall.py -install</span><br></pre></td></tr></table></figure></p>\n<p> source  <code>_build</code>  build   git main  ignore <code>_build</code>  <code>_build</code>  push   <code>gh-pages</code> web </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><code>_build/html/index.html</code>   <code>file://Users/my_path_to_book/_build/html/index.html</code></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> github  <code>mybook</code> <code>README</code>  clone <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/&lt;my-account&gt;/mybook</span><br></pre></td></tr></table></figure></p>\n<p> book <br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp -r mybookname/* mybook/</span><br></pre></td></tr></table></figure></p>\n<p> <code>.gitignore</code> <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mybook/_build/*</span><br><span class=\"line\">.ipynb_checkpoints</span><br><span class=\"line\">.DS_Store</span><br><span class=\"line\">__pycache__/</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> mybook</span><br><span class=\"line\">git add ./*</span><br><span class=\"line\">git commit -m <span class=\"string\">&quot;adding my first book&quot;</span></span><br><span class=\"line\">git push</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-Github-Page--book-\"><a href=\"#-Github-Page--book-\" class=\"headerlink\" title=\" Github Page  book \"></a> Github Page  book </h2><p> github  web  <code>ghp-import</code> </p>\n<p><code>ghp-import</code>  <code>_build/html</code>  <code>gh-pages</code> github<code>ghp-import</code> <code>gh-pages</code> </p>\n<p></p>\n<ol>\n<li><p></p>\n <figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install ghp-import</span><br></pre></td></tr></table></figure>\n</li>\n<li><p> Github pages </p>\n<ul>\n<li> <code>gh-pages</code></li>\n</ul>\n</li>\n<li><p> <code>main</code>  <code>master</code>  <code>_build/html</code> </p>\n <figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ghp-import -n -p -f _build/html</span><br></pre></td></tr></table></figure>\n<p> <code>-n</code>  Github  <code>Jekyll</code>  book HTML </p>\n</li>\n</ol>\n<p>book  <code>https://&lt;user&gt;.github.io/mybook/</code> </p>\n<h2 id=\"-book\"><a href=\"#-book\" class=\"headerlink\" title=\" book\"></a> book</h2><p>checkout  <code>main</code>  book  re-build <code>jupyter-book build .</code> <code>ghp-import -n -p -f _build/html</code>  <code>gh-pages</code></p>"},{"title":"ubuntu zsh ","date":"2021-01-23T10:27:51.000Z","_content":" zsh\n```\nsudo apt-get install zsh\n```\n\n```\nzsh --version\n```\n shell  zsh\n```\nchsh -s /bin/zsh\n```\n shell\n```\necho $SHELL\n```\n shell \n\n\n oh-my-zsh zsh \n```\nwget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh\n```\n\n```\nchmod +x install.sh\n```\n \n ```\n ./install.sh\n ```\n\n powerlevel10k \n```\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n```\n\n `~/.zshrc`\n```\nZSH_THEME=\"powerlevel10k/powerlevel10k\"\n```\n\n# redirect printing message to file\n## stop output to console but file\n```sh\nls -al >> output.txt\nls -al >> output.txt 2>&1 # redirect the stderr to stdout\n```\n\n## output to console and file \n```sh\nls -al 2>&1 | tee output.txt\n```","source":"_posts/tools/shell.md","raw":"---\ntitle: ubuntu zsh \ndate: 2021-01-23 18:27:51\ntags:\n---\n zsh\n```\nsudo apt-get install zsh\n```\n\n```\nzsh --version\n```\n shell  zsh\n```\nchsh -s /bin/zsh\n```\n shell\n```\necho $SHELL\n```\n shell \n\n\n oh-my-zsh zsh \n```\nwget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh\n```\n\n```\nchmod +x install.sh\n```\n \n ```\n ./install.sh\n ```\n\n powerlevel10k \n```\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n```\n\n `~/.zshrc`\n```\nZSH_THEME=\"powerlevel10k/powerlevel10k\"\n```\n\n# redirect printing message to file\n## stop output to console but file\n```sh\nls -al >> output.txt\nls -al >> output.txt 2>&1 # redirect the stderr to stdout\n```\n\n## output to console and file \n```sh\nls -al 2>&1 | tee output.txt\n```","slug":"tools/shell","published":1,"updated":"2021-08-17T03:17:33.668Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or927004up0djec2yfsph","content":"<p> zsh<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install zsh</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zsh --version</span><br></pre></td></tr></table></figure><br> shell  zsh<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chsh -s /bin/zsh</span><br></pre></td></tr></table></figure><br> shell<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo $SHELL</span><br></pre></td></tr></table></figure><br> shell </p>\n<p> oh-my-zsh zsh <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod +x install.sh</span><br></pre></td></tr></table></figure><br> <br> <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./install.sh</span><br></pre></td></tr></table></figure></p>\n<p> powerlevel10k <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --depth=1 https://github.com/romkatv/powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom&#125;/themes/powerlevel10k</span><br></pre></td></tr></table></figure></p>\n<p> <code>~/.zshrc</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"redirect-printing-message-to-file\"><a href=\"#redirect-printing-message-to-file\" class=\"headerlink\" title=\"redirect printing message to file\"></a>redirect printing message to file</h1><h2 id=\"stop-output-to-console-but-file\"><a href=\"#stop-output-to-console-but-file\" class=\"headerlink\" title=\"stop output to console but file\"></a>stop output to console but file</h2><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls -al &gt;&gt; output.txt</span><br><span class=\"line\">ls -al &gt;&gt; output.txt 2&gt;&amp;1 <span class=\"comment\"># redirect the stderr to stdout</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"output-to-console-and-file\"><a href=\"#output-to-console-and-file\" class=\"headerlink\" title=\"output to console and file\"></a>output to console and file</h2><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls -al 2&gt;&amp;1 | tee output.txt</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p> zsh<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install zsh</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zsh --version</span><br></pre></td></tr></table></figure><br> shell  zsh<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chsh -s /bin/zsh</span><br></pre></td></tr></table></figure><br> shell<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo $SHELL</span><br></pre></td></tr></table></figure><br> shell </p>\n<p> oh-my-zsh zsh <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod +x install.sh</span><br></pre></td></tr></table></figure><br> <br> <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./install.sh</span><br></pre></td></tr></table></figure></p>\n<p> powerlevel10k <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --depth=1 https://github.com/romkatv/powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom&#125;/themes/powerlevel10k</span><br></pre></td></tr></table></figure></p>\n<p> <code>~/.zshrc</code><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"redirect-printing-message-to-file\"><a href=\"#redirect-printing-message-to-file\" class=\"headerlink\" title=\"redirect printing message to file\"></a>redirect printing message to file</h1><h2 id=\"stop-output-to-console-but-file\"><a href=\"#stop-output-to-console-but-file\" class=\"headerlink\" title=\"stop output to console but file\"></a>stop output to console but file</h2><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls -al &gt;&gt; output.txt</span><br><span class=\"line\">ls -al &gt;&gt; output.txt 2&gt;&amp;1 <span class=\"comment\"># redirect the stderr to stdout</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"output-to-console-and-file\"><a href=\"#output-to-console-and-file\" class=\"headerlink\" title=\"output to console and file\"></a>output to console and file</h2><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls -al 2&gt;&amp;1 | tee output.txt</span><br></pre></td></tr></table></figure>"},{"title":"function vs. macro","date":"2021-08-10T06:09:28.000Z","p":"cpp/cmake/func_macro","_content":"\n# macro\n\n```cmake\nmacro(<name> [<arg1> ...])\n  <commands>\nendmacro()\n```\n `<name>`  `<arg1>,...`\n","source":"_posts/cpp/cmake/func_macro.md","raw":"---\ntitle: function vs. macro\ndate: 2021-08-10 14:09:28\ntags: cmake, c++\np: cpp/cmake/func_macro\n---\n\n# macro\n\n```cmake\nmacro(<name> [<arg1> ...])\n  <commands>\nendmacro()\n```\n `<name>`  `<arg1>,...`\n","slug":"cpp/cmake/func_macro","published":1,"updated":"2021-08-11T06:31:55.604Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or927004vp0dj7g4agy6h","content":"<h1 id=\"macro\"><a href=\"#macro\" class=\"headerlink\" title=\"macro\"></a>macro</h1><p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">macro</span>(&lt;name&gt; [&lt;arg1&gt; ...])</span><br><span class=\"line\">  &lt;commands&gt;</span><br><span class=\"line\"><span class=\"keyword\">endmacro</span>()</span><br></pre></td></tr></table></figure><br> <code>&lt;name&gt;</code>  <code>&lt;arg1&gt;,...</code></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"macro\"><a href=\"#macro\" class=\"headerlink\" title=\"macro\"></a>macro</h1><p><br><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">macro</span>(&lt;name&gt; [&lt;arg1&gt; ...])</span><br><span class=\"line\">  &lt;commands&gt;</span><br><span class=\"line\"><span class=\"keyword\">endmacro</span>()</span><br></pre></td></tr></table></figure><br> <code>&lt;name&gt;</code>  <code>&lt;arg1&gt;,...</code></p>\n"},{"title":"GAN","date":"2019-07-23T02:15:08.000Z","mathjax":true,"_content":" [Generative Adversarial Nets](https://arxiv.org/abs/1406.2661)\n<!-- more -->\n# GAN\n## \n GAN G  DG D \n\n z $p_z(z)$G  z  $G(z;\\theta_g)$ G  MLP  $\\theta_g$D  MLP $D(x;\\theta_d)$  x  D  x  x $G(x)$  x  G  $D(G(z))$  G  $D(G(x))$  $\\log(1-D(G(z)))$ \n\n$$\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log D(x)] + \\Bbb E_{z \\sim p_z(z)}[\\log(1-D(G(z)))] \\qquad (1)$$\n\n D  log D  G  D  log \n\n 1 \n![](/images/GAN_fig1.png)\n\n 1  D  x  $p_x$ G  $p_g$  x  z  z  x  x=G(z) G   \n(a)  $p_g,\\ p_{data}$ D   \n(b)  D  $D^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)}$  \n(c) D  G(z) G   \n(d) G  D  $p_g=p_{data}$D $D(x)=1/2$\n\n\n![](/images/GAN_alg1.png)\n\nk  D  G  G  D \n\n(1)  GG  D $\\log (1-D(G(z)))$ log  G  $\\log D(G(z))$ G  D log \n\n## \n z  $p_z$  G  1 G G  $p_{data}$ $p_g=p_{data}$  (1) \n### \n__Proposition 1.__  GD \n$$D_G^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)} \\qquad (2)$$\n____   GD  V(G,D)  \n$$\\begin{aligned} V(G,D)&=\\int_x p_{data}(x) \\log D(x) dx+\\int_z p_z(z) \\log (1-D(g(z))) dz\n\\\\\\\\ &=\\int_x p_{data}(x) \\log D(x)+p_g(x) \\log(1-D(x))dx \\end{aligned}$$\n$\\forall (a,b) \\in \\Bbb R^2 \\setminus \\{0,0\\}$ $y \\rightarrow a \\log y+b \\log(1-y)$  (0,1)  $y=\\frac a {a+b}$  0  V(G,D)  x  D(x)  (2) \n\nD  $P(Y=y|x)$  log  binary cross-entropy x  $p_{data}$  y=1 x  $p_g$  y=0 D  $D_G^{\\ast}$  (1)   \n\n$$\\begin{aligned} C(G)&=\\max_D V(G,D)\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{z \\sim p_z} [\\log(1-D_G^{\\ast}(G(z)))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}} \\left[\\log \\frac {P_{data}(x)} {p_{data}(x)+p_g(x)} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {p_{data}(x)+p_g(x)}\\right] \\qquad(4) \\end{aligned}$$\n\n__Theorem 1.__  $p_g=p_{data}$  C(G)  -log4  \n\n____ \n\n1.   \n $p_g=p_{data}$ (2)  $D_G^{\\ast}(x)=1/2$ (4) \n$$C(G)=\\Bbb E_{x \\sim p_{data}}[-\\log 2]+\\Bbb E_{x \\sim p_g}[-\\log 2] \\equiv -\\log 4$$\n2.   \n   $$\\begin{aligned}C(G)&=C(G)+\\Bbb E_{x \\sim p_{data}}[\\log 2]+\\Bbb E_{x \\sim p_g}[\\log 2]  -\\log 4 \\\\\\\\ &=-\\log4 +\\Bbb E_{x \\sim p_{data}}\\left[\\log \\frac {P_{data}(x)} {\\frac {p_{data}(x)+p_g(x)} 2} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {\\frac {p_{data}(x)+p_g(x)} 2}\\right] \\\\\\\\ &=-\\log4+KL \\left(p_{data} \\| \\frac {p_{data}+p_g} 2 \\right)+KL \\left(p_g \\| \\frac {p_{data}+p_g} 2 \\right) \\\\\\\\ &=-\\log4 + 2\\cdot JSD(p_{data} \\| p_g) \\end{aligned}$$\n    KL  Kullback-Leibler JSD  Jensen-Shannon  JSD  $p_g=p_{data}$  0 C(G)=-log4 $p_g=p_{data}$  \n\n\n\n###  1 \n $p_g=p_{data}$__Proposition 2__  1 \n\n__Proposition 2.__  G  D  1  G  G  C(G)  $p_g$ \n$$\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))] \\qquad(5)$$\n$p_g$  $p_{data}$\n\n____\n\n $V(G,D)=U(p_g,D)$  $p_g$ $p_g$  (5)  $U(p_g,D)$  $p_g$  D  ____  D  $p_g$D  $p_g$ \n\n-  $f(x)=\\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$ $f_{\\alpha}(x)$  $\\alpha$  x  $\\beta=\\arg \\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$  $\\partial f_{\\beta}(x) \\in \\partial f(x)$\n\n$V(G,D)=U(p_g,D)$  $p_g$   $p_g$  D  D  D*  V(G,D)  (5) / $p_g$ $p_g$  $p_{data}$ Theorem 1\n\n (5)  1  SGD  $p_g$  $p_g$ D  $p_g$ \n\n $G(z;\\theta_g)$  $p_g$  $\\theta_g$  G  G  MLP $\\theta_g$  $p_g$  $p_g$   $\\theta_g$  MLP  G  (1)  $p_g$  batch $p_{data}$  batch  (1)  batch  log-likelihood function log \n\n## \n [adversarial](http://www.github.com/goodfeli/adversarial)\n\n>  Theano  Pylearn2github  GAN  [generative-models](https://github.com/wiseodd/generative-models)\n\n github  clone  adversarial  mnist \n\n mnist.yaml \n```yaml\n!obj:pylearn2.train.Train {         # \n    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {    #  mnist \n        which_set: 'train',                                 #  train  50000 \n        start: 0,\n        stop: 50000\n    },\n    model: !obj:adversarial.AdversaryPair {                 # GANG & D\n        generator: !obj:adversarial.Generator {             # G\n            noise: 'uniform',                               # noise \n            monitor_ll: 1,\n            mlp: !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.mlp.RectifiedLinear { #  ReLu  FC \n                         layer_name: 'h0',\n                         dim: 1200,                             #  output units \n                         irange: .05,\n                     },\n                     ...\n                     !obj:pylearn2.models.mlp.Sigmoid {     # FC  sigmoid\n                         init_bias: !obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals { dataset: *train},\n                         layer_name: 'y',\n                         irange: .05,\n                         dim: 784                               # 784=28x28 mnist \n                     }\n                    ],\n            nvis: 100,                                          # G \n        }},\n        discriminator:                                          # D\n            !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     ...\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         layer_name: 'y',\n                         dim: 1,                                # \n                         irange: .005\n                     }\n                    ],\n            nvis: 784,                                          # \n        },\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {      # \n        ...\n        cost: !obj:adversarial.AdversaryCost2 {                 # \n            scale_grads: 0,\n            #target_scale: 1.,\n            discriminator_default_input_include_prob: .5,\n            discriminator_input_include_probs: {\n                'h0': .8\n            },\n            discriminator_default_input_scale: 2.,\n            discriminator_input_scales: {\n                'h0': 1.25   \n            }\n            },\n        ...\n    },\n    ...\n}\n```\n mnist  `train`  50000  adversarial.AdversaryPair adversarial.Generator MLP MLP adversarial.AdversaryCost2 `__init__.py`  AdversaryCost2\n\n `get_samples_and_objectives`\n```python\ng=model.generator       # model is an instance of AdversaryPair\nd=model.discriminator\nX=data                  #  batch\nm=data.shape[space.get_batch_axis()]    #  batch \ny1=T.alloc(1,m,1)       #  m  1  label\ny0=T.alloc(0,m,1)       #  m  0  label\n# 1.  m  G  z\n# 2. G  m  S\nS,z,other_layers=g.sample_and_noise(m,\n    default_input_include_prob=self.generator_default_input_include_prob,   # 1\n    default_input_scale=self.generator_default_input_scale,                 # 1\n    all_g_layers=(self.infer_layer is not None)                         # False\n)\nif self.noise_both !=0:     # \n    ...\n# D  label  label\ny_hat1 = d.dropout_fprop(...)       # \ny_hat0 = d.dropout_fprop(...)\n# D d.layers[-1]  Sigmoid  KL \nd_obj = 0.5*(d.layers[-1].cost(y1,y_hat1)+d.layers[-1].cost(y0,y_hat0))\n# G G  D  y_hat0  label y1   \ng_obj = d.layers[-1].cost(y1,y_hat0)\nif model.inferer is not None:       # \n    ...\nelse:\n    i_obj = 0\nreturn S, d_obj, g_obj, i_obj       # D  G \n```\n `get_gradients` \n```python\ng=model.generator\nd=model.generator\nS,d_obj,g_obj,i_obj = self.get_samples_and_objectives(model,data)   # \ng_params = g.get_params()\nd_params = d.get_params()\n# \nd_grads = T.grad(d_obj,d_params)\ng_grads = T.grad(g_obj,g_params)\nif self.scale_grads:    #  g_grads\n    S_grad = T.grad(g_obj, S)   # G  G \n    # S_grad \n    scale = T.maximum(1.,self.target_scale/T.sqrt(T.sqr(S_grad).sum()))\n    #  g_grads\n    g_grads = [g_grad * scale for g_grad in g_grads]\n\n# \nrval = OrderDict()\nrval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg for dg in d_grads])))\nrval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg for gg in g_grads])))\n\nupdates = OrderDict()\nif self.alternate_g:\n    updates[self.now_train_generator]=1. - self.now_train_generator\nreturn rval, updates\n```\n Pylearn2/Theano \n\n log  1  `g_grads`  scale \n\n $S=\\theta_g \\cdot z$ $\\theta_g$ \n$$\\nabla_{\\theta_g}L=\\nabla_S L \\cdot \\frac {\\partial S}{\\partial \\theta_g}$$\n\n S  D  y_0$y_0=\\theta_d \\cdot S$\n$$\\nabla_S L=\\frac {dL}{dy_0}\\cdot \\theta_d$$\n G $\\nabla_S L$  D \n1.  L2  1 G  $\\nabla_{\\theta_g}L$   scale  $\\nabla_S L$  L2  `self.target_scale`1\n    G \n   ![](/images/GAN_fig2.png)<center>fig 2.  $G_0$  V(G,D)  $G_1$  V(G,D)  $D_1^{\\ast}$  G ~</center>\n\n    $D_0^{\\ast}$  $\\max_D V(G_0,D_0)=V(G_0,D_0^{\\ast})$ $G_0$  $G_1$ G  V(G,D) $V(G_1,D_0^{\\ast}) < V(G_0,D_0^{\\ast})$ D  V(G,D) $V(G_1,D_1^{\\ast}) < V(G_0,D_0^{\\ast})$ $D_1^{\\ast}$  $D_0^{\\ast}$  G  D  G  G  G  D  G \n2.  L2 1 scale \n\n\n\n\n\n## \n zG  z  G(z)D  G(z)  (1)  D  G G  D  G D ","source":"_posts/GAN.md","raw":"---\ntitle: GAN\ndate: 2019-07-23 10:15:08\ntags: GAN\nmathjax: true\n---\n [Generative Adversarial Nets](https://arxiv.org/abs/1406.2661)\n<!-- more -->\n# GAN\n## \n GAN G  DG D \n\n z $p_z(z)$G  z  $G(z;\\theta_g)$ G  MLP  $\\theta_g$D  MLP $D(x;\\theta_d)$  x  D  x  x $G(x)$  x  G  $D(G(z))$  G  $D(G(x))$  $\\log(1-D(G(z)))$ \n\n$$\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log D(x)] + \\Bbb E_{z \\sim p_z(z)}[\\log(1-D(G(z)))] \\qquad (1)$$\n\n D  log D  G  D  log \n\n 1 \n![](/images/GAN_fig1.png)\n\n 1  D  x  $p_x$ G  $p_g$  x  z  z  x  x=G(z) G   \n(a)  $p_g,\\ p_{data}$ D   \n(b)  D  $D^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)}$  \n(c) D  G(z) G   \n(d) G  D  $p_g=p_{data}$D $D(x)=1/2$\n\n\n![](/images/GAN_alg1.png)\n\nk  D  G  G  D \n\n(1)  GG  D $\\log (1-D(G(z)))$ log  G  $\\log D(G(z))$ G  D log \n\n## \n z  $p_z$  G  1 G G  $p_{data}$ $p_g=p_{data}$  (1) \n### \n__Proposition 1.__  GD \n$$D_G^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)} \\qquad (2)$$\n____   GD  V(G,D)  \n$$\\begin{aligned} V(G,D)&=\\int_x p_{data}(x) \\log D(x) dx+\\int_z p_z(z) \\log (1-D(g(z))) dz\n\\\\\\\\ &=\\int_x p_{data}(x) \\log D(x)+p_g(x) \\log(1-D(x))dx \\end{aligned}$$\n$\\forall (a,b) \\in \\Bbb R^2 \\setminus \\{0,0\\}$ $y \\rightarrow a \\log y+b \\log(1-y)$  (0,1)  $y=\\frac a {a+b}$  0  V(G,D)  x  D(x)  (2) \n\nD  $P(Y=y|x)$  log  binary cross-entropy x  $p_{data}$  y=1 x  $p_g$  y=0 D  $D_G^{\\ast}$  (1)   \n\n$$\\begin{aligned} C(G)&=\\max_D V(G,D)\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{z \\sim p_z} [\\log(1-D_G^{\\ast}(G(z)))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}} \\left[\\log \\frac {P_{data}(x)} {p_{data}(x)+p_g(x)} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {p_{data}(x)+p_g(x)}\\right] \\qquad(4) \\end{aligned}$$\n\n__Theorem 1.__  $p_g=p_{data}$  C(G)  -log4  \n\n____ \n\n1.   \n $p_g=p_{data}$ (2)  $D_G^{\\ast}(x)=1/2$ (4) \n$$C(G)=\\Bbb E_{x \\sim p_{data}}[-\\log 2]+\\Bbb E_{x \\sim p_g}[-\\log 2] \\equiv -\\log 4$$\n2.   \n   $$\\begin{aligned}C(G)&=C(G)+\\Bbb E_{x \\sim p_{data}}[\\log 2]+\\Bbb E_{x \\sim p_g}[\\log 2]  -\\log 4 \\\\\\\\ &=-\\log4 +\\Bbb E_{x \\sim p_{data}}\\left[\\log \\frac {P_{data}(x)} {\\frac {p_{data}(x)+p_g(x)} 2} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {\\frac {p_{data}(x)+p_g(x)} 2}\\right] \\\\\\\\ &=-\\log4+KL \\left(p_{data} \\| \\frac {p_{data}+p_g} 2 \\right)+KL \\left(p_g \\| \\frac {p_{data}+p_g} 2 \\right) \\\\\\\\ &=-\\log4 + 2\\cdot JSD(p_{data} \\| p_g) \\end{aligned}$$\n    KL  Kullback-Leibler JSD  Jensen-Shannon  JSD  $p_g=p_{data}$  0 C(G)=-log4 $p_g=p_{data}$  \n\n\n\n###  1 \n $p_g=p_{data}$__Proposition 2__  1 \n\n__Proposition 2.__  G  D  1  G  G  C(G)  $p_g$ \n$$\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))] \\qquad(5)$$\n$p_g$  $p_{data}$\n\n____\n\n $V(G,D)=U(p_g,D)$  $p_g$ $p_g$  (5)  $U(p_g,D)$  $p_g$  D  ____  D  $p_g$D  $p_g$ \n\n-  $f(x)=\\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$ $f_{\\alpha}(x)$  $\\alpha$  x  $\\beta=\\arg \\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$  $\\partial f_{\\beta}(x) \\in \\partial f(x)$\n\n$V(G,D)=U(p_g,D)$  $p_g$   $p_g$  D  D  D*  V(G,D)  (5) / $p_g$ $p_g$  $p_{data}$ Theorem 1\n\n (5)  1  SGD  $p_g$  $p_g$ D  $p_g$ \n\n $G(z;\\theta_g)$  $p_g$  $\\theta_g$  G  G  MLP $\\theta_g$  $p_g$  $p_g$   $\\theta_g$  MLP  G  (1)  $p_g$  batch $p_{data}$  batch  (1)  batch  log-likelihood function log \n\n## \n [adversarial](http://www.github.com/goodfeli/adversarial)\n\n>  Theano  Pylearn2github  GAN  [generative-models](https://github.com/wiseodd/generative-models)\n\n github  clone  adversarial  mnist \n\n mnist.yaml \n```yaml\n!obj:pylearn2.train.Train {         # \n    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {    #  mnist \n        which_set: 'train',                                 #  train  50000 \n        start: 0,\n        stop: 50000\n    },\n    model: !obj:adversarial.AdversaryPair {                 # GANG & D\n        generator: !obj:adversarial.Generator {             # G\n            noise: 'uniform',                               # noise \n            monitor_ll: 1,\n            mlp: !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.mlp.RectifiedLinear { #  ReLu  FC \n                         layer_name: 'h0',\n                         dim: 1200,                             #  output units \n                         irange: .05,\n                     },\n                     ...\n                     !obj:pylearn2.models.mlp.Sigmoid {     # FC  sigmoid\n                         init_bias: !obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals { dataset: *train},\n                         layer_name: 'y',\n                         irange: .05,\n                         dim: 784                               # 784=28x28 mnist \n                     }\n                    ],\n            nvis: 100,                                          # G \n        }},\n        discriminator:                                          # D\n            !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     ...\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         layer_name: 'y',\n                         dim: 1,                                # \n                         irange: .005\n                     }\n                    ],\n            nvis: 784,                                          # \n        },\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {      # \n        ...\n        cost: !obj:adversarial.AdversaryCost2 {                 # \n            scale_grads: 0,\n            #target_scale: 1.,\n            discriminator_default_input_include_prob: .5,\n            discriminator_input_include_probs: {\n                'h0': .8\n            },\n            discriminator_default_input_scale: 2.,\n            discriminator_input_scales: {\n                'h0': 1.25   \n            }\n            },\n        ...\n    },\n    ...\n}\n```\n mnist  `train`  50000  adversarial.AdversaryPair adversarial.Generator MLP MLP adversarial.AdversaryCost2 `__init__.py`  AdversaryCost2\n\n `get_samples_and_objectives`\n```python\ng=model.generator       # model is an instance of AdversaryPair\nd=model.discriminator\nX=data                  #  batch\nm=data.shape[space.get_batch_axis()]    #  batch \ny1=T.alloc(1,m,1)       #  m  1  label\ny0=T.alloc(0,m,1)       #  m  0  label\n# 1.  m  G  z\n# 2. G  m  S\nS,z,other_layers=g.sample_and_noise(m,\n    default_input_include_prob=self.generator_default_input_include_prob,   # 1\n    default_input_scale=self.generator_default_input_scale,                 # 1\n    all_g_layers=(self.infer_layer is not None)                         # False\n)\nif self.noise_both !=0:     # \n    ...\n# D  label  label\ny_hat1 = d.dropout_fprop(...)       # \ny_hat0 = d.dropout_fprop(...)\n# D d.layers[-1]  Sigmoid  KL \nd_obj = 0.5*(d.layers[-1].cost(y1,y_hat1)+d.layers[-1].cost(y0,y_hat0))\n# G G  D  y_hat0  label y1   \ng_obj = d.layers[-1].cost(y1,y_hat0)\nif model.inferer is not None:       # \n    ...\nelse:\n    i_obj = 0\nreturn S, d_obj, g_obj, i_obj       # D  G \n```\n `get_gradients` \n```python\ng=model.generator\nd=model.generator\nS,d_obj,g_obj,i_obj = self.get_samples_and_objectives(model,data)   # \ng_params = g.get_params()\nd_params = d.get_params()\n# \nd_grads = T.grad(d_obj,d_params)\ng_grads = T.grad(g_obj,g_params)\nif self.scale_grads:    #  g_grads\n    S_grad = T.grad(g_obj, S)   # G  G \n    # S_grad \n    scale = T.maximum(1.,self.target_scale/T.sqrt(T.sqr(S_grad).sum()))\n    #  g_grads\n    g_grads = [g_grad * scale for g_grad in g_grads]\n\n# \nrval = OrderDict()\nrval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg for dg in d_grads])))\nrval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg for gg in g_grads])))\n\nupdates = OrderDict()\nif self.alternate_g:\n    updates[self.now_train_generator]=1. - self.now_train_generator\nreturn rval, updates\n```\n Pylearn2/Theano \n\n log  1  `g_grads`  scale \n\n $S=\\theta_g \\cdot z$ $\\theta_g$ \n$$\\nabla_{\\theta_g}L=\\nabla_S L \\cdot \\frac {\\partial S}{\\partial \\theta_g}$$\n\n S  D  y_0$y_0=\\theta_d \\cdot S$\n$$\\nabla_S L=\\frac {dL}{dy_0}\\cdot \\theta_d$$\n G $\\nabla_S L$  D \n1.  L2  1 G  $\\nabla_{\\theta_g}L$   scale  $\\nabla_S L$  L2  `self.target_scale`1\n    G \n   ![](/images/GAN_fig2.png)<center>fig 2.  $G_0$  V(G,D)  $G_1$  V(G,D)  $D_1^{\\ast}$  G ~</center>\n\n    $D_0^{\\ast}$  $\\max_D V(G_0,D_0)=V(G_0,D_0^{\\ast})$ $G_0$  $G_1$ G  V(G,D) $V(G_1,D_0^{\\ast}) < V(G_0,D_0^{\\ast})$ D  V(G,D) $V(G_1,D_1^{\\ast}) < V(G_0,D_0^{\\ast})$ $D_1^{\\ast}$  $D_0^{\\ast}$  G  D  G  G  G  D  G \n2.  L2 1 scale \n\n\n\n\n\n## \n zG  z  G(z)D  G(z)  (1)  D  G G  D  G D ","slug":"GAN","published":1,"updated":"2020-04-24T10:37:46.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or928004wp0dj6adu34oj","content":"<p> <a href=\"https://arxiv.org/abs/1406.2661\">Generative Adversarial Nets</a><br><span id=\"more\"></span></p>\n<h1 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN\"></a>GAN</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> GAN G  DG D </p>\n<p> z $p_z(z)$G  z  $G(z;\\theta_g)$ G  MLP  $\\theta_g$D  MLP $D(x;\\theta_d)$  x  D  x  x $G(x)$  x  G  $D(G(z))$  G  $D(G(x))$  $\\log(1-D(G(z)))$ </p>\n<script type=\"math/tex; mode=display\">\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log D(x)] + \\Bbb E_{z \\sim p_z(z)}[\\log(1-D(G(z)))] \\qquad (1)</script><p> D  log D  G  D  log </p>\n<p> 1 <br><img src=\"/images/GAN_fig1.png\" alt=\"\"></p>\n<p> 1  D  x  $p_x$ G  $p_g$  x  z  z  x  x=G(z) G <br>(a)  $p_g,\\ p_{data}$ D <br>(b)  D  $D^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)}$<br>(c) D  G(z) G <br>(d) G  D  $p_g=p_{data}$D $D(x)=1/2$</p>\n<p><br><img src=\"/images/GAN_alg1.png\" alt=\"\"></p>\n<p>k  D  G  G  D </p>\n<p>(1)  GG  D $\\log (1-D(G(z)))$ log  G  $\\log D(G(z))$ G  D log </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> z  $p_z$  G  1 G G  $p_{data}$ $p_g=p_{data}$  (1) </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Proposition 1.</strong>  GD </p>\n<script type=\"math/tex; mode=display\">D_G^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)} \\qquad (2)</script><p><strong></strong>   GD  V(G,D)  </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} V(G,D)&=\\int_x p_{data}(x) \\log D(x) dx+\\int_z p_z(z) \\log (1-D(g(z))) dz\n\\\\\\\\ &=\\int_x p_{data}(x) \\log D(x)+p_g(x) \\log(1-D(x))dx \\end{aligned}</script><p>$\\forall (a,b) \\in \\Bbb R^2 \\setminus \\{0,0\\}$ $y \\rightarrow a \\log y+b \\log(1-y)$  (0,1)  $y=\\frac a {a+b}$  0  V(G,D)  x  D(x)  (2) </p>\n<p>D  $P(Y=y|x)$  log  binary cross-entropy x  $p_{data}$  y=1 x  $p_g$  y=0 D  $D_G^{\\ast}$  (1)   </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} C(G)&=\\max_D V(G,D)\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{z \\sim p_z} [\\log(1-D_G^{\\ast}(G(z)))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}} \\left[\\log \\frac {P_{data}(x)} {p_{data}(x)+p_g(x)} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {p_{data}(x)+p_g(x)}\\right] \\qquad(4) \\end{aligned}</script><p><strong>Theorem 1.</strong>  $p_g=p_{data}$  C(G)  -log4  </p>\n<p><strong></strong> </p>\n<ol>\n<li><br> $p_g=p_{data}$ (2)  $D_G^{\\ast}(x)=1/2$ (4) <script type=\"math/tex; mode=display\">C(G)=\\Bbb E_{x \\sim p_{data}}[-\\log 2]+\\Bbb E_{x \\sim p_g}[-\\log 2] \\equiv -\\log 4</script></li>\n<li>  <script type=\"math/tex; mode=display\">\\begin{aligned}C(G)&=C(G)+\\Bbb E_{x \\sim p_{data}}[\\log 2]+\\Bbb E_{x \\sim p_g}[\\log 2]  -\\log 4 \\\\\\\\ &=-\\log4 +\\Bbb E_{x \\sim p_{data}}\\left[\\log \\frac {P_{data}(x)} {\\frac {p_{data}(x)+p_g(x)} 2} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {\\frac {p_{data}(x)+p_g(x)} 2}\\right] \\\\\\\\ &=-\\log4+KL \\left(p_{data} \\| \\frac {p_{data}+p_g} 2 \\right)+KL \\left(p_g \\| \\frac {p_{data}+p_g} 2 \\right) \\\\\\\\ &=-\\log4 + 2\\cdot JSD(p_{data} \\| p_g) \\end{aligned}</script> KL  Kullback-Leibler JSD  Jensen-Shannon  JSD  $p_g=p_{data}$  0 C(G)=-log4 $p_g=p_{data}$  </li>\n</ol>\n<p></p>\n<h3 id=\"-1-\"><a href=\"#-1-\" class=\"headerlink\" title=\" 1 \"></a> 1 </h3><p> $p_g=p_{data}$<strong>Proposition 2</strong>  1 </p>\n<p><strong>Proposition 2.</strong>  G  D  1  G  G  C(G)  $p_g$ </p>\n<script type=\"math/tex; mode=display\">\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))] \\qquad(5)</script><p>$p_g$  $p_{data}$</p>\n<p><strong></strong></p>\n<p> $V(G,D)=U(p_g,D)$  $p_g$ $p_g$  (5)  $U(p_g,D)$  $p_g$  D  <strong></strong>  D  $p_g$D  $p_g$ </p>\n<ul>\n<li> $f(x)=\\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$ $f_{\\alpha}(x)$  $\\alpha$  x  $\\beta=\\arg \\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$  $\\partial f_{\\beta}(x) \\in \\partial f(x)$</li>\n</ul>\n<p>$V(G,D)=U(p_g,D)$  $p_g$   $p_g$  D  D  D*  V(G,D)  (5) / $p_g$ $p_g$  $p_{data}$ Theorem 1</p>\n<p> (5)  1  SGD  $p_g$  $p_g$ D  $p_g$ </p>\n<p> $G(z;\\theta_g)$  $p_g$  $\\theta_g$  G  G  MLP $\\theta_g$  $p_g$  $p_g$   $\\theta_g$  MLP  G  (1)  $p_g$  batch $p_{data}$  batch  (1)  batch  log-likelihood function log </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <a href=\"http://www.github.com/goodfeli/adversarial\">adversarial</a></p>\n<blockquote>\n<p> Theano  Pylearn2github  GAN  <a href=\"https://github.com/wiseodd/generative-models\">generative-models</a></p>\n</blockquote>\n<p> github  clone  adversarial  mnist </p>\n<p> mnist.yaml <br><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">!obj:pylearn2.train.Train</span> &#123;         <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"attr\">dataset:</span> <span class=\"string\">&amp;train</span> <span class=\"type\">!obj:pylearn2.datasets.mnist.MNIST</span> &#123;    <span class=\"comment\">#  mnist </span></span><br><span class=\"line\">        <span class=\"attr\">which_set:</span> <span class=\"string\">&#x27;train&#x27;</span>,                                 <span class=\"comment\">#  train  50000 </span></span><br><span class=\"line\">        <span class=\"attr\">start:</span> <span class=\"number\">0</span>,</span><br><span class=\"line\">        <span class=\"attr\">stop:</span> <span class=\"number\">50000</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">model:</span> <span class=\"type\">!obj:adversarial.AdversaryPair</span> &#123;                 <span class=\"comment\"># GANG &amp; D</span></span><br><span class=\"line\">        <span class=\"attr\">generator:</span> <span class=\"type\">!obj:adversarial.Generator</span> &#123;             <span class=\"comment\"># G</span></span><br><span class=\"line\">            <span class=\"attr\">noise:</span> <span class=\"string\">&#x27;uniform&#x27;</span>,                               <span class=\"comment\"># noise </span></span><br><span class=\"line\">            <span class=\"attr\">monitor_ll:</span> <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">mlp:</span> <span class=\"type\">!obj:pylearn2.models.mlp.MLP</span> &#123;</span><br><span class=\"line\">            <span class=\"attr\">layers:</span> [</span><br><span class=\"line\">                     <span class=\"type\">!obj:pylearn2.models.mlp.RectifiedLinear</span> &#123; <span class=\"comment\">#  ReLu  FC </span></span><br><span class=\"line\">                         <span class=\"attr\">layer_name:</span> <span class=\"string\">&#x27;h0&#x27;</span>,</span><br><span class=\"line\">                         <span class=\"attr\">dim:</span> <span class=\"number\">1200</span>,                             <span class=\"comment\">#  output units </span></span><br><span class=\"line\">                         <span class=\"attr\">irange:</span> <span class=\"number\">.05</span>,</span><br><span class=\"line\">                     &#125;,</span><br><span class=\"line\">                     <span class=\"string\">...</span></span><br><span class=\"line\">                     <span class=\"type\">!obj:pylearn2.models.mlp.Sigmoid</span> &#123;     <span class=\"comment\"># FC  sigmoid</span></span><br><span class=\"line\">                         <span class=\"attr\">init_bias:</span> <span class=\"type\">!obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals</span> &#123; <span class=\"attr\">dataset:</span> <span class=\"string\">*train</span>&#125;,</span><br><span class=\"line\">                         <span class=\"attr\">layer_name:</span> <span class=\"string\">&#x27;y&#x27;</span>,</span><br><span class=\"line\">                         <span class=\"attr\">irange:</span> <span class=\"number\">.05</span>,</span><br><span class=\"line\">                         <span class=\"attr\">dim:</span> <span class=\"number\">784</span>                               <span class=\"comment\"># 784=28x28 mnist </span></span><br><span class=\"line\">                     &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">            <span class=\"attr\">nvis:</span> <span class=\"number\">100</span>,                                          <span class=\"comment\"># G </span></span><br><span class=\"line\">        &#125;&#125;,</span><br><span class=\"line\">        <span class=\"attr\">discriminator:</span>                                          <span class=\"comment\"># D</span></span><br><span class=\"line\">            <span class=\"type\">!obj:pylearn2.models.mlp.MLP</span> &#123;</span><br><span class=\"line\">            <span class=\"attr\">layers:</span> [</span><br><span class=\"line\">                     <span class=\"string\">...</span></span><br><span class=\"line\">                     <span class=\"type\">!obj:pylearn2.models.mlp.Sigmoid</span> &#123;</span><br><span class=\"line\">                         <span class=\"attr\">layer_name:</span> <span class=\"string\">&#x27;y&#x27;</span>,</span><br><span class=\"line\">                         <span class=\"attr\">dim:</span> <span class=\"number\">1</span>,                                <span class=\"comment\"># </span></span><br><span class=\"line\">                         <span class=\"attr\">irange:</span> <span class=\"number\">.005</span></span><br><span class=\"line\">                     &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">            <span class=\"attr\">nvis:</span> <span class=\"number\">784</span>,                                          <span class=\"comment\"># </span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">algorithm:</span> <span class=\"type\">!obj:pylearn2.training_algorithms.sgd.SGD</span> &#123;      <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"string\">...</span></span><br><span class=\"line\">        <span class=\"attr\">cost:</span> <span class=\"type\">!obj:adversarial.AdversaryCost2</span> &#123;                 <span class=\"comment\"># </span></span><br><span class=\"line\">            <span class=\"attr\">scale_grads:</span> <span class=\"number\">0</span>,</span><br><span class=\"line\">            <span class=\"comment\">#target_scale: 1.,</span></span><br><span class=\"line\">            <span class=\"attr\">discriminator_default_input_include_prob:</span> <span class=\"number\">.5</span>,</span><br><span class=\"line\">            <span class=\"attr\">discriminator_input_include_probs:</span> &#123;</span><br><span class=\"line\">                <span class=\"attr\">&#x27;h0&#x27;:</span> <span class=\"number\">.8</span></span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"attr\">discriminator_default_input_scale:</span> <span class=\"number\">2</span><span class=\"string\">.</span>,</span><br><span class=\"line\">            <span class=\"attr\">discriminator_input_scales:</span> &#123;</span><br><span class=\"line\">                <span class=\"attr\">&#x27;h0&#x27;:</span> <span class=\"number\">1.25</span>   </span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        <span class=\"string\">...</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> mnist  <code>train</code>  50000  adversarial.AdversaryPair adversarial.Generator MLP MLP adversarial.AdversaryCost2 <code>__init__.py</code>  AdversaryCost2</p>\n<p> <code>get_samples_and_objectives</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g=model.generator       <span class=\"comment\"># model is an instance of AdversaryPair</span></span><br><span class=\"line\">d=model.discriminator</span><br><span class=\"line\">X=data                  <span class=\"comment\">#  batch</span></span><br><span class=\"line\">m=data.shape[space.get_batch_axis()]    <span class=\"comment\">#  batch </span></span><br><span class=\"line\">y1=T.alloc(<span class=\"number\">1</span>,m,<span class=\"number\">1</span>)       <span class=\"comment\">#  m  1  label</span></span><br><span class=\"line\">y0=T.alloc(<span class=\"number\">0</span>,m,<span class=\"number\">1</span>)       <span class=\"comment\">#  m  0  label</span></span><br><span class=\"line\"><span class=\"comment\"># 1.  m  G  z</span></span><br><span class=\"line\"><span class=\"comment\"># 2. G  m  S</span></span><br><span class=\"line\">S,z,other_layers=g.sample_and_noise(m,</span><br><span class=\"line\">    default_input_include_prob=self.generator_default_input_include_prob,   <span class=\"comment\"># 1</span></span><br><span class=\"line\">    default_input_scale=self.generator_default_input_scale,                 <span class=\"comment\"># 1</span></span><br><span class=\"line\">    all_g_layers=(self.infer_layer <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>)                         <span class=\"comment\"># False</span></span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> self.noise_both !=<span class=\"number\">0</span>:     <span class=\"comment\"># </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"comment\"># D  label  label</span></span><br><span class=\"line\">y_hat1 = d.dropout_fprop(...)       <span class=\"comment\"># </span></span><br><span class=\"line\">y_hat0 = d.dropout_fprop(...)</span><br><span class=\"line\"><span class=\"comment\"># D d.layers[-1]  Sigmoid  KL </span></span><br><span class=\"line\">d_obj = <span class=\"number\">0.5</span>*(d.layers[-<span class=\"number\">1</span>].cost(y1,y_hat1)+d.layers[-<span class=\"number\">1</span>].cost(y0,y_hat0))</span><br><span class=\"line\"><span class=\"comment\"># G G  D  y_hat0  label y1   </span></span><br><span class=\"line\">g_obj = d.layers[-<span class=\"number\">1</span>].cost(y1,y_hat0)</span><br><span class=\"line\"><span class=\"keyword\">if</span> model.inferer <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:       <span class=\"comment\"># </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    i_obj = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">return</span> S, d_obj, g_obj, i_obj       <span class=\"comment\"># D  G </span></span><br></pre></td></tr></table></figure><br> <code>get_gradients</code> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g=model.generator</span><br><span class=\"line\">d=model.generator</span><br><span class=\"line\">S,d_obj,g_obj,i_obj = self.get_samples_and_objectives(model,data)   <span class=\"comment\"># </span></span><br><span class=\"line\">g_params = g.get_params()</span><br><span class=\"line\">d_params = d.get_params()</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">d_grads = T.grad(d_obj,d_params)</span><br><span class=\"line\">g_grads = T.grad(g_obj,g_params)</span><br><span class=\"line\"><span class=\"keyword\">if</span> self.scale_grads:    <span class=\"comment\">#  g_grads</span></span><br><span class=\"line\">    S_grad = T.grad(g_obj, S)   <span class=\"comment\"># G  G </span></span><br><span class=\"line\">    <span class=\"comment\"># S_grad </span></span><br><span class=\"line\">    scale = T.maximum(<span class=\"number\">1.</span>,self.target_scale/T.sqrt(T.sqr(S_grad).<span class=\"built_in\">sum</span>()))</span><br><span class=\"line\">    <span class=\"comment\">#  g_grads</span></span><br><span class=\"line\">    g_grads = [g_grad * scale <span class=\"keyword\">for</span> g_grad <span class=\"keyword\">in</span> g_grads]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">rval = OrderDict()</span><br><span class=\"line\">rval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg <span class=\"keyword\">for</span> dg <span class=\"keyword\">in</span> d_grads])))</span><br><span class=\"line\">rval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg <span class=\"keyword\">for</span> gg <span class=\"keyword\">in</span> g_grads])))</span><br><span class=\"line\"></span><br><span class=\"line\">updates = OrderDict()</span><br><span class=\"line\"><span class=\"keyword\">if</span> self.alternate_g:</span><br><span class=\"line\">    updates[self.now_train_generator]=<span class=\"number\">1.</span> - self.now_train_generator</span><br><span class=\"line\"><span class=\"keyword\">return</span> rval, updates</span><br></pre></td></tr></table></figure><br> Pylearn2/Theano </p>\n<p> log  1  <code>g_grads</code>  scale </p>\n<p> $S=\\theta_g \\cdot z$ $\\theta_g$ </p>\n<script type=\"math/tex; mode=display\">\\nabla_{\\theta_g}L=\\nabla_S L \\cdot \\frac {\\partial S}{\\partial \\theta_g}</script><p> S  D  y_0$y_0=\\theta_d \\cdot S$</p>\n<script type=\"math/tex; mode=display\">\\nabla_S L=\\frac {dL}{dy_0}\\cdot \\theta_d</script><p> G $\\nabla_S L$  D </p>\n<ol>\n<li><p> L2  1 G  $\\nabla_{\\theta_g}L$   scale  $\\nabla_S L$  L2  <code>self.target_scale</code>1<br> G <br><img src=\"/images/GAN_fig2.png\" alt=\"\"><center>fig 2.  $G_0$  V(G,D)  $G_1$  V(G,D)  $D_1^{\\ast}$  G ~</center></p>\n<p> $D_0^{\\ast}$  $\\max_D V(G_0,D_0)=V(G_0,D_0^{\\ast})$ $G_0$  $G_1$ G  V(G,D) $V(G_1,D_0^{\\ast}) &lt; V(G_0,D_0^{\\ast})$ D  V(G,D) $V(G_1,D_1^{\\ast}) &lt; V(G_0,D_0^{\\ast})$ $D_1^{\\ast}$  $D_0^{\\ast}$  G  D  G  G  G  D  G </p>\n</li>\n<li> L2 1 scale </li>\n</ol>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> zG  z  G(z)D  G(z)  (1)  D  G G  D  G D </p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1406.2661\">Generative Adversarial Nets</a><br>","more":"</p>\n<h1 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN\"></a>GAN</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> GAN G  DG D </p>\n<p> z $p_z(z)$G  z  $G(z;\\theta_g)$ G  MLP  $\\theta_g$D  MLP $D(x;\\theta_d)$  x  D  x  x $G(x)$  x  G  $D(G(z))$  G  $D(G(x))$  $\\log(1-D(G(z)))$ </p>\n<script type=\"math/tex; mode=display\">\\min_G \\max_D V(D,G)=\\Bbb E_{x \\sim p_{data}(x)}[\\log D(x)] + \\Bbb E_{z \\sim p_z(z)}[\\log(1-D(G(z)))] \\qquad (1)</script><p> D  log D  G  D  log </p>\n<p> 1 <br><img src=\"/images/GAN_fig1.png\" alt=\"\"></p>\n<p> 1  D  x  $p_x$ G  $p_g$  x  z  z  x  x=G(z) G <br>(a)  $p_g,\\ p_{data}$ D <br>(b)  D  $D^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)}$<br>(c) D  G(z) G <br>(d) G  D  $p_g=p_{data}$D $D(x)=1/2$</p>\n<p><br><img src=\"/images/GAN_alg1.png\" alt=\"\"></p>\n<p>k  D  G  G  D </p>\n<p>(1)  GG  D $\\log (1-D(G(z)))$ log  G  $\\log D(G(z))$ G  D log </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> z  $p_z$  G  1 G G  $p_{data}$ $p_g=p_{data}$  (1) </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Proposition 1.</strong>  GD </p>\n<script type=\"math/tex; mode=display\">D_G^{\\ast}(x)=\\frac {p_{data}(x)}{p_{data}(x)+p_g(x)} \\qquad (2)</script><p><strong></strong>   GD  V(G,D)  </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} V(G,D)&=\\int_x p_{data}(x) \\log D(x) dx+\\int_z p_z(z) \\log (1-D(g(z))) dz\n\\\\\\\\ &=\\int_x p_{data}(x) \\log D(x)+p_g(x) \\log(1-D(x))dx \\end{aligned}</script><p>$\\forall (a,b) \\in \\Bbb R^2 \\setminus \\{0,0\\}$ $y \\rightarrow a \\log y+b \\log(1-y)$  (0,1)  $y=\\frac a {a+b}$  0  V(G,D)  x  D(x)  (2) </p>\n<p>D  $P(Y=y|x)$  log  binary cross-entropy x  $p_{data}$  y=1 x  $p_g$  y=0 D  $D_G^{\\ast}$  (1)   </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} C(G)&=\\max_D V(G,D)\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{z \\sim p_z} [\\log(1-D_G^{\\ast}(G(z)))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))]\n\\\\\\\\ &=\\Bbb E_{x \\sim p_{data}} \\left[\\log \\frac {P_{data}(x)} {p_{data}(x)+p_g(x)} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {p_{data}(x)+p_g(x)}\\right] \\qquad(4) \\end{aligned}</script><p><strong>Theorem 1.</strong>  $p_g=p_{data}$  C(G)  -log4  </p>\n<p><strong></strong> </p>\n<ol>\n<li><br> $p_g=p_{data}$ (2)  $D_G^{\\ast}(x)=1/2$ (4) <script type=\"math/tex; mode=display\">C(G)=\\Bbb E_{x \\sim p_{data}}[-\\log 2]+\\Bbb E_{x \\sim p_g}[-\\log 2] \\equiv -\\log 4</script></li>\n<li>  <script type=\"math/tex; mode=display\">\\begin{aligned}C(G)&=C(G)+\\Bbb E_{x \\sim p_{data}}[\\log 2]+\\Bbb E_{x \\sim p_g}[\\log 2]  -\\log 4 \\\\\\\\ &=-\\log4 +\\Bbb E_{x \\sim p_{data}}\\left[\\log \\frac {P_{data}(x)} {\\frac {p_{data}(x)+p_g(x)} 2} \\right]+\\Bbb E_{x \\sim p_g} \\left[\\log \\frac {p_g(x)} {\\frac {p_{data}(x)+p_g(x)} 2}\\right] \\\\\\\\ &=-\\log4+KL \\left(p_{data} \\| \\frac {p_{data}+p_g} 2 \\right)+KL \\left(p_g \\| \\frac {p_{data}+p_g} 2 \\right) \\\\\\\\ &=-\\log4 + 2\\cdot JSD(p_{data} \\| p_g) \\end{aligned}</script> KL  Kullback-Leibler JSD  Jensen-Shannon  JSD  $p_g=p_{data}$  0 C(G)=-log4 $p_g=p_{data}$  </li>\n</ol>\n<p></p>\n<h3 id=\"-1-\"><a href=\"#-1-\" class=\"headerlink\" title=\" 1 \"></a> 1 </h3><p> $p_g=p_{data}$<strong>Proposition 2</strong>  1 </p>\n<p><strong>Proposition 2.</strong>  G  D  1  G  G  C(G)  $p_g$ </p>\n<script type=\"math/tex; mode=display\">\\Bbb E_{x \\sim p_{data}}[\\log D_G^{\\ast}(x)] + \\Bbb E_{x \\sim p_g} [\\log(1-D_G^{\\ast}(x))] \\qquad(5)</script><p>$p_g$  $p_{data}$</p>\n<p><strong></strong></p>\n<p> $V(G,D)=U(p_g,D)$  $p_g$ $p_g$  (5)  $U(p_g,D)$  $p_g$  D  <strong></strong>  D  $p_g$D  $p_g$ </p>\n<ul>\n<li> $f(x)=\\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$ $f_{\\alpha}(x)$  $\\alpha$  x  $\\beta=\\arg \\sup_{\\alpha \\in \\mathcal A} f_{\\alpha}(x)$  $\\partial f_{\\beta}(x) \\in \\partial f(x)$</li>\n</ul>\n<p>$V(G,D)=U(p_g,D)$  $p_g$   $p_g$  D  D  D*  V(G,D)  (5) / $p_g$ $p_g$  $p_{data}$ Theorem 1</p>\n<p> (5)  1  SGD  $p_g$  $p_g$ D  $p_g$ </p>\n<p> $G(z;\\theta_g)$  $p_g$  $\\theta_g$  G  G  MLP $\\theta_g$  $p_g$  $p_g$   $\\theta_g$  MLP  G  (1)  $p_g$  batch $p_{data}$  batch  (1)  batch  log-likelihood function log </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> <a href=\"http://www.github.com/goodfeli/adversarial\">adversarial</a></p>\n<blockquote>\n<p> Theano  Pylearn2github  GAN  <a href=\"https://github.com/wiseodd/generative-models\">generative-models</a></p>\n</blockquote>\n<p> github  clone  adversarial  mnist </p>\n<p> mnist.yaml <br><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">!obj:pylearn2.train.Train</span> &#123;         <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"attr\">dataset:</span> <span class=\"string\">&amp;train</span> <span class=\"type\">!obj:pylearn2.datasets.mnist.MNIST</span> &#123;    <span class=\"comment\">#  mnist </span></span><br><span class=\"line\">        <span class=\"attr\">which_set:</span> <span class=\"string\">&#x27;train&#x27;</span>,                                 <span class=\"comment\">#  train  50000 </span></span><br><span class=\"line\">        <span class=\"attr\">start:</span> <span class=\"number\">0</span>,</span><br><span class=\"line\">        <span class=\"attr\">stop:</span> <span class=\"number\">50000</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">model:</span> <span class=\"type\">!obj:adversarial.AdversaryPair</span> &#123;                 <span class=\"comment\"># GANG &amp; D</span></span><br><span class=\"line\">        <span class=\"attr\">generator:</span> <span class=\"type\">!obj:adversarial.Generator</span> &#123;             <span class=\"comment\"># G</span></span><br><span class=\"line\">            <span class=\"attr\">noise:</span> <span class=\"string\">&#x27;uniform&#x27;</span>,                               <span class=\"comment\"># noise </span></span><br><span class=\"line\">            <span class=\"attr\">monitor_ll:</span> <span class=\"number\">1</span>,</span><br><span class=\"line\">            <span class=\"attr\">mlp:</span> <span class=\"type\">!obj:pylearn2.models.mlp.MLP</span> &#123;</span><br><span class=\"line\">            <span class=\"attr\">layers:</span> [</span><br><span class=\"line\">                     <span class=\"type\">!obj:pylearn2.models.mlp.RectifiedLinear</span> &#123; <span class=\"comment\">#  ReLu  FC </span></span><br><span class=\"line\">                         <span class=\"attr\">layer_name:</span> <span class=\"string\">&#x27;h0&#x27;</span>,</span><br><span class=\"line\">                         <span class=\"attr\">dim:</span> <span class=\"number\">1200</span>,                             <span class=\"comment\">#  output units </span></span><br><span class=\"line\">                         <span class=\"attr\">irange:</span> <span class=\"number\">.05</span>,</span><br><span class=\"line\">                     &#125;,</span><br><span class=\"line\">                     <span class=\"string\">...</span></span><br><span class=\"line\">                     <span class=\"type\">!obj:pylearn2.models.mlp.Sigmoid</span> &#123;     <span class=\"comment\"># FC  sigmoid</span></span><br><span class=\"line\">                         <span class=\"attr\">init_bias:</span> <span class=\"type\">!obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals</span> &#123; <span class=\"attr\">dataset:</span> <span class=\"string\">*train</span>&#125;,</span><br><span class=\"line\">                         <span class=\"attr\">layer_name:</span> <span class=\"string\">&#x27;y&#x27;</span>,</span><br><span class=\"line\">                         <span class=\"attr\">irange:</span> <span class=\"number\">.05</span>,</span><br><span class=\"line\">                         <span class=\"attr\">dim:</span> <span class=\"number\">784</span>                               <span class=\"comment\"># 784=28x28 mnist </span></span><br><span class=\"line\">                     &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">            <span class=\"attr\">nvis:</span> <span class=\"number\">100</span>,                                          <span class=\"comment\"># G </span></span><br><span class=\"line\">        &#125;&#125;,</span><br><span class=\"line\">        <span class=\"attr\">discriminator:</span>                                          <span class=\"comment\"># D</span></span><br><span class=\"line\">            <span class=\"type\">!obj:pylearn2.models.mlp.MLP</span> &#123;</span><br><span class=\"line\">            <span class=\"attr\">layers:</span> [</span><br><span class=\"line\">                     <span class=\"string\">...</span></span><br><span class=\"line\">                     <span class=\"type\">!obj:pylearn2.models.mlp.Sigmoid</span> &#123;</span><br><span class=\"line\">                         <span class=\"attr\">layer_name:</span> <span class=\"string\">&#x27;y&#x27;</span>,</span><br><span class=\"line\">                         <span class=\"attr\">dim:</span> <span class=\"number\">1</span>,                                <span class=\"comment\"># </span></span><br><span class=\"line\">                         <span class=\"attr\">irange:</span> <span class=\"number\">.005</span></span><br><span class=\"line\">                     &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">            <span class=\"attr\">nvis:</span> <span class=\"number\">784</span>,                                          <span class=\"comment\"># </span></span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">algorithm:</span> <span class=\"type\">!obj:pylearn2.training_algorithms.sgd.SGD</span> &#123;      <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"string\">...</span></span><br><span class=\"line\">        <span class=\"attr\">cost:</span> <span class=\"type\">!obj:adversarial.AdversaryCost2</span> &#123;                 <span class=\"comment\"># </span></span><br><span class=\"line\">            <span class=\"attr\">scale_grads:</span> <span class=\"number\">0</span>,</span><br><span class=\"line\">            <span class=\"comment\">#target_scale: 1.,</span></span><br><span class=\"line\">            <span class=\"attr\">discriminator_default_input_include_prob:</span> <span class=\"number\">.5</span>,</span><br><span class=\"line\">            <span class=\"attr\">discriminator_input_include_probs:</span> &#123;</span><br><span class=\"line\">                <span class=\"attr\">&#x27;h0&#x27;:</span> <span class=\"number\">.8</span></span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"attr\">discriminator_default_input_scale:</span> <span class=\"number\">2</span><span class=\"string\">.</span>,</span><br><span class=\"line\">            <span class=\"attr\">discriminator_input_scales:</span> &#123;</span><br><span class=\"line\">                <span class=\"attr\">&#x27;h0&#x27;:</span> <span class=\"number\">1.25</span>   </span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        <span class=\"string\">...</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">...</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> mnist  <code>train</code>  50000  adversarial.AdversaryPair adversarial.Generator MLP MLP adversarial.AdversaryCost2 <code>__init__.py</code>  AdversaryCost2</p>\n<p> <code>get_samples_and_objectives</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g=model.generator       <span class=\"comment\"># model is an instance of AdversaryPair</span></span><br><span class=\"line\">d=model.discriminator</span><br><span class=\"line\">X=data                  <span class=\"comment\">#  batch</span></span><br><span class=\"line\">m=data.shape[space.get_batch_axis()]    <span class=\"comment\">#  batch </span></span><br><span class=\"line\">y1=T.alloc(<span class=\"number\">1</span>,m,<span class=\"number\">1</span>)       <span class=\"comment\">#  m  1  label</span></span><br><span class=\"line\">y0=T.alloc(<span class=\"number\">0</span>,m,<span class=\"number\">1</span>)       <span class=\"comment\">#  m  0  label</span></span><br><span class=\"line\"><span class=\"comment\"># 1.  m  G  z</span></span><br><span class=\"line\"><span class=\"comment\"># 2. G  m  S</span></span><br><span class=\"line\">S,z,other_layers=g.sample_and_noise(m,</span><br><span class=\"line\">    default_input_include_prob=self.generator_default_input_include_prob,   <span class=\"comment\"># 1</span></span><br><span class=\"line\">    default_input_scale=self.generator_default_input_scale,                 <span class=\"comment\"># 1</span></span><br><span class=\"line\">    all_g_layers=(self.infer_layer <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>)                         <span class=\"comment\"># False</span></span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> self.noise_both !=<span class=\"number\">0</span>:     <span class=\"comment\"># </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"comment\"># D  label  label</span></span><br><span class=\"line\">y_hat1 = d.dropout_fprop(...)       <span class=\"comment\"># </span></span><br><span class=\"line\">y_hat0 = d.dropout_fprop(...)</span><br><span class=\"line\"><span class=\"comment\"># D d.layers[-1]  Sigmoid  KL </span></span><br><span class=\"line\">d_obj = <span class=\"number\">0.5</span>*(d.layers[-<span class=\"number\">1</span>].cost(y1,y_hat1)+d.layers[-<span class=\"number\">1</span>].cost(y0,y_hat0))</span><br><span class=\"line\"><span class=\"comment\"># G G  D  y_hat0  label y1   </span></span><br><span class=\"line\">g_obj = d.layers[-<span class=\"number\">1</span>].cost(y1,y_hat0)</span><br><span class=\"line\"><span class=\"keyword\">if</span> model.inferer <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:       <span class=\"comment\"># </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    i_obj = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">return</span> S, d_obj, g_obj, i_obj       <span class=\"comment\"># D  G </span></span><br></pre></td></tr></table></figure><br> <code>get_gradients</code> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g=model.generator</span><br><span class=\"line\">d=model.generator</span><br><span class=\"line\">S,d_obj,g_obj,i_obj = self.get_samples_and_objectives(model,data)   <span class=\"comment\"># </span></span><br><span class=\"line\">g_params = g.get_params()</span><br><span class=\"line\">d_params = d.get_params()</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">d_grads = T.grad(d_obj,d_params)</span><br><span class=\"line\">g_grads = T.grad(g_obj,g_params)</span><br><span class=\"line\"><span class=\"keyword\">if</span> self.scale_grads:    <span class=\"comment\">#  g_grads</span></span><br><span class=\"line\">    S_grad = T.grad(g_obj, S)   <span class=\"comment\"># G  G </span></span><br><span class=\"line\">    <span class=\"comment\"># S_grad </span></span><br><span class=\"line\">    scale = T.maximum(<span class=\"number\">1.</span>,self.target_scale/T.sqrt(T.sqr(S_grad).<span class=\"built_in\">sum</span>()))</span><br><span class=\"line\">    <span class=\"comment\">#  g_grads</span></span><br><span class=\"line\">    g_grads = [g_grad * scale <span class=\"keyword\">for</span> g_grad <span class=\"keyword\">in</span> g_grads]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">rval = OrderDict()</span><br><span class=\"line\">rval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg <span class=\"keyword\">for</span> dg <span class=\"keyword\">in</span> d_grads])))</span><br><span class=\"line\">rval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg <span class=\"keyword\">for</span> gg <span class=\"keyword\">in</span> g_grads])))</span><br><span class=\"line\"></span><br><span class=\"line\">updates = OrderDict()</span><br><span class=\"line\"><span class=\"keyword\">if</span> self.alternate_g:</span><br><span class=\"line\">    updates[self.now_train_generator]=<span class=\"number\">1.</span> - self.now_train_generator</span><br><span class=\"line\"><span class=\"keyword\">return</span> rval, updates</span><br></pre></td></tr></table></figure><br> Pylearn2/Theano </p>\n<p> log  1  <code>g_grads</code>  scale </p>\n<p> $S=\\theta_g \\cdot z$ $\\theta_g$ </p>\n<script type=\"math/tex; mode=display\">\\nabla_{\\theta_g}L=\\nabla_S L \\cdot \\frac {\\partial S}{\\partial \\theta_g}</script><p> S  D  y_0$y_0=\\theta_d \\cdot S$</p>\n<script type=\"math/tex; mode=display\">\\nabla_S L=\\frac {dL}{dy_0}\\cdot \\theta_d</script><p> G $\\nabla_S L$  D </p>\n<ol>\n<li><p> L2  1 G  $\\nabla_{\\theta_g}L$   scale  $\\nabla_S L$  L2  <code>self.target_scale</code>1<br> G <br><img src=\"/images/GAN_fig2.png\" alt=\"\"><center>fig 2.  $G_0$  V(G,D)  $G_1$  V(G,D)  $D_1^{\\ast}$  G ~</center></p>\n<p> $D_0^{\\ast}$  $\\max_D V(G_0,D_0)=V(G_0,D_0^{\\ast})$ $G_0$  $G_1$ G  V(G,D) $V(G_1,D_0^{\\ast}) &lt; V(G_0,D_0^{\\ast})$ D  V(G,D) $V(G_1,D_1^{\\ast}) &lt; V(G_0,D_0^{\\ast})$ $D_1^{\\ast}$  $D_0^{\\ast}$  G  D  G  G  G  D  G </p>\n</li>\n<li> L2 1 scale </li>\n</ol>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> zG  z  G(z)D  G(z)  (1)  D  G G  D  G D </p>"},{"title":"GIoU","date":"2019-06-13T07:00:48.000Z","mathjax":true,"_content":" [Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression](https://arxiv.org/abs/1902.09630)\n<!-- more -->\n# \nIoU benchmarksbboxIoU2D bboxIoU  IoU bboxIou GIou GIoU  sota benchmarks PASCAL VOC  MS COCO IoU  GIoU \n# \n2D/3D bbox bbox IoU  $l_1, l_2$ \n\nIoU  bbox IoU\n\n$l_n$IoU2D1(a)\n![](/images/GIoU_fig1.png)\n\n<!-- {% asset_img fig1.png This figure 1 %} -->\n\nboxgt box$(x_1,y_1,x_2,y_2)$boxcorner $l_2$ gt box  corner  box  corner  $l_2$ IoUbbox1(b)\n\n IoU  IoU $l_n$  bbox bbox  center+size $(x_c,y_c)$ $(w,h)$  box size\n\nsota  anchor faster-rcnnIoU\n\nIoU$ndim \\ge 2$IoUIoU IoU IouIoUIouIoU0IoU00\n\nIoU(a)  IoU (b)  IoU (c) IoUIoUGIoUGIoU sota benchmarksIoUGIoU\n\n\n\n- GIoU\n- GIoU\n- GIoUsota Faster R-CNNMask R-CNNYOLO v3benchmark\n\n# \n____ IoUboxIoUPASCAL VOCmAP IoU=0.5IoUmAPIoUmAPIoUMS COCO benchmark IoUmAP\n\n__bbox__ 2Dbboxbbox\n1. YOLO v1\n   \n   YOLO v1  bbox $(x_c,y_c,w,h)$scale(w,h)$(w-\\hat w)^2+(h-\\hat h)^2$  $(\\sqrt w - \\sqrt {\\hat w})^2+(\\sqrt h - \\sqrt {\\hat h})^2$\n2. R-CNN\n   \n   R-CNNselective searchboxesbboxsizescalesize log$l_2$MSE\n3. Fast R-CNN\n   \n   Fast R-CNN $l_1$-smooth  $l_2$ \n4. Faster R-CNN\n   \n   Faster R-CNNanchor boxessizeanchor boxes1:3batch 128proposalsFast R-CNNRetinaNet  focal loss\n\nbboxGIoU  bbox IoU \n\n__IoU__ IoUIoUbboxIoUGIoUIoU\n\n# IoU\n $A,B \\subseteq S \\in \\mathbb{R}^n$  IoU \n$$IoU = \\frac {|A \\cap B|} {|A \\cup B|} $$\n2D/3D\n- IoU\n  \n  IoU $\\mathcal L_{IoU}=1-IoU$ $\\mathcal L_{IoU}$  IoU \n- IoUA B S \n   \nIoU\n- $|A \\cap B|=0 \\Rightarrow IoU(A,B)=0$IoUA B\n\nIoU GIoU\n\n $A, B \\subseteq S \\in \\mathbb S^n$ S  A  B  CC C  C  A  B  C  A  B  IoU  GIoU/ 2D/3D\n\n1\n___\n1GIoU\n___\n  $A,B \\subseteq S \\in \\mathbb S^n$\n\n GIoU\n-  S  A B  C\n-  IoU\n  \n  $IoU=\\frac {|A \\cap B|} {|A \\cup B|}$\n-  GIoU\n  \n  $GIoU = IoU - \\frac {|C \\setminus (A \\cup B)|} {|C|}$\n___\n\nGIoU \n\n-  IoU GIoU \n  \n  IoU  $\\mathcal L_{GIoU} = 1-GIoU$\n-  IoU GIoU \n- GIoU  IoU\n  \n  $\\forall A,B \\subseteq \\mathbb S, GIoU(A,B) \\le IoU(A,B)$ A B GIoU  IoU $\\lim_{A \\rightarrow B} GIoU(A,B)=IoU(A,B)$\n- IoU  GIoU \n  \n  $\\forall A,B \\subseteq \\mathbb S, 0 \\le IoU(A,B) \\le 1$ GIoU $-1 \\le GIoU(A,B) \\le 1$\n\n  \n   *  IoU  A B $|A \\cup B|=|A \\cap B|$$GIoU =IoU=1$\n   *  A B  C  0GIoU  -1$\\lim_{\\frac{|A \\cup B|}{|C|}\\rightarrow 0} GIoU(A,B)=-1$\n\nGIoU  IoU  IoU 2D/3D GIoU  IoU 2D  GIoU GIoU  3D  GIoU \n\n## GIoUBBox\n GIoU  IoU \n\n2D bbox  GIoU  A B  A B  A B  min  max  A B  A B  x  x  $x^{tl} < x^{br}$ $x^{tl}=\\max (x_A^{tl}, x_B^{tl}), \\ x^{br}=\\min (x_A^{br},x_B^{br})$ $x_B^{tl} \\le x_A^{tl}<x_B^{br}$  $x_A^{tl} \\le x_B^{tl}<x_A^{br}$\n\nminmax ReLU 2  IoU  GIoU  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ \n_________\n2IoUGIoUBBox\n_________\n $B^p$  GT  $B^g$ $B^p=(x_1^p,y_1^p,x_2^p,y_2^p), \\quad B^g=(x_1^g,y_1^g,x_2^g,y_2^g)$\n\n$\\mathcal L_{IoU}, \\ \\mathcal L_{GIoU}$\n\n1.   box \n   \n   $x_2^p>x_1^p, \\ y_2^p>y_1^p$\n   - $\\hat x_1^p=\\min(x_1^p,x_2^p), \\ \\hat x_2^p=\\max(x_1^p,x_2^p)$\n   - $\\hat y_1^p=\\min(y_1^p,y_2^p), \\ \\hat y_2^p=\\max(y_1^p,y_2^p)$\n2.  GT box \n   \n   $A^g=(x_2^g-x_1^g)\\times (y_2^g-y_1^g)$\n3.  box \n   \n   $A^p=(x_2^p-x_1^p)\\times (y_2^p-y_1^p)$\n4. \n   \n   - $x_1^{\\mathcal I}=\\max(\\hat x_1^p, x_1^g), \\ x_2^{\\mathcal I}=\\min(\\hat x_2^p,x_2^p)$\n   - $y_1^{\\mathcal I}=\\max(\\hat y_1^p, y_1^g), \\ y_2^{\\mathcal I}=\\min(\\hat y_2^p,y_2^p)$\n   - $\\mathcal I=\\begin{cases} (x_2^{\\mathcal I}-x_1^{\\mathcal I})\\times (y_2^{\\mathcal I}-y_1^{\\mathcal I}) & x_2^{\\mathcal I} > x_1^{\\mathcal I}, y_2^{\\mathcal I} > y_1^{\\mathcal I} \\\\ 0 & \\text{otherwise} \\end{cases}$\n5.  c\n   \n   - $x_1^c=\\min(\\hat x_1^p, x_1^g), \\ \\max(\\hat x_2^p, x_2^g)$\n   - $y_1^c=\\min(\\hat y_1^p, y_1^g), \\ \\max(\\hat y_2^p, y_2^g)$\n6.  c \n   \n   $A^c=(x_2^c-x_1^c)\\times (y_2^c-y_1^c)$\n7.  IoU\n   \n   $IoU = \\frac {\\mathcal I}{\\mathcal U}$ $\\mathcal U = A^p+A^g-\\mathcal I$\n8.  GIoU\n   \n   $GIoU = IoU - \\frac {A^c-\\mathcal U} {A^c}$\n9.  GIoU \n    \n   $\\mathcal L_{IoU}=1-IoU, \\ \\mathcal L_{GIoU}=1-GIoU$\n_________\nbboxIoU=00GIoU 3GIoU  IoU  IoU 2 \n\n![](/images/GIoU_fig2.png)\n\n21 2D pair IoU  GIoU $IoU \\le 0.2, \\ GIoU \\le 0.2$GIoU  IoU GIoU  GIoU $\\mathcal L_{GIoU}$ IoU $\\mathcal L_{IoU}$IoU\n\n### \n0\n\n GT box 0$A^g > 0$214bbox$A^p \\ge 0, \\ \\mathcal I \\ge 0, \\forall B^p \\in \\mathbb R^4$$\\mathcal U \\ge A^g$ $\\mathcal U > 0$ IoU  $\\mathcal U \\ge \\mathcal I$ $0 \\le IoU \\le 1$ IoU  $0 \\le \\mathcal L_{IoU} \\le 1$\n\n GIoU  $\\frac {A^c-\\mathcal U} {A^c}$ A B  A B  $A^c \\ge \\mathcal U > 0$ $\\frac {A^c-\\mathcal U} {A^c} \\ge 0$$\\frac {A^c-\\mathcal U} {A^c} <1$ A B  A B  size  A B  $\\frac {A^c-\\mathcal U} {A^c} \\rightarrow 1$ $-1 < GIoU \\le 1$ $-1 \\le GIoU \\le 1$\n\n### IoU=0$\\mathcal L_{GIoU}$\nGIoU  $\\mathcal L_{GIoU}=1-GIoU=1+\\frac {A^c-\\mathcal U} {A^c} - IoU$ $B^p$  $B^g$  $\\mathcal I=0, IoU=0$ GIoU  $\\mathcal L_{GIoU}=1+\\frac{A^c-\\mathcal U}{A^c}=2-\\frac {\\mathcal U}{A^c}$ GIoU  $\\frac {\\mathcal U}{A^c}$ $0\\le \\frac {\\mathcal U}{A^c} \\le 1$ $A^c$ $\\mathcal U$ $\\mathcal I=0$ $\\mathcal U=A^p+A^g$ $A^g$  $A^p$ $A^c$  $A^p$ $B^p$  $B^g$ \n\n# \n bbox  $\\mathcal L_{GIoU}$ 2D Faster R-CNNMask R-CNN  YOLO v3 Faster R-CNN/Mask R-CNN  $l_1$-smooth  YOLO v3  MSE  $\\mathcal L_{GIoU}$ baseline  $\\mathcal L_{IoU}$  baseline\n\n____ PASCAL VOC  MS COCO \n\n____  MS COCO  mAP IoU  mAP IoU mAP $IoU=\\{.5,.55,...,.95\\}$ IoU  mAP  __AP__ GIoU  IoU  $GIoU=\\{.5,.55,...,.95\\}$ mAP __AP__ IoU  GIoU  0.75  mAP __AP75__\n\n## YOLO v3\n____  YOLO v3  Darknet  Baseline  MSE  DarkNet-608  backbone YOLO v3  IoU  GIoU  YOLO v3  MSE  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ MSE  YOLO v3  bbox \n\n## Faster R-CNN  Mask R-CNN\n____  Faster R-CNN/Mask R-CNN  PyTorch baseline$l_1$-smooth ResNet-50  backbone IoU  GIoU RPN $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ YOLO v3  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$  10\n\n# \n GIoU GIoU  IoU  IoU  IoU  2D/3D GIoU \n\n GIoU  GIoU / GIoU  bbox  GIoU  sota GIoU  bbox  2D bbox \n\n# \n","source":"_posts/GIoU.md","raw":"---\ntitle: GIoU\ndate: 2019-06-13 15:00:48\ntags: object detection\nmathjax: true\n---\n [Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression](https://arxiv.org/abs/1902.09630)\n<!-- more -->\n# \nIoU benchmarksbboxIoU2D bboxIoU  IoU bboxIou GIou GIoU  sota benchmarks PASCAL VOC  MS COCO IoU  GIoU \n# \n2D/3D bbox bbox IoU  $l_1, l_2$ \n\nIoU  bbox IoU\n\n$l_n$IoU2D1(a)\n![](/images/GIoU_fig1.png)\n\n<!-- {% asset_img fig1.png This figure 1 %} -->\n\nboxgt box$(x_1,y_1,x_2,y_2)$boxcorner $l_2$ gt box  corner  box  corner  $l_2$ IoUbbox1(b)\n\n IoU  IoU $l_n$  bbox bbox  center+size $(x_c,y_c)$ $(w,h)$  box size\n\nsota  anchor faster-rcnnIoU\n\nIoU$ndim \\ge 2$IoUIoU IoU IouIoUIouIoU0IoU00\n\nIoU(a)  IoU (b)  IoU (c) IoUIoUGIoUGIoU sota benchmarksIoUGIoU\n\n\n\n- GIoU\n- GIoU\n- GIoUsota Faster R-CNNMask R-CNNYOLO v3benchmark\n\n# \n____ IoUboxIoUPASCAL VOCmAP IoU=0.5IoUmAPIoUmAPIoUMS COCO benchmark IoUmAP\n\n__bbox__ 2Dbboxbbox\n1. YOLO v1\n   \n   YOLO v1  bbox $(x_c,y_c,w,h)$scale(w,h)$(w-\\hat w)^2+(h-\\hat h)^2$  $(\\sqrt w - \\sqrt {\\hat w})^2+(\\sqrt h - \\sqrt {\\hat h})^2$\n2. R-CNN\n   \n   R-CNNselective searchboxesbboxsizescalesize log$l_2$MSE\n3. Fast R-CNN\n   \n   Fast R-CNN $l_1$-smooth  $l_2$ \n4. Faster R-CNN\n   \n   Faster R-CNNanchor boxessizeanchor boxes1:3batch 128proposalsFast R-CNNRetinaNet  focal loss\n\nbboxGIoU  bbox IoU \n\n__IoU__ IoUIoUbboxIoUGIoUIoU\n\n# IoU\n $A,B \\subseteq S \\in \\mathbb{R}^n$  IoU \n$$IoU = \\frac {|A \\cap B|} {|A \\cup B|} $$\n2D/3D\n- IoU\n  \n  IoU $\\mathcal L_{IoU}=1-IoU$ $\\mathcal L_{IoU}$  IoU \n- IoUA B S \n   \nIoU\n- $|A \\cap B|=0 \\Rightarrow IoU(A,B)=0$IoUA B\n\nIoU GIoU\n\n $A, B \\subseteq S \\in \\mathbb S^n$ S  A  B  CC C  C  A  B  C  A  B  IoU  GIoU/ 2D/3D\n\n1\n___\n1GIoU\n___\n  $A,B \\subseteq S \\in \\mathbb S^n$\n\n GIoU\n-  S  A B  C\n-  IoU\n  \n  $IoU=\\frac {|A \\cap B|} {|A \\cup B|}$\n-  GIoU\n  \n  $GIoU = IoU - \\frac {|C \\setminus (A \\cup B)|} {|C|}$\n___\n\nGIoU \n\n-  IoU GIoU \n  \n  IoU  $\\mathcal L_{GIoU} = 1-GIoU$\n-  IoU GIoU \n- GIoU  IoU\n  \n  $\\forall A,B \\subseteq \\mathbb S, GIoU(A,B) \\le IoU(A,B)$ A B GIoU  IoU $\\lim_{A \\rightarrow B} GIoU(A,B)=IoU(A,B)$\n- IoU  GIoU \n  \n  $\\forall A,B \\subseteq \\mathbb S, 0 \\le IoU(A,B) \\le 1$ GIoU $-1 \\le GIoU(A,B) \\le 1$\n\n  \n   *  IoU  A B $|A \\cup B|=|A \\cap B|$$GIoU =IoU=1$\n   *  A B  C  0GIoU  -1$\\lim_{\\frac{|A \\cup B|}{|C|}\\rightarrow 0} GIoU(A,B)=-1$\n\nGIoU  IoU  IoU 2D/3D GIoU  IoU 2D  GIoU GIoU  3D  GIoU \n\n## GIoUBBox\n GIoU  IoU \n\n2D bbox  GIoU  A B  A B  A B  min  max  A B  A B  x  x  $x^{tl} < x^{br}$ $x^{tl}=\\max (x_A^{tl}, x_B^{tl}), \\ x^{br}=\\min (x_A^{br},x_B^{br})$ $x_B^{tl} \\le x_A^{tl}<x_B^{br}$  $x_A^{tl} \\le x_B^{tl}<x_A^{br}$\n\nminmax ReLU 2  IoU  GIoU  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ \n_________\n2IoUGIoUBBox\n_________\n $B^p$  GT  $B^g$ $B^p=(x_1^p,y_1^p,x_2^p,y_2^p), \\quad B^g=(x_1^g,y_1^g,x_2^g,y_2^g)$\n\n$\\mathcal L_{IoU}, \\ \\mathcal L_{GIoU}$\n\n1.   box \n   \n   $x_2^p>x_1^p, \\ y_2^p>y_1^p$\n   - $\\hat x_1^p=\\min(x_1^p,x_2^p), \\ \\hat x_2^p=\\max(x_1^p,x_2^p)$\n   - $\\hat y_1^p=\\min(y_1^p,y_2^p), \\ \\hat y_2^p=\\max(y_1^p,y_2^p)$\n2.  GT box \n   \n   $A^g=(x_2^g-x_1^g)\\times (y_2^g-y_1^g)$\n3.  box \n   \n   $A^p=(x_2^p-x_1^p)\\times (y_2^p-y_1^p)$\n4. \n   \n   - $x_1^{\\mathcal I}=\\max(\\hat x_1^p, x_1^g), \\ x_2^{\\mathcal I}=\\min(\\hat x_2^p,x_2^p)$\n   - $y_1^{\\mathcal I}=\\max(\\hat y_1^p, y_1^g), \\ y_2^{\\mathcal I}=\\min(\\hat y_2^p,y_2^p)$\n   - $\\mathcal I=\\begin{cases} (x_2^{\\mathcal I}-x_1^{\\mathcal I})\\times (y_2^{\\mathcal I}-y_1^{\\mathcal I}) & x_2^{\\mathcal I} > x_1^{\\mathcal I}, y_2^{\\mathcal I} > y_1^{\\mathcal I} \\\\ 0 & \\text{otherwise} \\end{cases}$\n5.  c\n   \n   - $x_1^c=\\min(\\hat x_1^p, x_1^g), \\ \\max(\\hat x_2^p, x_2^g)$\n   - $y_1^c=\\min(\\hat y_1^p, y_1^g), \\ \\max(\\hat y_2^p, y_2^g)$\n6.  c \n   \n   $A^c=(x_2^c-x_1^c)\\times (y_2^c-y_1^c)$\n7.  IoU\n   \n   $IoU = \\frac {\\mathcal I}{\\mathcal U}$ $\\mathcal U = A^p+A^g-\\mathcal I$\n8.  GIoU\n   \n   $GIoU = IoU - \\frac {A^c-\\mathcal U} {A^c}$\n9.  GIoU \n    \n   $\\mathcal L_{IoU}=1-IoU, \\ \\mathcal L_{GIoU}=1-GIoU$\n_________\nbboxIoU=00GIoU 3GIoU  IoU  IoU 2 \n\n![](/images/GIoU_fig2.png)\n\n21 2D pair IoU  GIoU $IoU \\le 0.2, \\ GIoU \\le 0.2$GIoU  IoU GIoU  GIoU $\\mathcal L_{GIoU}$ IoU $\\mathcal L_{IoU}$IoU\n\n### \n0\n\n GT box 0$A^g > 0$214bbox$A^p \\ge 0, \\ \\mathcal I \\ge 0, \\forall B^p \\in \\mathbb R^4$$\\mathcal U \\ge A^g$ $\\mathcal U > 0$ IoU  $\\mathcal U \\ge \\mathcal I$ $0 \\le IoU \\le 1$ IoU  $0 \\le \\mathcal L_{IoU} \\le 1$\n\n GIoU  $\\frac {A^c-\\mathcal U} {A^c}$ A B  A B  $A^c \\ge \\mathcal U > 0$ $\\frac {A^c-\\mathcal U} {A^c} \\ge 0$$\\frac {A^c-\\mathcal U} {A^c} <1$ A B  A B  size  A B  $\\frac {A^c-\\mathcal U} {A^c} \\rightarrow 1$ $-1 < GIoU \\le 1$ $-1 \\le GIoU \\le 1$\n\n### IoU=0$\\mathcal L_{GIoU}$\nGIoU  $\\mathcal L_{GIoU}=1-GIoU=1+\\frac {A^c-\\mathcal U} {A^c} - IoU$ $B^p$  $B^g$  $\\mathcal I=0, IoU=0$ GIoU  $\\mathcal L_{GIoU}=1+\\frac{A^c-\\mathcal U}{A^c}=2-\\frac {\\mathcal U}{A^c}$ GIoU  $\\frac {\\mathcal U}{A^c}$ $0\\le \\frac {\\mathcal U}{A^c} \\le 1$ $A^c$ $\\mathcal U$ $\\mathcal I=0$ $\\mathcal U=A^p+A^g$ $A^g$  $A^p$ $A^c$  $A^p$ $B^p$  $B^g$ \n\n# \n bbox  $\\mathcal L_{GIoU}$ 2D Faster R-CNNMask R-CNN  YOLO v3 Faster R-CNN/Mask R-CNN  $l_1$-smooth  YOLO v3  MSE  $\\mathcal L_{GIoU}$ baseline  $\\mathcal L_{IoU}$  baseline\n\n____ PASCAL VOC  MS COCO \n\n____  MS COCO  mAP IoU  mAP IoU mAP $IoU=\\{.5,.55,...,.95\\}$ IoU  mAP  __AP__ GIoU  IoU  $GIoU=\\{.5,.55,...,.95\\}$ mAP __AP__ IoU  GIoU  0.75  mAP __AP75__\n\n## YOLO v3\n____  YOLO v3  Darknet  Baseline  MSE  DarkNet-608  backbone YOLO v3  IoU  GIoU  YOLO v3  MSE  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ MSE  YOLO v3  bbox \n\n## Faster R-CNN  Mask R-CNN\n____  Faster R-CNN/Mask R-CNN  PyTorch baseline$l_1$-smooth ResNet-50  backbone IoU  GIoU RPN $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ YOLO v3  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$  10\n\n# \n GIoU GIoU  IoU  IoU  IoU  2D/3D GIoU \n\n GIoU  GIoU / GIoU  bbox  GIoU  sota GIoU  bbox  2D bbox \n\n# \n","slug":"GIoU","published":1,"updated":"2020-05-15T01:24:49.573Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92a004zp0djcmllhcux","content":"<p> <a href=\"https://arxiv.org/abs/1902.09630\">Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression</a><br><span id=\"more\"></span></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>IoU benchmarksbboxIoU2D bboxIoU  IoU bboxIou GIou GIoU  sota benchmarks PASCAL VOC  MS COCO IoU  GIoU </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>2D/3D bbox bbox IoU  $l_1, l_2$ </p>\n<p>IoU  bbox IoU</p>\n<p>$l_n$IoU2D1(a)<br><img src=\"/images/GIoU_fig1.png\" alt=\"\"></p>\n<!--  -->\n<p>boxgt box$(x_1,y_1,x_2,y_2)$boxcorner $l_2$ gt box  corner  box  corner  $l_2$ IoUbbox1(b)</p>\n<p> IoU  IoU $l_n$  bbox bbox  center+size $(x_c,y_c)$ $(w,h)$  box size</p>\n<p>sota  anchor faster-rcnnIoU</p>\n<p>IoU$ndim \\ge 2$IoUIoU IoU IouIoUIouIoU0IoU00</p>\n<p>IoU(a)  IoU (b)  IoU (c) IoUIoUGIoUGIoU sota benchmarksIoUGIoU</p>\n<p></p>\n<ul>\n<li>GIoU</li>\n<li>GIoU</li>\n<li>GIoUsota Faster R-CNNMask R-CNNYOLO v3benchmark</li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><strong></strong> IoUboxIoUPASCAL VOCmAP IoU=0.5IoUmAPIoUmAPIoUMS COCO benchmark IoUmAP</p>\n<p><strong>bbox</strong> 2Dbboxbbox</p>\n<ol>\n<li><p>YOLO v1</p>\n<p>YOLO v1  bbox $(x_c,y_c,w,h)$scale(w,h)$(w-\\hat w)^2+(h-\\hat h)^2$  $(\\sqrt w - \\sqrt {\\hat w})^2+(\\sqrt h - \\sqrt {\\hat h})^2$</p>\n</li>\n<li><p>R-CNN</p>\n<p>R-CNNselective searchboxesbboxsizescalesize log$l_2$MSE</p>\n</li>\n<li><p>Fast R-CNN</p>\n<p>Fast R-CNN $l_1$-smooth  $l_2$ </p>\n</li>\n<li><p>Faster R-CNN</p>\n<p>Faster R-CNNanchor boxessizeanchor boxes1:3batch 128proposalsFast R-CNNRetinaNet  focal loss</p>\n</li>\n</ol>\n<p>bboxGIoU  bbox IoU </p>\n<p><strong>IoU</strong> IoUIoUbboxIoUGIoUIoU</p>\n<h1 id=\"IoU\"><a href=\"#IoU\" class=\"headerlink\" title=\"IoU\"></a>IoU</h1><p> $A,B \\subseteq S \\in \\mathbb{R}^n$  IoU </p>\n<script type=\"math/tex; mode=display\">IoU = \\frac {|A \\cap B|} {|A \\cup B|}</script><p>2D/3D</p>\n<ul>\n<li><p>IoU</p>\n<p>IoU $\\mathcal L_{IoU}=1-IoU$ $\\mathcal L_{IoU}$  IoU </p>\n</li>\n<li>IoUA B S </li>\n</ul>\n<p>IoU</p>\n<ul>\n<li>$|A \\cap B|=0 \\Rightarrow IoU(A,B)=0$IoUA B</li>\n</ul>\n<p>IoU GIoU</p>\n<p> $A, B \\subseteq S \\in \\mathbb S^n$ S  A  B  CC C  C  A  B  C  A  B  IoU  GIoU/ 2D/3D</p>\n<p>1</p>\n<hr>\n<p>1GIoU</p>\n<hr>\n<p>  $A,B \\subseteq S \\in \\mathbb S^n$</p>\n<p> GIoU</p>\n<ul>\n<li> S  A B  C</li>\n<li><p> IoU</p>\n<p>$IoU=\\frac {|A \\cap B|} {|A \\cup B|}$</p>\n</li>\n<li><p> GIoU</p>\n<p>$GIoU = IoU - \\frac {|C \\setminus (A \\cup B)|} {|C|}$</p>\n</li>\n</ul>\n<hr>\n<p>GIoU </p>\n<ul>\n<li><p> IoU GIoU </p>\n<p>IoU  $\\mathcal L_{GIoU} = 1-GIoU$</p>\n</li>\n<li> IoU GIoU </li>\n<li><p>GIoU  IoU</p>\n<p>$\\forall A,B \\subseteq \\mathbb S, GIoU(A,B) \\le IoU(A,B)$ A B GIoU  IoU $\\lim_{A \\rightarrow B} GIoU(A,B)=IoU(A,B)$</p>\n</li>\n<li><p>IoU  GIoU </p>\n<p>$\\forall A,B \\subseteq \\mathbb S, 0 \\le IoU(A,B) \\le 1$ GIoU $-1 \\le GIoU(A,B) \\le 1$</p>\n<p></p>\n<ul>\n<li> IoU  A B $|A \\cup B|=|A \\cap B|$$GIoU =IoU=1$</li>\n<li> A B  C  0GIoU  -1$\\lim_{\\frac{|A \\cup B|}{|C|}\\rightarrow 0} GIoU(A,B)=-1$</li>\n</ul>\n</li>\n</ul>\n<p>GIoU  IoU  IoU 2D/3D GIoU  IoU 2D  GIoU GIoU  3D  GIoU </p>\n<h2 id=\"GIoUBBox\"><a href=\"#GIoUBBox\" class=\"headerlink\" title=\"GIoUBBox\"></a>GIoUBBox</h2><p> GIoU  IoU </p>\n<p>2D bbox  GIoU  A B  A B  A B  min  max  A B  A B  x  x  $x^{tl} &lt; x^{br}$ $x^{tl}=\\max (x_A^{tl}, x_B^{tl}), \\ x^{br}=\\min (x_A^{br},x_B^{br})$ $x_B^{tl} \\le x_A^{tl}&lt;x_B^{br}$  $x_A^{tl} \\le x_B^{tl}&lt;x_A^{br}$</p>\n<p>minmax ReLU 2  IoU  GIoU  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ </p>\n<hr>\n<p>2IoUGIoUBBox</p>\n<hr>\n<p> $B^p$  GT  $B^g$ $B^p=(x_1^p,y_1^p,x_2^p,y_2^p), \\quad B^g=(x_1^g,y_1^g,x_2^g,y_2^g)$</p>\n<p>$\\mathcal L_{IoU}, \\ \\mathcal L_{GIoU}$</p>\n<ol>\n<li><p>  box </p>\n<p>$x_2^p&gt;x_1^p, \\ y_2^p&gt;y_1^p$</p>\n<ul>\n<li>$\\hat x_1^p=\\min(x_1^p,x_2^p), \\ \\hat x_2^p=\\max(x_1^p,x_2^p)$</li>\n<li>$\\hat y_1^p=\\min(y_1^p,y_2^p), \\ \\hat y_2^p=\\max(y_1^p,y_2^p)$</li>\n</ul>\n</li>\n<li><p> GT box </p>\n<p>$A^g=(x_2^g-x_1^g)\\times (y_2^g-y_1^g)$</p>\n</li>\n<li><p> box </p>\n<p>$A^p=(x_2^p-x_1^p)\\times (y_2^p-y_1^p)$</p>\n</li>\n<li><p></p>\n<ul>\n<li>$x_1^{\\mathcal I}=\\max(\\hat x_1^p, x_1^g), \\ x_2^{\\mathcal I}=\\min(\\hat x_2^p,x_2^p)$</li>\n<li>$y_1^{\\mathcal I}=\\max(\\hat y_1^p, y_1^g), \\ y_2^{\\mathcal I}=\\min(\\hat y_2^p,y_2^p)$</li>\n<li>$\\mathcal I=\\begin{cases} (x_2^{\\mathcal I}-x_1^{\\mathcal I})\\times (y_2^{\\mathcal I}-y_1^{\\mathcal I}) &amp; x_2^{\\mathcal I} &gt; x_1^{\\mathcal I}, y_2^{\\mathcal I} &gt; y_1^{\\mathcal I} \\\\ 0 &amp; \\text{otherwise} \\end{cases}$</li>\n</ul>\n</li>\n<li><p> c</p>\n<ul>\n<li>$x_1^c=\\min(\\hat x_1^p, x_1^g), \\ \\max(\\hat x_2^p, x_2^g)$</li>\n<li>$y_1^c=\\min(\\hat y_1^p, y_1^g), \\ \\max(\\hat y_2^p, y_2^g)$</li>\n</ul>\n</li>\n<li><p> c </p>\n<p>$A^c=(x_2^c-x_1^c)\\times (y_2^c-y_1^c)$</p>\n</li>\n<li><p> IoU</p>\n<p>$IoU = \\frac {\\mathcal I}{\\mathcal U}$ $\\mathcal U = A^p+A^g-\\mathcal I$</p>\n</li>\n<li><p> GIoU</p>\n<p>$GIoU = IoU - \\frac {A^c-\\mathcal U} {A^c}$</p>\n</li>\n<li><p> GIoU </p>\n<p>$\\mathcal L_{IoU}=1-IoU, \\ \\mathcal L_{GIoU}=1-GIoU$</p>\n</li>\n</ol>\n<hr>\n<p>bboxIoU=00GIoU 3GIoU  IoU  IoU 2 </p>\n<p><img src=\"/images/GIoU_fig2.png\" alt=\"\"></p>\n<p>21 2D pair IoU  GIoU $IoU \\le 0.2, \\ GIoU \\le 0.2$GIoU  IoU GIoU  GIoU $\\mathcal L_{GIoU}$ IoU $\\mathcal L_{IoU}$IoU</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>0</p>\n<p> GT box 0$A^g &gt; 0$214bbox$A^p \\ge 0, \\ \\mathcal I \\ge 0, \\forall B^p \\in \\mathbb R^4$$\\mathcal U \\ge A^g$ $\\mathcal U &gt; 0$ IoU  $\\mathcal U \\ge \\mathcal I$ $0 \\le IoU \\le 1$ IoU  $0 \\le \\mathcal L_{IoU} \\le 1$</p>\n<p> GIoU  $\\frac {A^c-\\mathcal U} {A^c}$ A B  A B  $A^c \\ge \\mathcal U &gt; 0$ $\\frac {A^c-\\mathcal U} {A^c} \\ge 0$$\\frac {A^c-\\mathcal U} {A^c} &lt;1$ A B  A B  size  A B  $\\frac {A^c-\\mathcal U} {A^c} \\rightarrow 1$ $-1 &lt; GIoU \\le 1$ $-1 \\le GIoU \\le 1$</p>\n<h3 id=\"IoU-0-mathcal-L-GIoU-\"><a href=\"#IoU-0-mathcal-L-GIoU-\" class=\"headerlink\" title=\"IoU=0$\\mathcal L_{GIoU}$\"></a>IoU=0$\\mathcal L_{GIoU}$</h3><p>GIoU  $\\mathcal L_{GIoU}=1-GIoU=1+\\frac {A^c-\\mathcal U} {A^c} - IoU$ $B^p$  $B^g$  $\\mathcal I=0, IoU=0$ GIoU  $\\mathcal L_{GIoU}=1+\\frac{A^c-\\mathcal U}{A^c}=2-\\frac {\\mathcal U}{A^c}$ GIoU  $\\frac {\\mathcal U}{A^c}$ $0\\le \\frac {\\mathcal U}{A^c} \\le 1$ $A^c$ $\\mathcal U$ $\\mathcal I=0$ $\\mathcal U=A^p+A^g$ $A^g$  $A^p$ $A^c$  $A^p$ $B^p$  $B^g$ </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> bbox  $\\mathcal L_{GIoU}$ 2D Faster R-CNNMask R-CNN  YOLO v3 Faster R-CNN/Mask R-CNN  $l_1$-smooth  YOLO v3  MSE  $\\mathcal L_{GIoU}$ baseline  $\\mathcal L_{IoU}$  baseline</p>\n<p><strong></strong> PASCAL VOC  MS COCO </p>\n<p><strong></strong>  MS COCO  mAP IoU  mAP IoU mAP $IoU=\\{.5,.55,,.95\\}$ IoU  mAP  <strong>AP</strong> GIoU  IoU  $GIoU=\\{.5,.55,,.95\\}$ mAP <strong>AP</strong> IoU  GIoU  0.75  mAP <strong>AP75</strong></p>\n<h2 id=\"YOLO-v3\"><a href=\"#YOLO-v3\" class=\"headerlink\" title=\"YOLO v3\"></a>YOLO v3</h2><p><strong></strong>  YOLO v3  Darknet  Baseline  MSE  DarkNet-608  backbone YOLO v3  IoU  GIoU  YOLO v3  MSE  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ MSE  YOLO v3  bbox </p>\n<h2 id=\"Faster-R-CNN--Mask-R-CNN\"><a href=\"#Faster-R-CNN--Mask-R-CNN\" class=\"headerlink\" title=\"Faster R-CNN  Mask R-CNN\"></a>Faster R-CNN  Mask R-CNN</h2><p><strong></strong>  Faster R-CNN/Mask R-CNN  PyTorch baseline$l_1$-smooth ResNet-50  backbone IoU  GIoU RPN $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ YOLO v3  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$  10</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> GIoU GIoU  IoU  IoU  IoU  2D/3D GIoU </p>\n<p> GIoU  GIoU / GIoU  bbox  GIoU  sota GIoU  bbox  2D bbox </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"https://arxiv.org/abs/1902.09630\">Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression</a><br>","more":"</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>IoU benchmarksbboxIoU2D bboxIoU  IoU bboxIou GIou GIoU  sota benchmarks PASCAL VOC  MS COCO IoU  GIoU </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>2D/3D bbox bbox IoU  $l_1, l_2$ </p>\n<p>IoU  bbox IoU</p>\n<p>$l_n$IoU2D1(a)<br><img src=\"/images/GIoU_fig1.png\" alt=\"\"></p>\n<!--  -->\n<p>boxgt box$(x_1,y_1,x_2,y_2)$boxcorner $l_2$ gt box  corner  box  corner  $l_2$ IoUbbox1(b)</p>\n<p> IoU  IoU $l_n$  bbox bbox  center+size $(x_c,y_c)$ $(w,h)$  box size</p>\n<p>sota  anchor faster-rcnnIoU</p>\n<p>IoU$ndim \\ge 2$IoUIoU IoU IouIoUIouIoU0IoU00</p>\n<p>IoU(a)  IoU (b)  IoU (c) IoUIoUGIoUGIoU sota benchmarksIoUGIoU</p>\n<p></p>\n<ul>\n<li>GIoU</li>\n<li>GIoU</li>\n<li>GIoUsota Faster R-CNNMask R-CNNYOLO v3benchmark</li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><strong></strong> IoUboxIoUPASCAL VOCmAP IoU=0.5IoUmAPIoUmAPIoUMS COCO benchmark IoUmAP</p>\n<p><strong>bbox</strong> 2Dbboxbbox</p>\n<ol>\n<li><p>YOLO v1</p>\n<p>YOLO v1  bbox $(x_c,y_c,w,h)$scale(w,h)$(w-\\hat w)^2+(h-\\hat h)^2$  $(\\sqrt w - \\sqrt {\\hat w})^2+(\\sqrt h - \\sqrt {\\hat h})^2$</p>\n</li>\n<li><p>R-CNN</p>\n<p>R-CNNselective searchboxesbboxsizescalesize log$l_2$MSE</p>\n</li>\n<li><p>Fast R-CNN</p>\n<p>Fast R-CNN $l_1$-smooth  $l_2$ </p>\n</li>\n<li><p>Faster R-CNN</p>\n<p>Faster R-CNNanchor boxessizeanchor boxes1:3batch 128proposalsFast R-CNNRetinaNet  focal loss</p>\n</li>\n</ol>\n<p>bboxGIoU  bbox IoU </p>\n<p><strong>IoU</strong> IoUIoUbboxIoUGIoUIoU</p>\n<h1 id=\"IoU\"><a href=\"#IoU\" class=\"headerlink\" title=\"IoU\"></a>IoU</h1><p> $A,B \\subseteq S \\in \\mathbb{R}^n$  IoU </p>\n<script type=\"math/tex; mode=display\">IoU = \\frac {|A \\cap B|} {|A \\cup B|}</script><p>2D/3D</p>\n<ul>\n<li><p>IoU</p>\n<p>IoU $\\mathcal L_{IoU}=1-IoU$ $\\mathcal L_{IoU}$  IoU </p>\n</li>\n<li>IoUA B S </li>\n</ul>\n<p>IoU</p>\n<ul>\n<li>$|A \\cap B|=0 \\Rightarrow IoU(A,B)=0$IoUA B</li>\n</ul>\n<p>IoU GIoU</p>\n<p> $A, B \\subseteq S \\in \\mathbb S^n$ S  A  B  CC C  C  A  B  C  A  B  IoU  GIoU/ 2D/3D</p>\n<p>1</p>\n<hr>\n<p>1GIoU</p>\n<hr>\n<p>  $A,B \\subseteq S \\in \\mathbb S^n$</p>\n<p> GIoU</p>\n<ul>\n<li> S  A B  C</li>\n<li><p> IoU</p>\n<p>$IoU=\\frac {|A \\cap B|} {|A \\cup B|}$</p>\n</li>\n<li><p> GIoU</p>\n<p>$GIoU = IoU - \\frac {|C \\setminus (A \\cup B)|} {|C|}$</p>\n</li>\n</ul>\n<hr>\n<p>GIoU </p>\n<ul>\n<li><p> IoU GIoU </p>\n<p>IoU  $\\mathcal L_{GIoU} = 1-GIoU$</p>\n</li>\n<li> IoU GIoU </li>\n<li><p>GIoU  IoU</p>\n<p>$\\forall A,B \\subseteq \\mathbb S, GIoU(A,B) \\le IoU(A,B)$ A B GIoU  IoU $\\lim_{A \\rightarrow B} GIoU(A,B)=IoU(A,B)$</p>\n</li>\n<li><p>IoU  GIoU </p>\n<p>$\\forall A,B \\subseteq \\mathbb S, 0 \\le IoU(A,B) \\le 1$ GIoU $-1 \\le GIoU(A,B) \\le 1$</p>\n<p></p>\n<ul>\n<li> IoU  A B $|A \\cup B|=|A \\cap B|$$GIoU =IoU=1$</li>\n<li> A B  C  0GIoU  -1$\\lim_{\\frac{|A \\cup B|}{|C|}\\rightarrow 0} GIoU(A,B)=-1$</li>\n</ul>\n</li>\n</ul>\n<p>GIoU  IoU  IoU 2D/3D GIoU  IoU 2D  GIoU GIoU  3D  GIoU </p>\n<h2 id=\"GIoUBBox\"><a href=\"#GIoUBBox\" class=\"headerlink\" title=\"GIoUBBox\"></a>GIoUBBox</h2><p> GIoU  IoU </p>\n<p>2D bbox  GIoU  A B  A B  A B  min  max  A B  A B  x  x  $x^{tl} &lt; x^{br}$ $x^{tl}=\\max (x_A^{tl}, x_B^{tl}), \\ x^{br}=\\min (x_A^{br},x_B^{br})$ $x_B^{tl} \\le x_A^{tl}&lt;x_B^{br}$  $x_A^{tl} \\le x_B^{tl}&lt;x_A^{br}$</p>\n<p>minmax ReLU 2  IoU  GIoU  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ </p>\n<hr>\n<p>2IoUGIoUBBox</p>\n<hr>\n<p> $B^p$  GT  $B^g$ $B^p=(x_1^p,y_1^p,x_2^p,y_2^p), \\quad B^g=(x_1^g,y_1^g,x_2^g,y_2^g)$</p>\n<p>$\\mathcal L_{IoU}, \\ \\mathcal L_{GIoU}$</p>\n<ol>\n<li><p>  box </p>\n<p>$x_2^p&gt;x_1^p, \\ y_2^p&gt;y_1^p$</p>\n<ul>\n<li>$\\hat x_1^p=\\min(x_1^p,x_2^p), \\ \\hat x_2^p=\\max(x_1^p,x_2^p)$</li>\n<li>$\\hat y_1^p=\\min(y_1^p,y_2^p), \\ \\hat y_2^p=\\max(y_1^p,y_2^p)$</li>\n</ul>\n</li>\n<li><p> GT box </p>\n<p>$A^g=(x_2^g-x_1^g)\\times (y_2^g-y_1^g)$</p>\n</li>\n<li><p> box </p>\n<p>$A^p=(x_2^p-x_1^p)\\times (y_2^p-y_1^p)$</p>\n</li>\n<li><p></p>\n<ul>\n<li>$x_1^{\\mathcal I}=\\max(\\hat x_1^p, x_1^g), \\ x_2^{\\mathcal I}=\\min(\\hat x_2^p,x_2^p)$</li>\n<li>$y_1^{\\mathcal I}=\\max(\\hat y_1^p, y_1^g), \\ y_2^{\\mathcal I}=\\min(\\hat y_2^p,y_2^p)$</li>\n<li>$\\mathcal I=\\begin{cases} (x_2^{\\mathcal I}-x_1^{\\mathcal I})\\times (y_2^{\\mathcal I}-y_1^{\\mathcal I}) &amp; x_2^{\\mathcal I} &gt; x_1^{\\mathcal I}, y_2^{\\mathcal I} &gt; y_1^{\\mathcal I} \\\\ 0 &amp; \\text{otherwise} \\end{cases}$</li>\n</ul>\n</li>\n<li><p> c</p>\n<ul>\n<li>$x_1^c=\\min(\\hat x_1^p, x_1^g), \\ \\max(\\hat x_2^p, x_2^g)$</li>\n<li>$y_1^c=\\min(\\hat y_1^p, y_1^g), \\ \\max(\\hat y_2^p, y_2^g)$</li>\n</ul>\n</li>\n<li><p> c </p>\n<p>$A^c=(x_2^c-x_1^c)\\times (y_2^c-y_1^c)$</p>\n</li>\n<li><p> IoU</p>\n<p>$IoU = \\frac {\\mathcal I}{\\mathcal U}$ $\\mathcal U = A^p+A^g-\\mathcal I$</p>\n</li>\n<li><p> GIoU</p>\n<p>$GIoU = IoU - \\frac {A^c-\\mathcal U} {A^c}$</p>\n</li>\n<li><p> GIoU </p>\n<p>$\\mathcal L_{IoU}=1-IoU, \\ \\mathcal L_{GIoU}=1-GIoU$</p>\n</li>\n</ol>\n<hr>\n<p>bboxIoU=00GIoU 3GIoU  IoU  IoU 2 </p>\n<p><img src=\"/images/GIoU_fig2.png\" alt=\"\"></p>\n<p>21 2D pair IoU  GIoU $IoU \\le 0.2, \\ GIoU \\le 0.2$GIoU  IoU GIoU  GIoU $\\mathcal L_{GIoU}$ IoU $\\mathcal L_{IoU}$IoU</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>0</p>\n<p> GT box 0$A^g &gt; 0$214bbox$A^p \\ge 0, \\ \\mathcal I \\ge 0, \\forall B^p \\in \\mathbb R^4$$\\mathcal U \\ge A^g$ $\\mathcal U &gt; 0$ IoU  $\\mathcal U \\ge \\mathcal I$ $0 \\le IoU \\le 1$ IoU  $0 \\le \\mathcal L_{IoU} \\le 1$</p>\n<p> GIoU  $\\frac {A^c-\\mathcal U} {A^c}$ A B  A B  $A^c \\ge \\mathcal U &gt; 0$ $\\frac {A^c-\\mathcal U} {A^c} \\ge 0$$\\frac {A^c-\\mathcal U} {A^c} &lt;1$ A B  A B  size  A B  $\\frac {A^c-\\mathcal U} {A^c} \\rightarrow 1$ $-1 &lt; GIoU \\le 1$ $-1 \\le GIoU \\le 1$</p>\n<h3 id=\"IoU-0-mathcal-L-GIoU-\"><a href=\"#IoU-0-mathcal-L-GIoU-\" class=\"headerlink\" title=\"IoU=0$\\mathcal L_{GIoU}$\"></a>IoU=0$\\mathcal L_{GIoU}$</h3><p>GIoU  $\\mathcal L_{GIoU}=1-GIoU=1+\\frac {A^c-\\mathcal U} {A^c} - IoU$ $B^p$  $B^g$  $\\mathcal I=0, IoU=0$ GIoU  $\\mathcal L_{GIoU}=1+\\frac{A^c-\\mathcal U}{A^c}=2-\\frac {\\mathcal U}{A^c}$ GIoU  $\\frac {\\mathcal U}{A^c}$ $0\\le \\frac {\\mathcal U}{A^c} \\le 1$ $A^c$ $\\mathcal U$ $\\mathcal I=0$ $\\mathcal U=A^p+A^g$ $A^g$  $A^p$ $A^c$  $A^p$ $B^p$  $B^g$ </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> bbox  $\\mathcal L_{GIoU}$ 2D Faster R-CNNMask R-CNN  YOLO v3 Faster R-CNN/Mask R-CNN  $l_1$-smooth  YOLO v3  MSE  $\\mathcal L_{GIoU}$ baseline  $\\mathcal L_{IoU}$  baseline</p>\n<p><strong></strong> PASCAL VOC  MS COCO </p>\n<p><strong></strong>  MS COCO  mAP IoU  mAP IoU mAP $IoU=\\{.5,.55,,.95\\}$ IoU  mAP  <strong>AP</strong> GIoU  IoU  $GIoU=\\{.5,.55,,.95\\}$ mAP <strong>AP</strong> IoU  GIoU  0.75  mAP <strong>AP75</strong></p>\n<h2 id=\"YOLO-v3\"><a href=\"#YOLO-v3\" class=\"headerlink\" title=\"YOLO v3\"></a>YOLO v3</h2><p><strong></strong>  YOLO v3  Darknet  Baseline  MSE  DarkNet-608  backbone YOLO v3  IoU  GIoU  YOLO v3  MSE  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ MSE  YOLO v3  bbox </p>\n<h2 id=\"Faster-R-CNN--Mask-R-CNN\"><a href=\"#Faster-R-CNN--Mask-R-CNN\" class=\"headerlink\" title=\"Faster R-CNN  Mask R-CNN\"></a>Faster R-CNN  Mask R-CNN</h2><p><strong></strong>  Faster R-CNN/Mask R-CNN  PyTorch baseline$l_1$-smooth ResNet-50  backbone IoU  GIoU RPN $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$ YOLO v3  $\\mathcal L_{IoU}, \\mathcal L_{GIoU}$  10</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> GIoU GIoU  IoU  IoU  IoU  2D/3D GIoU </p>\n<p> GIoU  GIoU / GIoU  bbox  GIoU  sota GIoU  bbox  2D bbox </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>"},{"title":"gcc-src","date":"2019-07-02T05:49:38.000Z","_content":" c++  c++ \n<!-- more -->\n ubuntu gcc  7.3.0 /usr/include/c++/7/ \n1. [gcc-mirror/gcc](https://github.com/gcc-mirror/gcc) clone  github \n2. [GNU Mirror List](http://www.gnu.org/prep/ftp.html)  gcc \n\nC++ \n\n\n\n# Allocator\n __allocator_traits_base  libstdc++-v3/include/bits/alloc_traits.h \n```c++\nstruct __allocator_traits_base\n{\n    template<typename _Tp, typename _Up, typename = void>\n    struct __rebind : __replace_first_arg<_Tp, _Up> { };\n    template<typename _Tp, typename _Up>\n    struct __rebind<_Tp, _Up, __void_t<typename _Tp::template rebind<_Up>::other>>\n    { using type = typename _Tp::template rebind<_Up>::other; };\n\n    //  _Tp \nprotected:\n    template<typename _Tp>\n    using __pointer = typename _Tp::pointer;\n    ...\n};\n```\n __rebind __rebind\n1.  void __rebind  \n2.  void\n    -  _Tp::template rebind<_Up>::other  __rebind \n    -  __rebind \n\n\n```c++\ntemplate<typename _Alloc, typename _Up>\nusing __alloc_rebind = typename __allocator_traits_base::template __rebind<_Alloc, _Up>::type;\n```\n _Alloc::template rebind<_Up>::other  __rebind  _Alloc __alloc_rebind  _Alloc<_Up, ...>::type\n\n allocator_traits \n```c++\ntemplate<typename _Alloc>\nstruct allocator_traits: _allocator_traits_base\n{\n    typedef _Alloc allocator_type;\n    typedef type _Alloc::value_type value_type;\n\n    using pointer = __detected_or_t<value_type*, __pointer, _Alloc>;\n    ...\n};\n```\n pointer  _Alloc::pointer  value_type*_Alloc::pointer  value_type* __pointer   \n std/type_traits  __detected_or_t  __rebind  allocator_traits \n```c++\ntemplate<template<typename> class _Func, typename _Tp, typename = void>\nstruct _Ptr\n{\n    using type = typename pointer_traits<pointer>::template rebind<_Tp>;\n};\ntemplate<template<typename> class _Func, typename _Tp>\nstruct _Ptr<_Func, _Tp, __void_t<_Func<_Alloc>>>\n{\n    using type = _Func<_Alloc>;\n};\n```\n _Ptr type  _Func<_Alloc> _Func  type  `pointer_traits<pointer>::template rebind<_Tp>` pointer  value_type*  bits/ptr_traits.h  pointer_traits \n```\ntemplate<typename _Tp>\nstruct pointer_traits<_Tp*>\n{\n    ...\n    template<typename _Up>\n    using rebind = _Up*;\n    ...\n};\n```\n _Ptr::type  _Tp* allocator_traits  _Diff type _Size  type  _Ptr::type, _Diff::type  _Size::type \n```c++\n//  _Alloc::const_pointer  _Alloc::const_pointer const value_type*\nusing const_pointer = typename _Ptr<__c_pointer, const value_type>::type;\n//  _Alloc::void_pointer  void*\nusing void_pointer = typename _Ptr<__v_pointer, void>::type;\n//  _Alloc::difference_type  pointer_traits<pointer>::difference_type\nusing difference_type = typename _Diff<_Alloc, pointer>::type;\n//  _Alloc::size_type  difference_type \nusing size_type = typename _Size<_Alloc, difference_type>::type;\n```\n\n\n __alloc_traits ext/alloc_traits.h \n```c++\ntemplate<typename _Alloc, typename = typename _Alloc::value_type>\nstruct __alloc_traits\n    : std::allocator_traits<_Alloc>     //  __cplusplus >= 201103L\n{\n    typedef _Alloc allocator_type;\n    // std::allocator_traits \n    typedef std::allocator_traits<_Alloc>               _Base_type;\n    typedef typename _Base_type::value_type             value_type;\n    // _Alloc::pointer or value_type*\n    typedef typename _Base_type::pointer                pointer;\n    typedef typename _Base_type::const_pointer          const_pointer;\n    typedef typename _Base_type::size_type              size_type;\n    typedef typename _Base_type::difference_type        difference_type;\n    typedef value_type&                                 reference;\n    typedef const value_type&                           const_reference;\n    // \n    using _Base_type::allocate;\n    using _Base_type::deallocate;\n    using _Base_type::construct;\n    using _Base_type::destroy;\n    using _Base_type::max_size;\n    ...\n}\n```\n std::allocator_traits  allocate \n```c++\n_GLIBCXX_NODISCARD static pointer       // _GLIBCXX_NODISCARD \nallocate(_Alloc& __a, size_type __n)\n{ return __a.allocate(__n); }\n\n_GLIBCXX_NODISCARD static pointer\nallocate(_Alloc& __a, size_type __n, const_void_pointer __hint) \n{ return _S_allocate(__a, __n, __hint, 0); }\n```\n_Alloc  allocate  __a  __n  allocate  __hint  __hint  allocate  allocate  allocatedeallocate, construct, destroy, max_size  _Tp  _Tp \n\n std::allocator_traits::construct \n```c++\ntemplate<typename _Tp, typename... _Args>\nstatic auto construct(_Alloc& __a, _Tp* __p, _Args&&... __args)\n...\n```\n _Tp* _Tp  __gnu_cxx::__alloc_traits  construct \n```c++\n// \ntemplate<typename _Ptr>\nusing __is_custom_pointer\n//  _Ptr  pointer  _Ptr  => __is_custom_pointer \n//  _Ptr  pointer  __is_custom_pointer \n= std::__and_<std::is_same<pointer, _Ptr>,\n        std::__not_<std::is_pointer<_Ptr>>>;\n\n//  \ntemplate<typename _Ptr, typename... _Args>\n//  __is_custom_pointer<_Ptr> enable_if<xx>::type \nstatic typename std::enable_if<__is_custom_pointer<_Ptr>::value>::type\nconstruct(_Alloc& __a, _Ptr __p, _Args&&... __args)\n...\n```\nconst / rebind _Alloc  _Alloc  value_type  allocator_traits  value_type  rebind  allocator_traits::value_type  Allocator\n\n/\n\nstd::allocator  bits/allocator.h  __allocator_base __gnu_cxx::new_allocator  new_allocator  allocate, deallocate, max_size, construct, destroy \n\n# Iterator\n bit/stl_iterator_base_types.h \n```c++\n//  Iterator \n// \ninput_iterator_tag\noutput_iterator_tag\nforward_iterator_tag\nbidirectional_iterator_tag\nrandom_access_iterator_tag\n```\n iterator_tag // std::iterator  iterator_traits \n\n bits/stl_iterator.h \n\n1. input  input  input   \n   \n2. output  input   \n   \n3. forward  input  output  input/output forward  multipass \n4. bidirectional  forword \n5. random-access  bidirectional \n\n\n## reverse_iterator\n```c++\ntemplate<typename _Iterator>\nclass reverse_iterator      // \n: public iterator<typename iterator_traits<_Iterator>::iterator_category,\n                typename iterator_traits<_Iterator>::value_type,\n                typename iterator_traits<_Iterator>::difference_type,\n                typename iterator_traits<_Iterator>::pointer,\n                typename iterator_traits<_Iterator>::reference>\n{\nprotected:\n    _Iterator current;  // \npublic:\n    // \n    ...\n    _GLIBCXX17_CONSTEXPR reference\n    operator*() const {\n        _Iterator __tmp = current;\n        return *--__tmp;// \n                        // \n    }\n\n    _GLIBCXX17_CONSTEXPR reverse_iterator&\n    operator++() {\n        --current;      // \n        return *this;\n    }\n}\n```\n r i r  i  i \n1. : *r = *(i-1)\n2. ++r = --i, --r = ++i\n3. r+n = i-n, r-n = i+n\n\nr  i \n\n## back_insert_iterator\n```c++\ntemplate<typename _Container>\nclass back_insert_iterator\n:public iterator<output_iterator_tag, void, void, void, void> // \n{\nprotected:\n    _Container* container;  // \npublic:\n    back_insert_iterator&   // \n    operator=(const typename _Container::value_type& __value)\n    {\n        container->push_back(__value);\n        return *this;\n    }\n    ...\n\n    back_insert_iterator&\n    operator*() { return *this; }       //  output \n    back_insert_iterator&\n    operator++() {return *this; }       // \n    back_insert_iterator&\n}\n```\n front_insert_iterator, insert_iterator \n\n## __normal_iterator\n _Iterator, _Container_Container  __normal_iterator \n```c++\ntemplate<typename _Iterator, typename _Container>\nclass __normal_iterator\n{\nprotected:\n    _Iterator _M_current;   // _normal_iterator  _M_current \n    ...\npublic:\n    // \n    ...\n    //  _M_current \n    //  __normal_iterator  _M_current \n    //  normal \n}\n```\n\n## move_iterator\n move move_iterator  move move  copy\n```c++\ntemplate<typename _Iterator>\nclass move_iterator\n{\nprotected:\n    _Iterator _M_current;\n    typedef iterator_traits<_Iterator>          __traits_type;  // _Iterator \n    typedef typename __traits_type::reference   __base_ref;     //  _Iterator \npublic:\n    ...\n    // __base_ref __base_ref \n    typedef typename conditional<is_reference<__base_ref>::value,\n        typename remove_reference<__base_ref>::type&&,\n        __base_ref>::type               reference;\n    \n    _GLIBCXX17_CONSTEXPR reference\n    operator*() const\n    { return static_cast<reference>(*_M_current); } // \n\n    _GLIBCXX17_CONSTEXPR reference\n    operator[](difference_type __n) const\n    { return std::move(_M_current[__n]); }  // \n}\n```\n\n\n# Container\n## Vector\n vector  bits/stl_vector.h  _Vector_base\n```c++\ntemplate<typename _Tp, typename _Alloc>\nstruct _Vector_base\n{\n    typedef typename __gnu_cxx::__alloc_traits<_Alloc>::template rebind<_Tp>::other _Tp_alloc_type;\n    typedef typename __gnu_cxx::__alloc_traits<_Tp_alloc_type>::pointer pointer;\n    ...\n}\n```\n\n _Alloc  value_type  _Tp rebind  value_type  _Tp  alloctor alloctor<_Tp> _Tp_alloc_type pointer _Tp_alloc_type::pointer _Tp* std::allocator  _Tp_alloc_type::pointer  _Tp* _Vector_base::pointer  _Tp*\n\n _Vector_base \n```c++\nstruct _Vector_impl_data\n{\n    pointer _M_start;   //  vector \n    pointer _M_finish;  //  vector  past-the-last-element \n    pointer _M_end_of_storage;  // vector  past-the-max-element \n\n    // \n    ...\n}\n\nstruct _Vector_impl : public _Tp_alloc_type, public _Vector_impl_data\n{\n    // \n    // vector  overflow  _GLIBCXX_SANITIZE_VECTOR AddressSanitizer\n}\n```\n _Vector_base _Vector_base \n```c++\ntemplate<typename _Tp, typename _Alloc>\nstruct _Vector_base\n{\n    ...\npublic:\n    typedef _Alloc allocator_type;\n    _Vector_impl _M_impl;           // \n    ...\n    // / \n\n    pointer _M_allocator(size_t __n) {      //  n  pointer \n        typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type> _Tr;\n        //  __n=0 nullptr _M_impl \n        return __n != 0 ? _Tr::allocate(_M_impl, __n) : pointer();\n    }\n\nprotected:\n    void _M_create_storage(size_t __n) {    // \n        this->_M_impl._M_start = this->_M_allocate(__n);\n        this->_M_impl._M_finish = this->_M_impl._M_start;\n        this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __n;\n    }\n}\n```\n _Vector_base  vector  vector \n```c++\n// vector  vector  _Tp vector  _Alloc\n//   _Alloc  std::allocator<_Tp> _Tp \n//   _Alloc  _Tp  _Alloc::rebind  alloctor\ntemplate<typename _Tp, typename _Alloc = std::allocator<_Tp>>\nclass vector : protected _Vector_base<_Tp, _Alloc>\n{\n    typedef _Vector_base<_Tp, _Alloc>               _Base;\n    typedef typename _Base::_Tp_alloc_type          _Tp_alloc_type;\n    typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type>   _Alloc_traits;\npublic:\n    typedef _Tp                             value_type;\n    typedef typename _Base::pointer         pointer;\n    typedef __gnu_cxx::__normal_iterator<pointer, vector>   iterator;\n    typedef std::reverse_iterator<iterator>                 reverse_iterator;\n    ...\n}\n```\n vector  iterator pointer  __gnu::cxx::__normal_iterator  _Iterator  \n vector  vector  _M_impl._M_finish  past-the-last-element  vector \n```c++\niterator\nbegin() _GLIBCXX_NOEXCEPT\n{ return iterator(this->_M_impl._M_start); }\n\niterator\nend() _GLIBCXX_NOEXCEPT\n{ return iterator(this->_M_impl._M_finish); }\n\nreverse_iterator\nrbegin() _GLIBCXX_NOEXCEPT\n{ return reverse_iterator(end()); }\n\nreverse_iterator\nrend() _GLIBCXX_NOEXCEPT\n{ return reverse_iterator(begin()); }\n```\n\n\n vector resize  vector  new_size > old_size resize  new_size<=old_size _M_impl._M_finish [_M_start, _M_finish) _M_finish \n\n vector  push_back \n```c++\nvoid\npush_back(const value_type& __x)\n{\n    if(this->_M_impl._M_finish != this->_M_impl._M_end_of_storage) {\n        //  __x\n        ...\n    } else\n        _M_realloc_insert(end(), __x);  //  _M_finish  __x\n                                        //   _M_finish \n}\n```\n bits/vector.tcc  _M_realloc_insert \n```c++\ntemplate<typename _Tp, typename _Alloc>\ntemplate<typename ..._Arg>\nvoid\nvector<_Tp, _Alloc>::_M_realloc_insert(iterator __position, _Args&&... _args)\n{\n    //  2  _M_check_len\n    const size_type __len = _M_check_len(size_type(1), \"vector::_M_realloc_insert\");\n    pointer __old_start = this->_M_impl._M_start;\n    pointer __old_finish = this->_M_impl._M_finish; //  past-the-last \n    const size_type __elems_before = __position - begin();// \n    pointer __new_start(this->_M_allocate(__len));   //  __len \n    pointer __new_finish(__new_start);  //  past-the-last \n    __try\n    {\n        // \n        _Alloc_traits::construct(this->_M_impl,                     // \n                                 __new_start + __elems_before,      // \n                                 std::forward<_Args>(__args)...);   // \n        //  vector  __new_finish  nullptr\n        __new_finish = pointer();\n\n        if _GLIBCXX17_CONSTEXPR (_S_use_relocate()) {   // \n            // \n            __new_finish = _S_relocate(__old_start, __position.base()\n                __new_start, _M_get_Tp_allocator());\n            //  __new_finish  1\n            ++__new_finish;\n            __new_finish = _S_relocate(__position.base(), __old_finish,\n                __new_finish, _M_get_Tp_allocator());   //  __new_finish  past-of-last \n        }\n        ...\n        // \n        // \n        // \n    }\n}\n```\nvector \n\n","source":"_posts/gcc-src.md","raw":"---\ntitle: gcc-src\ndate: 2019-07-02 13:49:38\ntags: c++\n---\n c++  c++ \n<!-- more -->\n ubuntu gcc  7.3.0 /usr/include/c++/7/ \n1. [gcc-mirror/gcc](https://github.com/gcc-mirror/gcc) clone  github \n2. [GNU Mirror List](http://www.gnu.org/prep/ftp.html)  gcc \n\nC++ \n\n\n\n# Allocator\n __allocator_traits_base  libstdc++-v3/include/bits/alloc_traits.h \n```c++\nstruct __allocator_traits_base\n{\n    template<typename _Tp, typename _Up, typename = void>\n    struct __rebind : __replace_first_arg<_Tp, _Up> { };\n    template<typename _Tp, typename _Up>\n    struct __rebind<_Tp, _Up, __void_t<typename _Tp::template rebind<_Up>::other>>\n    { using type = typename _Tp::template rebind<_Up>::other; };\n\n    //  _Tp \nprotected:\n    template<typename _Tp>\n    using __pointer = typename _Tp::pointer;\n    ...\n};\n```\n __rebind __rebind\n1.  void __rebind  \n2.  void\n    -  _Tp::template rebind<_Up>::other  __rebind \n    -  __rebind \n\n\n```c++\ntemplate<typename _Alloc, typename _Up>\nusing __alloc_rebind = typename __allocator_traits_base::template __rebind<_Alloc, _Up>::type;\n```\n _Alloc::template rebind<_Up>::other  __rebind  _Alloc __alloc_rebind  _Alloc<_Up, ...>::type\n\n allocator_traits \n```c++\ntemplate<typename _Alloc>\nstruct allocator_traits: _allocator_traits_base\n{\n    typedef _Alloc allocator_type;\n    typedef type _Alloc::value_type value_type;\n\n    using pointer = __detected_or_t<value_type*, __pointer, _Alloc>;\n    ...\n};\n```\n pointer  _Alloc::pointer  value_type*_Alloc::pointer  value_type* __pointer   \n std/type_traits  __detected_or_t  __rebind  allocator_traits \n```c++\ntemplate<template<typename> class _Func, typename _Tp, typename = void>\nstruct _Ptr\n{\n    using type = typename pointer_traits<pointer>::template rebind<_Tp>;\n};\ntemplate<template<typename> class _Func, typename _Tp>\nstruct _Ptr<_Func, _Tp, __void_t<_Func<_Alloc>>>\n{\n    using type = _Func<_Alloc>;\n};\n```\n _Ptr type  _Func<_Alloc> _Func  type  `pointer_traits<pointer>::template rebind<_Tp>` pointer  value_type*  bits/ptr_traits.h  pointer_traits \n```\ntemplate<typename _Tp>\nstruct pointer_traits<_Tp*>\n{\n    ...\n    template<typename _Up>\n    using rebind = _Up*;\n    ...\n};\n```\n _Ptr::type  _Tp* allocator_traits  _Diff type _Size  type  _Ptr::type, _Diff::type  _Size::type \n```c++\n//  _Alloc::const_pointer  _Alloc::const_pointer const value_type*\nusing const_pointer = typename _Ptr<__c_pointer, const value_type>::type;\n//  _Alloc::void_pointer  void*\nusing void_pointer = typename _Ptr<__v_pointer, void>::type;\n//  _Alloc::difference_type  pointer_traits<pointer>::difference_type\nusing difference_type = typename _Diff<_Alloc, pointer>::type;\n//  _Alloc::size_type  difference_type \nusing size_type = typename _Size<_Alloc, difference_type>::type;\n```\n\n\n __alloc_traits ext/alloc_traits.h \n```c++\ntemplate<typename _Alloc, typename = typename _Alloc::value_type>\nstruct __alloc_traits\n    : std::allocator_traits<_Alloc>     //  __cplusplus >= 201103L\n{\n    typedef _Alloc allocator_type;\n    // std::allocator_traits \n    typedef std::allocator_traits<_Alloc>               _Base_type;\n    typedef typename _Base_type::value_type             value_type;\n    // _Alloc::pointer or value_type*\n    typedef typename _Base_type::pointer                pointer;\n    typedef typename _Base_type::const_pointer          const_pointer;\n    typedef typename _Base_type::size_type              size_type;\n    typedef typename _Base_type::difference_type        difference_type;\n    typedef value_type&                                 reference;\n    typedef const value_type&                           const_reference;\n    // \n    using _Base_type::allocate;\n    using _Base_type::deallocate;\n    using _Base_type::construct;\n    using _Base_type::destroy;\n    using _Base_type::max_size;\n    ...\n}\n```\n std::allocator_traits  allocate \n```c++\n_GLIBCXX_NODISCARD static pointer       // _GLIBCXX_NODISCARD \nallocate(_Alloc& __a, size_type __n)\n{ return __a.allocate(__n); }\n\n_GLIBCXX_NODISCARD static pointer\nallocate(_Alloc& __a, size_type __n, const_void_pointer __hint) \n{ return _S_allocate(__a, __n, __hint, 0); }\n```\n_Alloc  allocate  __a  __n  allocate  __hint  __hint  allocate  allocate  allocatedeallocate, construct, destroy, max_size  _Tp  _Tp \n\n std::allocator_traits::construct \n```c++\ntemplate<typename _Tp, typename... _Args>\nstatic auto construct(_Alloc& __a, _Tp* __p, _Args&&... __args)\n...\n```\n _Tp* _Tp  __gnu_cxx::__alloc_traits  construct \n```c++\n// \ntemplate<typename _Ptr>\nusing __is_custom_pointer\n//  _Ptr  pointer  _Ptr  => __is_custom_pointer \n//  _Ptr  pointer  __is_custom_pointer \n= std::__and_<std::is_same<pointer, _Ptr>,\n        std::__not_<std::is_pointer<_Ptr>>>;\n\n//  \ntemplate<typename _Ptr, typename... _Args>\n//  __is_custom_pointer<_Ptr> enable_if<xx>::type \nstatic typename std::enable_if<__is_custom_pointer<_Ptr>::value>::type\nconstruct(_Alloc& __a, _Ptr __p, _Args&&... __args)\n...\n```\nconst / rebind _Alloc  _Alloc  value_type  allocator_traits  value_type  rebind  allocator_traits::value_type  Allocator\n\n/\n\nstd::allocator  bits/allocator.h  __allocator_base __gnu_cxx::new_allocator  new_allocator  allocate, deallocate, max_size, construct, destroy \n\n# Iterator\n bit/stl_iterator_base_types.h \n```c++\n//  Iterator \n// \ninput_iterator_tag\noutput_iterator_tag\nforward_iterator_tag\nbidirectional_iterator_tag\nrandom_access_iterator_tag\n```\n iterator_tag // std::iterator  iterator_traits \n\n bits/stl_iterator.h \n\n1. input  input  input   \n   \n2. output  input   \n   \n3. forward  input  output  input/output forward  multipass \n4. bidirectional  forword \n5. random-access  bidirectional \n\n\n## reverse_iterator\n```c++\ntemplate<typename _Iterator>\nclass reverse_iterator      // \n: public iterator<typename iterator_traits<_Iterator>::iterator_category,\n                typename iterator_traits<_Iterator>::value_type,\n                typename iterator_traits<_Iterator>::difference_type,\n                typename iterator_traits<_Iterator>::pointer,\n                typename iterator_traits<_Iterator>::reference>\n{\nprotected:\n    _Iterator current;  // \npublic:\n    // \n    ...\n    _GLIBCXX17_CONSTEXPR reference\n    operator*() const {\n        _Iterator __tmp = current;\n        return *--__tmp;// \n                        // \n    }\n\n    _GLIBCXX17_CONSTEXPR reverse_iterator&\n    operator++() {\n        --current;      // \n        return *this;\n    }\n}\n```\n r i r  i  i \n1. : *r = *(i-1)\n2. ++r = --i, --r = ++i\n3. r+n = i-n, r-n = i+n\n\nr  i \n\n## back_insert_iterator\n```c++\ntemplate<typename _Container>\nclass back_insert_iterator\n:public iterator<output_iterator_tag, void, void, void, void> // \n{\nprotected:\n    _Container* container;  // \npublic:\n    back_insert_iterator&   // \n    operator=(const typename _Container::value_type& __value)\n    {\n        container->push_back(__value);\n        return *this;\n    }\n    ...\n\n    back_insert_iterator&\n    operator*() { return *this; }       //  output \n    back_insert_iterator&\n    operator++() {return *this; }       // \n    back_insert_iterator&\n}\n```\n front_insert_iterator, insert_iterator \n\n## __normal_iterator\n _Iterator, _Container_Container  __normal_iterator \n```c++\ntemplate<typename _Iterator, typename _Container>\nclass __normal_iterator\n{\nprotected:\n    _Iterator _M_current;   // _normal_iterator  _M_current \n    ...\npublic:\n    // \n    ...\n    //  _M_current \n    //  __normal_iterator  _M_current \n    //  normal \n}\n```\n\n## move_iterator\n move move_iterator  move move  copy\n```c++\ntemplate<typename _Iterator>\nclass move_iterator\n{\nprotected:\n    _Iterator _M_current;\n    typedef iterator_traits<_Iterator>          __traits_type;  // _Iterator \n    typedef typename __traits_type::reference   __base_ref;     //  _Iterator \npublic:\n    ...\n    // __base_ref __base_ref \n    typedef typename conditional<is_reference<__base_ref>::value,\n        typename remove_reference<__base_ref>::type&&,\n        __base_ref>::type               reference;\n    \n    _GLIBCXX17_CONSTEXPR reference\n    operator*() const\n    { return static_cast<reference>(*_M_current); } // \n\n    _GLIBCXX17_CONSTEXPR reference\n    operator[](difference_type __n) const\n    { return std::move(_M_current[__n]); }  // \n}\n```\n\n\n# Container\n## Vector\n vector  bits/stl_vector.h  _Vector_base\n```c++\ntemplate<typename _Tp, typename _Alloc>\nstruct _Vector_base\n{\n    typedef typename __gnu_cxx::__alloc_traits<_Alloc>::template rebind<_Tp>::other _Tp_alloc_type;\n    typedef typename __gnu_cxx::__alloc_traits<_Tp_alloc_type>::pointer pointer;\n    ...\n}\n```\n\n _Alloc  value_type  _Tp rebind  value_type  _Tp  alloctor alloctor<_Tp> _Tp_alloc_type pointer _Tp_alloc_type::pointer _Tp* std::allocator  _Tp_alloc_type::pointer  _Tp* _Vector_base::pointer  _Tp*\n\n _Vector_base \n```c++\nstruct _Vector_impl_data\n{\n    pointer _M_start;   //  vector \n    pointer _M_finish;  //  vector  past-the-last-element \n    pointer _M_end_of_storage;  // vector  past-the-max-element \n\n    // \n    ...\n}\n\nstruct _Vector_impl : public _Tp_alloc_type, public _Vector_impl_data\n{\n    // \n    // vector  overflow  _GLIBCXX_SANITIZE_VECTOR AddressSanitizer\n}\n```\n _Vector_base _Vector_base \n```c++\ntemplate<typename _Tp, typename _Alloc>\nstruct _Vector_base\n{\n    ...\npublic:\n    typedef _Alloc allocator_type;\n    _Vector_impl _M_impl;           // \n    ...\n    // / \n\n    pointer _M_allocator(size_t __n) {      //  n  pointer \n        typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type> _Tr;\n        //  __n=0 nullptr _M_impl \n        return __n != 0 ? _Tr::allocate(_M_impl, __n) : pointer();\n    }\n\nprotected:\n    void _M_create_storage(size_t __n) {    // \n        this->_M_impl._M_start = this->_M_allocate(__n);\n        this->_M_impl._M_finish = this->_M_impl._M_start;\n        this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __n;\n    }\n}\n```\n _Vector_base  vector  vector \n```c++\n// vector  vector  _Tp vector  _Alloc\n//   _Alloc  std::allocator<_Tp> _Tp \n//   _Alloc  _Tp  _Alloc::rebind  alloctor\ntemplate<typename _Tp, typename _Alloc = std::allocator<_Tp>>\nclass vector : protected _Vector_base<_Tp, _Alloc>\n{\n    typedef _Vector_base<_Tp, _Alloc>               _Base;\n    typedef typename _Base::_Tp_alloc_type          _Tp_alloc_type;\n    typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type>   _Alloc_traits;\npublic:\n    typedef _Tp                             value_type;\n    typedef typename _Base::pointer         pointer;\n    typedef __gnu_cxx::__normal_iterator<pointer, vector>   iterator;\n    typedef std::reverse_iterator<iterator>                 reverse_iterator;\n    ...\n}\n```\n vector  iterator pointer  __gnu::cxx::__normal_iterator  _Iterator  \n vector  vector  _M_impl._M_finish  past-the-last-element  vector \n```c++\niterator\nbegin() _GLIBCXX_NOEXCEPT\n{ return iterator(this->_M_impl._M_start); }\n\niterator\nend() _GLIBCXX_NOEXCEPT\n{ return iterator(this->_M_impl._M_finish); }\n\nreverse_iterator\nrbegin() _GLIBCXX_NOEXCEPT\n{ return reverse_iterator(end()); }\n\nreverse_iterator\nrend() _GLIBCXX_NOEXCEPT\n{ return reverse_iterator(begin()); }\n```\n\n\n vector resize  vector  new_size > old_size resize  new_size<=old_size _M_impl._M_finish [_M_start, _M_finish) _M_finish \n\n vector  push_back \n```c++\nvoid\npush_back(const value_type& __x)\n{\n    if(this->_M_impl._M_finish != this->_M_impl._M_end_of_storage) {\n        //  __x\n        ...\n    } else\n        _M_realloc_insert(end(), __x);  //  _M_finish  __x\n                                        //   _M_finish \n}\n```\n bits/vector.tcc  _M_realloc_insert \n```c++\ntemplate<typename _Tp, typename _Alloc>\ntemplate<typename ..._Arg>\nvoid\nvector<_Tp, _Alloc>::_M_realloc_insert(iterator __position, _Args&&... _args)\n{\n    //  2  _M_check_len\n    const size_type __len = _M_check_len(size_type(1), \"vector::_M_realloc_insert\");\n    pointer __old_start = this->_M_impl._M_start;\n    pointer __old_finish = this->_M_impl._M_finish; //  past-the-last \n    const size_type __elems_before = __position - begin();// \n    pointer __new_start(this->_M_allocate(__len));   //  __len \n    pointer __new_finish(__new_start);  //  past-the-last \n    __try\n    {\n        // \n        _Alloc_traits::construct(this->_M_impl,                     // \n                                 __new_start + __elems_before,      // \n                                 std::forward<_Args>(__args)...);   // \n        //  vector  __new_finish  nullptr\n        __new_finish = pointer();\n\n        if _GLIBCXX17_CONSTEXPR (_S_use_relocate()) {   // \n            // \n            __new_finish = _S_relocate(__old_start, __position.base()\n                __new_start, _M_get_Tp_allocator());\n            //  __new_finish  1\n            ++__new_finish;\n            __new_finish = _S_relocate(__position.base(), __old_finish,\n                __new_finish, _M_get_Tp_allocator());   //  __new_finish  past-of-last \n        }\n        ...\n        // \n        // \n        // \n    }\n}\n```\nvector \n\n","slug":"gcc-src","published":1,"updated":"2020-04-24T10:37:53.028Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92b0051p0dj0wbt2s07","content":"<p> c++  c++ <br><span id=\"more\"></span><br> ubuntu gcc  7.3.0 /usr/include/c++/7/ </p>\n<ol>\n<li><a href=\"https://github.com/gcc-mirror/gcc\">gcc-mirror/gcc</a> clone  github </li>\n<li><a href=\"http://www.gnu.org/prep/ftp.html\">GNU Mirror List</a>  gcc </li>\n</ol>\n<p>C++ </p>\n<p></p>\n<h1 id=\"Allocator\"><a href=\"#Allocator\" class=\"headerlink\" title=\"Allocator\"></a>Allocator</h1><p> <strong>allocator_traits_base  libstdc++-v3/include/bits/alloc_traits.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> __<span class=\"title\">allocator_traits_base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Up, <span class=\"keyword\">typename</span> = <span class=\"keyword\">void</span>&gt;</span><br><span class=\"line\">    struct __rebind : __replace_first_arg&lt;_Tp, _Up&gt; &#123; &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Up&gt;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> __<span class=\"title\">rebind</span>&lt;</span>_Tp, _Up, <span class=\"keyword\">__void_t</span>&lt;<span class=\"keyword\">typename</span> _Tp::<span class=\"keyword\">template</span> rebind&lt;_Up&gt;::other&gt;&gt;</span><br><span class=\"line\">    &#123; <span class=\"keyword\">using</span> type = <span class=\"keyword\">typename</span> _Tp::<span class=\"keyword\">template</span> rebind&lt;_Up&gt;::other; &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//  _Tp </span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp&gt;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> __pointer = <span class=\"keyword\">typename</span> _Tp::pointer;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> </strong>rebind __rebind</p>\n<ol>\n<li> void __rebind  </li>\n<li> void<ul>\n<li> _Tp::template rebind<_Up>::other  __rebind </li>\n<li> __rebind </li>\n</ul>\n</li>\n</ol>\n<p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Alloc, <span class=\"keyword\">typename</span> _Up&gt;</span><br><span class=\"line\"><span class=\"keyword\">using</span> __alloc_rebind = <span class=\"keyword\">typename</span> __allocator_traits_base::<span class=\"keyword\">template</span> __rebind&lt;_Alloc, _Up&gt;::type;</span><br></pre></td></tr></table></figure><br> _Alloc::template rebind<_Up>::other  <strong>rebind  _Alloc </strong>alloc_rebind  _Alloc<_Up, ...>::type</p>\n<p> allocator_traits <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">allocator_traits</span>:</span> _allocator_traits_base</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Alloc allocator_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> type _Alloc::value_type value_type;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">using</span> pointer = <span class=\"keyword\">__detected_or_t</span>&lt;value_type*, __pointer, _Alloc&gt;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> pointer  _Alloc::pointer  value_type<em>_Alloc::pointer  value_type</em> <strong>pointer <br> std/type_traits  </strong>detected_or_t  __rebind  allocator_traits <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span>&gt; <span class=\"class\"><span class=\"keyword\">class</span> _<span class=\"title\">Func</span>, <span class=\"title\">typename</span> _<span class=\"title\">Tp</span>, <span class=\"title\">typename</span> =</span> <span class=\"keyword\">void</span>&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Ptr</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">using</span> type = <span class=\"keyword\">typename</span> pointer_traits&lt;pointer&gt;::<span class=\"keyword\">template</span> rebind&lt;_Tp&gt;;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span>&gt; <span class=\"class\"><span class=\"keyword\">class</span> _<span class=\"title\">Func</span>, <span class=\"title\">typename</span> _<span class=\"title\">Tp</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Ptr</span>&lt;</span>_Func, _Tp, <span class=\"keyword\">__void_t</span>&lt;_Func&lt;_Alloc&gt;&gt;&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> type = _Func&lt;_Alloc&gt;;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> _Ptr type  _Func<_Alloc> _Func  type  <code>pointer_traits&lt;pointer&gt;::template rebind&lt;_Tp&gt;</code> pointer  value_type<em>  bits/ptr_traits.h  pointer_traits <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;typename _Tp&gt;</span><br><span class=\"line\">struct pointer_traits&lt;_Tp*&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    template&lt;typename _Up&gt;</span><br><span class=\"line\">    using rebind = _Up*;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> _Ptr::type  _Tp</em> allocator_traits  _Diff type _Size  type  _Ptr::type, _Diff::type  _Size::type <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//  _Alloc::const_pointer  _Alloc::const_pointer const value_type*</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> const_pointer = <span class=\"keyword\">typename</span> _Ptr&lt;__c_pointer, <span class=\"keyword\">const</span> value_type&gt;::type;</span><br><span class=\"line\"><span class=\"comment\">//  _Alloc::void_pointer  void*</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> void_pointer = <span class=\"keyword\">typename</span> _Ptr&lt;__v_pointer, <span class=\"keyword\">void</span>&gt;::type;</span><br><span class=\"line\"><span class=\"comment\">//  _Alloc::difference_type  pointer_traits&lt;pointer&gt;::difference_type</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> difference_type = <span class=\"keyword\">typename</span> _Diff&lt;_Alloc, pointer&gt;::type;</span><br><span class=\"line\"><span class=\"comment\">//  _Alloc::size_type  difference_type </span></span><br><span class=\"line\"><span class=\"keyword\">using</span> size_type = <span class=\"keyword\">typename</span> _Size&lt;_Alloc, difference_type&gt;::type;</span><br></pre></td></tr></table></figure><br></p>\n<p> <strong>alloc_traits ext/alloc_traits.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Alloc, <span class=\"keyword\">typename</span> = <span class=\"keyword\">typename</span> _Alloc::value_type&gt;</span><br><span class=\"line\">struct __alloc_traits</span><br><span class=\"line\">    : std::allocator_traits&lt;_Alloc&gt;     <span class=\"comment\">//  __cplusplus &gt;= 201103L</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Alloc allocator_type;</span><br><span class=\"line\">    <span class=\"comment\">// std::allocator_traits </span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> std::allocator_traits&lt;_Alloc&gt;               _Base_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::value_type             value_type;</span><br><span class=\"line\">    <span class=\"comment\">// _Alloc::pointer or value_type*</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::pointer                pointer;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::const_pointer          const_pointer;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::size_type              size_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::difference_type        difference_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> value_type&amp;                                 reference;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">const</span> value_type&amp;                           const_reference;</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::allocate;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::deallocate;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::construct;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::destroy;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::max_size;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> std::allocator_traits  allocate <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_GLIBCXX_NODISCARD <span class=\"keyword\">static</span> pointer       <span class=\"comment\">// _GLIBCXX_NODISCARD </span></span><br><span class=\"line\"><span class=\"built_in\">allocate</span>(_Alloc&amp; __a, size_type __n)</span><br><span class=\"line\">&#123; <span class=\"keyword\">return</span> __a.<span class=\"built_in\">allocate</span>(__n); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">_GLIBCXX_NODISCARD <span class=\"keyword\">static</span> pointer</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">allocate</span><span class=\"params\">(_Alloc&amp; __a, size_type __n, const_void_pointer __hint)</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> _S_allocate(__a, __n, __hint, <span class=\"number\">0</span>); &#125;</span><br></pre></td></tr></table></figure><br>_Alloc  allocate  </strong>a  <strong>n  allocate  </strong>hint  __hint  allocate  allocate  allocatedeallocate, construct, destroy, max_size  _Tp  _Tp </p>\n<p> std::allocator_traits::construct <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span>... _Args&gt;</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">auto</span> <span class=\"title\">construct</span><span class=\"params\">(_Alloc&amp; __a, _Tp* __p, _Args&amp;&amp;... __args)</span></span></span><br><span class=\"line\"><span class=\"function\">...</span></span><br></pre></td></tr></table></figure><br> _Tp* _Tp  <strong>gnu_cxx::</strong>alloc_traits  construct <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Ptr&gt;</span><br><span class=\"line\"><span class=\"keyword\">using</span> __is_custom_pointer</span><br><span class=\"line\"><span class=\"comment\">//  _Ptr  pointer  _Ptr  =&gt; __is_custom_pointer </span></span><br><span class=\"line\"><span class=\"comment\">//  _Ptr  pointer  __is_custom_pointer </span></span><br><span class=\"line\">= std::__and_&lt;std::is_same&lt;pointer, _Ptr&gt;,</span><br><span class=\"line\">        std::__not_&lt;std::is_pointer&lt;_Ptr&gt;&gt;&gt;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  </span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Ptr, <span class=\"keyword\">typename</span>... _Args&gt;</span><br><span class=\"line\"><span class=\"comment\">//  __is_custom_pointer&lt;_Ptr&gt; enable_if&lt;xx&gt;::type </span></span><br><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">typename</span> std::enable_if&lt;__is_custom_pointer&lt;_Ptr&gt;::value&gt;::<span class=\"function\">type</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">construct</span><span class=\"params\">(_Alloc&amp; __a, _Ptr __p, _Args&amp;&amp;... __args)</span></span></span><br><span class=\"line\"><span class=\"function\">...</span></span><br></pre></td></tr></table></figure><br>const / rebind _Alloc  _Alloc  value_type  allocator_traits  value_type  rebind  allocator_traits::value_type  Allocator</p>\n<p>/</p>\n<p>std::allocator  bits/allocator.h  <strong>allocator_base </strong>gnu_cxx::new_allocator  new_allocator  allocate, deallocate, max_size, construct, destroy </p>\n<h1 id=\"Iterator\"><a href=\"#Iterator\" class=\"headerlink\" title=\"Iterator\"></a>Iterator</h1><p> bit/stl_iterator_base_types.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//  Iterator </span></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">input_iterator_tag</span><br><span class=\"line\">output_iterator_tag</span><br><span class=\"line\">forward_iterator_tag</span><br><span class=\"line\">bidirectional_iterator_tag</span><br><span class=\"line\">random_access_iterator_tag</span><br></pre></td></tr></table></figure><br> iterator_tag // std::iterator  iterator_traits </p>\n<p> bits/stl_iterator.h </p>\n<ol>\n<li>input  input  input <br></li>\n<li>output  input <br></li>\n<li>forward  input  output  input/output forward  multipass </li>\n<li>bidirectional  forword </li>\n<li>random-access  bidirectional </li>\n</ol>\n<p></p>\n<h2 id=\"reverse-iterator\"><a href=\"#reverse-iterator\" class=\"headerlink\" title=\"reverse_iterator\"></a>reverse_iterator</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Iterator&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">reverse_iterator</span>      // </span></span><br><span class=\"line\"><span class=\"class\">:</span> <span class=\"keyword\">public</span> iterator&lt;<span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::iterator_category,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::value_type,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::difference_type,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::pointer,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::reference&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Iterator current;  <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reference</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>*() <span class=\"keyword\">const</span> &#123;</span><br><span class=\"line\">        _Iterator __tmp = current;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *--__tmp;<span class=\"comment\">// </span></span><br><span class=\"line\">                        <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reverse_iterator&amp;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>++() &#123;</span><br><span class=\"line\">        --current;      <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> r i r  i  i </p>\n<ol>\n<li>: <em>r = </em>(i-1)</li>\n<li>++r = i, r = ++i</li>\n<li>r+n = i-n, r-n = i+n</li>\n</ol>\n<p>r  i </p>\n<h2 id=\"back-insert-iterator\"><a href=\"#back-insert-iterator\" class=\"headerlink\" title=\"back_insert_iterator\"></a>back_insert_iterator</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Container&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">back_insert_iterator</span></span></span><br><span class=\"line\"><span class=\"class\">:</span><span class=\"keyword\">public</span> iterator&lt;output_iterator_tag, <span class=\"keyword\">void</span>, <span class=\"keyword\">void</span>, <span class=\"keyword\">void</span>, <span class=\"keyword\">void</span>&gt; <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Container* container;  <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    back_insert_iterator&amp;   <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> <span class=\"keyword\">typename</span> _Container::value_type&amp; __value)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        container-&gt;<span class=\"built_in\">push_back</span>(__value);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    back_insert_iterator&amp;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>*() &#123; <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>; &#125;       <span class=\"comment\">//  output </span></span><br><span class=\"line\">    back_insert_iterator&amp;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>++() &#123;<span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>; &#125;       <span class=\"comment\">// </span></span><br><span class=\"line\">    back_insert_iterator&amp;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> front_insert_iterator, insert_iterator </p>\n<h2 id=\"normal-iterator\"><a href=\"#normal-iterator\" class=\"headerlink\" title=\"__normal_iterator\"></a>__normal_iterator</h2><p> _Iterator, _Container_Container  __normal_iterator <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Iterator, <span class=\"keyword\">typename</span> _Container&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> __<span class=\"title\">normal_iterator</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Iterator _M_current;   <span class=\"comment\">// _normal_iterator  _M_current </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\">//  _M_current </span></span><br><span class=\"line\">    <span class=\"comment\">//  __normal_iterator  _M_current </span></span><br><span class=\"line\">    <span class=\"comment\">//  normal </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"move-iterator\"><a href=\"#move-iterator\" class=\"headerlink\" title=\"move_iterator\"></a>move_iterator</h2><p> move move_iterator  move move  copy<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Iterator&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">move_iterator</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Iterator _M_current;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> iterator_traits&lt;_Iterator&gt;          __traits_type;  <span class=\"comment\">// _Iterator </span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> __traits_type::reference   __base_ref;     <span class=\"comment\">//  _Iterator </span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\">// __base_ref __base_ref </span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> conditional&lt;is_reference&lt;__base_ref&gt;::value,</span><br><span class=\"line\">        <span class=\"keyword\">typename</span> remove_reference&lt;__base_ref&gt;::type&amp;&amp;,</span><br><span class=\"line\">        __base_ref&gt;::type               reference;</span><br><span class=\"line\">    </span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reference</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>*() <span class=\"keyword\">const</span></span><br><span class=\"line\">    &#123; <span class=\"keyword\">return</span> <span class=\"keyword\">static_cast</span>&lt;reference&gt;(*_M_current); &#125; <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reference</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>[](difference_type __n) <span class=\"keyword\">const</span></span><br><span class=\"line\">    &#123; <span class=\"keyword\">return</span> std::<span class=\"built_in\">move</span>(_M_current[__n]); &#125;  <span class=\"comment\">// </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Container\"><a href=\"#Container\" class=\"headerlink\" title=\"Container\"></a>Container</h1><h2 id=\"Vector\"><a href=\"#Vector\" class=\"headerlink\" title=\"Vector\"></a>Vector</h2><p> vector  bits/stl_vector.h  _Vector_base<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> __gnu_cxx::__alloc_traits&lt;_Alloc&gt;::<span class=\"keyword\">template</span> rebind&lt;_Tp&gt;::other _Tp_alloc_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;::pointer pointer;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> _Alloc  value_type  _Tp rebind  value_type  _Tp  alloctor alloctor<_Tp> _Tp_alloc_type pointer _Tp_alloc_type::pointer _Tp<em> std::allocator  _Tp_alloc_type::pointer  _Tp</em> _Vector_base::pointer  _Tp*</p>\n<p> _Vector_base <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_impl_data</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    pointer _M_start;   <span class=\"comment\">//  vector </span></span><br><span class=\"line\">    pointer _M_finish;  <span class=\"comment\">//  vector  past-the-last-element </span></span><br><span class=\"line\">    pointer _M_end_of_storage;  <span class=\"comment\">// vector  past-the-max-element </span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_impl</span> :</span> <span class=\"keyword\">public</span> _Tp_alloc_type, <span class=\"keyword\">public</span> _Vector_impl_data</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"comment\">// vector  overflow  _GLIBCXX_SANITIZE_VECTOR AddressSanitizer</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> _Vector_base _Vector_base <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Alloc allocator_type;</span><br><span class=\"line\">    _Vector_impl _M_impl;           <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\">// / </span></span><br><span class=\"line\"></span><br><span class=\"line\">    pointer _M_allocator(<span class=\"keyword\">size_t</span> __n) &#123;      <span class=\"comment\">//  n  pointer </span></span><br><span class=\"line\">        <span class=\"keyword\">typedef</span> __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr;</span><br><span class=\"line\">        <span class=\"comment\">//  __n=0 nullptr _M_impl </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> __n != <span class=\"number\">0</span> ? _Tr::<span class=\"built_in\">allocate</span>(_M_impl, __n) : <span class=\"built_in\">pointer</span>();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    <span class=\"keyword\">void</span> _M_create_storage(<span class=\"keyword\">size_t</span> __n) &#123;    <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">this</span>-&gt;_M_impl._M_start = <span class=\"keyword\">this</span>-&gt;_M_allocate(__n);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>-&gt;_M_impl._M_finish = <span class=\"keyword\">this</span>-&gt;_M_impl._M_start;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>-&gt;_M_impl._M_end_of_storage = <span class=\"keyword\">this</span>-&gt;_M_impl._M_start + __n;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> _Vector_base  vector  vector <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// vector  vector  _Tp vector  _Alloc</span></span><br><span class=\"line\"><span class=\"comment\">//   _Alloc  std::allocator&lt;_Tp&gt; _Tp </span></span><br><span class=\"line\"><span class=\"comment\">//   _Alloc  _Tp  _Alloc::rebind  alloctor</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc = std::allocator&lt;_Tp&gt;&gt;</span><br><span class=\"line\">class vector : <span class=\"keyword\">protected</span> _Vector_base&lt;_Tp, _Alloc&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Vector_base&lt;_Tp, _Alloc&gt;               _Base;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base::_Tp_alloc_type          _Tp_alloc_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;   _Alloc_traits;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Tp                             value_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base::pointer         pointer;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> __gnu_cxx::__normal_iterator&lt;pointer, vector&gt;   iterator;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> std::reverse_iterator&lt;iterator&gt;                 reverse_iterator;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> vector  iterator pointer  <strong>gnu::cxx::</strong>normal_iterator  _Iterator<br> vector  vector  _M_impl._M_finish  past-the-last-element  vector <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">begin</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">iterator</span>(<span class=\"keyword\">this</span>-&gt;_M_impl._M_start); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">end</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">iterator</span>(<span class=\"keyword\">this</span>-&gt;_M_impl._M_finish); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">reverse_iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">rbegin</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">reverse_iterator</span>(<span class=\"built_in\">end</span>()); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">reverse_iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">rend</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">reverse_iterator</span>(<span class=\"built_in\">begin</span>()); &#125;</span><br></pre></td></tr></table></figure><br></p>\n<p> vector resize  vector  new_size &gt; old_size resize  new_size&lt;=old_size _M_impl._M_finish [_M_start, _M_finish) _M_finish </p>\n<p> vector  push_back <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">push_back</span><span class=\"params\">(<span class=\"keyword\">const</span> value_type&amp; __x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"keyword\">this</span>-&gt;_M_impl._M_finish != <span class=\"keyword\">this</span>-&gt;_M_impl._M_end_of_storage) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//  __x</span></span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span></span><br><span class=\"line\">        _M_realloc_insert(<span class=\"built_in\">end</span>(), __x);  <span class=\"comment\">//  _M_finish  __x</span></span><br><span class=\"line\">                                        <span class=\"comment\">//   _M_finish </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> bits/vector.tcc  _M_realloc_insert <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> ..._Arg&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span></span><br><span class=\"line\">vector&lt;_Tp, _Alloc&gt;::_M_realloc_insert(iterator __position, _Args&amp;&amp;... _args)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">//  2  _M_check_len</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> size_type __len = _M_check_len(<span class=\"built_in\">size_type</span>(<span class=\"number\">1</span>), <span class=\"string\">&quot;vector::_M_realloc_insert&quot;</span>);</span><br><span class=\"line\">    pointer __old_start = <span class=\"keyword\">this</span>-&gt;_M_impl._M_start;</span><br><span class=\"line\">    pointer __old_finish = <span class=\"keyword\">this</span>-&gt;_M_impl._M_finish; <span class=\"comment\">//  past-the-last </span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> size_type __elems_before = __position - <span class=\"built_in\">begin</span>();<span class=\"comment\">// </span></span><br><span class=\"line\">    pointer __new_start(<span class=\"keyword\">this</span>-&gt;_M_allocate(__len));   <span class=\"comment\">//  __len </span></span><br><span class=\"line\">    pointer __new_finish(__new_start);  <span class=\"comment\">//  past-the-last </span></span><br><span class=\"line\">    __try</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        _Alloc_traits::<span class=\"built_in\">construct</span>(<span class=\"keyword\">this</span>-&gt;_M_impl,                     <span class=\"comment\">// </span></span><br><span class=\"line\">                                 __new_start + __elems_before,      <span class=\"comment\">// </span></span><br><span class=\"line\">                                 std::forward&lt;_Args&gt;(__args)...);   <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"comment\">//  vector  __new_finish  nullptr</span></span><br><span class=\"line\">        __new_finish = <span class=\"built_in\">pointer</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> _GLIBCXX17_CONSTEXPR (_S_use_relocate()) &#123;   <span class=\"comment\">// </span></span><br><span class=\"line\">            <span class=\"comment\">// </span></span><br><span class=\"line\">            __new_finish = _S_relocate(__old_start, __position.<span class=\"built_in\">base</span>()</span><br><span class=\"line\">                __new_start, _M_get_Tp_allocator());</span><br><span class=\"line\">            <span class=\"comment\">//  __new_finish  1</span></span><br><span class=\"line\">            ++__new_finish;</span><br><span class=\"line\">            __new_finish = _S_relocate(__position.<span class=\"built_in\">base</span>(), __old_finish,</span><br><span class=\"line\">                __new_finish, _M_get_Tp_allocator());   <span class=\"comment\">//  __new_finish  past-of-last </span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>vector </p>\n<p></p>\n","site":{"data":{}},"excerpt":"<p> c++  c++ <br>","more":"<br> ubuntu gcc  7.3.0 /usr/include/c++/7/ </p>\n<ol>\n<li><a href=\"https://github.com/gcc-mirror/gcc\">gcc-mirror/gcc</a> clone  github </li>\n<li><a href=\"http://www.gnu.org/prep/ftp.html\">GNU Mirror List</a>  gcc </li>\n</ol>\n<p>C++ </p>\n<p></p>\n<h1 id=\"Allocator\"><a href=\"#Allocator\" class=\"headerlink\" title=\"Allocator\"></a>Allocator</h1><p> <strong>allocator_traits_base  libstdc++-v3/include/bits/alloc_traits.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> __<span class=\"title\">allocator_traits_base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Up, <span class=\"keyword\">typename</span> = <span class=\"keyword\">void</span>&gt;</span><br><span class=\"line\">    struct __rebind : __replace_first_arg&lt;_Tp, _Up&gt; &#123; &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Up&gt;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> __<span class=\"title\">rebind</span>&lt;</span>_Tp, _Up, <span class=\"keyword\">__void_t</span>&lt;<span class=\"keyword\">typename</span> _Tp::<span class=\"keyword\">template</span> rebind&lt;_Up&gt;::other&gt;&gt;</span><br><span class=\"line\">    &#123; <span class=\"keyword\">using</span> type = <span class=\"keyword\">typename</span> _Tp::<span class=\"keyword\">template</span> rebind&lt;_Up&gt;::other; &#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//  _Tp </span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp&gt;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> __pointer = <span class=\"keyword\">typename</span> _Tp::pointer;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> </strong>rebind __rebind</p>\n<ol>\n<li> void __rebind  </li>\n<li> void<ul>\n<li> _Tp::template rebind<_Up>::other  __rebind </li>\n<li> __rebind </li>\n</ul>\n</li>\n</ol>\n<p><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Alloc, <span class=\"keyword\">typename</span> _Up&gt;</span><br><span class=\"line\"><span class=\"keyword\">using</span> __alloc_rebind = <span class=\"keyword\">typename</span> __allocator_traits_base::<span class=\"keyword\">template</span> __rebind&lt;_Alloc, _Up&gt;::type;</span><br></pre></td></tr></table></figure><br> _Alloc::template rebind<_Up>::other  <strong>rebind  _Alloc </strong>alloc_rebind  _Alloc<_Up, ...>::type</p>\n<p> allocator_traits <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">allocator_traits</span>:</span> _allocator_traits_base</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Alloc allocator_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> type _Alloc::value_type value_type;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">using</span> pointer = <span class=\"keyword\">__detected_or_t</span>&lt;value_type*, __pointer, _Alloc&gt;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> pointer  _Alloc::pointer  value_type<em>_Alloc::pointer  value_type</em> <strong>pointer <br> std/type_traits  </strong>detected_or_t  __rebind  allocator_traits <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span>&gt; <span class=\"class\"><span class=\"keyword\">class</span> _<span class=\"title\">Func</span>, <span class=\"title\">typename</span> _<span class=\"title\">Tp</span>, <span class=\"title\">typename</span> =</span> <span class=\"keyword\">void</span>&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Ptr</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">using</span> type = <span class=\"keyword\">typename</span> pointer_traits&lt;pointer&gt;::<span class=\"keyword\">template</span> rebind&lt;_Tp&gt;;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span>&gt; <span class=\"class\"><span class=\"keyword\">class</span> _<span class=\"title\">Func</span>, <span class=\"title\">typename</span> _<span class=\"title\">Tp</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Ptr</span>&lt;</span>_Func, _Tp, <span class=\"keyword\">__void_t</span>&lt;_Func&lt;_Alloc&gt;&gt;&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> type = _Func&lt;_Alloc&gt;;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> _Ptr type  _Func<_Alloc> _Func  type  <code>pointer_traits&lt;pointer&gt;::template rebind&lt;_Tp&gt;</code> pointer  value_type<em>  bits/ptr_traits.h  pointer_traits <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;typename _Tp&gt;</span><br><span class=\"line\">struct pointer_traits&lt;_Tp*&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    template&lt;typename _Up&gt;</span><br><span class=\"line\">    using rebind = _Up*;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br> _Ptr::type  _Tp</em> allocator_traits  _Diff type _Size  type  _Ptr::type, _Diff::type  _Size::type <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//  _Alloc::const_pointer  _Alloc::const_pointer const value_type*</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> const_pointer = <span class=\"keyword\">typename</span> _Ptr&lt;__c_pointer, <span class=\"keyword\">const</span> value_type&gt;::type;</span><br><span class=\"line\"><span class=\"comment\">//  _Alloc::void_pointer  void*</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> void_pointer = <span class=\"keyword\">typename</span> _Ptr&lt;__v_pointer, <span class=\"keyword\">void</span>&gt;::type;</span><br><span class=\"line\"><span class=\"comment\">//  _Alloc::difference_type  pointer_traits&lt;pointer&gt;::difference_type</span></span><br><span class=\"line\"><span class=\"keyword\">using</span> difference_type = <span class=\"keyword\">typename</span> _Diff&lt;_Alloc, pointer&gt;::type;</span><br><span class=\"line\"><span class=\"comment\">//  _Alloc::size_type  difference_type </span></span><br><span class=\"line\"><span class=\"keyword\">using</span> size_type = <span class=\"keyword\">typename</span> _Size&lt;_Alloc, difference_type&gt;::type;</span><br></pre></td></tr></table></figure><br></p>\n<p> <strong>alloc_traits ext/alloc_traits.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Alloc, <span class=\"keyword\">typename</span> = <span class=\"keyword\">typename</span> _Alloc::value_type&gt;</span><br><span class=\"line\">struct __alloc_traits</span><br><span class=\"line\">    : std::allocator_traits&lt;_Alloc&gt;     <span class=\"comment\">//  __cplusplus &gt;= 201103L</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Alloc allocator_type;</span><br><span class=\"line\">    <span class=\"comment\">// std::allocator_traits </span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> std::allocator_traits&lt;_Alloc&gt;               _Base_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::value_type             value_type;</span><br><span class=\"line\">    <span class=\"comment\">// _Alloc::pointer or value_type*</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::pointer                pointer;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::const_pointer          const_pointer;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::size_type              size_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base_type::difference_type        difference_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> value_type&amp;                                 reference;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">const</span> value_type&amp;                           const_reference;</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::allocate;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::deallocate;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::construct;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::destroy;</span><br><span class=\"line\">    <span class=\"keyword\">using</span> _Base_type::max_size;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> std::allocator_traits  allocate <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_GLIBCXX_NODISCARD <span class=\"keyword\">static</span> pointer       <span class=\"comment\">// _GLIBCXX_NODISCARD </span></span><br><span class=\"line\"><span class=\"built_in\">allocate</span>(_Alloc&amp; __a, size_type __n)</span><br><span class=\"line\">&#123; <span class=\"keyword\">return</span> __a.<span class=\"built_in\">allocate</span>(__n); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">_GLIBCXX_NODISCARD <span class=\"keyword\">static</span> pointer</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">allocate</span><span class=\"params\">(_Alloc&amp; __a, size_type __n, const_void_pointer __hint)</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> _S_allocate(__a, __n, __hint, <span class=\"number\">0</span>); &#125;</span><br></pre></td></tr></table></figure><br>_Alloc  allocate  </strong>a  <strong>n  allocate  </strong>hint  __hint  allocate  allocate  allocatedeallocate, construct, destroy, max_size  _Tp  _Tp </p>\n<p> std::allocator_traits::construct <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span>... _Args&gt;</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">auto</span> <span class=\"title\">construct</span><span class=\"params\">(_Alloc&amp; __a, _Tp* __p, _Args&amp;&amp;... __args)</span></span></span><br><span class=\"line\"><span class=\"function\">...</span></span><br></pre></td></tr></table></figure><br> _Tp* _Tp  <strong>gnu_cxx::</strong>alloc_traits  construct <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Ptr&gt;</span><br><span class=\"line\"><span class=\"keyword\">using</span> __is_custom_pointer</span><br><span class=\"line\"><span class=\"comment\">//  _Ptr  pointer  _Ptr  =&gt; __is_custom_pointer </span></span><br><span class=\"line\"><span class=\"comment\">//  _Ptr  pointer  __is_custom_pointer </span></span><br><span class=\"line\">= std::__and_&lt;std::is_same&lt;pointer, _Ptr&gt;,</span><br><span class=\"line\">        std::__not_&lt;std::is_pointer&lt;_Ptr&gt;&gt;&gt;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  </span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Ptr, <span class=\"keyword\">typename</span>... _Args&gt;</span><br><span class=\"line\"><span class=\"comment\">//  __is_custom_pointer&lt;_Ptr&gt; enable_if&lt;xx&gt;::type </span></span><br><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">typename</span> std::enable_if&lt;__is_custom_pointer&lt;_Ptr&gt;::value&gt;::<span class=\"function\">type</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">construct</span><span class=\"params\">(_Alloc&amp; __a, _Ptr __p, _Args&amp;&amp;... __args)</span></span></span><br><span class=\"line\"><span class=\"function\">...</span></span><br></pre></td></tr></table></figure><br>const / rebind _Alloc  _Alloc  value_type  allocator_traits  value_type  rebind  allocator_traits::value_type  Allocator</p>\n<p>/</p>\n<p>std::allocator  bits/allocator.h  <strong>allocator_base </strong>gnu_cxx::new_allocator  new_allocator  allocate, deallocate, max_size, construct, destroy </p>\n<h1 id=\"Iterator\"><a href=\"#Iterator\" class=\"headerlink\" title=\"Iterator\"></a>Iterator</h1><p> bit/stl_iterator_base_types.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//  Iterator </span></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">input_iterator_tag</span><br><span class=\"line\">output_iterator_tag</span><br><span class=\"line\">forward_iterator_tag</span><br><span class=\"line\">bidirectional_iterator_tag</span><br><span class=\"line\">random_access_iterator_tag</span><br></pre></td></tr></table></figure><br> iterator_tag // std::iterator  iterator_traits </p>\n<p> bits/stl_iterator.h </p>\n<ol>\n<li>input  input  input <br></li>\n<li>output  input <br></li>\n<li>forward  input  output  input/output forward  multipass </li>\n<li>bidirectional  forword </li>\n<li>random-access  bidirectional </li>\n</ol>\n<p></p>\n<h2 id=\"reverse-iterator\"><a href=\"#reverse-iterator\" class=\"headerlink\" title=\"reverse_iterator\"></a>reverse_iterator</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Iterator&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">reverse_iterator</span>      // </span></span><br><span class=\"line\"><span class=\"class\">:</span> <span class=\"keyword\">public</span> iterator&lt;<span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::iterator_category,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::value_type,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::difference_type,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::pointer,</span><br><span class=\"line\">                <span class=\"keyword\">typename</span> iterator_traits&lt;_Iterator&gt;::reference&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Iterator current;  <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reference</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>*() <span class=\"keyword\">const</span> &#123;</span><br><span class=\"line\">        _Iterator __tmp = current;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *--__tmp;<span class=\"comment\">// </span></span><br><span class=\"line\">                        <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reverse_iterator&amp;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>++() &#123;</span><br><span class=\"line\">        --current;      <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> r i r  i  i </p>\n<ol>\n<li>: <em>r = </em>(i-1)</li>\n<li>++r = i, r = ++i</li>\n<li>r+n = i-n, r-n = i+n</li>\n</ol>\n<p>r  i </p>\n<h2 id=\"back-insert-iterator\"><a href=\"#back-insert-iterator\" class=\"headerlink\" title=\"back_insert_iterator\"></a>back_insert_iterator</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Container&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">back_insert_iterator</span></span></span><br><span class=\"line\"><span class=\"class\">:</span><span class=\"keyword\">public</span> iterator&lt;output_iterator_tag, <span class=\"keyword\">void</span>, <span class=\"keyword\">void</span>, <span class=\"keyword\">void</span>, <span class=\"keyword\">void</span>&gt; <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Container* container;  <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    back_insert_iterator&amp;   <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> <span class=\"keyword\">typename</span> _Container::value_type&amp; __value)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        container-&gt;<span class=\"built_in\">push_back</span>(__value);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    back_insert_iterator&amp;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>*() &#123; <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>; &#125;       <span class=\"comment\">//  output </span></span><br><span class=\"line\">    back_insert_iterator&amp;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>++() &#123;<span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>; &#125;       <span class=\"comment\">// </span></span><br><span class=\"line\">    back_insert_iterator&amp;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> front_insert_iterator, insert_iterator </p>\n<h2 id=\"normal-iterator\"><a href=\"#normal-iterator\" class=\"headerlink\" title=\"__normal_iterator\"></a>__normal_iterator</h2><p> _Iterator, _Container_Container  __normal_iterator <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Iterator, <span class=\"keyword\">typename</span> _Container&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> __<span class=\"title\">normal_iterator</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Iterator _M_current;   <span class=\"comment\">// _normal_iterator  _M_current </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\">//  _M_current </span></span><br><span class=\"line\">    <span class=\"comment\">//  __normal_iterator  _M_current </span></span><br><span class=\"line\">    <span class=\"comment\">//  normal </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"move-iterator\"><a href=\"#move-iterator\" class=\"headerlink\" title=\"move_iterator\"></a>move_iterator</h2><p> move move_iterator  move move  copy<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Iterator&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">move_iterator</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    _Iterator _M_current;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> iterator_traits&lt;_Iterator&gt;          __traits_type;  <span class=\"comment\">// _Iterator </span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> __traits_type::reference   __base_ref;     <span class=\"comment\">//  _Iterator </span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\">// __base_ref __base_ref </span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> conditional&lt;is_reference&lt;__base_ref&gt;::value,</span><br><span class=\"line\">        <span class=\"keyword\">typename</span> remove_reference&lt;__base_ref&gt;::type&amp;&amp;,</span><br><span class=\"line\">        __base_ref&gt;::type               reference;</span><br><span class=\"line\">    </span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reference</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>*() <span class=\"keyword\">const</span></span><br><span class=\"line\">    &#123; <span class=\"keyword\">return</span> <span class=\"keyword\">static_cast</span>&lt;reference&gt;(*_M_current); &#125; <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\">    _GLIBCXX17_CONSTEXPR reference</span><br><span class=\"line\">    <span class=\"keyword\">operator</span>[](difference_type __n) <span class=\"keyword\">const</span></span><br><span class=\"line\">    &#123; <span class=\"keyword\">return</span> std::<span class=\"built_in\">move</span>(_M_current[__n]); &#125;  <span class=\"comment\">// </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Container\"><a href=\"#Container\" class=\"headerlink\" title=\"Container\"></a>Container</h1><h2 id=\"Vector\"><a href=\"#Vector\" class=\"headerlink\" title=\"Vector\"></a>Vector</h2><p> vector  bits/stl_vector.h  _Vector_base<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> __gnu_cxx::__alloc_traits&lt;_Alloc&gt;::<span class=\"keyword\">template</span> rebind&lt;_Tp&gt;::other _Tp_alloc_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;::pointer pointer;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p> _Alloc  value_type  _Tp rebind  value_type  _Tp  alloctor alloctor<_Tp> _Tp_alloc_type pointer _Tp_alloc_type::pointer _Tp<em> std::allocator  _Tp_alloc_type::pointer  _Tp</em> _Vector_base::pointer  _Tp*</p>\n<p> _Vector_base <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_impl_data</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    pointer _M_start;   <span class=\"comment\">//  vector </span></span><br><span class=\"line\">    pointer _M_finish;  <span class=\"comment\">//  vector  past-the-last-element </span></span><br><span class=\"line\">    pointer _M_end_of_storage;  <span class=\"comment\">// vector  past-the-max-element </span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_impl</span> :</span> <span class=\"keyword\">public</span> _Tp_alloc_type, <span class=\"keyword\">public</span> _Vector_impl_data</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"comment\">// vector  overflow  _GLIBCXX_SANITIZE_VECTOR AddressSanitizer</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> _Vector_base _Vector_base <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> _<span class=\"title\">Vector_base</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Alloc allocator_type;</span><br><span class=\"line\">    _Vector_impl _M_impl;           <span class=\"comment\">// </span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"comment\">// / </span></span><br><span class=\"line\"></span><br><span class=\"line\">    pointer _M_allocator(<span class=\"keyword\">size_t</span> __n) &#123;      <span class=\"comment\">//  n  pointer </span></span><br><span class=\"line\">        <span class=\"keyword\">typedef</span> __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr;</span><br><span class=\"line\">        <span class=\"comment\">//  __n=0 nullptr _M_impl </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> __n != <span class=\"number\">0</span> ? _Tr::<span class=\"built_in\">allocate</span>(_M_impl, __n) : <span class=\"built_in\">pointer</span>();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">protected</span>:</span><br><span class=\"line\">    <span class=\"keyword\">void</span> _M_create_storage(<span class=\"keyword\">size_t</span> __n) &#123;    <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">this</span>-&gt;_M_impl._M_start = <span class=\"keyword\">this</span>-&gt;_M_allocate(__n);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>-&gt;_M_impl._M_finish = <span class=\"keyword\">this</span>-&gt;_M_impl._M_start;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>-&gt;_M_impl._M_end_of_storage = <span class=\"keyword\">this</span>-&gt;_M_impl._M_start + __n;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> _Vector_base  vector  vector <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// vector  vector  _Tp vector  _Alloc</span></span><br><span class=\"line\"><span class=\"comment\">//   _Alloc  std::allocator&lt;_Tp&gt; _Tp </span></span><br><span class=\"line\"><span class=\"comment\">//   _Alloc  _Tp  _Alloc::rebind  alloctor</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc = std::allocator&lt;_Tp&gt;&gt;</span><br><span class=\"line\">class vector : <span class=\"keyword\">protected</span> _Vector_base&lt;_Tp, _Alloc&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Vector_base&lt;_Tp, _Alloc&gt;               _Base;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base::_Tp_alloc_type          _Tp_alloc_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;   _Alloc_traits;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> _Tp                             value_type;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> _Base::pointer         pointer;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> __gnu_cxx::__normal_iterator&lt;pointer, vector&gt;   iterator;</span><br><span class=\"line\">    <span class=\"keyword\">typedef</span> std::reverse_iterator&lt;iterator&gt;                 reverse_iterator;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> vector  iterator pointer  <strong>gnu::cxx::</strong>normal_iterator  _Iterator<br> vector  vector  _M_impl._M_finish  past-the-last-element  vector <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">begin</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">iterator</span>(<span class=\"keyword\">this</span>-&gt;_M_impl._M_start); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">end</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">iterator</span>(<span class=\"keyword\">this</span>-&gt;_M_impl._M_finish); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">reverse_iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">rbegin</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">reverse_iterator</span>(<span class=\"built_in\">end</span>()); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">reverse_iterator</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">rend</span><span class=\"params\">()</span> _GLIBCXX_NOEXCEPT</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123; <span class=\"keyword\">return</span> <span class=\"built_in\">reverse_iterator</span>(<span class=\"built_in\">begin</span>()); &#125;</span><br></pre></td></tr></table></figure><br></p>\n<p> vector resize  vector  new_size &gt; old_size resize  new_size&lt;=old_size _M_impl._M_finish [_M_start, _M_finish) _M_finish </p>\n<p> vector  push_back <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">push_back</span><span class=\"params\">(<span class=\"keyword\">const</span> value_type&amp; __x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"keyword\">this</span>-&gt;_M_impl._M_finish != <span class=\"keyword\">this</span>-&gt;_M_impl._M_end_of_storage) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//  __x</span></span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span></span><br><span class=\"line\">        _M_realloc_insert(<span class=\"built_in\">end</span>(), __x);  <span class=\"comment\">//  _M_finish  __x</span></span><br><span class=\"line\">                                        <span class=\"comment\">//   _M_finish </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> bits/vector.tcc  _M_realloc_insert <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Alloc&gt;</span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> ..._Arg&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span></span><br><span class=\"line\">vector&lt;_Tp, _Alloc&gt;::_M_realloc_insert(iterator __position, _Args&amp;&amp;... _args)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">//  2  _M_check_len</span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> size_type __len = _M_check_len(<span class=\"built_in\">size_type</span>(<span class=\"number\">1</span>), <span class=\"string\">&quot;vector::_M_realloc_insert&quot;</span>);</span><br><span class=\"line\">    pointer __old_start = <span class=\"keyword\">this</span>-&gt;_M_impl._M_start;</span><br><span class=\"line\">    pointer __old_finish = <span class=\"keyword\">this</span>-&gt;_M_impl._M_finish; <span class=\"comment\">//  past-the-last </span></span><br><span class=\"line\">    <span class=\"keyword\">const</span> size_type __elems_before = __position - <span class=\"built_in\">begin</span>();<span class=\"comment\">// </span></span><br><span class=\"line\">    pointer __new_start(<span class=\"keyword\">this</span>-&gt;_M_allocate(__len));   <span class=\"comment\">//  __len </span></span><br><span class=\"line\">    pointer __new_finish(__new_start);  <span class=\"comment\">//  past-the-last </span></span><br><span class=\"line\">    __try</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        _Alloc_traits::<span class=\"built_in\">construct</span>(<span class=\"keyword\">this</span>-&gt;_M_impl,                     <span class=\"comment\">// </span></span><br><span class=\"line\">                                 __new_start + __elems_before,      <span class=\"comment\">// </span></span><br><span class=\"line\">                                 std::forward&lt;_Args&gt;(__args)...);   <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"comment\">//  vector  __new_finish  nullptr</span></span><br><span class=\"line\">        __new_finish = <span class=\"built_in\">pointer</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> _GLIBCXX17_CONSTEXPR (_S_use_relocate()) &#123;   <span class=\"comment\">// </span></span><br><span class=\"line\">            <span class=\"comment\">// </span></span><br><span class=\"line\">            __new_finish = _S_relocate(__old_start, __position.<span class=\"built_in\">base</span>()</span><br><span class=\"line\">                __new_start, _M_get_Tp_allocator());</span><br><span class=\"line\">            <span class=\"comment\">//  __new_finish  1</span></span><br><span class=\"line\">            ++__new_finish;</span><br><span class=\"line\">            __new_finish = _S_relocate(__position.<span class=\"built_in\">base</span>(), __old_finish,</span><br><span class=\"line\">                __new_finish, _M_get_Tp_allocator());   <span class=\"comment\">//  __new_finish  past-of-last </span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>vector </p>\n<p></p>"},{"title":"Dynamic Programming (1)","date":"2019-08-07T09:29:56.000Z","p":"dp/DP1","mathjax":true,"_content":" Dynamic Programming  A Computational Tool\n\n# \n\n / ``\n<!-- more -->\n\n## \n\n> \n\n~~~~\n\n### \n$opt_{d \\in \\Delta} \\{H(d)\\}$ d  $\\Delta$H H(d)  $d^{\\ast}$$d^{\\ast}=\\arg opt_d \\{H(d)\\}$ $\\{d_1,...,d_n\\}$ $h(d_1,...,h_n)$  $H^{\\ast}$\n\n $\\{d_1,...,d_n\\}$    $d_1,...,d_n$\n$$\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2}\\{...\\{opt_{d_n \\in D_n}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.1)\\end{aligned}$$\n\n $(d_1,...,d_n) \\in \\Delta=D_1 \\times ... \\times D_n$ i $d_i \\in D_i(d_1,...,d_{i-1})$ (1.1) \n$$\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.2)\\end{aligned}$$\n\n (1.2)  $d_n$ $d_n^{\\ast}(d_1,...,d_{n-1})$ $d_n^{\\ast}$  $opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast},...,d_n^{\\ast} \\}$  $d_1^{\\ast}$\n\n\n$$\\begin{aligned} &opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)} \\{... \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})} \\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_n \\in D_n} \\{opt_{d_{n-1} \\in D_{n-1}(d_n)} \\{... \\{opt_{d_1 \\in D_n(d_2,...,d_n)} \\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.3) \\end{aligned}$$\n\n $D_i$  $D_i$  $(d_{i+1},...,d_n)$\n\n (1.2) $d_1$ $d_1$ \n$$\\begin{aligned}H^{\\ast}&=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1}\\{h(d_1,d_2^{\\ast}(d_1),...,d_n^{\\ast}(d_1)\\} \\qquad \\qquad(1.4) \\end{aligned}$$\n\n $d_i^{\\ast}(d_1), \\ i>1$  $d_1$ partial function $d_1^{\\ast}=\\arg opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast}(d_1),...,d_n^{\\ast}(d_1))\\}$$d_1$ \n\n#### \n $d_1$  $d_2,...,d_n$  $opt_{d_1 \\in D_1}\\{H'(d_1)\\}$  $d_1$  $opt_{d_1}\\{H'(d_1)\\}$  $H^{\\ast}$  h \n$$h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_2) \\circ ... \\circ C_n(d_n) \\qquad (1.5)$$\n $C_i$  $d_i$ $\\circ$     \n$$opt_d\\{a \\circ C(d)\\}=a \\circ opt_d\\{C(d)\\}$$\n a  d $C_n$  $d_n$ $(d_1,d_2,...,d_{n-1})$\n$$h(d_1,...,d_n)=C_1(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\qquad(1.6)$$\n\n h \n$$h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n) \\qquad(1.7)$$\n\n$$\\begin{aligned} & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{C_1(d_1|\\emptyset) \\circ opt_{d_2 \\in D_2(d_1)}\\{C_2(d_1,d_2) \\circ ... \\circ \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_n(d_1,...,d_n)\\}...\\}\\} \\qquad(1.8) \\end{aligned}$$\n $\\circ$ \n\n $f(d_1,...,d_n)$  $d_1,...,d_{i-1}$ \n$$f(d_1,...,d_{i-1})=opt_{d_i}\\{opt_{d_{i+1}}\\{... \\{opt_{d_n} \\{C_i(d_i|d_1,...,d_{i-1}) \\circ C_{i+1}(d_{i+1}|d_1,...,d_i) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\}\\}...\\}\\} \\ (1.9)$$\n $D_i$\n$$\\begin{aligned}f(\\emptyset)&=opt_{d_1}\\{opt_{d_2}\\{...\\{opt_{d_n}\\{C(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1})\\}\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ opt_{d_2}\\{C(d_2|d_1) \\circ...\\circ opt_{d_n}\\{C_n(d_n|d_1,...,d_{n-1})\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ f(d_1)\\}  \\qquad \\quad (1.10) \\end{aligned}$$\n\n$$f(d_1,...,d_{i-1})=opt_{d_i \\in D_i(d_1,...,d_{i-1})}\\{C_i(d_i|d_1,...,d_{i-1})\\circ f(d_1,...,d_i)\\} \\qquad(1.11)$$\n\nDPFE\n\n### DPFE\n DPFE  $f(d_1,...,d_{i-1})$ $S=(d_1,...,d_{i-1})$ $i=|S|+1=|\\{d_1,...,d_{i-1}\\}|+1$ DPFE \n$$f(S)=opt_{d_i \\in D_i(S)}\\{C_i(d_i|S) \\circ f(S')\\} \\qquad (1.12)$$\n $S'=(d_1,...,d_i)$ $\\emptyset$  $\\mathcal S$ DPFE  $f(S_0)=b, \\ S_0 \\in \\mathcal S_{base}$ $S_0$$f(S_0)$  DPFE  b\n\n n  S  d  D(S)  S  d  $d \\in S$ DPFE \n$$f(S)=opt_{d \\in S} \\{C(d|S) \\circ f(S')\\} \\qquad (1.13)$$\n\n S  d  S  S'D(S)  S  DPFE  b(S,S') d  C(d|S) $S'=T(S,d), \\ T: \\mathcal S \\times D \\rightarrow \\mathcal S$T  DPFE \n$$f(S)=opt_S\\{b(S,S') \\circ f(S')\\} \\qquad(1.14) $$\n\nDPFE \n$$f'(S)=opt_{S'}\\{f'(S') \\circ b(S',S)\\} \\qquad(1.15) $$\n f'(S)  $S_0$  S  f(S)  S  $S_0$  (1.14) backward (1.15) forward\n\n### \n\n$$f(S)=opt_{d \\in D(S)} \\{R(S,d) \\circ f(T(S,d))\\}  \\quad (1.16)$$\nS  $\\mathcal S$ d  D(S) R(S,d)  C(d|S)T(S,d) $\\circ$ \n\n### \n N  A  x  $p_x$ A={a,b,c} $p_a=0.2,p_b=0.5,p_c=0.3$ 6  abc,acb,bac,bca,cab,cba bca  1.7\n1. Strong separable S  \n   $1p_b+2p_c+3p_a$\n2. Weak separable W  \n   $(p_a+p_b+p_c)+(p_a+p_c)+(p_a)$\n\n A  A'  S  x  $ip_x$ i  x  A'  W  A'  bca  {a,b,c} b  A'  {a,c}...  $\\sum_{x\\in D_i} p_x$\n\n i=1,2,3 $D_1=A,D_2=A-\\{d_1\\},D_3=A-\\{d_1,d_2\\}$ S  $h(d_1,d_2,d_3)=1p_{d_1}+2p_{d_2}+3p_{d_3}$\n$$\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{1p_{d_1}+2p_{d_2}+3p_{d_3}\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{1p_{d_1}+\\min_{d_2 \\in A-\\{d_1\\}}\\{2p_{d_2}+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{3p_{d_3}\\}\\}\\} \\end{aligned}$$\n\n W  $h(d_1,d_2,d_3)=\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x$\n$$\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{\\sum_{x \\in A}p_x+\\min_{d_2 \\in A-\\{d_1\\}}\\{\\sum_{x\\in A-\\{d_1\\}}p_x+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\} \\end{aligned}$$\n\n____ bca \n\n### \n DP  S  A' DPFE \n$$f(S)=\\min_{x \\in S} \\{C(x|S)+f(S-\\{x\\})\\}     \\quad(1.17)$$\n $S \\in 2^A$$2^A$  A  $f(\\emptyset)=0$ $f(A)$\n\n DPFE DPFE (1.15) \n$$f(S)=\\min_{S'} \\{C(x|S')+f(S')\\}     \\quad(1.18)$$\n $S \\in 2^A$ $f(\\emptyset)$ $f(A)=0$S'  S  S'  x  S\n\n W\n$$C_W(x|S)=\\sum_{y\\in S}p_y$$\n x  S  S \n\n S\n$$C_S(x|S)=(N+1-|S|)p_x$$\n x  A'  A' ... A'  $C_S'(x|S)=|S|p_x$ S  $C(x|S)+f(S-\\{x\\})$ DP \n\n DP  (1.17)  DPFE \n$$\\begin{aligned} f(\\{a,b,c\\}) &= \\min\\{C(a|\\{a,b,c\\})+f(\\{b,c\\}), C(b|\\{a,b,c\\})+f(\\{a,c\\}), C(c|\\{a,b,c\\})+f(\\{a,b\\})\\}\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(b|\\{b,c\\}+f(\\{c\\}),C(c|\\{b,c\\}+f(\\{b\\})\\}\n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(a|\\{a,c\\}+f(\\{c\\}),C(c|\\{a,c\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(a|\\{a,b\\}+f(\\{b\\}),C(c|\\{a,b\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(c|\\{c\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(b|\\{b\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(a|\\{a\\})+f(\\emptyset)\\} \n\\\\\\\\ f(\\emptyset) &= 0 \\end{aligned}$$\n S  W \n\n (1.18)  DPFE \n$$\\begin{aligned} f(\\{a,b,c\\}) &= 0\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(a|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0 \n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(b|\\{a,a,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(c|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(a|\\{a,c\\})+f(\\{a,c\\}), C(b|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.5+1.0,0.8+1.0\\}=1.5\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(a|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.8+1.0\\}=1.7\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(b|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{a,c\\})+f(\\{a,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.5+1.0\\}=1.5\n\\\\\\\\ f(\\emptyset) &= \\min \\{C(a|a)+f(\\{a\\}), C(b|b)+f(\\{b\\}), C(c|c)+f(\\{c\\})\\}\\stackrel W = \\min \\{0.2+1.5,0.5+1.7,0.3+1.5\\}=1.7 \\end{aligned}$$\n $\\stackrel W=$  W  S \n\n### \n 1 2...  S DPFE  (1.17) \n$$f(k,S)=\\min_{x \\in S} \\{C(x|k,S)+f(k+1,S-\\{x\\})\\} \\quad(1.19)$$\n\n### Path-States\n S  $(d_1,...,d_{i-1})$ S  $\\emptyset$  S  $(d_1,...,d_{i-1})$ S  S={a,b} a  b a  b a  b  Path-States S=(a,b) a  b DPFE \n$$f(S)=\\min_{x \\notin S} \\{C(x|S)+f(S + (x))\\} \\qquad(1.20)$$\n\n\n$$\\begin{aligned} f(\\emptyset) &= \\min \\{C(a|\\emptyset)+f(a),C(b|\\emptyset)+f(b),C(c|\\emptyset)+f(c)\\}\\stackrel S= \\min\\{0.2+1.9,0.5+1.2,0.3+1.6\\}=1.7\n\\\\\\\\ f(a) &= \\min \\{C(b|a)+f(ab), C(c|a)+f(ac)\\}\\stackrel S= \\min\\{2*0.5+0.9,2*0.3+1.5\\}=1.9\n\\\\\\\\ f(b) &= \\min \\{C(a|b)+f(ba), C(c|b)+f(bc)\\}\\stackrel S= \\min\\{2*0.2+0.9,2*0.3+0.6\\}=1.2\n\\\\\\\\ f(c) &= \\min \\{C(a|c)+f(ca), C(b|c)+f(cb)\\}\\stackrel S= \\min\\{2*0.2+1.5,2*0.5+0.6\\}=1.6\n\\\\\\\\ f(ab) &= \\min \\{C(c|ab)+f(abc)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(ac) &= \\min \\{C(b|ac)+f(acb)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(ba) &= \\min \\{C(c|ba)+f(bac)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(bc) &= \\min \\{C(a|bc)+f(bca)\\}\\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(ca) &= \\min \\{C(b|ca)+f(cab)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(cb) &= \\min \\{C(a|cb)+f(cba)\\} \\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(abc) &= f(acb)=f(bac)=f(bca)=f(cab)=f(cba)=0 \\end{aligned}$$\n $N!$  S  W  S $C(c|ab)$  c S  $C(c|ab)=3p_c=3*0.3=0.9$ $\\stackrel S=$  S  W \n\n###  Relaxation\n $\\{a_1,...,a_N\\}$\n$$x^{\\ast}=\\min\\{\\min\\{...\\{\\min\\{a_1,a_2\\},a_3\\},...\\},a_N\\}$$\n $x_1=a_1, x_2=\\min\\{x_1,a_2\\},...$ $x_1=\\min\\{x_0,a_1\\}, x_0=\\infty$ $x_1,x_2,...$  $x^{\\ast}$ DPFE \n$$\\begin{aligned} f(S)&=\\min_{x \\in S} \\{C(x|S)+f(S_x')\\}\n\\\\\\\\ &=\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}'),...,C(x_m|S)+f(S_{x_m}')\\} \\end{aligned}$$\n $S=\\{x_1,x_2,...,x_m\\}$$S_x'$  x  $C(x|S)+f(S_x')$ \n$$f(S)=\\min\\{\\min\\{...\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}')\\},...\\},C(x_m|S)+f(S_{x_m}')\\} \\quad (1.21)$$\n $C(x_i|S)$  S $f(S_{x_i}')$ \n\n DPFE \n$$f(k,S)=\\min_x \\{C(x|k,S) + f(k-1,S_x')\\} \\qquad(1.22)$$\n k  k  S  k  T (1.22) $f(0,S),f(1,S),...$  $f(S)$ $f(S)$ $f(S)=\\min_k \\{f(k,S)\\}$ $f(k,S)$  $f(k-1,S)$  $f(k-1,S_x')$  $f(k,S)$  $F(k,S)$ \n$$F(k,S)=\\min\\{F(k-1,S), \\min_x \\{C(x|k,S)+F(k-1,S_x')\\}\\} \\quad(1.23)$$\n $F(k,S)$  S  T  k  (1.22)  k  \n\n### \n\n\n s  t  DPFE \n$$f(p)=\\min_q \\{b(p,q)+f(q)\\} \\qquad(1.24)$$\n b(p,q)  p  q q  p f(p)  p  t  f(t)=0 q  p  $b(p,q)=\\infty$ f(p)  f(q)\n\np  q f(p)  f(q)  p  p \n1. b(p,p) > 0\n2. b(p,p) < 0\n3. b(p,p) = 0\n\nDPFE \n$$f(p) = \\min_q \\{b(p,q)+f(q)\\} \\qquad(1.25)$$\n f(q)  f(p) $f(p)=\\infty, \\forall p \\ne t; \\ f(t)=0$ (1.25)  (1.24) \n\n 1.2\n![](/images/DP1_fig1.png)\n\n (1.25) \n$$\\begin{aligned}f(s)&=\\min \\{b(s,x)+f(x),b(s,y)+f(y),b(s,t)+f(t)\\}=\\min \\{3+f(x),5+f(y),\\infty+f(t)\\}\n\\\\\\\\f(x)&=\\min \\{b(x,y)+f(y),b(x,t)+f(t)\\}=\\min \\{1+f(y),8+f(t)\\}\n\\\\\\\\f(y)&=\\min \\{b(y,x)+f(x),b(y,t)+f(t)\\}=\\min \\{2+f(x),5+f(t)\\}\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n f(x)  f(y) \n\n $f(s)=f(x)=f(y)=\\infty$\n$$\\begin{aligned}f(s)&=\\min \\{3+\\infty,5+\\infty,\\infty+f(t)\\}=\\infty\n\\\\\\\\f(x)&=\\min \\{1+\\infty,8+0\\}=8\n\\\\\\\\f(y)&=\\min \\{2+\\infty,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n\n\n$$\\begin{aligned}f(s)&=\\min \\{3+8,5+5,\\infty+0\\}=10\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+8,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n\n$$\\begin{aligned}f(s)&=\\min \\{3+6,5+5,\\infty+0\\}=9\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+6,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n $f(x),f(y),f(t)$  f(s)  f(s)\n\n Relaxation  (1.22) DPFE \n$$f(k,p)=\\min_q \\{b(p,q)+f(k-1,q)\\} \\qquad(1.26)$$\n f(k,p)  p  t k  p  t  k  $f(0,t)=0;f(k,t)=\\infty, k>0;f(0,p)=\\infty, \\forall p \\ne t$ t  t  0  0 0  $\\infty$ t p  t  0  $\\infty$ p  (1.26) \n$$\\begin{aligned}f(k,s)&=\\min \\{b(s,x)+f(k-1,x),b(s,y)+f(k-1,y),b(s,t)+f(k-1,t)\\}\n\\\\\\\\f(k,x)&=\\min \\{b(x,y)+f(k-1,y),b(x,t)+f(k-1,t)\\}\n\\\\\\\\f(k,y)&=\\min \\{b(y,x)+f(k-1,x),b(y,t)+f(k-1,t)\\}\n\\\\\\\\f(k,t) \\end{aligned}$$\n k=0 \n$$\\begin{aligned}f(1,s)&=\\min \\{3+f(0,x),5+f(0,y),\\infty+f(0,t)\\}=\\infty\n\\\\\\\\f(1,x)&=\\min \\{1+f(0,y),8+f(0,t)\\}=8\n\\\\\\\\f(1,y)&=\\min \\{2+f(0,x),5+f(0,t)\\}=5\n\\\\\\\\f(1,t)&=\\infty \\end{aligned}$$\n\n$$\\begin{aligned}f(2,s)&=\\min \\{3+f(1,x),5+f(1,y),\\infty+f(1,t)\\}=10\n\\\\\\\\f(2,x)&=\\min \\{1+f(1,y),8+f(1,t)\\}=6\n\\\\\\\\f(2,y)&=\\min \\{2+f(1,x),5+f(1,t)\\}=10\n\\\\\\\\f(2,t)&=\\infty \\end{aligned}$$\n\n$$\\begin{aligned}f(3,s)&=\\min \\{3+f(2,x),5+f(2,y),\\infty+f(2,t)\\}=9\n\\\\\\\\f(3,x)&=\\min \\{1+f(2,y),8+f(2,t)\\}=11\n\\\\\\\\f(3,y)&=\\min \\{2+f(1,x),5+f(2,t)\\}=8\n\\\\\\\\f(3,t)&=\\infty \\end{aligned}$$\n N  p  t  k k  {0,1,...,N-1}k  N circle 0 N=4 k  3 f  $f(p)=\\min_k \\{f(k,p)\\}$ \n$$\\begin{aligned}f(s)&=\\min \\{\\infty,\\infty,10,9\\}=9\n\\\\\\\\f(x)&=\\min \\{\\infty,8,6,11\\}=6\n\\\\\\\\f(y)&=\\min \\{\\infty,5,10,8\\}=5\n\\\\\\\\f(t)&=\\min \\{0,\\infty,\\infty,\\infty\\}=0 \\end{aligned}$$\n (1.22)  $f(k,S)$ \n\n $f(k,S)$  (1.23)  DPFE\n$$F(k,p)=\\min \\{F(k-1,p), \\ \\min_q \\{b(p,q)+F(k-1,q)\\}\\} \\qquad(1.27)$$\n\n $F(k,p)$  p  t  k  p  t  $N-1$  $F(N-1,s)$k  $N-1$ $F(k,t)=0,k\\ge 0; F(0,p)=\\infty, p \\ne t$\n\n\n DPFE","source":"_posts/dp/DP1.md","raw":"---\ntitle: Dynamic Programming (1)\ndate: 2019-08-07 17:29:56\np: dp/DP1\ntags:\n    - math\n    - DP\ncategory: math\nmathjax: true\n---\n Dynamic Programming  A Computational Tool\n\n# \n\n / ``\n<!-- more -->\n\n## \n\n> \n\n~~~~\n\n### \n$opt_{d \\in \\Delta} \\{H(d)\\}$ d  $\\Delta$H H(d)  $d^{\\ast}$$d^{\\ast}=\\arg opt_d \\{H(d)\\}$ $\\{d_1,...,d_n\\}$ $h(d_1,...,h_n)$  $H^{\\ast}$\n\n $\\{d_1,...,d_n\\}$    $d_1,...,d_n$\n$$\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2}\\{...\\{opt_{d_n \\in D_n}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.1)\\end{aligned}$$\n\n $(d_1,...,d_n) \\in \\Delta=D_1 \\times ... \\times D_n$ i $d_i \\in D_i(d_1,...,d_{i-1})$ (1.1) \n$$\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.2)\\end{aligned}$$\n\n (1.2)  $d_n$ $d_n^{\\ast}(d_1,...,d_{n-1})$ $d_n^{\\ast}$  $opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast},...,d_n^{\\ast} \\}$  $d_1^{\\ast}$\n\n\n$$\\begin{aligned} &opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)} \\{... \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})} \\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_n \\in D_n} \\{opt_{d_{n-1} \\in D_{n-1}(d_n)} \\{... \\{opt_{d_1 \\in D_n(d_2,...,d_n)} \\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.3) \\end{aligned}$$\n\n $D_i$  $D_i$  $(d_{i+1},...,d_n)$\n\n (1.2) $d_1$ $d_1$ \n$$\\begin{aligned}H^{\\ast}&=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1}\\{h(d_1,d_2^{\\ast}(d_1),...,d_n^{\\ast}(d_1)\\} \\qquad \\qquad(1.4) \\end{aligned}$$\n\n $d_i^{\\ast}(d_1), \\ i>1$  $d_1$ partial function $d_1^{\\ast}=\\arg opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast}(d_1),...,d_n^{\\ast}(d_1))\\}$$d_1$ \n\n#### \n $d_1$  $d_2,...,d_n$  $opt_{d_1 \\in D_1}\\{H'(d_1)\\}$  $d_1$  $opt_{d_1}\\{H'(d_1)\\}$  $H^{\\ast}$  h \n$$h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_2) \\circ ... \\circ C_n(d_n) \\qquad (1.5)$$\n $C_i$  $d_i$ $\\circ$     \n$$opt_d\\{a \\circ C(d)\\}=a \\circ opt_d\\{C(d)\\}$$\n a  d $C_n$  $d_n$ $(d_1,d_2,...,d_{n-1})$\n$$h(d_1,...,d_n)=C_1(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\qquad(1.6)$$\n\n h \n$$h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n) \\qquad(1.7)$$\n\n$$\\begin{aligned} & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{C_1(d_1|\\emptyset) \\circ opt_{d_2 \\in D_2(d_1)}\\{C_2(d_1,d_2) \\circ ... \\circ \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_n(d_1,...,d_n)\\}...\\}\\} \\qquad(1.8) \\end{aligned}$$\n $\\circ$ \n\n $f(d_1,...,d_n)$  $d_1,...,d_{i-1}$ \n$$f(d_1,...,d_{i-1})=opt_{d_i}\\{opt_{d_{i+1}}\\{... \\{opt_{d_n} \\{C_i(d_i|d_1,...,d_{i-1}) \\circ C_{i+1}(d_{i+1}|d_1,...,d_i) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\}\\}...\\}\\} \\ (1.9)$$\n $D_i$\n$$\\begin{aligned}f(\\emptyset)&=opt_{d_1}\\{opt_{d_2}\\{...\\{opt_{d_n}\\{C(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1})\\}\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ opt_{d_2}\\{C(d_2|d_1) \\circ...\\circ opt_{d_n}\\{C_n(d_n|d_1,...,d_{n-1})\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ f(d_1)\\}  \\qquad \\quad (1.10) \\end{aligned}$$\n\n$$f(d_1,...,d_{i-1})=opt_{d_i \\in D_i(d_1,...,d_{i-1})}\\{C_i(d_i|d_1,...,d_{i-1})\\circ f(d_1,...,d_i)\\} \\qquad(1.11)$$\n\nDPFE\n\n### DPFE\n DPFE  $f(d_1,...,d_{i-1})$ $S=(d_1,...,d_{i-1})$ $i=|S|+1=|\\{d_1,...,d_{i-1}\\}|+1$ DPFE \n$$f(S)=opt_{d_i \\in D_i(S)}\\{C_i(d_i|S) \\circ f(S')\\} \\qquad (1.12)$$\n $S'=(d_1,...,d_i)$ $\\emptyset$  $\\mathcal S$ DPFE  $f(S_0)=b, \\ S_0 \\in \\mathcal S_{base}$ $S_0$$f(S_0)$  DPFE  b\n\n n  S  d  D(S)  S  d  $d \\in S$ DPFE \n$$f(S)=opt_{d \\in S} \\{C(d|S) \\circ f(S')\\} \\qquad (1.13)$$\n\n S  d  S  S'D(S)  S  DPFE  b(S,S') d  C(d|S) $S'=T(S,d), \\ T: \\mathcal S \\times D \\rightarrow \\mathcal S$T  DPFE \n$$f(S)=opt_S\\{b(S,S') \\circ f(S')\\} \\qquad(1.14) $$\n\nDPFE \n$$f'(S)=opt_{S'}\\{f'(S') \\circ b(S',S)\\} \\qquad(1.15) $$\n f'(S)  $S_0$  S  f(S)  S  $S_0$  (1.14) backward (1.15) forward\n\n### \n\n$$f(S)=opt_{d \\in D(S)} \\{R(S,d) \\circ f(T(S,d))\\}  \\quad (1.16)$$\nS  $\\mathcal S$ d  D(S) R(S,d)  C(d|S)T(S,d) $\\circ$ \n\n### \n N  A  x  $p_x$ A={a,b,c} $p_a=0.2,p_b=0.5,p_c=0.3$ 6  abc,acb,bac,bca,cab,cba bca  1.7\n1. Strong separable S  \n   $1p_b+2p_c+3p_a$\n2. Weak separable W  \n   $(p_a+p_b+p_c)+(p_a+p_c)+(p_a)$\n\n A  A'  S  x  $ip_x$ i  x  A'  W  A'  bca  {a,b,c} b  A'  {a,c}...  $\\sum_{x\\in D_i} p_x$\n\n i=1,2,3 $D_1=A,D_2=A-\\{d_1\\},D_3=A-\\{d_1,d_2\\}$ S  $h(d_1,d_2,d_3)=1p_{d_1}+2p_{d_2}+3p_{d_3}$\n$$\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{1p_{d_1}+2p_{d_2}+3p_{d_3}\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{1p_{d_1}+\\min_{d_2 \\in A-\\{d_1\\}}\\{2p_{d_2}+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{3p_{d_3}\\}\\}\\} \\end{aligned}$$\n\n W  $h(d_1,d_2,d_3)=\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x$\n$$\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{\\sum_{x \\in A}p_x+\\min_{d_2 \\in A-\\{d_1\\}}\\{\\sum_{x\\in A-\\{d_1\\}}p_x+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\} \\end{aligned}$$\n\n____ bca \n\n### \n DP  S  A' DPFE \n$$f(S)=\\min_{x \\in S} \\{C(x|S)+f(S-\\{x\\})\\}     \\quad(1.17)$$\n $S \\in 2^A$$2^A$  A  $f(\\emptyset)=0$ $f(A)$\n\n DPFE DPFE (1.15) \n$$f(S)=\\min_{S'} \\{C(x|S')+f(S')\\}     \\quad(1.18)$$\n $S \\in 2^A$ $f(\\emptyset)$ $f(A)=0$S'  S  S'  x  S\n\n W\n$$C_W(x|S)=\\sum_{y\\in S}p_y$$\n x  S  S \n\n S\n$$C_S(x|S)=(N+1-|S|)p_x$$\n x  A'  A' ... A'  $C_S'(x|S)=|S|p_x$ S  $C(x|S)+f(S-\\{x\\})$ DP \n\n DP  (1.17)  DPFE \n$$\\begin{aligned} f(\\{a,b,c\\}) &= \\min\\{C(a|\\{a,b,c\\})+f(\\{b,c\\}), C(b|\\{a,b,c\\})+f(\\{a,c\\}), C(c|\\{a,b,c\\})+f(\\{a,b\\})\\}\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(b|\\{b,c\\}+f(\\{c\\}),C(c|\\{b,c\\}+f(\\{b\\})\\}\n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(a|\\{a,c\\}+f(\\{c\\}),C(c|\\{a,c\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(a|\\{a,b\\}+f(\\{b\\}),C(c|\\{a,b\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(c|\\{c\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(b|\\{b\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(a|\\{a\\})+f(\\emptyset)\\} \n\\\\\\\\ f(\\emptyset) &= 0 \\end{aligned}$$\n S  W \n\n (1.18)  DPFE \n$$\\begin{aligned} f(\\{a,b,c\\}) &= 0\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(a|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0 \n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(b|\\{a,a,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(c|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(a|\\{a,c\\})+f(\\{a,c\\}), C(b|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.5+1.0,0.8+1.0\\}=1.5\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(a|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.8+1.0\\}=1.7\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(b|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{a,c\\})+f(\\{a,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.5+1.0\\}=1.5\n\\\\\\\\ f(\\emptyset) &= \\min \\{C(a|a)+f(\\{a\\}), C(b|b)+f(\\{b\\}), C(c|c)+f(\\{c\\})\\}\\stackrel W = \\min \\{0.2+1.5,0.5+1.7,0.3+1.5\\}=1.7 \\end{aligned}$$\n $\\stackrel W=$  W  S \n\n### \n 1 2...  S DPFE  (1.17) \n$$f(k,S)=\\min_{x \\in S} \\{C(x|k,S)+f(k+1,S-\\{x\\})\\} \\quad(1.19)$$\n\n### Path-States\n S  $(d_1,...,d_{i-1})$ S  $\\emptyset$  S  $(d_1,...,d_{i-1})$ S  S={a,b} a  b a  b a  b  Path-States S=(a,b) a  b DPFE \n$$f(S)=\\min_{x \\notin S} \\{C(x|S)+f(S + (x))\\} \\qquad(1.20)$$\n\n\n$$\\begin{aligned} f(\\emptyset) &= \\min \\{C(a|\\emptyset)+f(a),C(b|\\emptyset)+f(b),C(c|\\emptyset)+f(c)\\}\\stackrel S= \\min\\{0.2+1.9,0.5+1.2,0.3+1.6\\}=1.7\n\\\\\\\\ f(a) &= \\min \\{C(b|a)+f(ab), C(c|a)+f(ac)\\}\\stackrel S= \\min\\{2*0.5+0.9,2*0.3+1.5\\}=1.9\n\\\\\\\\ f(b) &= \\min \\{C(a|b)+f(ba), C(c|b)+f(bc)\\}\\stackrel S= \\min\\{2*0.2+0.9,2*0.3+0.6\\}=1.2\n\\\\\\\\ f(c) &= \\min \\{C(a|c)+f(ca), C(b|c)+f(cb)\\}\\stackrel S= \\min\\{2*0.2+1.5,2*0.5+0.6\\}=1.6\n\\\\\\\\ f(ab) &= \\min \\{C(c|ab)+f(abc)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(ac) &= \\min \\{C(b|ac)+f(acb)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(ba) &= \\min \\{C(c|ba)+f(bac)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(bc) &= \\min \\{C(a|bc)+f(bca)\\}\\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(ca) &= \\min \\{C(b|ca)+f(cab)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(cb) &= \\min \\{C(a|cb)+f(cba)\\} \\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(abc) &= f(acb)=f(bac)=f(bca)=f(cab)=f(cba)=0 \\end{aligned}$$\n $N!$  S  W  S $C(c|ab)$  c S  $C(c|ab)=3p_c=3*0.3=0.9$ $\\stackrel S=$  S  W \n\n###  Relaxation\n $\\{a_1,...,a_N\\}$\n$$x^{\\ast}=\\min\\{\\min\\{...\\{\\min\\{a_1,a_2\\},a_3\\},...\\},a_N\\}$$\n $x_1=a_1, x_2=\\min\\{x_1,a_2\\},...$ $x_1=\\min\\{x_0,a_1\\}, x_0=\\infty$ $x_1,x_2,...$  $x^{\\ast}$ DPFE \n$$\\begin{aligned} f(S)&=\\min_{x \\in S} \\{C(x|S)+f(S_x')\\}\n\\\\\\\\ &=\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}'),...,C(x_m|S)+f(S_{x_m}')\\} \\end{aligned}$$\n $S=\\{x_1,x_2,...,x_m\\}$$S_x'$  x  $C(x|S)+f(S_x')$ \n$$f(S)=\\min\\{\\min\\{...\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}')\\},...\\},C(x_m|S)+f(S_{x_m}')\\} \\quad (1.21)$$\n $C(x_i|S)$  S $f(S_{x_i}')$ \n\n DPFE \n$$f(k,S)=\\min_x \\{C(x|k,S) + f(k-1,S_x')\\} \\qquad(1.22)$$\n k  k  S  k  T (1.22) $f(0,S),f(1,S),...$  $f(S)$ $f(S)$ $f(S)=\\min_k \\{f(k,S)\\}$ $f(k,S)$  $f(k-1,S)$  $f(k-1,S_x')$  $f(k,S)$  $F(k,S)$ \n$$F(k,S)=\\min\\{F(k-1,S), \\min_x \\{C(x|k,S)+F(k-1,S_x')\\}\\} \\quad(1.23)$$\n $F(k,S)$  S  T  k  (1.22)  k  \n\n### \n\n\n s  t  DPFE \n$$f(p)=\\min_q \\{b(p,q)+f(q)\\} \\qquad(1.24)$$\n b(p,q)  p  q q  p f(p)  p  t  f(t)=0 q  p  $b(p,q)=\\infty$ f(p)  f(q)\n\np  q f(p)  f(q)  p  p \n1. b(p,p) > 0\n2. b(p,p) < 0\n3. b(p,p) = 0\n\nDPFE \n$$f(p) = \\min_q \\{b(p,q)+f(q)\\} \\qquad(1.25)$$\n f(q)  f(p) $f(p)=\\infty, \\forall p \\ne t; \\ f(t)=0$ (1.25)  (1.24) \n\n 1.2\n![](/images/DP1_fig1.png)\n\n (1.25) \n$$\\begin{aligned}f(s)&=\\min \\{b(s,x)+f(x),b(s,y)+f(y),b(s,t)+f(t)\\}=\\min \\{3+f(x),5+f(y),\\infty+f(t)\\}\n\\\\\\\\f(x)&=\\min \\{b(x,y)+f(y),b(x,t)+f(t)\\}=\\min \\{1+f(y),8+f(t)\\}\n\\\\\\\\f(y)&=\\min \\{b(y,x)+f(x),b(y,t)+f(t)\\}=\\min \\{2+f(x),5+f(t)\\}\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n f(x)  f(y) \n\n $f(s)=f(x)=f(y)=\\infty$\n$$\\begin{aligned}f(s)&=\\min \\{3+\\infty,5+\\infty,\\infty+f(t)\\}=\\infty\n\\\\\\\\f(x)&=\\min \\{1+\\infty,8+0\\}=8\n\\\\\\\\f(y)&=\\min \\{2+\\infty,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n\n\n$$\\begin{aligned}f(s)&=\\min \\{3+8,5+5,\\infty+0\\}=10\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+8,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n\n$$\\begin{aligned}f(s)&=\\min \\{3+6,5+5,\\infty+0\\}=9\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+6,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}$$\n $f(x),f(y),f(t)$  f(s)  f(s)\n\n Relaxation  (1.22) DPFE \n$$f(k,p)=\\min_q \\{b(p,q)+f(k-1,q)\\} \\qquad(1.26)$$\n f(k,p)  p  t k  p  t  k  $f(0,t)=0;f(k,t)=\\infty, k>0;f(0,p)=\\infty, \\forall p \\ne t$ t  t  0  0 0  $\\infty$ t p  t  0  $\\infty$ p  (1.26) \n$$\\begin{aligned}f(k,s)&=\\min \\{b(s,x)+f(k-1,x),b(s,y)+f(k-1,y),b(s,t)+f(k-1,t)\\}\n\\\\\\\\f(k,x)&=\\min \\{b(x,y)+f(k-1,y),b(x,t)+f(k-1,t)\\}\n\\\\\\\\f(k,y)&=\\min \\{b(y,x)+f(k-1,x),b(y,t)+f(k-1,t)\\}\n\\\\\\\\f(k,t) \\end{aligned}$$\n k=0 \n$$\\begin{aligned}f(1,s)&=\\min \\{3+f(0,x),5+f(0,y),\\infty+f(0,t)\\}=\\infty\n\\\\\\\\f(1,x)&=\\min \\{1+f(0,y),8+f(0,t)\\}=8\n\\\\\\\\f(1,y)&=\\min \\{2+f(0,x),5+f(0,t)\\}=5\n\\\\\\\\f(1,t)&=\\infty \\end{aligned}$$\n\n$$\\begin{aligned}f(2,s)&=\\min \\{3+f(1,x),5+f(1,y),\\infty+f(1,t)\\}=10\n\\\\\\\\f(2,x)&=\\min \\{1+f(1,y),8+f(1,t)\\}=6\n\\\\\\\\f(2,y)&=\\min \\{2+f(1,x),5+f(1,t)\\}=10\n\\\\\\\\f(2,t)&=\\infty \\end{aligned}$$\n\n$$\\begin{aligned}f(3,s)&=\\min \\{3+f(2,x),5+f(2,y),\\infty+f(2,t)\\}=9\n\\\\\\\\f(3,x)&=\\min \\{1+f(2,y),8+f(2,t)\\}=11\n\\\\\\\\f(3,y)&=\\min \\{2+f(1,x),5+f(2,t)\\}=8\n\\\\\\\\f(3,t)&=\\infty \\end{aligned}$$\n N  p  t  k k  {0,1,...,N-1}k  N circle 0 N=4 k  3 f  $f(p)=\\min_k \\{f(k,p)\\}$ \n$$\\begin{aligned}f(s)&=\\min \\{\\infty,\\infty,10,9\\}=9\n\\\\\\\\f(x)&=\\min \\{\\infty,8,6,11\\}=6\n\\\\\\\\f(y)&=\\min \\{\\infty,5,10,8\\}=5\n\\\\\\\\f(t)&=\\min \\{0,\\infty,\\infty,\\infty\\}=0 \\end{aligned}$$\n (1.22)  $f(k,S)$ \n\n $f(k,S)$  (1.23)  DPFE\n$$F(k,p)=\\min \\{F(k-1,p), \\ \\min_q \\{b(p,q)+F(k-1,q)\\}\\} \\qquad(1.27)$$\n\n $F(k,p)$  p  t  k  p  t  $N-1$  $F(N-1,s)$k  $N-1$ $F(k,t)=0,k\\ge 0; F(0,p)=\\infty, p \\ne t$\n\n\n DPFE","slug":"dp/DP1","published":1,"updated":"2020-04-24T10:31:05.843Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92b0053p0djb63rajmr","content":"<p> Dynamic Programming  A Computational Tool</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> / <code></code><br><span id=\"more\"></span></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><blockquote>\n<p></p>\n</blockquote>\n<p><del></del></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$opt_{d \\in \\Delta} \\{H(d)\\}$ d  $\\Delta$H H(d)  $d^{\\ast}$$d^{\\ast}=\\arg opt_d \\{H(d)\\}$ $\\{d_1,,d_n\\}$ $h(d_1,,h_n)$  $H^{\\ast}$</p>\n<p> $\\{d_1,,d_n\\}$    $d_1,,d_n$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2}\\{...\\{opt_{d_n \\in D_n}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.1)\\end{aligned}</script><p> $(d_1,,d_n) \\in \\Delta=D_1 \\times  \\times D_n$ i $d_i \\in D_i(d_1,,d_{i-1})$ (1.1) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.2)\\end{aligned}</script><p> (1.2)  $d_n$ $d_n^{\\ast}(d_1,,d_{n-1})$ $d_n^{\\ast}$  $opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast},,d_n^{\\ast} \\}$  $d_1^{\\ast}$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} &opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)} \\{... \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})} \\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_n \\in D_n} \\{opt_{d_{n-1} \\in D_{n-1}(d_n)} \\{... \\{opt_{d_1 \\in D_n(d_2,...,d_n)} \\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.3) \\end{aligned}</script><p> $D_i$  $D_i$  $(d_{i+1},,d_n)$</p>\n<p> (1.2) $d_1$ $d_1$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}H^{\\ast}&=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1}\\{h(d_1,d_2^{\\ast}(d_1),...,d_n^{\\ast}(d_1)\\} \\qquad \\qquad(1.4) \\end{aligned}</script><p> $d_i^{\\ast}(d_1), \\ i&gt;1$  $d_1$ partial function $d_1^{\\ast}=\\arg opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast}(d_1),,d_n^{\\ast}(d_1))\\}$$d_1$ </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> $d_1$  $d_2,,d_n$  $opt_{d_1 \\in D_1}\\{H(d_1)\\}$  $d_1$  $opt_{d_1}\\{H(d_1)\\}$  $H^{\\ast}$  h </p>\n<script type=\"math/tex; mode=display\">h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_2) \\circ ... \\circ C_n(d_n) \\qquad (1.5)</script><p> $C_i$  $d_i$ $\\circ$     </p>\n<script type=\"math/tex; mode=display\">opt_d\\{a \\circ C(d)\\}=a \\circ opt_d\\{C(d)\\}</script><p> a  d $C_n$  $d_n$ $(d_1,d_2,,d_{n-1})$</p>\n<script type=\"math/tex; mode=display\">h(d_1,...,d_n)=C_1(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\qquad(1.6)</script><p> h </p>\n<script type=\"math/tex; mode=display\">h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n) \\qquad(1.7)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{C_1(d_1|\\emptyset) \\circ opt_{d_2 \\in D_2(d_1)}\\{C_2(d_1,d_2) \\circ ... \\circ \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_n(d_1,...,d_n)\\}...\\}\\} \\qquad(1.8) \\end{aligned}</script><p> $\\circ$ </p>\n<p> $f(d_1,,d_n)$  $d_1,,d_{i-1}$ </p>\n<script type=\"math/tex; mode=display\">f(d_1,...,d_{i-1})=opt_{d_i}\\{opt_{d_{i+1}}\\{... \\{opt_{d_n} \\{C_i(d_i|d_1,...,d_{i-1}) \\circ C_{i+1}(d_{i+1}|d_1,...,d_i) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\}\\}...\\}\\} \\ (1.9)</script><p> $D_i$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(\\emptyset)&=opt_{d_1}\\{opt_{d_2}\\{...\\{opt_{d_n}\\{C(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1})\\}\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ opt_{d_2}\\{C(d_2|d_1) \\circ...\\circ opt_{d_n}\\{C_n(d_n|d_1,...,d_{n-1})\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ f(d_1)\\}  \\qquad \\quad (1.10) \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">f(d_1,...,d_{i-1})=opt_{d_i \\in D_i(d_1,...,d_{i-1})}\\{C_i(d_i|d_1,...,d_{i-1})\\circ f(d_1,...,d_i)\\} \\qquad(1.11)</script><p>DPFE</p>\n<h3 id=\"DPFE\"><a href=\"#DPFE\" class=\"headerlink\" title=\"DPFE\"></a>DPFE</h3><p> DPFE  $f(d_1,,d_{i-1})$ $S=(d_1,,d_{i-1})$ $i=|S|+1=|\\{d_1,,d_{i-1}\\}|+1$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=opt_{d_i \\in D_i(S)}\\{C_i(d_i|S) \\circ f(S')\\} \\qquad (1.12)</script><p> $S=(d_1,,d_i)$ $\\emptyset$  $\\mathcal S$ DPFE  $f(S_0)=b, \\ S_0 \\in \\mathcal S_{base}$ $S_0$$f(S_0)$  DPFE  b</p>\n<p> n  S  d  D(S)  S  d  $d \\in S$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=opt_{d \\in S} \\{C(d|S) \\circ f(S')\\} \\qquad (1.13)</script><p> S  d  S  SD(S)  S  DPFE  b(S,S) d  C(d|S) $S=T(S,d), \\ T: \\mathcal S \\times D \\rightarrow \\mathcal S$T  DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=opt_S\\{b(S,S') \\circ f(S')\\} \\qquad(1.14)</script><p>DPFE </p>\n<script type=\"math/tex; mode=display\">f'(S)=opt_{S'}\\{f'(S') \\circ b(S',S)\\} \\qquad(1.15)</script><p> f(S)  $S_0$  S  f(S)  S  $S_0$  (1.14) backward (1.15) forward</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">f(S)=opt_{d \\in D(S)} \\{R(S,d) \\circ f(T(S,d))\\}  \\quad (1.16)</script><p>S  $\\mathcal S$ d  D(S) R(S,d)  C(d|S)T(S,d) $\\circ$ </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> N  A  x  $p_x$ A={a,b,c} $p_a=0.2,p_b=0.5,p_c=0.3$ 6  abc,acb,bac,bca,cab,cba bca  1.7</p>\n<ol>\n<li>Strong separable S<br>$1p_b+2p_c+3p_a$</li>\n<li>Weak separable W<br>$(p_a+p_b+p_c)+(p_a+p_c)+(p_a)$</li>\n</ol>\n<p> A  A  S  x  $ip_x$ i  x  A  W  A  bca  {a,b,c} b  A  {a,c}  $\\sum_{x\\in D_i} p_x$</p>\n<p> i=1,2,3 $D_1=A,D_2=A-\\{d_1\\},D_3=A-\\{d_1,d_2\\}$ S  $h(d_1,d_2,d_3)=1p_{d_1}+2p_{d_2}+3p_{d_3}$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{1p_{d_1}+2p_{d_2}+3p_{d_3}\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{1p_{d_1}+\\min_{d_2 \\in A-\\{d_1\\}}\\{2p_{d_2}+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{3p_{d_3}\\}\\}\\} \\end{aligned}</script><p> W  $h(d_1,d_2,d_3)=\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{\\sum_{x \\in A}p_x+\\min_{d_2 \\in A-\\{d_1\\}}\\{\\sum_{x\\in A-\\{d_1\\}}p_x+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\} \\end{aligned}</script><p><strong></strong> bca </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> DP  S  A DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min_{x \\in S} \\{C(x|S)+f(S-\\{x\\})\\}     \\quad(1.17)</script><p> $S \\in 2^A$$2^A$  A  $f(\\emptyset)=0$ $f(A)$</p>\n<p> DPFE DPFE (1.15) </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min_{S'} \\{C(x|S')+f(S')\\}     \\quad(1.18)</script><p> $S \\in 2^A$ $f(\\emptyset)$ $f(A)=0$S  S  S  x  S</p>\n<p> W</p>\n<script type=\"math/tex; mode=display\">C_W(x|S)=\\sum_{y\\in S}p_y</script><p> x  S  S </p>\n<p> S</p>\n<script type=\"math/tex; mode=display\">C_S(x|S)=(N+1-|S|)p_x</script><p> x  A  A  A  $C_S(x|S)=|S|p_x$ S  $C(x|S)+f(S-\\{x\\})$ DP </p>\n<p> DP  (1.17)  DPFE </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(\\{a,b,c\\}) &= \\min\\{C(a|\\{a,b,c\\})+f(\\{b,c\\}), C(b|\\{a,b,c\\})+f(\\{a,c\\}), C(c|\\{a,b,c\\})+f(\\{a,b\\})\\}\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(b|\\{b,c\\}+f(\\{c\\}),C(c|\\{b,c\\}+f(\\{b\\})\\}\n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(a|\\{a,c\\}+f(\\{c\\}),C(c|\\{a,c\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(a|\\{a,b\\}+f(\\{b\\}),C(c|\\{a,b\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(c|\\{c\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(b|\\{b\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(a|\\{a\\})+f(\\emptyset)\\} \n\\\\\\\\ f(\\emptyset) &= 0 \\end{aligned}</script><p> S  W </p>\n<p> (1.18)  DPFE </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(\\{a,b,c\\}) &= 0\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(a|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0 \n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(b|\\{a,a,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(c|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(a|\\{a,c\\})+f(\\{a,c\\}), C(b|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.5+1.0,0.8+1.0\\}=1.5\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(a|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.8+1.0\\}=1.7\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(b|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{a,c\\})+f(\\{a,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.5+1.0\\}=1.5\n\\\\\\\\ f(\\emptyset) &= \\min \\{C(a|a)+f(\\{a\\}), C(b|b)+f(\\{b\\}), C(c|c)+f(\\{c\\})\\}\\stackrel W = \\min \\{0.2+1.5,0.5+1.7,0.3+1.5\\}=1.7 \\end{aligned}</script><p> $\\stackrel W=$  W  S </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 1 2  S DPFE  (1.17) </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_{x \\in S} \\{C(x|k,S)+f(k+1,S-\\{x\\})\\} \\quad(1.19)</script><h3 id=\"Path-States\"><a href=\"#Path-States\" class=\"headerlink\" title=\"Path-States\"></a>Path-States</h3><p> S  $(d_1,,d_{i-1})$ S  $\\emptyset$  S  $(d_1,,d_{i-1})$ S  S={a,b} a  b a  b a  b  Path-States S=(a,b) a  b DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min_{x \\notin S} \\{C(x|S)+f(S + (x))\\} \\qquad(1.20)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(\\emptyset) &= \\min \\{C(a|\\emptyset)+f(a),C(b|\\emptyset)+f(b),C(c|\\emptyset)+f(c)\\}\\stackrel S= \\min\\{0.2+1.9,0.5+1.2,0.3+1.6\\}=1.7\n\\\\\\\\ f(a) &= \\min \\{C(b|a)+f(ab), C(c|a)+f(ac)\\}\\stackrel S= \\min\\{2*0.5+0.9,2*0.3+1.5\\}=1.9\n\\\\\\\\ f(b) &= \\min \\{C(a|b)+f(ba), C(c|b)+f(bc)\\}\\stackrel S= \\min\\{2*0.2+0.9,2*0.3+0.6\\}=1.2\n\\\\\\\\ f(c) &= \\min \\{C(a|c)+f(ca), C(b|c)+f(cb)\\}\\stackrel S= \\min\\{2*0.2+1.5,2*0.5+0.6\\}=1.6\n\\\\\\\\ f(ab) &= \\min \\{C(c|ab)+f(abc)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(ac) &= \\min \\{C(b|ac)+f(acb)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(ba) &= \\min \\{C(c|ba)+f(bac)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(bc) &= \\min \\{C(a|bc)+f(bca)\\}\\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(ca) &= \\min \\{C(b|ca)+f(cab)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(cb) &= \\min \\{C(a|cb)+f(cba)\\} \\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(abc) &= f(acb)=f(bac)=f(bca)=f(cab)=f(cba)=0 \\end{aligned}</script><p> $N!$  S  W  S $C(c|ab)$  c S  $C(c|ab)=3p_c=3*0.3=0.9$ $\\stackrel S=$  S  W </p>\n<h3 id=\"-Relaxation\"><a href=\"#-Relaxation\" class=\"headerlink\" title=\" Relaxation\"></a> Relaxation</h3><p> $\\{a_1,,a_N\\}$</p>\n<script type=\"math/tex; mode=display\">x^{\\ast}=\\min\\{\\min\\{...\\{\\min\\{a_1,a_2\\},a_3\\},...\\},a_N\\}</script><p> $x_1=a_1, x_2=\\min\\{x_1,a_2\\},$ $x_1=\\min\\{x_0,a_1\\}, x_0=\\infty$ $x_1,x_2,$  $x^{\\ast}$ DPFE </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(S)&=\\min_{x \\in S} \\{C(x|S)+f(S_x')\\}\n\\\\\\\\ &=\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}'),...,C(x_m|S)+f(S_{x_m}')\\} \\end{aligned}</script><p> $S=\\{x_1,x_2,,x_m\\}$$S_x$  x  $C(x|S)+f(S_x)$ </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min\\{\\min\\{...\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}')\\},...\\},C(x_m|S)+f(S_{x_m}')\\} \\quad (1.21)</script><p> $C(x_i|S)$  S $f(S_{x_i})$ </p>\n<p> DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_x \\{C(x|k,S) + f(k-1,S_x')\\} \\qquad(1.22)</script><p> k  k  S  k  T (1.22) $f(0,S),f(1,S),$  $f(S)$ $f(S)$ $f(S)=\\min_k \\{f(k,S)\\}$ $f(k,S)$  $f(k-1,S)$  $f(k-1,S_x)$  $f(k,S)$  $F(k,S)$ </p>\n<script type=\"math/tex; mode=display\">F(k,S)=\\min\\{F(k-1,S), \\min_x \\{C(x|k,S)+F(k-1,S_x')\\}\\} \\quad(1.23)</script><p> $F(k,S)$  S  T  k  (1.22)  k  </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p> s  t  DPFE </p>\n<script type=\"math/tex; mode=display\">f(p)=\\min_q \\{b(p,q)+f(q)\\} \\qquad(1.24)</script><p> b(p,q)  p  q q  p f(p)  p  t  f(t)=0 q  p  $b(p,q)=\\infty$ f(p)  f(q)</p>\n<p>p  q f(p)  f(q)  p  p </p>\n<ol>\n<li>b(p,p) &gt; 0</li>\n<li>b(p,p) &lt; 0</li>\n<li>b(p,p) = 0</li>\n</ol>\n<p>DPFE </p>\n<script type=\"math/tex; mode=display\">f(p) = \\min_q \\{b(p,q)+f(q)\\} \\qquad(1.25)</script><p> f(q)  f(p) $f(p)=\\infty, \\forall p \\ne t; \\ f(t)=0$ (1.25)  (1.24) </p>\n<p> 1.2<br><img src=\"/images/DP1_fig1.png\" alt=\"\"></p>\n<p> (1.25) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{b(s,x)+f(x),b(s,y)+f(y),b(s,t)+f(t)\\}=\\min \\{3+f(x),5+f(y),\\infty+f(t)\\}\n\\\\\\\\f(x)&=\\min \\{b(x,y)+f(y),b(x,t)+f(t)\\}=\\min \\{1+f(y),8+f(t)\\}\n\\\\\\\\f(y)&=\\min \\{b(y,x)+f(x),b(y,t)+f(t)\\}=\\min \\{2+f(x),5+f(t)\\}\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p> f(x)  f(y) </p>\n<p> $f(s)=f(x)=f(y)=\\infty$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{3+\\infty,5+\\infty,\\infty+f(t)\\}=\\infty\n\\\\\\\\f(x)&=\\min \\{1+\\infty,8+0\\}=8\n\\\\\\\\f(y)&=\\min \\{2+\\infty,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{3+8,5+5,\\infty+0\\}=10\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+8,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{3+6,5+5,\\infty+0\\}=9\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+6,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p> $f(x),f(y),f(t)$  f(s)  f(s)</p>\n<p> Relaxation  (1.22) DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,p)=\\min_q \\{b(p,q)+f(k-1,q)\\} \\qquad(1.26)</script><p> f(k,p)  p  t k  p  t  k  $f(0,t)=0;f(k,t)=\\infty, k&gt;0;f(0,p)=\\infty, \\forall p \\ne t$ t  t  0  0 0  $\\infty$ t p  t  0  $\\infty$ p  (1.26) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(k,s)&=\\min \\{b(s,x)+f(k-1,x),b(s,y)+f(k-1,y),b(s,t)+f(k-1,t)\\}\n\\\\\\\\f(k,x)&=\\min \\{b(x,y)+f(k-1,y),b(x,t)+f(k-1,t)\\}\n\\\\\\\\f(k,y)&=\\min \\{b(y,x)+f(k-1,x),b(y,t)+f(k-1,t)\\}\n\\\\\\\\f(k,t) \\end{aligned}</script><p> k=0 </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(1,s)&=\\min \\{3+f(0,x),5+f(0,y),\\infty+f(0,t)\\}=\\infty\n\\\\\\\\f(1,x)&=\\min \\{1+f(0,y),8+f(0,t)\\}=8\n\\\\\\\\f(1,y)&=\\min \\{2+f(0,x),5+f(0,t)\\}=5\n\\\\\\\\f(1,t)&=\\infty \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(2,s)&=\\min \\{3+f(1,x),5+f(1,y),\\infty+f(1,t)\\}=10\n\\\\\\\\f(2,x)&=\\min \\{1+f(1,y),8+f(1,t)\\}=6\n\\\\\\\\f(2,y)&=\\min \\{2+f(1,x),5+f(1,t)\\}=10\n\\\\\\\\f(2,t)&=\\infty \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(3,s)&=\\min \\{3+f(2,x),5+f(2,y),\\infty+f(2,t)\\}=9\n\\\\\\\\f(3,x)&=\\min \\{1+f(2,y),8+f(2,t)\\}=11\n\\\\\\\\f(3,y)&=\\min \\{2+f(1,x),5+f(2,t)\\}=8\n\\\\\\\\f(3,t)&=\\infty \\end{aligned}</script><p> N  p  t  k k  {0,1,,N-1}k  N circle 0 N=4 k  3 f  $f(p)=\\min_k \\{f(k,p)\\}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{\\infty,\\infty,10,9\\}=9\n\\\\\\\\f(x)&=\\min \\{\\infty,8,6,11\\}=6\n\\\\\\\\f(y)&=\\min \\{\\infty,5,10,8\\}=5\n\\\\\\\\f(t)&=\\min \\{0,\\infty,\\infty,\\infty\\}=0 \\end{aligned}</script><p> (1.22)  $f(k,S)$ </p>\n<p> $f(k,S)$  (1.23)  DPFE</p>\n<script type=\"math/tex; mode=display\">F(k,p)=\\min \\{F(k-1,p), \\ \\min_q \\{b(p,q)+F(k-1,q)\\}\\} \\qquad(1.27)</script><p> $F(k,p)$  p  t  k  p  t  $N-1$  $F(N-1,s)$k  $N-1$ $F(k,t)=0,k\\ge 0; F(0,p)=\\infty, p \\ne t$</p>\n<p> DPFE</p>\n","site":{"data":{}},"excerpt":"<p> Dynamic Programming  A Computational Tool</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> / <code></code><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><blockquote>\n<p></p>\n</blockquote>\n<p><del></del></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$opt_{d \\in \\Delta} \\{H(d)\\}$ d  $\\Delta$H H(d)  $d^{\\ast}$$d^{\\ast}=\\arg opt_d \\{H(d)\\}$ $\\{d_1,,d_n\\}$ $h(d_1,,h_n)$  $H^{\\ast}$</p>\n<p> $\\{d_1,,d_n\\}$    $d_1,,d_n$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2}\\{...\\{opt_{d_n \\in D_n}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.1)\\end{aligned}</script><p> $(d_1,,d_n) \\in \\Delta=D_1 \\times  \\times D_n$ i $d_i \\in D_i(d_1,,d_{i-1})$ (1.1) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}H^{\\ast}&=opt_{(d_1,...,d_n)\\in \\Delta} \\{h(d_1,...,d_n)\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.2)\\end{aligned}</script><p> (1.2)  $d_n$ $d_n^{\\ast}(d_1,,d_{n-1})$ $d_n^{\\ast}$  $opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast},,d_n^{\\ast} \\}$  $d_1^{\\ast}$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} &opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)} \\{... \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})} \\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_n \\in D_n} \\{opt_{d_{n-1} \\in D_{n-1}(d_n)} \\{... \\{opt_{d_1 \\in D_n(d_2,...,d_n)} \\{h(d_1,...,d_n)\\}\\}...\\}\\} \\quad(1.3) \\end{aligned}</script><p> $D_i$  $D_i$  $(d_{i+1},,d_n)$</p>\n<p> (1.2) $d_1$ $d_1$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}H^{\\ast}&=opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ &=opt_{d_1 \\in D_1}\\{h(d_1,d_2^{\\ast}(d_1),...,d_n^{\\ast}(d_1)\\} \\qquad \\qquad(1.4) \\end{aligned}</script><p> $d_i^{\\ast}(d_1), \\ i&gt;1$  $d_1$ partial function $d_1^{\\ast}=\\arg opt_{d_1 \\in D_1} \\{h(d_1,d_2^{\\ast}(d_1),,d_n^{\\ast}(d_1))\\}$$d_1$ </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> $d_1$  $d_2,,d_n$  $opt_{d_1 \\in D_1}\\{H(d_1)\\}$  $d_1$  $opt_{d_1}\\{H(d_1)\\}$  $H^{\\ast}$  h </p>\n<script type=\"math/tex; mode=display\">h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_2) \\circ ... \\circ C_n(d_n) \\qquad (1.5)</script><p> $C_i$  $d_i$ $\\circ$     </p>\n<script type=\"math/tex; mode=display\">opt_d\\{a \\circ C(d)\\}=a \\circ opt_d\\{C(d)\\}</script><p> a  d $C_n$  $d_n$ $(d_1,d_2,,d_{n-1})$</p>\n<script type=\"math/tex; mode=display\">h(d_1,...,d_n)=C_1(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\qquad(1.6)</script><p> h </p>\n<script type=\"math/tex; mode=display\">h(d_1,...,d_n)=C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n) \\qquad(1.7)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{h(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{opt_{d_2 \\in D_2(d_1)}\\{...\\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_1(d_1) \\circ C_2(d_1,d_2) \\circ ... \\circ C_n(d_1,...,d_n)\\}\\}...\\}\\}\n\\\\\\\\ = \\ & opt_{d_1 \\in D_1} \\{C_1(d_1|\\emptyset) \\circ opt_{d_2 \\in D_2(d_1)}\\{C_2(d_1,d_2) \\circ ... \\circ \\{opt_{d_n \\in D_n(d_1,...,d_{n-1})}\\{C_n(d_1,...,d_n)\\}...\\}\\} \\qquad(1.8) \\end{aligned}</script><p> $\\circ$ </p>\n<p> $f(d_1,,d_n)$  $d_1,,d_{i-1}$ </p>\n<script type=\"math/tex; mode=display\">f(d_1,...,d_{i-1})=opt_{d_i}\\{opt_{d_{i+1}}\\{... \\{opt_{d_n} \\{C_i(d_i|d_1,...,d_{i-1}) \\circ C_{i+1}(d_{i+1}|d_1,...,d_i) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1}) \\}\\}...\\}\\} \\ (1.9)</script><p> $D_i$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(\\emptyset)&=opt_{d_1}\\{opt_{d_2}\\{...\\{opt_{d_n}\\{C(d_1|\\emptyset) \\circ C_2(d_2|d_1) \\circ ... \\circ C_n(d_n|d_1,...,d_{n-1})\\}\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ opt_{d_2}\\{C(d_2|d_1) \\circ...\\circ opt_{d_n}\\{C_n(d_n|d_1,...,d_{n-1})\\}...\\}\\}\n\\\\\\\\ &opt_{d_1}\\{C_1(d_1|\\emptyset) \\circ f(d_1)\\}  \\qquad \\quad (1.10) \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">f(d_1,...,d_{i-1})=opt_{d_i \\in D_i(d_1,...,d_{i-1})}\\{C_i(d_i|d_1,...,d_{i-1})\\circ f(d_1,...,d_i)\\} \\qquad(1.11)</script><p>DPFE</p>\n<h3 id=\"DPFE\"><a href=\"#DPFE\" class=\"headerlink\" title=\"DPFE\"></a>DPFE</h3><p> DPFE  $f(d_1,,d_{i-1})$ $S=(d_1,,d_{i-1})$ $i=|S|+1=|\\{d_1,,d_{i-1}\\}|+1$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=opt_{d_i \\in D_i(S)}\\{C_i(d_i|S) \\circ f(S')\\} \\qquad (1.12)</script><p> $S=(d_1,,d_i)$ $\\emptyset$  $\\mathcal S$ DPFE  $f(S_0)=b, \\ S_0 \\in \\mathcal S_{base}$ $S_0$$f(S_0)$  DPFE  b</p>\n<p> n  S  d  D(S)  S  d  $d \\in S$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=opt_{d \\in S} \\{C(d|S) \\circ f(S')\\} \\qquad (1.13)</script><p> S  d  S  SD(S)  S  DPFE  b(S,S) d  C(d|S) $S=T(S,d), \\ T: \\mathcal S \\times D \\rightarrow \\mathcal S$T  DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=opt_S\\{b(S,S') \\circ f(S')\\} \\qquad(1.14)</script><p>DPFE </p>\n<script type=\"math/tex; mode=display\">f'(S)=opt_{S'}\\{f'(S') \\circ b(S',S)\\} \\qquad(1.15)</script><p> f(S)  $S_0$  S  f(S)  S  $S_0$  (1.14) backward (1.15) forward</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">f(S)=opt_{d \\in D(S)} \\{R(S,d) \\circ f(T(S,d))\\}  \\quad (1.16)</script><p>S  $\\mathcal S$ d  D(S) R(S,d)  C(d|S)T(S,d) $\\circ$ </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> N  A  x  $p_x$ A={a,b,c} $p_a=0.2,p_b=0.5,p_c=0.3$ 6  abc,acb,bac,bca,cab,cba bca  1.7</p>\n<ol>\n<li>Strong separable S<br>$1p_b+2p_c+3p_a$</li>\n<li>Weak separable W<br>$(p_a+p_b+p_c)+(p_a+p_c)+(p_a)$</li>\n</ol>\n<p> A  A  S  x  $ip_x$ i  x  A  W  A  bca  {a,b,c} b  A  {a,c}  $\\sum_{x\\in D_i} p_x$</p>\n<p> i=1,2,3 $D_1=A,D_2=A-\\{d_1\\},D_3=A-\\{d_1,d_2\\}$ S  $h(d_1,d_2,d_3)=1p_{d_1}+2p_{d_2}+3p_{d_3}$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{1p_{d_1}+2p_{d_2}+3p_{d_3}\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{1p_{d_1}+\\min_{d_2 \\in A-\\{d_1\\}}\\{2p_{d_2}+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{3p_{d_3}\\}\\}\\} \\end{aligned}</script><p> W  $h(d_1,d_2,d_3)=\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(\\emptyset)&=\\min_{d_1\\in A}\\{\\min_{d_2\\in A-\\{d_1\\}}\\{\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A}p_x+\\sum_{x\\in A-\\{d_1\\}}p_x+\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\}\n\\\\\\\\ &=\\min_{d_1\\in A}\\{\\sum_{x \\in A}p_x+\\min_{d_2 \\in A-\\{d_1\\}}\\{\\sum_{x\\in A-\\{d_1\\}}p_x+\\min_{d_3\\in A-\\{d_1,d_2\\}}\\{\\sum_{x \\in A-\\{d_1,d_2\\}}p_x\\}\\}\\} \\end{aligned}</script><p><strong></strong> bca </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> DP  S  A DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min_{x \\in S} \\{C(x|S)+f(S-\\{x\\})\\}     \\quad(1.17)</script><p> $S \\in 2^A$$2^A$  A  $f(\\emptyset)=0$ $f(A)$</p>\n<p> DPFE DPFE (1.15) </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min_{S'} \\{C(x|S')+f(S')\\}     \\quad(1.18)</script><p> $S \\in 2^A$ $f(\\emptyset)$ $f(A)=0$S  S  S  x  S</p>\n<p> W</p>\n<script type=\"math/tex; mode=display\">C_W(x|S)=\\sum_{y\\in S}p_y</script><p> x  S  S </p>\n<p> S</p>\n<script type=\"math/tex; mode=display\">C_S(x|S)=(N+1-|S|)p_x</script><p> x  A  A  A  $C_S(x|S)=|S|p_x$ S  $C(x|S)+f(S-\\{x\\})$ DP </p>\n<p> DP  (1.17)  DPFE </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(\\{a,b,c\\}) &= \\min\\{C(a|\\{a,b,c\\})+f(\\{b,c\\}), C(b|\\{a,b,c\\})+f(\\{a,c\\}), C(c|\\{a,b,c\\})+f(\\{a,b\\})\\}\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(b|\\{b,c\\}+f(\\{c\\}),C(c|\\{b,c\\}+f(\\{b\\})\\}\n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(a|\\{a,c\\}+f(\\{c\\}),C(c|\\{a,c\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(a|\\{a,b\\}+f(\\{b\\}),C(c|\\{a,b\\}+f(\\{a\\})\\}\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(c|\\{c\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(b|\\{b\\})+f(\\emptyset)\\}\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(a|\\{a\\})+f(\\emptyset)\\} \n\\\\\\\\ f(\\emptyset) &= 0 \\end{aligned}</script><p> S  W </p>\n<p> (1.18)  DPFE </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(\\{a,b,c\\}) &= 0\n\\\\\\\\ f(\\{b,c\\}) &= \\min\\{C(a|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0 \n\\\\\\\\ f(\\{a,c\\}) &= \\min\\{C(b|\\{a,a,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{a,b\\}) &= \\min\\{C(c|\\{a,b,c\\}+f(\\{a,b,c\\})\\}\\stackrel W=\\min \\{1.0+0\\}=1.0\n\\\\\\\\ f(\\{c\\}) &= \\min \\{C(a|\\{a,c\\})+f(\\{a,c\\}), C(b|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.5+1.0,0.8+1.0\\}=1.5\n\\\\\\\\ f(\\{b\\}) &= \\min \\{C(a|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{b,c\\})+f(\\{b,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.8+1.0\\}=1.7\n\\\\\\\\ f(\\{a\\}) &= \\min \\{C(b|\\{a,b\\})+f(\\{a,b\\}), C(c|\\{a,c\\})+f(\\{a,c\\})\\}\\stackrel W = \\min \\{0.7+1.0,0.5+1.0\\}=1.5\n\\\\\\\\ f(\\emptyset) &= \\min \\{C(a|a)+f(\\{a\\}), C(b|b)+f(\\{b\\}), C(c|c)+f(\\{c\\})\\}\\stackrel W = \\min \\{0.2+1.5,0.5+1.7,0.3+1.5\\}=1.7 \\end{aligned}</script><p> $\\stackrel W=$  W  S </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 1 2  S DPFE  (1.17) </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_{x \\in S} \\{C(x|k,S)+f(k+1,S-\\{x\\})\\} \\quad(1.19)</script><h3 id=\"Path-States\"><a href=\"#Path-States\" class=\"headerlink\" title=\"Path-States\"></a>Path-States</h3><p> S  $(d_1,,d_{i-1})$ S  $\\emptyset$  S  $(d_1,,d_{i-1})$ S  S={a,b} a  b a  b a  b  Path-States S=(a,b) a  b DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min_{x \\notin S} \\{C(x|S)+f(S + (x))\\} \\qquad(1.20)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(\\emptyset) &= \\min \\{C(a|\\emptyset)+f(a),C(b|\\emptyset)+f(b),C(c|\\emptyset)+f(c)\\}\\stackrel S= \\min\\{0.2+1.9,0.5+1.2,0.3+1.6\\}=1.7\n\\\\\\\\ f(a) &= \\min \\{C(b|a)+f(ab), C(c|a)+f(ac)\\}\\stackrel S= \\min\\{2*0.5+0.9,2*0.3+1.5\\}=1.9\n\\\\\\\\ f(b) &= \\min \\{C(a|b)+f(ba), C(c|b)+f(bc)\\}\\stackrel S= \\min\\{2*0.2+0.9,2*0.3+0.6\\}=1.2\n\\\\\\\\ f(c) &= \\min \\{C(a|c)+f(ca), C(b|c)+f(cb)\\}\\stackrel S= \\min\\{2*0.2+1.5,2*0.5+0.6\\}=1.6\n\\\\\\\\ f(ab) &= \\min \\{C(c|ab)+f(abc)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(ac) &= \\min \\{C(b|ac)+f(acb)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(ba) &= \\min \\{C(c|ba)+f(bac)\\}\\stackrel S= 3*0.3=0.9\n\\\\\\\\ f(bc) &= \\min \\{C(a|bc)+f(bca)\\}\\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(ca) &= \\min \\{C(b|ca)+f(cab)\\}\\stackrel S= 3*0.5=1.5\n\\\\\\\\ f(cb) &= \\min \\{C(a|cb)+f(cba)\\} \\stackrel S= 3*0.2=0.6\n\\\\\\\\ f(abc) &= f(acb)=f(bac)=f(bca)=f(cab)=f(cba)=0 \\end{aligned}</script><p> $N!$  S  W  S $C(c|ab)$  c S  $C(c|ab)=3p_c=3*0.3=0.9$ $\\stackrel S=$  S  W </p>\n<h3 id=\"-Relaxation\"><a href=\"#-Relaxation\" class=\"headerlink\" title=\" Relaxation\"></a> Relaxation</h3><p> $\\{a_1,,a_N\\}$</p>\n<script type=\"math/tex; mode=display\">x^{\\ast}=\\min\\{\\min\\{...\\{\\min\\{a_1,a_2\\},a_3\\},...\\},a_N\\}</script><p> $x_1=a_1, x_2=\\min\\{x_1,a_2\\},$ $x_1=\\min\\{x_0,a_1\\}, x_0=\\infty$ $x_1,x_2,$  $x^{\\ast}$ DPFE </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(S)&=\\min_{x \\in S} \\{C(x|S)+f(S_x')\\}\n\\\\\\\\ &=\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}'),...,C(x_m|S)+f(S_{x_m}')\\} \\end{aligned}</script><p> $S=\\{x_1,x_2,,x_m\\}$$S_x$  x  $C(x|S)+f(S_x)$ </p>\n<script type=\"math/tex; mode=display\">f(S)=\\min\\{\\min\\{...\\min\\{C(x_1|S)+f(S_{x_1}'), C(x_2|S)+f(S_{x_2}')\\},...\\},C(x_m|S)+f(S_{x_m}')\\} \\quad (1.21)</script><p> $C(x_i|S)$  S $f(S_{x_i})$ </p>\n<p> DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_x \\{C(x|k,S) + f(k-1,S_x')\\} \\qquad(1.22)</script><p> k  k  S  k  T (1.22) $f(0,S),f(1,S),$  $f(S)$ $f(S)$ $f(S)=\\min_k \\{f(k,S)\\}$ $f(k,S)$  $f(k-1,S)$  $f(k-1,S_x)$  $f(k,S)$  $F(k,S)$ </p>\n<script type=\"math/tex; mode=display\">F(k,S)=\\min\\{F(k-1,S), \\min_x \\{C(x|k,S)+F(k-1,S_x')\\}\\} \\quad(1.23)</script><p> $F(k,S)$  S  T  k  (1.22)  k  </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p> s  t  DPFE </p>\n<script type=\"math/tex; mode=display\">f(p)=\\min_q \\{b(p,q)+f(q)\\} \\qquad(1.24)</script><p> b(p,q)  p  q q  p f(p)  p  t  f(t)=0 q  p  $b(p,q)=\\infty$ f(p)  f(q)</p>\n<p>p  q f(p)  f(q)  p  p </p>\n<ol>\n<li>b(p,p) &gt; 0</li>\n<li>b(p,p) &lt; 0</li>\n<li>b(p,p) = 0</li>\n</ol>\n<p>DPFE </p>\n<script type=\"math/tex; mode=display\">f(p) = \\min_q \\{b(p,q)+f(q)\\} \\qquad(1.25)</script><p> f(q)  f(p) $f(p)=\\infty, \\forall p \\ne t; \\ f(t)=0$ (1.25)  (1.24) </p>\n<p> 1.2<br><img src=\"/images/DP1_fig1.png\" alt=\"\"></p>\n<p> (1.25) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{b(s,x)+f(x),b(s,y)+f(y),b(s,t)+f(t)\\}=\\min \\{3+f(x),5+f(y),\\infty+f(t)\\}\n\\\\\\\\f(x)&=\\min \\{b(x,y)+f(y),b(x,t)+f(t)\\}=\\min \\{1+f(y),8+f(t)\\}\n\\\\\\\\f(y)&=\\min \\{b(y,x)+f(x),b(y,t)+f(t)\\}=\\min \\{2+f(x),5+f(t)\\}\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p> f(x)  f(y) </p>\n<p> $f(s)=f(x)=f(y)=\\infty$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{3+\\infty,5+\\infty,\\infty+f(t)\\}=\\infty\n\\\\\\\\f(x)&=\\min \\{1+\\infty,8+0\\}=8\n\\\\\\\\f(y)&=\\min \\{2+\\infty,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{3+8,5+5,\\infty+0\\}=10\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+8,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{3+6,5+5,\\infty+0\\}=9\n\\\\\\\\f(x)&=\\min \\{1+5,8+0\\}=6\n\\\\\\\\f(y)&=\\min \\{2+6,5+0\\}=5\n\\\\\\\\f(t)&=0 \\end{aligned}</script><p> $f(x),f(y),f(t)$  f(s)  f(s)</p>\n<p> Relaxation  (1.22) DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,p)=\\min_q \\{b(p,q)+f(k-1,q)\\} \\qquad(1.26)</script><p> f(k,p)  p  t k  p  t  k  $f(0,t)=0;f(k,t)=\\infty, k&gt;0;f(0,p)=\\infty, \\forall p \\ne t$ t  t  0  0 0  $\\infty$ t p  t  0  $\\infty$ p  (1.26) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(k,s)&=\\min \\{b(s,x)+f(k-1,x),b(s,y)+f(k-1,y),b(s,t)+f(k-1,t)\\}\n\\\\\\\\f(k,x)&=\\min \\{b(x,y)+f(k-1,y),b(x,t)+f(k-1,t)\\}\n\\\\\\\\f(k,y)&=\\min \\{b(y,x)+f(k-1,x),b(y,t)+f(k-1,t)\\}\n\\\\\\\\f(k,t) \\end{aligned}</script><p> k=0 </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(1,s)&=\\min \\{3+f(0,x),5+f(0,y),\\infty+f(0,t)\\}=\\infty\n\\\\\\\\f(1,x)&=\\min \\{1+f(0,y),8+f(0,t)\\}=8\n\\\\\\\\f(1,y)&=\\min \\{2+f(0,x),5+f(0,t)\\}=5\n\\\\\\\\f(1,t)&=\\infty \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(2,s)&=\\min \\{3+f(1,x),5+f(1,y),\\infty+f(1,t)\\}=10\n\\\\\\\\f(2,x)&=\\min \\{1+f(1,y),8+f(1,t)\\}=6\n\\\\\\\\f(2,y)&=\\min \\{2+f(1,x),5+f(1,t)\\}=10\n\\\\\\\\f(2,t)&=\\infty \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(3,s)&=\\min \\{3+f(2,x),5+f(2,y),\\infty+f(2,t)\\}=9\n\\\\\\\\f(3,x)&=\\min \\{1+f(2,y),8+f(2,t)\\}=11\n\\\\\\\\f(3,y)&=\\min \\{2+f(1,x),5+f(2,t)\\}=8\n\\\\\\\\f(3,t)&=\\infty \\end{aligned}</script><p> N  p  t  k k  {0,1,,N-1}k  N circle 0 N=4 k  3 f  $f(p)=\\min_k \\{f(k,p)\\}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}f(s)&=\\min \\{\\infty,\\infty,10,9\\}=9\n\\\\\\\\f(x)&=\\min \\{\\infty,8,6,11\\}=6\n\\\\\\\\f(y)&=\\min \\{\\infty,5,10,8\\}=5\n\\\\\\\\f(t)&=\\min \\{0,\\infty,\\infty,\\infty\\}=0 \\end{aligned}</script><p> (1.22)  $f(k,S)$ </p>\n<p> $f(k,S)$  (1.23)  DPFE</p>\n<script type=\"math/tex; mode=display\">F(k,p)=\\min \\{F(k-1,p), \\ \\min_q \\{b(p,q)+F(k-1,q)\\}\\} \\qquad(1.27)</script><p> $F(k,p)$  p  t  k  p  t  $N-1$  $F(N-1,s)$k  $N-1$ $F(k,t)=0,k\\ge 0; F(0,p)=\\infty, p \\ne t$</p>\n<p> DPFE</p>"},{"title":"Dynamic Programming (2)","date":"2019-08-14T06:36:05.000Z","p":"dp/DP2","mathjax":true,"_content":" [Dynamic Programming (1)](2019/08/07/DP1)  DPFE\n\n##  ALLOT\n ALLOTALLOT  KSINT \n\n<!-- more -->\n\n M  N  C(k,d)  d  k  $d_1$  1 $d_2$  2 (k,m)  k  m  k  m k  C(k,d) (k+1,m-d) [Dynamic Programming (1)](2019/08/07/DP1)  (1.19)  DPFE \n$$f(k,m)=\\min_{d \\in \\{0,...,m\\}} \\{C(k,d)+f(k+1,m-d)\\} \\quad (2.1)$$\n f(1,M) f(N+1,m)=0 $m \\ge 0$\n\n M=4N=3\n$$(C_{k,d})_{k\\in \\{1,2,3\\};d\\in \\{0,...,4\\}}=\\begin{pmatrix}\\infty & 1.0 & 0.8& 0.4 & 0.0 \\\\\\\\ \\infty & 1.0& 0.5 & 0.0 & 0.0 \\\\\\\\ \\infty & 1.0 & 0.6 & 0.3 & 0.0 \\end{pmatrix}$$\nf(1,M)=1.0+0.5+1.0=2.5 $d_1=1,d_2=2,d_3=1$ (2.1) \n```python\ndef allot(cache=True):\n    M=4\n    N=3\n    max_float=1e8\n    cost=[[max_float, 1.0, 0.8, 0.4, 0.0],\n          [max_float, 1.0, 0.5, 0.0, 0.0],\n          [max_float, 1.0, 0.6, 0.3, 0.0]]\n    \n    if cache:\n        cache_dict = {}\n    def allot_inner(k,m):\n        if cache and (k,m) in cache_dict:\n            return cache_dict[(k,m)]\n        if k>= N: return [], 0\n\n        min_f=max_float\n        min_ds = []\n        for d in range(m+1):\n            ds,f=allot_inner(k+1,m-d)\n            temp=cost[k][d]+f\n            if min_f > temp:\n                min_f = temp\n                min_ds = [d]+ds\n        if cache and k > 1:\n            cache_dict[(k,m)]=(min_ds,min_f)\n        return min_ds, min_f\n    ds, f=allot_inner(0,M)\n    print(\"min cost:\",f,\"opt allotments:\", ds)\n```\n\n\n\n##  APSP\n\n s  t  Nself-loop\n\n [Dynamic Programming (1)](2019/08/07/DP1)  (s,t) \n\n__Relaxation__ \n\n F(k,p,q)  p  q k  p  q  k  [Dynamic Programming (1)](2019/08/07/DP1)  (1.27)DPFE \n$$F(k,p,q)=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\quad(2.2)$$\n r  p :\n1. $F(k,p,q)=0, k \\ge 0, p=q$ p  q  k  0\n2. $F(0,p,q)=\\infty, p \\ne q$  p  q  0 \n\n $b(p,p)=0$ (2.2) \n$$\\begin{aligned}F(k,p,q)&=\\min \\{F(k-1,p,q)+b(p,p), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\\\\\\\ &=\\min_{r \\in succ(p)\\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.3) \\end{aligned}$$\n\n\n__Floyd-Warshall__ \n\n (2.2)  DPFE  p  q  k  p  r  r  k-1  q  p  r  r  q p  r  1 p  q  k r  k  k  $\\{1,2,...,k\\}$ p  q  $\\{1,2,...,N\\}$  p  q DPFE \n$$F(k,p,q)=\\min \\{F(k-1,p,q), F(k-1,p,k)+F(k-1,k,q)\\} \\qquad(2.4)$$\n\n\n1.  N  $V=\\{1,2,...,N\\}$$p,q \\in V$\n2. $F(k,p,q)$  p  q  $\\{1,2,...,k\\}$ \n3.  $F(N,p,q)$\n4.  $(2.4)$\n   - p  q  k $\\{1,2,...,k-1\\}$ \n   -  p  q  k p  k  k  q $\\{1,2,...,k-1\\}$ \n5.  $(2.4)$  k>0k=0  $F(0,p,q)=0, p=q$ $F(0,p,q)=b(p,q), p\\ne q$ p q  0 p q  $b(p,q)$ q  p  $F(0,p,q)=\\infty, p \\notin succ(p) \\cup \\{p\\}$\n6.  $\\{1,2,...,k\\}$  p  q $b(p,p)=0$\n\n (2.2)  r  p  $N-1$  p  $N-1$k  $N-1$ p  q  N  (2.2)  $O(N^4)$ (2.4)  $O(N^3)$\n\n APSP  (2.2)  $\\{F^{(1)},F^{(2)},...,F^{(N-1)}\\}$ $F^{(k)}$  $N \\times N$$F_{p,q}^{k}$  p  q  k  $\\min_{p,q} F_{p,q}^{(N-1)}$  APSP \n\n____\n\n (2.2) \n$$\\begin{aligned} F(k,p,q)&=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\}\n\\\\\\\\ &= \\min_{r \\in succ(p)} \\{b(p,p)+F(k-1,p,q), b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in succ(p) \\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in \\{1,2,...,N\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.5) \\end{aligned}$$\n$b(p,r)$  edge  $\\infty$ $W_{N \\times N}$ (2.2)  $F^{(0)}$  0 $\\infty$\n\n$$F^{(0)}=\\begin{bmatrix}0 & \\infty & \\cdots & \\infty\n\\\\\\\\                    \\infty & 0  & \\cdots & \\infty\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    \\infty & \\infty & \\cdots & 0 \\end{bmatrix}_{N \\times N}$$\n\n$$W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}$$\n\n (2.5) $F^{(k-1)}$  $F^{(k)}$ \n```python\nimport sys\nF_k=[[None]*N]*N\nfor p in range(0,N):\n  for q in range(0,N):\n    F_k[p][q]=sys.info.float_max\n    # F_k[p][q]=0\n    for r in range(0,N):\n      F_k[p][q]=min(F_k[p][q],W[p][r]+F_k_1[r][q])\n      # F_k[p][q]=F_k[p][q]+W[p][r]*F_k_1[r][q])\n```\n $F^{(N-1)}$ $F^{(k)}$ \n$$\\begin{aligned} F^{(1)}&=W \\circ F^{(0)}=W\n\\\\\\\\ F^{(2)}&=W \\circ F^{(1)}=W^2\n\\\\\\\\ F^{(3)}&=W \\circ F^{(2)}=W^3\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{(N-1)}&=W \\circ F^{(N-2)}=W^{(N-1)} \\end{aligned} \\quad(2.6)$$\n\n$\\circ$ \n$$\\begin{aligned} F^{(1)}&=W\n\\\\\\\\ F^{(2)}&=W^2=W \\circ W\n\\\\\\\\ F^{(4)}&=W^4=W^2 \\circ W^2\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{2^{\\lceil log(N-1) \\rceil}}&=W^{2^{\\lceil log(N-1) \\rceil}} =W^{2^{\\lceil log(N-1) \\rceil-1}} \\circ W^{2^{\\lceil log(N-1) \\rceil-1}} \\end{aligned} \\quad(2.7)$$\n $2^{\\lceil log(N-1) \\rceil}$  $\\lceil \\cdot \\rceil$  $2^{\\lceil log(N-1) \\rceil} \\ge N-1$ $F^{2^{\\lceil log(N-1) \\rceil}} \\le F^{(N-1)}$ element-wise comparison\n\n (2.6)  (2.7)\n$$F^{(4)}=W \\circ F^{(3)}=W \\circ (W \\circ F^{(2)})=\\cdots =W \\circ(W \\circ (W \\circ W)) \\stackrel{*}=(W \\circ W) \\circ (W \\circ W)=W^2 \\circ W^2$$\n $\\circ$  $\\min$ $\\min (W, \\min(W, \\min(W,W)))=\\min(\\min(W,W), \\min(W,W))$ $\\min$  element-wise operator (2.6)  (2.7) \n\n (2.7)  $F^{(M)}, M \\ge N-1$ $F^{(k)}$  $F^{(N-1)}$ $F^{(M)}$ \n\n\n```python\nimport sys\n\ndef fast_apsp():\n  k=1\n  F_prev=W\n  while k<N-1:\n    F_next=[[sys.info.float_max]*N]*N\n    for p in range(0,N):\n      for q in range(0,N):\n        for r in range(0,N):\n          F_next[p][q]=min(F_next[p][q], F_prev[p][r]+F_prev[r][q])\n    F_prev=F_next\n    k*=2\n  return F_prev\n```\n\n__Floyd-Warshall__ \n\n (2.4) $F^{(k)}$  k  $\\{1,2,...,k\\}$ $F^{(0)}$ \n$$F^{(0)}=W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}$$\n\n (2.4) __Floyd-Warshall__ \n```python\nF_prev=F_0\ndef floyd_warshall():\n  for k in range(0,N):\n    F_next=[[None]*N]*N\n    for p in range(0,N):\n      for q in range(0,N):\n        F_next[p][q]=min(F_prev[p][q], F_prev[p][k]+F_prev[k][q])\n    F_prev=F_next\n  return F_prev\n```\n\n##  ARC\n\nARC *\n\nARCinternal nodes root $S=(w_0,w_1,...,w_{n-1})$  $(i,j)$  $(w_i,...,w_j)$\n$$f(i,j)=\\min_{}\\{c(i,j,d)+f(i,d)+f(d+1,j)\\}, \\quad i<j \\qquad(2.8)$$\n $f(i,j)$  $(i,...,j)$  $c(i,j,d)=\\sum_{k=i}^j w_k$  (2.8)d  $(i,...,d)$ $(d+1,...,j)$  d  $(i,...,j)$  $c(i,j,d)$ \n\n $f(0,n-1)$ $f(i,i)=0, \\ \\forall i \\in \\{0,1,...,n-1\\}$\n\n ARC  Huffman $S=(1,2,3,4)$ $(((1,2),3),4)$$f(S)=3+6+10=19$ $S=(2,3,3,4)$ $((2,3),(3,4))$$f(S)=5+7+12=24$\n\n  \n##  ASMBAL\n/ stage  k i  k+1  j  c(k,i,j) c(k,i,i)=0 0 s  t  0  c(0,0,j) c(N,j,0)j  \n\n 0~13  14  0  13  14 \n$$v=(0,7,8,9,5,3,6,4,8,5,4,7,0)$$\n\n![](/images/DP2_fig1.png)\n\n 14x14 \n\n k i  j  $R(k,i,j)=v(k,i)+c(k,i,j)$DPFE \n$$f(k,i)=\\min_j \\{R(k,i,j)+f(k+1,j)\\}$$\n $f(k,i)$  k  i  $f(0,0)$ $f(k,i)=0, k > N$N  N=6\n$$\\begin{aligned} f(0,0)=\\min \\{R(0,0,0)+f(1,0), R(0,0,1)+f(1,1)\\}\n\\\\\\\\ f(1,0)=\\min \\{R(1,0,0)+f(2,0), R(1,0,1)+f(2,1)\\}\n\\\\\\\\ f(1,1)=\\min \\{R(1,1,0)+f(2,0), R(1,1,1)+f(2,1)\\}\n\\\\\\\\ \\cdots \\ (omitted)\n\\end{aligned}$$\n\n##  ASSIGN\n B  A  A  A  $\\{1,2,3\\}$  $\\{3,2,1\\}$ 3!  $A=(a_0,a_1,...,a_{n-1})$  $B=(b_0,b_1,...,b_{n-1})$  i $a_j$  $b_i$ $c(i,j)$ A  $(k,S)$ k  A  S k  d $C(k,S,d)$ $(k+1,S-\\{d\\})$DPFE \n$$f(k,S)=\\min_{d \\in S} \\{C(k,S,d)+f(k+1,S-\\{d\\})\\}$$\n $f(1,S^{\\ast})$ $f(k,S)=0, \\ k=n+1 \\ or \\ S=\\emptyset$\n\n##  BST\n n  $X=\\{x_0,...,x_{n-1}\\}$ ____  $x_i$  $p(x_i)$ $p_i$ $\\sum_{i=0}^{n-1}p_i=1$\n$$\\sum_{i=0}^{n-1}(p_i \\text{level}(x_i))$$\n$\\text{level}(x_i)$  $x_i$  DP \n\n### \n S  DPFE \n$$f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & S \\ne \\emptyset\n\\\\\\\\ 0 & S=\\emptyset \\end{cases}$$\n $S_l = \\{x \\in S: x < \\alpha\\}, \\ S_r = \\{x \\in S: x > \\alpha\\}$ $r(\\alpha, S)=\\sum_{x \\in S} p(x)$ 1 DPFE \n\n $S_l,\\ S_r$  ____ \n\n\n$$f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & |S|>1\n\\\\\\\\ p(x) & S=\\{x\\} \\end{cases}$$\n\n### \n $(i,j)$ $X=\\{x_0,...,x_{n-1}\\}$ DPFE \n$$f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i \\le j\n\\\\\\\\ 0 & i > j \\end{cases}$$\n$(i,j)$  k  $(i,j)$, $(i,k-1)$ $(k+1,j)$  k$(i,j)$  level  level level  $f(i,j)$ $(i,j)$  level level  $\\sum_{l=i}^j p_l$\n\n\n$$f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i < j\n\\\\\\\\ p_i & i = j \\end{cases}$$\n\n##  COV\n k k  0  i  $c_i$ n  $n \\le k$ n \n\n DP  $0,1,...,k-1$ $l$  $s_l$ $c_{s_l}$ $c_l$ $j$ $l$  DPFE \n$$f(j,l)=\\begin{cases} \\min_{d \\in \\{j-2,...,l-1\\}} \\{(l-d)c_l+f(j-1,d)\\} & j>1\n\\\\\\\\ (l+1)c_l & j=1 \\end{cases}$$\nd exclusive $s_l$  $\\{d+1,...,l\\}$  d  $l-1$ $l$ d  $j-2$ $\\{j-1,...,l\\}$ $\\{0,1,...,j-2\\}$  $j-1$  $j-1$ \n\n$f(j,l)=(l+1)c_l, j=1$ $l$ $0,...,l$ \n\n##  DEADLINE\n 0 ____\n\n $S^{\\ast}=\\{0,1,2,3,4\\}$ $p=\\{10,15,20,1,5\\}$ $t=\\{1,2,2,3,3\\}$\n```python\nimport numpy as np\nt=np.array([1,2,2,3,3])\np=np.array([10,15,20,1,5])\nm=0   # \nn=t.shape[0]  # \n\nfor i in range(n):\n  idx=np.where(t>0)[0]\n  if idx.shape[0]==0:\n    break   # \n  c=np.max(p[idx])  # \n  if c < 0:\n    break\n  m+=c\n  idx=np.argmax(p[idx])+idx[0]  # \n  p[idx]=-1e8                   # \n  t-=1                          # \nprint('', sep=' ')\nprint(m)    # 40\n```\n\n DP  $(k,S)$ k S  d  S  $(k+1,S-\\{d\\})$DPFE \n$$f(k,S)=\\max_{d \\in S}\\{c(d|S)+f(k+1,S-\\{d\\})\\}$$\n d  k k  1 $c(d|S)=w_d$  $c(d|S)=0$ $f(1,S^{\\ast})$ $f(k,S)=0, k=n+1 \\ or \\ S=\\emptyset$ n \n```python\nt=[1,2,2,3,3]\np=[10,15,20,1,5]\nS=[0,1,2,3,4]\nn=len(t)\ndef profit(k,d):\n  return p[d] if t[d]>=k else 0\n\ndef deadline(k,S):\n  return 0 if len(S)==0 or k==n+1 else \\\n    max([profit(k,S[i])+deadline(k+1,S[:i]+S[i+1:]) for i in range(len(S))])\n\nprint(deadline(1, S))   # 40\n```\n\n##  DPP\n $b_1$  t  $b_t$ t  $x_t$  $r(x_t)$ $c(x_t,b_t)$ s s  $1,...,T$ T  y $x_t$   t  $(t,b)$ t b  t DPFE \n$$f(t,b)=\\begin{cases} \\max_{x_t \\in \\{0,...,b\\}} \\{r(x_t)-c(x_t,b)+\\frac 1 {1+y} f(t+1, \\lfloor s(b-x_t) \\rfloor)\\} & t \\le T\n\\\\\\\\ 0 & t=T+1 \\end{cases}$$\n\n\n##  EDP\n $\\Sigma$  $x\\in \\Sigma^m, \\ y \\in \\Sigma^n$ $x=x_1\\cdots x_m, \\ y=y_1 \\cdots y_n$ x  y\n-  D $c(D)$\n-  I $c(I)$\n-  R $c(R)$ $c(R)=0$\n  \n x  yDPFE \n$$f(i,j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min \\{f(i-1,j)+c(D),f(i,j-1)+c(I),f(i-1,j-1)+c(R)\\} & i>0,j>0 \\end{cases}$$\n $f(i,j)$  $X_i$  $Y_j$ $X_i$  x  i $Y_j$  y  j  i=0  $X_i$  j  $Y_j$ j=0  $X_i$  i  $Y_j$ i>0  j>0  $X_i$  $Y_j$/\n-  $X_i$  i  $X_{i-1}$  $Y_j$ $c(D)$  $f(i-1,j)$\n-  $X_i$  $Y_{j-1}$ $Y_j$ $f(i,j-1)$  $c(I)$\n- $x_i \\rightarrow y_j$ $X_{i-1}$  $Y_{j-1}$  $X_i$  $Y_j$  $f(i-1,j-1)$  $c(R)$\n\n DPFE\n$$f(X_i,Y_j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min_{d \\in \\{D,I,R\\}} \\{f(t(X_i,Y_j,d))+c(d)\\} & i>0,j>0\n\\end{cases}$$\n\n$$t(X_i,Y_j,D)=(X_{i-1},Y_j)\n\\\\\\\\ t(X_i,Y_j,I)=(X_i,Y_{j-1})\n\\\\\\\\ t(X_i,Y_j,R)=(X_{i-1},Y_{j-1})$$\n","source":"_posts/dp/DP2.md","raw":"---\ntitle: Dynamic Programming (2)\ndate: 2019-08-14 14:36:05\np: dp/DP2\ntags: \n    - math\n    - DP\nmathjax: true\n---\n [Dynamic Programming (1)](2019/08/07/DP1)  DPFE\n\n##  ALLOT\n ALLOTALLOT  KSINT \n\n<!-- more -->\n\n M  N  C(k,d)  d  k  $d_1$  1 $d_2$  2 (k,m)  k  m  k  m k  C(k,d) (k+1,m-d) [Dynamic Programming (1)](2019/08/07/DP1)  (1.19)  DPFE \n$$f(k,m)=\\min_{d \\in \\{0,...,m\\}} \\{C(k,d)+f(k+1,m-d)\\} \\quad (2.1)$$\n f(1,M) f(N+1,m)=0 $m \\ge 0$\n\n M=4N=3\n$$(C_{k,d})_{k\\in \\{1,2,3\\};d\\in \\{0,...,4\\}}=\\begin{pmatrix}\\infty & 1.0 & 0.8& 0.4 & 0.0 \\\\\\\\ \\infty & 1.0& 0.5 & 0.0 & 0.0 \\\\\\\\ \\infty & 1.0 & 0.6 & 0.3 & 0.0 \\end{pmatrix}$$\nf(1,M)=1.0+0.5+1.0=2.5 $d_1=1,d_2=2,d_3=1$ (2.1) \n```python\ndef allot(cache=True):\n    M=4\n    N=3\n    max_float=1e8\n    cost=[[max_float, 1.0, 0.8, 0.4, 0.0],\n          [max_float, 1.0, 0.5, 0.0, 0.0],\n          [max_float, 1.0, 0.6, 0.3, 0.0]]\n    \n    if cache:\n        cache_dict = {}\n    def allot_inner(k,m):\n        if cache and (k,m) in cache_dict:\n            return cache_dict[(k,m)]\n        if k>= N: return [], 0\n\n        min_f=max_float\n        min_ds = []\n        for d in range(m+1):\n            ds,f=allot_inner(k+1,m-d)\n            temp=cost[k][d]+f\n            if min_f > temp:\n                min_f = temp\n                min_ds = [d]+ds\n        if cache and k > 1:\n            cache_dict[(k,m)]=(min_ds,min_f)\n        return min_ds, min_f\n    ds, f=allot_inner(0,M)\n    print(\"min cost:\",f,\"opt allotments:\", ds)\n```\n\n\n\n##  APSP\n\n s  t  Nself-loop\n\n [Dynamic Programming (1)](2019/08/07/DP1)  (s,t) \n\n__Relaxation__ \n\n F(k,p,q)  p  q k  p  q  k  [Dynamic Programming (1)](2019/08/07/DP1)  (1.27)DPFE \n$$F(k,p,q)=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\quad(2.2)$$\n r  p :\n1. $F(k,p,q)=0, k \\ge 0, p=q$ p  q  k  0\n2. $F(0,p,q)=\\infty, p \\ne q$  p  q  0 \n\n $b(p,p)=0$ (2.2) \n$$\\begin{aligned}F(k,p,q)&=\\min \\{F(k-1,p,q)+b(p,p), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\\\\\\\ &=\\min_{r \\in succ(p)\\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.3) \\end{aligned}$$\n\n\n__Floyd-Warshall__ \n\n (2.2)  DPFE  p  q  k  p  r  r  k-1  q  p  r  r  q p  r  1 p  q  k r  k  k  $\\{1,2,...,k\\}$ p  q  $\\{1,2,...,N\\}$  p  q DPFE \n$$F(k,p,q)=\\min \\{F(k-1,p,q), F(k-1,p,k)+F(k-1,k,q)\\} \\qquad(2.4)$$\n\n\n1.  N  $V=\\{1,2,...,N\\}$$p,q \\in V$\n2. $F(k,p,q)$  p  q  $\\{1,2,...,k\\}$ \n3.  $F(N,p,q)$\n4.  $(2.4)$\n   - p  q  k $\\{1,2,...,k-1\\}$ \n   -  p  q  k p  k  k  q $\\{1,2,...,k-1\\}$ \n5.  $(2.4)$  k>0k=0  $F(0,p,q)=0, p=q$ $F(0,p,q)=b(p,q), p\\ne q$ p q  0 p q  $b(p,q)$ q  p  $F(0,p,q)=\\infty, p \\notin succ(p) \\cup \\{p\\}$\n6.  $\\{1,2,...,k\\}$  p  q $b(p,p)=0$\n\n (2.2)  r  p  $N-1$  p  $N-1$k  $N-1$ p  q  N  (2.2)  $O(N^4)$ (2.4)  $O(N^3)$\n\n APSP  (2.2)  $\\{F^{(1)},F^{(2)},...,F^{(N-1)}\\}$ $F^{(k)}$  $N \\times N$$F_{p,q}^{k}$  p  q  k  $\\min_{p,q} F_{p,q}^{(N-1)}$  APSP \n\n____\n\n (2.2) \n$$\\begin{aligned} F(k,p,q)&=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\}\n\\\\\\\\ &= \\min_{r \\in succ(p)} \\{b(p,p)+F(k-1,p,q), b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in succ(p) \\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in \\{1,2,...,N\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.5) \\end{aligned}$$\n$b(p,r)$  edge  $\\infty$ $W_{N \\times N}$ (2.2)  $F^{(0)}$  0 $\\infty$\n\n$$F^{(0)}=\\begin{bmatrix}0 & \\infty & \\cdots & \\infty\n\\\\\\\\                    \\infty & 0  & \\cdots & \\infty\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    \\infty & \\infty & \\cdots & 0 \\end{bmatrix}_{N \\times N}$$\n\n$$W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}$$\n\n (2.5) $F^{(k-1)}$  $F^{(k)}$ \n```python\nimport sys\nF_k=[[None]*N]*N\nfor p in range(0,N):\n  for q in range(0,N):\n    F_k[p][q]=sys.info.float_max\n    # F_k[p][q]=0\n    for r in range(0,N):\n      F_k[p][q]=min(F_k[p][q],W[p][r]+F_k_1[r][q])\n      # F_k[p][q]=F_k[p][q]+W[p][r]*F_k_1[r][q])\n```\n $F^{(N-1)}$ $F^{(k)}$ \n$$\\begin{aligned} F^{(1)}&=W \\circ F^{(0)}=W\n\\\\\\\\ F^{(2)}&=W \\circ F^{(1)}=W^2\n\\\\\\\\ F^{(3)}&=W \\circ F^{(2)}=W^3\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{(N-1)}&=W \\circ F^{(N-2)}=W^{(N-1)} \\end{aligned} \\quad(2.6)$$\n\n$\\circ$ \n$$\\begin{aligned} F^{(1)}&=W\n\\\\\\\\ F^{(2)}&=W^2=W \\circ W\n\\\\\\\\ F^{(4)}&=W^4=W^2 \\circ W^2\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{2^{\\lceil log(N-1) \\rceil}}&=W^{2^{\\lceil log(N-1) \\rceil}} =W^{2^{\\lceil log(N-1) \\rceil-1}} \\circ W^{2^{\\lceil log(N-1) \\rceil-1}} \\end{aligned} \\quad(2.7)$$\n $2^{\\lceil log(N-1) \\rceil}$  $\\lceil \\cdot \\rceil$  $2^{\\lceil log(N-1) \\rceil} \\ge N-1$ $F^{2^{\\lceil log(N-1) \\rceil}} \\le F^{(N-1)}$ element-wise comparison\n\n (2.6)  (2.7)\n$$F^{(4)}=W \\circ F^{(3)}=W \\circ (W \\circ F^{(2)})=\\cdots =W \\circ(W \\circ (W \\circ W)) \\stackrel{*}=(W \\circ W) \\circ (W \\circ W)=W^2 \\circ W^2$$\n $\\circ$  $\\min$ $\\min (W, \\min(W, \\min(W,W)))=\\min(\\min(W,W), \\min(W,W))$ $\\min$  element-wise operator (2.6)  (2.7) \n\n (2.7)  $F^{(M)}, M \\ge N-1$ $F^{(k)}$  $F^{(N-1)}$ $F^{(M)}$ \n\n\n```python\nimport sys\n\ndef fast_apsp():\n  k=1\n  F_prev=W\n  while k<N-1:\n    F_next=[[sys.info.float_max]*N]*N\n    for p in range(0,N):\n      for q in range(0,N):\n        for r in range(0,N):\n          F_next[p][q]=min(F_next[p][q], F_prev[p][r]+F_prev[r][q])\n    F_prev=F_next\n    k*=2\n  return F_prev\n```\n\n__Floyd-Warshall__ \n\n (2.4) $F^{(k)}$  k  $\\{1,2,...,k\\}$ $F^{(0)}$ \n$$F^{(0)}=W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}$$\n\n (2.4) __Floyd-Warshall__ \n```python\nF_prev=F_0\ndef floyd_warshall():\n  for k in range(0,N):\n    F_next=[[None]*N]*N\n    for p in range(0,N):\n      for q in range(0,N):\n        F_next[p][q]=min(F_prev[p][q], F_prev[p][k]+F_prev[k][q])\n    F_prev=F_next\n  return F_prev\n```\n\n##  ARC\n\nARC *\n\nARCinternal nodes root $S=(w_0,w_1,...,w_{n-1})$  $(i,j)$  $(w_i,...,w_j)$\n$$f(i,j)=\\min_{}\\{c(i,j,d)+f(i,d)+f(d+1,j)\\}, \\quad i<j \\qquad(2.8)$$\n $f(i,j)$  $(i,...,j)$  $c(i,j,d)=\\sum_{k=i}^j w_k$  (2.8)d  $(i,...,d)$ $(d+1,...,j)$  d  $(i,...,j)$  $c(i,j,d)$ \n\n $f(0,n-1)$ $f(i,i)=0, \\ \\forall i \\in \\{0,1,...,n-1\\}$\n\n ARC  Huffman $S=(1,2,3,4)$ $(((1,2),3),4)$$f(S)=3+6+10=19$ $S=(2,3,3,4)$ $((2,3),(3,4))$$f(S)=5+7+12=24$\n\n  \n##  ASMBAL\n/ stage  k i  k+1  j  c(k,i,j) c(k,i,i)=0 0 s  t  0  c(0,0,j) c(N,j,0)j  \n\n 0~13  14  0  13  14 \n$$v=(0,7,8,9,5,3,6,4,8,5,4,7,0)$$\n\n![](/images/DP2_fig1.png)\n\n 14x14 \n\n k i  j  $R(k,i,j)=v(k,i)+c(k,i,j)$DPFE \n$$f(k,i)=\\min_j \\{R(k,i,j)+f(k+1,j)\\}$$\n $f(k,i)$  k  i  $f(0,0)$ $f(k,i)=0, k > N$N  N=6\n$$\\begin{aligned} f(0,0)=\\min \\{R(0,0,0)+f(1,0), R(0,0,1)+f(1,1)\\}\n\\\\\\\\ f(1,0)=\\min \\{R(1,0,0)+f(2,0), R(1,0,1)+f(2,1)\\}\n\\\\\\\\ f(1,1)=\\min \\{R(1,1,0)+f(2,0), R(1,1,1)+f(2,1)\\}\n\\\\\\\\ \\cdots \\ (omitted)\n\\end{aligned}$$\n\n##  ASSIGN\n B  A  A  A  $\\{1,2,3\\}$  $\\{3,2,1\\}$ 3!  $A=(a_0,a_1,...,a_{n-1})$  $B=(b_0,b_1,...,b_{n-1})$  i $a_j$  $b_i$ $c(i,j)$ A  $(k,S)$ k  A  S k  d $C(k,S,d)$ $(k+1,S-\\{d\\})$DPFE \n$$f(k,S)=\\min_{d \\in S} \\{C(k,S,d)+f(k+1,S-\\{d\\})\\}$$\n $f(1,S^{\\ast})$ $f(k,S)=0, \\ k=n+1 \\ or \\ S=\\emptyset$\n\n##  BST\n n  $X=\\{x_0,...,x_{n-1}\\}$ ____  $x_i$  $p(x_i)$ $p_i$ $\\sum_{i=0}^{n-1}p_i=1$\n$$\\sum_{i=0}^{n-1}(p_i \\text{level}(x_i))$$\n$\\text{level}(x_i)$  $x_i$  DP \n\n### \n S  DPFE \n$$f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & S \\ne \\emptyset\n\\\\\\\\ 0 & S=\\emptyset \\end{cases}$$\n $S_l = \\{x \\in S: x < \\alpha\\}, \\ S_r = \\{x \\in S: x > \\alpha\\}$ $r(\\alpha, S)=\\sum_{x \\in S} p(x)$ 1 DPFE \n\n $S_l,\\ S_r$  ____ \n\n\n$$f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & |S|>1\n\\\\\\\\ p(x) & S=\\{x\\} \\end{cases}$$\n\n### \n $(i,j)$ $X=\\{x_0,...,x_{n-1}\\}$ DPFE \n$$f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i \\le j\n\\\\\\\\ 0 & i > j \\end{cases}$$\n$(i,j)$  k  $(i,j)$, $(i,k-1)$ $(k+1,j)$  k$(i,j)$  level  level level  $f(i,j)$ $(i,j)$  level level  $\\sum_{l=i}^j p_l$\n\n\n$$f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i < j\n\\\\\\\\ p_i & i = j \\end{cases}$$\n\n##  COV\n k k  0  i  $c_i$ n  $n \\le k$ n \n\n DP  $0,1,...,k-1$ $l$  $s_l$ $c_{s_l}$ $c_l$ $j$ $l$  DPFE \n$$f(j,l)=\\begin{cases} \\min_{d \\in \\{j-2,...,l-1\\}} \\{(l-d)c_l+f(j-1,d)\\} & j>1\n\\\\\\\\ (l+1)c_l & j=1 \\end{cases}$$\nd exclusive $s_l$  $\\{d+1,...,l\\}$  d  $l-1$ $l$ d  $j-2$ $\\{j-1,...,l\\}$ $\\{0,1,...,j-2\\}$  $j-1$  $j-1$ \n\n$f(j,l)=(l+1)c_l, j=1$ $l$ $0,...,l$ \n\n##  DEADLINE\n 0 ____\n\n $S^{\\ast}=\\{0,1,2,3,4\\}$ $p=\\{10,15,20,1,5\\}$ $t=\\{1,2,2,3,3\\}$\n```python\nimport numpy as np\nt=np.array([1,2,2,3,3])\np=np.array([10,15,20,1,5])\nm=0   # \nn=t.shape[0]  # \n\nfor i in range(n):\n  idx=np.where(t>0)[0]\n  if idx.shape[0]==0:\n    break   # \n  c=np.max(p[idx])  # \n  if c < 0:\n    break\n  m+=c\n  idx=np.argmax(p[idx])+idx[0]  # \n  p[idx]=-1e8                   # \n  t-=1                          # \nprint('', sep=' ')\nprint(m)    # 40\n```\n\n DP  $(k,S)$ k S  d  S  $(k+1,S-\\{d\\})$DPFE \n$$f(k,S)=\\max_{d \\in S}\\{c(d|S)+f(k+1,S-\\{d\\})\\}$$\n d  k k  1 $c(d|S)=w_d$  $c(d|S)=0$ $f(1,S^{\\ast})$ $f(k,S)=0, k=n+1 \\ or \\ S=\\emptyset$ n \n```python\nt=[1,2,2,3,3]\np=[10,15,20,1,5]\nS=[0,1,2,3,4]\nn=len(t)\ndef profit(k,d):\n  return p[d] if t[d]>=k else 0\n\ndef deadline(k,S):\n  return 0 if len(S)==0 or k==n+1 else \\\n    max([profit(k,S[i])+deadline(k+1,S[:i]+S[i+1:]) for i in range(len(S))])\n\nprint(deadline(1, S))   # 40\n```\n\n##  DPP\n $b_1$  t  $b_t$ t  $x_t$  $r(x_t)$ $c(x_t,b_t)$ s s  $1,...,T$ T  y $x_t$   t  $(t,b)$ t b  t DPFE \n$$f(t,b)=\\begin{cases} \\max_{x_t \\in \\{0,...,b\\}} \\{r(x_t)-c(x_t,b)+\\frac 1 {1+y} f(t+1, \\lfloor s(b-x_t) \\rfloor)\\} & t \\le T\n\\\\\\\\ 0 & t=T+1 \\end{cases}$$\n\n\n##  EDP\n $\\Sigma$  $x\\in \\Sigma^m, \\ y \\in \\Sigma^n$ $x=x_1\\cdots x_m, \\ y=y_1 \\cdots y_n$ x  y\n-  D $c(D)$\n-  I $c(I)$\n-  R $c(R)$ $c(R)=0$\n  \n x  yDPFE \n$$f(i,j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min \\{f(i-1,j)+c(D),f(i,j-1)+c(I),f(i-1,j-1)+c(R)\\} & i>0,j>0 \\end{cases}$$\n $f(i,j)$  $X_i$  $Y_j$ $X_i$  x  i $Y_j$  y  j  i=0  $X_i$  j  $Y_j$ j=0  $X_i$  i  $Y_j$ i>0  j>0  $X_i$  $Y_j$/\n-  $X_i$  i  $X_{i-1}$  $Y_j$ $c(D)$  $f(i-1,j)$\n-  $X_i$  $Y_{j-1}$ $Y_j$ $f(i,j-1)$  $c(I)$\n- $x_i \\rightarrow y_j$ $X_{i-1}$  $Y_{j-1}$  $X_i$  $Y_j$  $f(i-1,j-1)$  $c(R)$\n\n DPFE\n$$f(X_i,Y_j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min_{d \\in \\{D,I,R\\}} \\{f(t(X_i,Y_j,d))+c(d)\\} & i>0,j>0\n\\end{cases}$$\n\n$$t(X_i,Y_j,D)=(X_{i-1},Y_j)\n\\\\\\\\ t(X_i,Y_j,I)=(X_i,Y_{j-1})\n\\\\\\\\ t(X_i,Y_j,R)=(X_{i-1},Y_{j-1})$$\n","slug":"dp/DP2","published":1,"updated":"2020-04-24T10:31:14.130Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92c0055p0dj1yf8g9qt","content":"<p> <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  DPFE</p>\n<h2 id=\"-ALLOT\"><a href=\"#-ALLOT\" class=\"headerlink\" title=\" ALLOT\"></a> ALLOT</h2><p> ALLOTALLOT  KSINT </p>\n<span id=\"more\"></span>\n<p> M  N  C(k,d)  d  k  $d_1$  1 $d_2$  2 (k,m)  k  m  k  m k  C(k,d) (k+1,m-d) <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  (1.19)  DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,m)=\\min_{d \\in \\{0,...,m\\}} \\{C(k,d)+f(k+1,m-d)\\} \\quad (2.1)</script><p> f(1,M) f(N+1,m)=0 $m \\ge 0$</p>\n<p> M=4N=3</p>\n<script type=\"math/tex; mode=display\">(C_{k,d})_{k\\in \\{1,2,3\\};d\\in \\{0,...,4\\}}=\\begin{pmatrix}\\infty & 1.0 & 0.8& 0.4 & 0.0 \\\\\\\\ \\infty & 1.0& 0.5 & 0.0 & 0.0 \\\\\\\\ \\infty & 1.0 & 0.6 & 0.3 & 0.0 \\end{pmatrix}</script><p>f(1,M)=1.0+0.5+1.0=2.5 $d_1=1,d_2=2,d_3=1$ (2.1) <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">allot</span>(<span class=\"params\">cache=<span class=\"literal\">True</span></span>):</span></span><br><span class=\"line\">    M=<span class=\"number\">4</span></span><br><span class=\"line\">    N=<span class=\"number\">3</span></span><br><span class=\"line\">    max_float=<span class=\"number\">1e8</span></span><br><span class=\"line\">    cost=[[max_float, <span class=\"number\">1.0</span>, <span class=\"number\">0.8</span>, <span class=\"number\">0.4</span>, <span class=\"number\">0.0</span>],</span><br><span class=\"line\">          [max_float, <span class=\"number\">1.0</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>],</span><br><span class=\"line\">          [max_float, <span class=\"number\">1.0</span>, <span class=\"number\">0.6</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.0</span>]]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">if</span> cache:</span><br><span class=\"line\">        cache_dict = &#123;&#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">allot_inner</span>(<span class=\"params\">k,m</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> cache <span class=\"keyword\">and</span> (k,m) <span class=\"keyword\">in</span> cache_dict:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> cache_dict[(k,m)]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> k&gt;= N: <span class=\"keyword\">return</span> [], <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">        min_f=max_float</span><br><span class=\"line\">        min_ds = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(m+<span class=\"number\">1</span>):</span><br><span class=\"line\">            ds,f=allot_inner(k+<span class=\"number\">1</span>,m-d)</span><br><span class=\"line\">            temp=cost[k][d]+f</span><br><span class=\"line\">            <span class=\"keyword\">if</span> min_f &gt; temp:</span><br><span class=\"line\">                min_f = temp</span><br><span class=\"line\">                min_ds = [d]+ds</span><br><span class=\"line\">        <span class=\"keyword\">if</span> cache <span class=\"keyword\">and</span> k &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">            cache_dict[(k,m)]=(min_ds,min_f)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> min_ds, min_f</span><br><span class=\"line\">    ds, f=allot_inner(<span class=\"number\">0</span>,M)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;min cost:&quot;</span>,f,<span class=\"string\">&quot;opt allotments:&quot;</span>, ds)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-APSP\"><a href=\"#-APSP\" class=\"headerlink\" title=\" APSP\"></a> APSP</h2><p> s  t  Nself-loop</p>\n<p> <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  (s,t) </p>\n<p><strong>Relaxation</strong> </p>\n<p> F(k,p,q)  p  q k  p  q  k  <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  (1.27)DPFE </p>\n<script type=\"math/tex; mode=display\">F(k,p,q)=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\quad(2.2)</script><p> r  p :</p>\n<ol>\n<li>$F(k,p,q)=0, k \\ge 0, p=q$ p  q  k  0</li>\n<li>$F(0,p,q)=\\infty, p \\ne q$  p  q  0 </li>\n</ol>\n<p> $b(p,p)=0$ (2.2) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}F(k,p,q)&=\\min \\{F(k-1,p,q)+b(p,p), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\\\\\\\ &=\\min_{r \\in succ(p)\\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.3) \\end{aligned}</script><p><strong>Floyd-Warshall</strong> </p>\n<p> (2.2)  DPFE  p  q  k  p  r  r  k-1  q  p  r  r  q p  r  1 p  q  k r  k  k  $\\{1,2,,k\\}$ p  q  $\\{1,2,,N\\}$  p  q DPFE </p>\n<script type=\"math/tex; mode=display\">F(k,p,q)=\\min \\{F(k-1,p,q), F(k-1,p,k)+F(k-1,k,q)\\} \\qquad(2.4)</script><p></p>\n<ol>\n<li> N  $V=\\{1,2,,N\\}$$p,q \\in V$</li>\n<li>$F(k,p,q)$  p  q  $\\{1,2,,k\\}$ </li>\n<li> $F(N,p,q)$</li>\n<li> $(2.4)$<ul>\n<li>p  q  k $\\{1,2,,k-1\\}$ </li>\n<li> p  q  k p  k  k  q $\\{1,2,,k-1\\}$ </li>\n</ul>\n</li>\n<li> $(2.4)$  k&gt;0k=0  $F(0,p,q)=0, p=q$ $F(0,p,q)=b(p,q), p\\ne q$ p q  0 p q  $b(p,q)$ q  p  $F(0,p,q)=\\infty, p \\notin succ(p) \\cup \\{p\\}$</li>\n<li> $\\{1,2,,k\\}$  p  q $b(p,p)=0$</li>\n</ol>\n<p> (2.2)  r  p  $N-1$  p  $N-1$k  $N-1$ p  q  N  (2.2)  $O(N^4)$ (2.4)  $O(N^3)$</p>\n<p> APSP  (2.2)  $\\{F^{(1)},F^{(2)},,F^{(N-1)}\\}$ $F^{(k)}$  $N \\times N$$F_{p,q}^{k}$  p  q  k  $\\min_{p,q} F_{p,q}^{(N-1)}$  APSP </p>\n<p><strong></strong></p>\n<p> (2.2) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F(k,p,q)&=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\}\n\\\\\\\\ &= \\min_{r \\in succ(p)} \\{b(p,p)+F(k-1,p,q), b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in succ(p) \\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in \\{1,2,...,N\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.5) \\end{aligned}</script><p>$b(p,r)$  edge  $\\infty$ $W_{N \\times N}$ (2.2)  $F^{(0)}$  0 $\\infty$</p>\n<script type=\"math/tex; mode=display\">F^{(0)}=\\begin{bmatrix}0 & \\infty & \\cdots & \\infty\n\\\\\\\\                    \\infty & 0  & \\cdots & \\infty\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    \\infty & \\infty & \\cdots & 0 \\end{bmatrix}_{N \\times N}</script><script type=\"math/tex; mode=display\">W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}</script><p> (2.5) $F^{(k-1)}$  $F^{(k)}$ <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">F_k=[[<span class=\"literal\">None</span>]*N]*N</span><br><span class=\"line\"><span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">  <span class=\"keyword\">for</span> q <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">    F_k[p][q]=sys.info.float_max</span><br><span class=\"line\">    <span class=\"comment\"># F_k[p][q]=0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">      F_k[p][q]=<span class=\"built_in\">min</span>(F_k[p][q],W[p][r]+F_k_1[r][q])</span><br><span class=\"line\">      <span class=\"comment\"># F_k[p][q]=F_k[p][q]+W[p][r]*F_k_1[r][q])</span></span><br></pre></td></tr></table></figure><br> $F^{(N-1)}$ $F^{(k)}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F^{(1)}&=W \\circ F^{(0)}=W\n\\\\\\\\ F^{(2)}&=W \\circ F^{(1)}=W^2\n\\\\\\\\ F^{(3)}&=W \\circ F^{(2)}=W^3\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{(N-1)}&=W \\circ F^{(N-2)}=W^{(N-1)} \\end{aligned} \\quad(2.6)</script><p>$\\circ$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F^{(1)}&=W\n\\\\\\\\ F^{(2)}&=W^2=W \\circ W\n\\\\\\\\ F^{(4)}&=W^4=W^2 \\circ W^2\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{2^{\\lceil log(N-1) \\rceil}}&=W^{2^{\\lceil log(N-1) \\rceil}} =W^{2^{\\lceil log(N-1) \\rceil-1}} \\circ W^{2^{\\lceil log(N-1) \\rceil-1}} \\end{aligned} \\quad(2.7)</script><p> $2^{\\lceil log(N-1) \\rceil}$  $\\lceil \\cdot \\rceil$  $2^{\\lceil log(N-1) \\rceil} \\ge N-1$ $F^{2^{\\lceil log(N-1) \\rceil}} \\le F^{(N-1)}$ element-wise comparison</p>\n<p> (2.6)  (2.7)</p>\n<script type=\"math/tex; mode=display\">F^{(4)}=W \\circ F^{(3)}=W \\circ (W \\circ F^{(2)})=\\cdots =W \\circ(W \\circ (W \\circ W)) \\stackrel{*}=(W \\circ W) \\circ (W \\circ W)=W^2 \\circ W^2</script><p> $\\circ$  $\\min$ $\\min (W, \\min(W, \\min(W,W)))=\\min(\\min(W,W), \\min(W,W))$ $\\min$  element-wise operator (2.6)  (2.7) </p>\n<p> (2.7)  $F^{(M)}, M \\ge N-1$ $F^{(k)}$  $F^{(N-1)}$ $F^{(M)}$ </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fast_apsp</span>():</span></span><br><span class=\"line\">  k=<span class=\"number\">1</span></span><br><span class=\"line\">  F_prev=W</span><br><span class=\"line\">  <span class=\"keyword\">while</span> k&lt;N-<span class=\"number\">1</span>:</span><br><span class=\"line\">    F_next=[[sys.info.float_max]*N]*N</span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">      <span class=\"keyword\">for</span> q <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">          F_next[p][q]=<span class=\"built_in\">min</span>(F_next[p][q], F_prev[p][r]+F_prev[r][q])</span><br><span class=\"line\">    F_prev=F_next</span><br><span class=\"line\">    k*=<span class=\"number\">2</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> F_prev</span><br></pre></td></tr></table></figure></p>\n<p><strong>Floyd-Warshall</strong> </p>\n<p> (2.4) $F^{(k)}$  k  $\\{1,2,,k\\}$ $F^{(0)}$ </p>\n<script type=\"math/tex; mode=display\">F^{(0)}=W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}</script><p> (2.4) <strong>Floyd-Warshall</strong> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">F_prev=F_0</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">floyd_warshall</span>():</span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">    F_next=[[<span class=\"literal\">None</span>]*N]*N</span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">      <span class=\"keyword\">for</span> q <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">        F_next[p][q]=<span class=\"built_in\">min</span>(F_prev[p][q], F_prev[p][k]+F_prev[k][q])</span><br><span class=\"line\">    F_prev=F_next</span><br><span class=\"line\">  <span class=\"keyword\">return</span> F_prev</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-ARC\"><a href=\"#-ARC\" class=\"headerlink\" title=\" ARC\"></a> ARC</h2><p>ARC *</p>\n<p>ARCinternal nodes root $S=(w_0,w_1,,w_{n-1})$  $(i,j)$  $(w_i,,w_j)$</p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\min_{}\\{c(i,j,d)+f(i,d)+f(d+1,j)\\}, \\quad i<j \\qquad(2.8)</script><p> $f(i,j)$  $(i,,j)$  $c(i,j,d)=\\sum_{k=i}^j w_k$  (2.8)d  $(i,,d)$ $(d+1,,j)$  d  $(i,,j)$  $c(i,j,d)$ </p>\n<p> $f(0,n-1)$ $f(i,i)=0, \\ \\forall i \\in \\{0,1,,n-1\\}$</p>\n<p> ARC  Huffman $S=(1,2,3,4)$ $(((1,2),3),4)$$f(S)=3+6+10=19$ $S=(2,3,3,4)$ $((2,3),(3,4))$$f(S)=5+7+12=24$</p>\n<h2 id=\"-ASMBAL\"><a href=\"#-ASMBAL\" class=\"headerlink\" title=\" ASMBAL\"></a> ASMBAL</h2><p>/ stage  k i  k+1  j  c(k,i,j) c(k,i,i)=0 0 s  t  0  c(0,0,j) c(N,j,0)j  </p>\n<p> 0~13  14  0  13  14 </p>\n<script type=\"math/tex; mode=display\">v=(0,7,8,9,5,3,6,4,8,5,4,7,0)</script><p><br><img src=\"/images/DP2_fig1.png\" alt=\"\"></p>\n<p> 14x14 </p>\n<p> k i  j  $R(k,i,j)=v(k,i)+c(k,i,j)$DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,i)=\\min_j \\{R(k,i,j)+f(k+1,j)\\}</script><p> $f(k,i)$  k  i  $f(0,0)$ $f(k,i)=0, k &gt; N$N  N=6</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(0,0)=\\min \\{R(0,0,0)+f(1,0), R(0,0,1)+f(1,1)\\}\n\\\\\\\\ f(1,0)=\\min \\{R(1,0,0)+f(2,0), R(1,0,1)+f(2,1)\\}\n\\\\\\\\ f(1,1)=\\min \\{R(1,1,0)+f(2,0), R(1,1,1)+f(2,1)\\}\n\\\\\\\\ \\cdots \\ (omitted)\n\\end{aligned}</script><h2 id=\"-ASSIGN\"><a href=\"#-ASSIGN\" class=\"headerlink\" title=\" ASSIGN\"></a> ASSIGN</h2><p> B  A  A  A  $\\{1,2,3\\}$  $\\{3,2,1\\}$ 3!  $A=(a_0,a_1,,a_{n-1})$  $B=(b_0,b_1,,b_{n-1})$  i $a_j$  $b_i$ $c(i,j)$ A  $(k,S)$ k  A  S k  d $C(k,S,d)$ $(k+1,S-\\{d\\})$DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_{d \\in S} \\{C(k,S,d)+f(k+1,S-\\{d\\})\\}</script><p> $f(1,S^{\\ast})$ $f(k,S)=0, \\ k=n+1 \\ or \\ S=\\emptyset$</p>\n<h2 id=\"-BST\"><a href=\"#-BST\" class=\"headerlink\" title=\" BST\"></a> BST</h2><p> n  $X=\\{x_0,,x_{n-1}\\}$ <strong></strong>  $x_i$  $p(x_i)$ $p_i$ $\\sum_{i=0}^{n-1}p_i=1$</p>\n<script type=\"math/tex; mode=display\">\\sum_{i=0}^{n-1}(p_i \\text{level}(x_i))</script><p>$\\text{level}(x_i)$  $x_i$  DP </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> S  DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & S \\ne \\emptyset\n\\\\\\\\ 0 & S=\\emptyset \\end{cases}</script><p> $S_l = \\{x \\in S: x &lt; \\alpha\\}, \\ S_r = \\{x \\in S: x &gt; \\alpha\\}$ $r(\\alpha, S)=\\sum_{x \\in S} p(x)$ 1 DPFE </p>\n<p> $S_l,\\ S_r$  <strong></strong> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & |S|>1\n\\\\\\\\ p(x) & S=\\{x\\} \\end{cases}</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> $(i,j)$ $X=\\{x_0,,x_{n-1}\\}$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i \\le j\n\\\\\\\\ 0 & i > j \\end{cases}</script><p>$(i,j)$  k  $(i,j)$, $(i,k-1)$ $(k+1,j)$  k$(i,j)$  level  level level  $f(i,j)$ $(i,j)$  level level  $\\sum_{l=i}^j p_l$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i < j\n\\\\\\\\ p_i & i = j \\end{cases}</script><h2 id=\"-COV\"><a href=\"#-COV\" class=\"headerlink\" title=\" COV\"></a> COV</h2><p> k k  0  i  $c_i$ n  $n \\le k$ n </p>\n<p> DP  $0,1,,k-1$ $l$  $s_l$ $c_{s_l}$ $c_l$ $j$ $l$  DPFE </p>\n<script type=\"math/tex; mode=display\">f(j,l)=\\begin{cases} \\min_{d \\in \\{j-2,...,l-1\\}} \\{(l-d)c_l+f(j-1,d)\\} & j>1\n\\\\\\\\ (l+1)c_l & j=1 \\end{cases}</script><p>d exclusive $s_l$  $\\{d+1,,l\\}$  d  $l-1$ $l$ d  $j-2$ $\\{j-1,,l\\}$ $\\{0,1,,j-2\\}$  $j-1$  $j-1$ </p>\n<p>$f(j,l)=(l+1)c_l, j=1$ $l$ $0,,l$ </p>\n<h2 id=\"-DEADLINE\"><a href=\"#-DEADLINE\" class=\"headerlink\" title=\" DEADLINE\"></a> DEADLINE</h2><p> 0 <strong></strong></p>\n<p> $S^{\\ast}=\\{0,1,2,3,4\\}$ $p=\\{10,15,20,1,5\\}$ $t=\\{1,2,2,3,3\\}$<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">t=np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">p=np.array([<span class=\"number\">10</span>,<span class=\"number\">15</span>,<span class=\"number\">20</span>,<span class=\"number\">1</span>,<span class=\"number\">5</span>])</span><br><span class=\"line\">m=<span class=\"number\">0</span>   <span class=\"comment\"># </span></span><br><span class=\"line\">n=t.shape[<span class=\"number\">0</span>]  <span class=\"comment\"># </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">  idx=np.where(t&gt;<span class=\"number\">0</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">  <span class=\"keyword\">if</span> idx.shape[<span class=\"number\">0</span>]==<span class=\"number\">0</span>:</span><br><span class=\"line\">    <span class=\"keyword\">break</span>   <span class=\"comment\"># </span></span><br><span class=\"line\">  c=np.<span class=\"built_in\">max</span>(p[idx])  <span class=\"comment\"># </span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> c &lt; <span class=\"number\">0</span>:</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br><span class=\"line\">  m+=c</span><br><span class=\"line\">  idx=np.argmax(p[idx])+idx[<span class=\"number\">0</span>]  <span class=\"comment\"># </span></span><br><span class=\"line\">  p[idx]=-<span class=\"number\">1e8</span>                   <span class=\"comment\"># </span></span><br><span class=\"line\">  t-=<span class=\"number\">1</span>                          <span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;&#x27;</span>, sep=<span class=\"string\">&#x27; &#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(m)    <span class=\"comment\"># 40</span></span><br></pre></td></tr></table></figure></p>\n<p> DP  $(k,S)$ k S  d  S  $(k+1,S-\\{d\\})$DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\max_{d \\in S}\\{c(d|S)+f(k+1,S-\\{d\\})\\}</script><p> d  k k  1 $c(d|S)=w_d$  $c(d|S)=0$ $f(1,S^{\\ast})$ $f(k,S)=0, k=n+1 \\ or \\ S=\\emptyset$ n <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\">p=[<span class=\"number\">10</span>,<span class=\"number\">15</span>,<span class=\"number\">20</span>,<span class=\"number\">1</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\">S=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\">n=<span class=\"built_in\">len</span>(t)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">profit</span>(<span class=\"params\">k,d</span>):</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> p[d] <span class=\"keyword\">if</span> t[d]&gt;=k <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">deadline</span>(<span class=\"params\">k,S</span>):</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span> <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(S)==<span class=\"number\">0</span> <span class=\"keyword\">or</span> k==n+<span class=\"number\">1</span> <span class=\"keyword\">else</span> \\</span><br><span class=\"line\">    <span class=\"built_in\">max</span>([profit(k,S[i])+deadline(k+<span class=\"number\">1</span>,S[:i]+S[i+<span class=\"number\">1</span>:]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(S))])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(deadline(<span class=\"number\">1</span>, S))   <span class=\"comment\"># 40</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-DPP\"><a href=\"#-DPP\" class=\"headerlink\" title=\" DPP\"></a> DPP</h2><p> $b_1$  t  $b_t$ t  $x_t$  $r(x_t)$ $c(x_t,b_t)$ s s  $1,,T$ T  y $x_t$   t  $(t,b)$ t b  t DPFE </p>\n<script type=\"math/tex; mode=display\">f(t,b)=\\begin{cases} \\max_{x_t \\in \\{0,...,b\\}} \\{r(x_t)-c(x_t,b)+\\frac 1 {1+y} f(t+1, \\lfloor s(b-x_t) \\rfloor)\\} & t \\le T\n\\\\\\\\ 0 & t=T+1 \\end{cases}</script><h2 id=\"-EDP\"><a href=\"#-EDP\" class=\"headerlink\" title=\" EDP\"></a> EDP</h2><p> $\\Sigma$  $x\\in \\Sigma^m, \\ y \\in \\Sigma^n$ $x=x_1\\cdots x_m, \\ y=y_1 \\cdots y_n$ x  y</p>\n<ul>\n<li> D $c(D)$</li>\n<li> I $c(I)$</li>\n<li> R $c(R)$ $c(R)=0$</li>\n</ul>\n<p> x  yDPFE </p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min \\{f(i-1,j)+c(D),f(i,j-1)+c(I),f(i-1,j-1)+c(R)\\} & i>0,j>0 \\end{cases}</script><p> $f(i,j)$  $X_i$  $Y_j$ $X_i$  x  i $Y_j$  y  j  i=0  $X_i$  j  $Y_j$ j=0  $X_i$  i  $Y_j$ i&gt;0  j&gt;0  $X_i$  $Y_j$/</p>\n<ul>\n<li> $X_i$  i  $X_{i-1}$  $Y_j$ $c(D)$  $f(i-1,j)$</li>\n<li> $X_i$  $Y_{j-1}$ $Y_j$ $f(i,j-1)$  $c(I)$</li>\n<li>$x_i \\rightarrow y_j$ $X_{i-1}$  $Y_{j-1}$  $X_i$  $Y_j$  $f(i-1,j-1)$  $c(R)$</li>\n</ul>\n<p> DPFE</p>\n<script type=\"math/tex; mode=display\">f(X_i,Y_j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min_{d \\in \\{D,I,R\\}} \\{f(t(X_i,Y_j,d))+c(d)\\} & i>0,j>0\n\\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">t(X_i,Y_j,D)=(X_{i-1},Y_j)\n\\\\\\\\ t(X_i,Y_j,I)=(X_i,Y_{j-1})\n\\\\\\\\ t(X_i,Y_j,R)=(X_{i-1},Y_{j-1})</script>","site":{"data":{}},"excerpt":"<p> <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  DPFE</p>\n<h2 id=\"-ALLOT\"><a href=\"#-ALLOT\" class=\"headerlink\" title=\" ALLOT\"></a> ALLOT</h2><p> ALLOTALLOT  KSINT </p>","more":"<p> M  N  C(k,d)  d  k  $d_1$  1 $d_2$  2 (k,m)  k  m  k  m k  C(k,d) (k+1,m-d) <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  (1.19)  DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,m)=\\min_{d \\in \\{0,...,m\\}} \\{C(k,d)+f(k+1,m-d)\\} \\quad (2.1)</script><p> f(1,M) f(N+1,m)=0 $m \\ge 0$</p>\n<p> M=4N=3</p>\n<script type=\"math/tex; mode=display\">(C_{k,d})_{k\\in \\{1,2,3\\};d\\in \\{0,...,4\\}}=\\begin{pmatrix}\\infty & 1.0 & 0.8& 0.4 & 0.0 \\\\\\\\ \\infty & 1.0& 0.5 & 0.0 & 0.0 \\\\\\\\ \\infty & 1.0 & 0.6 & 0.3 & 0.0 \\end{pmatrix}</script><p>f(1,M)=1.0+0.5+1.0=2.5 $d_1=1,d_2=2,d_3=1$ (2.1) <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">allot</span>(<span class=\"params\">cache=<span class=\"literal\">True</span></span>):</span></span><br><span class=\"line\">    M=<span class=\"number\">4</span></span><br><span class=\"line\">    N=<span class=\"number\">3</span></span><br><span class=\"line\">    max_float=<span class=\"number\">1e8</span></span><br><span class=\"line\">    cost=[[max_float, <span class=\"number\">1.0</span>, <span class=\"number\">0.8</span>, <span class=\"number\">0.4</span>, <span class=\"number\">0.0</span>],</span><br><span class=\"line\">          [max_float, <span class=\"number\">1.0</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.0</span>, <span class=\"number\">0.0</span>],</span><br><span class=\"line\">          [max_float, <span class=\"number\">1.0</span>, <span class=\"number\">0.6</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.0</span>]]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">if</span> cache:</span><br><span class=\"line\">        cache_dict = &#123;&#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">allot_inner</span>(<span class=\"params\">k,m</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> cache <span class=\"keyword\">and</span> (k,m) <span class=\"keyword\">in</span> cache_dict:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> cache_dict[(k,m)]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> k&gt;= N: <span class=\"keyword\">return</span> [], <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">        min_f=max_float</span><br><span class=\"line\">        min_ds = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(m+<span class=\"number\">1</span>):</span><br><span class=\"line\">            ds,f=allot_inner(k+<span class=\"number\">1</span>,m-d)</span><br><span class=\"line\">            temp=cost[k][d]+f</span><br><span class=\"line\">            <span class=\"keyword\">if</span> min_f &gt; temp:</span><br><span class=\"line\">                min_f = temp</span><br><span class=\"line\">                min_ds = [d]+ds</span><br><span class=\"line\">        <span class=\"keyword\">if</span> cache <span class=\"keyword\">and</span> k &gt; <span class=\"number\">1</span>:</span><br><span class=\"line\">            cache_dict[(k,m)]=(min_ds,min_f)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> min_ds, min_f</span><br><span class=\"line\">    ds, f=allot_inner(<span class=\"number\">0</span>,M)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;min cost:&quot;</span>,f,<span class=\"string\">&quot;opt allotments:&quot;</span>, ds)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-APSP\"><a href=\"#-APSP\" class=\"headerlink\" title=\" APSP\"></a> APSP</h2><p> s  t  Nself-loop</p>\n<p> <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  (s,t) </p>\n<p><strong>Relaxation</strong> </p>\n<p> F(k,p,q)  p  q k  p  q  k  <a href=\"2019/08/07/DP1\">Dynamic Programming (1)</a>  (1.27)DPFE </p>\n<script type=\"math/tex; mode=display\">F(k,p,q)=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\quad(2.2)</script><p> r  p :</p>\n<ol>\n<li>$F(k,p,q)=0, k \\ge 0, p=q$ p  q  k  0</li>\n<li>$F(0,p,q)=\\infty, p \\ne q$  p  q  0 </li>\n</ol>\n<p> $b(p,p)=0$ (2.2) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}F(k,p,q)&=\\min \\{F(k-1,p,q)+b(p,p), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\} \\\\\\\\ &=\\min_{r \\in succ(p)\\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.3) \\end{aligned}</script><p><strong>Floyd-Warshall</strong> </p>\n<p> (2.2)  DPFE  p  q  k  p  r  r  k-1  q  p  r  r  q p  r  1 p  q  k r  k  k  $\\{1,2,,k\\}$ p  q  $\\{1,2,,N\\}$  p  q DPFE </p>\n<script type=\"math/tex; mode=display\">F(k,p,q)=\\min \\{F(k-1,p,q), F(k-1,p,k)+F(k-1,k,q)\\} \\qquad(2.4)</script><p></p>\n<ol>\n<li> N  $V=\\{1,2,,N\\}$$p,q \\in V$</li>\n<li>$F(k,p,q)$  p  q  $\\{1,2,,k\\}$ </li>\n<li> $F(N,p,q)$</li>\n<li> $(2.4)$<ul>\n<li>p  q  k $\\{1,2,,k-1\\}$ </li>\n<li> p  q  k p  k  k  q $\\{1,2,,k-1\\}$ </li>\n</ul>\n</li>\n<li> $(2.4)$  k&gt;0k=0  $F(0,p,q)=0, p=q$ $F(0,p,q)=b(p,q), p\\ne q$ p q  0 p q  $b(p,q)$ q  p  $F(0,p,q)=\\infty, p \\notin succ(p) \\cup \\{p\\}$</li>\n<li> $\\{1,2,,k\\}$  p  q $b(p,p)=0$</li>\n</ol>\n<p> (2.2)  r  p  $N-1$  p  $N-1$k  $N-1$ p  q  N  (2.2)  $O(N^4)$ (2.4)  $O(N^3)$</p>\n<p> APSP  (2.2)  $\\{F^{(1)},F^{(2)},,F^{(N-1)}\\}$ $F^{(k)}$  $N \\times N$$F_{p,q}^{k}$  p  q  k  $\\min_{p,q} F_{p,q}^{(N-1)}$  APSP </p>\n<p><strong></strong></p>\n<p> (2.2) </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F(k,p,q)&=\\min \\{F(k-1,p,q), \\min_{r \\in succ(p)} \\{b(p,r)+F(k-1,r,q)\\}\\}\n\\\\\\\\ &= \\min_{r \\in succ(p)} \\{b(p,p)+F(k-1,p,q), b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in succ(p) \\cup \\{p\\}} \\{b(p,r)+F(k-1,r,q)\\}\n\\\\\\\\ &= \\min_{r \\in \\{1,2,...,N\\}} \\{b(p,r)+F(k-1,r,q)\\} \\qquad(2.5) \\end{aligned}</script><p>$b(p,r)$  edge  $\\infty$ $W_{N \\times N}$ (2.2)  $F^{(0)}$  0 $\\infty$</p>\n<script type=\"math/tex; mode=display\">F^{(0)}=\\begin{bmatrix}0 & \\infty & \\cdots & \\infty\n\\\\\\\\                    \\infty & 0  & \\cdots & \\infty\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    \\infty & \\infty & \\cdots & 0 \\end{bmatrix}_{N \\times N}</script><script type=\"math/tex; mode=display\">W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}</script><p> (2.5) $F^{(k-1)}$  $F^{(k)}$ <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\">F_k=[[<span class=\"literal\">None</span>]*N]*N</span><br><span class=\"line\"><span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">  <span class=\"keyword\">for</span> q <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">    F_k[p][q]=sys.info.float_max</span><br><span class=\"line\">    <span class=\"comment\"># F_k[p][q]=0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">      F_k[p][q]=<span class=\"built_in\">min</span>(F_k[p][q],W[p][r]+F_k_1[r][q])</span><br><span class=\"line\">      <span class=\"comment\"># F_k[p][q]=F_k[p][q]+W[p][r]*F_k_1[r][q])</span></span><br></pre></td></tr></table></figure><br> $F^{(N-1)}$ $F^{(k)}$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F^{(1)}&=W \\circ F^{(0)}=W\n\\\\\\\\ F^{(2)}&=W \\circ F^{(1)}=W^2\n\\\\\\\\ F^{(3)}&=W \\circ F^{(2)}=W^3\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{(N-1)}&=W \\circ F^{(N-2)}=W^{(N-1)} \\end{aligned} \\quad(2.6)</script><p>$\\circ$ </p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} F^{(1)}&=W\n\\\\\\\\ F^{(2)}&=W^2=W \\circ W\n\\\\\\\\ F^{(4)}&=W^4=W^2 \\circ W^2\n\\\\\\\\ &\\vdots\n\\\\\\\\ F^{2^{\\lceil log(N-1) \\rceil}}&=W^{2^{\\lceil log(N-1) \\rceil}} =W^{2^{\\lceil log(N-1) \\rceil-1}} \\circ W^{2^{\\lceil log(N-1) \\rceil-1}} \\end{aligned} \\quad(2.7)</script><p> $2^{\\lceil log(N-1) \\rceil}$  $\\lceil \\cdot \\rceil$  $2^{\\lceil log(N-1) \\rceil} \\ge N-1$ $F^{2^{\\lceil log(N-1) \\rceil}} \\le F^{(N-1)}$ element-wise comparison</p>\n<p> (2.6)  (2.7)</p>\n<script type=\"math/tex; mode=display\">F^{(4)}=W \\circ F^{(3)}=W \\circ (W \\circ F^{(2)})=\\cdots =W \\circ(W \\circ (W \\circ W)) \\stackrel{*}=(W \\circ W) \\circ (W \\circ W)=W^2 \\circ W^2</script><p> $\\circ$  $\\min$ $\\min (W, \\min(W, \\min(W,W)))=\\min(\\min(W,W), \\min(W,W))$ $\\min$  element-wise operator (2.6)  (2.7) </p>\n<p> (2.7)  $F^{(M)}, M \\ge N-1$ $F^{(k)}$  $F^{(N-1)}$ $F^{(M)}$ </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fast_apsp</span>():</span></span><br><span class=\"line\">  k=<span class=\"number\">1</span></span><br><span class=\"line\">  F_prev=W</span><br><span class=\"line\">  <span class=\"keyword\">while</span> k&lt;N-<span class=\"number\">1</span>:</span><br><span class=\"line\">    F_next=[[sys.info.float_max]*N]*N</span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">      <span class=\"keyword\">for</span> q <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> r <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">          F_next[p][q]=<span class=\"built_in\">min</span>(F_next[p][q], F_prev[p][r]+F_prev[r][q])</span><br><span class=\"line\">    F_prev=F_next</span><br><span class=\"line\">    k*=<span class=\"number\">2</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> F_prev</span><br></pre></td></tr></table></figure></p>\n<p><strong>Floyd-Warshall</strong> </p>\n<p> (2.4) $F^{(k)}$  k  $\\{1,2,,k\\}$ $F^{(0)}$ </p>\n<script type=\"math/tex; mode=display\">F^{(0)}=W=\\begin{bmatrix}0 & w_{12} & \\cdots & w_{1N}\n\\\\\\\\                    w_{21} & 0  & \\cdots & w_{2N}\n\\\\\\\\                    \\vdots & \\vdots & \\ddots & \\vdots\n\\\\\\\\                    w_{N1} & w_{N2} & \\cdots & 0 \\end{bmatrix}_{N \\times N}</script><p> (2.4) <strong>Floyd-Warshall</strong> <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">F_prev=F_0</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">floyd_warshall</span>():</span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">    F_next=[[<span class=\"literal\">None</span>]*N]*N</span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">      <span class=\"keyword\">for</span> q <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,N):</span><br><span class=\"line\">        F_next[p][q]=<span class=\"built_in\">min</span>(F_prev[p][q], F_prev[p][k]+F_prev[k][q])</span><br><span class=\"line\">    F_prev=F_next</span><br><span class=\"line\">  <span class=\"keyword\">return</span> F_prev</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-ARC\"><a href=\"#-ARC\" class=\"headerlink\" title=\" ARC\"></a> ARC</h2><p>ARC *</p>\n<p>ARCinternal nodes root $S=(w_0,w_1,,w_{n-1})$  $(i,j)$  $(w_i,,w_j)$</p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\min_{}\\{c(i,j,d)+f(i,d)+f(d+1,j)\\}, \\quad i<j \\qquad(2.8)</script><p> $f(i,j)$  $(i,,j)$  $c(i,j,d)=\\sum_{k=i}^j w_k$  (2.8)d  $(i,,d)$ $(d+1,,j)$  d  $(i,,j)$  $c(i,j,d)$ </p>\n<p> $f(0,n-1)$ $f(i,i)=0, \\ \\forall i \\in \\{0,1,,n-1\\}$</p>\n<p> ARC  Huffman $S=(1,2,3,4)$ $(((1,2),3),4)$$f(S)=3+6+10=19$ $S=(2,3,3,4)$ $((2,3),(3,4))$$f(S)=5+7+12=24$</p>\n<h2 id=\"-ASMBAL\"><a href=\"#-ASMBAL\" class=\"headerlink\" title=\" ASMBAL\"></a> ASMBAL</h2><p>/ stage  k i  k+1  j  c(k,i,j) c(k,i,i)=0 0 s  t  0  c(0,0,j) c(N,j,0)j  </p>\n<p> 0~13  14  0  13  14 </p>\n<script type=\"math/tex; mode=display\">v=(0,7,8,9,5,3,6,4,8,5,4,7,0)</script><p><br><img src=\"/images/DP2_fig1.png\" alt=\"\"></p>\n<p> 14x14 </p>\n<p> k i  j  $R(k,i,j)=v(k,i)+c(k,i,j)$DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,i)=\\min_j \\{R(k,i,j)+f(k+1,j)\\}</script><p> $f(k,i)$  k  i  $f(0,0)$ $f(k,i)=0, k &gt; N$N  N=6</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} f(0,0)=\\min \\{R(0,0,0)+f(1,0), R(0,0,1)+f(1,1)\\}\n\\\\\\\\ f(1,0)=\\min \\{R(1,0,0)+f(2,0), R(1,0,1)+f(2,1)\\}\n\\\\\\\\ f(1,1)=\\min \\{R(1,1,0)+f(2,0), R(1,1,1)+f(2,1)\\}\n\\\\\\\\ \\cdots \\ (omitted)\n\\end{aligned}</script><h2 id=\"-ASSIGN\"><a href=\"#-ASSIGN\" class=\"headerlink\" title=\" ASSIGN\"></a> ASSIGN</h2><p> B  A  A  A  $\\{1,2,3\\}$  $\\{3,2,1\\}$ 3!  $A=(a_0,a_1,,a_{n-1})$  $B=(b_0,b_1,,b_{n-1})$  i $a_j$  $b_i$ $c(i,j)$ A  $(k,S)$ k  A  S k  d $C(k,S,d)$ $(k+1,S-\\{d\\})$DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\min_{d \\in S} \\{C(k,S,d)+f(k+1,S-\\{d\\})\\}</script><p> $f(1,S^{\\ast})$ $f(k,S)=0, \\ k=n+1 \\ or \\ S=\\emptyset$</p>\n<h2 id=\"-BST\"><a href=\"#-BST\" class=\"headerlink\" title=\" BST\"></a> BST</h2><p> n  $X=\\{x_0,,x_{n-1}\\}$ <strong></strong>  $x_i$  $p(x_i)$ $p_i$ $\\sum_{i=0}^{n-1}p_i=1$</p>\n<script type=\"math/tex; mode=display\">\\sum_{i=0}^{n-1}(p_i \\text{level}(x_i))</script><p>$\\text{level}(x_i)$  $x_i$  DP </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> S  DPFE </p>\n<script type=\"math/tex; mode=display\">f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & S \\ne \\emptyset\n\\\\\\\\ 0 & S=\\emptyset \\end{cases}</script><p> $S_l = \\{x \\in S: x &lt; \\alpha\\}, \\ S_r = \\{x \\in S: x &gt; \\alpha\\}$ $r(\\alpha, S)=\\sum_{x \\in S} p(x)$ 1 DPFE </p>\n<p> $S_l,\\ S_r$  <strong></strong> </p>\n<p></p>\n<script type=\"math/tex; mode=display\">f(S)=\\begin{cases} \\min_{\\alpha \\in S} \\{f(S_l)+f(S_r)+r(\\alpha, S)\\} & |S|>1\n\\\\\\\\ p(x) & S=\\{x\\} \\end{cases}</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> $(i,j)$ $X=\\{x_0,,x_{n-1}\\}$ DPFE </p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i \\le j\n\\\\\\\\ 0 & i > j \\end{cases}</script><p>$(i,j)$  k  $(i,j)$, $(i,k-1)$ $(k+1,j)$  k$(i,j)$  level  level level  $f(i,j)$ $(i,j)$  level level  $\\sum_{l=i}^j p_l$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\begin{cases} \\min_{k \\in \\{i,...,j\\}} \\{f(i,k-1)+f(k+1,j)+\\sum_{l=i}^j p_l\\} & i < j\n\\\\\\\\ p_i & i = j \\end{cases}</script><h2 id=\"-COV\"><a href=\"#-COV\" class=\"headerlink\" title=\" COV\"></a> COV</h2><p> k k  0  i  $c_i$ n  $n \\le k$ n </p>\n<p> DP  $0,1,,k-1$ $l$  $s_l$ $c_{s_l}$ $c_l$ $j$ $l$  DPFE </p>\n<script type=\"math/tex; mode=display\">f(j,l)=\\begin{cases} \\min_{d \\in \\{j-2,...,l-1\\}} \\{(l-d)c_l+f(j-1,d)\\} & j>1\n\\\\\\\\ (l+1)c_l & j=1 \\end{cases}</script><p>d exclusive $s_l$  $\\{d+1,,l\\}$  d  $l-1$ $l$ d  $j-2$ $\\{j-1,,l\\}$ $\\{0,1,,j-2\\}$  $j-1$  $j-1$ </p>\n<p>$f(j,l)=(l+1)c_l, j=1$ $l$ $0,,l$ </p>\n<h2 id=\"-DEADLINE\"><a href=\"#-DEADLINE\" class=\"headerlink\" title=\" DEADLINE\"></a> DEADLINE</h2><p> 0 <strong></strong></p>\n<p> $S^{\\ast}=\\{0,1,2,3,4\\}$ $p=\\{10,15,20,1,5\\}$ $t=\\{1,2,2,3,3\\}$<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">t=np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">p=np.array([<span class=\"number\">10</span>,<span class=\"number\">15</span>,<span class=\"number\">20</span>,<span class=\"number\">1</span>,<span class=\"number\">5</span>])</span><br><span class=\"line\">m=<span class=\"number\">0</span>   <span class=\"comment\"># </span></span><br><span class=\"line\">n=t.shape[<span class=\"number\">0</span>]  <span class=\"comment\"># </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">  idx=np.where(t&gt;<span class=\"number\">0</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">  <span class=\"keyword\">if</span> idx.shape[<span class=\"number\">0</span>]==<span class=\"number\">0</span>:</span><br><span class=\"line\">    <span class=\"keyword\">break</span>   <span class=\"comment\"># </span></span><br><span class=\"line\">  c=np.<span class=\"built_in\">max</span>(p[idx])  <span class=\"comment\"># </span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> c &lt; <span class=\"number\">0</span>:</span><br><span class=\"line\">    <span class=\"keyword\">break</span></span><br><span class=\"line\">  m+=c</span><br><span class=\"line\">  idx=np.argmax(p[idx])+idx[<span class=\"number\">0</span>]  <span class=\"comment\"># </span></span><br><span class=\"line\">  p[idx]=-<span class=\"number\">1e8</span>                   <span class=\"comment\"># </span></span><br><span class=\"line\">  t-=<span class=\"number\">1</span>                          <span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;&#x27;</span>, sep=<span class=\"string\">&#x27; &#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(m)    <span class=\"comment\"># 40</span></span><br></pre></td></tr></table></figure></p>\n<p> DP  $(k,S)$ k S  d  S  $(k+1,S-\\{d\\})$DPFE </p>\n<script type=\"math/tex; mode=display\">f(k,S)=\\max_{d \\in S}\\{c(d|S)+f(k+1,S-\\{d\\})\\}</script><p> d  k k  1 $c(d|S)=w_d$  $c(d|S)=0$ $f(1,S^{\\ast})$ $f(k,S)=0, k=n+1 \\ or \\ S=\\emptyset$ n <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">t=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\">p=[<span class=\"number\">10</span>,<span class=\"number\">15</span>,<span class=\"number\">20</span>,<span class=\"number\">1</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\">S=[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]</span><br><span class=\"line\">n=<span class=\"built_in\">len</span>(t)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">profit</span>(<span class=\"params\">k,d</span>):</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> p[d] <span class=\"keyword\">if</span> t[d]&gt;=k <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">deadline</span>(<span class=\"params\">k,S</span>):</span></span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"number\">0</span> <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(S)==<span class=\"number\">0</span> <span class=\"keyword\">or</span> k==n+<span class=\"number\">1</span> <span class=\"keyword\">else</span> \\</span><br><span class=\"line\">    <span class=\"built_in\">max</span>([profit(k,S[i])+deadline(k+<span class=\"number\">1</span>,S[:i]+S[i+<span class=\"number\">1</span>:]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(S))])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(deadline(<span class=\"number\">1</span>, S))   <span class=\"comment\"># 40</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"-DPP\"><a href=\"#-DPP\" class=\"headerlink\" title=\" DPP\"></a> DPP</h2><p> $b_1$  t  $b_t$ t  $x_t$  $r(x_t)$ $c(x_t,b_t)$ s s  $1,,T$ T  y $x_t$   t  $(t,b)$ t b  t DPFE </p>\n<script type=\"math/tex; mode=display\">f(t,b)=\\begin{cases} \\max_{x_t \\in \\{0,...,b\\}} \\{r(x_t)-c(x_t,b)+\\frac 1 {1+y} f(t+1, \\lfloor s(b-x_t) \\rfloor)\\} & t \\le T\n\\\\\\\\ 0 & t=T+1 \\end{cases}</script><h2 id=\"-EDP\"><a href=\"#-EDP\" class=\"headerlink\" title=\" EDP\"></a> EDP</h2><p> $\\Sigma$  $x\\in \\Sigma^m, \\ y \\in \\Sigma^n$ $x=x_1\\cdots x_m, \\ y=y_1 \\cdots y_n$ x  y</p>\n<ul>\n<li> D $c(D)$</li>\n<li> I $c(I)$</li>\n<li> R $c(R)$ $c(R)=0$</li>\n</ul>\n<p> x  yDPFE </p>\n<script type=\"math/tex; mode=display\">f(i,j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min \\{f(i-1,j)+c(D),f(i,j-1)+c(I),f(i-1,j-1)+c(R)\\} & i>0,j>0 \\end{cases}</script><p> $f(i,j)$  $X_i$  $Y_j$ $X_i$  x  i $Y_j$  y  j  i=0  $X_i$  j  $Y_j$ j=0  $X_i$  i  $Y_j$ i&gt;0  j&gt;0  $X_i$  $Y_j$/</p>\n<ul>\n<li> $X_i$  i  $X_{i-1}$  $Y_j$ $c(D)$  $f(i-1,j)$</li>\n<li> $X_i$  $Y_{j-1}$ $Y_j$ $f(i,j-1)$  $c(I)$</li>\n<li>$x_i \\rightarrow y_j$ $X_{i-1}$  $Y_{j-1}$  $X_i$  $Y_j$  $f(i-1,j-1)$  $c(R)$</li>\n</ul>\n<p> DPFE</p>\n<script type=\"math/tex; mode=display\">f(X_i,Y_j)=\\begin{cases} jI & i=0\n\\\\\\\\ iD & j=0\n\\\\\\\\ \\min_{d \\in \\{D,I,R\\}} \\{f(t(X_i,Y_j,d))+c(d)\\} & i>0,j>0\n\\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">t(X_i,Y_j,D)=(X_{i-1},Y_j)\n\\\\\\\\ t(X_i,Y_j,I)=(X_i,Y_{j-1})\n\\\\\\\\ t(X_i,Y_j,R)=(X_{i-1},Y_{j-1})</script>"},{"title":"PyTorch-2","p":"pytorch/PyTorch-2","date":"2019-06-13T02:19:52.000Z","_content":"# torch installization\n<!-- more -->\nPyTorchpythonPyTorch\n```\nimport torch\n```\n `torch/__init__.py`torch._CRTLD_GLOBAL|RTLD_LAZYRTLD_GLOBAL|RTLD_LAZYtorch._C\n```\nold_flags=sys.getdlopenflags()\nsys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)\nfrom torch._C import *\n__all__ += [name for name in dir(_C)\n            if name[0] != '_' and\n            not name.endswith('Base')]\nsys.setdlopenflags(old_flags)\n```\n__torch._C_Base__\n\n`__init__.py`import torch._Cimportmodulepackagetorch._C torch._Ctorch/csrc/stub.cppshmtorch_pythonstub.cpp\n```\nextern PyObject* initModule();\nPyMODINIT_FUNC PyInit__C()   // pythonimport _C \n{\n  return initModule();\n}\n```\npython3`import torch._C` PyInit__CPyInit_&lt;package>initModuleinitModuleexterninitModuleshmtorch_python\n\nshmDomain Sockettorch/CMakeLists.txtshm\n```\nset(LIBSHM_SUBDIR libshm)\nset(LIBSHM_SRCDIR ${LIBSHM_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\nshmtorch/lib/libshmtorch._Ctorch_pythoninitModuletorch/CMakeLists.txt\n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\nTORCH_PYTHON_SRCStorch_pythontorch_pythontorch/CMakeLists.txt\n\ninitModuletorch/csrc/Module.cpp\n```\n#ifdef USE_CUDA\nnamespace torch { namespace cuda {\nvoid initModule(PyObject* module);       // cuda\n}}\n#endif\n\nstatic std::vector<PyMethodDef> methods;\n\nPyObject* module;\nPyObject* initModule() {                 // \n  // methods\n  THPUtils_addPyMethodDefs(methods, TorchMethods);\n  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);\n  ...\n  // \n  static struct PyModuleDef torchmodule = {\n    PyModuleDef_HEAD_INIT,\n    \"torch._C\",                          // \n    nullptr,                           \n    -1,\n    methods.data()                       // \n  };\n  ASSERT_TRUE(module = PyModule_Create(&torchmodule)); // \n  // \n#ifdef USE_CUDA\n  torch::cuda::initModule(module);       // cuda\n#endif\n  ...\n  // setter\n  // namevincref\n  // 10\n  auto set_module_attr = [&](const char* name, PyObject* v, bool incref = true) \n  {\n    if(incref) {\n      Py_INCREF(v);\n    }\n    return PyModule_AddObject(module, name, v) == 0;\n  }\n  // \n  ...\n  ASSERT_TRUE(set_module_attr(\"has_cudnn\", has_cudnn));\n  // \n  auto py_module = py::reinterpret_borrow<py::module>(module);\n  py_module.def(\"_demangle\", &c10::demangle);\n  py_module.def(\"_log_api_usage_once\", &LogAPIUsageOnceFromPython);\n  ...    // \n  ASSERT_TRUE(set_module_attr(\"default_generator\", \n        (PyObject*)THPDefaultGenerator, false));\n  torch::nn::init__THNN(module);  //  _THNN \n#ifdef USE_CUDA\n  torch::nn::init_THCUDD(module);\n#endif\n  return module;\n  ...\n}\n```\ntorch._Cattr\n# methods/members in torch._C\n-  THPUtils_addPyMethodDefs torch._C \n```\n# TorchMethods \n_initExtension\n_autograd_init\n...\n# DataLoaderMethods \n_set_worker_signal_handlers\n_set_worker_pids\n...\n# torch::autograd::python_functions(), torch/csrc/autograd/init.cpp\nset_grad_enabled\nis_grad_enabled\nset_anomaly_enabled\nis_anomaly_enabled\n# torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp\n_multiprocessing_init\n# torch::distributed::c10d::python_functions()  \n...\n# THCPModule_method(), torch/csrc/cuda/Module.cpp\n_cuda_init\n_cuda_setDevice\n...\n_nccl_version\n...\n# THCUDNN_method()\n_cudnn_version\n# THDPModule_methods(), torch/csrc/distributed/Module.cpp\n_dist_init_extension\n_dist_init_process_group\n...\n```\n- torch._C \n\n    - torch._C_PtrWrapperGeneratorFatalErrorSizedtypeiinfolayoutmemory_formatdevice_LegacyVariableBase_TensorBase_VariableFunctions_FunctionBase_EngineBaseJITExceptionIODescriptor_THNN_THCUNN\n\n        torch._C._TensorBase\n        ```\n        _cdata\n        _version\n        grad_fn\n        _grad_fn\n        is_leaf\n        data\n        _grad\n        grad\n        ...\n        device\n        ndim\n        ```\n        \n        ```\n        # variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp\n        __add__\n        __radd__\n        ...\n        apply_\n        byte\n        char\n        contiguous\n        ...\n        where\n        zero_\n        # extra_method\n        _make_subclass\n        ```\n        torch._C._FunctionBase \n        ```\n        # method\n        apply\n        _do_forward\n        _do_backward\n        _register_hook_dict\n        register_hook\n        # property\n        saved_tensors\n        saved_variables\n        ...\n        requires_grad\n        metadata\n        ```\n         torch._C._VariableFunctions \n        ```python\n        arange\n        as_tensor\n        ...\n        empty       #  torch.empty\n        empty_like\n        ...\n        ```\n\n        _TensorBaseTensorTensor_FunctionBase\n\n    - torch._C _wrap_tensor_impl_tensor_impl_raw_handle_demangle_log_api_usage_once_jit\n\n    - torch._C _nncpp_onnx\n\n    - torch._C has_cudnnhas_openmphas_mklhas_lapackhas_cudahas_mkldnn_GLIBCXX_USE_CXX11_APIdefault_generator\n\n# some installization w.r.t. torch._C\n### THPxxxStorage_init\ntorch._CTensor THPxxxStorage_init  THCPxxxStorage_init \n\nModule.cpp\n```\n#include <TH/TH.h>               // TH=TorcH\n#include <c10/util/Logging.h>\n#include <ATen/ATen.h>\n...\n#include <torch/csrc/THP.h>      // THP=TorcH Python\n...\n```\nATenc10torchATen [A Tensor Library] Tensorc10 [caffe2ATen] Tensor\n\n TH/TH.h #include <TH/THGeneral.h>aten/src/THCMakeLists.txt\n```\nCONFIGURE_FILE(THGeneral.h.in \"${CMAKE_CURRENT_BINARY_DIR}/THGeneral.h\")\n```\nTHGeneral.h\n```\n#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w\n#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)\n```\ntorch/csrc/THP.h #include <torch/src/Storage.h>Storage.h\n```\n#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)\n...\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateAllType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateQTypes.h>\n```\n4include/include torch/csrc/generic/Storage.htorch/csrc/generic/Storage.h \n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.h\"         // (0)\n#else\n...\nbool THPStorage_(init)(PyObject *module);                      // (1)\n...\n#endif\n```\nTH/THGenerateAllType.h\n```\n#include <TH/THGenerateFloatTypes.h>\n#include <TH/THGenerateIntTypes.h>\n...\n#undef TH_GENERIC_FILE\n```\n4includeinclude#undef TH_GENERIC_FILEincludeinclude torch/csrc/generic/Storage.h (0) (1)TH/THGenerateFloatTypes.h\n```\n//  TH_GENERIC_FILE\n#include <TH/THGenerateFloatType.h>\n#include <TH/THGenerateDoubleType.h>\n#undef TH_GENERIC_FILE     // TH_GENERIC_FILE \n```\nTH/THGenerateFloatType.h\n```\n#define Real Float\n...\n#line 1 TH_GENERIC_FILE\n#include TH_GENERIC_FILE         // (2)\n...\n#undef Real\n```\n (2) include torch/csrc/generic/Storate.hTH_GENERIC_FILE  (1) \n```\nbool THPStorage_(init)(PyObject *module);  ->\nbool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    ->\nbool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   ->\nbool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); ->\nbool THPFloatStorage_init(PyObject *module);\n```\n#include <TH/THGenerateDoubleType.h>THPDoubleStorage_init\n\n#include <TH/THGenerateIntTypes.h> \n```\nTHPByteStorage_init\nTHPCharStorage_init\nTHPShortStorage_init\nTHPIntStorage_init\nTHPLongStorage_init\n```\n4include\n```\nTHPHalfStorage_init\nTHPBoolStorage_init\nTHPQUInt8Storage_init\nTHPQInt8Storage_init\nTHPQInt32Storage_init\n```\ntorch/csrc/Storage.cpp\n```\n#include <TH/THStorageFunctions.hpp>\n#include <torch/csrc/THP.h>                   // include THPxxxStorage_init \n...\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateAllTypes.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateQTypes.h>\n```\n4include torch/csrc/generic/Storage.cpp\n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.cpp\"              // (11)\n#else\n...                                                                   // (12)\nbool THPStorage_(init)(PyObject *module)\n{\n  static std::vector<PyMethodDef> methods;\n  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));\n#ifndef THD_GENERIC_FILE\n  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);\n#endif\n  \n  THPStorageType.tp_methods = methods.data();\n  THPStorageType.tp_members = THPStorage_(members);\n  THPStorageType.tp_getset = THPStorage_(properties);\n  if (PyType_Ready(&THPStorageType) < 0)\n    return false;\n  Py_INCREF(&THPStorageType);\n  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&THPStorageType);\n  THPStorage_(initCopyMethods)();\n  return true;\n}\n```\nmoduleTHPStorageBaseStr torch/csrc/Storage.h\n```\n#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)\n```\nTH/THGeneral.h\n```\n#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)\n#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y\n```\nStorageBaseReal Int, Float, Double, Short, CharTHPxxxStorage_initReal=FloatTHPStorageBaseStr\"FloatStorageBase\"torch._C FloatStorageBase python class torch._C.FloatStorageBase\n\n4includeinclude torch/csrc/generic/Storage.cppTH_GENERIC_FILE (11)include TH/THGenerateAllTypes.hTH/THGenerateFloatType.h\n```\n#define Real Float\n...\n#include TH_GENERIC_FILE\n```\ninclude torch/csrc/generic/Storage.cppTH_GENERIC_FILE (12) THPFloatStorage_inittorch._C  FloatStorageBase\n\nIntCharByteDoubleHalfQUInt8\n\ntorch/csrc/Module.cppinitModule THCPxxxStorage_init  THPxxxStorage_init  torch/csrc/cuda/Storage.h  torch/csrc/cuda/Storage.cpp \n\ntorch._CFloatStorageBasetorch/csrc/generic/Storage.cpp THPStorageType\n```\nPyTypeObject THPStorageType = {\n  PyVarObject_HEAD_INIT(nullptr, 0)\n  \"torch._C.\" THPStorageBaseStr,               /* tp_name */\n  sizeof(THPStorage),                          /* tp_basicsize */\n  ...\n  THPStorage_(pynew),                          /* tp_new */\n}\n```\npythonFloatStorageBaseC++THPStorage torch/csrc/StorageDef.hTHPStorage\n```\nstruct THPStorage {\n  PyObject_HEAD\n  THWStorage *cdata;\n};\n```\ntorch/csrc/generic/Storage.cpp  THPStoragetorch/csrc/Storage.cppinclude torch/csrc/THP.htorch/csrc/generic/Storage.cpp torch/csrc/THP.h include torch/csrc/Storage.htorch/csrc/Storage.hincludetorch/csrc/generic/Storage.hgeneric/Storage.hinclude torch/csrc/StorageDef.h\n\n THPStorage_(pynew) \n```\nstatic PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)\n{\n  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // \n\n  THPStoragePtr self((THPStorage *)type->tp_alloc(type, 0); // self\n  ...\n  c10::Allocator * allocator = nullptr;\n\n  if (kwargs != nullptr) {                               // named arguments\n    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, \"allocator\"); // allocator\n    if (allocator_ptr) {\n      THPUtils_assert(THPUtils_checkLong(allocator_ptr), \"invalid allocator\");\n      //  c10::Allocator \n      allocator = static_cast<c10::Allocator*>(PyLong_AsVoidPtr(allocator_ptr));\n      PyDict_DelItemString(kwargs, \"allocator\");\n    }\n    Py_ssize_t num_kwargs = PyDict_Size(kwargs);\n    if (num_args == 0) {\n      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, \"cdata\");\n      if (num_kwargs==1 && cdata_ptr && THPUtils_checkLong(cdata_ptr)) {   // cdata\n        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);\n        self->cdata = ptr;\n        return (PyObject*)self.release();       // THPStorage\n      }\n    }\n    THPUtils_assert(num_kwargs == 0, THPStoragePtr \"(): invalid keyword arguments\");\n  }\n\n  if (num_args == 0) {\n    if (allocator) {                            // cdataTHWStorage\n      self->cdata = THPStorage_(newWithAllocator)(0, allocator);\n    } else {\n      self->cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);\n    }\n    return (PyObject*)self.release();\n  }\n  ...     //  self->cdata\n}   \n```\nFloatStorageBase THPStorage.cdataTHWStoragetorch/csrc/THP.h\n```\n#define THWStorage THStorage\n```\n THStorage torch/csrc/Storage.cppinclude\n```\nStorage.cpp                 ->\n#include <TH/TH.h>          ->\n#include <TH/THStorageFunction.h>   ->\n#include <TH/generic/THStorage.h>   ->\n#include <c10/core/StorageImpl.h>\n```\n TH/generic/THStorage.h \n```\n#define THStorage at::StorageImpl\n```\n c10/core/StorageImpl.h \n```\nnamespace c10 {\nstruct C10_API StorageImpl final : public c10::intrusive_ptr_target {\n...\nprivate:\n  caffe2::TypeMeta  data_type_;  // \n  DataPtr data_ptr_;             // \n  int64_t numel_;                // \n  bool resizable_;\n  bool received_cuda_;\n  Allocator* allocator_;         // \n};\n}\n```\nTHWStorage at::StorageImpl THPStorage_(pynew)  cdata THWStorage THWStorage_(NAME)NAME\n```\nnew                // THStorage sizesize=0Allocator\nfree\nsize\nget\nset\ndata\nnewWithSize        // THStorage sizeAllocator\nnewWithAllocator   // THStorage size  Allocator\ncopy_functions\ncopyByte\n...\ncopyCudaByte\n...\n```\n\n```\n#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h\n#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h\n```\nTHStorage_(NAME)  TH/generic/THStorage.hTH/generic/THStorageCopy.h cpp\n\ncuda#define THWStorage_(NAME) THCStorage_(NAME)THC/generic/THCStorage.hTHC/generic/THCStorageCopy.h\n\n THStorage_(newWithSize) TH/generic/THStorage.cpp\n```\nTHStorage* THStorage_(newWithSize)(ptrdiff_t size)\n{\n  THStorage* storage = c10::make_instrusive<at::StorageImpl>(\n#ifdef THQUANTIZED\n    caffe2::TypeMeta::Make<quantized_t>(),\n#else\n    caffe2::TypeMeta::Make<scalar_t>(),        // scalar_t \n#endif\n    size,\n    getTHDefaultAllocator(),\n    true).release();\n  return storage;\n}\n```\nStorageImplintrusive_ptrStorageImplintrusive_ptr  THStorage  at::StorageImplStorageImplc10::make_instrusiveStorageImpl\n```\nStorageImpl(\n    caffe2::TypeMeta data_type,\n    int64_4 numel,\n    at::Allocator* allocator,\n    bool resizable)\n...\n```\nStorageImpl\n\nFloatStorageBaseTH/THGenerateFloatType.h  4include\n```\n#define scalar_t float\n```\n\n```\ncaffe2::TypeMeta::Make<scalar_t>()    //  THQUANTIZED \n```\ncaffe2::TypeMeta::Make caffe2::TypeMeta detail::TypeMetaData* data_new TypeMetaData\n```\n#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\\n  namespace detail {                                                       \\\n  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\\n    _makeTypeMetaDataInstance<T>(_typeName<T>(#T));                        \\\n  }                                                                        \\\n  template<>                                                               \\\n  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                          \\\n    return &C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\\n  }\n  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)\n\n#define C10_CONCATENATE_IMPL(s1,s2) s1##s2\n#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)\n```\n _typeMetaDataInstance\n```\ntemplate<>\nconst detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<T>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<T>(_typeName<T>(#T));\n}\n```\n\n```\n#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\\n  template<>                                                           \\\n  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get<T>() {          \\\n    return TypeIdentifier(PreallocatedId);                             \\\n  }                                                                    \\\n  namespace detail {                                                   \\\n  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\\n    _typeMetaDataInstance_preallocated_,                               \\\n    PreallocatedId);                                                   \\\n  }                                                                    \\\n  template<>                                                           \\\n  inline const detail::TypeMetaData*                                   \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                      \\\n    return &C10_CONCATENATE(                                           \\\n      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\\n  }                                                                    \\\n#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\\n  namespace detail {                                                 \\\n  const TypeMetaData C10_CONCATENATE(                                \\\n    _typeMetaDataInstance_preallocated_,                             \\\n    PreallocatedId) = _makeTypeMetaDataInstance<T>(_typeName<T>(#T));\\\n  }                                                                  \n// \nCAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)\n```\n float\n```\n// \nnamespace detail {\n__attrubyte((__visibility(\"default\"))) extern const TypeMetaData\n_typeMetaDataInstance_preallocated_Preallocated;\n}\n\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_typeMetaDataInstance_preallocated_Preallocated;\n}\n```\nc10/util/typeid.cpp\n```\nCAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)\n```\n\n```\nnamespace detail {                                                 \n  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId\n    = _makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}   \n```\n\n```\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}\n```\ndetail::_makeTypeMetaDataInstanceTypeMetaDataTypeMetaData floatid\n```\nstruct TypeMetaData final {\n// \nusing New = void*();                            // new\nusing PlacementNew = void(void*, size_t);       // new\nusing Copy = void(const void*, void*, size_t);  // \nusing PlacementDelete = void(void*, size_t);\nusing Delete = void(void*);\n... //\n\nsize_t itemsize_;  // \nNew* new_;\nPlacementNew* placementNew_;   //  new\nCopy* copy_;        // \nDelete* delete_;    // \nTypeIdentifier id_; // id\nconst char* name_;  // \n};\n```\nfloatdetail::_makeTypeMetaDataInstance \n```\ntemplate <class T>\ninline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) {\n  return {sizeof(T),                 // T\n          _PickNew<T>(),             //  new T\n          _PickPlacementNew<T>(),\n          _PickCopy<T>(),      \n          _PickPlacementDelete<T>(),\n          _PickDelete<T>(),\n          TypeIdentifier::Get<T>(),  // id\n          typeName};                 // float\"float\"\n```\nstructstruct{}id\n```\nTypeIdentifier::Get<T>()\n```\nCAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE TypeIdentifer(PreallocatedId)floatPreallocatedId6\n\n intdoubleint64_t\n\nPyTorchidid_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCETypeIdentifier::createTypeId()PyTorchid32_CaffeHighestPreallocatedTypeIdid1\n\nTypeMetaDataTypeMetaTypeMetaDataStorageImplTHStorage_(newWithSize)(ptrdiff_t size)StorageImpl\n```\nsize,             // StorageImplTypeMetafloat\ngetTHDefaultAllocator(),  // posix_memalign\ntrue                      // StorageImplresize\n```\nStorageImplTHPStorageStorageImplTHPStorage torch._C FloatStorageBase\n\nfloatTHPStorageIntStorageBase\n\nFloatStorageBasemethods, members, properties generic/Storage.cppTHPStorage_(int)(PyObject* module)\n\n _THNN  _THCUNN  torch._C\n```\n  torch::nn::init_THNN(module);\n#ifdef USE_CUDA\n  torch::nn::init_THCUNN(module);\n#endif\n```\ntorch/csrc/nnTHNN.cppTHCUNN.cpp torch_python TARGET tools/setup_helpers/generate_code.py torch/CMakeLists.txt\n\n`torch._C` `torch/__init__.py` import torch\n\n1.  typenameis_tensoris_storage\n2. torch\n3. _C._init_nametorch/csrc/Module.cpp torchDoubleStorage torch.DoubleStorageFloatStorageHalfStorage\n4. _C._initExtensiontorch/csrc/Module.cpp \n    - layouttorchstridedsparse_coo_mkldnn\n    - torchany_formatpreserve_formatcontiguous_formatchannels_last\n    - torchuint8int8float64float32int32int64int16float16complex32complex64complex128boolqint8quint8qint32torch\n    - python1PyTensorType PyTensorTypeBackendScalarType2torch.tensortypetorch.FloatTensorTensormetaclass3pythonTensortorch.FloatTensor4Tensor torch 5FloatTensorTensor\n    - \n    -  THPxxxStorage_postInit(module)xxxTHPxxxStorage_Init moduletorchtorch._CPython storageFloattorch.FloatStorage\n        ```\n        torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, \n        TH_CONCAT_2(at::k, Real));\n        ```\n         TH_CONCAT_2(at::k, Real)at::kRealReal=Floatat::ScalarType::Float\n        ```\n        AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`\n        ```\n        THPStorageClassback+at::kReal\n\nimport torch \n\n# \nPyTorch","source":"_posts/pytorch/PyTorch-2.md","raw":"---\ntitle: PyTorch-2\np: pytorch/PyTorch-2\ndate: 2019-06-13 10:19:52\ntags: PyTorch\ncategories: DL Framework\n---\n# torch installization\n<!-- more -->\nPyTorchpythonPyTorch\n```\nimport torch\n```\n `torch/__init__.py`torch._CRTLD_GLOBAL|RTLD_LAZYRTLD_GLOBAL|RTLD_LAZYtorch._C\n```\nold_flags=sys.getdlopenflags()\nsys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)\nfrom torch._C import *\n__all__ += [name for name in dir(_C)\n            if name[0] != '_' and\n            not name.endswith('Base')]\nsys.setdlopenflags(old_flags)\n```\n__torch._C_Base__\n\n`__init__.py`import torch._Cimportmodulepackagetorch._C torch._Ctorch/csrc/stub.cppshmtorch_pythonstub.cpp\n```\nextern PyObject* initModule();\nPyMODINIT_FUNC PyInit__C()   // pythonimport _C \n{\n  return initModule();\n}\n```\npython3`import torch._C` PyInit__CPyInit_&lt;package>initModuleinitModuleexterninitModuleshmtorch_python\n\nshmDomain Sockettorch/CMakeLists.txtshm\n```\nset(LIBSHM_SUBDIR libshm)\nset(LIBSHM_SRCDIR ${LIBSHM_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\nshmtorch/lib/libshmtorch._Ctorch_pythoninitModuletorch/CMakeLists.txt\n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\nTORCH_PYTHON_SRCStorch_pythontorch_pythontorch/CMakeLists.txt\n\ninitModuletorch/csrc/Module.cpp\n```\n#ifdef USE_CUDA\nnamespace torch { namespace cuda {\nvoid initModule(PyObject* module);       // cuda\n}}\n#endif\n\nstatic std::vector<PyMethodDef> methods;\n\nPyObject* module;\nPyObject* initModule() {                 // \n  // methods\n  THPUtils_addPyMethodDefs(methods, TorchMethods);\n  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);\n  ...\n  // \n  static struct PyModuleDef torchmodule = {\n    PyModuleDef_HEAD_INIT,\n    \"torch._C\",                          // \n    nullptr,                           \n    -1,\n    methods.data()                       // \n  };\n  ASSERT_TRUE(module = PyModule_Create(&torchmodule)); // \n  // \n#ifdef USE_CUDA\n  torch::cuda::initModule(module);       // cuda\n#endif\n  ...\n  // setter\n  // namevincref\n  // 10\n  auto set_module_attr = [&](const char* name, PyObject* v, bool incref = true) \n  {\n    if(incref) {\n      Py_INCREF(v);\n    }\n    return PyModule_AddObject(module, name, v) == 0;\n  }\n  // \n  ...\n  ASSERT_TRUE(set_module_attr(\"has_cudnn\", has_cudnn));\n  // \n  auto py_module = py::reinterpret_borrow<py::module>(module);\n  py_module.def(\"_demangle\", &c10::demangle);\n  py_module.def(\"_log_api_usage_once\", &LogAPIUsageOnceFromPython);\n  ...    // \n  ASSERT_TRUE(set_module_attr(\"default_generator\", \n        (PyObject*)THPDefaultGenerator, false));\n  torch::nn::init__THNN(module);  //  _THNN \n#ifdef USE_CUDA\n  torch::nn::init_THCUDD(module);\n#endif\n  return module;\n  ...\n}\n```\ntorch._Cattr\n# methods/members in torch._C\n-  THPUtils_addPyMethodDefs torch._C \n```\n# TorchMethods \n_initExtension\n_autograd_init\n...\n# DataLoaderMethods \n_set_worker_signal_handlers\n_set_worker_pids\n...\n# torch::autograd::python_functions(), torch/csrc/autograd/init.cpp\nset_grad_enabled\nis_grad_enabled\nset_anomaly_enabled\nis_anomaly_enabled\n# torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp\n_multiprocessing_init\n# torch::distributed::c10d::python_functions()  \n...\n# THCPModule_method(), torch/csrc/cuda/Module.cpp\n_cuda_init\n_cuda_setDevice\n...\n_nccl_version\n...\n# THCUDNN_method()\n_cudnn_version\n# THDPModule_methods(), torch/csrc/distributed/Module.cpp\n_dist_init_extension\n_dist_init_process_group\n...\n```\n- torch._C \n\n    - torch._C_PtrWrapperGeneratorFatalErrorSizedtypeiinfolayoutmemory_formatdevice_LegacyVariableBase_TensorBase_VariableFunctions_FunctionBase_EngineBaseJITExceptionIODescriptor_THNN_THCUNN\n\n        torch._C._TensorBase\n        ```\n        _cdata\n        _version\n        grad_fn\n        _grad_fn\n        is_leaf\n        data\n        _grad\n        grad\n        ...\n        device\n        ndim\n        ```\n        \n        ```\n        # variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp\n        __add__\n        __radd__\n        ...\n        apply_\n        byte\n        char\n        contiguous\n        ...\n        where\n        zero_\n        # extra_method\n        _make_subclass\n        ```\n        torch._C._FunctionBase \n        ```\n        # method\n        apply\n        _do_forward\n        _do_backward\n        _register_hook_dict\n        register_hook\n        # property\n        saved_tensors\n        saved_variables\n        ...\n        requires_grad\n        metadata\n        ```\n         torch._C._VariableFunctions \n        ```python\n        arange\n        as_tensor\n        ...\n        empty       #  torch.empty\n        empty_like\n        ...\n        ```\n\n        _TensorBaseTensorTensor_FunctionBase\n\n    - torch._C _wrap_tensor_impl_tensor_impl_raw_handle_demangle_log_api_usage_once_jit\n\n    - torch._C _nncpp_onnx\n\n    - torch._C has_cudnnhas_openmphas_mklhas_lapackhas_cudahas_mkldnn_GLIBCXX_USE_CXX11_APIdefault_generator\n\n# some installization w.r.t. torch._C\n### THPxxxStorage_init\ntorch._CTensor THPxxxStorage_init  THCPxxxStorage_init \n\nModule.cpp\n```\n#include <TH/TH.h>               // TH=TorcH\n#include <c10/util/Logging.h>\n#include <ATen/ATen.h>\n...\n#include <torch/csrc/THP.h>      // THP=TorcH Python\n...\n```\nATenc10torchATen [A Tensor Library] Tensorc10 [caffe2ATen] Tensor\n\n TH/TH.h #include <TH/THGeneral.h>aten/src/THCMakeLists.txt\n```\nCONFIGURE_FILE(THGeneral.h.in \"${CMAKE_CURRENT_BINARY_DIR}/THGeneral.h\")\n```\nTHGeneral.h\n```\n#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w\n#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)\n```\ntorch/csrc/THP.h #include <torch/src/Storage.h>Storage.h\n```\n#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)\n...\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateAllType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateQTypes.h>\n```\n4include/include torch/csrc/generic/Storage.htorch/csrc/generic/Storage.h \n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.h\"         // (0)\n#else\n...\nbool THPStorage_(init)(PyObject *module);                      // (1)\n...\n#endif\n```\nTH/THGenerateAllType.h\n```\n#include <TH/THGenerateFloatTypes.h>\n#include <TH/THGenerateIntTypes.h>\n...\n#undef TH_GENERIC_FILE\n```\n4includeinclude#undef TH_GENERIC_FILEincludeinclude torch/csrc/generic/Storage.h (0) (1)TH/THGenerateFloatTypes.h\n```\n//  TH_GENERIC_FILE\n#include <TH/THGenerateFloatType.h>\n#include <TH/THGenerateDoubleType.h>\n#undef TH_GENERIC_FILE     // TH_GENERIC_FILE \n```\nTH/THGenerateFloatType.h\n```\n#define Real Float\n...\n#line 1 TH_GENERIC_FILE\n#include TH_GENERIC_FILE         // (2)\n...\n#undef Real\n```\n (2) include torch/csrc/generic/Storate.hTH_GENERIC_FILE  (1) \n```\nbool THPStorage_(init)(PyObject *module);  ->\nbool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    ->\nbool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   ->\nbool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); ->\nbool THPFloatStorage_init(PyObject *module);\n```\n#include <TH/THGenerateDoubleType.h>THPDoubleStorage_init\n\n#include <TH/THGenerateIntTypes.h> \n```\nTHPByteStorage_init\nTHPCharStorage_init\nTHPShortStorage_init\nTHPIntStorage_init\nTHPLongStorage_init\n```\n4include\n```\nTHPHalfStorage_init\nTHPBoolStorage_init\nTHPQUInt8Storage_init\nTHPQInt8Storage_init\nTHPQInt32Storage_init\n```\ntorch/csrc/Storage.cpp\n```\n#include <TH/THStorageFunctions.hpp>\n#include <torch/csrc/THP.h>                   // include THPxxxStorage_init \n...\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateAllTypes.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateQTypes.h>\n```\n4include torch/csrc/generic/Storage.cpp\n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.cpp\"              // (11)\n#else\n...                                                                   // (12)\nbool THPStorage_(init)(PyObject *module)\n{\n  static std::vector<PyMethodDef> methods;\n  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));\n#ifndef THD_GENERIC_FILE\n  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);\n#endif\n  \n  THPStorageType.tp_methods = methods.data();\n  THPStorageType.tp_members = THPStorage_(members);\n  THPStorageType.tp_getset = THPStorage_(properties);\n  if (PyType_Ready(&THPStorageType) < 0)\n    return false;\n  Py_INCREF(&THPStorageType);\n  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&THPStorageType);\n  THPStorage_(initCopyMethods)();\n  return true;\n}\n```\nmoduleTHPStorageBaseStr torch/csrc/Storage.h\n```\n#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)\n```\nTH/THGeneral.h\n```\n#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)\n#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y\n```\nStorageBaseReal Int, Float, Double, Short, CharTHPxxxStorage_initReal=FloatTHPStorageBaseStr\"FloatStorageBase\"torch._C FloatStorageBase python class torch._C.FloatStorageBase\n\n4includeinclude torch/csrc/generic/Storage.cppTH_GENERIC_FILE (11)include TH/THGenerateAllTypes.hTH/THGenerateFloatType.h\n```\n#define Real Float\n...\n#include TH_GENERIC_FILE\n```\ninclude torch/csrc/generic/Storage.cppTH_GENERIC_FILE (12) THPFloatStorage_inittorch._C  FloatStorageBase\n\nIntCharByteDoubleHalfQUInt8\n\ntorch/csrc/Module.cppinitModule THCPxxxStorage_init  THPxxxStorage_init  torch/csrc/cuda/Storage.h  torch/csrc/cuda/Storage.cpp \n\ntorch._CFloatStorageBasetorch/csrc/generic/Storage.cpp THPStorageType\n```\nPyTypeObject THPStorageType = {\n  PyVarObject_HEAD_INIT(nullptr, 0)\n  \"torch._C.\" THPStorageBaseStr,               /* tp_name */\n  sizeof(THPStorage),                          /* tp_basicsize */\n  ...\n  THPStorage_(pynew),                          /* tp_new */\n}\n```\npythonFloatStorageBaseC++THPStorage torch/csrc/StorageDef.hTHPStorage\n```\nstruct THPStorage {\n  PyObject_HEAD\n  THWStorage *cdata;\n};\n```\ntorch/csrc/generic/Storage.cpp  THPStoragetorch/csrc/Storage.cppinclude torch/csrc/THP.htorch/csrc/generic/Storage.cpp torch/csrc/THP.h include torch/csrc/Storage.htorch/csrc/Storage.hincludetorch/csrc/generic/Storage.hgeneric/Storage.hinclude torch/csrc/StorageDef.h\n\n THPStorage_(pynew) \n```\nstatic PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)\n{\n  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // \n\n  THPStoragePtr self((THPStorage *)type->tp_alloc(type, 0); // self\n  ...\n  c10::Allocator * allocator = nullptr;\n\n  if (kwargs != nullptr) {                               // named arguments\n    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, \"allocator\"); // allocator\n    if (allocator_ptr) {\n      THPUtils_assert(THPUtils_checkLong(allocator_ptr), \"invalid allocator\");\n      //  c10::Allocator \n      allocator = static_cast<c10::Allocator*>(PyLong_AsVoidPtr(allocator_ptr));\n      PyDict_DelItemString(kwargs, \"allocator\");\n    }\n    Py_ssize_t num_kwargs = PyDict_Size(kwargs);\n    if (num_args == 0) {\n      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, \"cdata\");\n      if (num_kwargs==1 && cdata_ptr && THPUtils_checkLong(cdata_ptr)) {   // cdata\n        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);\n        self->cdata = ptr;\n        return (PyObject*)self.release();       // THPStorage\n      }\n    }\n    THPUtils_assert(num_kwargs == 0, THPStoragePtr \"(): invalid keyword arguments\");\n  }\n\n  if (num_args == 0) {\n    if (allocator) {                            // cdataTHWStorage\n      self->cdata = THPStorage_(newWithAllocator)(0, allocator);\n    } else {\n      self->cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);\n    }\n    return (PyObject*)self.release();\n  }\n  ...     //  self->cdata\n}   \n```\nFloatStorageBase THPStorage.cdataTHWStoragetorch/csrc/THP.h\n```\n#define THWStorage THStorage\n```\n THStorage torch/csrc/Storage.cppinclude\n```\nStorage.cpp                 ->\n#include <TH/TH.h>          ->\n#include <TH/THStorageFunction.h>   ->\n#include <TH/generic/THStorage.h>   ->\n#include <c10/core/StorageImpl.h>\n```\n TH/generic/THStorage.h \n```\n#define THStorage at::StorageImpl\n```\n c10/core/StorageImpl.h \n```\nnamespace c10 {\nstruct C10_API StorageImpl final : public c10::intrusive_ptr_target {\n...\nprivate:\n  caffe2::TypeMeta  data_type_;  // \n  DataPtr data_ptr_;             // \n  int64_t numel_;                // \n  bool resizable_;\n  bool received_cuda_;\n  Allocator* allocator_;         // \n};\n}\n```\nTHWStorage at::StorageImpl THPStorage_(pynew)  cdata THWStorage THWStorage_(NAME)NAME\n```\nnew                // THStorage sizesize=0Allocator\nfree\nsize\nget\nset\ndata\nnewWithSize        // THStorage sizeAllocator\nnewWithAllocator   // THStorage size  Allocator\ncopy_functions\ncopyByte\n...\ncopyCudaByte\n...\n```\n\n```\n#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h\n#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h\n```\nTHStorage_(NAME)  TH/generic/THStorage.hTH/generic/THStorageCopy.h cpp\n\ncuda#define THWStorage_(NAME) THCStorage_(NAME)THC/generic/THCStorage.hTHC/generic/THCStorageCopy.h\n\n THStorage_(newWithSize) TH/generic/THStorage.cpp\n```\nTHStorage* THStorage_(newWithSize)(ptrdiff_t size)\n{\n  THStorage* storage = c10::make_instrusive<at::StorageImpl>(\n#ifdef THQUANTIZED\n    caffe2::TypeMeta::Make<quantized_t>(),\n#else\n    caffe2::TypeMeta::Make<scalar_t>(),        // scalar_t \n#endif\n    size,\n    getTHDefaultAllocator(),\n    true).release();\n  return storage;\n}\n```\nStorageImplintrusive_ptrStorageImplintrusive_ptr  THStorage  at::StorageImplStorageImplc10::make_instrusiveStorageImpl\n```\nStorageImpl(\n    caffe2::TypeMeta data_type,\n    int64_4 numel,\n    at::Allocator* allocator,\n    bool resizable)\n...\n```\nStorageImpl\n\nFloatStorageBaseTH/THGenerateFloatType.h  4include\n```\n#define scalar_t float\n```\n\n```\ncaffe2::TypeMeta::Make<scalar_t>()    //  THQUANTIZED \n```\ncaffe2::TypeMeta::Make caffe2::TypeMeta detail::TypeMetaData* data_new TypeMetaData\n```\n#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\\n  namespace detail {                                                       \\\n  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\\n    _makeTypeMetaDataInstance<T>(_typeName<T>(#T));                        \\\n  }                                                                        \\\n  template<>                                                               \\\n  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                          \\\n    return &C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\\n  }\n  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)\n\n#define C10_CONCATENATE_IMPL(s1,s2) s1##s2\n#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)\n```\n _typeMetaDataInstance\n```\ntemplate<>\nconst detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<T>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<T>(_typeName<T>(#T));\n}\n```\n\n```\n#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\\n  template<>                                                           \\\n  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get<T>() {          \\\n    return TypeIdentifier(PreallocatedId);                             \\\n  }                                                                    \\\n  namespace detail {                                                   \\\n  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\\n    _typeMetaDataInstance_preallocated_,                               \\\n    PreallocatedId);                                                   \\\n  }                                                                    \\\n  template<>                                                           \\\n  inline const detail::TypeMetaData*                                   \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                      \\\n    return &C10_CONCATENATE(                                           \\\n      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\\n  }                                                                    \\\n#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\\n  namespace detail {                                                 \\\n  const TypeMetaData C10_CONCATENATE(                                \\\n    _typeMetaDataInstance_preallocated_,                             \\\n    PreallocatedId) = _makeTypeMetaDataInstance<T>(_typeName<T>(#T));\\\n  }                                                                  \n// \nCAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)\n```\n float\n```\n// \nnamespace detail {\n__attrubyte((__visibility(\"default\"))) extern const TypeMetaData\n_typeMetaDataInstance_preallocated_Preallocated;\n}\n\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_typeMetaDataInstance_preallocated_Preallocated;\n}\n```\nc10/util/typeid.cpp\n```\nCAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)\n```\n\n```\nnamespace detail {                                                 \n  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId\n    = _makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}   \n```\n\n```\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}\n```\ndetail::_makeTypeMetaDataInstanceTypeMetaDataTypeMetaData floatid\n```\nstruct TypeMetaData final {\n// \nusing New = void*();                            // new\nusing PlacementNew = void(void*, size_t);       // new\nusing Copy = void(const void*, void*, size_t);  // \nusing PlacementDelete = void(void*, size_t);\nusing Delete = void(void*);\n... //\n\nsize_t itemsize_;  // \nNew* new_;\nPlacementNew* placementNew_;   //  new\nCopy* copy_;        // \nDelete* delete_;    // \nTypeIdentifier id_; // id\nconst char* name_;  // \n};\n```\nfloatdetail::_makeTypeMetaDataInstance \n```\ntemplate <class T>\ninline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) {\n  return {sizeof(T),                 // T\n          _PickNew<T>(),             //  new T\n          _PickPlacementNew<T>(),\n          _PickCopy<T>(),      \n          _PickPlacementDelete<T>(),\n          _PickDelete<T>(),\n          TypeIdentifier::Get<T>(),  // id\n          typeName};                 // float\"float\"\n```\nstructstruct{}id\n```\nTypeIdentifier::Get<T>()\n```\nCAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE TypeIdentifer(PreallocatedId)floatPreallocatedId6\n\n intdoubleint64_t\n\nPyTorchidid_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCETypeIdentifier::createTypeId()PyTorchid32_CaffeHighestPreallocatedTypeIdid1\n\nTypeMetaDataTypeMetaTypeMetaDataStorageImplTHStorage_(newWithSize)(ptrdiff_t size)StorageImpl\n```\nsize,             // StorageImplTypeMetafloat\ngetTHDefaultAllocator(),  // posix_memalign\ntrue                      // StorageImplresize\n```\nStorageImplTHPStorageStorageImplTHPStorage torch._C FloatStorageBase\n\nfloatTHPStorageIntStorageBase\n\nFloatStorageBasemethods, members, properties generic/Storage.cppTHPStorage_(int)(PyObject* module)\n\n _THNN  _THCUNN  torch._C\n```\n  torch::nn::init_THNN(module);\n#ifdef USE_CUDA\n  torch::nn::init_THCUNN(module);\n#endif\n```\ntorch/csrc/nnTHNN.cppTHCUNN.cpp torch_python TARGET tools/setup_helpers/generate_code.py torch/CMakeLists.txt\n\n`torch._C` `torch/__init__.py` import torch\n\n1.  typenameis_tensoris_storage\n2. torch\n3. _C._init_nametorch/csrc/Module.cpp torchDoubleStorage torch.DoubleStorageFloatStorageHalfStorage\n4. _C._initExtensiontorch/csrc/Module.cpp \n    - layouttorchstridedsparse_coo_mkldnn\n    - torchany_formatpreserve_formatcontiguous_formatchannels_last\n    - torchuint8int8float64float32int32int64int16float16complex32complex64complex128boolqint8quint8qint32torch\n    - python1PyTensorType PyTensorTypeBackendScalarType2torch.tensortypetorch.FloatTensorTensormetaclass3pythonTensortorch.FloatTensor4Tensor torch 5FloatTensorTensor\n    - \n    -  THPxxxStorage_postInit(module)xxxTHPxxxStorage_Init moduletorchtorch._CPython storageFloattorch.FloatStorage\n        ```\n        torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, \n        TH_CONCAT_2(at::k, Real));\n        ```\n         TH_CONCAT_2(at::k, Real)at::kRealReal=Floatat::ScalarType::Float\n        ```\n        AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`\n        ```\n        THPStorageClassback+at::kReal\n\nimport torch \n\n# \nPyTorch","slug":"pytorch/PyTorch-2","published":1,"updated":"2020-04-24T10:34:28.998Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92d0058p0dj4xjrgm8c","content":"<h1 id=\"torch-installization\"><a href=\"#torch-installization\" class=\"headerlink\" title=\"torch installization\"></a>torch installization</h1><span id=\"more\"></span>\n<p>PyTorchpythonPyTorch<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import torch</span><br></pre></td></tr></table></figure><br> <code>torch/__init__.py</code>torch._CRTLD_GLOBAL|RTLD_LAZYRTLD_GLOBAL|RTLD_LAZYtorch._C<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">old_flags=sys.getdlopenflags()</span><br><span class=\"line\">sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)</span><br><span class=\"line\">from torch._C import *</span><br><span class=\"line\">__all__ += [name for name in dir(_C)</span><br><span class=\"line\">            if name[0] != &#x27;_&#x27; and</span><br><span class=\"line\">            not name.endswith(&#x27;Base&#x27;)]</span><br><span class=\"line\">sys.setdlopenflags(old_flags)</span><br></pre></td></tr></table></figure><br><strong>torch._C_Base</strong></p>\n<p><code>__init__.py</code>import torch._Cimportmodulepackagetorch._C torch._Ctorch/csrc/stub.cppshmtorch_pythonstub.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">extern PyObject* initModule();</span><br><span class=\"line\">PyMODINIT_FUNC PyInit__C()   // pythonimport _C </span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  return initModule();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>python3<code>import torch._C</code> PyInit__CPyInit_&lt;package&gt;initModuleinitModuleexterninitModuleshmtorch_python</p>\n<p>shmDomain Sockettorch/CMakeLists.txtshm<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM_SUBDIR libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure><br>shmtorch/lib/libshmtorch._Ctorch_pythoninitModuletorch/CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure><br>TORCH_PYTHON_SRCStorch_pythontorch_pythontorch/CMakeLists.txt</p>\n<p>initModuletorch/csrc/Module.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">namespace torch &#123; namespace cuda &#123;</span><br><span class=\"line\">void initModule(PyObject* module);       // cuda</span><br><span class=\"line\">&#125;&#125;</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\"></span><br><span class=\"line\">PyObject* module;</span><br><span class=\"line\">PyObject* initModule() &#123;                 // </span><br><span class=\"line\">  // methods</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // </span><br><span class=\"line\">  static struct PyModuleDef torchmodule = &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    &quot;torch._C&quot;,                          // </span><br><span class=\"line\">    nullptr,                           </span><br><span class=\"line\">    -1,</span><br><span class=\"line\">    methods.data()                       // </span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">  ASSERT_TRUE(module = PyModule_Create(&amp;torchmodule)); // </span><br><span class=\"line\">  // </span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::cuda::initModule(module);       // cuda</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // setter</span><br><span class=\"line\">  // namevincref</span><br><span class=\"line\">  // 10</span><br><span class=\"line\">  auto set_module_attr = [&amp;](const char* name, PyObject* v, bool incref = true) </span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    if(incref) &#123;</span><br><span class=\"line\">      Py_INCREF(v);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return PyModule_AddObject(module, name, v) == 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // </span><br><span class=\"line\">  ...</span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));</span><br><span class=\"line\">  // </span><br><span class=\"line\">  auto py_module = py::reinterpret_borrow&lt;py::module&gt;(module);</span><br><span class=\"line\">  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);</span><br><span class=\"line\">  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);</span><br><span class=\"line\">  ...    // </span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;, </span><br><span class=\"line\">        (PyObject*)THPDefaultGenerator, false));</span><br><span class=\"line\">  torch::nn::init__THNN(module);  //  _THNN </span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUDD(module);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  return module;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>torch._Cattr</p>\n<h1 id=\"methods-members-in-torch-C\"><a href=\"#methods-members-in-torch-C\" class=\"headerlink\" title=\"methods/members in torch._C\"></a>methods/members in torch._C</h1><ul>\n<li> THPUtils_addPyMethodDefs torch._C <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># TorchMethods </span><br><span class=\"line\">_initExtension</span><br><span class=\"line\">_autograd_init</span><br><span class=\"line\">...</span><br><span class=\"line\"># DataLoaderMethods </span><br><span class=\"line\">_set_worker_signal_handlers</span><br><span class=\"line\">_set_worker_pids</span><br><span class=\"line\">...</span><br><span class=\"line\"># torch::autograd::python_functions(), torch/csrc/autograd/init.cpp</span><br><span class=\"line\">set_grad_enabled</span><br><span class=\"line\">is_grad_enabled</span><br><span class=\"line\">set_anomaly_enabled</span><br><span class=\"line\">is_anomaly_enabled</span><br><span class=\"line\"># torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp</span><br><span class=\"line\">_multiprocessing_init</span><br><span class=\"line\"># torch::distributed::c10d::python_functions()  </span><br><span class=\"line\">...</span><br><span class=\"line\"># THCPModule_method(), torch/csrc/cuda/Module.cpp</span><br><span class=\"line\">_cuda_init</span><br><span class=\"line\">_cuda_setDevice</span><br><span class=\"line\">...</span><br><span class=\"line\">_nccl_version</span><br><span class=\"line\">...</span><br><span class=\"line\"># THCUDNN_method()</span><br><span class=\"line\">_cudnn_version</span><br><span class=\"line\"># THDPModule_methods(), torch/csrc/distributed/Module.cpp</span><br><span class=\"line\">_dist_init_extension</span><br><span class=\"line\">_dist_init_process_group</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></li>\n<li><p>torch._C </p>\n<ul>\n<li><p>torch._C_PtrWrapperGeneratorFatalErrorSizedtypeiinfolayoutmemory_formatdevice_LegacyVariableBase_TensorBase_VariableFunctions_FunctionBase_EngineBaseJITExceptionIODescriptor_THNN_THCUNN</p>\n<p>  torch._C._TensorBase</p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_cdata</span><br><span class=\"line\">_version</span><br><span class=\"line\">grad_fn</span><br><span class=\"line\">_grad_fn</span><br><span class=\"line\">is_leaf</span><br><span class=\"line\">data</span><br><span class=\"line\">_grad</span><br><span class=\"line\">grad</span><br><span class=\"line\">...</span><br><span class=\"line\">device</span><br><span class=\"line\">ndim</span><br></pre></td></tr></table></figure>\n<p>  </p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp</span><br><span class=\"line\">__add__</span><br><span class=\"line\">__radd__</span><br><span class=\"line\">...</span><br><span class=\"line\">apply_</span><br><span class=\"line\">byte</span><br><span class=\"line\">char</span><br><span class=\"line\">contiguous</span><br><span class=\"line\">...</span><br><span class=\"line\">where</span><br><span class=\"line\">zero_</span><br><span class=\"line\"># extra_method</span><br><span class=\"line\">_make_subclass</span><br></pre></td></tr></table></figure>\n<p>  torch._C._FunctionBase </p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># method</span><br><span class=\"line\">apply</span><br><span class=\"line\">_do_forward</span><br><span class=\"line\">_do_backward</span><br><span class=\"line\">_register_hook_dict</span><br><span class=\"line\">register_hook</span><br><span class=\"line\"># property</span><br><span class=\"line\">saved_tensors</span><br><span class=\"line\">saved_variables</span><br><span class=\"line\">...</span><br><span class=\"line\">requires_grad</span><br><span class=\"line\">metadata</span><br></pre></td></tr></table></figure>\n<p>   torch._C._VariableFunctions </p>\n  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">arange</span><br><span class=\"line\">as_tensor</span><br><span class=\"line\">...</span><br><span class=\"line\">empty       <span class=\"comment\">#  torch.empty</span></span><br><span class=\"line\">empty_like</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>  _TensorBaseTensorTensor_FunctionBase</p>\n</li>\n<li><p>torch._C _wrap_tensor_impl_tensor_impl_raw_handle_demangle_log_api_usage_once_jit</p>\n</li>\n<li><p>torch._C _nncpp_onnx</p>\n</li>\n<li><p>torch._C has_cudnnhas_openmphas_mklhas_lapackhas_cudahas_mkldnn_GLIBCXX_USE_CXX11_APIdefault_generator</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"some-installization-w-r-t-torch-C\"><a href=\"#some-installization-w-r-t-torch-C\" class=\"headerlink\" title=\"some installization w.r.t. torch._C\"></a>some installization w.r.t. torch._C</h1><h3 id=\"THPxxxStorage-init\"><a href=\"#THPxxxStorage-init\" class=\"headerlink\" title=\"THPxxxStorage_init\"></a>THPxxxStorage_init</h3><p>torch._CTensor THPxxxStorage_init  THCPxxxStorage_init </p>\n<p>Module.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/TH.h&gt;               // TH=TorcH</span><br><span class=\"line\">#include &lt;c10/util/Logging.h&gt;</span><br><span class=\"line\">#include &lt;ATen/ATen.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;      // THP=TorcH Python</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br>ATenc10torchATen [A Tensor Library] Tensorc10 [caffe2ATen] Tensor</p>\n<p> TH/TH.h #include <TH/THGeneral.h>aten/src/THCMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/THGeneral.h&quot;)</span><br></pre></td></tr></table></figure><br>THGeneral.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w</span><br><span class=\"line\">#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)</span><br></pre></td></tr></table></figure><br>torch/csrc/THP.h #include <torch/src/Storage.h>Storage.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure><br>4include/include torch/csrc/generic/Storage.htorch/csrc/generic/Storage.h <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.h&quot;         // (0)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module);                      // (1)</span><br><span class=\"line\">...</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure><br>TH/THGenerateAllType.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THGenerateFloatTypes.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateIntTypes.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef TH_GENERIC_FILE</span><br></pre></td></tr></table></figure><br>4includeinclude#undef TH_GENERIC_FILEincludeinclude torch/csrc/generic/Storage.h (0) (1)TH/THGenerateFloatTypes.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//  TH_GENERIC_FILE</span><br><span class=\"line\">#include &lt;TH/THGenerateFloatType.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateDoubleType.h&gt;</span><br><span class=\"line\">#undef TH_GENERIC_FILE     // TH_GENERIC_FILE </span><br></pre></td></tr></table></figure><br>TH/THGenerateFloatType.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#line 1 TH_GENERIC_FILE</span><br><span class=\"line\">#include TH_GENERIC_FILE         // (2)</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef Real</span><br></pre></td></tr></table></figure><br> (2) include torch/csrc/generic/Storate.hTH_GENERIC_FILE  (1) <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool THPStorage_(init)(PyObject *module);  -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;</span><br><span class=\"line\">bool THPFloatStorage_init(PyObject *module);</span><br></pre></td></tr></table></figure><br>#include <TH/THGenerateDoubleType.h>THPDoubleStorage_init</p>\n<h1 id=\"include-\"><a href=\"#include-\" class=\"headerlink\" title=\"include  \"></a>include <TH/THGenerateIntTypes.h> </h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPByteStorage_init</span><br><span class=\"line\">THPCharStorage_init</span><br><span class=\"line\">THPShortStorage_init</span><br><span class=\"line\">THPIntStorage_init</span><br><span class=\"line\">THPLongStorage_init</span><br></pre></td></tr></table></figure>\n<p>4include<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPHalfStorage_init</span><br><span class=\"line\">THPBoolStorage_init</span><br><span class=\"line\">THPQUInt8Storage_init</span><br><span class=\"line\">THPQInt8Storage_init</span><br><span class=\"line\">THPQInt32Storage_init</span><br></pre></td></tr></table></figure><br>torch/csrc/Storage.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THStorageFunctions.hpp&gt;</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;                   // include THPxxxStorage_init </span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllTypes.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure><br>4include torch/csrc/generic/Storage.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.cpp&quot;              // (11)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...                                                                   // (12)</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class=\"line\">#ifndef THD_GENERIC_FILE</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  </span><br><span class=\"line\">  THPStorageType.tp_methods = methods.data();</span><br><span class=\"line\">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class=\"line\">  THPStorageType.tp_getset = THPStorage_(properties);</span><br><span class=\"line\">  if (PyType_Ready(&amp;THPStorageType) &lt; 0)</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  Py_INCREF(&amp;THPStorageType);</span><br><span class=\"line\">  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);</span><br><span class=\"line\">  THPStorage_(initCopyMethods)();</span><br><span class=\"line\">  return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>moduleTHPStorageBaseStr torch/csrc/Storage.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)</span><br></pre></td></tr></table></figure><br>TH/THGeneral.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)</span><br><span class=\"line\">#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y</span><br></pre></td></tr></table></figure><br>StorageBaseReal Int, Float, Double, Short, CharTHPxxxStorage_initReal=FloatTHPStorageBaseStrFloatStorageBasetorch._C FloatStorageBase python class torch._C.FloatStorageBase</p>\n<p>4includeinclude torch/csrc/generic/Storage.cppTH_GENERIC_FILE (11)include TH/THGenerateAllTypes.hTH/THGenerateFloatType.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#include TH_GENERIC_FILE</span><br></pre></td></tr></table></figure><br>include torch/csrc/generic/Storage.cppTH_GENERIC_FILE (12) THPFloatStorage_inittorch._C  FloatStorageBase</p>\n<p>IntCharByteDoubleHalfQUInt8</p>\n<p>torch/csrc/Module.cppinitModule THCPxxxStorage_init  THPxxxStorage_init  torch/csrc/cuda/Storage.h  torch/csrc/cuda/Storage.cpp </p>\n<p>torch._CFloatStorageBasetorch/csrc/generic/Storage.cpp THPStorageType<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyTypeObject THPStorageType = &#123;</span><br><span class=\"line\">  PyVarObject_HEAD_INIT(nullptr, 0)</span><br><span class=\"line\">  &quot;torch._C.&quot; THPStorageBaseStr,               /* tp_name */</span><br><span class=\"line\">  sizeof(THPStorage),                          /* tp_basicsize */</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  THPStorage_(pynew),                          /* tp_new */</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>pythonFloatStorageBaseC++THPStorage torch/csrc/StorageDef.hTHPStorage<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct THPStorage &#123;</span><br><span class=\"line\">  PyObject_HEAD</span><br><span class=\"line\">  THWStorage *cdata;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>torch/csrc/generic/Storage.cpp  THPStoragetorch/csrc/Storage.cppinclude torch/csrc/THP.htorch/csrc/generic/Storage.cpp torch/csrc/THP.h include torch/csrc/Storage.htorch/csrc/Storage.hincludetorch/csrc/generic/Storage.hgeneric/Storage.hinclude torch/csrc/StorageDef.h</p>\n<p> THPStorage_(pynew) <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // </span><br><span class=\"line\"></span><br><span class=\"line\">  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); // self</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  c10::Allocator * allocator = nullptr;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (kwargs != nullptr) &#123;                               // named arguments</span><br><span class=\"line\">    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, &quot;allocator&quot;); // allocator</span><br><span class=\"line\">    if (allocator_ptr) &#123;</span><br><span class=\"line\">      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);</span><br><span class=\"line\">      //  c10::Allocator </span><br><span class=\"line\">      allocator = static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));</span><br><span class=\"line\">      PyDict_DelItemString(kwargs, &quot;allocator&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Py_ssize_t num_kwargs = PyDict_Size(kwargs);</span><br><span class=\"line\">    if (num_args == 0) &#123;</span><br><span class=\"line\">      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, &quot;cdata&quot;);</span><br><span class=\"line\">      if (num_kwargs==1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   // cdata</span><br><span class=\"line\">        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);</span><br><span class=\"line\">        self-&gt;cdata = ptr;</span><br><span class=\"line\">        return (PyObject*)self.release();       // THPStorage</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    THPUtils_assert(num_kwargs == 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (num_args == 0) &#123;</span><br><span class=\"line\">    if (allocator) &#123;                            // cdataTHWStorage</span><br><span class=\"line\">      self-&gt;cdata = THPStorage_(newWithAllocator)(0, allocator);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      self-&gt;cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return (PyObject*)self.release();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...     //  self-&gt;cdata</span><br><span class=\"line\">&#125;   </span><br></pre></td></tr></table></figure><br>FloatStorageBase THPStorage.cdataTHWStoragetorch/csrc/THP.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage THStorage</span><br></pre></td></tr></table></figure><br> THStorage torch/csrc/Storage.cppinclude<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Storage.cpp                 -&gt;</span><br><span class=\"line\">#include &lt;TH/TH.h&gt;          -&gt;</span><br><span class=\"line\">#include &lt;TH/THStorageFunction.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;TH/generic/THStorage.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;c10/core/StorageImpl.h&gt;</span><br></pre></td></tr></table></figure><br> TH/generic/THStorage.h <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THStorage at::StorageImpl</span><br></pre></td></tr></table></figure><br> c10/core/StorageImpl.h <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace c10 &#123;</span><br><span class=\"line\">struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">private:</span><br><span class=\"line\">  caffe2::TypeMeta  data_type_;  // </span><br><span class=\"line\">  DataPtr data_ptr_;             // </span><br><span class=\"line\">  int64_t numel_;                // </span><br><span class=\"line\">  bool resizable_;</span><br><span class=\"line\">  bool received_cuda_;</span><br><span class=\"line\">  Allocator* allocator_;         // </span><br><span class=\"line\">&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>THWStorage at::StorageImpl THPStorage_(pynew)  cdata THWStorage THWStorage_(NAME)NAME<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">new                // THStorage sizesize=0Allocator</span><br><span class=\"line\">free</span><br><span class=\"line\">size</span><br><span class=\"line\">get</span><br><span class=\"line\">set</span><br><span class=\"line\">data</span><br><span class=\"line\">newWithSize        // THStorage sizeAllocator</span><br><span class=\"line\">newWithAllocator   // THStorage size  Allocator</span><br><span class=\"line\">copy_functions</span><br><span class=\"line\">copyByte</span><br><span class=\"line\">...</span><br><span class=\"line\">copyCudaByte</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h</span><br><span class=\"line\">#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h</span><br></pre></td></tr></table></figure><br>THStorage_(NAME)  TH/generic/THStorage.hTH/generic/THStorageCopy.h cpp</p>\n<p>cuda#define THWStorage_(NAME) THCStorage_(NAME)THC/generic/THCStorage.hTHC/generic/THCStorageCopy.h</p>\n<p> THStorage_(newWithSize) TH/generic/THStorage.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THStorage* THStorage_(newWithSize)(ptrdiff_t size)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  THStorage* storage = c10::make_instrusive&lt;at::StorageImpl&gt;(</span><br><span class=\"line\">#ifdef THQUANTIZED</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),</span><br><span class=\"line\">#else</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        // scalar_t </span><br><span class=\"line\">#endif</span><br><span class=\"line\">    size,</span><br><span class=\"line\">    getTHDefaultAllocator(),</span><br><span class=\"line\">    true).release();</span><br><span class=\"line\">  return storage;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>StorageImplintrusive_ptrStorageImplintrusive_ptr  THStorage  at::StorageImplStorageImplc10::make_instrusiveStorageImpl<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StorageImpl(</span><br><span class=\"line\">    caffe2::TypeMeta data_type,</span><br><span class=\"line\">    int64_4 numel,</span><br><span class=\"line\">    at::Allocator* allocator,</span><br><span class=\"line\">    bool resizable)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br>StorageImpl</p>\n<p>FloatStorageBaseTH/THGenerateFloatType.h  4include<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define scalar_t float</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    //  THQUANTIZED </span><br></pre></td></tr></table></figure><br>caffe2::TypeMeta::Make caffe2::TypeMeta detail::TypeMetaData* data_new TypeMetaData<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\</span><br><span class=\"line\">  namespace detail &#123;                                                       \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\</span><br><span class=\"line\">    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \\</span><br><span class=\"line\">  &#125;                                                                        \\</span><br><span class=\"line\">  template&lt;&gt;                                                               \\</span><br><span class=\"line\">  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)</span><br><span class=\"line\"></span><br><span class=\"line\">#define C10_CONCATENATE_IMPL(s1,s2) s1##s2</span><br><span class=\"line\">#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)</span><br></pre></td></tr></table></figure><br> _typeMetaDataInstance<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \\</span><br><span class=\"line\">    return TypeIdentifier(PreallocatedId);                             \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  namespace detail &#123;                                                   \\</span><br><span class=\"line\">  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                               \\</span><br><span class=\"line\">    PreallocatedId);                                                   \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline const detail::TypeMetaData*                                   \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(                                           \\</span><br><span class=\"line\">      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\</span><br><span class=\"line\">  namespace detail &#123;                                                 \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(                                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                             \\</span><br><span class=\"line\">    PreallocatedId) = _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\\</span><br><span class=\"line\">  &#125;                                                                  </span><br><span class=\"line\">// </span><br><span class=\"line\">CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)</span><br></pre></td></tr></table></figure><br> float<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// </span><br><span class=\"line\">namespace detail &#123;</span><br><span class=\"line\">__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData</span><br><span class=\"line\">_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>c10/util/typeid.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace detail &#123;                                                 </span><br><span class=\"line\">  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId</span><br><span class=\"line\">    = _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;   </span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>detail::_makeTypeMetaDataInstanceTypeMetaDataTypeMetaData floatid<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct TypeMetaData final &#123;</span><br><span class=\"line\">// </span><br><span class=\"line\">using New = void*();                            // new</span><br><span class=\"line\">using PlacementNew = void(void*, size_t);       // new</span><br><span class=\"line\">using Copy = void(const void*, void*, size_t);  // </span><br><span class=\"line\">using PlacementDelete = void(void*, size_t);</span><br><span class=\"line\">using Delete = void(void*);</span><br><span class=\"line\">... //</span><br><span class=\"line\"></span><br><span class=\"line\">size_t itemsize_;  // </span><br><span class=\"line\">New* new_;</span><br><span class=\"line\">PlacementNew* placementNew_;   //  new</span><br><span class=\"line\">Copy* copy_;        // </span><br><span class=\"line\">Delete* delete_;    // </span><br><span class=\"line\">TypeIdentifier id_; // id</span><br><span class=\"line\">const char* name_;  // </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>floatdetail::_makeTypeMetaDataInstance <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template &lt;class T&gt;</span><br><span class=\"line\">inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;</span><br><span class=\"line\">  return &#123;sizeof(T),                 // T</span><br><span class=\"line\">          _PickNew&lt;T&gt;(),             //  new T</span><br><span class=\"line\">          _PickPlacementNew&lt;T&gt;(),</span><br><span class=\"line\">          _PickCopy&lt;T&gt;(),      </span><br><span class=\"line\">          _PickPlacementDelete&lt;T&gt;(),</span><br><span class=\"line\">          _PickDelete&lt;T&gt;(),</span><br><span class=\"line\">          TypeIdentifier::Get&lt;T&gt;(),  // id</span><br><span class=\"line\">          typeName&#125;;                 // float&quot;float&quot;</span><br></pre></td></tr></table></figure><br>structstruct{}id<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TypeIdentifier::Get&lt;T&gt;()</span><br></pre></td></tr></table></figure><br>CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE TypeIdentifer(PreallocatedId)floatPreallocatedId6</p>\n<p> intdoubleint64_t</p>\n<p>PyTorchidid_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCETypeIdentifier::createTypeId()PyTorchid32_CaffeHighestPreallocatedTypeIdid1</p>\n<p>TypeMetaDataTypeMetaTypeMetaDataStorageImplTHStorage_(newWithSize)(ptrdiff_t size)StorageImpl<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">size,             // StorageImplTypeMetafloat</span><br><span class=\"line\">getTHDefaultAllocator(),  // posix_memalign</span><br><span class=\"line\">true                      // StorageImplresize</span><br></pre></td></tr></table></figure><br>StorageImplTHPStorageStorageImplTHPStorage torch._C FloatStorageBase</p>\n<p>floatTHPStorageIntStorageBase</p>\n<p>FloatStorageBasemethods, members, properties generic/Storage.cppTHPStorage_(int)(PyObject* module)</p>\n<p> _THNN  _THCUNN  torch._C<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  torch::nn::init_THNN(module);</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUNN(module);</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure><br>torch/csrc/nnTHNN.cppTHCUNN.cpp torch_python TARGET tools/setup_helpers/generate_code.py torch/CMakeLists.txt</p>\n<p><code>torch._C</code> <code>torch/__init__.py</code> import torch</p>\n<ol>\n<li> typenameis_tensoris_storage</li>\n<li>torch</li>\n<li>_C._init_nametorch/csrc/Module.cpp torchDoubleStorage torch.DoubleStorageFloatStorageHalfStorage</li>\n<li>_C._initExtensiontorch/csrc/Module.cpp <ul>\n<li>layouttorchstridedsparse_coo_mkldnn</li>\n<li>torchany_formatpreserve_formatcontiguous_formatchannels_last</li>\n<li>torchuint8int8float64float32int32int64int16float16complex32complex64complex128boolqint8quint8qint32torch</li>\n<li>python1PyTensorType PyTensorTypeBackendScalarType2torch.tensortypetorch.FloatTensorTensormetaclass3pythonTensortorch.FloatTensor4Tensor torch 5FloatTensorTensor</li>\n<li></li>\n<li> THPxxxStorage_postInit(module)xxxTHPxxxStorage_Init moduletorchtorch._CPython storageFloattorch.FloatStorage  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, </span><br><span class=\"line\">TH_CONCAT_2(at::k, Real));</span><br></pre></td></tr></table></figure>\n   TH_CONCAT_2(at::k, Real)at::kRealReal=Floatat::ScalarType::Float  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`</span><br></pre></td></tr></table></figure>\n  THPStorageClassback+at::kReal</li>\n</ul>\n</li>\n</ol>\n<p>import torch </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>PyTorch</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"torch-installization\"><a href=\"#torch-installization\" class=\"headerlink\" title=\"torch installization\"></a>torch installization</h1>","more":"<p>PyTorchpythonPyTorch<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import torch</span><br></pre></td></tr></table></figure><br> <code>torch/__init__.py</code>torch._CRTLD_GLOBAL|RTLD_LAZYRTLD_GLOBAL|RTLD_LAZYtorch._C<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">old_flags=sys.getdlopenflags()</span><br><span class=\"line\">sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)</span><br><span class=\"line\">from torch._C import *</span><br><span class=\"line\">__all__ += [name for name in dir(_C)</span><br><span class=\"line\">            if name[0] != &#x27;_&#x27; and</span><br><span class=\"line\">            not name.endswith(&#x27;Base&#x27;)]</span><br><span class=\"line\">sys.setdlopenflags(old_flags)</span><br></pre></td></tr></table></figure><br><strong>torch._C_Base</strong></p>\n<p><code>__init__.py</code>import torch._Cimportmodulepackagetorch._C torch._Ctorch/csrc/stub.cppshmtorch_pythonstub.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">extern PyObject* initModule();</span><br><span class=\"line\">PyMODINIT_FUNC PyInit__C()   // pythonimport _C </span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  return initModule();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>python3<code>import torch._C</code> PyInit__CPyInit_&lt;package&gt;initModuleinitModuleexterninitModuleshmtorch_python</p>\n<p>shmDomain Sockettorch/CMakeLists.txtshm<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM_SUBDIR libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure><br>shmtorch/lib/libshmtorch._Ctorch_pythoninitModuletorch/CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure><br>TORCH_PYTHON_SRCStorch_pythontorch_pythontorch/CMakeLists.txt</p>\n<p>initModuletorch/csrc/Module.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">namespace torch &#123; namespace cuda &#123;</span><br><span class=\"line\">void initModule(PyObject* module);       // cuda</span><br><span class=\"line\">&#125;&#125;</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\"></span><br><span class=\"line\">PyObject* module;</span><br><span class=\"line\">PyObject* initModule() &#123;                 // </span><br><span class=\"line\">  // methods</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // </span><br><span class=\"line\">  static struct PyModuleDef torchmodule = &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    &quot;torch._C&quot;,                          // </span><br><span class=\"line\">    nullptr,                           </span><br><span class=\"line\">    -1,</span><br><span class=\"line\">    methods.data()                       // </span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">  ASSERT_TRUE(module = PyModule_Create(&amp;torchmodule)); // </span><br><span class=\"line\">  // </span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::cuda::initModule(module);       // cuda</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // setter</span><br><span class=\"line\">  // namevincref</span><br><span class=\"line\">  // 10</span><br><span class=\"line\">  auto set_module_attr = [&amp;](const char* name, PyObject* v, bool incref = true) </span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    if(incref) &#123;</span><br><span class=\"line\">      Py_INCREF(v);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return PyModule_AddObject(module, name, v) == 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // </span><br><span class=\"line\">  ...</span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));</span><br><span class=\"line\">  // </span><br><span class=\"line\">  auto py_module = py::reinterpret_borrow&lt;py::module&gt;(module);</span><br><span class=\"line\">  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);</span><br><span class=\"line\">  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);</span><br><span class=\"line\">  ...    // </span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;, </span><br><span class=\"line\">        (PyObject*)THPDefaultGenerator, false));</span><br><span class=\"line\">  torch::nn::init__THNN(module);  //  _THNN </span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUDD(module);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  return module;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>torch._Cattr</p>\n<h1 id=\"methods-members-in-torch-C\"><a href=\"#methods-members-in-torch-C\" class=\"headerlink\" title=\"methods/members in torch._C\"></a>methods/members in torch._C</h1><ul>\n<li> THPUtils_addPyMethodDefs torch._C <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># TorchMethods </span><br><span class=\"line\">_initExtension</span><br><span class=\"line\">_autograd_init</span><br><span class=\"line\">...</span><br><span class=\"line\"># DataLoaderMethods </span><br><span class=\"line\">_set_worker_signal_handlers</span><br><span class=\"line\">_set_worker_pids</span><br><span class=\"line\">...</span><br><span class=\"line\"># torch::autograd::python_functions(), torch/csrc/autograd/init.cpp</span><br><span class=\"line\">set_grad_enabled</span><br><span class=\"line\">is_grad_enabled</span><br><span class=\"line\">set_anomaly_enabled</span><br><span class=\"line\">is_anomaly_enabled</span><br><span class=\"line\"># torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp</span><br><span class=\"line\">_multiprocessing_init</span><br><span class=\"line\"># torch::distributed::c10d::python_functions()  </span><br><span class=\"line\">...</span><br><span class=\"line\"># THCPModule_method(), torch/csrc/cuda/Module.cpp</span><br><span class=\"line\">_cuda_init</span><br><span class=\"line\">_cuda_setDevice</span><br><span class=\"line\">...</span><br><span class=\"line\">_nccl_version</span><br><span class=\"line\">...</span><br><span class=\"line\"># THCUDNN_method()</span><br><span class=\"line\">_cudnn_version</span><br><span class=\"line\"># THDPModule_methods(), torch/csrc/distributed/Module.cpp</span><br><span class=\"line\">_dist_init_extension</span><br><span class=\"line\">_dist_init_process_group</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></li>\n<li><p>torch._C </p>\n<ul>\n<li><p>torch._C_PtrWrapperGeneratorFatalErrorSizedtypeiinfolayoutmemory_formatdevice_LegacyVariableBase_TensorBase_VariableFunctions_FunctionBase_EngineBaseJITExceptionIODescriptor_THNN_THCUNN</p>\n<p>  torch._C._TensorBase</p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_cdata</span><br><span class=\"line\">_version</span><br><span class=\"line\">grad_fn</span><br><span class=\"line\">_grad_fn</span><br><span class=\"line\">is_leaf</span><br><span class=\"line\">data</span><br><span class=\"line\">_grad</span><br><span class=\"line\">grad</span><br><span class=\"line\">...</span><br><span class=\"line\">device</span><br><span class=\"line\">ndim</span><br></pre></td></tr></table></figure>\n<p>  </p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp</span><br><span class=\"line\">__add__</span><br><span class=\"line\">__radd__</span><br><span class=\"line\">...</span><br><span class=\"line\">apply_</span><br><span class=\"line\">byte</span><br><span class=\"line\">char</span><br><span class=\"line\">contiguous</span><br><span class=\"line\">...</span><br><span class=\"line\">where</span><br><span class=\"line\">zero_</span><br><span class=\"line\"># extra_method</span><br><span class=\"line\">_make_subclass</span><br></pre></td></tr></table></figure>\n<p>  torch._C._FunctionBase </p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># method</span><br><span class=\"line\">apply</span><br><span class=\"line\">_do_forward</span><br><span class=\"line\">_do_backward</span><br><span class=\"line\">_register_hook_dict</span><br><span class=\"line\">register_hook</span><br><span class=\"line\"># property</span><br><span class=\"line\">saved_tensors</span><br><span class=\"line\">saved_variables</span><br><span class=\"line\">...</span><br><span class=\"line\">requires_grad</span><br><span class=\"line\">metadata</span><br></pre></td></tr></table></figure>\n<p>   torch._C._VariableFunctions </p>\n  <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">arange</span><br><span class=\"line\">as_tensor</span><br><span class=\"line\">...</span><br><span class=\"line\">empty       <span class=\"comment\">#  torch.empty</span></span><br><span class=\"line\">empty_like</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>  _TensorBaseTensorTensor_FunctionBase</p>\n</li>\n<li><p>torch._C _wrap_tensor_impl_tensor_impl_raw_handle_demangle_log_api_usage_once_jit</p>\n</li>\n<li><p>torch._C _nncpp_onnx</p>\n</li>\n<li><p>torch._C has_cudnnhas_openmphas_mklhas_lapackhas_cudahas_mkldnn_GLIBCXX_USE_CXX11_APIdefault_generator</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"some-installization-w-r-t-torch-C\"><a href=\"#some-installization-w-r-t-torch-C\" class=\"headerlink\" title=\"some installization w.r.t. torch._C\"></a>some installization w.r.t. torch._C</h1><h3 id=\"THPxxxStorage-init\"><a href=\"#THPxxxStorage-init\" class=\"headerlink\" title=\"THPxxxStorage_init\"></a>THPxxxStorage_init</h3><p>torch._CTensor THPxxxStorage_init  THCPxxxStorage_init </p>\n<p>Module.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/TH.h&gt;               // TH=TorcH</span><br><span class=\"line\">#include &lt;c10/util/Logging.h&gt;</span><br><span class=\"line\">#include &lt;ATen/ATen.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;      // THP=TorcH Python</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br>ATenc10torchATen [A Tensor Library] Tensorc10 [caffe2ATen] Tensor</p>\n<p> TH/TH.h #include <TH/THGeneral.h>aten/src/THCMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/THGeneral.h&quot;)</span><br></pre></td></tr></table></figure><br>THGeneral.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w</span><br><span class=\"line\">#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)</span><br></pre></td></tr></table></figure><br>torch/csrc/THP.h #include <torch/src/Storage.h>Storage.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure><br>4include/include torch/csrc/generic/Storage.htorch/csrc/generic/Storage.h <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.h&quot;         // (0)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module);                      // (1)</span><br><span class=\"line\">...</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure><br>TH/THGenerateAllType.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THGenerateFloatTypes.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateIntTypes.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef TH_GENERIC_FILE</span><br></pre></td></tr></table></figure><br>4includeinclude#undef TH_GENERIC_FILEincludeinclude torch/csrc/generic/Storage.h (0) (1)TH/THGenerateFloatTypes.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//  TH_GENERIC_FILE</span><br><span class=\"line\">#include &lt;TH/THGenerateFloatType.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateDoubleType.h&gt;</span><br><span class=\"line\">#undef TH_GENERIC_FILE     // TH_GENERIC_FILE </span><br></pre></td></tr></table></figure><br>TH/THGenerateFloatType.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#line 1 TH_GENERIC_FILE</span><br><span class=\"line\">#include TH_GENERIC_FILE         // (2)</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef Real</span><br></pre></td></tr></table></figure><br> (2) include torch/csrc/generic/Storate.hTH_GENERIC_FILE  (1) <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool THPStorage_(init)(PyObject *module);  -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;</span><br><span class=\"line\">bool THPFloatStorage_init(PyObject *module);</span><br></pre></td></tr></table></figure><br>#include <TH/THGenerateDoubleType.h>THPDoubleStorage_init</p>\n<h1 id=\"include-\"><a href=\"#include-\" class=\"headerlink\" title=\"include  \"></a>include <TH/THGenerateIntTypes.h> </h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPByteStorage_init</span><br><span class=\"line\">THPCharStorage_init</span><br><span class=\"line\">THPShortStorage_init</span><br><span class=\"line\">THPIntStorage_init</span><br><span class=\"line\">THPLongStorage_init</span><br></pre></td></tr></table></figure>\n<p>4include<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPHalfStorage_init</span><br><span class=\"line\">THPBoolStorage_init</span><br><span class=\"line\">THPQUInt8Storage_init</span><br><span class=\"line\">THPQInt8Storage_init</span><br><span class=\"line\">THPQInt32Storage_init</span><br></pre></td></tr></table></figure><br>torch/csrc/Storage.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THStorageFunctions.hpp&gt;</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;                   // include THPxxxStorage_init </span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllTypes.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure><br>4include torch/csrc/generic/Storage.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.cpp&quot;              // (11)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...                                                                   // (12)</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class=\"line\">#ifndef THD_GENERIC_FILE</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  </span><br><span class=\"line\">  THPStorageType.tp_methods = methods.data();</span><br><span class=\"line\">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class=\"line\">  THPStorageType.tp_getset = THPStorage_(properties);</span><br><span class=\"line\">  if (PyType_Ready(&amp;THPStorageType) &lt; 0)</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  Py_INCREF(&amp;THPStorageType);</span><br><span class=\"line\">  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);</span><br><span class=\"line\">  THPStorage_(initCopyMethods)();</span><br><span class=\"line\">  return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>moduleTHPStorageBaseStr torch/csrc/Storage.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)</span><br></pre></td></tr></table></figure><br>TH/THGeneral.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)</span><br><span class=\"line\">#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y</span><br></pre></td></tr></table></figure><br>StorageBaseReal Int, Float, Double, Short, CharTHPxxxStorage_initReal=FloatTHPStorageBaseStrFloatStorageBasetorch._C FloatStorageBase python class torch._C.FloatStorageBase</p>\n<p>4includeinclude torch/csrc/generic/Storage.cppTH_GENERIC_FILE (11)include TH/THGenerateAllTypes.hTH/THGenerateFloatType.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#include TH_GENERIC_FILE</span><br></pre></td></tr></table></figure><br>include torch/csrc/generic/Storage.cppTH_GENERIC_FILE (12) THPFloatStorage_inittorch._C  FloatStorageBase</p>\n<p>IntCharByteDoubleHalfQUInt8</p>\n<p>torch/csrc/Module.cppinitModule THCPxxxStorage_init  THPxxxStorage_init  torch/csrc/cuda/Storage.h  torch/csrc/cuda/Storage.cpp </p>\n<p>torch._CFloatStorageBasetorch/csrc/generic/Storage.cpp THPStorageType<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyTypeObject THPStorageType = &#123;</span><br><span class=\"line\">  PyVarObject_HEAD_INIT(nullptr, 0)</span><br><span class=\"line\">  &quot;torch._C.&quot; THPStorageBaseStr,               /* tp_name */</span><br><span class=\"line\">  sizeof(THPStorage),                          /* tp_basicsize */</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  THPStorage_(pynew),                          /* tp_new */</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>pythonFloatStorageBaseC++THPStorage torch/csrc/StorageDef.hTHPStorage<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct THPStorage &#123;</span><br><span class=\"line\">  PyObject_HEAD</span><br><span class=\"line\">  THWStorage *cdata;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>torch/csrc/generic/Storage.cpp  THPStoragetorch/csrc/Storage.cppinclude torch/csrc/THP.htorch/csrc/generic/Storage.cpp torch/csrc/THP.h include torch/csrc/Storage.htorch/csrc/Storage.hincludetorch/csrc/generic/Storage.hgeneric/Storage.hinclude torch/csrc/StorageDef.h</p>\n<p> THPStorage_(pynew) <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // </span><br><span class=\"line\"></span><br><span class=\"line\">  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); // self</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  c10::Allocator * allocator = nullptr;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (kwargs != nullptr) &#123;                               // named arguments</span><br><span class=\"line\">    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, &quot;allocator&quot;); // allocator</span><br><span class=\"line\">    if (allocator_ptr) &#123;</span><br><span class=\"line\">      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);</span><br><span class=\"line\">      //  c10::Allocator </span><br><span class=\"line\">      allocator = static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));</span><br><span class=\"line\">      PyDict_DelItemString(kwargs, &quot;allocator&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Py_ssize_t num_kwargs = PyDict_Size(kwargs);</span><br><span class=\"line\">    if (num_args == 0) &#123;</span><br><span class=\"line\">      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, &quot;cdata&quot;);</span><br><span class=\"line\">      if (num_kwargs==1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   // cdata</span><br><span class=\"line\">        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);</span><br><span class=\"line\">        self-&gt;cdata = ptr;</span><br><span class=\"line\">        return (PyObject*)self.release();       // THPStorage</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    THPUtils_assert(num_kwargs == 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (num_args == 0) &#123;</span><br><span class=\"line\">    if (allocator) &#123;                            // cdataTHWStorage</span><br><span class=\"line\">      self-&gt;cdata = THPStorage_(newWithAllocator)(0, allocator);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      self-&gt;cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return (PyObject*)self.release();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...     //  self-&gt;cdata</span><br><span class=\"line\">&#125;   </span><br></pre></td></tr></table></figure><br>FloatStorageBase THPStorage.cdataTHWStoragetorch/csrc/THP.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage THStorage</span><br></pre></td></tr></table></figure><br> THStorage torch/csrc/Storage.cppinclude<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Storage.cpp                 -&gt;</span><br><span class=\"line\">#include &lt;TH/TH.h&gt;          -&gt;</span><br><span class=\"line\">#include &lt;TH/THStorageFunction.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;TH/generic/THStorage.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;c10/core/StorageImpl.h&gt;</span><br></pre></td></tr></table></figure><br> TH/generic/THStorage.h <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THStorage at::StorageImpl</span><br></pre></td></tr></table></figure><br> c10/core/StorageImpl.h <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace c10 &#123;</span><br><span class=\"line\">struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">private:</span><br><span class=\"line\">  caffe2::TypeMeta  data_type_;  // </span><br><span class=\"line\">  DataPtr data_ptr_;             // </span><br><span class=\"line\">  int64_t numel_;                // </span><br><span class=\"line\">  bool resizable_;</span><br><span class=\"line\">  bool received_cuda_;</span><br><span class=\"line\">  Allocator* allocator_;         // </span><br><span class=\"line\">&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>THWStorage at::StorageImpl THPStorage_(pynew)  cdata THWStorage THWStorage_(NAME)NAME<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">new                // THStorage sizesize=0Allocator</span><br><span class=\"line\">free</span><br><span class=\"line\">size</span><br><span class=\"line\">get</span><br><span class=\"line\">set</span><br><span class=\"line\">data</span><br><span class=\"line\">newWithSize        // THStorage sizeAllocator</span><br><span class=\"line\">newWithAllocator   // THStorage size  Allocator</span><br><span class=\"line\">copy_functions</span><br><span class=\"line\">copyByte</span><br><span class=\"line\">...</span><br><span class=\"line\">copyCudaByte</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h</span><br><span class=\"line\">#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h</span><br></pre></td></tr></table></figure><br>THStorage_(NAME)  TH/generic/THStorage.hTH/generic/THStorageCopy.h cpp</p>\n<p>cuda#define THWStorage_(NAME) THCStorage_(NAME)THC/generic/THCStorage.hTHC/generic/THCStorageCopy.h</p>\n<p> THStorage_(newWithSize) TH/generic/THStorage.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THStorage* THStorage_(newWithSize)(ptrdiff_t size)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  THStorage* storage = c10::make_instrusive&lt;at::StorageImpl&gt;(</span><br><span class=\"line\">#ifdef THQUANTIZED</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),</span><br><span class=\"line\">#else</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        // scalar_t </span><br><span class=\"line\">#endif</span><br><span class=\"line\">    size,</span><br><span class=\"line\">    getTHDefaultAllocator(),</span><br><span class=\"line\">    true).release();</span><br><span class=\"line\">  return storage;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>StorageImplintrusive_ptrStorageImplintrusive_ptr  THStorage  at::StorageImplStorageImplc10::make_instrusiveStorageImpl<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StorageImpl(</span><br><span class=\"line\">    caffe2::TypeMeta data_type,</span><br><span class=\"line\">    int64_4 numel,</span><br><span class=\"line\">    at::Allocator* allocator,</span><br><span class=\"line\">    bool resizable)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br>StorageImpl</p>\n<p>FloatStorageBaseTH/THGenerateFloatType.h  4include<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define scalar_t float</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    //  THQUANTIZED </span><br></pre></td></tr></table></figure><br>caffe2::TypeMeta::Make caffe2::TypeMeta detail::TypeMetaData* data_new TypeMetaData<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\</span><br><span class=\"line\">  namespace detail &#123;                                                       \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\</span><br><span class=\"line\">    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \\</span><br><span class=\"line\">  &#125;                                                                        \\</span><br><span class=\"line\">  template&lt;&gt;                                                               \\</span><br><span class=\"line\">  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)</span><br><span class=\"line\"></span><br><span class=\"line\">#define C10_CONCATENATE_IMPL(s1,s2) s1##s2</span><br><span class=\"line\">#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)</span><br></pre></td></tr></table></figure><br> _typeMetaDataInstance<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \\</span><br><span class=\"line\">    return TypeIdentifier(PreallocatedId);                             \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  namespace detail &#123;                                                   \\</span><br><span class=\"line\">  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                               \\</span><br><span class=\"line\">    PreallocatedId);                                                   \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline const detail::TypeMetaData*                                   \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(                                           \\</span><br><span class=\"line\">      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\</span><br><span class=\"line\">  namespace detail &#123;                                                 \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(                                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                             \\</span><br><span class=\"line\">    PreallocatedId) = _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\\</span><br><span class=\"line\">  &#125;                                                                  </span><br><span class=\"line\">// </span><br><span class=\"line\">CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)</span><br></pre></td></tr></table></figure><br> float<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// </span><br><span class=\"line\">namespace detail &#123;</span><br><span class=\"line\">__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData</span><br><span class=\"line\">_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>c10/util/typeid.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace detail &#123;                                                 </span><br><span class=\"line\">  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId</span><br><span class=\"line\">    = _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;   </span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>detail::_makeTypeMetaDataInstanceTypeMetaDataTypeMetaData floatid<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct TypeMetaData final &#123;</span><br><span class=\"line\">// </span><br><span class=\"line\">using New = void*();                            // new</span><br><span class=\"line\">using PlacementNew = void(void*, size_t);       // new</span><br><span class=\"line\">using Copy = void(const void*, void*, size_t);  // </span><br><span class=\"line\">using PlacementDelete = void(void*, size_t);</span><br><span class=\"line\">using Delete = void(void*);</span><br><span class=\"line\">... //</span><br><span class=\"line\"></span><br><span class=\"line\">size_t itemsize_;  // </span><br><span class=\"line\">New* new_;</span><br><span class=\"line\">PlacementNew* placementNew_;   //  new</span><br><span class=\"line\">Copy* copy_;        // </span><br><span class=\"line\">Delete* delete_;    // </span><br><span class=\"line\">TypeIdentifier id_; // id</span><br><span class=\"line\">const char* name_;  // </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>floatdetail::_makeTypeMetaDataInstance <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template &lt;class T&gt;</span><br><span class=\"line\">inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;</span><br><span class=\"line\">  return &#123;sizeof(T),                 // T</span><br><span class=\"line\">          _PickNew&lt;T&gt;(),             //  new T</span><br><span class=\"line\">          _PickPlacementNew&lt;T&gt;(),</span><br><span class=\"line\">          _PickCopy&lt;T&gt;(),      </span><br><span class=\"line\">          _PickPlacementDelete&lt;T&gt;(),</span><br><span class=\"line\">          _PickDelete&lt;T&gt;(),</span><br><span class=\"line\">          TypeIdentifier::Get&lt;T&gt;(),  // id</span><br><span class=\"line\">          typeName&#125;;                 // float&quot;float&quot;</span><br></pre></td></tr></table></figure><br>structstruct{}id<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TypeIdentifier::Get&lt;T&gt;()</span><br></pre></td></tr></table></figure><br>CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE TypeIdentifer(PreallocatedId)floatPreallocatedId6</p>\n<p> intdoubleint64_t</p>\n<p>PyTorchidid_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCETypeIdentifier::createTypeId()PyTorchid32_CaffeHighestPreallocatedTypeIdid1</p>\n<p>TypeMetaDataTypeMetaTypeMetaDataStorageImplTHStorage_(newWithSize)(ptrdiff_t size)StorageImpl<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">size,             // StorageImplTypeMetafloat</span><br><span class=\"line\">getTHDefaultAllocator(),  // posix_memalign</span><br><span class=\"line\">true                      // StorageImplresize</span><br></pre></td></tr></table></figure><br>StorageImplTHPStorageStorageImplTHPStorage torch._C FloatStorageBase</p>\n<p>floatTHPStorageIntStorageBase</p>\n<p>FloatStorageBasemethods, members, properties generic/Storage.cppTHPStorage_(int)(PyObject* module)</p>\n<p> _THNN  _THCUNN  torch._C<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  torch::nn::init_THNN(module);</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUNN(module);</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure><br>torch/csrc/nnTHNN.cppTHCUNN.cpp torch_python TARGET tools/setup_helpers/generate_code.py torch/CMakeLists.txt</p>\n<p><code>torch._C</code> <code>torch/__init__.py</code> import torch</p>\n<ol>\n<li> typenameis_tensoris_storage</li>\n<li>torch</li>\n<li>_C._init_nametorch/csrc/Module.cpp torchDoubleStorage torch.DoubleStorageFloatStorageHalfStorage</li>\n<li>_C._initExtensiontorch/csrc/Module.cpp <ul>\n<li>layouttorchstridedsparse_coo_mkldnn</li>\n<li>torchany_formatpreserve_formatcontiguous_formatchannels_last</li>\n<li>torchuint8int8float64float32int32int64int16float16complex32complex64complex128boolqint8quint8qint32torch</li>\n<li>python1PyTensorType PyTensorTypeBackendScalarType2torch.tensortypetorch.FloatTensorTensormetaclass3pythonTensortorch.FloatTensor4Tensor torch 5FloatTensorTensor</li>\n<li></li>\n<li> THPxxxStorage_postInit(module)xxxTHPxxxStorage_Init moduletorchtorch._CPython storageFloattorch.FloatStorage  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, </span><br><span class=\"line\">TH_CONCAT_2(at::k, Real));</span><br></pre></td></tr></table></figure>\n   TH_CONCAT_2(at::k, Real)at::kRealReal=Floatat::ScalarType::Float  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`</span><br></pre></td></tr></table></figure>\n  THPStorageClassback+at::kReal</li>\n</ul>\n</li>\n</ol>\n<p>import torch </p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>PyTorch</p>"},{"title":"PyTorch-1","p":"pytorch/PyTorch-1","date":"2019-06-12T11:17:11.000Z","_content":"# \nC++pythonCUDA\n<!-- more -->\ntensorflowpytorchtensorflowpytorch\n\n\n```\ngit clone --recursive https://github.com/pytorch/pytorch\n```\n\n--recursivepytorchroot dir$ROOT_DIR\n\nLinux\n```\ncd pytorch\npython setup.py install\n```\npytorchC++pythonsetuptoolspython$ROOT_DIR/setup.pysetup()build_deps() caffe2 \n\n### build_deps()\n\n```\nbuild_caffe2(...)\n```\nbuild_caffe2\n1. run_cmakecmakecmake`$ROOD_DIR/build` cmakeSource Tree$ROOD_DIR top levelCMakeLists.txt\n2. $ROOT_DIR/buildmake install ninja installcmakeMakefileinstalltargetbuild\n3. build/caffe2/proto.py caffe2/proto/.pycaffe2/proto/.proto\n\nrun_cmakecmake-D optioncmakesource treecmake top levelCMakeLists.txt1)2)include dirlib dir3.cmakecmake4C++5/\n```\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\nadd_subdirectory(modules)\n```\nc10,caffe2,modulesbuild treeCMakeLists.txt CMakeLists.txt\n\ntop level CMakeLists.txt\n```\ninclude(cmake/Dependencies.cmake)\n```\nDependencies.cmakeCaffe2`$ROOT_DIR/third_party`$ROOT_DIR/caffe2\n1. BLASBLAS=OpenBLASsetup.py, OpenBLASDependencies.cmake\n```\n...\nelseif(BLAS STREQUAL \"OpenBLAS\")\n  find_package(OpenBLAS REQUIRED)\n  include_directories(SYSTEM ${OpenBLAS_INCLUDE_DIR})\n  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS ${OpenBLAS_LIB})\n```\nfind_package`$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake`.cmakeOpenBLAScblas.hopenblas OpenBLAS_INCLUDE_DIROpenBLAS_LIBCaffe2_PUBLIC_DEPENDENCY_LIBS$ROOT_DIR/caffe2/CMakeLists.txt\n```\ntarget_link_libraries(caffe2 PUBLIC ${Caffe2_PUBLIC_DEPENDENCY_LIBS})\n```\n-lopenblas\n\ncaffe2_pybind11_state$ROOT_DIR/caffe2/CMakeLists.txt\n```\nadd_subdirectory(python)\n...\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\ninstall(TARGETS caffe2_pybind11_state DESTINATION \"${PYTHON_LIB_REL_PATH}/caffe2/python\")\n```\nCaffe2_CPU_PYTHON_SRCS$ROOT_DIR/caffe2/python/CMakeLists.txt CUDAROCM , caffe2_pybind11_state_gpucaffe2_pybind11_state_hipinstallpythonsite-packagescaffe2/python\n\nbuild_dep()$ROOT_DIR/setup.pysetup\n\n### setup()\nsetup[setup()](https://docs.python.org/3/distutils/apiref.html)\n1. ext_modules 5\n- torch._C C++/dir\n- torch._dl WINDOWSC\n- caffe2.python.caffe2_pybind11_state\n- caffe2.python.caffe2_pybind11_state_gpu\n- caffe2.python.caffe2_pybind11_state_hip\n\ncaffe2.pythonpackage$ROOT_DIR/build/caffe2/pythonext_modulesbuild_ext\n\n2. cmdclassbuild_ext, clean, installactionactionpython setup.py <action> install cleanpattern.gitignorebuild_extbuild_ext\n\n- create_compile_commandscompile_commands.jsongccg++gccsinclude c++ compile_commands.json`$ROOT_DIR/CMakeLists.txtset(CMAKE_EXPORT_COMPILE_COMMAND ON)`$ROOT_DIR/buildjsonworking directorycommand\n```\n[\n{\n  \"directory\":\"<path/to/root>build/third_party/protobuf/cmake\",\n  \"command\": \"/usr/bin/c++ ... -I<path/to/root>/third_party/protobuf/src ... \n                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...\",\n  \"file\": \"<path/to/root>/third_party/protobuf/src/google/protobuf/arena.cc\"\n},\n...\n]\n```\n{...} .o gccg++$ROOT_DIR/compile_commands.json\n- runlibrary CUDA, CUDNN, NUMPY\n- build_extensions ext_modulespython\n\next_modules5build_deps()caffe2_pybind11_state_gpucaffe2_pybind11_state_hipCUDAROCMbuild_deps()ext_modulesbuild_extensionstorch._C, torch._dl\n\nbuild_deps()ext_modules `$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/`build_deps()ext_modules `$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/`caffe2.python.caffe2_pybind11_state`$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/`caffe2_pybind11_statepython.cpython-37m-x86_64-linux-gnu.so$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so build_extensions() pythonsite-packages.../miniconda3/lib/python3.7/site-packages/caffe2/python/\n\n3. packages python site-packages\n```\npackages = find_packages(exclude=['tools', 'tools.*'])\n```\n\nPyTorchtoolscaffe2torch__init__.pycaffe2torchsite-packages\n\next_modules5torch._C, torch._dlsite-packages/torch_C, _dlextcaffe2.site-packages/caffe2/python\n\n### \n\npytorch:\n\n1. CMakec++build_deps()\n2. pythonsetupbuild_ext\n\n\n```\ntop-levelCMakeLists.txt\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\n```\ncaffe2CMakeLists.txt \n```\nadd_library(caffe2_proto STATIC $<TARGET_OBJECTS:Caffe2_PROTO>\nadd_library(thnvrtc SHARED ${TORCH_SRC_DIR}/csrc/jit/fuser/cuda/thnvrtc.cpp>\nadd_library(caffe2 ${Caffe2_CPU_SRCS})\nif (TORCH_STATIC)\n  add_library(torch STATIC ${DUMMY_EMPTY_FILE})\nelse()\n  add_library(torch SHARED ${DUMMY_EMPTY_FILE})\nendif()\ntorch_cuda_based_add_library(caffe2_gpu ${Caffe2_GPU_SRCS})\nhip_add_library(caffe2_hip ${Caffe2_HIP_SRCS})\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_gpu MODULE ${Caffe2_GPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_hip MODULE ${Caffe2_HIP_PYTHON_SRCS})\n```\ninstall\n```\nadd_subdirectory(../torch torch)\n```\ncaffe2CMakeLists.txtadd_subdirectorytorch\n\ntorchCMakeLists.txt \n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\n\n```\nset(LIBSHM libshm)\nset(LIBSHM_SRCDIR ${TORCH_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\ntorch/lib/libshmCMakeLists.txt\n```\nADD_LIBRARY(shm SHARED core.cpp)\n```\npytorchCMakecmake/Dependencies.cmake\n- Caffe2_PUBLIC_DEPENDENCY_LIBSOpenBLAS g++flag `-I<include dir>flag`\n- \n(1) tbb\n```\nadd_subdirectory(${CMAKE_SOURCE_DIR}/aten/src/ATen/cpu/tbb)    # tbb\n```\n(2) qnnpack\n```\n#  qnnpack \n# source directory${PROJECT_SOURCE_DIR}/third_party/QNNPACK\n# output directory${PROJECT_BINARY_DIR}/confu-deps/QNNPACK\nadd_subdirectory(\"${QNNPACK_SOURCE_DIR}\" \"${CONFU_DEPENDENCIES_BINARY_DIR}/QNNPACK\")\nlist(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)\n```\nCMakeQNNPACKthird_partyqnnpackDependencies.cmakeCaffe2_DEPENDENCY_LIBS\n(3) nnpack\n```\n#  nnpack\ninclude(${CMAKE_CURRENT_LIST_DIR}/External/nnpack.cmake)\n```\nnnpack.cmake\n```\nadd_subdirectory(${NNPACK_SOURCE_DIR} ${CONFU_DEPENDENCIES_BINARY_DIR}/NNPACK)\n```\nNNPACKthird_partyNNPACKCMakeLists.txtCMake nnpackDependencies.cmakennpackCaffe2_DEPENDENCY_LIBS\n\n(4)  cpuinfogflagglog::gloggoogletestfbgemmfp16\n\n(5) LMDB\n```\nfind_package(LMDB)\n```\ncmake/ModulesFindLMDB.cmake .cmakelmdblmdb.hlinux/usr/lib/x86_64-linux-gnu/usr/include, LMDB_LIBRARIESLMDB_INCLUDE_DIRDependencies.cmake\n```\ninclude_directories(SYSTEM ${LMDB_INCLUDE_DIR})\nlist(APPEND Caffe2_DEPENDENCY_LIBS ${LMDB_LIBRARIES})\n```\nOPENCLLEVELDBNUMAZMQREDISOPENCVFFMPEGPythonMPI\n\n(6) pybind11Dependencies.cmakepybind11\n```\nfind_package(pybind11 CONFIG)# ${pybind11_DIR}pybind11Config.cmake\nif(NOT pybind11_FOUND)\n  find_package(pybind11)     # module\nendif()\n```\ncmake/Modules/Findpybind11.cmakefind_pathpybind11/pybind11.hpybind11CMakeDependencies.cmake\n```\ninclude_directories(SYSTEM ${CMAKE_CURRENT_LIST_DIR}/../third_party/pybind11/include)\n\n```\n(7) OPENMP\n```\nFIND_PACKAGE(OpenMP QUIET)\n```\nOpenMP${OpenMP_CXX_FLAGS}  ${OpenMP_CXX_LIBRARIES}flagcaffe2OpenMPcaffe2/CMakeLists.txt\n```\ntarget_compile_options(caffe2 INTERFACE ${OpenMP_CXX_FLAGS})\ntarget_link_libraries(caffe2 PRIVATE ${OpenMP_CXX_LIBRARIES})\n```\n(8) CUDADependencies.cmake\n```\ninclude(${CMAKE_CURRENT_LIST_DIR}/public/cuda.cmake)\n```\ncuda.cmake find_librarycudaIMPORTED target\n```\nadd_library(caffe2::cuda UNKNOWN IMPORTED)\n```\ncudacaffe2::cudartcaffe2::cudnncaffe2::curandcaffe2::cufftcaffe2::tensorrt caffe2::cublascaffe2::nvrtcDependencies.cmake\n```\nlist(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)\n```\nCaffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txt\n\n(9) NCCLCUBGLOO\n\nDependencies.cmakecaffe2QNNPACKCaffe2_DEPENDENCY_LIBSCaffe2_PUBLIC_DEPENDENCY_LIBSCaffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txtflag\n```\ntarget_link_libraries(caffe2 PRIVATE ${Caffe2_DEPENDENCY_LIBS})\n```\n2. pythoncaffe2\n\n- torch._C \n```\nmain_libraries=['shm', 'torch_python']\n```\n\n```\nmain_sources=[\"torch/csrc/stub.cpp\"]\n```\n- torch._dltorch/csrc/dl.c <dlfcn.h>torch._dl\n```\nRTLD_GLOBAL=0x100\nRTLD_NOW   =0x2\nRTLD_LAZY  =0x1\n```\ntorch._Cdlopen()python os flagpythonDLFCNtorch._dlflagtorch._dl\n\n### ...\nPyTorch","source":"_posts/pytorch/PyTorch-1.md","raw":"---\ntitle: PyTorch-1\np: pytorch/PyTorch-1\ndate: 2019-06-12 19:17:11\ntags: PyTorch\ncategories: DL Framework\n---\n# \nC++pythonCUDA\n<!-- more -->\ntensorflowpytorchtensorflowpytorch\n\n\n```\ngit clone --recursive https://github.com/pytorch/pytorch\n```\n\n--recursivepytorchroot dir$ROOT_DIR\n\nLinux\n```\ncd pytorch\npython setup.py install\n```\npytorchC++pythonsetuptoolspython$ROOT_DIR/setup.pysetup()build_deps() caffe2 \n\n### build_deps()\n\n```\nbuild_caffe2(...)\n```\nbuild_caffe2\n1. run_cmakecmakecmake`$ROOD_DIR/build` cmakeSource Tree$ROOD_DIR top levelCMakeLists.txt\n2. $ROOT_DIR/buildmake install ninja installcmakeMakefileinstalltargetbuild\n3. build/caffe2/proto.py caffe2/proto/.pycaffe2/proto/.proto\n\nrun_cmakecmake-D optioncmakesource treecmake top levelCMakeLists.txt1)2)include dirlib dir3.cmakecmake4C++5/\n```\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\nadd_subdirectory(modules)\n```\nc10,caffe2,modulesbuild treeCMakeLists.txt CMakeLists.txt\n\ntop level CMakeLists.txt\n```\ninclude(cmake/Dependencies.cmake)\n```\nDependencies.cmakeCaffe2`$ROOT_DIR/third_party`$ROOT_DIR/caffe2\n1. BLASBLAS=OpenBLASsetup.py, OpenBLASDependencies.cmake\n```\n...\nelseif(BLAS STREQUAL \"OpenBLAS\")\n  find_package(OpenBLAS REQUIRED)\n  include_directories(SYSTEM ${OpenBLAS_INCLUDE_DIR})\n  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS ${OpenBLAS_LIB})\n```\nfind_package`$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake`.cmakeOpenBLAScblas.hopenblas OpenBLAS_INCLUDE_DIROpenBLAS_LIBCaffe2_PUBLIC_DEPENDENCY_LIBS$ROOT_DIR/caffe2/CMakeLists.txt\n```\ntarget_link_libraries(caffe2 PUBLIC ${Caffe2_PUBLIC_DEPENDENCY_LIBS})\n```\n-lopenblas\n\ncaffe2_pybind11_state$ROOT_DIR/caffe2/CMakeLists.txt\n```\nadd_subdirectory(python)\n...\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\ninstall(TARGETS caffe2_pybind11_state DESTINATION \"${PYTHON_LIB_REL_PATH}/caffe2/python\")\n```\nCaffe2_CPU_PYTHON_SRCS$ROOT_DIR/caffe2/python/CMakeLists.txt CUDAROCM , caffe2_pybind11_state_gpucaffe2_pybind11_state_hipinstallpythonsite-packagescaffe2/python\n\nbuild_dep()$ROOT_DIR/setup.pysetup\n\n### setup()\nsetup[setup()](https://docs.python.org/3/distutils/apiref.html)\n1. ext_modules 5\n- torch._C C++/dir\n- torch._dl WINDOWSC\n- caffe2.python.caffe2_pybind11_state\n- caffe2.python.caffe2_pybind11_state_gpu\n- caffe2.python.caffe2_pybind11_state_hip\n\ncaffe2.pythonpackage$ROOT_DIR/build/caffe2/pythonext_modulesbuild_ext\n\n2. cmdclassbuild_ext, clean, installactionactionpython setup.py <action> install cleanpattern.gitignorebuild_extbuild_ext\n\n- create_compile_commandscompile_commands.jsongccg++gccsinclude c++ compile_commands.json`$ROOT_DIR/CMakeLists.txtset(CMAKE_EXPORT_COMPILE_COMMAND ON)`$ROOT_DIR/buildjsonworking directorycommand\n```\n[\n{\n  \"directory\":\"<path/to/root>build/third_party/protobuf/cmake\",\n  \"command\": \"/usr/bin/c++ ... -I<path/to/root>/third_party/protobuf/src ... \n                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...\",\n  \"file\": \"<path/to/root>/third_party/protobuf/src/google/protobuf/arena.cc\"\n},\n...\n]\n```\n{...} .o gccg++$ROOT_DIR/compile_commands.json\n- runlibrary CUDA, CUDNN, NUMPY\n- build_extensions ext_modulespython\n\next_modules5build_deps()caffe2_pybind11_state_gpucaffe2_pybind11_state_hipCUDAROCMbuild_deps()ext_modulesbuild_extensionstorch._C, torch._dl\n\nbuild_deps()ext_modules `$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/`build_deps()ext_modules `$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/`caffe2.python.caffe2_pybind11_state`$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/`caffe2_pybind11_statepython.cpython-37m-x86_64-linux-gnu.so$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so build_extensions() pythonsite-packages.../miniconda3/lib/python3.7/site-packages/caffe2/python/\n\n3. packages python site-packages\n```\npackages = find_packages(exclude=['tools', 'tools.*'])\n```\n\nPyTorchtoolscaffe2torch__init__.pycaffe2torchsite-packages\n\next_modules5torch._C, torch._dlsite-packages/torch_C, _dlextcaffe2.site-packages/caffe2/python\n\n### \n\npytorch:\n\n1. CMakec++build_deps()\n2. pythonsetupbuild_ext\n\n\n```\ntop-levelCMakeLists.txt\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\n```\ncaffe2CMakeLists.txt \n```\nadd_library(caffe2_proto STATIC $<TARGET_OBJECTS:Caffe2_PROTO>\nadd_library(thnvrtc SHARED ${TORCH_SRC_DIR}/csrc/jit/fuser/cuda/thnvrtc.cpp>\nadd_library(caffe2 ${Caffe2_CPU_SRCS})\nif (TORCH_STATIC)\n  add_library(torch STATIC ${DUMMY_EMPTY_FILE})\nelse()\n  add_library(torch SHARED ${DUMMY_EMPTY_FILE})\nendif()\ntorch_cuda_based_add_library(caffe2_gpu ${Caffe2_GPU_SRCS})\nhip_add_library(caffe2_hip ${Caffe2_HIP_SRCS})\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_gpu MODULE ${Caffe2_GPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_hip MODULE ${Caffe2_HIP_PYTHON_SRCS})\n```\ninstall\n```\nadd_subdirectory(../torch torch)\n```\ncaffe2CMakeLists.txtadd_subdirectorytorch\n\ntorchCMakeLists.txt \n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\n\n```\nset(LIBSHM libshm)\nset(LIBSHM_SRCDIR ${TORCH_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\ntorch/lib/libshmCMakeLists.txt\n```\nADD_LIBRARY(shm SHARED core.cpp)\n```\npytorchCMakecmake/Dependencies.cmake\n- Caffe2_PUBLIC_DEPENDENCY_LIBSOpenBLAS g++flag `-I<include dir>flag`\n- \n(1) tbb\n```\nadd_subdirectory(${CMAKE_SOURCE_DIR}/aten/src/ATen/cpu/tbb)    # tbb\n```\n(2) qnnpack\n```\n#  qnnpack \n# source directory${PROJECT_SOURCE_DIR}/third_party/QNNPACK\n# output directory${PROJECT_BINARY_DIR}/confu-deps/QNNPACK\nadd_subdirectory(\"${QNNPACK_SOURCE_DIR}\" \"${CONFU_DEPENDENCIES_BINARY_DIR}/QNNPACK\")\nlist(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)\n```\nCMakeQNNPACKthird_partyqnnpackDependencies.cmakeCaffe2_DEPENDENCY_LIBS\n(3) nnpack\n```\n#  nnpack\ninclude(${CMAKE_CURRENT_LIST_DIR}/External/nnpack.cmake)\n```\nnnpack.cmake\n```\nadd_subdirectory(${NNPACK_SOURCE_DIR} ${CONFU_DEPENDENCIES_BINARY_DIR}/NNPACK)\n```\nNNPACKthird_partyNNPACKCMakeLists.txtCMake nnpackDependencies.cmakennpackCaffe2_DEPENDENCY_LIBS\n\n(4)  cpuinfogflagglog::gloggoogletestfbgemmfp16\n\n(5) LMDB\n```\nfind_package(LMDB)\n```\ncmake/ModulesFindLMDB.cmake .cmakelmdblmdb.hlinux/usr/lib/x86_64-linux-gnu/usr/include, LMDB_LIBRARIESLMDB_INCLUDE_DIRDependencies.cmake\n```\ninclude_directories(SYSTEM ${LMDB_INCLUDE_DIR})\nlist(APPEND Caffe2_DEPENDENCY_LIBS ${LMDB_LIBRARIES})\n```\nOPENCLLEVELDBNUMAZMQREDISOPENCVFFMPEGPythonMPI\n\n(6) pybind11Dependencies.cmakepybind11\n```\nfind_package(pybind11 CONFIG)# ${pybind11_DIR}pybind11Config.cmake\nif(NOT pybind11_FOUND)\n  find_package(pybind11)     # module\nendif()\n```\ncmake/Modules/Findpybind11.cmakefind_pathpybind11/pybind11.hpybind11CMakeDependencies.cmake\n```\ninclude_directories(SYSTEM ${CMAKE_CURRENT_LIST_DIR}/../third_party/pybind11/include)\n\n```\n(7) OPENMP\n```\nFIND_PACKAGE(OpenMP QUIET)\n```\nOpenMP${OpenMP_CXX_FLAGS}  ${OpenMP_CXX_LIBRARIES}flagcaffe2OpenMPcaffe2/CMakeLists.txt\n```\ntarget_compile_options(caffe2 INTERFACE ${OpenMP_CXX_FLAGS})\ntarget_link_libraries(caffe2 PRIVATE ${OpenMP_CXX_LIBRARIES})\n```\n(8) CUDADependencies.cmake\n```\ninclude(${CMAKE_CURRENT_LIST_DIR}/public/cuda.cmake)\n```\ncuda.cmake find_librarycudaIMPORTED target\n```\nadd_library(caffe2::cuda UNKNOWN IMPORTED)\n```\ncudacaffe2::cudartcaffe2::cudnncaffe2::curandcaffe2::cufftcaffe2::tensorrt caffe2::cublascaffe2::nvrtcDependencies.cmake\n```\nlist(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)\n```\nCaffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txt\n\n(9) NCCLCUBGLOO\n\nDependencies.cmakecaffe2QNNPACKCaffe2_DEPENDENCY_LIBSCaffe2_PUBLIC_DEPENDENCY_LIBSCaffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txtflag\n```\ntarget_link_libraries(caffe2 PRIVATE ${Caffe2_DEPENDENCY_LIBS})\n```\n2. pythoncaffe2\n\n- torch._C \n```\nmain_libraries=['shm', 'torch_python']\n```\n\n```\nmain_sources=[\"torch/csrc/stub.cpp\"]\n```\n- torch._dltorch/csrc/dl.c <dlfcn.h>torch._dl\n```\nRTLD_GLOBAL=0x100\nRTLD_NOW   =0x2\nRTLD_LAZY  =0x1\n```\ntorch._Cdlopen()python os flagpythonDLFCNtorch._dlflagtorch._dl\n\n### ...\nPyTorch","slug":"pytorch/PyTorch-1","published":1,"updated":"2020-04-24T10:34:18.685Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92e005ap0dj2ilw4i3o","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>C++pythonCUDA<br><span id=\"more\"></span><br>tensorflowpytorchtensorflowpytorch</p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --recursive https://github.com/pytorch/pytorch</span><br></pre></td></tr></table></figure></p>\n<p>recursivepytorchroot dir$ROOT_DIR</p>\n<p>Linux<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd pytorch</span><br><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><br>pytorchC++pythonsetuptoolspython$ROOT_DIR/setup.pysetup()build_deps() caffe2 </p>\n<h3 id=\"build-deps\"><a href=\"#build-deps\" class=\"headerlink\" title=\"build_deps()\"></a>build_deps()</h3><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">build_caffe2(...)</span><br></pre></td></tr></table></figure><br>build_caffe2</p>\n<ol>\n<li>run_cmakecmakecmake<code>$ROOD_DIR/build</code> cmakeSource Tree$ROOD_DIR top levelCMakeLists.txt</li>\n<li>$ROOT_DIR/buildmake install ninja installcmakeMakefileinstalltargetbuild</li>\n<li>build/caffe2/proto.py caffe2/proto/.pycaffe2/proto/.proto</li>\n</ol>\n<p>run_cmakecmake-D optioncmakesource treecmake top levelCMakeLists.txt1)2)include dirlib dir3.cmakecmake4C++5/<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br><span class=\"line\">add_subdirectory(modules)</span><br></pre></td></tr></table></figure><br>c10,caffe2,modulesbuild treeCMakeLists.txt CMakeLists.txt</p>\n<p>top level CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include(cmake/Dependencies.cmake)</span><br></pre></td></tr></table></figure><br>Dependencies.cmakeCaffe2<code>$ROOT_DIR/third_party</code>$ROOT_DIR/caffe2</p>\n<ol>\n<li>BLASBLAS=OpenBLASsetup.py, OpenBLASDependencies.cmake<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">elseif(BLAS STREQUAL &quot;OpenBLAS&quot;)</span><br><span class=\"line\">  find_package(OpenBLAS REQUIRED)</span><br><span class=\"line\">  include_directories(SYSTEM $&#123;OpenBLAS_INCLUDE_DIR&#125;)</span><br><span class=\"line\">  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS $&#123;OpenBLAS_LIB&#125;)</span><br></pre></td></tr></table></figure>\nfind_package<code>$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake</code>.cmakeOpenBLAScblas.hopenblas OpenBLAS_INCLUDE_DIROpenBLAS_LIBCaffe2_PUBLIC_DEPENDENCY_LIBS$ROOT_DIR/caffe2/CMakeLists.txt<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PUBLIC $&#123;Caffe2_PUBLIC_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>\n-lopenblas</li>\n</ol>\n<p>caffe2_pybind11_state$ROOT_DIR/caffe2/CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(python)</span><br><span class=\"line\">...</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">install(TARGETS caffe2_pybind11_state DESTINATION &quot;$&#123;PYTHON_LIB_REL_PATH&#125;/caffe2/python&quot;)</span><br></pre></td></tr></table></figure><br>Caffe2_CPU_PYTHON_SRCS$ROOT_DIR/caffe2/python/CMakeLists.txt CUDAROCM , caffe2_pybind11_state_gpucaffe2_pybind11_state_hipinstallpythonsite-packagescaffe2/python</p>\n<p>build_dep()$ROOT_DIR/setup.pysetup</p>\n<h3 id=\"setup\"><a href=\"#setup\" class=\"headerlink\" title=\"setup()\"></a>setup()</h3><p>setup<a href=\"https://docs.python.org/3/distutils/apiref.html\">setup()</a></p>\n<ol>\n<li>ext_modules 5</li>\n</ol>\n<ul>\n<li>torch._C C++/dir</li>\n<li>torch._dl WINDOWSC</li>\n<li>caffe2.python.caffe2_pybind11_state</li>\n<li>caffe2.python.caffe2_pybind11_state_gpu</li>\n<li>caffe2.python.caffe2_pybind11_state_hip</li>\n</ul>\n<p>caffe2.pythonpackage$ROOT_DIR/build/caffe2/pythonext_modulesbuild_ext</p>\n<ol>\n<li>cmdclassbuild_ext, clean, installactionactionpython setup.py <action> install cleanpattern.gitignorebuild_extbuild_ext</li>\n</ol>\n<ul>\n<li>create_compile_commandscompile_commands.jsongccg++gccsinclude c++ compile_commands.json<code>$ROOT_DIR/CMakeLists.txtset(CMAKE_EXPORT_COMPILE_COMMAND ON)</code>$ROOT_DIR/buildjsonworking directorycommand<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;directory&quot;:&quot;&lt;path/to/root&gt;build/third_party/protobuf/cmake&quot;,</span><br><span class=\"line\">  &quot;command&quot;: &quot;/usr/bin/c++ ... -I&lt;path/to/root&gt;/third_party/protobuf/src ... </span><br><span class=\"line\">                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...&quot;,</span><br><span class=\"line\">  &quot;file&quot;: &quot;&lt;path/to/root&gt;/third_party/protobuf/src/google/protobuf/arena.cc&quot;</span><br><span class=\"line\">&#125;,</span><br><span class=\"line\">...</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n{} .o gccg++$ROOT_DIR/compile_commands.json</li>\n<li>runlibrary CUDA, CUDNN, NUMPY</li>\n<li>build_extensions ext_modulespython</li>\n</ul>\n<p>ext_modules5build_deps()caffe2_pybind11_state_gpucaffe2_pybind11_state_hipCUDAROCMbuild_deps()ext_modulesbuild_extensionstorch._C, torch._dl</p>\n<p>build_deps()ext_modules <code>$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/</code>build_deps()ext_modules <code>$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/</code>caffe2.python.caffe2_pybind11_state<code>$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/</code>caffe2_pybind11_statepython.cpython-37m-x86_64-linux-gnu.so$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so build_extensions() pythonsite-packages/miniconda3/lib/python3.7/site-packages/caffe2/python/</p>\n<ol>\n<li>packages python site-packages<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">packages = find_packages(exclude=[&#x27;tools&#x27;, &#x27;tools.*&#x27;])</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>PyTorchtoolscaffe2torch<strong>init</strong>.pycaffe2torchsite-packages</p>\n<p>ext_modules5torch._C, torch._dlsite-packages/torch_C, _dlextcaffe2.site-packages/caffe2/python</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>pytorch:</p>\n<ol>\n<li>CMakec++build_deps()</li>\n<li>pythonsetupbuild_ext</li>\n</ol>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top-levelCMakeLists.txt</span><br><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br></pre></td></tr></table></figure><br>caffe2CMakeLists.txt <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2_proto STATIC $&lt;TARGET_OBJECTS:Caffe2_PROTO&gt;</span><br><span class=\"line\">add_library(thnvrtc SHARED $&#123;TORCH_SRC_DIR&#125;/csrc/jit/fuser/cuda/thnvrtc.cpp&gt;</span><br><span class=\"line\">add_library(caffe2 $&#123;Caffe2_CPU_SRCS&#125;)</span><br><span class=\"line\">if (TORCH_STATIC)</span><br><span class=\"line\">  add_library(torch STATIC $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">else()</span><br><span class=\"line\">  add_library(torch SHARED $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">endif()</span><br><span class=\"line\">torch_cuda_based_add_library(caffe2_gpu $&#123;Caffe2_GPU_SRCS&#125;)</span><br><span class=\"line\">hip_add_library(caffe2_hip $&#123;Caffe2_HIP_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_gpu MODULE $&#123;Caffe2_GPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_hip MODULE $&#123;Caffe2_HIP_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure><br>install<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(../torch torch)</span><br></pre></td></tr></table></figure><br>caffe2CMakeLists.txtadd_subdirectorytorch</p>\n<p>torchCMakeLists.txt <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;TORCH_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure><br>torch/lib/libshmCMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD_LIBRARY(shm SHARED core.cpp)</span><br></pre></td></tr></table></figure><br>pytorchCMakecmake/Dependencies.cmake</p>\n<ul>\n<li>Caffe2_PUBLIC_DEPENDENCY_LIBSOpenBLAS g++flag <code>-I&lt;include dir&gt;flag</code></li>\n<li><br>(1) tbb<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;/aten/src/ATen/cpu/tbb)    # tbb</span><br></pre></td></tr></table></figure>\n(2) qnnpack<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  qnnpack </span><br><span class=\"line\"># source directory$&#123;PROJECT_SOURCE_DIR&#125;/third_party/QNNPACK</span><br><span class=\"line\"># output directory$&#123;PROJECT_BINARY_DIR&#125;/confu-deps/QNNPACK</span><br><span class=\"line\">add_subdirectory(&quot;$&#123;QNNPACK_SOURCE_DIR&#125;&quot; &quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/QNNPACK&quot;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)</span><br></pre></td></tr></table></figure>\nCMakeQNNPACKthird_partyqnnpackDependencies.cmakeCaffe2_DEPENDENCY_LIBS<br>(3) nnpack<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  nnpack</span><br><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/External/nnpack.cmake)</span><br></pre></td></tr></table></figure>\nnnpack.cmake<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;NNPACK_SOURCE_DIR&#125; $&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/NNPACK)</span><br></pre></td></tr></table></figure>\nNNPACKthird_partyNNPACKCMakeLists.txtCMake nnpackDependencies.cmakennpackCaffe2_DEPENDENCY_LIBS</li>\n</ul>\n<p>(4)  cpuinfogflagglog::gloggoogletestfbgemmfp16</p>\n<p>(5) LMDB<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(LMDB)</span><br></pre></td></tr></table></figure><br>cmake/ModulesFindLMDB.cmake .cmakelmdblmdb.hlinux/usr/lib/x86_64-linux-gnu/usr/include, LMDB_LIBRARIESLMDB_INCLUDE_DIRDependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;LMDB_INCLUDE_DIR&#125;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS $&#123;LMDB_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure><br>OPENCLLEVELDBNUMAZMQREDISOPENCVFFMPEGPythonMPI</p>\n<p>(6) pybind11Dependencies.cmakepybind11<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(pybind11 CONFIG)# $&#123;pybind11_DIR&#125;pybind11Config.cmake</span><br><span class=\"line\">if(NOT pybind11_FOUND)</span><br><span class=\"line\">  find_package(pybind11)     # module</span><br><span class=\"line\">endif()</span><br></pre></td></tr></table></figure><br>cmake/Modules/Findpybind11.cmakefind_pathpybind11/pybind11.hpybind11CMakeDependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../third_party/pybind11/include)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure><br>(7) OPENMP<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FIND_PACKAGE(OpenMP QUIET)</span><br></pre></td></tr></table></figure><br>OpenMP${OpenMP_CXX_FLAGS}  ${OpenMP_CXX_LIBRARIES}flagcaffe2OpenMPcaffe2/CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_options(caffe2 INTERFACE $&#123;OpenMP_CXX_FLAGS&#125;)</span><br><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;OpenMP_CXX_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure><br>(8) CUDADependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/public/cuda.cmake)</span><br></pre></td></tr></table></figure><br>cuda.cmake find_librarycudaIMPORTED target<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2::cuda UNKNOWN IMPORTED)</span><br></pre></td></tr></table></figure><br>cudacaffe2::cudartcaffe2::cudnncaffe2::curandcaffe2::cufftcaffe2::tensorrt caffe2::cublascaffe2::nvrtcDependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">list(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)</span><br></pre></td></tr></table></figure><br>Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txt</p>\n<p>(9) NCCLCUBGLOO</p>\n<p>Dependencies.cmakecaffe2QNNPACKCaffe2_DEPENDENCY_LIBSCaffe2_PUBLIC_DEPENDENCY_LIBSCaffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txtflag<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;Caffe2_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure></p>\n<ol>\n<li>pythoncaffe2</li>\n</ol>\n<ul>\n<li>torch._C <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_libraries=[&#x27;shm&#x27;, &#x27;torch_python&#x27;]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_sources=[&quot;torch/csrc/stub.cpp&quot;]</span><br></pre></td></tr></table></figure></li>\n<li>torch._dltorch/csrc/dl.c <dlfcn.h>torch._dl<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RTLD_GLOBAL=0x100</span><br><span class=\"line\">RTLD_NOW   =0x2</span><br><span class=\"line\">RTLD_LAZY  =0x1</span><br></pre></td></tr></table></figure>\ntorch._Cdlopen()python os flagpythonDLFCNtorch._dlflagtorch._dl</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>PyTorch</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>C++pythonCUDA<br>","more":"<br>tensorflowpytorchtensorflowpytorch</p>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --recursive https://github.com/pytorch/pytorch</span><br></pre></td></tr></table></figure></p>\n<p>recursivepytorchroot dir$ROOT_DIR</p>\n<p>Linux<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd pytorch</span><br><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><br>pytorchC++pythonsetuptoolspython$ROOT_DIR/setup.pysetup()build_deps() caffe2 </p>\n<h3 id=\"build-deps\"><a href=\"#build-deps\" class=\"headerlink\" title=\"build_deps()\"></a>build_deps()</h3><p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">build_caffe2(...)</span><br></pre></td></tr></table></figure><br>build_caffe2</p>\n<ol>\n<li>run_cmakecmakecmake<code>$ROOD_DIR/build</code> cmakeSource Tree$ROOD_DIR top levelCMakeLists.txt</li>\n<li>$ROOT_DIR/buildmake install ninja installcmakeMakefileinstalltargetbuild</li>\n<li>build/caffe2/proto.py caffe2/proto/.pycaffe2/proto/.proto</li>\n</ol>\n<p>run_cmakecmake-D optioncmakesource treecmake top levelCMakeLists.txt1)2)include dirlib dir3.cmakecmake4C++5/<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br><span class=\"line\">add_subdirectory(modules)</span><br></pre></td></tr></table></figure><br>c10,caffe2,modulesbuild treeCMakeLists.txt CMakeLists.txt</p>\n<p>top level CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include(cmake/Dependencies.cmake)</span><br></pre></td></tr></table></figure><br>Dependencies.cmakeCaffe2<code>$ROOT_DIR/third_party</code>$ROOT_DIR/caffe2</p>\n<ol>\n<li>BLASBLAS=OpenBLASsetup.py, OpenBLASDependencies.cmake<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">elseif(BLAS STREQUAL &quot;OpenBLAS&quot;)</span><br><span class=\"line\">  find_package(OpenBLAS REQUIRED)</span><br><span class=\"line\">  include_directories(SYSTEM $&#123;OpenBLAS_INCLUDE_DIR&#125;)</span><br><span class=\"line\">  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS $&#123;OpenBLAS_LIB&#125;)</span><br></pre></td></tr></table></figure>\nfind_package<code>$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake</code>.cmakeOpenBLAScblas.hopenblas OpenBLAS_INCLUDE_DIROpenBLAS_LIBCaffe2_PUBLIC_DEPENDENCY_LIBS$ROOT_DIR/caffe2/CMakeLists.txt<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PUBLIC $&#123;Caffe2_PUBLIC_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>\n-lopenblas</li>\n</ol>\n<p>caffe2_pybind11_state$ROOT_DIR/caffe2/CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(python)</span><br><span class=\"line\">...</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">install(TARGETS caffe2_pybind11_state DESTINATION &quot;$&#123;PYTHON_LIB_REL_PATH&#125;/caffe2/python&quot;)</span><br></pre></td></tr></table></figure><br>Caffe2_CPU_PYTHON_SRCS$ROOT_DIR/caffe2/python/CMakeLists.txt CUDAROCM , caffe2_pybind11_state_gpucaffe2_pybind11_state_hipinstallpythonsite-packagescaffe2/python</p>\n<p>build_dep()$ROOT_DIR/setup.pysetup</p>\n<h3 id=\"setup\"><a href=\"#setup\" class=\"headerlink\" title=\"setup()\"></a>setup()</h3><p>setup<a href=\"https://docs.python.org/3/distutils/apiref.html\">setup()</a></p>\n<ol>\n<li>ext_modules 5</li>\n</ol>\n<ul>\n<li>torch._C C++/dir</li>\n<li>torch._dl WINDOWSC</li>\n<li>caffe2.python.caffe2_pybind11_state</li>\n<li>caffe2.python.caffe2_pybind11_state_gpu</li>\n<li>caffe2.python.caffe2_pybind11_state_hip</li>\n</ul>\n<p>caffe2.pythonpackage$ROOT_DIR/build/caffe2/pythonext_modulesbuild_ext</p>\n<ol>\n<li>cmdclassbuild_ext, clean, installactionactionpython setup.py <action> install cleanpattern.gitignorebuild_extbuild_ext</li>\n</ol>\n<ul>\n<li>create_compile_commandscompile_commands.jsongccg++gccsinclude c++ compile_commands.json<code>$ROOT_DIR/CMakeLists.txtset(CMAKE_EXPORT_COMPILE_COMMAND ON)</code>$ROOT_DIR/buildjsonworking directorycommand<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;directory&quot;:&quot;&lt;path/to/root&gt;build/third_party/protobuf/cmake&quot;,</span><br><span class=\"line\">  &quot;command&quot;: &quot;/usr/bin/c++ ... -I&lt;path/to/root&gt;/third_party/protobuf/src ... </span><br><span class=\"line\">                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...&quot;,</span><br><span class=\"line\">  &quot;file&quot;: &quot;&lt;path/to/root&gt;/third_party/protobuf/src/google/protobuf/arena.cc&quot;</span><br><span class=\"line\">&#125;,</span><br><span class=\"line\">...</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n{} .o gccg++$ROOT_DIR/compile_commands.json</li>\n<li>runlibrary CUDA, CUDNN, NUMPY</li>\n<li>build_extensions ext_modulespython</li>\n</ul>\n<p>ext_modules5build_deps()caffe2_pybind11_state_gpucaffe2_pybind11_state_hipCUDAROCMbuild_deps()ext_modulesbuild_extensionstorch._C, torch._dl</p>\n<p>build_deps()ext_modules <code>$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/</code>build_deps()ext_modules <code>$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/</code>caffe2.python.caffe2_pybind11_state<code>$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/</code>caffe2_pybind11_statepython.cpython-37m-x86_64-linux-gnu.so$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so build_extensions() pythonsite-packages/miniconda3/lib/python3.7/site-packages/caffe2/python/</p>\n<ol>\n<li>packages python site-packages<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">packages = find_packages(exclude=[&#x27;tools&#x27;, &#x27;tools.*&#x27;])</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>PyTorchtoolscaffe2torch<strong>init</strong>.pycaffe2torchsite-packages</p>\n<p>ext_modules5torch._C, torch._dlsite-packages/torch_C, _dlextcaffe2.site-packages/caffe2/python</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>pytorch:</p>\n<ol>\n<li>CMakec++build_deps()</li>\n<li>pythonsetupbuild_ext</li>\n</ol>\n<p><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top-levelCMakeLists.txt</span><br><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br></pre></td></tr></table></figure><br>caffe2CMakeLists.txt <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2_proto STATIC $&lt;TARGET_OBJECTS:Caffe2_PROTO&gt;</span><br><span class=\"line\">add_library(thnvrtc SHARED $&#123;TORCH_SRC_DIR&#125;/csrc/jit/fuser/cuda/thnvrtc.cpp&gt;</span><br><span class=\"line\">add_library(caffe2 $&#123;Caffe2_CPU_SRCS&#125;)</span><br><span class=\"line\">if (TORCH_STATIC)</span><br><span class=\"line\">  add_library(torch STATIC $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">else()</span><br><span class=\"line\">  add_library(torch SHARED $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">endif()</span><br><span class=\"line\">torch_cuda_based_add_library(caffe2_gpu $&#123;Caffe2_GPU_SRCS&#125;)</span><br><span class=\"line\">hip_add_library(caffe2_hip $&#123;Caffe2_HIP_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_gpu MODULE $&#123;Caffe2_GPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_hip MODULE $&#123;Caffe2_HIP_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure><br>install<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(../torch torch)</span><br></pre></td></tr></table></figure><br>caffe2CMakeLists.txtadd_subdirectorytorch</p>\n<p>torchCMakeLists.txt <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;TORCH_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure><br>torch/lib/libshmCMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD_LIBRARY(shm SHARED core.cpp)</span><br></pre></td></tr></table></figure><br>pytorchCMakecmake/Dependencies.cmake</p>\n<ul>\n<li>Caffe2_PUBLIC_DEPENDENCY_LIBSOpenBLAS g++flag <code>-I&lt;include dir&gt;flag</code></li>\n<li><br>(1) tbb<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;/aten/src/ATen/cpu/tbb)    # tbb</span><br></pre></td></tr></table></figure>\n(2) qnnpack<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  qnnpack </span><br><span class=\"line\"># source directory$&#123;PROJECT_SOURCE_DIR&#125;/third_party/QNNPACK</span><br><span class=\"line\"># output directory$&#123;PROJECT_BINARY_DIR&#125;/confu-deps/QNNPACK</span><br><span class=\"line\">add_subdirectory(&quot;$&#123;QNNPACK_SOURCE_DIR&#125;&quot; &quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/QNNPACK&quot;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)</span><br></pre></td></tr></table></figure>\nCMakeQNNPACKthird_partyqnnpackDependencies.cmakeCaffe2_DEPENDENCY_LIBS<br>(3) nnpack<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  nnpack</span><br><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/External/nnpack.cmake)</span><br></pre></td></tr></table></figure>\nnnpack.cmake<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;NNPACK_SOURCE_DIR&#125; $&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/NNPACK)</span><br></pre></td></tr></table></figure>\nNNPACKthird_partyNNPACKCMakeLists.txtCMake nnpackDependencies.cmakennpackCaffe2_DEPENDENCY_LIBS</li>\n</ul>\n<p>(4)  cpuinfogflagglog::gloggoogletestfbgemmfp16</p>\n<p>(5) LMDB<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(LMDB)</span><br></pre></td></tr></table></figure><br>cmake/ModulesFindLMDB.cmake .cmakelmdblmdb.hlinux/usr/lib/x86_64-linux-gnu/usr/include, LMDB_LIBRARIESLMDB_INCLUDE_DIRDependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;LMDB_INCLUDE_DIR&#125;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS $&#123;LMDB_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure><br>OPENCLLEVELDBNUMAZMQREDISOPENCVFFMPEGPythonMPI</p>\n<p>(6) pybind11Dependencies.cmakepybind11<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(pybind11 CONFIG)# $&#123;pybind11_DIR&#125;pybind11Config.cmake</span><br><span class=\"line\">if(NOT pybind11_FOUND)</span><br><span class=\"line\">  find_package(pybind11)     # module</span><br><span class=\"line\">endif()</span><br></pre></td></tr></table></figure><br>cmake/Modules/Findpybind11.cmakefind_pathpybind11/pybind11.hpybind11CMakeDependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../third_party/pybind11/include)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure><br>(7) OPENMP<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FIND_PACKAGE(OpenMP QUIET)</span><br></pre></td></tr></table></figure><br>OpenMP${OpenMP_CXX_FLAGS}  ${OpenMP_CXX_LIBRARIES}flagcaffe2OpenMPcaffe2/CMakeLists.txt<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_options(caffe2 INTERFACE $&#123;OpenMP_CXX_FLAGS&#125;)</span><br><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;OpenMP_CXX_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure><br>(8) CUDADependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/public/cuda.cmake)</span><br></pre></td></tr></table></figure><br>cuda.cmake find_librarycudaIMPORTED target<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2::cuda UNKNOWN IMPORTED)</span><br></pre></td></tr></table></figure><br>cudacaffe2::cudartcaffe2::cudnncaffe2::curandcaffe2::cufftcaffe2::tensorrt caffe2::cublascaffe2::nvrtcDependencies.cmake<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">list(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)</span><br></pre></td></tr></table></figure><br>Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txt</p>\n<p>(9) NCCLCUBGLOO</p>\n<p>Dependencies.cmakecaffe2QNNPACKCaffe2_DEPENDENCY_LIBSCaffe2_PUBLIC_DEPENDENCY_LIBSCaffe2_PUBLIC_CUDA_DEPENDENCY_LIBScaffe2/CMakeLists.txtflag<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;Caffe2_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure></p>\n<ol>\n<li>pythoncaffe2</li>\n</ol>\n<ul>\n<li>torch._C <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_libraries=[&#x27;shm&#x27;, &#x27;torch_python&#x27;]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_sources=[&quot;torch/csrc/stub.cpp&quot;]</span><br></pre></td></tr></table></figure></li>\n<li>torch._dltorch/csrc/dl.c <dlfcn.h>torch._dl<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RTLD_GLOBAL=0x100</span><br><span class=\"line\">RTLD_NOW   =0x2</span><br><span class=\"line\">RTLD_LAZY  =0x1</span><br></pre></td></tr></table></figure>\ntorch._Cdlopen()python os flagpythonDLFCNtorch._dlflagtorch._dl</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>PyTorch</p>"},{"title":"PyTorch-3","p":"pytorch/PyTorch-3","date":"2019-06-18T08:44:44.000Z","_content":" [PyTorch-2](PyTorch-2)  torch  package  PyTorch [](https://pytorch.org/docs/stable/torch.html)\n<!-- more -->\n# torch \n `torch/__init__.py`  torch \n1. / typename, is_tensor, is_storage, _storage_classes \n2.  torch /\n   ```\n   from .random import set_rng_state, get_rng_state, manual_seed, initial_seed\n   ...\n   ```\n3.  torch._C //\n4.  torch._C._VariableFunctions /\n   \nPyTorch  torch \n## torch.empty\n torch._C._VariableFunctions  torch/csrc/Module.cpp  THPVariable_initModule torch/csrc/autograd/python_variable.cpp  torch::autograd::initTorchFunctions torch/csrc/autograd/generated/python_torch_functions.cpp PyTorch \n1. caffe2/CMakeLists.txt \n   ```\n   set(GENERATED_CXX_PYTHON\n     ...\n     \"${TORCH_SRC_DIR}/csrc/autograd/generated/python_torch_functions.cpp\"\n     ...)\n   ...\n   add_custom_command(\n       OUTPUT\n       ${TORCH_GENERATED_CODE}\n       COMMAND\n       \"${PYTHON_EXECUTABLE}\" tools/setup_helpers/generate_code.py\n        ...\n       DEPENDS\n       ...)\n   ```\n2.  tools/setup_helpers/generate_code.py generate_code \n   ```\n   generate_nn_wrappers\n   gen_autograd_python\n   gen_autograd\n   gen_jit_dispatch\n   ```\n torch/csrc/autograd/generated/python_torch_functions.cpp  tools/autograd/templates/python_torch_functions.cpp  ${py_methods}  ${py_method_defs}  torch/share/ATen/Declarations.yaml, tools/autograd/deprecated.yaml, tools/autograd/derivatives.yaml\n1.  caffe2/CMakeLists.txt \n   ```\n   include(../cmake/Codegen.cmake)\n   ```\n2.  cmake/Codegen.cmake  `gen.py`\n   ```\n   SET(GEN_COMMAND\n       \"${PYTHON_EXECUTABLE}\" ${CMAKE_CURRENT_LIST_DIR}/../aten/src/ATen/gen.py\n       --source-path ${CMAKE_CURRENT_LIST_DIR}/../aten/src/ATen\n       --install_dir ${CMAKE_BINARY_DIR}/aten/src/ATen\n       ${GEN_ROCM_FLAG}\n       ${cwrap_files})\n   ```\n    aten/src/ATen/native/native_functions.yaml  `empty` \n3. aten/src/ATen/gen.py  generate_outputs  Declarations.yaml \n   ```\n   file_manager.write(\"Declarations.yaml\", format_yaml(output_declarations))\n   ```\n4.  2 install_dir  build/aten/src/ATen Declarations.yaml  build/aten/src/ATen\n   - CMakeLists.txt  add_subdirectory(caffe2)\n   - caffe2/CMakeLists.txt  add_subdirectory(../aten aten)\n   - aten/CMakeLists.txt  add_subdirectory(src/ATen)\n   - aten/src/ATen/CMakeLists.txt \n     ```\n     INSTALL(FILES ${CMAKE_BINARY_DIR}/aten/src/ATen/Declarations.yaml\n       DESTINATION ${AT_INSTALL_SHARE_DIR}/ATen)\n     ```\n    Declarations.yaml aten/src/ATen/CMakeLists.txt  build/aten/src/ATen/Functions.h aten/src/ATen/CMakeLists.txt  INSTALL \n   \n tools/autograd/gen_python_functions.py  create_python_bindings  ${py_methods}  ${py_method_defs} \n```\nPY_VARIABLE_METHOD_VARARGS = CodeTemplate(\"\"\"\\\nstatic PyObject * ${pycname}(PyObject* self_, PyObject* args, PyObject* kwargs)\n{\n    HANDLE_TH_ERRORS\n    static PythonArgsParser parser({\n        ${signatures}\n    }, /*traceable=*/${traceable});\n    ${unpack_self}\n    ParserArgs<${max_args}> parsed_args;\n    auto r = parser.parse(args, kwargs, parsed_args);\n    ${declare_namedtuple_return_types}\n    ${dispatch}\n    Py_RETURN_NONE;\n    END_HANDLE_TH_ERRORS\n}\n\"\"\")\n...\ndef create_python_bindings(python_functions, has_self, is_module=False):\n    def process_function(name, declarations):\n        ...\n        env = {\n            'name': name,\n            'dispatch_name': 'dispatch_{}'.format(name),\n            'pycname': 'THPVariable_{}'.format(name),\n            'signature': [],\n            'max_args': max(len(o['arguments'])+len(o['python_binding_arguments']) for o in declarations),\n            'unpack_self': [],\n            'dispatch': [],\n            'declare_namedtuple_return_types': '',\n        }\n        ... //  env  key-value pair or  env  key  value\n        if len(declarations) == 1 and len(declarations[0]['args']) == 1 and has_self:\n            ...\n        else:\n            tmpl = PY_VARIABLE_METHOD_VARARGS\n            env['flags'] = 'METH_VARARGS | METH_KEYWORDS'\n        if not is_module and not has_self:\n            env['flags'] += ' | METH_STATIC'\n        \n        py_methods.append(tmpl.substitute(env))\n        py_methods_defs.append(PY_VARIABLE_METHOD_DEF.substitute(env))\n```\n PY_VARIABLE_METHOD_VARARGS Declarations.yaml, deprecated.yaml, derivatives.yaml env  PY_VARIABLE_METHOD_VARARGS  env  key \n\n## empty \n empty  torch/csrc/autograd/generated/python_torch_function.cpp\n```\nstatic PyObject * THPVariable_empty(PyObject* self_, PyObject* args, PyObject* kwargs)\n{\n    HANDLE_TH_ERRORS\n    static PythonArgParser parser({\n        \"empty(IntList size, *, Tensor out=None, ScalarType dtype=None, Layout layout=torch.strided, Device device=None, bool requires_grad=False)\",\n    }, /*tracebalbe*/true); // vector\n    ParseArgs<6> parsed_args;\n    auto r = parser.parse(args, kwargs, parseed_args);\n    if (r.idx == 0) {       // vector\n        if (r.isNone(1)) {  // parameter 'out' is None\n            auto size = r.intlist(0);\n            auto dtype = r.scalartype(2);\n            auto device = r.device(4);\n            const auto options = TensorOptions()\n                .dtype(dtype)\n                .device(device)\n                .layout(r.layout(3).layout)\n                .requires_grad(r.toBool(5));\n            return wrap(dispatch_empty(size, options));\n        } else {\n            check_out_type_matches(r.tensor(1), r.scalartype(2), r.isNone(2),\n                                   r.layout(3), r.isNone(3),\n                                   r.device(4), r.isNone(4));\n            return wrap(dispatch_empty(r.intlist(0), r.tensor(1)).set_requires_grad(r.toBool(5)));\n        }\n    }\n    Py_RETURN_NONE;\n    END_HANDLE_TH_ERRORS\n}\n```\n empty  Tensor Tensor Tensor\n1. `out` None dtype, device, layout  requires_grad  Tensor\n2. `out` None,  `out`  Tensor  dtype, layout, device  `out`  requires_grad  requires_grad\n\n dispatch_empty torch/csrc/autograd/generated/python_torch_functions_dispatch.h python_torch_function.cpp  tools/autograd/templates/python_torch_functions_dispatch.h  tools/autograd/gen_python_functions.py  gen_py_torch_functionsdispatch_empty \n```\n// empty  Tensor 'out'\ninline Tensor dispatch_empty(IntList size, Tensor result) {\n    AutoNoGIL no_gil;\n    return at::empty_out(result, size);\n}\n// empty  Tensor 'out' options \ninline Tensor dispatch_empty(IntList size, const TensorOptions & options) {\n    maybe_initialize_cuda(options);\n    AutoNoGIL no_gil;\n    return torch::empty(size, options);\n}\n```\n###  Tensor\n Tensor AutoNoGIL\n```\nAutoNoGIL() : save(PyEval_SaveThread()) {}\n```\n GIL at::empty_out  GIL at::empty_out  GIL\n```\n~AutoNoGIL() {\n    PyEval_RestoreThread(save);\n}\n```\n at::empty_out  torch/lib/include/Aten/Functions.h\n```\nstatic inline Tensor & empty_out(Tensor & result, IntList size) {\n    return detail::infer_type(result).empty_out(result, size);\n}\n```\n at::empty_out  Functions.h  aten/src/ATen/gen.py  generate_outputs  Declarations.yaml \n```\nfile_manager.write('Functions.h', FUNCTIONS_H, top_env)\n```\n at::empty_out  detail::infer_type(result)  Tensor  result  TypeExtendedInference  empty_out TypeExtendedInferfaceTypeDefault torch/lib/include/ATen/TypeExtendedInferface.h torch/lib/include/ATen/TypeDefault.hTypeDefault build/aten/src/ATen/TypeDefault.cpp empty_out \n```\nTensor & TypeDefault::empty_out(Tensor & result, IntList size) const {\n    return at::native::empty_out(/* native_actuals */ result, size);\n}\n```\n Declarations.yaml  at::native::empty_out  torch/lib/include/ATen/NativeFunctions.h Declarations.yaml  aten/src/ATen/native/TensorFactories.cpp\n```\nnamespace at {\nnamespace native {\n...\nTensor& empty_out(Tensor& result, IntList size) {\n    if (result.is_sparse()) {\n        result.sparse_resize_and_clear_(size, size.size(), 0);\n    } else {\n        result.resize_(size);\n    }\n    return result;\n}\n...\n}\n}\n```\n Tensor \n1.  Tensor \n   \n    Tensor  sparse_resize_and_clear_ torch/lib/include/ATen/core/Tensor.h Declarations.yaml  aten/src/ATen/gen.py aten/src/ATen/core/Tensor.h TensorMethods.h  Type.h sparse_resize_and_clear_  torch/lib/include/ATen/core/TensorMethods.h\n   ```\n   inline Tensor & Tensor::sparse_resize_and_clear_(IntList size, int64_t sparse_dim, int64_t dense_dim) {\n       return type().sparse_resize_and_clear_(*this, size, sparse_dim, dense_dim);\n   }\n   ```\n    Tensor  Type Type  sparse_resize_and_clear_ Type  Type  .cpp Type  int,float,double  BackendCPU,CUDA,SparseCPU, SparseCUDA  SparseCPUByteType.h  SparseCPUByteType.cpp\n   ```\n   Tensor & SparseCPUByteType::sparse_resize_and_clear_(Tensor & self, IntList size, int64_t sparse_dim, int64_t dense_dim) const {\n       const OptionalDeviceGuard device_guard(device_of(self));\n       return at::native::sparse_resize_and_clear_(/* actuals */ self, size, sparse_dim, dense_dim);\n   }\n   ```\n    at::native::sparse_resize_and_clear_  torch/lib/include/ATen/NativeFunctions.h aten/src/ATen/native/sparse/SparseTensor.cpp\n   ```\n   SparseTensor& sparse_resize_and_clear_(SparseTensor& self, ArrayRef<int64_t> size, int64_t sparse_dim, int64_t dense_dim) {\n       get_sparse_impl(self)->resize_and_clear_(sparse_dim, dense_dim, size);\n       return self;\n   }\n   ```\n    Tensor  SparseTensorImpl  SparseTensorImpl  resize_and_clear_\n2.  Tensor \n   \n   Tensor  resize_  TensorMethods.h\n   ```\n   inline Tensor & Tensor::resize_(IntList size) {\n       return type().resize_(*this, size);\n   }\n   ```\n    Tensor  resize_ CPUByteType.cpp \n   ```c++\n   Tensor & CPUByteType::resize_(Tensor & self, IntList size) const {\n       return at::native::resize_cpu_(/* actuals */ self, size);\n   }\n   ```\n    Tensor  size  resize  aten/src/ATen/native/Resize.cpp  resize_cpu_ \n   ```c++\n   Tensor& resize_cpu_(Tensor& self, IntList size) {\n       auto* self = self.unsafeGetTensorImpl();         //  Tensor \n       //  size  Tensor  resize size  Tensor size \n       resize_impl_cpu_(self_, size, c10::nullopt);     \n       self_->maybe_zero_dim(size.size()==0);\n       return self;\n   }\n   ```\n   resize_impl_cpu_  cpu  resize  aten/src/ATen/native/Resize.h \n   ```c++\n   inline TensorImpl* resize_impl_cpu_(\n       TensorImpl* self,\n       IntList size,\n       c10::optional<IntList> stride) {\n       if (self->sizes() == size && (!stride || self->strides() == stride)) {\n           //  size  size \n           // size size \n           return self;\n       }\n       int64_t storage_size = 1;\n       ...\n       if(!stride){     // stride=1\n           self->set_sizes_contiguous(size);    //  size  size\n           storage_size = self->numel();        //  size  size  (n1,n2,n3) n1 * n2 * n3\n       }\n       maybe_resize_storage_cpu(self, storage_size);    // resize \n   }\n   \n   static inline void maybe_resize_storage_cpu(TensorImpl* self, int64_t new_size) {\n       ...\n       if (new_size+self->storage_offset() > self->storage().numel()) {\n           // self->storage_offset()  0\n           // \n           THStorage_resize(THTensor_getStoragePtr(self), new_size+self->storage_offset());\n       }\n   }\n   ```\n    aten/src/TH/THStorageFunctions.cpp  THStorage_resize \n   ```c++\n   void THStorage_resize(THStorage* storage, ptrdiff_t size) {\n       if (storage->resizable()) {\n           at::DataPtr new_data;\n           if (size != 0) {\n               new_data = storage->allocator()->allocate(storage->itemsize()*size);\n           }\n           //  Tensor \n           //  Tensor \n           at::DataPtr old_data = storage->set_data_ptr(std::move(new_data));\n           ptrdiff_t old_size = storage->numel();   //  size\n           storage->set_numel(size);                // \n           if (old_data != nullptr) {\n               ptrdiff_t copy_size = old_size;\n               if (storage->numel() < copy_size) {\n                   copy_size = storage_numel();\n               }\n               if (copy_size > 0) {                 // \n                   memcpy(\n                       storage->data(),\n                       old_data.get(),\n                       storage->itemsize() * copy_size);\n               }\n           }\n       }\n       ...\n   }\n   ```\n    resize  N1resize  N2\n   1. N1 >= N2 size N1  N2 \n   2. N1 < N2 N1  N1  Tensor  allocator \n\n torch.empty \n```python\nimport torch\n\nx=torch.rand(3,4)\nprint(x)\ntorch.empty(4,5,out=x)  # resize  size\nprint(x)\ntorch.empty(1,2,out=x)  # resize  size\nprint(x)\ntorch.empty(4,4,out=x)  #  resize  size\n```\n\n```\ntensor([[0.0446, 0.1545, 0.5059, 0.6027],\n        [0.4872, 0.4557, 0.1010, 0.2962],\n        [0.0576, 0.1087, 0.3033, 0.4694]])\ntensor([[4.4638e-02, 1.5454e-01, 5.0591e-01, 6.0266e-01, 4.8720e-01],\n        [4.5573e-01, 1.0103e-01, 2.9619e-01, 5.7569e-02, 1.0874e-01],\n        [3.0331e-01, 4.6944e-01, 0.0000e+00, 0.0000e+00,        nan],\n        [0.0000e+00, 1.4013e-45, 0.0000e+00, 1.4013e-45, 0.0000e+00]])\ntensor([[0.0446, 0.1545]])\ntensor([[0.0446, 0.1545, 0.5059, 0.6027],\n        [0.4872, 0.4557, 0.1010, 0.2962],\n        [0.0576, 0.1087, 0.3033, 0.4694],\n        [0.0000, 0.0000,    nan, 0.0000]])\n```\n###  Tensor\n torch/csrc/autograd/generated/python_torch_functions_dispatch.h  tensor  dispatch_empty  torch::empty torch/csrc/autograd/generated/variable_factories.h jit  Tensor \n```c++\ninline at::Tensor empty(at::IntList size, const at::TensorOptions & options={}) {\n    ...     // jit tracing\n    at::Tensor tensor = at::empty(size, at::TensorOptions(options).is_variable(false));\n    auto result = autograd::make_variable(tensor, options.requires_grad()); //  Tensor  Variable\n    ...     // jit tracing\n    return result\n}\n```\n at::empty  Functions.h\n```c++\nstatic inline Tensor empty(IntList size, const TensorOptions & options) {\n    return at::getType(options).empty(size, options);\n}\n```\n Tensor  empty  at::getType(options)  options  TypeExtendedInterface  instance options.backend(), options.dtype()  options.is_variable()  CPU  backend  aten/src/ATen/Context.cpp  Context  register_cpu_types(this)  register_cpu_type(Context* context)  build/aten/src/ATen/RegisterCPU.cpp  aten/src/ATen/gen.py  generate_outputs  gen.py  register_cpu_types \n```\nCPUByteType\nCPUCharType\nCPUDoubleType\nCPUFloatType\nCPUIntType\nCPULongType\nCPUShortType\n...\n```\n CPUByteType empty \n```\nTensor CPUByteType::empty(IntList size, const TensorOptions & options) const {\n    const DeviceGuard device_guard(options.device());   //  device  Tensor\n    return at::native::empty_cpu(size, options);\n}\n```\n at::native::empty_cpu  aten/src/ATen/native/TensorFactories.cpp \n```c++\nauto* allocator = at::getCPUAllocator();\nint64_t nelements = prod_intlist(size); // \nauto dtype = options.dtype();\nauto storage_impl = c10::make_intrusive<StorageImpl>(\n    dtype,\n    nelements,\n    allocator->allocate(nelements*dtype.itemsize()),\n    allocator,\n    /*resizeable=*/true\n);\nauto tensor = detail::make_tensor<TensorImpl>(storage_impl, at::CPUTensorId(), false);\n```\n c10::make_intrusive<StorageImpl>  new StorageImpl(...) wrap  intrusive_ptr [PyTorch-2](2019/06/13/PyTorch-2)  Tensor  StorageImpl StorageImpl  detail::make_tensor  Tensor at::getCPUAllocator  THDefaultAllocator  allocate  THAlloc THAlloc  THAllocInternal  malloc posix_memalign  \n\n\n```python\nimport torch\ntorch.empty(2,3)\n```\n\n```\ntensor([[1.6504e-12,3.0637e-41,1.6588e-12],\n        [3.0637e-41,4.4842e-44,0.0000e+00]])\n```\n\n### Tensor \n torch.empty  torch.Tensor  `torch/__init__.py`  `import autograd` `torch/autograd/__init__.py`\n```python\nif not torch._C._autograd_init():\n```\n_autograd_init  python  torch/csrc/Module.cpp  THPAutograd_initExtension  c++  torch/csrc/autograd/autograd.h  torch/csrc/autograd/init.cpp \n```c++\n//  torch/tensor.py \nauto tensor_module = THPObjectPtr(PyImport_ImportModule(\"torch.tensor\"));\n//  torch/tensor.py  Tensor \nTHPVariableClass = PyObject_GetAttrString(tensor_module, \"Tensor\");\n```\n `THPVariableClass`  torch/csrc/autograd/python_variable.h \n```c++\nTHP_API PyObject *THPVariableClass;\n```\n extern  torch/csrc/autograd/python_variable.cpp  torch.empty  c++  THPVariable_empty  dispatch_empty  Variable  wrap  PyObject wrap  torch/csrc/autograd/utils/wrap_outputs.h  THPVariable_Wrap torch/csrc/autograd/python_variable.cpp THPVariableClass  THPVariableClass  torch/tensor.py  Tensor  THPVariable_Wrap  THPVariable_NewWithVar  Variable  THPVariableClass  Tensor THPVariable_NewWithVar \n```c++\nstatic PyObject* THPVariable_NewWithVar(PyTypeObject* type, Variable var) {\nPyObject *obj=type->tp_alloc(type, 0);      //  torch.Tensor \nif(obj) {\n    auto v = (THPVariable*)obj; // cast  THPVariable  torch.Tensor  torch._C._TensorBase \n    new(&v->cdata) Variable(std::move(var));    //  VariableC++  Tensor\n    v->cdata.set_pyobj(obj);\n    ...\n}\nreturn obj;\n}\n```\n\n\n```python\n>>> type(torch.empty(2,3))\n<class 'torch.Tensor'>\n```\n\n# PS\n","source":"_posts/pytorch/PyTorch-3.md","raw":"---\ntitle: PyTorch-3\np: pytorch/PyTorch-3\ndate: 2019-06-18 16:44:44\ntags: PyTorch\ncategories: DL Framework\n---\n [PyTorch-2](PyTorch-2)  torch  package  PyTorch [](https://pytorch.org/docs/stable/torch.html)\n<!-- more -->\n# torch \n `torch/__init__.py`  torch \n1. / typename, is_tensor, is_storage, _storage_classes \n2.  torch /\n   ```\n   from .random import set_rng_state, get_rng_state, manual_seed, initial_seed\n   ...\n   ```\n3.  torch._C //\n4.  torch._C._VariableFunctions /\n   \nPyTorch  torch \n## torch.empty\n torch._C._VariableFunctions  torch/csrc/Module.cpp  THPVariable_initModule torch/csrc/autograd/python_variable.cpp  torch::autograd::initTorchFunctions torch/csrc/autograd/generated/python_torch_functions.cpp PyTorch \n1. caffe2/CMakeLists.txt \n   ```\n   set(GENERATED_CXX_PYTHON\n     ...\n     \"${TORCH_SRC_DIR}/csrc/autograd/generated/python_torch_functions.cpp\"\n     ...)\n   ...\n   add_custom_command(\n       OUTPUT\n       ${TORCH_GENERATED_CODE}\n       COMMAND\n       \"${PYTHON_EXECUTABLE}\" tools/setup_helpers/generate_code.py\n        ...\n       DEPENDS\n       ...)\n   ```\n2.  tools/setup_helpers/generate_code.py generate_code \n   ```\n   generate_nn_wrappers\n   gen_autograd_python\n   gen_autograd\n   gen_jit_dispatch\n   ```\n torch/csrc/autograd/generated/python_torch_functions.cpp  tools/autograd/templates/python_torch_functions.cpp  ${py_methods}  ${py_method_defs}  torch/share/ATen/Declarations.yaml, tools/autograd/deprecated.yaml, tools/autograd/derivatives.yaml\n1.  caffe2/CMakeLists.txt \n   ```\n   include(../cmake/Codegen.cmake)\n   ```\n2.  cmake/Codegen.cmake  `gen.py`\n   ```\n   SET(GEN_COMMAND\n       \"${PYTHON_EXECUTABLE}\" ${CMAKE_CURRENT_LIST_DIR}/../aten/src/ATen/gen.py\n       --source-path ${CMAKE_CURRENT_LIST_DIR}/../aten/src/ATen\n       --install_dir ${CMAKE_BINARY_DIR}/aten/src/ATen\n       ${GEN_ROCM_FLAG}\n       ${cwrap_files})\n   ```\n    aten/src/ATen/native/native_functions.yaml  `empty` \n3. aten/src/ATen/gen.py  generate_outputs  Declarations.yaml \n   ```\n   file_manager.write(\"Declarations.yaml\", format_yaml(output_declarations))\n   ```\n4.  2 install_dir  build/aten/src/ATen Declarations.yaml  build/aten/src/ATen\n   - CMakeLists.txt  add_subdirectory(caffe2)\n   - caffe2/CMakeLists.txt  add_subdirectory(../aten aten)\n   - aten/CMakeLists.txt  add_subdirectory(src/ATen)\n   - aten/src/ATen/CMakeLists.txt \n     ```\n     INSTALL(FILES ${CMAKE_BINARY_DIR}/aten/src/ATen/Declarations.yaml\n       DESTINATION ${AT_INSTALL_SHARE_DIR}/ATen)\n     ```\n    Declarations.yaml aten/src/ATen/CMakeLists.txt  build/aten/src/ATen/Functions.h aten/src/ATen/CMakeLists.txt  INSTALL \n   \n tools/autograd/gen_python_functions.py  create_python_bindings  ${py_methods}  ${py_method_defs} \n```\nPY_VARIABLE_METHOD_VARARGS = CodeTemplate(\"\"\"\\\nstatic PyObject * ${pycname}(PyObject* self_, PyObject* args, PyObject* kwargs)\n{\n    HANDLE_TH_ERRORS\n    static PythonArgsParser parser({\n        ${signatures}\n    }, /*traceable=*/${traceable});\n    ${unpack_self}\n    ParserArgs<${max_args}> parsed_args;\n    auto r = parser.parse(args, kwargs, parsed_args);\n    ${declare_namedtuple_return_types}\n    ${dispatch}\n    Py_RETURN_NONE;\n    END_HANDLE_TH_ERRORS\n}\n\"\"\")\n...\ndef create_python_bindings(python_functions, has_self, is_module=False):\n    def process_function(name, declarations):\n        ...\n        env = {\n            'name': name,\n            'dispatch_name': 'dispatch_{}'.format(name),\n            'pycname': 'THPVariable_{}'.format(name),\n            'signature': [],\n            'max_args': max(len(o['arguments'])+len(o['python_binding_arguments']) for o in declarations),\n            'unpack_self': [],\n            'dispatch': [],\n            'declare_namedtuple_return_types': '',\n        }\n        ... //  env  key-value pair or  env  key  value\n        if len(declarations) == 1 and len(declarations[0]['args']) == 1 and has_self:\n            ...\n        else:\n            tmpl = PY_VARIABLE_METHOD_VARARGS\n            env['flags'] = 'METH_VARARGS | METH_KEYWORDS'\n        if not is_module and not has_self:\n            env['flags'] += ' | METH_STATIC'\n        \n        py_methods.append(tmpl.substitute(env))\n        py_methods_defs.append(PY_VARIABLE_METHOD_DEF.substitute(env))\n```\n PY_VARIABLE_METHOD_VARARGS Declarations.yaml, deprecated.yaml, derivatives.yaml env  PY_VARIABLE_METHOD_VARARGS  env  key \n\n## empty \n empty  torch/csrc/autograd/generated/python_torch_function.cpp\n```\nstatic PyObject * THPVariable_empty(PyObject* self_, PyObject* args, PyObject* kwargs)\n{\n    HANDLE_TH_ERRORS\n    static PythonArgParser parser({\n        \"empty(IntList size, *, Tensor out=None, ScalarType dtype=None, Layout layout=torch.strided, Device device=None, bool requires_grad=False)\",\n    }, /*tracebalbe*/true); // vector\n    ParseArgs<6> parsed_args;\n    auto r = parser.parse(args, kwargs, parseed_args);\n    if (r.idx == 0) {       // vector\n        if (r.isNone(1)) {  // parameter 'out' is None\n            auto size = r.intlist(0);\n            auto dtype = r.scalartype(2);\n            auto device = r.device(4);\n            const auto options = TensorOptions()\n                .dtype(dtype)\n                .device(device)\n                .layout(r.layout(3).layout)\n                .requires_grad(r.toBool(5));\n            return wrap(dispatch_empty(size, options));\n        } else {\n            check_out_type_matches(r.tensor(1), r.scalartype(2), r.isNone(2),\n                                   r.layout(3), r.isNone(3),\n                                   r.device(4), r.isNone(4));\n            return wrap(dispatch_empty(r.intlist(0), r.tensor(1)).set_requires_grad(r.toBool(5)));\n        }\n    }\n    Py_RETURN_NONE;\n    END_HANDLE_TH_ERRORS\n}\n```\n empty  Tensor Tensor Tensor\n1. `out` None dtype, device, layout  requires_grad  Tensor\n2. `out` None,  `out`  Tensor  dtype, layout, device  `out`  requires_grad  requires_grad\n\n dispatch_empty torch/csrc/autograd/generated/python_torch_functions_dispatch.h python_torch_function.cpp  tools/autograd/templates/python_torch_functions_dispatch.h  tools/autograd/gen_python_functions.py  gen_py_torch_functionsdispatch_empty \n```\n// empty  Tensor 'out'\ninline Tensor dispatch_empty(IntList size, Tensor result) {\n    AutoNoGIL no_gil;\n    return at::empty_out(result, size);\n}\n// empty  Tensor 'out' options \ninline Tensor dispatch_empty(IntList size, const TensorOptions & options) {\n    maybe_initialize_cuda(options);\n    AutoNoGIL no_gil;\n    return torch::empty(size, options);\n}\n```\n###  Tensor\n Tensor AutoNoGIL\n```\nAutoNoGIL() : save(PyEval_SaveThread()) {}\n```\n GIL at::empty_out  GIL at::empty_out  GIL\n```\n~AutoNoGIL() {\n    PyEval_RestoreThread(save);\n}\n```\n at::empty_out  torch/lib/include/Aten/Functions.h\n```\nstatic inline Tensor & empty_out(Tensor & result, IntList size) {\n    return detail::infer_type(result).empty_out(result, size);\n}\n```\n at::empty_out  Functions.h  aten/src/ATen/gen.py  generate_outputs  Declarations.yaml \n```\nfile_manager.write('Functions.h', FUNCTIONS_H, top_env)\n```\n at::empty_out  detail::infer_type(result)  Tensor  result  TypeExtendedInference  empty_out TypeExtendedInferfaceTypeDefault torch/lib/include/ATen/TypeExtendedInferface.h torch/lib/include/ATen/TypeDefault.hTypeDefault build/aten/src/ATen/TypeDefault.cpp empty_out \n```\nTensor & TypeDefault::empty_out(Tensor & result, IntList size) const {\n    return at::native::empty_out(/* native_actuals */ result, size);\n}\n```\n Declarations.yaml  at::native::empty_out  torch/lib/include/ATen/NativeFunctions.h Declarations.yaml  aten/src/ATen/native/TensorFactories.cpp\n```\nnamespace at {\nnamespace native {\n...\nTensor& empty_out(Tensor& result, IntList size) {\n    if (result.is_sparse()) {\n        result.sparse_resize_and_clear_(size, size.size(), 0);\n    } else {\n        result.resize_(size);\n    }\n    return result;\n}\n...\n}\n}\n```\n Tensor \n1.  Tensor \n   \n    Tensor  sparse_resize_and_clear_ torch/lib/include/ATen/core/Tensor.h Declarations.yaml  aten/src/ATen/gen.py aten/src/ATen/core/Tensor.h TensorMethods.h  Type.h sparse_resize_and_clear_  torch/lib/include/ATen/core/TensorMethods.h\n   ```\n   inline Tensor & Tensor::sparse_resize_and_clear_(IntList size, int64_t sparse_dim, int64_t dense_dim) {\n       return type().sparse_resize_and_clear_(*this, size, sparse_dim, dense_dim);\n   }\n   ```\n    Tensor  Type Type  sparse_resize_and_clear_ Type  Type  .cpp Type  int,float,double  BackendCPU,CUDA,SparseCPU, SparseCUDA  SparseCPUByteType.h  SparseCPUByteType.cpp\n   ```\n   Tensor & SparseCPUByteType::sparse_resize_and_clear_(Tensor & self, IntList size, int64_t sparse_dim, int64_t dense_dim) const {\n       const OptionalDeviceGuard device_guard(device_of(self));\n       return at::native::sparse_resize_and_clear_(/* actuals */ self, size, sparse_dim, dense_dim);\n   }\n   ```\n    at::native::sparse_resize_and_clear_  torch/lib/include/ATen/NativeFunctions.h aten/src/ATen/native/sparse/SparseTensor.cpp\n   ```\n   SparseTensor& sparse_resize_and_clear_(SparseTensor& self, ArrayRef<int64_t> size, int64_t sparse_dim, int64_t dense_dim) {\n       get_sparse_impl(self)->resize_and_clear_(sparse_dim, dense_dim, size);\n       return self;\n   }\n   ```\n    Tensor  SparseTensorImpl  SparseTensorImpl  resize_and_clear_\n2.  Tensor \n   \n   Tensor  resize_  TensorMethods.h\n   ```\n   inline Tensor & Tensor::resize_(IntList size) {\n       return type().resize_(*this, size);\n   }\n   ```\n    Tensor  resize_ CPUByteType.cpp \n   ```c++\n   Tensor & CPUByteType::resize_(Tensor & self, IntList size) const {\n       return at::native::resize_cpu_(/* actuals */ self, size);\n   }\n   ```\n    Tensor  size  resize  aten/src/ATen/native/Resize.cpp  resize_cpu_ \n   ```c++\n   Tensor& resize_cpu_(Tensor& self, IntList size) {\n       auto* self = self.unsafeGetTensorImpl();         //  Tensor \n       //  size  Tensor  resize size  Tensor size \n       resize_impl_cpu_(self_, size, c10::nullopt);     \n       self_->maybe_zero_dim(size.size()==0);\n       return self;\n   }\n   ```\n   resize_impl_cpu_  cpu  resize  aten/src/ATen/native/Resize.h \n   ```c++\n   inline TensorImpl* resize_impl_cpu_(\n       TensorImpl* self,\n       IntList size,\n       c10::optional<IntList> stride) {\n       if (self->sizes() == size && (!stride || self->strides() == stride)) {\n           //  size  size \n           // size size \n           return self;\n       }\n       int64_t storage_size = 1;\n       ...\n       if(!stride){     // stride=1\n           self->set_sizes_contiguous(size);    //  size  size\n           storage_size = self->numel();        //  size  size  (n1,n2,n3) n1 * n2 * n3\n       }\n       maybe_resize_storage_cpu(self, storage_size);    // resize \n   }\n   \n   static inline void maybe_resize_storage_cpu(TensorImpl* self, int64_t new_size) {\n       ...\n       if (new_size+self->storage_offset() > self->storage().numel()) {\n           // self->storage_offset()  0\n           // \n           THStorage_resize(THTensor_getStoragePtr(self), new_size+self->storage_offset());\n       }\n   }\n   ```\n    aten/src/TH/THStorageFunctions.cpp  THStorage_resize \n   ```c++\n   void THStorage_resize(THStorage* storage, ptrdiff_t size) {\n       if (storage->resizable()) {\n           at::DataPtr new_data;\n           if (size != 0) {\n               new_data = storage->allocator()->allocate(storage->itemsize()*size);\n           }\n           //  Tensor \n           //  Tensor \n           at::DataPtr old_data = storage->set_data_ptr(std::move(new_data));\n           ptrdiff_t old_size = storage->numel();   //  size\n           storage->set_numel(size);                // \n           if (old_data != nullptr) {\n               ptrdiff_t copy_size = old_size;\n               if (storage->numel() < copy_size) {\n                   copy_size = storage_numel();\n               }\n               if (copy_size > 0) {                 // \n                   memcpy(\n                       storage->data(),\n                       old_data.get(),\n                       storage->itemsize() * copy_size);\n               }\n           }\n       }\n       ...\n   }\n   ```\n    resize  N1resize  N2\n   1. N1 >= N2 size N1  N2 \n   2. N1 < N2 N1  N1  Tensor  allocator \n\n torch.empty \n```python\nimport torch\n\nx=torch.rand(3,4)\nprint(x)\ntorch.empty(4,5,out=x)  # resize  size\nprint(x)\ntorch.empty(1,2,out=x)  # resize  size\nprint(x)\ntorch.empty(4,4,out=x)  #  resize  size\n```\n\n```\ntensor([[0.0446, 0.1545, 0.5059, 0.6027],\n        [0.4872, 0.4557, 0.1010, 0.2962],\n        [0.0576, 0.1087, 0.3033, 0.4694]])\ntensor([[4.4638e-02, 1.5454e-01, 5.0591e-01, 6.0266e-01, 4.8720e-01],\n        [4.5573e-01, 1.0103e-01, 2.9619e-01, 5.7569e-02, 1.0874e-01],\n        [3.0331e-01, 4.6944e-01, 0.0000e+00, 0.0000e+00,        nan],\n        [0.0000e+00, 1.4013e-45, 0.0000e+00, 1.4013e-45, 0.0000e+00]])\ntensor([[0.0446, 0.1545]])\ntensor([[0.0446, 0.1545, 0.5059, 0.6027],\n        [0.4872, 0.4557, 0.1010, 0.2962],\n        [0.0576, 0.1087, 0.3033, 0.4694],\n        [0.0000, 0.0000,    nan, 0.0000]])\n```\n###  Tensor\n torch/csrc/autograd/generated/python_torch_functions_dispatch.h  tensor  dispatch_empty  torch::empty torch/csrc/autograd/generated/variable_factories.h jit  Tensor \n```c++\ninline at::Tensor empty(at::IntList size, const at::TensorOptions & options={}) {\n    ...     // jit tracing\n    at::Tensor tensor = at::empty(size, at::TensorOptions(options).is_variable(false));\n    auto result = autograd::make_variable(tensor, options.requires_grad()); //  Tensor  Variable\n    ...     // jit tracing\n    return result\n}\n```\n at::empty  Functions.h\n```c++\nstatic inline Tensor empty(IntList size, const TensorOptions & options) {\n    return at::getType(options).empty(size, options);\n}\n```\n Tensor  empty  at::getType(options)  options  TypeExtendedInterface  instance options.backend(), options.dtype()  options.is_variable()  CPU  backend  aten/src/ATen/Context.cpp  Context  register_cpu_types(this)  register_cpu_type(Context* context)  build/aten/src/ATen/RegisterCPU.cpp  aten/src/ATen/gen.py  generate_outputs  gen.py  register_cpu_types \n```\nCPUByteType\nCPUCharType\nCPUDoubleType\nCPUFloatType\nCPUIntType\nCPULongType\nCPUShortType\n...\n```\n CPUByteType empty \n```\nTensor CPUByteType::empty(IntList size, const TensorOptions & options) const {\n    const DeviceGuard device_guard(options.device());   //  device  Tensor\n    return at::native::empty_cpu(size, options);\n}\n```\n at::native::empty_cpu  aten/src/ATen/native/TensorFactories.cpp \n```c++\nauto* allocator = at::getCPUAllocator();\nint64_t nelements = prod_intlist(size); // \nauto dtype = options.dtype();\nauto storage_impl = c10::make_intrusive<StorageImpl>(\n    dtype,\n    nelements,\n    allocator->allocate(nelements*dtype.itemsize()),\n    allocator,\n    /*resizeable=*/true\n);\nauto tensor = detail::make_tensor<TensorImpl>(storage_impl, at::CPUTensorId(), false);\n```\n c10::make_intrusive<StorageImpl>  new StorageImpl(...) wrap  intrusive_ptr [PyTorch-2](2019/06/13/PyTorch-2)  Tensor  StorageImpl StorageImpl  detail::make_tensor  Tensor at::getCPUAllocator  THDefaultAllocator  allocate  THAlloc THAlloc  THAllocInternal  malloc posix_memalign  \n\n\n```python\nimport torch\ntorch.empty(2,3)\n```\n\n```\ntensor([[1.6504e-12,3.0637e-41,1.6588e-12],\n        [3.0637e-41,4.4842e-44,0.0000e+00]])\n```\n\n### Tensor \n torch.empty  torch.Tensor  `torch/__init__.py`  `import autograd` `torch/autograd/__init__.py`\n```python\nif not torch._C._autograd_init():\n```\n_autograd_init  python  torch/csrc/Module.cpp  THPAutograd_initExtension  c++  torch/csrc/autograd/autograd.h  torch/csrc/autograd/init.cpp \n```c++\n//  torch/tensor.py \nauto tensor_module = THPObjectPtr(PyImport_ImportModule(\"torch.tensor\"));\n//  torch/tensor.py  Tensor \nTHPVariableClass = PyObject_GetAttrString(tensor_module, \"Tensor\");\n```\n `THPVariableClass`  torch/csrc/autograd/python_variable.h \n```c++\nTHP_API PyObject *THPVariableClass;\n```\n extern  torch/csrc/autograd/python_variable.cpp  torch.empty  c++  THPVariable_empty  dispatch_empty  Variable  wrap  PyObject wrap  torch/csrc/autograd/utils/wrap_outputs.h  THPVariable_Wrap torch/csrc/autograd/python_variable.cpp THPVariableClass  THPVariableClass  torch/tensor.py  Tensor  THPVariable_Wrap  THPVariable_NewWithVar  Variable  THPVariableClass  Tensor THPVariable_NewWithVar \n```c++\nstatic PyObject* THPVariable_NewWithVar(PyTypeObject* type, Variable var) {\nPyObject *obj=type->tp_alloc(type, 0);      //  torch.Tensor \nif(obj) {\n    auto v = (THPVariable*)obj; // cast  THPVariable  torch.Tensor  torch._C._TensorBase \n    new(&v->cdata) Variable(std::move(var));    //  VariableC++  Tensor\n    v->cdata.set_pyobj(obj);\n    ...\n}\nreturn obj;\n}\n```\n\n\n```python\n>>> type(torch.empty(2,3))\n<class 'torch.Tensor'>\n```\n\n# PS\n","slug":"pytorch/PyTorch-3","published":1,"updated":"2020-04-24T10:34:35.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92f005cp0djhk3sdj9s","content":"<p> <a href=\"PyTorch-2\">PyTorch-2</a>  torch  package  PyTorch <a href=\"https://pytorch.org/docs/stable/torch.html\"></a><br><span id=\"more\"></span></p>\n<h1 id=\"torch-\"><a href=\"#torch-\" class=\"headerlink\" title=\"torch \"></a>torch </h1><p> <code>torch/__init__.py</code>  torch </p>\n<ol>\n<li>/ typename, is_tensor, is_storage, _storage_classes </li>\n<li> torch /<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from .random import set_rng_state, get_rng_state, manual_seed, initial_seed</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></li>\n<li> torch._C //</li>\n<li> torch._C._VariableFunctions /</li>\n</ol>\n<p>PyTorch  torch </p>\n<h2 id=\"torch-empty\"><a href=\"#torch-empty\" class=\"headerlink\" title=\"torch.empty\"></a>torch.empty</h2><p> torch._C._VariableFunctions  torch/csrc/Module.cpp  THPVariable_initModule torch/csrc/autograd/python_variable.cpp  torch::autograd::initTorchFunctions torch/csrc/autograd/generated/python_torch_functions.cpp PyTorch </p>\n<ol>\n<li>caffe2/CMakeLists.txt <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(GENERATED_CXX_PYTHON</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  &quot;$&#123;TORCH_SRC_DIR&#125;/csrc/autograd/generated/python_torch_functions.cpp&quot;</span><br><span class=\"line\">  ...)</span><br><span class=\"line\">...</span><br><span class=\"line\">add_custom_command(</span><br><span class=\"line\">    OUTPUT</span><br><span class=\"line\">    $&#123;TORCH_GENERATED_CODE&#125;</span><br><span class=\"line\">    COMMAND</span><br><span class=\"line\">    &quot;$&#123;PYTHON_EXECUTABLE&#125;&quot; tools/setup_helpers/generate_code.py</span><br><span class=\"line\">     ...</span><br><span class=\"line\">    DEPENDS</span><br><span class=\"line\">    ...)</span><br></pre></td></tr></table></figure></li>\n<li> tools/setup_helpers/generate_code.py generate_code <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">generate_nn_wrappers</span><br><span class=\"line\">gen_autograd_python</span><br><span class=\"line\">gen_autograd</span><br><span class=\"line\">gen_jit_dispatch</span><br></pre></td></tr></table></figure>\n torch/csrc/autograd/generated/python_torch_functions.cpp  tools/autograd/templates/python_torch_functions.cpp  ${py_methods}  ${py_method_defs}  torch/share/ATen/Declarations.yaml, tools/autograd/deprecated.yaml, tools/autograd/derivatives.yaml</li>\n<li> caffe2/CMakeLists.txt <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include(../cmake/Codegen.cmake)</span><br></pre></td></tr></table></figure></li>\n<li> cmake/Codegen.cmake  <code>gen.py</code><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET(GEN_COMMAND</span><br><span class=\"line\">    &quot;$&#123;PYTHON_EXECUTABLE&#125;&quot; $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../aten/src/ATen/gen.py</span><br><span class=\"line\">    --source-path $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../aten/src/ATen</span><br><span class=\"line\">    --install_dir $&#123;CMAKE_BINARY_DIR&#125;/aten/src/ATen</span><br><span class=\"line\">    $&#123;GEN_ROCM_FLAG&#125;</span><br><span class=\"line\">    $&#123;cwrap_files&#125;)</span><br></pre></td></tr></table></figure>\n aten/src/ATen/native/native_functions.yaml  <code>empty</code> </li>\n<li>aten/src/ATen/gen.py  generate_outputs  Declarations.yaml <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">file_manager.write(&quot;Declarations.yaml&quot;, format_yaml(output_declarations))</span><br></pre></td></tr></table></figure></li>\n<li> 2 install_dir  build/aten/src/ATen Declarations.yaml  build/aten/src/ATen<ul>\n<li>CMakeLists.txt  add_subdirectory(caffe2)</li>\n<li>caffe2/CMakeLists.txt  add_subdirectory(../aten aten)</li>\n<li>aten/CMakeLists.txt  add_subdirectory(src/ATen)</li>\n<li>aten/src/ATen/CMakeLists.txt <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSTALL(FILES $&#123;CMAKE_BINARY_DIR&#125;/aten/src/ATen/Declarations.yaml</span><br><span class=\"line\">  DESTINATION $&#123;AT_INSTALL_SHARE_DIR&#125;/ATen)</span><br></pre></td></tr></table></figure>\n Declarations.yaml aten/src/ATen/CMakeLists.txt  build/aten/src/ATen/Functions.h aten/src/ATen/CMakeLists.txt  INSTALL </li>\n</ul>\n</li>\n</ol>\n<p> tools/autograd/gen_python_functions.py  create_python_bindings  ${py_methods}  ${py_method_defs} <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PY_VARIABLE_METHOD_VARARGS = CodeTemplate(&quot;&quot;&quot;\\</span><br><span class=\"line\">static PyObject * $&#123;pycname&#125;(PyObject* self_, PyObject* args, PyObject* kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    HANDLE_TH_ERRORS</span><br><span class=\"line\">    static PythonArgsParser parser(&#123;</span><br><span class=\"line\">        $&#123;signatures&#125;</span><br><span class=\"line\">    &#125;, /*traceable=*/$&#123;traceable&#125;);</span><br><span class=\"line\">    $&#123;unpack_self&#125;</span><br><span class=\"line\">    ParserArgs&lt;$&#123;max_args&#125;&gt; parsed_args;</span><br><span class=\"line\">    auto r = parser.parse(args, kwargs, parsed_args);</span><br><span class=\"line\">    $&#123;declare_namedtuple_return_types&#125;</span><br><span class=\"line\">    $&#123;dispatch&#125;</span><br><span class=\"line\">    Py_RETURN_NONE;</span><br><span class=\"line\">    END_HANDLE_TH_ERRORS</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&quot;&quot;&quot;)</span><br><span class=\"line\">...</span><br><span class=\"line\">def create_python_bindings(python_functions, has_self, is_module=False):</span><br><span class=\"line\">    def process_function(name, declarations):</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        env = &#123;</span><br><span class=\"line\">            &#x27;name&#x27;: name,</span><br><span class=\"line\">            &#x27;dispatch_name&#x27;: &#x27;dispatch_&#123;&#125;&#x27;.format(name),</span><br><span class=\"line\">            &#x27;pycname&#x27;: &#x27;THPVariable_&#123;&#125;&#x27;.format(name),</span><br><span class=\"line\">            &#x27;signature&#x27;: [],</span><br><span class=\"line\">            &#x27;max_args&#x27;: max(len(o[&#x27;arguments&#x27;])+len(o[&#x27;python_binding_arguments&#x27;]) for o in declarations),</span><br><span class=\"line\">            &#x27;unpack_self&#x27;: [],</span><br><span class=\"line\">            &#x27;dispatch&#x27;: [],</span><br><span class=\"line\">            &#x27;declare_namedtuple_return_types&#x27;: &#x27;&#x27;,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ... //  env  key-value pair or  env  key  value</span><br><span class=\"line\">        if len(declarations) == 1 and len(declarations[0][&#x27;args&#x27;]) == 1 and has_self:</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            tmpl = PY_VARIABLE_METHOD_VARARGS</span><br><span class=\"line\">            env[&#x27;flags&#x27;] = &#x27;METH_VARARGS | METH_KEYWORDS&#x27;</span><br><span class=\"line\">        if not is_module and not has_self:</span><br><span class=\"line\">            env[&#x27;flags&#x27;] += &#x27; | METH_STATIC&#x27;</span><br><span class=\"line\">        </span><br><span class=\"line\">        py_methods.append(tmpl.substitute(env))</span><br><span class=\"line\">        py_methods_defs.append(PY_VARIABLE_METHOD_DEF.substitute(env))</span><br></pre></td></tr></table></figure><br> PY_VARIABLE_METHOD_VARARGS Declarations.yaml, deprecated.yaml, derivatives.yaml env  PY_VARIABLE_METHOD_VARARGS  env  key </p>\n<h2 id=\"empty-\"><a href=\"#empty-\" class=\"headerlink\" title=\"empty \"></a>empty </h2><p> empty  torch/csrc/autograd/generated/python_torch_function.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyObject * THPVariable_empty(PyObject* self_, PyObject* args, PyObject* kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    HANDLE_TH_ERRORS</span><br><span class=\"line\">    static PythonArgParser parser(&#123;</span><br><span class=\"line\">        &quot;empty(IntList size, *, Tensor out=None, ScalarType dtype=None, Layout layout=torch.strided, Device device=None, bool requires_grad=False)&quot;,</span><br><span class=\"line\">    &#125;, /*tracebalbe*/true); // vector</span><br><span class=\"line\">    ParseArgs&lt;6&gt; parsed_args;</span><br><span class=\"line\">    auto r = parser.parse(args, kwargs, parseed_args);</span><br><span class=\"line\">    if (r.idx == 0) &#123;       // vector</span><br><span class=\"line\">        if (r.isNone(1)) &#123;  // parameter &#x27;out&#x27; is None</span><br><span class=\"line\">            auto size = r.intlist(0);</span><br><span class=\"line\">            auto dtype = r.scalartype(2);</span><br><span class=\"line\">            auto device = r.device(4);</span><br><span class=\"line\">            const auto options = TensorOptions()</span><br><span class=\"line\">                .dtype(dtype)</span><br><span class=\"line\">                .device(device)</span><br><span class=\"line\">                .layout(r.layout(3).layout)</span><br><span class=\"line\">                .requires_grad(r.toBool(5));</span><br><span class=\"line\">            return wrap(dispatch_empty(size, options));</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            check_out_type_matches(r.tensor(1), r.scalartype(2), r.isNone(2),</span><br><span class=\"line\">                                   r.layout(3), r.isNone(3),</span><br><span class=\"line\">                                   r.device(4), r.isNone(4));</span><br><span class=\"line\">            return wrap(dispatch_empty(r.intlist(0), r.tensor(1)).set_requires_grad(r.toBool(5)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Py_RETURN_NONE;</span><br><span class=\"line\">    END_HANDLE_TH_ERRORS</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> empty  Tensor Tensor Tensor</p>\n<ol>\n<li><code>out</code> None dtype, device, layout  requires_grad  Tensor</li>\n<li><code>out</code> None,  <code>out</code>  Tensor  dtype, layout, device  <code>out</code>  requires_grad  requires_grad</li>\n</ol>\n<p> dispatch_empty torch/csrc/autograd/generated/python_torch_functions_dispatch.h python_torch_function.cpp  tools/autograd/templates/python_torch_functions_dispatch.h  tools/autograd/gen_python_functions.py  gen_py_torch_functionsdispatch_empty <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// empty  Tensor &#x27;out&#x27;</span><br><span class=\"line\">inline Tensor dispatch_empty(IntList size, Tensor result) &#123;</span><br><span class=\"line\">    AutoNoGIL no_gil;</span><br><span class=\"line\">    return at::empty_out(result, size);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// empty  Tensor &#x27;out&#x27; options </span><br><span class=\"line\">inline Tensor dispatch_empty(IntList size, const TensorOptions &amp; options) &#123;</span><br><span class=\"line\">    maybe_initialize_cuda(options);</span><br><span class=\"line\">    AutoNoGIL no_gil;</span><br><span class=\"line\">    return torch::empty(size, options);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"-Tensor\"><a href=\"#-Tensor\" class=\"headerlink\" title=\" Tensor\"></a> Tensor</h3><p> Tensor AutoNoGIL<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AutoNoGIL() : save(PyEval_SaveThread()) &#123;&#125;</span><br></pre></td></tr></table></figure><br> GIL at::empty_out  GIL at::empty_out  GIL<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~AutoNoGIL() &#123;</span><br><span class=\"line\">    PyEval_RestoreThread(save);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::empty_out  torch/lib/include/Aten/Functions.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static inline Tensor &amp; empty_out(Tensor &amp; result, IntList size) &#123;</span><br><span class=\"line\">    return detail::infer_type(result).empty_out(result, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::empty_out  Functions.h  aten/src/ATen/gen.py  generate_outputs  Declarations.yaml <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">file_manager.write(&#x27;Functions.h&#x27;, FUNCTIONS_H, top_env)</span><br></pre></td></tr></table></figure><br> at::empty_out  detail::infer_type(result)  Tensor  result  TypeExtendedInference  empty_out TypeExtendedInferfaceTypeDefault torch/lib/include/ATen/TypeExtendedInferface.h torch/lib/include/ATen/TypeDefault.hTypeDefault build/aten/src/ATen/TypeDefault.cpp empty_out <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor &amp; TypeDefault::empty_out(Tensor &amp; result, IntList size) const &#123;</span><br><span class=\"line\">    return at::native::empty_out(/* native_actuals */ result, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Declarations.yaml  at::native::empty_out  torch/lib/include/ATen/NativeFunctions.h Declarations.yaml  aten/src/ATen/native/TensorFactories.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace at &#123;</span><br><span class=\"line\">namespace native &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">Tensor&amp; empty_out(Tensor&amp; result, IntList size) &#123;</span><br><span class=\"line\">    if (result.is_sparse()) &#123;</span><br><span class=\"line\">        result.sparse_resize_and_clear_(size, size.size(), 0);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        result.resize_(size);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return result;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Tensor </p>\n<ol>\n<li><p> Tensor </p>\n<p> Tensor  sparse_resize_and_clear_ torch/lib/include/ATen/core/Tensor.h Declarations.yaml  aten/src/ATen/gen.py aten/src/ATen/core/Tensor.h TensorMethods.h  Type.h sparse_resize_and_clear_  torch/lib/include/ATen/core/TensorMethods.h</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inline Tensor &amp; Tensor::sparse_resize_and_clear_(IntList size, int64_t sparse_dim, int64_t dense_dim) &#123;</span><br><span class=\"line\">    return type().sparse_resize_and_clear_(*this, size, sparse_dim, dense_dim);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  Type Type  sparse_resize_and_clear_ Type  Type  .cpp Type  int,float,double  BackendCPU,CUDA,SparseCPU, SparseCUDA  SparseCPUByteType.h  SparseCPUByteType.cpp</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor &amp; SparseCPUByteType::sparse_resize_and_clear_(Tensor &amp; self, IntList size, int64_t sparse_dim, int64_t dense_dim) const &#123;</span><br><span class=\"line\">    const OptionalDeviceGuard device_guard(device_of(self));</span><br><span class=\"line\">    return at::native::sparse_resize_and_clear_(/* actuals */ self, size, sparse_dim, dense_dim);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> at::native::sparse_resize_and_clear_  torch/lib/include/ATen/NativeFunctions.h aten/src/ATen/native/sparse/SparseTensor.cpp</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SparseTensor&amp; sparse_resize_and_clear_(SparseTensor&amp; self, ArrayRef&lt;int64_t&gt; size, int64_t sparse_dim, int64_t dense_dim) &#123;</span><br><span class=\"line\">    get_sparse_impl(self)-&gt;resize_and_clear_(sparse_dim, dense_dim, size);</span><br><span class=\"line\">    return self;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  SparseTensorImpl  SparseTensorImpl  resize_and_clear_</p>\n</li>\n<li><p> Tensor </p>\n<p>Tensor  resize_  TensorMethods.h</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inline Tensor &amp; Tensor::resize_(IntList size) &#123;</span><br><span class=\"line\">    return type().resize_(*this, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  resize_ CPUByteType.cpp </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Tensor &amp; <span class=\"title\">CPUByteType::resize_</span><span class=\"params\">(Tensor &amp; self, IntList size)</span> <span class=\"keyword\">const</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> at::native::<span class=\"built_in\">resize_cpu_</span>(<span class=\"comment\">/* actuals */</span> self, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  size  resize  aten/src/ATen/native/Resize.cpp  resize_cpu_ </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Tensor&amp; <span class=\"title\">resize_cpu_</span><span class=\"params\">(Tensor&amp; self, IntList size)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">auto</span>* self = self.<span class=\"built_in\">unsafeGetTensorImpl</span>();         <span class=\"comment\">//  Tensor </span></span><br><span class=\"line\">    <span class=\"comment\">//  size  Tensor  resize size  Tensor size </span></span><br><span class=\"line\">    <span class=\"built_in\">resize_impl_cpu_</span>(self_, size, c10::nullopt);     </span><br><span class=\"line\">    self_-&gt;<span class=\"built_in\">maybe_zero_dim</span>(size.<span class=\"built_in\">size</span>()==<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> self;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>resize_impl_cpu_  cpu  resize  aten/src/ATen/native/Resize.h </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> TensorImpl* <span class=\"title\">resize_impl_cpu_</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">    TensorImpl* self,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">    IntList size,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">    c10::optional&lt;IntList&gt; stride)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (self-&gt;<span class=\"built_in\">sizes</span>() == size &amp;&amp; (!stride || self-&gt;<span class=\"built_in\">strides</span>() == stride)) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//  size  size </span></span><br><span class=\"line\">        <span class=\"comment\">// size size </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">int64_t</span> storage_size = <span class=\"number\">1</span>;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!stride)&#123;     <span class=\"comment\">// stride=1</span></span><br><span class=\"line\">        self-&gt;<span class=\"built_in\">set_sizes_contiguous</span>(size);    <span class=\"comment\">//  size  size</span></span><br><span class=\"line\">        storage_size = self-&gt;<span class=\"built_in\">numel</span>();        <span class=\"comment\">//  size  size  (n1,n2,n3) n1 * n2 * n3</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">maybe_resize_storage_cpu</span>(self, storage_size);    <span class=\"comment\">// resize </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> <span class=\"title\">maybe_resize_storage_cpu</span><span class=\"params\">(TensorImpl* self, <span class=\"keyword\">int64_t</span> new_size)</span> </span>&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (new_size+self-&gt;<span class=\"built_in\">storage_offset</span>() &gt; self-&gt;<span class=\"built_in\">storage</span>().<span class=\"built_in\">numel</span>()) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// self-&gt;storage_offset()  0</span></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"built_in\">THStorage_resize</span>(<span class=\"built_in\">THTensor_getStoragePtr</span>(self), new_size+self-&gt;<span class=\"built_in\">storage_offset</span>());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> aten/src/TH/THStorageFunctions.cpp  THStorage_resize </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">THStorage_resize</span><span class=\"params\">(THStorage* storage, <span class=\"keyword\">ptrdiff_t</span> size)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (storage-&gt;<span class=\"built_in\">resizable</span>()) &#123;</span><br><span class=\"line\">        at::DataPtr new_data;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (size != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            new_data = storage-&gt;<span class=\"built_in\">allocator</span>()-&gt;<span class=\"built_in\">allocate</span>(storage-&gt;<span class=\"built_in\">itemsize</span>()*size);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//  Tensor </span></span><br><span class=\"line\">        <span class=\"comment\">//  Tensor </span></span><br><span class=\"line\">        at::DataPtr old_data = storage-&gt;<span class=\"built_in\">set_data_ptr</span>(std::<span class=\"built_in\">move</span>(new_data));</span><br><span class=\"line\">        <span class=\"keyword\">ptrdiff_t</span> old_size = storage-&gt;<span class=\"built_in\">numel</span>();   <span class=\"comment\">//  size</span></span><br><span class=\"line\">        storage-&gt;<span class=\"built_in\">set_numel</span>(size);                <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (old_data != <span class=\"literal\">nullptr</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">ptrdiff_t</span> copy_size = old_size;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (storage-&gt;<span class=\"built_in\">numel</span>() &lt; copy_size) &#123;</span><br><span class=\"line\">                copy_size = <span class=\"built_in\">storage_numel</span>();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (copy_size &gt; <span class=\"number\">0</span>) &#123;                 <span class=\"comment\">// </span></span><br><span class=\"line\">                <span class=\"built_in\">memcpy</span>(</span><br><span class=\"line\">                    storage-&gt;<span class=\"built_in\">data</span>(),</span><br><span class=\"line\">                    old_data.<span class=\"built_in\">get</span>(),</span><br><span class=\"line\">                    storage-&gt;<span class=\"built_in\">itemsize</span>() * copy_size);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> resize  N1resize  N2</p>\n<ol>\n<li>N1 &gt;= N2 size N1  N2 </li>\n<li>N1 &lt; N2 N1  N1  Tensor  allocator </li>\n</ol>\n</li>\n</ol>\n<p> torch.empty <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x=torch.rand(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.empty(<span class=\"number\">4</span>,<span class=\"number\">5</span>,out=x)  <span class=\"comment\"># resize  size</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.empty(<span class=\"number\">1</span>,<span class=\"number\">2</span>,out=x)  <span class=\"comment\"># resize  size</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.empty(<span class=\"number\">4</span>,<span class=\"number\">4</span>,out=x)  <span class=\"comment\">#  resize  size</span></span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([[0.0446, 0.1545, 0.5059, 0.6027],</span><br><span class=\"line\">        [0.4872, 0.4557, 0.1010, 0.2962],</span><br><span class=\"line\">        [0.0576, 0.1087, 0.3033, 0.4694]])</span><br><span class=\"line\">tensor([[4.4638e-02, 1.5454e-01, 5.0591e-01, 6.0266e-01, 4.8720e-01],</span><br><span class=\"line\">        [4.5573e-01, 1.0103e-01, 2.9619e-01, 5.7569e-02, 1.0874e-01],</span><br><span class=\"line\">        [3.0331e-01, 4.6944e-01, 0.0000e+00, 0.0000e+00,        nan],</span><br><span class=\"line\">        [0.0000e+00, 1.4013e-45, 0.0000e+00, 1.4013e-45, 0.0000e+00]])</span><br><span class=\"line\">tensor([[0.0446, 0.1545]])</span><br><span class=\"line\">tensor([[0.0446, 0.1545, 0.5059, 0.6027],</span><br><span class=\"line\">        [0.4872, 0.4557, 0.1010, 0.2962],</span><br><span class=\"line\">        [0.0576, 0.1087, 0.3033, 0.4694],</span><br><span class=\"line\">        [0.0000, 0.0000,    nan, 0.0000]])</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"-Tensor\"><a href=\"#-Tensor\" class=\"headerlink\" title=\" Tensor\"></a> Tensor</h3><p> torch/csrc/autograd/generated/python_torch_functions_dispatch.h  tensor  dispatch_empty  torch::empty torch/csrc/autograd/generated/variable_factories.h jit  Tensor <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> at::Tensor <span class=\"title\">empty</span><span class=\"params\">(at::IntList size, <span class=\"keyword\">const</span> at::TensorOptions &amp; options=&#123;&#125;)</span> </span>&#123;</span><br><span class=\"line\">    ...     <span class=\"comment\">// jit tracing</span></span><br><span class=\"line\">    at::Tensor tensor = at::<span class=\"built_in\">empty</span>(size, at::<span class=\"built_in\">TensorOptions</span>(options).<span class=\"built_in\">is_variable</span>(<span class=\"literal\">false</span>));</span><br><span class=\"line\">    <span class=\"keyword\">auto</span> result = autograd::<span class=\"built_in\">make_variable</span>(tensor, options.<span class=\"built_in\">requires_grad</span>()); <span class=\"comment\">//  Tensor  Variable</span></span><br><span class=\"line\">    ...     <span class=\"comment\">// jit tracing</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::empty  Functions.h<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">inline</span> Tensor <span class=\"title\">empty</span><span class=\"params\">(IntList size, <span class=\"keyword\">const</span> TensorOptions &amp; options)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> at::<span class=\"built_in\">getType</span>(options).<span class=\"built_in\">empty</span>(size, options);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Tensor  empty  at::getType(options)  options  TypeExtendedInterface  instance options.backend(), options.dtype()  options.is_variable()  CPU  backend  aten/src/ATen/Context.cpp  Context  register_cpu_types(this)  register_cpu_type(Context* context)  build/aten/src/ATen/RegisterCPU.cpp  aten/src/ATen/gen.py  generate_outputs  gen.py  register_cpu_types <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPUByteType</span><br><span class=\"line\">CPUCharType</span><br><span class=\"line\">CPUDoubleType</span><br><span class=\"line\">CPUFloatType</span><br><span class=\"line\">CPUIntType</span><br><span class=\"line\">CPULongType</span><br><span class=\"line\">CPUShortType</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br> CPUByteType empty <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor CPUByteType::empty(IntList size, const TensorOptions &amp; options) const &#123;</span><br><span class=\"line\">    const DeviceGuard device_guard(options.device());   //  device  Tensor</span><br><span class=\"line\">    return at::native::empty_cpu(size, options);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::native::empty_cpu  aten/src/ATen/native/TensorFactories.cpp <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">auto</span>* allocator = at::<span class=\"built_in\">getCPUAllocator</span>();</span><br><span class=\"line\"><span class=\"keyword\">int64_t</span> nelements = <span class=\"built_in\">prod_intlist</span>(size); <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> dtype = options.<span class=\"built_in\">dtype</span>();</span><br><span class=\"line\"><span class=\"keyword\">auto</span> storage_impl = c10::make_intrusive&lt;StorageImpl&gt;(</span><br><span class=\"line\">    dtype,</span><br><span class=\"line\">    nelements,</span><br><span class=\"line\">    allocator-&gt;<span class=\"built_in\">allocate</span>(nelements*dtype.<span class=\"built_in\">itemsize</span>()),</span><br><span class=\"line\">    allocator,</span><br><span class=\"line\">    <span class=\"comment\">/*resizeable=*/</span><span class=\"literal\">true</span></span><br><span class=\"line\">);</span><br><span class=\"line\"><span class=\"keyword\">auto</span> tensor = detail::make_tensor&lt;TensorImpl&gt;(storage_impl, at::<span class=\"built_in\">CPUTensorId</span>(), <span class=\"literal\">false</span>);</span><br></pre></td></tr></table></figure><br> c10::make_intrusive<StorageImpl>  new StorageImpl() wrap  intrusive_ptr <a href=\"2019/06/13/PyTorch-2\">PyTorch-2</a>  Tensor  StorageImpl StorageImpl  detail::make_tensor  Tensor at::getCPUAllocator  THDefaultAllocator  allocate  THAlloc THAlloc  THAllocInternal  malloc posix_memalign  </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">torch.empty(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([[1.6504e-12,3.0637e-41,1.6588e-12],</span><br><span class=\"line\">        [3.0637e-41,4.4842e-44,0.0000e+00]])</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Tensor-\"><a href=\"#Tensor-\" class=\"headerlink\" title=\"Tensor \"></a>Tensor </h3><p> torch.empty  torch.Tensor  <code>torch/__init__.py</code>  <code>import autograd</code> <code>torch/autograd/__init__.py</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> torch._C._autograd_init():</span><br></pre></td></tr></table></figure><br>_autograd_init  python  torch/csrc/Module.cpp  THPAutograd_initExtension  c++  torch/csrc/autograd/autograd.h  torch/csrc/autograd/init.cpp <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//  torch/tensor.py </span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> tensor_module = <span class=\"built_in\">THPObjectPtr</span>(<span class=\"built_in\">PyImport_ImportModule</span>(<span class=\"string\">&quot;torch.tensor&quot;</span>));</span><br><span class=\"line\"><span class=\"comment\">//  torch/tensor.py  Tensor </span></span><br><span class=\"line\">THPVariableClass = <span class=\"built_in\">PyObject_GetAttrString</span>(tensor_module, <span class=\"string\">&quot;Tensor&quot;</span>);</span><br></pre></td></tr></table></figure><br> <code>THPVariableClass</code>  torch/csrc/autograd/python_variable.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THP_API PyObject *THPVariableClass;</span><br></pre></td></tr></table></figure><br> extern  torch/csrc/autograd/python_variable.cpp  torch.empty  c++  THPVariable_empty  dispatch_empty  Variable  wrap  PyObject wrap  torch/csrc/autograd/utils/wrap_outputs.h  THPVariable_Wrap torch/csrc/autograd/python_variable.cpp THPVariableClass  THPVariableClass  torch/tensor.py  Tensor  THPVariable_Wrap  THPVariable_NewWithVar  Variable  THPVariableClass  Tensor THPVariable_NewWithVar <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject* <span class=\"title\">THPVariable_NewWithVar</span><span class=\"params\">(PyTypeObject* type, Variable var)</span> </span>&#123;</span><br><span class=\"line\">PyObject *obj=type-&gt;<span class=\"built_in\">tp_alloc</span>(type, <span class=\"number\">0</span>);      <span class=\"comment\">//  torch.Tensor </span></span><br><span class=\"line\"><span class=\"keyword\">if</span>(obj) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">auto</span> v = (THPVariable*)obj; <span class=\"comment\">// cast  THPVariable  torch.Tensor  torch._C._TensorBase </span></span><br><span class=\"line\">    <span class=\"keyword\">new</span>(&amp;v-&gt;cdata) <span class=\"built_in\">Variable</span>(std::<span class=\"built_in\">move</span>(var));    <span class=\"comment\">//  VariableC++  Tensor</span></span><br><span class=\"line\">    v-&gt;cdata.<span class=\"built_in\">set_pyobj</span>(obj);</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> obj;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"built_in\">type</span>(torch.empty(<span class=\"number\">2</span>,<span class=\"number\">3</span>))</span><br><span class=\"line\">&lt;<span class=\"class\"><span class=\"keyword\">class</span> &#x27;<span class=\"title\">torch</span>.<span class=\"title\">Tensor</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"PS\"><a href=\"#PS\" class=\"headerlink\" title=\"PS\"></a>PS</h1><p></p>\n","site":{"data":{}},"excerpt":"<p> <a href=\"PyTorch-2\">PyTorch-2</a>  torch  package  PyTorch <a href=\"https://pytorch.org/docs/stable/torch.html\"></a><br>","more":"</p>\n<h1 id=\"torch-\"><a href=\"#torch-\" class=\"headerlink\" title=\"torch \"></a>torch </h1><p> <code>torch/__init__.py</code>  torch </p>\n<ol>\n<li>/ typename, is_tensor, is_storage, _storage_classes </li>\n<li> torch /<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from .random import set_rng_state, get_rng_state, manual_seed, initial_seed</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></li>\n<li> torch._C //</li>\n<li> torch._C._VariableFunctions /</li>\n</ol>\n<p>PyTorch  torch </p>\n<h2 id=\"torch-empty\"><a href=\"#torch-empty\" class=\"headerlink\" title=\"torch.empty\"></a>torch.empty</h2><p> torch._C._VariableFunctions  torch/csrc/Module.cpp  THPVariable_initModule torch/csrc/autograd/python_variable.cpp  torch::autograd::initTorchFunctions torch/csrc/autograd/generated/python_torch_functions.cpp PyTorch </p>\n<ol>\n<li>caffe2/CMakeLists.txt <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(GENERATED_CXX_PYTHON</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  &quot;$&#123;TORCH_SRC_DIR&#125;/csrc/autograd/generated/python_torch_functions.cpp&quot;</span><br><span class=\"line\">  ...)</span><br><span class=\"line\">...</span><br><span class=\"line\">add_custom_command(</span><br><span class=\"line\">    OUTPUT</span><br><span class=\"line\">    $&#123;TORCH_GENERATED_CODE&#125;</span><br><span class=\"line\">    COMMAND</span><br><span class=\"line\">    &quot;$&#123;PYTHON_EXECUTABLE&#125;&quot; tools/setup_helpers/generate_code.py</span><br><span class=\"line\">     ...</span><br><span class=\"line\">    DEPENDS</span><br><span class=\"line\">    ...)</span><br></pre></td></tr></table></figure></li>\n<li> tools/setup_helpers/generate_code.py generate_code <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">generate_nn_wrappers</span><br><span class=\"line\">gen_autograd_python</span><br><span class=\"line\">gen_autograd</span><br><span class=\"line\">gen_jit_dispatch</span><br></pre></td></tr></table></figure>\n torch/csrc/autograd/generated/python_torch_functions.cpp  tools/autograd/templates/python_torch_functions.cpp  ${py_methods}  ${py_method_defs}  torch/share/ATen/Declarations.yaml, tools/autograd/deprecated.yaml, tools/autograd/derivatives.yaml</li>\n<li> caffe2/CMakeLists.txt <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include(../cmake/Codegen.cmake)</span><br></pre></td></tr></table></figure></li>\n<li> cmake/Codegen.cmake  <code>gen.py</code><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET(GEN_COMMAND</span><br><span class=\"line\">    &quot;$&#123;PYTHON_EXECUTABLE&#125;&quot; $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../aten/src/ATen/gen.py</span><br><span class=\"line\">    --source-path $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../aten/src/ATen</span><br><span class=\"line\">    --install_dir $&#123;CMAKE_BINARY_DIR&#125;/aten/src/ATen</span><br><span class=\"line\">    $&#123;GEN_ROCM_FLAG&#125;</span><br><span class=\"line\">    $&#123;cwrap_files&#125;)</span><br></pre></td></tr></table></figure>\n aten/src/ATen/native/native_functions.yaml  <code>empty</code> </li>\n<li>aten/src/ATen/gen.py  generate_outputs  Declarations.yaml <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">file_manager.write(&quot;Declarations.yaml&quot;, format_yaml(output_declarations))</span><br></pre></td></tr></table></figure></li>\n<li> 2 install_dir  build/aten/src/ATen Declarations.yaml  build/aten/src/ATen<ul>\n<li>CMakeLists.txt  add_subdirectory(caffe2)</li>\n<li>caffe2/CMakeLists.txt  add_subdirectory(../aten aten)</li>\n<li>aten/CMakeLists.txt  add_subdirectory(src/ATen)</li>\n<li>aten/src/ATen/CMakeLists.txt <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSTALL(FILES $&#123;CMAKE_BINARY_DIR&#125;/aten/src/ATen/Declarations.yaml</span><br><span class=\"line\">  DESTINATION $&#123;AT_INSTALL_SHARE_DIR&#125;/ATen)</span><br></pre></td></tr></table></figure>\n Declarations.yaml aten/src/ATen/CMakeLists.txt  build/aten/src/ATen/Functions.h aten/src/ATen/CMakeLists.txt  INSTALL </li>\n</ul>\n</li>\n</ol>\n<p> tools/autograd/gen_python_functions.py  create_python_bindings  ${py_methods}  ${py_method_defs} <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PY_VARIABLE_METHOD_VARARGS = CodeTemplate(&quot;&quot;&quot;\\</span><br><span class=\"line\">static PyObject * $&#123;pycname&#125;(PyObject* self_, PyObject* args, PyObject* kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    HANDLE_TH_ERRORS</span><br><span class=\"line\">    static PythonArgsParser parser(&#123;</span><br><span class=\"line\">        $&#123;signatures&#125;</span><br><span class=\"line\">    &#125;, /*traceable=*/$&#123;traceable&#125;);</span><br><span class=\"line\">    $&#123;unpack_self&#125;</span><br><span class=\"line\">    ParserArgs&lt;$&#123;max_args&#125;&gt; parsed_args;</span><br><span class=\"line\">    auto r = parser.parse(args, kwargs, parsed_args);</span><br><span class=\"line\">    $&#123;declare_namedtuple_return_types&#125;</span><br><span class=\"line\">    $&#123;dispatch&#125;</span><br><span class=\"line\">    Py_RETURN_NONE;</span><br><span class=\"line\">    END_HANDLE_TH_ERRORS</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&quot;&quot;&quot;)</span><br><span class=\"line\">...</span><br><span class=\"line\">def create_python_bindings(python_functions, has_self, is_module=False):</span><br><span class=\"line\">    def process_function(name, declarations):</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        env = &#123;</span><br><span class=\"line\">            &#x27;name&#x27;: name,</span><br><span class=\"line\">            &#x27;dispatch_name&#x27;: &#x27;dispatch_&#123;&#125;&#x27;.format(name),</span><br><span class=\"line\">            &#x27;pycname&#x27;: &#x27;THPVariable_&#123;&#125;&#x27;.format(name),</span><br><span class=\"line\">            &#x27;signature&#x27;: [],</span><br><span class=\"line\">            &#x27;max_args&#x27;: max(len(o[&#x27;arguments&#x27;])+len(o[&#x27;python_binding_arguments&#x27;]) for o in declarations),</span><br><span class=\"line\">            &#x27;unpack_self&#x27;: [],</span><br><span class=\"line\">            &#x27;dispatch&#x27;: [],</span><br><span class=\"line\">            &#x27;declare_namedtuple_return_types&#x27;: &#x27;&#x27;,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ... //  env  key-value pair or  env  key  value</span><br><span class=\"line\">        if len(declarations) == 1 and len(declarations[0][&#x27;args&#x27;]) == 1 and has_self:</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            tmpl = PY_VARIABLE_METHOD_VARARGS</span><br><span class=\"line\">            env[&#x27;flags&#x27;] = &#x27;METH_VARARGS | METH_KEYWORDS&#x27;</span><br><span class=\"line\">        if not is_module and not has_self:</span><br><span class=\"line\">            env[&#x27;flags&#x27;] += &#x27; | METH_STATIC&#x27;</span><br><span class=\"line\">        </span><br><span class=\"line\">        py_methods.append(tmpl.substitute(env))</span><br><span class=\"line\">        py_methods_defs.append(PY_VARIABLE_METHOD_DEF.substitute(env))</span><br></pre></td></tr></table></figure><br> PY_VARIABLE_METHOD_VARARGS Declarations.yaml, deprecated.yaml, derivatives.yaml env  PY_VARIABLE_METHOD_VARARGS  env  key </p>\n<h2 id=\"empty-\"><a href=\"#empty-\" class=\"headerlink\" title=\"empty \"></a>empty </h2><p> empty  torch/csrc/autograd/generated/python_torch_function.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyObject * THPVariable_empty(PyObject* self_, PyObject* args, PyObject* kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    HANDLE_TH_ERRORS</span><br><span class=\"line\">    static PythonArgParser parser(&#123;</span><br><span class=\"line\">        &quot;empty(IntList size, *, Tensor out=None, ScalarType dtype=None, Layout layout=torch.strided, Device device=None, bool requires_grad=False)&quot;,</span><br><span class=\"line\">    &#125;, /*tracebalbe*/true); // vector</span><br><span class=\"line\">    ParseArgs&lt;6&gt; parsed_args;</span><br><span class=\"line\">    auto r = parser.parse(args, kwargs, parseed_args);</span><br><span class=\"line\">    if (r.idx == 0) &#123;       // vector</span><br><span class=\"line\">        if (r.isNone(1)) &#123;  // parameter &#x27;out&#x27; is None</span><br><span class=\"line\">            auto size = r.intlist(0);</span><br><span class=\"line\">            auto dtype = r.scalartype(2);</span><br><span class=\"line\">            auto device = r.device(4);</span><br><span class=\"line\">            const auto options = TensorOptions()</span><br><span class=\"line\">                .dtype(dtype)</span><br><span class=\"line\">                .device(device)</span><br><span class=\"line\">                .layout(r.layout(3).layout)</span><br><span class=\"line\">                .requires_grad(r.toBool(5));</span><br><span class=\"line\">            return wrap(dispatch_empty(size, options));</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            check_out_type_matches(r.tensor(1), r.scalartype(2), r.isNone(2),</span><br><span class=\"line\">                                   r.layout(3), r.isNone(3),</span><br><span class=\"line\">                                   r.device(4), r.isNone(4));</span><br><span class=\"line\">            return wrap(dispatch_empty(r.intlist(0), r.tensor(1)).set_requires_grad(r.toBool(5)));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Py_RETURN_NONE;</span><br><span class=\"line\">    END_HANDLE_TH_ERRORS</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> empty  Tensor Tensor Tensor</p>\n<ol>\n<li><code>out</code> None dtype, device, layout  requires_grad  Tensor</li>\n<li><code>out</code> None,  <code>out</code>  Tensor  dtype, layout, device  <code>out</code>  requires_grad  requires_grad</li>\n</ol>\n<p> dispatch_empty torch/csrc/autograd/generated/python_torch_functions_dispatch.h python_torch_function.cpp  tools/autograd/templates/python_torch_functions_dispatch.h  tools/autograd/gen_python_functions.py  gen_py_torch_functionsdispatch_empty <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// empty  Tensor &#x27;out&#x27;</span><br><span class=\"line\">inline Tensor dispatch_empty(IntList size, Tensor result) &#123;</span><br><span class=\"line\">    AutoNoGIL no_gil;</span><br><span class=\"line\">    return at::empty_out(result, size);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// empty  Tensor &#x27;out&#x27; options </span><br><span class=\"line\">inline Tensor dispatch_empty(IntList size, const TensorOptions &amp; options) &#123;</span><br><span class=\"line\">    maybe_initialize_cuda(options);</span><br><span class=\"line\">    AutoNoGIL no_gil;</span><br><span class=\"line\">    return torch::empty(size, options);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"-Tensor\"><a href=\"#-Tensor\" class=\"headerlink\" title=\" Tensor\"></a> Tensor</h3><p> Tensor AutoNoGIL<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AutoNoGIL() : save(PyEval_SaveThread()) &#123;&#125;</span><br></pre></td></tr></table></figure><br> GIL at::empty_out  GIL at::empty_out  GIL<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~AutoNoGIL() &#123;</span><br><span class=\"line\">    PyEval_RestoreThread(save);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::empty_out  torch/lib/include/Aten/Functions.h<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static inline Tensor &amp; empty_out(Tensor &amp; result, IntList size) &#123;</span><br><span class=\"line\">    return detail::infer_type(result).empty_out(result, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::empty_out  Functions.h  aten/src/ATen/gen.py  generate_outputs  Declarations.yaml <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">file_manager.write(&#x27;Functions.h&#x27;, FUNCTIONS_H, top_env)</span><br></pre></td></tr></table></figure><br> at::empty_out  detail::infer_type(result)  Tensor  result  TypeExtendedInference  empty_out TypeExtendedInferfaceTypeDefault torch/lib/include/ATen/TypeExtendedInferface.h torch/lib/include/ATen/TypeDefault.hTypeDefault build/aten/src/ATen/TypeDefault.cpp empty_out <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor &amp; TypeDefault::empty_out(Tensor &amp; result, IntList size) const &#123;</span><br><span class=\"line\">    return at::native::empty_out(/* native_actuals */ result, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Declarations.yaml  at::native::empty_out  torch/lib/include/ATen/NativeFunctions.h Declarations.yaml  aten/src/ATen/native/TensorFactories.cpp<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace at &#123;</span><br><span class=\"line\">namespace native &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">Tensor&amp; empty_out(Tensor&amp; result, IntList size) &#123;</span><br><span class=\"line\">    if (result.is_sparse()) &#123;</span><br><span class=\"line\">        result.sparse_resize_and_clear_(size, size.size(), 0);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        result.resize_(size);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return result;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Tensor </p>\n<ol>\n<li><p> Tensor </p>\n<p> Tensor  sparse_resize_and_clear_ torch/lib/include/ATen/core/Tensor.h Declarations.yaml  aten/src/ATen/gen.py aten/src/ATen/core/Tensor.h TensorMethods.h  Type.h sparse_resize_and_clear_  torch/lib/include/ATen/core/TensorMethods.h</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inline Tensor &amp; Tensor::sparse_resize_and_clear_(IntList size, int64_t sparse_dim, int64_t dense_dim) &#123;</span><br><span class=\"line\">    return type().sparse_resize_and_clear_(*this, size, sparse_dim, dense_dim);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  Type Type  sparse_resize_and_clear_ Type  Type  .cpp Type  int,float,double  BackendCPU,CUDA,SparseCPU, SparseCUDA  SparseCPUByteType.h  SparseCPUByteType.cpp</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor &amp; SparseCPUByteType::sparse_resize_and_clear_(Tensor &amp; self, IntList size, int64_t sparse_dim, int64_t dense_dim) const &#123;</span><br><span class=\"line\">    const OptionalDeviceGuard device_guard(device_of(self));</span><br><span class=\"line\">    return at::native::sparse_resize_and_clear_(/* actuals */ self, size, sparse_dim, dense_dim);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> at::native::sparse_resize_and_clear_  torch/lib/include/ATen/NativeFunctions.h aten/src/ATen/native/sparse/SparseTensor.cpp</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SparseTensor&amp; sparse_resize_and_clear_(SparseTensor&amp; self, ArrayRef&lt;int64_t&gt; size, int64_t sparse_dim, int64_t dense_dim) &#123;</span><br><span class=\"line\">    get_sparse_impl(self)-&gt;resize_and_clear_(sparse_dim, dense_dim, size);</span><br><span class=\"line\">    return self;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  SparseTensorImpl  SparseTensorImpl  resize_and_clear_</p>\n</li>\n<li><p> Tensor </p>\n<p>Tensor  resize_  TensorMethods.h</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inline Tensor &amp; Tensor::resize_(IntList size) &#123;</span><br><span class=\"line\">    return type().resize_(*this, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  resize_ CPUByteType.cpp </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Tensor &amp; <span class=\"title\">CPUByteType::resize_</span><span class=\"params\">(Tensor &amp; self, IntList size)</span> <span class=\"keyword\">const</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> at::native::<span class=\"built_in\">resize_cpu_</span>(<span class=\"comment\">/* actuals */</span> self, size);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> Tensor  size  resize  aten/src/ATen/native/Resize.cpp  resize_cpu_ </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Tensor&amp; <span class=\"title\">resize_cpu_</span><span class=\"params\">(Tensor&amp; self, IntList size)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">auto</span>* self = self.<span class=\"built_in\">unsafeGetTensorImpl</span>();         <span class=\"comment\">//  Tensor </span></span><br><span class=\"line\">    <span class=\"comment\">//  size  Tensor  resize size  Tensor size </span></span><br><span class=\"line\">    <span class=\"built_in\">resize_impl_cpu_</span>(self_, size, c10::nullopt);     </span><br><span class=\"line\">    self_-&gt;<span class=\"built_in\">maybe_zero_dim</span>(size.<span class=\"built_in\">size</span>()==<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> self;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>resize_impl_cpu_  cpu  resize  aten/src/ATen/native/Resize.h </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> TensorImpl* <span class=\"title\">resize_impl_cpu_</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">    TensorImpl* self,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">    IntList size,</span></span></span><br><span class=\"line\"><span class=\"params\"><span class=\"function\">    c10::optional&lt;IntList&gt; stride)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (self-&gt;<span class=\"built_in\">sizes</span>() == size &amp;&amp; (!stride || self-&gt;<span class=\"built_in\">strides</span>() == stride)) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//  size  size </span></span><br><span class=\"line\">        <span class=\"comment\">// size size </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">int64_t</span> storage_size = <span class=\"number\">1</span>;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!stride)&#123;     <span class=\"comment\">// stride=1</span></span><br><span class=\"line\">        self-&gt;<span class=\"built_in\">set_sizes_contiguous</span>(size);    <span class=\"comment\">//  size  size</span></span><br><span class=\"line\">        storage_size = self-&gt;<span class=\"built_in\">numel</span>();        <span class=\"comment\">//  size  size  (n1,n2,n3) n1 * n2 * n3</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">maybe_resize_storage_cpu</span>(self, storage_size);    <span class=\"comment\">// resize </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> <span class=\"title\">maybe_resize_storage_cpu</span><span class=\"params\">(TensorImpl* self, <span class=\"keyword\">int64_t</span> new_size)</span> </span>&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (new_size+self-&gt;<span class=\"built_in\">storage_offset</span>() &gt; self-&gt;<span class=\"built_in\">storage</span>().<span class=\"built_in\">numel</span>()) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// self-&gt;storage_offset()  0</span></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"built_in\">THStorage_resize</span>(<span class=\"built_in\">THTensor_getStoragePtr</span>(self), new_size+self-&gt;<span class=\"built_in\">storage_offset</span>());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> aten/src/TH/THStorageFunctions.cpp  THStorage_resize </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">THStorage_resize</span><span class=\"params\">(THStorage* storage, <span class=\"keyword\">ptrdiff_t</span> size)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (storage-&gt;<span class=\"built_in\">resizable</span>()) &#123;</span><br><span class=\"line\">        at::DataPtr new_data;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (size != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            new_data = storage-&gt;<span class=\"built_in\">allocator</span>()-&gt;<span class=\"built_in\">allocate</span>(storage-&gt;<span class=\"built_in\">itemsize</span>()*size);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//  Tensor </span></span><br><span class=\"line\">        <span class=\"comment\">//  Tensor </span></span><br><span class=\"line\">        at::DataPtr old_data = storage-&gt;<span class=\"built_in\">set_data_ptr</span>(std::<span class=\"built_in\">move</span>(new_data));</span><br><span class=\"line\">        <span class=\"keyword\">ptrdiff_t</span> old_size = storage-&gt;<span class=\"built_in\">numel</span>();   <span class=\"comment\">//  size</span></span><br><span class=\"line\">        storage-&gt;<span class=\"built_in\">set_numel</span>(size);                <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (old_data != <span class=\"literal\">nullptr</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">ptrdiff_t</span> copy_size = old_size;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (storage-&gt;<span class=\"built_in\">numel</span>() &lt; copy_size) &#123;</span><br><span class=\"line\">                copy_size = <span class=\"built_in\">storage_numel</span>();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (copy_size &gt; <span class=\"number\">0</span>) &#123;                 <span class=\"comment\">// </span></span><br><span class=\"line\">                <span class=\"built_in\">memcpy</span>(</span><br><span class=\"line\">                    storage-&gt;<span class=\"built_in\">data</span>(),</span><br><span class=\"line\">                    old_data.<span class=\"built_in\">get</span>(),</span><br><span class=\"line\">                    storage-&gt;<span class=\"built_in\">itemsize</span>() * copy_size);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> resize  N1resize  N2</p>\n<ol>\n<li>N1 &gt;= N2 size N1  N2 </li>\n<li>N1 &lt; N2 N1  N1  Tensor  allocator </li>\n</ol>\n</li>\n</ol>\n<p> torch.empty <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">x=torch.rand(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.empty(<span class=\"number\">4</span>,<span class=\"number\">5</span>,out=x)  <span class=\"comment\"># resize  size</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.empty(<span class=\"number\">1</span>,<span class=\"number\">2</span>,out=x)  <span class=\"comment\"># resize  size</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\">torch.empty(<span class=\"number\">4</span>,<span class=\"number\">4</span>,out=x)  <span class=\"comment\">#  resize  size</span></span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([[0.0446, 0.1545, 0.5059, 0.6027],</span><br><span class=\"line\">        [0.4872, 0.4557, 0.1010, 0.2962],</span><br><span class=\"line\">        [0.0576, 0.1087, 0.3033, 0.4694]])</span><br><span class=\"line\">tensor([[4.4638e-02, 1.5454e-01, 5.0591e-01, 6.0266e-01, 4.8720e-01],</span><br><span class=\"line\">        [4.5573e-01, 1.0103e-01, 2.9619e-01, 5.7569e-02, 1.0874e-01],</span><br><span class=\"line\">        [3.0331e-01, 4.6944e-01, 0.0000e+00, 0.0000e+00,        nan],</span><br><span class=\"line\">        [0.0000e+00, 1.4013e-45, 0.0000e+00, 1.4013e-45, 0.0000e+00]])</span><br><span class=\"line\">tensor([[0.0446, 0.1545]])</span><br><span class=\"line\">tensor([[0.0446, 0.1545, 0.5059, 0.6027],</span><br><span class=\"line\">        [0.4872, 0.4557, 0.1010, 0.2962],</span><br><span class=\"line\">        [0.0576, 0.1087, 0.3033, 0.4694],</span><br><span class=\"line\">        [0.0000, 0.0000,    nan, 0.0000]])</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"-Tensor\"><a href=\"#-Tensor\" class=\"headerlink\" title=\" Tensor\"></a> Tensor</h3><p> torch/csrc/autograd/generated/python_torch_functions_dispatch.h  tensor  dispatch_empty  torch::empty torch/csrc/autograd/generated/variable_factories.h jit  Tensor <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">inline</span> at::Tensor <span class=\"title\">empty</span><span class=\"params\">(at::IntList size, <span class=\"keyword\">const</span> at::TensorOptions &amp; options=&#123;&#125;)</span> </span>&#123;</span><br><span class=\"line\">    ...     <span class=\"comment\">// jit tracing</span></span><br><span class=\"line\">    at::Tensor tensor = at::<span class=\"built_in\">empty</span>(size, at::<span class=\"built_in\">TensorOptions</span>(options).<span class=\"built_in\">is_variable</span>(<span class=\"literal\">false</span>));</span><br><span class=\"line\">    <span class=\"keyword\">auto</span> result = autograd::<span class=\"built_in\">make_variable</span>(tensor, options.<span class=\"built_in\">requires_grad</span>()); <span class=\"comment\">//  Tensor  Variable</span></span><br><span class=\"line\">    ...     <span class=\"comment\">// jit tracing</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::empty  Functions.h<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">inline</span> Tensor <span class=\"title\">empty</span><span class=\"params\">(IntList size, <span class=\"keyword\">const</span> TensorOptions &amp; options)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> at::<span class=\"built_in\">getType</span>(options).<span class=\"built_in\">empty</span>(size, options);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> Tensor  empty  at::getType(options)  options  TypeExtendedInterface  instance options.backend(), options.dtype()  options.is_variable()  CPU  backend  aten/src/ATen/Context.cpp  Context  register_cpu_types(this)  register_cpu_type(Context* context)  build/aten/src/ATen/RegisterCPU.cpp  aten/src/ATen/gen.py  generate_outputs  gen.py  register_cpu_types <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CPUByteType</span><br><span class=\"line\">CPUCharType</span><br><span class=\"line\">CPUDoubleType</span><br><span class=\"line\">CPUFloatType</span><br><span class=\"line\">CPUIntType</span><br><span class=\"line\">CPULongType</span><br><span class=\"line\">CPUShortType</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure><br> CPUByteType empty <br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Tensor CPUByteType::empty(IntList size, const TensorOptions &amp; options) const &#123;</span><br><span class=\"line\">    const DeviceGuard device_guard(options.device());   //  device  Tensor</span><br><span class=\"line\">    return at::native::empty_cpu(size, options);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br> at::native::empty_cpu  aten/src/ATen/native/TensorFactories.cpp <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">auto</span>* allocator = at::<span class=\"built_in\">getCPUAllocator</span>();</span><br><span class=\"line\"><span class=\"keyword\">int64_t</span> nelements = <span class=\"built_in\">prod_intlist</span>(size); <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> dtype = options.<span class=\"built_in\">dtype</span>();</span><br><span class=\"line\"><span class=\"keyword\">auto</span> storage_impl = c10::make_intrusive&lt;StorageImpl&gt;(</span><br><span class=\"line\">    dtype,</span><br><span class=\"line\">    nelements,</span><br><span class=\"line\">    allocator-&gt;<span class=\"built_in\">allocate</span>(nelements*dtype.<span class=\"built_in\">itemsize</span>()),</span><br><span class=\"line\">    allocator,</span><br><span class=\"line\">    <span class=\"comment\">/*resizeable=*/</span><span class=\"literal\">true</span></span><br><span class=\"line\">);</span><br><span class=\"line\"><span class=\"keyword\">auto</span> tensor = detail::make_tensor&lt;TensorImpl&gt;(storage_impl, at::<span class=\"built_in\">CPUTensorId</span>(), <span class=\"literal\">false</span>);</span><br></pre></td></tr></table></figure><br> c10::make_intrusive<StorageImpl>  new StorageImpl() wrap  intrusive_ptr <a href=\"2019/06/13/PyTorch-2\">PyTorch-2</a>  Tensor  StorageImpl StorageImpl  detail::make_tensor  Tensor at::getCPUAllocator  THDefaultAllocator  allocate  THAlloc THAlloc  THAllocInternal  malloc posix_memalign  </p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">torch.empty(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure><br><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor([[1.6504e-12,3.0637e-41,1.6588e-12],</span><br><span class=\"line\">        [3.0637e-41,4.4842e-44,0.0000e+00]])</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Tensor-\"><a href=\"#Tensor-\" class=\"headerlink\" title=\"Tensor \"></a>Tensor </h3><p> torch.empty  torch.Tensor  <code>torch/__init__.py</code>  <code>import autograd</code> <code>torch/autograd/__init__.py</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> torch._C._autograd_init():</span><br></pre></td></tr></table></figure><br>_autograd_init  python  torch/csrc/Module.cpp  THPAutograd_initExtension  c++  torch/csrc/autograd/autograd.h  torch/csrc/autograd/init.cpp <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//  torch/tensor.py </span></span><br><span class=\"line\"><span class=\"keyword\">auto</span> tensor_module = <span class=\"built_in\">THPObjectPtr</span>(<span class=\"built_in\">PyImport_ImportModule</span>(<span class=\"string\">&quot;torch.tensor&quot;</span>));</span><br><span class=\"line\"><span class=\"comment\">//  torch/tensor.py  Tensor </span></span><br><span class=\"line\">THPVariableClass = <span class=\"built_in\">PyObject_GetAttrString</span>(tensor_module, <span class=\"string\">&quot;Tensor&quot;</span>);</span><br></pre></td></tr></table></figure><br> <code>THPVariableClass</code>  torch/csrc/autograd/python_variable.h <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THP_API PyObject *THPVariableClass;</span><br></pre></td></tr></table></figure><br> extern  torch/csrc/autograd/python_variable.cpp  torch.empty  c++  THPVariable_empty  dispatch_empty  Variable  wrap  PyObject wrap  torch/csrc/autograd/utils/wrap_outputs.h  THPVariable_Wrap torch/csrc/autograd/python_variable.cpp THPVariableClass  THPVariableClass  torch/tensor.py  Tensor  THPVariable_Wrap  THPVariable_NewWithVar  Variable  THPVariableClass  Tensor THPVariable_NewWithVar <br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> PyObject* <span class=\"title\">THPVariable_NewWithVar</span><span class=\"params\">(PyTypeObject* type, Variable var)</span> </span>&#123;</span><br><span class=\"line\">PyObject *obj=type-&gt;<span class=\"built_in\">tp_alloc</span>(type, <span class=\"number\">0</span>);      <span class=\"comment\">//  torch.Tensor </span></span><br><span class=\"line\"><span class=\"keyword\">if</span>(obj) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">auto</span> v = (THPVariable*)obj; <span class=\"comment\">// cast  THPVariable  torch.Tensor  torch._C._TensorBase </span></span><br><span class=\"line\">    <span class=\"keyword\">new</span>(&amp;v-&gt;cdata) <span class=\"built_in\">Variable</span>(std::<span class=\"built_in\">move</span>(var));    <span class=\"comment\">//  VariableC++  Tensor</span></span><br><span class=\"line\">    v-&gt;cdata.<span class=\"built_in\">set_pyobj</span>(obj);</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">return</span> obj;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"built_in\">type</span>(torch.empty(<span class=\"number\">2</span>,<span class=\"number\">3</span>))</span><br><span class=\"line\">&lt;<span class=\"class\"><span class=\"keyword\">class</span> &#x27;<span class=\"title\">torch</span>.<span class=\"title\">Tensor</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h1 id=\"PS\"><a href=\"#PS\" class=\"headerlink\" title=\"PS\"></a>PS</h1><p></p>"},{"title":"PyTorch ","p":"pytorch/PyTorch-mtd","date":"2019-11-01T03:26:25.000Z","mathjax":true,"_content":"\n# 1. Fold / Unfold\n## Fold\n torch.nn.Fold \n\n size  `(N,C,H,W)` kernel size  `(C,h,w)` `d`padding  `p`stride  `s` `Cxhxw`  `L`  `L`  `(C,h,w)` map \n<!-- more -->\n$$H_o= \\frac {H - [d(h-1)+1] + 2p} {s}+1\n\\\\\\\\ W_o= \\frac {W - [d(w-1)+1] + 2p} {s}+1$$\n map  `L` \n$$L=H_o * W_o=\\left(\\frac {H - [d(h-1)+1] + 2p} {s}+1\\right) \\left(\\frac {W - [d(w-1)+1] + 2p} {s}+1\\right)$$\n\n Fold  fold  `L`  `(N,C*h*w,L)` size `(h,w)`dilationpaddingstrideFold `(H,W)`Fold  `L`  map  `(H,W)` map __Fold __\n\nFold  Fold `L`  tensorsize  `(N,C*h*w,L)` tensor Fold   map  `(H,W)` `N`  `C` Fold  tensor   `C*h*w`  Fold  `(h,w)`  `C`\n\n PyTorch \n```python\n>>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))  # (H,W)=(4,5), (h,w)=(2,2)\n>>> input = torch.randn(1, 3 * 2 * 2, 12)   # (N, C*h*w,L)\n>>> output = fold(input)\n>>> output.size()\ntorch.Size([1, 3, 4, 5])    # (N,C,H,W)\n```\n\n `H,W`  PyTorch  `L` \n$$L=\\prod_d \\lfloor \\frac {\\text{output\\_size} [d] + 2 \\times \\text{padding}[d]-\\text{dilation}[d] \\times (\\text{kernel\\_size}[d]-1) -1} {\\text{stride}[d]} +1 \\rfloor$$\n\n____\n\nFold  size  $(N, C \\times \\prod(\\text{kernel\\_size}), L)$ size  $(N,C, \\text{output\\_size}[0], \\text{output\\_size}[1], ...)$\n\n## Unfold\n torch.nn.Unfold  Fold  tensor dilationpadding  stride  `L` `L` Unfold  size  $(N,C,*)$ *  size  $(N,C \\times \\prod(\\text{kernel\\_size}), L)$\n\nPyTorch \n```python\n>>> unfold = nn.Unfold(kernel_size=(2, 3))\n>>> input = torch.randn(2, 5, 3, 4)\n>>> output = unfold(input)\n>>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n>>> # 4 blocks (2x3 kernels) in total in the 3x4 input\n>>> output.size()\ntorch.Size([2, 30, 4])\n```\n\n# 2. Normalization\n## BatchNorm\n mini-batch \n$$y=\\frac {x-E[x]} {\\sqrt{V[x]+\\epsilon}} * \\gamma + \\beta$$\n\n\nBatchNorm Layer mini-batch $\\mathcal B=\\{x_{1...m}\\}$ $\\gamma, \\beta$ mini-batch \n$$\\mu_{\\mathcal B} = \\frac 1 m \\sum_{i=1}^m x_i, \\quad \\sigma_{\\mathcal B}^2=\\frac 1 m \\sum_{i=1}^m(x_i - \\mu_{\\mathcal B})^2$$\n\n$$\\hat x_i = \\frac {x_i - \\mu_{\\mathcal B}} {\\sqrt {\\sigma_{\\mathcal B}^2+ \\epsilon}}$$\n scale  shift\n$$y_i=\\hat x_i \\cdot \\gamma + \\beta$$\n\n____  batch \n\n## LayerNorm\nLayer  LayerNorm  $x$ $x$  tensor 1D vector $x=(x_1,...x_H)$$H$  LayerNorm  $x$  LayerNorm \n$$\\mu=\\frac 1 H \\sum_{i=1}^H x_i, \\quad \\sigma^2=\\frac 1 H \\sum_{i=1}^H (x_i-\\mu)^2$$\n LayerNorm \n$$y=\\frac {x-\\mu} {\\sqrt {\\sigma^2+\\epsilon}} \\cdot \\gamma + \\beta$$\n\n____  batch \n\n\n $\\mu, \\sigma$\n\n## InstanceNorm\n channel  $\\mu, \\sigma$ $(N,C,H,W)$ $(H,W)$ \n\n## GroupNorm\nGroupNorm  channels  InstanceNormchannel LayerNorm  channels\n\n# 3. Pool\n\n## FractionalMaxPool2d\n [Fractional MaxPooling](https://arxiv.org/abs/1412.6071)\n\npool  feature map  `2x2` max-pooling  $N_{in} \\times N_{in}$ $N_{out} \\times N_{out}$\n$$N_{out}=\\frac {N_{in}-k+2p} {s} + 1= N_{in} / 2 \\Rightarrow N_{in} /N_{out} = 2$$\n\n $N_{in} \\times N_{in}$  feature map  $N_{out}^2$  pooling  $(P_{i,j})$ $\\{1,2,...,N_{in}\\}^2$  $[1,N_{in}]^2$ feature mappixel  pooling \n$$P_{i,j} \\subset \\{1,2,...,N_{in}\\}, \\quad (i,j) \\in \\{1,...,N_{out}\\}^2$$\n\n $N_{in} / N_{out} \\in (1,2)$ $N_{in} / N_{out} \\in (2,3)$ Fractional max-poolingFMP\n\nFMP \n\n $(a_i)_{i=0}^{N_{out}}, \\ (b_i)_{i=0}^{N_{out}}$  `1` $N_{in}$  `1`  `2` $\\forall i,\\ a_{i+1}-a_{i} \\in \\{1,2\\}$ pooling \n$$P_{i,j}=[a_{i-1}, a_i-1] \\times [b_{j-1},b_j-1], \\quad i,j \\in \\{1,...,N_{out}\\}\n\\\\\\\\ P_{i,j}=[a_{i-1}, a_i] \\times [b_{j-1},b_j], \\quad i,j \\in \\{1,...,N_{out}\\}$$\n `i,j` \n\n `disjoint`  `overlapping`  pooling \n\n $\\alpha = N_{in} / N_{out}$ $(a_i)_{i=0}^{N_{out}}$\n1. `random` \n   \n    $\\alpha$  $(a_i-a_{i-1})_{i=1}^{N_{out}}$  `1`  `2`  `1`  `2` shuffle  random permutation $\\alpha = N_{in} / N_{out}$\n\n2. `pseudorandom` \n   \n    $(0,0), \\ (N_{out}, N_{in}-1)$  $\\alpha$ $(1,2)$  y   $\\alpha \\cdot u$ $\\alpha \\in (1,2), \\ u \\in (0,1), \\alpha \\cdot u \\in (0,1)$\n   $$y=\\alpha(i+u)$$\n   x  $0,1,2,...,N_{out}$ y  ceiling  $a_i$ \n   $$a_i=\\text{ceiling}(\\alpha(i+u)), \\quad i=0,1,2,...,N_{out}$$\n    $\\{a_i\\}$ \n   - $i=0$$a_0=\\text{ceiling}(\\alpha \\cdot u)$ $\\alpha \\cdot u \\in (0,1)$ $a_0=1$\n   - $i=N_{out}$$a_{N_{out}}=\\text{ceiling}(N_{in}-1+\\alpha \\cdot u)=N_{in}$\n   - `otherwise` $a_{i+1}-a_i=\\text{ceiling}(\\alpha \\cdot i+\\alpha+\\alpha \\cdot u)-\\text{ceiling}(\\alpha \\cdot i+\\alpha \\cdot u)$\n\n   \n   \n    $\\alpha \\cdot i+\\alpha \\cdot u=f \\in [k,k+1)$k \n   - `f=k` \n  \n        $a_{i+1}-a_i=\\text{ceiling}(k+\\alpha)-k=k+\\text{ceiling}(\\alpha)-k=\\text{ceiling}(\\alpha)=2$\n\n   - `k<f<k+1` \n\n        $k+1<f+\\alpha<k+3$\n  \n        $a_{i+1}-a_i=\\text{ceiling}(f+\\alpha)-k-1 \\in \\{1,2\\}$\n\n    $(a_i)$  ceiling \n\n# 4. ConvTranspose\n\n## \n $L_{in}$ $L_{out}$ $k$dilation stride  padding  $d, p, s$\n$$L_{out}=\\frac {L_{in}-(d(k-1)+1)+2p} s + 1 \\qquad (4-1)$$\n $L_{in}^{\\top}, \\ L_{out}^{\\top}$ \n$$L_{out}^{\\top}=s(L_{in}^{\\top} - 1) +d(k-1)+1 - 2p \\qquad (4-2)$$\n\n\n## \n### \n $4 \\times 4$ $3 \\times 3$ padding stride  1 $(4-1)$  $2 \\times 2$ $4 \\times 9$ __ element  0 __ $9 \\times 1$  $4 \\times 1$ \n\n $2 \\times 2$ $3 \\times 3$ padding  stride  1 $(4-2)$  $4 \\times 4$____ zero-padding  $6\\times 6$ $6 \\times 6$  $3 \\times 3$  $4 \\times 4$  $16 \\times 9$  __ 180__ reshape  $9 \\times 1$  $16 \\times 1$ reshape  $4 \\times 4$\n\n\n\n![](/images/pytorch_mth_conv.png)<center></center>\n\n![](/images/pytorch_mtd_conv_t.png)<center></center>\n\n\n Pytorch \n\n```python\nimport torch\nfrom torch import nn\nconvt = nn.ConvTranspose2d(1,1,3)\nconvt.bias = nn.Parameter(torch.tensor([0.]))\nconvt.weight = nn.Parameter(torch.tensor([[[[0.,1,2],\n                                            [2,2,0],\n                                            [0,1,2]]]]))\ninput = torch.tensor([[[[12.,12],\n                        [10,17]]]])\noutput = convt(input)\noutput\n# tensor([[[[ 0., 12., 36., 24.],\n#           [24., 58., 61., 34.],\n#           [20., 66., 70., 24.],\n#           [ 0., 10., 37., 34.]]]])\n```\n\n### \n\n\n reshape  $1 \\times 16$ 4  zero-padding  4  $4 \\times 4$  $3 \\times 4$  $4 \\times 4$  zero-padding reshape  $16 \\times 4$ $16 \\times 4$  $K$  $1 \\times 4$ reshape  $2 \\times 2$ \n\n $2 \\times 2$ `[12,12,10,17]` reshape  $1 \\times 4$ $K$ ____ $4 \\times 16$  $1 \\times 16$  reshape  $4 \\times 4$ \n\n\n\n![](/images/pytorch_mtd_conv_t_1.png)<center></center>\n\n\n\n### dilation > 1\n `dilation`  1  `dilation=2` $(4-2)$  $6 \\times 6$ $5 \\times 5$  0 __ 180__ zero-padding  $10 \\times 10$  $6 \\times 6$  4  zero-padding\n\n `input`  $I$zero-padding$I[4:6,4:6]=[[12.,12],[10,17]]$ `0` __ 180__  $K'=[[2., 0, 1, 0, 0],[0,0,0,0,0],[0,0,2,0,2],[0,0,0,0,0],[2,0,1,0,0]]$ python \n```python\nconvt1 = nn.ConvTranspose2d(1,1,3,dilation=2)\nconvt1.bias = nn.Parameter(torch.tensor([0.]))\nconvt1.weight = nn.Parameter(torch.tensor([[[[0.,1,2],[2,2,0],[0,1,2]]]]))\noutput1 = convt1(input)\noutput1\n```\n\n### stride > 1\n `stride=2` $(4-2)$  $5 \\times 5$ $7 \\times 7$ `stride=2` $2 \\times 2$  $3 \\times 3$ 2*(2-1)+1=3 zero-padding  $7 \\times 7$  padding  (7-3)/2=2 $I[2,2]=I[2,4]=12, \\ I[4,2]=10, \\ I[4,4]=17$ `0` __ 180__  $K'=[[2., 1, 0],[0,2,2],[2,1,0]]$ python \n```python\nconvt.stride = (2,2)\noutput = convt(input)\noutput\n```\n\n### padding > 0\n `padding=1` $(4-2)$  $2 \\times 2$ 1  zero-padding $4 \\times 4$ $3 \\times 3$ __ 180__\n\n `dialtion > 1, stride > 1, padding > 0`  python  ``  `` \n\n# 5. Upsample\n `minibatch x channels x [optional depth] x [optional height] x width` 3D/4D/5D `nearest neighbor, linear, bilinear, bicubic, trilinear`\n\n## nearest neighbor\n size  $m \\times m$ S size  $n \\times n, \\ n > m$ $(x,y), \\ x,y =0,1,...,n-1$ S  $(x',y')$\n\n$$\\frac {x-0} {n-1-0}= \\frac {x'-0}{m-1-0} \\Rightarrow x' = \\frac {m-1} {n-1} \\cdot x$$\n $y' = \\frac {m-1} {n-1} \\cdot y$ $(i',j')$  $(\\lfloor x'\\rfloor, \\lfloor y' \\rfloor), \\ (\\lfloor x'\\rfloor, \\lceil y' \\rceil), \\ (\\lceil x'\\rceil, \\lfloor y' \\rfloor), \\ (\\lceil x'\\rceil, \\lceil y' \\rceil)$  $(x',y')$  $(x,y)$  PyTorch \n\n## bilinear\n 4D\n### align_corners=True\n $(x_1,y_1), \\ (x_1,y_2), \\ (x_2,y_1), \\ (x_2,y_2)$ $(x,y), \\ x_1 \\le x \\le x_2, \\ y_1 \\le y \\le y_2$  x \n$$f(x,y_1)=\\frac {f_{21}-f_{11}} {x_2-x_1} \\cdot (x-x_1)+f_{11}\n\\\\\\\\ f(x,y_2)=\\frac {f_{22}-f_{12}} {x_2-x_1} \\cdot (x-x_1)+f_{12}\n\\\\\\\\ f(x,y)=\\frac {f_(x,y_2)-f(x,y_1)} {y_2-y_1} \\cdot (y-y_1)+f(x,y_1)$$\n\n `nearest neighbor`  $(x,y)$  $(x',y')$ $(\\lfloor x'\\rfloor, \\lfloor y' \\rfloor), \\ (\\lfloor x'\\rfloor, \\lceil y' \\rceil), \\ (\\lceil x'\\rceil, \\lfloor y' \\rfloor), \\ (\\lceil x'\\rceil, \\lceil y' \\rceil)$ corners  corners  `align_corners=True` \n\n### align_corners=False\n `align_corners` \n![](/images/pytorch_mtd_aligncorners.png)<center> [pytorch ](https://discuss.pytorch.org/t/what-we-should-use-align-corners-false/22663/9)</center>\n\n $(x,y)$ S \n$$x'=(x+0.5)/2-0.5\n\\\\\\\\ y'=(y+0.5)/2-0.5$$\n\n 4  $(\\lfloor x'\\rfloor, \\lfloor y' \\rfloor), \\ (\\lfloor x'\\rfloor, \\lceil y' \\rceil), \\ (\\lceil x'\\rceil, \\lfloor y' \\rfloor), \\ (\\lceil x'\\rceil, \\lceil y' \\rceil)$ \n## linear\n bilinear  3D\n\n## trilinear\n bilinear  5D\n\n","source":"_posts/pytorch/PyTorch-mtd.md","raw":"---\ntitle: PyTorch \np: pytorch/PyTorch-mtd\ndate: 2019-11-01 11:26:25\ntags: PyTorch\nmathjax: true\n---\n\n# 1. Fold / Unfold\n## Fold\n torch.nn.Fold \n\n size  `(N,C,H,W)` kernel size  `(C,h,w)` `d`padding  `p`stride  `s` `Cxhxw`  `L`  `L`  `(C,h,w)` map \n<!-- more -->\n$$H_o= \\frac {H - [d(h-1)+1] + 2p} {s}+1\n\\\\\\\\ W_o= \\frac {W - [d(w-1)+1] + 2p} {s}+1$$\n map  `L` \n$$L=H_o * W_o=\\left(\\frac {H - [d(h-1)+1] + 2p} {s}+1\\right) \\left(\\frac {W - [d(w-1)+1] + 2p} {s}+1\\right)$$\n\n Fold  fold  `L`  `(N,C*h*w,L)` size `(h,w)`dilationpaddingstrideFold `(H,W)`Fold  `L`  map  `(H,W)` map __Fold __\n\nFold  Fold `L`  tensorsize  `(N,C*h*w,L)` tensor Fold   map  `(H,W)` `N`  `C` Fold  tensor   `C*h*w`  Fold  `(h,w)`  `C`\n\n PyTorch \n```python\n>>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2))  # (H,W)=(4,5), (h,w)=(2,2)\n>>> input = torch.randn(1, 3 * 2 * 2, 12)   # (N, C*h*w,L)\n>>> output = fold(input)\n>>> output.size()\ntorch.Size([1, 3, 4, 5])    # (N,C,H,W)\n```\n\n `H,W`  PyTorch  `L` \n$$L=\\prod_d \\lfloor \\frac {\\text{output\\_size} [d] + 2 \\times \\text{padding}[d]-\\text{dilation}[d] \\times (\\text{kernel\\_size}[d]-1) -1} {\\text{stride}[d]} +1 \\rfloor$$\n\n____\n\nFold  size  $(N, C \\times \\prod(\\text{kernel\\_size}), L)$ size  $(N,C, \\text{output\\_size}[0], \\text{output\\_size}[1], ...)$\n\n## Unfold\n torch.nn.Unfold  Fold  tensor dilationpadding  stride  `L` `L` Unfold  size  $(N,C,*)$ *  size  $(N,C \\times \\prod(\\text{kernel\\_size}), L)$\n\nPyTorch \n```python\n>>> unfold = nn.Unfold(kernel_size=(2, 3))\n>>> input = torch.randn(2, 5, 3, 4)\n>>> output = unfold(input)\n>>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n>>> # 4 blocks (2x3 kernels) in total in the 3x4 input\n>>> output.size()\ntorch.Size([2, 30, 4])\n```\n\n# 2. Normalization\n## BatchNorm\n mini-batch \n$$y=\\frac {x-E[x]} {\\sqrt{V[x]+\\epsilon}} * \\gamma + \\beta$$\n\n\nBatchNorm Layer mini-batch $\\mathcal B=\\{x_{1...m}\\}$ $\\gamma, \\beta$ mini-batch \n$$\\mu_{\\mathcal B} = \\frac 1 m \\sum_{i=1}^m x_i, \\quad \\sigma_{\\mathcal B}^2=\\frac 1 m \\sum_{i=1}^m(x_i - \\mu_{\\mathcal B})^2$$\n\n$$\\hat x_i = \\frac {x_i - \\mu_{\\mathcal B}} {\\sqrt {\\sigma_{\\mathcal B}^2+ \\epsilon}}$$\n scale  shift\n$$y_i=\\hat x_i \\cdot \\gamma + \\beta$$\n\n____  batch \n\n## LayerNorm\nLayer  LayerNorm  $x$ $x$  tensor 1D vector $x=(x_1,...x_H)$$H$  LayerNorm  $x$  LayerNorm \n$$\\mu=\\frac 1 H \\sum_{i=1}^H x_i, \\quad \\sigma^2=\\frac 1 H \\sum_{i=1}^H (x_i-\\mu)^2$$\n LayerNorm \n$$y=\\frac {x-\\mu} {\\sqrt {\\sigma^2+\\epsilon}} \\cdot \\gamma + \\beta$$\n\n____  batch \n\n\n $\\mu, \\sigma$\n\n## InstanceNorm\n channel  $\\mu, \\sigma$ $(N,C,H,W)$ $(H,W)$ \n\n## GroupNorm\nGroupNorm  channels  InstanceNormchannel LayerNorm  channels\n\n# 3. Pool\n\n## FractionalMaxPool2d\n [Fractional MaxPooling](https://arxiv.org/abs/1412.6071)\n\npool  feature map  `2x2` max-pooling  $N_{in} \\times N_{in}$ $N_{out} \\times N_{out}$\n$$N_{out}=\\frac {N_{in}-k+2p} {s} + 1= N_{in} / 2 \\Rightarrow N_{in} /N_{out} = 2$$\n\n $N_{in} \\times N_{in}$  feature map  $N_{out}^2$  pooling  $(P_{i,j})$ $\\{1,2,...,N_{in}\\}^2$  $[1,N_{in}]^2$ feature mappixel  pooling \n$$P_{i,j} \\subset \\{1,2,...,N_{in}\\}, \\quad (i,j) \\in \\{1,...,N_{out}\\}^2$$\n\n $N_{in} / N_{out} \\in (1,2)$ $N_{in} / N_{out} \\in (2,3)$ Fractional max-poolingFMP\n\nFMP \n\n $(a_i)_{i=0}^{N_{out}}, \\ (b_i)_{i=0}^{N_{out}}$  `1` $N_{in}$  `1`  `2` $\\forall i,\\ a_{i+1}-a_{i} \\in \\{1,2\\}$ pooling \n$$P_{i,j}=[a_{i-1}, a_i-1] \\times [b_{j-1},b_j-1], \\quad i,j \\in \\{1,...,N_{out}\\}\n\\\\\\\\ P_{i,j}=[a_{i-1}, a_i] \\times [b_{j-1},b_j], \\quad i,j \\in \\{1,...,N_{out}\\}$$\n `i,j` \n\n `disjoint`  `overlapping`  pooling \n\n $\\alpha = N_{in} / N_{out}$ $(a_i)_{i=0}^{N_{out}}$\n1. `random` \n   \n    $\\alpha$  $(a_i-a_{i-1})_{i=1}^{N_{out}}$  `1`  `2`  `1`  `2` shuffle  random permutation $\\alpha = N_{in} / N_{out}$\n\n2. `pseudorandom` \n   \n    $(0,0), \\ (N_{out}, N_{in}-1)$  $\\alpha$ $(1,2)$  y   $\\alpha \\cdot u$ $\\alpha \\in (1,2), \\ u \\in (0,1), \\alpha \\cdot u \\in (0,1)$\n   $$y=\\alpha(i+u)$$\n   x  $0,1,2,...,N_{out}$ y  ceiling  $a_i$ \n   $$a_i=\\text{ceiling}(\\alpha(i+u)), \\quad i=0,1,2,...,N_{out}$$\n    $\\{a_i\\}$ \n   - $i=0$$a_0=\\text{ceiling}(\\alpha \\cdot u)$ $\\alpha \\cdot u \\in (0,1)$ $a_0=1$\n   - $i=N_{out}$$a_{N_{out}}=\\text{ceiling}(N_{in}-1+\\alpha \\cdot u)=N_{in}$\n   - `otherwise` $a_{i+1}-a_i=\\text{ceiling}(\\alpha \\cdot i+\\alpha+\\alpha \\cdot u)-\\text{ceiling}(\\alpha \\cdot i+\\alpha \\cdot u)$\n\n   \n   \n    $\\alpha \\cdot i+\\alpha \\cdot u=f \\in [k,k+1)$k \n   - `f=k` \n  \n        $a_{i+1}-a_i=\\text{ceiling}(k+\\alpha)-k=k+\\text{ceiling}(\\alpha)-k=\\text{ceiling}(\\alpha)=2$\n\n   - `k<f<k+1` \n\n        $k+1<f+\\alpha<k+3$\n  \n        $a_{i+1}-a_i=\\text{ceiling}(f+\\alpha)-k-1 \\in \\{1,2\\}$\n\n    $(a_i)$  ceiling \n\n# 4. ConvTranspose\n\n## \n $L_{in}$ $L_{out}$ $k$dilation stride  padding  $d, p, s$\n$$L_{out}=\\frac {L_{in}-(d(k-1)+1)+2p} s + 1 \\qquad (4-1)$$\n $L_{in}^{\\top}, \\ L_{out}^{\\top}$ \n$$L_{out}^{\\top}=s(L_{in}^{\\top} - 1) +d(k-1)+1 - 2p \\qquad (4-2)$$\n\n\n## \n### \n $4 \\times 4$ $3 \\times 3$ padding stride  1 $(4-1)$  $2 \\times 2$ $4 \\times 9$ __ element  0 __ $9 \\times 1$  $4 \\times 1$ \n\n $2 \\times 2$ $3 \\times 3$ padding  stride  1 $(4-2)$  $4 \\times 4$____ zero-padding  $6\\times 6$ $6 \\times 6$  $3 \\times 3$  $4 \\times 4$  $16 \\times 9$  __ 180__ reshape  $9 \\times 1$  $16 \\times 1$ reshape  $4 \\times 4$\n\n\n\n![](/images/pytorch_mth_conv.png)<center></center>\n\n![](/images/pytorch_mtd_conv_t.png)<center></center>\n\n\n Pytorch \n\n```python\nimport torch\nfrom torch import nn\nconvt = nn.ConvTranspose2d(1,1,3)\nconvt.bias = nn.Parameter(torch.tensor([0.]))\nconvt.weight = nn.Parameter(torch.tensor([[[[0.,1,2],\n                                            [2,2,0],\n                                            [0,1,2]]]]))\ninput = torch.tensor([[[[12.,12],\n                        [10,17]]]])\noutput = convt(input)\noutput\n# tensor([[[[ 0., 12., 36., 24.],\n#           [24., 58., 61., 34.],\n#           [20., 66., 70., 24.],\n#           [ 0., 10., 37., 34.]]]])\n```\n\n### \n\n\n reshape  $1 \\times 16$ 4  zero-padding  4  $4 \\times 4$  $3 \\times 4$  $4 \\times 4$  zero-padding reshape  $16 \\times 4$ $16 \\times 4$  $K$  $1 \\times 4$ reshape  $2 \\times 2$ \n\n $2 \\times 2$ `[12,12,10,17]` reshape  $1 \\times 4$ $K$ ____ $4 \\times 16$  $1 \\times 16$  reshape  $4 \\times 4$ \n\n\n\n![](/images/pytorch_mtd_conv_t_1.png)<center></center>\n\n\n\n### dilation > 1\n `dilation`  1  `dilation=2` $(4-2)$  $6 \\times 6$ $5 \\times 5$  0 __ 180__ zero-padding  $10 \\times 10$  $6 \\times 6$  4  zero-padding\n\n `input`  $I$zero-padding$I[4:6,4:6]=[[12.,12],[10,17]]$ `0` __ 180__  $K'=[[2., 0, 1, 0, 0],[0,0,0,0,0],[0,0,2,0,2],[0,0,0,0,0],[2,0,1,0,0]]$ python \n```python\nconvt1 = nn.ConvTranspose2d(1,1,3,dilation=2)\nconvt1.bias = nn.Parameter(torch.tensor([0.]))\nconvt1.weight = nn.Parameter(torch.tensor([[[[0.,1,2],[2,2,0],[0,1,2]]]]))\noutput1 = convt1(input)\noutput1\n```\n\n### stride > 1\n `stride=2` $(4-2)$  $5 \\times 5$ $7 \\times 7$ `stride=2` $2 \\times 2$  $3 \\times 3$ 2*(2-1)+1=3 zero-padding  $7 \\times 7$  padding  (7-3)/2=2 $I[2,2]=I[2,4]=12, \\ I[4,2]=10, \\ I[4,4]=17$ `0` __ 180__  $K'=[[2., 1, 0],[0,2,2],[2,1,0]]$ python \n```python\nconvt.stride = (2,2)\noutput = convt(input)\noutput\n```\n\n### padding > 0\n `padding=1` $(4-2)$  $2 \\times 2$ 1  zero-padding $4 \\times 4$ $3 \\times 3$ __ 180__\n\n `dialtion > 1, stride > 1, padding > 0`  python  ``  `` \n\n# 5. Upsample\n `minibatch x channels x [optional depth] x [optional height] x width` 3D/4D/5D `nearest neighbor, linear, bilinear, bicubic, trilinear`\n\n## nearest neighbor\n size  $m \\times m$ S size  $n \\times n, \\ n > m$ $(x,y), \\ x,y =0,1,...,n-1$ S  $(x',y')$\n\n$$\\frac {x-0} {n-1-0}= \\frac {x'-0}{m-1-0} \\Rightarrow x' = \\frac {m-1} {n-1} \\cdot x$$\n $y' = \\frac {m-1} {n-1} \\cdot y$ $(i',j')$  $(\\lfloor x'\\rfloor, \\lfloor y' \\rfloor), \\ (\\lfloor x'\\rfloor, \\lceil y' \\rceil), \\ (\\lceil x'\\rceil, \\lfloor y' \\rfloor), \\ (\\lceil x'\\rceil, \\lceil y' \\rceil)$  $(x',y')$  $(x,y)$  PyTorch \n\n## bilinear\n 4D\n### align_corners=True\n $(x_1,y_1), \\ (x_1,y_2), \\ (x_2,y_1), \\ (x_2,y_2)$ $(x,y), \\ x_1 \\le x \\le x_2, \\ y_1 \\le y \\le y_2$  x \n$$f(x,y_1)=\\frac {f_{21}-f_{11}} {x_2-x_1} \\cdot (x-x_1)+f_{11}\n\\\\\\\\ f(x,y_2)=\\frac {f_{22}-f_{12}} {x_2-x_1} \\cdot (x-x_1)+f_{12}\n\\\\\\\\ f(x,y)=\\frac {f_(x,y_2)-f(x,y_1)} {y_2-y_1} \\cdot (y-y_1)+f(x,y_1)$$\n\n `nearest neighbor`  $(x,y)$  $(x',y')$ $(\\lfloor x'\\rfloor, \\lfloor y' \\rfloor), \\ (\\lfloor x'\\rfloor, \\lceil y' \\rceil), \\ (\\lceil x'\\rceil, \\lfloor y' \\rfloor), \\ (\\lceil x'\\rceil, \\lceil y' \\rceil)$ corners  corners  `align_corners=True` \n\n### align_corners=False\n `align_corners` \n![](/images/pytorch_mtd_aligncorners.png)<center> [pytorch ](https://discuss.pytorch.org/t/what-we-should-use-align-corners-false/22663/9)</center>\n\n $(x,y)$ S \n$$x'=(x+0.5)/2-0.5\n\\\\\\\\ y'=(y+0.5)/2-0.5$$\n\n 4  $(\\lfloor x'\\rfloor, \\lfloor y' \\rfloor), \\ (\\lfloor x'\\rfloor, \\lceil y' \\rceil), \\ (\\lceil x'\\rceil, \\lfloor y' \\rfloor), \\ (\\lceil x'\\rceil, \\lceil y' \\rceil)$ \n## linear\n bilinear  3D\n\n## trilinear\n bilinear  5D\n\n","slug":"pytorch/PyTorch-mtd","published":1,"updated":"2020-04-24T10:35:09.355Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cku6or92f005ep0dj6a0kbjgt","content":"<h1 id=\"1-Fold-Unfold\"><a href=\"#1-Fold-Unfold\" class=\"headerlink\" title=\"1. Fold / Unfold\"></a>1. Fold / Unfold</h1><h2 id=\"Fold\"><a href=\"#Fold\" class=\"headerlink\" title=\"Fold\"></a>Fold</h2><p> torch.nn.Fold </p>\n<p> size  <code>(N,C,H,W)</code> kernel size  <code>(C,h,w)</code> <code>d</code>padding  <code>p</code>stride  <code>s</code> <code>Cxhxw</code>  <code>L</code>  <code>L</code>  <code>(C,h,w)</code> map <br><span id=\"more\"></span></p>\n<script type=\"math/tex; mode=display\">H_o= \\frac {H - [d(h-1)+1] + 2p} {s}+1\n\\\\\\\\ W_o= \\frac {W - [d(w-1)+1] + 2p} {s}+1</script><p> map  <code>L</code> </p>\n<script type=\"math/tex; mode=display\">L=H_o * W_o=\\left(\\frac {H - [d(h-1)+1] + 2p} {s}+1\\right) \\left(\\frac {W - [d(w-1)+1] + 2p} {s}+1\\right)</script><p> Fold  fold  <code>L</code>  <code>(N,C*h*w,L)</code> size <code>(h,w)</code>dilationpaddingstrideFold <code>(H,W)</code>Fold  <code>L</code>  map  <code>(H,W)</code> map <strong>Fold </strong></p>\n<p>Fold  Fold <code>L</code>  tensorsize  <code>(N,C*h*w,L)</code> tensor Fold   map  <code>(H,W)</code> <code>N</code>  <code>C</code> Fold  tensor   <code>C*h*w</code>  Fold  <code>(h,w)</code>  <code>C</code></p>\n<p> PyTorch <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fold = nn.Fold(output_size=(<span class=\"number\">4</span>, <span class=\"number\">5</span>), kernel_size=(<span class=\"number\">2</span>, <span class=\"number\">2</span>))  <span class=\"comment\"># (H,W)=(4,5), (h,w)=(2,2)</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"built_in\">input</span> = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">3</span> * <span class=\"number\">2</span> * <span class=\"number\">2</span>, <span class=\"number\">12</span>)   <span class=\"comment\"># (N, C*h*w,L)</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output = fold(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output.size()</span><br><span class=\"line\">torch.Size([<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])    <span class=\"comment\"># (N,C,H,W)</span></span><br></pre></td></tr></table></figure></p>\n<p> <code>H,W</code>  PyTorch  <code>L</code> </p>\n<script type=\"math/tex; mode=display\">L=\\prod_d \\lfloor \\frac {\\text{output\\_size} [d] + 2 \\times \\text{padding}[d]-\\text{dilation}[d] \\times (\\text{kernel\\_size}[d]-1) -1} {\\text{stride}[d]} +1 \\rfloor</script><p><strong></strong></p>\n<p>Fold  size  $(N, C \\times \\prod(\\text{kernel_size}), L)$ size  $(N,C, \\text{output_size}[0], \\text{output_size}[1], )$</p>\n<h2 id=\"Unfold\"><a href=\"#Unfold\" class=\"headerlink\" title=\"Unfold\"></a>Unfold</h2><p> torch.nn.Unfold  Fold  tensor dilationpadding  stride  <code>L</code> <code>L</code> Unfold  size  $(N,C,<em>)$ </em>  size  $(N,C \\times \\prod(\\text{kernel_size}), L)$</p>\n<p>PyTorch <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>unfold = nn.Unfold(kernel_size=(<span class=\"number\">2</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"built_in\">input</span> = torch.randn(<span class=\"number\">2</span>, <span class=\"number\">5</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output = unfold(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># each patch contains 30 values (2x3=6 vectors, each of 5 channels)</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 4 blocks (2x3 kernels) in total in the 3x4 input</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output.size()</span><br><span class=\"line\">torch.Size([<span class=\"number\">2</span>, <span class=\"number\">30</span>, <span class=\"number\">4</span>])</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"2-Normalization\"><a href=\"#2-Normalization\" class=\"headerlink\" title=\"2. Normalization\"></a>2. Normalization</h1><h2 id=\"BatchNorm\"><a href=\"#BatchNorm\" class=\"headerlink\" title=\"BatchNorm\"></a>BatchNorm</h2><p> mini-batch </p>\n<script type=\"math/tex; mode=display\">y=\\frac {x-E[x]} {\\sqrt{V[x]+\\epsilon}} * \\gamma + \\beta</script><p><br>BatchNorm Layer mini-batch $\\mathcal B=\\{x_{1m}\\}$ $\\gamma, \\beta$ mini-batch </p>\n<script type=\"math/tex; mode=display\">\\mu_{\\mathcal B} = \\frac 1 m \\sum_{i=1}^m x_i, \\quad \\sigma_{\\mathcal B}^2=\\frac 1 m \\sum_{i=1}^m(x_i - \\mu_{\\mathcal B})^2</script><p></p>\n<script type=\"math/tex; mode=display\">\\hat x_i = \\frac {x_i - \\mu_{\\mathcal B}} {\\sqrt {\\sigma_{\\mathcal B}^2+ \\epsilon}}</script><p> scale  shift</p>\n<script type=\"math/tex; mode=display\">y_i=\\hat x_i \\cdot \\gamma + \\beta</script><p><strong></strong>  batch </p>\n<h2 id=\"LayerNorm\"><a href=\"#LayerNorm\" class=\"headerlink\" title=\"LayerNorm\"></a>LayerNorm</h2><p>Layer  LayerNorm  $x$ $x$  tensor 1D vector $x=(x_1,x_H)$$H$  LayerNorm  $x$  LayerNorm </p>\n<script type=\"math/tex; mode=display\">\\mu=\\frac 1 H \\sum_{i=1}^H x_i, \\quad \\sigma^2=\\frac 1 H \\sum_{i=1}^H (x_i-\\mu)^2</script><p> LayerNorm </p>\n<script type=\"math/tex; mode=display\">y=\\frac {x-\\mu} {\\sqrt {\\sigma^2+\\epsilon}} \\cdot \\gamma + \\beta</script><p><strong></strong>  batch </p>\n<p> $\\mu, \\sigma$</p>\n<h2 id=\"InstanceNorm\"><a href=\"#InstanceNorm\" class=\"headerlink\" title=\"InstanceNorm\"></a>InstanceNorm</h2><p> channel  $\\mu, \\sigma$ $(N,C,H,W)$ $(H,W)$ </p>\n<h2 id=\"GroupNorm\"><a href=\"#GroupNorm\" class=\"headerlink\" title=\"GroupNorm\"></a>GroupNorm</h2><p>GroupNorm  channels  InstanceNormchannel LayerNorm  channels</p>\n<h1 id=\"3-Pool\"><a href=\"#3-Pool\" class=\"headerlink\" title=\"3. Pool\"></a>3. Pool</h1><p></p>\n<h2 id=\"FractionalMaxPool2d\"><a href=\"#FractionalMaxPool2d\" class=\"headerlink\" title=\"FractionalMaxPool2d\"></a>FractionalMaxPool2d</h2><p> <a href=\"https://arxiv.org/abs/1412.6071\">Fractional MaxPooling</a></p>\n<p>pool  feature map  <code>2x2</code> max-pooling  $N_{in} \\times N_{in}$ $N_{out} \\times N_{out}$</p>\n<script type=\"math/tex; mode=display\">N_{out}=\\frac {N_{in}-k+2p} {s} + 1= N_{in} / 2 \\Rightarrow N_{in} /N_{out} = 2</script><p> $N_{in} \\times N_{in}$  feature map  $N_{out}^2$  pooling  $(P_{i,j})$ $\\{1,2,,N_{in}\\}^2$  $[1,N_{in}]^2$ feature mappixel  pooling </p>\n<script type=\"math/tex; mode=display\">P_{i,j} \\subset \\{1,2,...,N_{in}\\}, \\quad (i,j) \\in \\{1,...,N_{out}\\}^2</script><p> $N_{in} / N_{out} \\in (1,2)$ $N_{in} / N_{out} \\in (2,3)$ Fractional max-poolingFMP</p>\n<p>FMP </p>\n<p> $(a_i)_{i=0}^{N_{out}}, \\ (b_i)_{i=0}^{N_{out}}$  <code>1</code> $N_{in}$  <code>1</code>  <code>2</code> $\\forall i,\\ a_{i+1}-a_{i} \\in \\{1,2\\}$ pooling </p>\n<script type=\"math/tex; mode=display\">P_{i,j}=[a_{i-1}, a_i-1] \\times [b_{j-1},b_j-1], \\quad i,j \\in \\{1,...,N_{out}\\}\n\\\\\\\\ P_{i,j}=[a_{i-1}, a_i] \\times [b_{j-1},b_j], \\quad i,j \\in \\{1,...,N_{out}\\}</script><p> <code>i,j</code> </p>\n<p> <code>disjoint</code>  <code>overlapping</code>  pooling </p>\n<p> $\\alpha = N_{in} / N_{out}$ $(a_i)_{i=0}^{N_{out}}$</p>\n<ol>\n<li><p><code>random</code> </p>\n<p> $\\alpha$  $(a_i-a_{i-1})_{i=1}^{N_{out}}$  <code>1</code>  <code>2</code>  <code>1</code>  <code>2</code> shuffle  random permutation $\\alpha = N_{in} / N_{out}$</p>\n</li>\n<li><p><code>pseudorandom</code> </p>\n<p> $(0,0), \\ (N_{out}, N_{in}-1)$  $\\alpha$ $(1,2)$  y   $\\alpha \\cdot u$ $\\alpha \\in (1,2), \\ u \\in (0,1), \\alpha \\cdot u \\in (0,1)$</p>\n<script type=\"math/tex; mode=display\">y=\\alpha(i+u)</script><p>x  $0,1,2,,N_{out}$ y  ceiling  $a_i$ </p>\n<script type=\"math/tex; mode=display\">a_i=\\text{ceiling}(\\alpha(i+u)), \\quad i=0,1,2,...,N_{out}</script><p> $\\{a_i\\}$ </p>\n<ul>\n<li>$i=0$$a_0=\\text{ceiling}(\\alpha \\cdot u)$ $\\alpha \\cdot u \\in (0,1)$ $a_0=1$</li>\n<li>$i=N_{out}$$a_{N_{out}}=\\text{ceiling}(N_{in}-1+\\alpha \\cdot u)=N_{in}$</li>\n<li><code>otherwise</code> $a_{i+1}-a_i=\\text{ceiling}(\\alpha \\cdot i+\\alpha+\\alpha \\cdot u)-\\text{ceiling}(\\alpha \\cdot i+\\alpha \\cdot u)$</li>\n</ul>\n<p></p>\n<p> $\\alpha \\cdot i+\\alpha \\cdot u=f \\in [k,k+1)$k </p>\n<ul>\n<li><p><code>f=k</code> </p>\n<p>   $a_{i+1}-a_i=\\text{ceiling}(k+\\alpha)-k=k+\\text{ceiling}(\\alpha)-k=\\text{ceiling}(\\alpha)=2$</p>\n</li>\n<li><p><code>k&lt;f&lt;k+1</code> </p>\n<p>   $k+1&lt;f+\\alpha&lt;k+3$</p>\n<p>   $a_{i+1}-a_i=\\text{ceiling}(f+\\alpha)-k-1 \\in \\{1,2\\}$</p>\n</li>\n</ul>\n<p> $(a_i)$  ceiling </p>\n</li>\n</ol>\n<h1 id=\"4-ConvTranspose\"><a href=\"#4-ConvTranspose\" class=\"headerlink\" title=\"4. ConvTranspose\"></a>4. ConvTranspose</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> $L_{in}$ $L_{out}$ $k$dilation stride  padding  $d, p, s$</p>\n<script type=\"math/tex; mode=display\">L_{out}=\\frac {L_{in}-(d(k-1)+1)+2p} s + 1 \\qquad (4-1)</script><p> $L_{in}^{\\top}, \\ L_{out}^{\\top}$ </p>\n<script type=\"math/tex; mode=display\">L_{out}^{\\top}=s(L_{in}^{\\top} - 1) +d(k-1)+1 - 2p \\qquad (4-2)</script><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> $4 \\times 4$ $3 \\times 3$ padding stride  1 $(4-1)$  $2 \\times 2$ $4 \\times 9$ <strong> element  0 </strong> $9 \\times 1$  $4 \\times 1$ </p>\n<p> $2 \\times 2$ $3 \\times 3$ padding  stride  1 $(4-2)$  $4 \\times 4$<strong></strong> zero-padding  $6\\times 6$ $6 \\times 6$  $3 \\times 3$  $4 \\times 4$  $16 \\times 9$  <strong> 180</strong> reshape  $9 \\times 1$  $16 \\times 1$ reshape  $4 \\times 4$</p>\n<p></p>\n<p><img src=\"/images/pytorch_mth_conv.png\" alt=\"\"><center></center></p>\n<p><img src=\"/images/pytorch_mtd_conv_t.png\" alt=\"\"><center></center></p>\n<p> Pytorch </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\">convt = nn.ConvTranspose2d(<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">convt.bias = nn.Parameter(torch.tensor([<span class=\"number\">0.</span>]))</span><br><span class=\"line\">convt.weight = nn.Parameter(torch.tensor([[[[<span class=\"number\">0.</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>],</span><br><span class=\"line\">                                            [<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>],</span><br><span class=\"line\">                                            [<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>]]]]))</span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([[[[<span class=\"number\">12.</span>,<span class=\"number\">12</span>],</span><br><span class=\"line\">                        [<span class=\"number\">10</span>,<span class=\"number\">17</span>]]]])</span><br><span class=\"line\">output = convt(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">output</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[ 0., 12., 36., 24.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [24., 58., 61., 34.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [20., 66., 70., 24.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 0., 10., 37., 34.]]]])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p> reshape  $1 \\times 16$ 4  zero-padding  4  $4 \\times 4$  $3 \\times 4$  $4 \\times 4$  zero-padding reshape  $16 \\times 4$ $16 \\times 4$  $K$  $1 \\times 4$ reshape  $2 \\times 2$ </p>\n<p> $2 \\times 2$ <code>[12,12,10,17]</code> reshape  $1 \\times 4$ $K$ <strong></strong> $4 \\times 16$  $1 \\times 16$  reshape  $4 \\times 4$ </p>\n<p></p>\n<p><img src=\"/images/pytorch_mtd_conv_t_1.png\" alt=\"\"><center></center></p>\n<p></p>\n<h3 id=\"dilation-gt-1\"><a href=\"#dilation-gt-1\" class=\"headerlink\" title=\"dilation &gt; 1\"></a>dilation &gt; 1</h3><p> <code>dilation</code>  1  <code>dilation=2</code> $(4-2)$  $6 \\times 6$ $5 \\times 5$  0 <strong> 180</strong> zero-padding  $10 \\times 10$  $6 \\times 6$  4  zero-padding</p>\n<p> <code>input</code>  $I$zero-padding$I[4:6,4:6]=[[12.,12],[10,17]]$ <code>0</code> <strong> 180</strong>  $K=[[2., 0, 1, 0, 0],[0,0,0,0,0],[0,0,2,0,2],[0,0,0,0,0],[2,0,1,0,0]]$ python <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">convt1 = nn.ConvTranspose2d(<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">3</span>,dilation=<span class=\"number\">2</span>)</span><br><span class=\"line\">convt1.bias = nn.Parameter(torch.tensor([<span class=\"number\">0.</span>]))</span><br><span class=\"line\">convt1.weight = nn.Parameter(torch.tensor([[[[<span class=\"number\">0.</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>],[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>]]]]))</span><br><span class=\"line\">output1 = convt1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">output1</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"stride-gt-1\"><a href=\"#stride-gt-1\" class=\"headerlink\" title=\"stride &gt; 1\"></a>stride &gt; 1</h3><p> <code>stride=2</code> $(4-2)$  $5 \\times 5$ $7 \\times 7$ <code>stride=2</code> $2 \\times 2$  $3 \\times 3$ 2*(2-1)+1=3 zero-padding  $7 \\times 7$  padding  (7-3)/2=2 $I[2,2]=I[2,4]=12, \\ I[4,2]=10, \\ I[4,4]=17$ <code>0</code> <strong> 180</strong>  $K=[[2., 1, 0],[0,2,2],[2,1,0]]$ python <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">convt.stride = (<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">output = convt(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">output</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"padding-gt-0\"><a href=\"#padding-gt-0\" class=\"headerlink\" title=\"padding &gt; 0\"></a>padding &gt; 0</h3><p> <code>padding=1</code> $(4-2)$  $2 \\times 2$ 1  zero-padding $4 \\times 4$ $3 \\times 3$ <strong> 180</strong></p>\n<p> <code>dialtion &gt; 1, stride &gt; 1, padding &gt; 0</code>  python  <code></code>  <code></code> </p>\n<h1 id=\"5-Upsample\"><a href=\"#5-Upsample\" class=\"headerlink\" title=\"5. Upsample\"></a>5. Upsample</h1><p> <code>minibatch x channels x [optional depth] x [optional height] x width</code> 3D/4D/5D <code>nearest neighbor, linear, bilinear, bicubic, trilinear</code></p>\n<h2 id=\"nearest-neighbor\"><a href=\"#nearest-neighbor\" class=\"headerlink\" title=\"nearest neighbor\"></a>nearest neighbor</h2><p> size  $m \\times m$ S size  $n \\times n, \\ n &gt; m$ $(x,y), \\ x,y =0,1,,n-1$ S  $(x,y)$</p>\n<script type=\"math/tex; mode=display\">\\frac {x-0} {n-1-0}= \\frac {x'-0}{m-1-0} \\Rightarrow x' = \\frac {m-1} {n-1} \\cdot x</script><p> $y = \\frac {m-1} {n-1} \\cdot y$ $(i,j)$  $(\\lfloor x\\rfloor, \\lfloor y \\rfloor), \\ (\\lfloor x\\rfloor, \\lceil y \\rceil), \\ (\\lceil x\\rceil, \\lfloor y \\rfloor), \\ (\\lceil x\\rceil, \\lceil y \\rceil)$  $(x,y)$  $(x,y)$  PyTorch </p>\n<h2 id=\"bilinear\"><a href=\"#bilinear\" class=\"headerlink\" title=\"bilinear\"></a>bilinear</h2><p> 4D</p>\n<h3 id=\"align-corners-True\"><a href=\"#align-corners-True\" class=\"headerlink\" title=\"align_corners=True\"></a>align_corners=True</h3><p> $(x_1,y_1), \\ (x_1,y_2), \\ (x_2,y_1), \\ (x_2,y_2)$ $(x,y), \\ x_1 \\le x \\le x_2, \\ y_1 \\le y \\le y_2$  x </p>\n<script type=\"math/tex; mode=display\">f(x,y_1)=\\frac {f_{21}-f_{11}} {x_2-x_1} \\cdot (x-x_1)+f_{11}\n\\\\\\\\ f(x,y_2)=\\frac {f_{22}-f_{12}} {x_2-x_1} \\cdot (x-x_1)+f_{12}\n\\\\\\\\ f(x,y)=\\frac {f_(x,y_2)-f(x,y_1)} {y_2-y_1} \\cdot (y-y_1)+f(x,y_1)</script><p> <code>nearest neighbor</code>  $(x,y)$  $(x,y)$ $(\\lfloor x\\rfloor, \\lfloor y \\rfloor), \\ (\\lfloor x\\rfloor, \\lceil y \\rceil), \\ (\\lceil x\\rceil, \\lfloor y \\rfloor), \\ (\\lceil x\\rceil, \\lceil y \\rceil)$ corners  corners  <code>align_corners=True</code> </p>\n<h3 id=\"align-corners-False\"><a href=\"#align-corners-False\" class=\"headerlink\" title=\"align_corners=False\"></a>align_corners=False</h3><p> <code>align_corners</code> <br><img src=\"/images/pytorch_mtd_aligncorners.png\" alt=\"\"><center> [pytorch ](https://discuss.pytorch.org/t/what-we-should-use-align-corners-false/22663/9)</center></p>\n<p> $(x,y)$ S </p>\n<script type=\"math/tex; mode=display\">x'=(x+0.5)/2-0.5\n\\\\\\\\ y'=(y+0.5)/2-0.5</script><p> 4  $(\\lfloor x\\rfloor, \\lfloor y \\rfloor), \\ (\\lfloor x\\rfloor, \\lceil y \\rceil), \\ (\\lceil x\\rceil, \\lfloor y \\rfloor), \\ (\\lceil x\\rceil, \\lceil y \\rceil)$ </p>\n<h2 id=\"linear\"><a href=\"#linear\" class=\"headerlink\" title=\"linear\"></a>linear</h2><p> bilinear  3D</p>\n<h2 id=\"trilinear\"><a href=\"#trilinear\" class=\"headerlink\" title=\"trilinear\"></a>trilinear</h2><p> bilinear  5D</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-Fold-Unfold\"><a href=\"#1-Fold-Unfold\" class=\"headerlink\" title=\"1. Fold / Unfold\"></a>1. Fold / Unfold</h1><h2 id=\"Fold\"><a href=\"#Fold\" class=\"headerlink\" title=\"Fold\"></a>Fold</h2><p> torch.nn.Fold </p>\n<p> size  <code>(N,C,H,W)</code> kernel size  <code>(C,h,w)</code> <code>d</code>padding  <code>p</code>stride  <code>s</code> <code>Cxhxw</code>  <code>L</code>  <code>L</code>  <code>(C,h,w)</code> map <br>","more":"</p>\n<script type=\"math/tex; mode=display\">H_o= \\frac {H - [d(h-1)+1] + 2p} {s}+1\n\\\\\\\\ W_o= \\frac {W - [d(w-1)+1] + 2p} {s}+1</script><p> map  <code>L</code> </p>\n<script type=\"math/tex; mode=display\">L=H_o * W_o=\\left(\\frac {H - [d(h-1)+1] + 2p} {s}+1\\right) \\left(\\frac {W - [d(w-1)+1] + 2p} {s}+1\\right)</script><p> Fold  fold  <code>L</code>  <code>(N,C*h*w,L)</code> size <code>(h,w)</code>dilationpaddingstrideFold <code>(H,W)</code>Fold  <code>L</code>  map  <code>(H,W)</code> map <strong>Fold </strong></p>\n<p>Fold  Fold <code>L</code>  tensorsize  <code>(N,C*h*w,L)</code> tensor Fold   map  <code>(H,W)</code> <code>N</code>  <code>C</code> Fold  tensor   <code>C*h*w</code>  Fold  <code>(h,w)</code>  <code>C</code></p>\n<p> PyTorch <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>fold = nn.Fold(output_size=(<span class=\"number\">4</span>, <span class=\"number\">5</span>), kernel_size=(<span class=\"number\">2</span>, <span class=\"number\">2</span>))  <span class=\"comment\"># (H,W)=(4,5), (h,w)=(2,2)</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"built_in\">input</span> = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">3</span> * <span class=\"number\">2</span> * <span class=\"number\">2</span>, <span class=\"number\">12</span>)   <span class=\"comment\"># (N, C*h*w,L)</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output = fold(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output.size()</span><br><span class=\"line\">torch.Size([<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])    <span class=\"comment\"># (N,C,H,W)</span></span><br></pre></td></tr></table></figure></p>\n<p> <code>H,W</code>  PyTorch  <code>L</code> </p>\n<script type=\"math/tex; mode=display\">L=\\prod_d \\lfloor \\frac {\\text{output\\_size} [d] + 2 \\times \\text{padding}[d]-\\text{dilation}[d] \\times (\\text{kernel\\_size}[d]-1) -1} {\\text{stride}[d]} +1 \\rfloor</script><p><strong></strong></p>\n<p>Fold  size  $(N, C \\times \\prod(\\text{kernel_size}), L)$ size  $(N,C, \\text{output_size}[0], \\text{output_size}[1], )$</p>\n<h2 id=\"Unfold\"><a href=\"#Unfold\" class=\"headerlink\" title=\"Unfold\"></a>Unfold</h2><p> torch.nn.Unfold  Fold  tensor dilationpadding  stride  <code>L</code> <code>L</code> Unfold  size  $(N,C,<em>)$ </em>  size  $(N,C \\times \\prod(\\text{kernel_size}), L)$</p>\n<p>PyTorch <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>unfold = nn.Unfold(kernel_size=(<span class=\"number\">2</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"built_in\">input</span> = torch.randn(<span class=\"number\">2</span>, <span class=\"number\">5</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output = unfold(<span class=\"built_in\">input</span>)</span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># each patch contains 30 values (2x3=6 vectors, each of 5 channels)</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\"># 4 blocks (2x3 kernels) in total in the 3x4 input</span></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>output.size()</span><br><span class=\"line\">torch.Size([<span class=\"number\">2</span>, <span class=\"number\">30</span>, <span class=\"number\">4</span>])</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"2-Normalization\"><a href=\"#2-Normalization\" class=\"headerlink\" title=\"2. Normalization\"></a>2. Normalization</h1><h2 id=\"BatchNorm\"><a href=\"#BatchNorm\" class=\"headerlink\" title=\"BatchNorm\"></a>BatchNorm</h2><p> mini-batch </p>\n<script type=\"math/tex; mode=display\">y=\\frac {x-E[x]} {\\sqrt{V[x]+\\epsilon}} * \\gamma + \\beta</script><p><br>BatchNorm Layer mini-batch $\\mathcal B=\\{x_{1m}\\}$ $\\gamma, \\beta$ mini-batch </p>\n<script type=\"math/tex; mode=display\">\\mu_{\\mathcal B} = \\frac 1 m \\sum_{i=1}^m x_i, \\quad \\sigma_{\\mathcal B}^2=\\frac 1 m \\sum_{i=1}^m(x_i - \\mu_{\\mathcal B})^2</script><p></p>\n<script type=\"math/tex; mode=display\">\\hat x_i = \\frac {x_i - \\mu_{\\mathcal B}} {\\sqrt {\\sigma_{\\mathcal B}^2+ \\epsilon}}</script><p> scale  shift</p>\n<script type=\"math/tex; mode=display\">y_i=\\hat x_i \\cdot \\gamma + \\beta</script><p><strong></strong>  batch </p>\n<h2 id=\"LayerNorm\"><a href=\"#LayerNorm\" class=\"headerlink\" title=\"LayerNorm\"></a>LayerNorm</h2><p>Layer  LayerNorm  $x$ $x$  tensor 1D vector $x=(x_1,x_H)$$H$  LayerNorm  $x$  LayerNorm </p>\n<script type=\"math/tex; mode=display\">\\mu=\\frac 1 H \\sum_{i=1}^H x_i, \\quad \\sigma^2=\\frac 1 H \\sum_{i=1}^H (x_i-\\mu)^2</script><p> LayerNorm </p>\n<script type=\"math/tex; mode=display\">y=\\frac {x-\\mu} {\\sqrt {\\sigma^2+\\epsilon}} \\cdot \\gamma + \\beta</script><p><strong></strong>  batch </p>\n<p> $\\mu, \\sigma$</p>\n<h2 id=\"InstanceNorm\"><a href=\"#InstanceNorm\" class=\"headerlink\" title=\"InstanceNorm\"></a>InstanceNorm</h2><p> channel  $\\mu, \\sigma$ $(N,C,H,W)$ $(H,W)$ </p>\n<h2 id=\"GroupNorm\"><a href=\"#GroupNorm\" class=\"headerlink\" title=\"GroupNorm\"></a>GroupNorm</h2><p>GroupNorm  channels  InstanceNormchannel LayerNorm  channels</p>\n<h1 id=\"3-Pool\"><a href=\"#3-Pool\" class=\"headerlink\" title=\"3. Pool\"></a>3. Pool</h1><p></p>\n<h2 id=\"FractionalMaxPool2d\"><a href=\"#FractionalMaxPool2d\" class=\"headerlink\" title=\"FractionalMaxPool2d\"></a>FractionalMaxPool2d</h2><p> <a href=\"https://arxiv.org/abs/1412.6071\">Fractional MaxPooling</a></p>\n<p>pool  feature map  <code>2x2</code> max-pooling  $N_{in} \\times N_{in}$ $N_{out} \\times N_{out}$</p>\n<script type=\"math/tex; mode=display\">N_{out}=\\frac {N_{in}-k+2p} {s} + 1= N_{in} / 2 \\Rightarrow N_{in} /N_{out} = 2</script><p> $N_{in} \\times N_{in}$  feature map  $N_{out}^2$  pooling  $(P_{i,j})$ $\\{1,2,,N_{in}\\}^2$  $[1,N_{in}]^2$ feature mappixel  pooling </p>\n<script type=\"math/tex; mode=display\">P_{i,j} \\subset \\{1,2,...,N_{in}\\}, \\quad (i,j) \\in \\{1,...,N_{out}\\}^2</script><p> $N_{in} / N_{out} \\in (1,2)$ $N_{in} / N_{out} \\in (2,3)$ Fractional max-poolingFMP</p>\n<p>FMP </p>\n<p> $(a_i)_{i=0}^{N_{out}}, \\ (b_i)_{i=0}^{N_{out}}$  <code>1</code> $N_{in}$  <code>1</code>  <code>2</code> $\\forall i,\\ a_{i+1}-a_{i} \\in \\{1,2\\}$ pooling </p>\n<script type=\"math/tex; mode=display\">P_{i,j}=[a_{i-1}, a_i-1] \\times [b_{j-1},b_j-1], \\quad i,j \\in \\{1,...,N_{out}\\}\n\\\\\\\\ P_{i,j}=[a_{i-1}, a_i] \\times [b_{j-1},b_j], \\quad i,j \\in \\{1,...,N_{out}\\}</script><p> <code>i,j</code> </p>\n<p> <code>disjoint</code>  <code>overlapping</code>  pooling </p>\n<p> $\\alpha = N_{in} / N_{out}$ $(a_i)_{i=0}^{N_{out}}$</p>\n<ol>\n<li><p><code>random</code> </p>\n<p> $\\alpha$  $(a_i-a_{i-1})_{i=1}^{N_{out}}$  <code>1</code>  <code>2</code>  <code>1</code>  <code>2</code> shuffle  random permutation $\\alpha = N_{in} / N_{out}$</p>\n</li>\n<li><p><code>pseudorandom</code> </p>\n<p> $(0,0), \\ (N_{out}, N_{in}-1)$  $\\alpha$ $(1,2)$  y   $\\alpha \\cdot u$ $\\alpha \\in (1,2), \\ u \\in (0,1), \\alpha \\cdot u \\in (0,1)$</p>\n<script type=\"math/tex; mode=display\">y=\\alpha(i+u)</script><p>x  $0,1,2,,N_{out}$ y  ceiling  $a_i$ </p>\n<script type=\"math/tex; mode=display\">a_i=\\text{ceiling}(\\alpha(i+u)), \\quad i=0,1,2,...,N_{out}</script><p> $\\{a_i\\}$ </p>\n<ul>\n<li>$i=0$$a_0=\\text{ceiling}(\\alpha \\cdot u)$ $\\alpha \\cdot u \\in (0,1)$ $a_0=1$</li>\n<li>$i=N_{out}$$a_{N_{out}}=\\text{ceiling}(N_{in}-1+\\alpha \\cdot u)=N_{in}$</li>\n<li><code>otherwise</code> $a_{i+1}-a_i=\\text{ceiling}(\\alpha \\cdot i+\\alpha+\\alpha \\cdot u)-\\text{ceiling}(\\alpha \\cdot i+\\alpha \\cdot u)$</li>\n</ul>\n<p></p>\n<p> $\\alpha \\cdot i+\\alpha \\cdot u=f \\in [k,k+1)$k </p>\n<ul>\n<li><p><code>f=k</code> </p>\n<p>   $a_{i+1}-a_i=\\text{ceiling}(k+\\alpha)-k=k+\\text{ceiling}(\\alpha)-k=\\text{ceiling}(\\alpha)=2$</p>\n</li>\n<li><p><code>k&lt;f&lt;k+1</code> </p>\n<p>   $k+1&lt;f+\\alpha&lt;k+3$</p>\n<p>   $a_{i+1}-a_i=\\text{ceiling}(f+\\alpha)-k-1 \\in \\{1,2\\}$</p>\n</li>\n</ul>\n<p> $(a_i)$  ceiling </p>\n</li>\n</ol>\n<h1 id=\"4-ConvTranspose\"><a href=\"#4-ConvTranspose\" class=\"headerlink\" title=\"4. ConvTranspose\"></a>4. ConvTranspose</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> $L_{in}$ $L_{out}$ $k$dilation stride  padding  $d, p, s$</p>\n<script type=\"math/tex; mode=display\">L_{out}=\\frac {L_{in}-(d(k-1)+1)+2p} s + 1 \\qquad (4-1)</script><p> $L_{in}^{\\top}, \\ L_{out}^{\\top}$ </p>\n<script type=\"math/tex; mode=display\">L_{out}^{\\top}=s(L_{in}^{\\top} - 1) +d(k-1)+1 - 2p \\qquad (4-2)</script><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> $4 \\times 4$ $3 \\times 3$ padding stride  1 $(4-1)$  $2 \\times 2$ $4 \\times 9$ <strong> element  0 </strong> $9 \\times 1$  $4 \\times 1$ </p>\n<p> $2 \\times 2$ $3 \\times 3$ padding  stride  1 $(4-2)$  $4 \\times 4$<strong></strong> zero-padding  $6\\times 6$ $6 \\times 6$  $3 \\times 3$  $4 \\times 4$  $16 \\times 9$  <strong> 180</strong> reshape  $9 \\times 1$  $16 \\times 1$ reshape  $4 \\times 4$</p>\n<p></p>\n<p><img src=\"/images/pytorch_mth_conv.png\" alt=\"\"><center></center></p>\n<p><img src=\"/images/pytorch_mtd_conv_t.png\" alt=\"\"><center></center></p>\n<p> Pytorch </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\">convt = nn.ConvTranspose2d(<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">convt.bias = nn.Parameter(torch.tensor([<span class=\"number\">0.</span>]))</span><br><span class=\"line\">convt.weight = nn.Parameter(torch.tensor([[[[<span class=\"number\">0.</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>],</span><br><span class=\"line\">                                            [<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>],</span><br><span class=\"line\">                                            [<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>]]]]))</span><br><span class=\"line\"><span class=\"built_in\">input</span> = torch.tensor([[[[<span class=\"number\">12.</span>,<span class=\"number\">12</span>],</span><br><span class=\"line\">                        [<span class=\"number\">10</span>,<span class=\"number\">17</span>]]]])</span><br><span class=\"line\">output = convt(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">output</span><br><span class=\"line\"><span class=\"comment\"># tensor([[[[ 0., 12., 36., 24.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [24., 58., 61., 34.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [20., 66., 70., 24.],</span></span><br><span class=\"line\"><span class=\"comment\">#           [ 0., 10., 37., 34.]]]])</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p> reshape  $1 \\times 16$ 4  zero-padding  4  $4 \\times 4$  $3 \\times 4$  $4 \\times 4$  zero-padding reshape  $16 \\times 4$ $16 \\times 4$  $K$  $1 \\times 4$ reshape  $2 \\times 2$ </p>\n<p> $2 \\times 2$ <code>[12,12,10,17]</code> reshape  $1 \\times 4$ $K$ <strong></strong> $4 \\times 16$  $1 \\times 16$  reshape  $4 \\times 4$ </p>\n<p></p>\n<p><img src=\"/images/pytorch_mtd_conv_t_1.png\" alt=\"\"><center></center></p>\n<p></p>\n<h3 id=\"dilation-gt-1\"><a href=\"#dilation-gt-1\" class=\"headerlink\" title=\"dilation &gt; 1\"></a>dilation &gt; 1</h3><p> <code>dilation</code>  1  <code>dilation=2</code> $(4-2)$  $6 \\times 6$ $5 \\times 5$  0 <strong> 180</strong> zero-padding  $10 \\times 10$  $6 \\times 6$  4  zero-padding</p>\n<p> <code>input</code>  $I$zero-padding$I[4:6,4:6]=[[12.,12],[10,17]]$ <code>0</code> <strong> 180</strong>  $K=[[2., 0, 1, 0, 0],[0,0,0,0,0],[0,0,2,0,2],[0,0,0,0,0],[2,0,1,0,0]]$ python <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">convt1 = nn.ConvTranspose2d(<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">3</span>,dilation=<span class=\"number\">2</span>)</span><br><span class=\"line\">convt1.bias = nn.Parameter(torch.tensor([<span class=\"number\">0.</span>]))</span><br><span class=\"line\">convt1.weight = nn.Parameter(torch.tensor([[[[<span class=\"number\">0.</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>],[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>]]]]))</span><br><span class=\"line\">output1 = convt1(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">output1</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"stride-gt-1\"><a href=\"#stride-gt-1\" class=\"headerlink\" title=\"stride &gt; 1\"></a>stride &gt; 1</h3><p> <code>stride=2</code> $(4-2)$  $5 \\times 5$ $7 \\times 7$ <code>stride=2</code> $2 \\times 2$  $3 \\times 3$ 2*(2-1)+1=3 zero-padding  $7 \\times 7$  padding  (7-3)/2=2 $I[2,2]=I[2,4]=12, \\ I[4,2]=10, \\ I[4,4]=17$ <code>0</code> <strong> 180</strong>  $K=[[2., 1, 0],[0,2,2],[2,1,0]]$ python <br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">convt.stride = (<span class=\"number\">2</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">output = convt(<span class=\"built_in\">input</span>)</span><br><span class=\"line\">output</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"padding-gt-0\"><a href=\"#padding-gt-0\" class=\"headerlink\" title=\"padding &gt; 0\"></a>padding &gt; 0</h3><p> <code>padding=1</code> $(4-2)$  $2 \\times 2$ 1  zero-padding $4 \\times 4$ $3 \\times 3$ <strong> 180</strong></p>\n<p> <code>dialtion &gt; 1, stride &gt; 1, padding &gt; 0</code>  python  <code></code>  <code></code> </p>\n<h1 id=\"5-Upsample\"><a href=\"#5-Upsample\" class=\"headerlink\" title=\"5. Upsample\"></a>5. Upsample</h1><p> <code>minibatch x channels x [optional depth] x [optional height] x width</code> 3D/4D/5D <code>nearest neighbor, linear, bilinear, bicubic, trilinear</code></p>\n<h2 id=\"nearest-neighbor\"><a href=\"#nearest-neighbor\" class=\"headerlink\" title=\"nearest neighbor\"></a>nearest neighbor</h2><p> size  $m \\times m$ S size  $n \\times n, \\ n &gt; m$ $(x,y), \\ x,y =0,1,,n-1$ S  $(x,y)$</p>\n<script type=\"math/tex; mode=display\">\\frac {x-0} {n-1-0}= \\frac {x'-0}{m-1-0} \\Rightarrow x' = \\frac {m-1} {n-1} \\cdot x</script><p> $y = \\frac {m-1} {n-1} \\cdot y$ $(i,j)$  $(\\lfloor x\\rfloor, \\lfloor y \\rfloor), \\ (\\lfloor x\\rfloor, \\lceil y \\rceil), \\ (\\lceil x\\rceil, \\lfloor y \\rfloor), \\ (\\lceil x\\rceil, \\lceil y \\rceil)$  $(x,y)$  $(x,y)$  PyTorch </p>\n<h2 id=\"bilinear\"><a href=\"#bilinear\" class=\"headerlink\" title=\"bilinear\"></a>bilinear</h2><p> 4D</p>\n<h3 id=\"align-corners-True\"><a href=\"#align-corners-True\" class=\"headerlink\" title=\"align_corners=True\"></a>align_corners=True</h3><p> $(x_1,y_1), \\ (x_1,y_2), \\ (x_2,y_1), \\ (x_2,y_2)$ $(x,y), \\ x_1 \\le x \\le x_2, \\ y_1 \\le y \\le y_2$  x </p>\n<script type=\"math/tex; mode=display\">f(x,y_1)=\\frac {f_{21}-f_{11}} {x_2-x_1} \\cdot (x-x_1)+f_{11}\n\\\\\\\\ f(x,y_2)=\\frac {f_{22}-f_{12}} {x_2-x_1} \\cdot (x-x_1)+f_{12}\n\\\\\\\\ f(x,y)=\\frac {f_(x,y_2)-f(x,y_1)} {y_2-y_1} \\cdot (y-y_1)+f(x,y_1)</script><p> <code>nearest neighbor</code>  $(x,y)$  $(x,y)$ $(\\lfloor x\\rfloor, \\lfloor y \\rfloor), \\ (\\lfloor x\\rfloor, \\lceil y \\rceil), \\ (\\lceil x\\rceil, \\lfloor y \\rfloor), \\ (\\lceil x\\rceil, \\lceil y \\rceil)$ corners  corners  <code>align_corners=True</code> </p>\n<h3 id=\"align-corners-False\"><a href=\"#align-corners-False\" class=\"headerlink\" title=\"align_corners=False\"></a>align_corners=False</h3><p> <code>align_corners</code> <br><img src=\"/images/pytorch_mtd_aligncorners.png\" alt=\"\"><center> [pytorch ](https://discuss.pytorch.org/t/what-we-should-use-align-corners-false/22663/9)</center></p>\n<p> $(x,y)$ S </p>\n<script type=\"math/tex; mode=display\">x'=(x+0.5)/2-0.5\n\\\\\\\\ y'=(y+0.5)/2-0.5</script><p> 4  $(\\lfloor x\\rfloor, \\lfloor y \\rfloor), \\ (\\lfloor x\\rfloor, \\lceil y \\rceil), \\ (\\lceil x\\rceil, \\lfloor y \\rfloor), \\ (\\lceil x\\rceil, \\lceil y \\rceil)$ </p>\n<h2 id=\"linear\"><a href=\"#linear\" class=\"headerlink\" title=\"linear\"></a>linear</h2><p> bilinear  3D</p>\n<h2 id=\"trilinear\"><a href=\"#trilinear\" class=\"headerlink\" title=\"trilinear\"></a>trilinear</h2><p> bilinear  5D</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cku6or91l003fp0djf0eweqym","category_id":"cku6or91n003ip0djgg456cxz","_id":"cku6or91r003up0dj2itc2bh8"},{"post_id":"cku6or91m003hp0dj9r5nbwc2","category_id":"cku6or91n003ip0djgg456cxz","_id":"cku6or91s003yp0djebescnhr"},{"post_id":"cku6or92d0058p0dj4xjrgm8c","category_id":"cku6or91n003ip0djgg456cxz","_id":"cku6or92g005fp0dj09ed9ivt"},{"post_id":"cku6or92e005ap0dj2ilw4i3o","category_id":"cku6or91n003ip0djgg456cxz","_id":"cku6or92g005hp0djahqngv3p"},{"post_id":"cku6or92b0053p0djb63rajmr","category_id":"cku6or92d0056p0djbvxa3mfi","_id":"cku6or92g005jp0dj2ysdbb08"},{"post_id":"cku6or92f005cp0djhk3sdj9s","category_id":"cku6or91n003ip0djgg456cxz","_id":"cku6or92g005lp0dj411m3l52"}],"PostTag":[{"post_id":"cku6or8zt0001p0dj8eu0876c","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or905000ap0djdhvn5vbe"},{"post_id":"cku6or9040008p0dje4ma96kl","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or905000cp0dj6azj9vft"},{"post_id":"cku6or905000bp0dj3u3rhgci","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or906000fp0dj58ho8hsv"},{"post_id":"cku6or8zy0003p0dj7os1hhn1","tag_id":"cku6or9040009p0dja2yadzzr","_id":"cku6or907000hp0djg1y16i6q"},{"post_id":"cku6or905000dp0djdkz1c77u","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or909000kp0dj4gb3g9va"},{"post_id":"cku6or906000gp0dj4cr6bfwq","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90a000mp0djhh95hdzj"},{"post_id":"cku6or9020006p0dje1967ydw","tag_id":"cku6or906000ep0djclpu6u7s","_id":"cku6or90b000op0djexhk9nll"},{"post_id":"cku6or907000ip0dj5aw3al7i","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90c000qp0djfsye25p4"},{"post_id":"cku6or909000lp0dj4tor7hps","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90c000sp0djekpm9nqo"},{"post_id":"cku6or9030007p0djdv3sg6h1","tag_id":"cku6or906000ep0djclpu6u7s","_id":"cku6or90d000up0dj4ekqd6gu"},{"post_id":"cku6or90a000np0dj293f0i8a","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90e000wp0dj6qene7mb"},{"post_id":"cku6or90b000pp0djemkhe7w1","tag_id":"cku6or9040009p0dja2yadzzr","_id":"cku6or90f000yp0dj7nk2eg1w"},{"post_id":"cku6or90c000rp0djc83zgue2","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90f0010p0dj42u2d0s0"},{"post_id":"cku6or90d000vp0dja7ogdasr","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90h0013p0dj9ewy8vyz"},{"post_id":"cku6or90e000xp0djgbhd4ge6","tag_id":"cku6or9040009p0dja2yadzzr","_id":"cku6or90h0015p0djayig27ix"},{"post_id":"cku6or90f0011p0dj4w5zb2v3","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90i0017p0dj3heb0z5u"},{"post_id":"cku6or90h0016p0dj6qwxa2c1","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90j001ap0dj0zb9chrw"},{"post_id":"cku6or90f000zp0dj9mkf4bd8","tag_id":"cku6or90g0012p0dj9vi83kt7","_id":"cku6or90k001cp0djf4ozh38h"},{"post_id":"cku6or90i0018p0dja8zqhskb","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or90l001fp0djcfn9bply"},{"post_id":"cku6or90h0014p0dj39v68im5","tag_id":"cku6or90g0012p0dj9vi83kt7","_id":"cku6or90m001hp0djcv5jcv0e"},{"post_id":"cku6or90j001bp0djaog2hfw3","tag_id":"cku6or90l001ep0djbhmj1z1q","_id":"cku6or90n001kp0djbfinbkgq"},{"post_id":"cku6or90o001mp0dj5eqcewf5","tag_id":"cku6or90p001op0dj89y1asbz","_id":"cku6or90r001tp0djg8yd38u1"},{"post_id":"cku6or90r001up0dj8zkj88yz","tag_id":"cku6or90g0012p0dj9vi83kt7","_id":"cku6or90t001xp0djfpd5hrg3"},{"post_id":"cku6or90o001np0djczip23hb","tag_id":"cku6or90r001sp0dj321f7nl8","_id":"cku6or90u001zp0djfqhj0tsc"},{"post_id":"cku6or90p001pp0djcw5t4unq","tag_id":"cku6or90p001op0dj89y1asbz","_id":"cku6or90v0022p0djc7i3c1w0"},{"post_id":"cku6or90v0021p0djh6qc1q6e","tag_id":"cku6or90w0024p0dj7dedbnrq","_id":"cku6or9110029p0djetpbdrhq"},{"post_id":"cku6or90z0025p0dje6ai3d7g","tag_id":"cku6or9110028p0dj0siz3qfb","_id":"cku6or913002ep0djafnq9yu6"},{"post_id":"cku6or9100026p0dj89ku7h0o","tag_id":"cku6or912002cp0dj6ghfdjcc","_id":"cku6or915002ip0dj6w3d929r"},{"post_id":"cku6or9100027p0djhj6f9a90","tag_id":"cku6or912002cp0dj6ghfdjcc","_id":"cku6or916002mp0dj6arjaiw6"},{"post_id":"cku6or911002ap0dj4nvkc92b","tag_id":"cku6or915002kp0dj1gpjdyov","_id":"cku6or91d002tp0dj0j2p1bj8"},{"post_id":"cku6or911002ap0dj4nvkc92b","tag_id":"cku6or917002op0djc9b0eb5z","_id":"cku6or91e002vp0dj9oqy5g0l"},{"post_id":"cku6or91d002up0dje4eb95rx","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or91f002yp0dj4uhy46km"},{"post_id":"cku6or912002bp0djhdx8bzai","tag_id":"cku6or915002kp0dj1gpjdyov","_id":"cku6or91g0032p0djfyxfbofg"},{"post_id":"cku6or912002bp0djhdx8bzai","tag_id":"cku6or917002op0djc9b0eb5z","_id":"cku6or91h0034p0dj4gf0houv"},{"post_id":"cku6or913002dp0dj001b96yg","tag_id":"cku6or91g0031p0dj8wb62mom","_id":"cku6or91i0038p0dj87yb06kc"},{"post_id":"cku6or913002fp0dj441i7dry","tag_id":"cku6or91i0036p0dj3nmf2y5p","_id":"cku6or91k003cp0djgy96bkna"},{"post_id":"cku6or914002hp0dj2u9w2rjf","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91m003gp0djgmpuh1is"},{"post_id":"cku6or915002jp0djba5k80ji","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91o003lp0djhfum4pl1"},{"post_id":"cku6or916002lp0dja1osfjr8","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91q003qp0dj6301bhx2"},{"post_id":"cku6or916002np0dj6qla6qfn","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91s003vp0dj1il222pz"},{"post_id":"cku6or917002pp0djeu0r7613","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91t003zp0djhf4u09o1"},{"post_id":"cku6or918002qp0dj4uu1ftx6","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91t0041p0dj9i0187v8"},{"post_id":"cku6or91c002rp0djeulw6nsi","tag_id":"cku6or91j003ap0dj035vag4q","_id":"cku6or91t0043p0dj0hwd9xul"},{"post_id":"cku6or91f0030p0djcj8jbzwo","tag_id":"cku6or91t0042p0dj246z7unj","_id":"cku6or91u0045p0dj4lxl82ir"},{"post_id":"cku6or91j003bp0djbglnclng","tag_id":"cku6or91t0044p0dj42bgcx10","_id":"cku6or91u0047p0dj4ftshgbm"},{"post_id":"cku6or91k003dp0dj4e7zg7p4","tag_id":"cku6or91u0046p0dj74k4hnvm","_id":"cku6or91u0049p0dj6n5795i1"},{"post_id":"cku6or91l003fp0djf0eweqym","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91v004bp0djbjsj77fb"},{"post_id":"cku6or91m003hp0dj9r5nbwc2","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91v004dp0djf859cc8c"},{"post_id":"cku6or91n003kp0djfng7c5dv","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91v004fp0dj1xrn6co4"},{"post_id":"cku6or91o003mp0dj1ylzbkon","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91w004hp0djhhmv47xt"},{"post_id":"cku6or91p003op0dj1brc324q","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91w004jp0djd3mo6k7u"},{"post_id":"cku6or91q003rp0dj1628dj5p","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91x004mp0dje5ip4cs8"},{"post_id":"cku6or91q003rp0dj1628dj5p","tag_id":"cku6or91u0046p0dj74k4hnvm","_id":"cku6or91x004np0djd02b66bo"},{"post_id":"cku6or91r003tp0dja8k7hvdq","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91x004pp0dj8gxz6f8i"},{"post_id":"cku6or91s003wp0dj28xpd876","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or91x004qp0djaomk1nt8"},{"post_id":"cku6or925004rp0djbj7f5d6u","tag_id":"cku6or926004tp0dj2mo63q4p","_id":"cku6or929004yp0dj7stia6gy"},{"post_id":"cku6or928004wp0dj6adu34oj","tag_id":"cku6or9040009p0dja2yadzzr","_id":"cku6or92a0050p0djavrp7ca8"},{"post_id":"cku6or92a004zp0djcmllhcux","tag_id":"cku6or9000004p0dj6xjdcv2u","_id":"cku6or92b0052p0dj0fiyci5x"},{"post_id":"cku6or92b0051p0dj0wbt2s07","tag_id":"cku6or90p001op0dj89y1asbz","_id":"cku6or92c0054p0dj9rvu7tqx"},{"post_id":"cku6or927004vp0dj7g4agy6h","tag_id":"cku6or929004xp0dj8lvq4vv8","_id":"cku6or92d0057p0dj8e5q0bl4"},{"post_id":"cku6or92b0053p0djb63rajmr","tag_id":"cku6or915002kp0dj1gpjdyov","_id":"cku6or92e0059p0dj50mz26rw"},{"post_id":"cku6or92b0053p0djb63rajmr","tag_id":"cku6or917002op0djc9b0eb5z","_id":"cku6or92f005bp0dj6ertchc7"},{"post_id":"cku6or92c0055p0dj1yf8g9qt","tag_id":"cku6or915002kp0dj1gpjdyov","_id":"cku6or92f005dp0dj03jb0ncn"},{"post_id":"cku6or92c0055p0dj1yf8g9qt","tag_id":"cku6or917002op0djc9b0eb5z","_id":"cku6or92g005gp0dj7xjiame7"},{"post_id":"cku6or92d0058p0dj4xjrgm8c","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or92g005ip0dj7u2sdu66"},{"post_id":"cku6or92e005ap0dj2ilw4i3o","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or92g005kp0dje90g3mwv"},{"post_id":"cku6or92f005cp0djhk3sdj9s","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or92g005mp0djbhx0573o"},{"post_id":"cku6or92f005ep0dj6a0kbjgt","tag_id":"cku6or91u0048p0djhdocgmck","_id":"cku6or92h005np0djfcdnbgrm"}],"Tag":[{"name":"object detection","_id":"cku6or9000004p0dj6xjdcv2u"},{"name":"GAN","_id":"cku6or9040009p0dja2yadzzr"},{"name":"DIP","_id":"cku6or906000ep0djclpu6u7s"},{"name":"CV","_id":"cku6or90g0012p0dj9vi83kt7"},{"name":"cmake","_id":"cku6or90l001ep0djbhmj1z1q"},{"name":"c++","_id":"cku6or90p001op0dj89y1asbz"},{"name":"C++","_id":"cku6or90r001sp0dj321f7nl8"},{"name":"CNN, Deep Learning","_id":"cku6or90w0024p0dj7dedbnrq"},{"name":"Deep Learning, CNN","_id":"cku6or9110028p0dj0siz3qfb"},{"name":"Deep Learning","_id":"cku6or912002cp0dj6ghfdjcc"},{"name":"math","_id":"cku6or915002kp0dj1gpjdyov"},{"name":"DP","_id":"cku6or917002op0djc9b0eb5z"},{"name":"image classification","_id":"cku6or91g0031p0dj8wb62mom"},{"name":"img cls","_id":"cku6or91i0036p0dj3nmf2y5p"},{"name":"machine learning","_id":"cku6or91j003ap0dj035vag4q"},{"name":"Object Detection","_id":"cku6or91t0042p0dj246z7unj"},{"name":"cmake, C++","_id":"cku6or91t0044p0dj42bgcx10"},{"name":"DL","_id":"cku6or91u0046p0dj74k4hnvm"},{"name":"PyTorch","_id":"cku6or91u0048p0djhdocgmck"},{"name":"tool","_id":"cku6or926004tp0dj2mo63q4p"},{"name":"cmake, c++","_id":"cku6or929004xp0dj8lvq4vv8"}]}}