{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/mango/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/mango/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/mango/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/mango/.gitignore","hash":"ea2b285a29690f1eabbad0f3a158e34e9ccd1d86","modified":1560342241897},{"_id":"themes/mango/Gruntfile.js","hash":"412e30530784993c8997aa8b1319c669b83b91c2","modified":1560342241897},{"_id":"themes/mango/LICENSE","hash":"2a7ea9f99cb166c845228c23b01bc2c1959728bb","modified":1560342241897},{"_id":"themes/mango/README.md","hash":"71717f8b799925fe739a1a83f7b827444b84ffab","modified":1560342241897},{"_id":"themes/mango/_config.yml","hash":"2757c3358caf4126be02b8cc8f18e55cb5affd48","modified":1560342241898},{"_id":"themes/mango/package.json","hash":"6e567a9654e61eb3f548c75edef380c2e135c433","modified":1560342241911},{"_id":"source/_posts/PyTorch-1.md","hash":"51009514017cff1f7042707d42160e2d159301e1","modified":1560387734341},{"_id":"source/_posts/Hexo-Sync.md","hash":"55bec04cf31fecb8a57c6b302317d288e03dd1a3","modified":1560394960852},{"_id":"source/_posts/PyTorch-2.md","hash":"623d3381892106379c8b6f444cda70aa992e8bc4","modified":1560397193449},{"_id":"themes/mango/languages/de.yml","hash":"d45cea36c5c83d7d09afcd1c26fff4a4c513c25b","modified":1560342241898},{"_id":"themes/mango/languages/es.yml","hash":"e3b4937da4cd2d0393b8a0ba310e70fc605cc431","modified":1560342241898},{"_id":"themes/mango/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1560342241898},{"_id":"themes/mango/languages/fr.yml","hash":"8cb0fe4b6913b4d5b662cdd0108a923c90025f85","modified":1560342241899},{"_id":"themes/mango/languages/ja.yml","hash":"3e2fedca096678c0c234ebffa4637828979296fa","modified":1560342241899},{"_id":"themes/mango/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1560342241900},{"_id":"themes/mango/languages/ko.yml","hash":"11330316e3c1262474a2b496e40dbc29f93fe01b","modified":1560342241899},{"_id":"themes/mango/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1560342241900},{"_id":"themes/mango/languages/pt.yml","hash":"ae2c61b30e638f74f1a42c9ce39ac08d063b30f5","modified":1560342241900},{"_id":"themes/mango/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1560342241900},{"_id":"themes/mango/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1560342241901},{"_id":"themes/mango/languages/zh-TW.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1560342241901},{"_id":"themes/mango/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1560342241909},{"_id":"themes/mango/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1560342241909},{"_id":"themes/mango/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1560342241909},{"_id":"themes/mango/layout/layout.ejs","hash":"a3e257fa82710d2bd217e9a3a820fd111acd84dd","modified":1560342241909},{"_id":"themes/mango/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1560342241910},{"_id":"themes/mango/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1560342241910},{"_id":"themes/mango/layout/tag.ejs","hash":"085718871e835fa4e278ab88e57a0340e9e1c6df","modified":1560342241911},{"_id":"themes/mango/scripts/fancybox.js","hash":"4c130fc242cf9b59b5df6ca5eae3b14302311e8c","modified":1560342241911},{"_id":"themes/mango/layout/_partial/after-footer.ejs","hash":"5e3b70c028d518b8f765e29a5e2020e7ba6ed589","modified":1560342241902},{"_id":"themes/mango/layout/_partial/archive-post.ejs","hash":"5062c723721d8497eebad372f57092ade45041f4","modified":1560342241902},{"_id":"themes/mango/layout/_partial/archive-tag.ejs","hash":"863acd8b89a108e6ff34afe6fd05de84f6d40b67","modified":1560342241903},{"_id":"themes/mango/layout/_partial/archive.ejs","hash":"863acd8b89a108e6ff34afe6fd05de84f6d40b67","modified":1560342241903},{"_id":"themes/mango/layout/_partial/article-abstract.ejs","hash":"90cb15fd0952e1219c990702803953bbe01f7c15","modified":1560342241903},{"_id":"themes/mango/layout/_partial/article.ejs","hash":"6d0abbacb2a0a17cb8d25f6475f82c99a7f6c27f","modified":1560342241904},{"_id":"themes/mango/layout/_partial/footer.ejs","hash":"ef456388033981653cdc3adf26d6a66edd255cce","modified":1560342241904},{"_id":"themes/mango/layout/_partial/gauges-analytics.ejs","hash":"ace3000bd3e01d03041d5be24f7640b6c003a5b5","modified":1560342241904},{"_id":"themes/mango/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1560342241904},{"_id":"themes/mango/layout/_partial/head.ejs","hash":"43afc4219f2bdbdc1ae59eede51fadbf96204483","modified":1560342241905},{"_id":"themes/mango/layout/_partial/header.ejs","hash":"1af7a4416c61d8a5729dfcb70db32ae2d4d4b25a","modified":1560342241905},{"_id":"themes/mango/layout/_partial/mobile-nav.ejs","hash":"347cf1befd2ea637c24bd5901929d8e36e359e75","modified":1560342241905},{"_id":"themes/mango/layout/_partial/sidebar.ejs","hash":"c70869569749a8f48cce202fa57926c06b55fdab","modified":1560342241907},{"_id":"themes/mango/layout/_widget/archive.ejs","hash":"0fe1e52c291c9499bd05b966e0b9aac5be351c58","modified":1560342241907},{"_id":"themes/mango/layout/_widget/category.ejs","hash":"866790acc13fed44b7ef74c3e19c300a3d6180d8","modified":1560342241908},{"_id":"themes/mango/layout/_widget/recent_posts.ejs","hash":"16800f85ffb036d2644a26e02facd61acb3706e9","modified":1560342241908},{"_id":"themes/mango/layout/_widget/tag.ejs","hash":"6017c54a8c3c8ff8db491cfbea3100c139da75d6","modified":1560342241908},{"_id":"themes/mango/layout/_widget/tagcloud.ejs","hash":"7259c179aa0c41c02e467ad892292e90430aaabc","modified":1560342241908},{"_id":"themes/mango/source/css/_extend.styl","hash":"8ab1ad313bd6707d248c5ca1ee9a5eab8d815e42","modified":1560342241912},{"_id":"themes/mango/source/css/_variables.styl","hash":"c40bb41ebde4234613c13cdfb795614d682ba52e","modified":1560342241916},{"_id":"themes/mango/source/css/style.styl","hash":"d8644b944fd8f65d5d292d124568c8cef4d6d0d2","modified":1560342241920},{"_id":"themes/mango/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1560342241921},{"_id":"themes/mango/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1560342241921},{"_id":"themes/mango/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1560342241921},{"_id":"themes/mango/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1560342241922},{"_id":"themes/mango/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1560342241922},{"_id":"themes/mango/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1560342241923},{"_id":"themes/mango/source/fancybox/jquery.fancybox.css","hash":"2e54d51d21e68ebc4bb870f6e57d3bfb660d4f9c","modified":1560342241925},{"_id":"themes/mango/source/fancybox/jquery.fancybox.js","hash":"58193c802f307ec9bc9e586c0e8a13ebef45d2f8","modified":1560342241926},{"_id":"themes/mango/source/fancybox/jquery.fancybox.pack.js","hash":"2da892a02778236b64076e5e8802ef0566e1d9e8","modified":1560342241926},{"_id":"themes/mango/source/js/script.js","hash":"c0d368681c687258b628bacc84cc30d353de6d47","modified":1560342241927},{"_id":"themes/mango/layout/_partial/post/category.ejs","hash":"16128d2422645e18d1b6882d4c4df17d895bd76e","modified":1560342241906},{"_id":"themes/mango/layout/_partial/post/date.ejs","hash":"947f513f7a85fbcf085624e46dc2ae6de8185eec","modified":1560342241906},{"_id":"themes/mango/layout/_partial/post/gallery.ejs","hash":"b0bf3f5d923c261ca2b5fabab513f1ec2708c8ca","modified":1560342241906},{"_id":"themes/mango/layout/_partial/post/nav.ejs","hash":"c87942501fbdb1a862dea3cb9967cbe3015d4a40","modified":1560342241906},{"_id":"themes/mango/layout/_partial/post/tag.ejs","hash":"694b5101bcc44c9f9c1cc62e5ad2fdfb4b7c7a07","modified":1560342241907},{"_id":"themes/mango/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1560342241907},{"_id":"themes/mango/source/css/_partial/archive.styl","hash":"9391a15b27b99f58ec1bdacfb8fad99b05188dcc","modified":1560342241912},{"_id":"themes/mango/source/css/_partial/article.styl","hash":"052b18448f47c54863d4c6d0f09a3f8090cf915e","modified":1560342241912},{"_id":"themes/mango/source/css/_partial/comment.styl","hash":"2834870661e490775f9154d71638bfdc72e640a6","modified":1560342241912},{"_id":"themes/mango/source/css/_partial/footer.styl","hash":"17cecbeb75e73a2f1e9769836b76a8c661bd9148","modified":1560342241913},{"_id":"themes/mango/source/css/_partial/header.styl","hash":"b9a211848e8c25bbbaeeebf34e426cc05e957ccc","modified":1560342241913},{"_id":"themes/mango/source/css/_partial/highlight.styl","hash":"ac19f1621305ca9f6a7b74acd211a4c0d88690bd","modified":1560342241913},{"_id":"themes/mango/source/css/_partial/mobile.styl","hash":"e607ce49f0a5baefbcd337989ef2506bea0347cc","modified":1560342241914},{"_id":"themes/mango/source/css/_partial/sidebar-bottom.styl","hash":"4132e25ba9680c4b911a01abc75f501cda3fa4f1","modified":1560342241914},{"_id":"themes/mango/source/css/_partial/sidebar-aside.styl","hash":"1fb15f13ba70d5b954f62920c6b63d26e2fb2985","modified":1560342241914},{"_id":"themes/mango/source/css/_partial/sidebar.styl","hash":"8d971a00e644a600179b04815688d188f094012e","modified":1560342241915},{"_id":"themes/mango/source/css/_util/grid.styl","hash":"1aa883ab432d9e4139c89dcbd40ae2bd1528d029","modified":1560342241915},{"_id":"themes/mango/source/css/_util/mixin.styl","hash":"429bad87fc156eacf226c5e35b0eafc277f2504b","modified":1560342241915},{"_id":"themes/mango/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1560342241917},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1560342241917},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1560342241920},{"_id":"themes/mango/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1560342241923},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1560342241923},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"4c9c395d705d22af7da06870d18f434e2a2eeaf9","modified":1560342241924},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-media.js","hash":"e14c32cc6823b81b2f758512f13ed8eb9ef2b454","modified":1560342241924},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"83cdfea43632b613771691a11f56f99d85fb6dbd","modified":1560342241925},{"_id":"themes/mango/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1560342241924},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1560342241920},{"_id":"themes/mango/source/css/fonts/fontawesome-webfont.svg","hash":"a275426daefd3716c53561fad121d258a7f05b47","modified":1560342241918},{"_id":"public/2019/06/13/Hexo-Sync/index.html","hash":"c1d9af8eca300f20ef78bd515b7a741d5a793857","modified":1560397254169},{"_id":"public/categories/DL-Framework/index.html","hash":"57666dd3288e8cebf75b40c81b270baa9a1cdc96","modified":1560397254169},{"_id":"public/archives/2019/index.html","hash":"aa2ba83369e060eaa6673b4de71c1c52d97eb58e","modified":1560397254192},{"_id":"public/archives/index.html","hash":"1052d3e4289bfc1ec632118f0dde71f41d8fb71e","modified":1560397254192},{"_id":"public/archives/2019/06/index.html","hash":"5f2d4bd362cf3c69ba695fdf72ab86a6abfdc17a","modified":1560397254193},{"_id":"public/tags/tool/index.html","hash":"ba50f2a4d236a72bc06f95b72f688f50511ecde0","modified":1560397254193},{"_id":"public/tags/PyTorch/index.html","hash":"ac74d0589fe6951a74c04c2087c326fac0357757","modified":1560397254193},{"_id":"public/2019/06/12/PyTorch-1/index.html","hash":"c720a60afcca3fb77005c2b3aff5dbcf3664a920","modified":1560397254193},{"_id":"public/index.html","hash":"b5aceca6bfe007952918bd7584bd1db2df153165","modified":1560397254193},{"_id":"public/2019/06/13/PyTorch-2/index.html","hash":"625b93aafcbe54ce636f3c52293027966f1dc0b1","modified":1560397254196},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1560397254198},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1560397254198},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1560397254198},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1560397254198},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1560397254198},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1560397254198},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1560397254198},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1560397254199},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1560397255007},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1560397255008},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1560397255008},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1560397255011},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1560397255011},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1560397255011},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1560397255011},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1560397255011},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1560397255011},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1560397255011},{"_id":"public/css/style.css","hash":"6164dece1e8b4610451ca5f091d7b653233f61cf","modified":1560397255011},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1560397255022},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"a275426daefd3716c53561fad121d258a7f05b47","modified":1560397255022},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1560397255029}],"Category":[{"name":"DL Framework","_id":"cjwu48im600047wvc6o8bg3kc"}],"Data":[],"Page":[],"Post":[{"title":"Hexo Sync","date":"2019-06-13T01:57:11.000Z","_content":"\n场景：\n```\n在A, B两台电脑上同步Hexo博客\n```\n假设在 computer B 上已经初次建立hexo博客 https://shajian.github.io， computer B 本地的文件夹（hexo部署环境目录）为 path/to/myblog，其内部文件/目录如下：\n```\n_config.yml\ndb.json\nnode_modules\npackage.json\npackage-lock.json\npublic\nscaffolds\nsource\nthemes\n```\n在github仓库 shajian.github.io 上新建branch，比如\"hexo\"，这样，\"mater\"主分支用于维护hexo生成的静态博客文件/目录，\"hexo\"分支用于维护hexo部署环境下的所有文件/目录。\n\n在 computer A 上 clone 这个仓库，并切换到 hexo 分支，\n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n$ git branch\n* hexo\n  master\n```\n将目录 shajian.github.io 内的所有文件/目录全部删除，然后将 path/to/myblog内的全部内容复制过来，\n```\n$ rm -rf .\n# do not use \"cp -R path/to/myblog/* ./\" which ignores hidden files/directories\n$ cp -R path/to/myblog/. ./\n```\n然后可在使用\n```\nhexo new \"<title>\"\n```\n写新文章或直接去source/_posts下修改已有文章，\n部署\n```\nhexo g -d\n```\n然后提交到仓库的hexo分支，进行备份\n```\n$ git add .\n$ git commit -m \"new post 'title'\"\n$ git push origin hexo\n```\n\n然后就可以去 https://shajian.github.io 浏览本地新增/修改文章内容了。\n\n在 computer B 上删除 path/to/myblog 目录，然后重新 clone 仓库，并切换到 hexo 分支，\n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n```\n如果仓库有 .gitignore 文件且包含 node_modules 目录，则执行\n```\n$ npm install\n```\n此时，要修改还是新增文章，步骤均与上面 computer A上的操作一致。\n\ncomputer A 和 B 本地均有仓库后，以后每次修改还是新增文章，首先需要将仓库更新到最新\n```\n$ git checkout master\n$ git pull origin master\n$ git checkout hexo\n$ git pull origin hexo\n```\n切换到 hexo 分支后，可以进行修改和新增文章了。\n\n由于 .depoly_git 下其实就是对应 master 主分支的内容，这也是一个git 仓库目录，内含 .git 文件夹，所以提交的时候无法提交 .deploy_git 内部的文件/目录，不过这个没关系，例如前面，在 computer B 上 clone 仓库后，执行\n```\nhexo g -d\n```\n由 hexo 向 .deploy_git 填充生成的文件/目录，而不需要在 hexo 分支上备份这些内容。","source":"_posts/Hexo-Sync.md","raw":"---\ntitle: Hexo Sync\ndate: 2019-06-13 9:57:11\ntag: tool\n---\n\n场景：\n```\n在A, B两台电脑上同步Hexo博客\n```\n假设在 computer B 上已经初次建立hexo博客 https://shajian.github.io， computer B 本地的文件夹（hexo部署环境目录）为 path/to/myblog，其内部文件/目录如下：\n```\n_config.yml\ndb.json\nnode_modules\npackage.json\npackage-lock.json\npublic\nscaffolds\nsource\nthemes\n```\n在github仓库 shajian.github.io 上新建branch，比如\"hexo\"，这样，\"mater\"主分支用于维护hexo生成的静态博客文件/目录，\"hexo\"分支用于维护hexo部署环境下的所有文件/目录。\n\n在 computer A 上 clone 这个仓库，并切换到 hexo 分支，\n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n$ git branch\n* hexo\n  master\n```\n将目录 shajian.github.io 内的所有文件/目录全部删除，然后将 path/to/myblog内的全部内容复制过来，\n```\n$ rm -rf .\n# do not use \"cp -R path/to/myblog/* ./\" which ignores hidden files/directories\n$ cp -R path/to/myblog/. ./\n```\n然后可在使用\n```\nhexo new \"<title>\"\n```\n写新文章或直接去source/_posts下修改已有文章，\n部署\n```\nhexo g -d\n```\n然后提交到仓库的hexo分支，进行备份\n```\n$ git add .\n$ git commit -m \"new post 'title'\"\n$ git push origin hexo\n```\n\n然后就可以去 https://shajian.github.io 浏览本地新增/修改文章内容了。\n\n在 computer B 上删除 path/to/myblog 目录，然后重新 clone 仓库，并切换到 hexo 分支，\n```\n$ git clone https://github/shajian/shajian.github.io.git\n$ cd shajian.github.io\n$ git checkout hexo\n```\n如果仓库有 .gitignore 文件且包含 node_modules 目录，则执行\n```\n$ npm install\n```\n此时，要修改还是新增文章，步骤均与上面 computer A上的操作一致。\n\ncomputer A 和 B 本地均有仓库后，以后每次修改还是新增文章，首先需要将仓库更新到最新\n```\n$ git checkout master\n$ git pull origin master\n$ git checkout hexo\n$ git pull origin hexo\n```\n切换到 hexo 分支后，可以进行修改和新增文章了。\n\n由于 .depoly_git 下其实就是对应 master 主分支的内容，这也是一个git 仓库目录，内含 .git 文件夹，所以提交的时候无法提交 .deploy_git 内部的文件/目录，不过这个没关系，例如前面，在 computer B 上 clone 仓库后，执行\n```\nhexo g -d\n```\n由 hexo 向 .deploy_git 填充生成的文件/目录，而不需要在 hexo 分支上备份这些内容。","slug":"Hexo-Sync","published":1,"updated":"2019-06-13T03:02:40.852Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjwu48ila00007wvclssm6cxn","content":"<p>场景：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在A, B两台电脑上同步Hexo博客</span><br></pre></td></tr></table></figure>\n\n<p>假设在 computer B 上已经初次建立hexo博客 <a href=\"https://shajian.github.io，\" target=\"_blank\" rel=\"noopener\">https://shajian.github.io，</a> computer B 本地的文件夹（hexo部署环境目录）为 path/to/myblog，其内部文件/目录如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_config.yml</span><br><span class=\"line\">db.json</span><br><span class=\"line\">node_modules</span><br><span class=\"line\">package.json</span><br><span class=\"line\">package-lock.json</span><br><span class=\"line\">public</span><br><span class=\"line\">scaffolds</span><br><span class=\"line\">source</span><br><span class=\"line\">themes</span><br></pre></td></tr></table></figure>\n\n<p>在github仓库 shajian.github.io 上新建branch，比如”hexo”，这样，”mater”主分支用于维护hexo生成的静态博客文件/目录，”hexo”分支用于维护hexo部署环境下的所有文件/目录。</p>\n<p>在 computer A 上 clone 这个仓库，并切换到 hexo 分支，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git branch</span><br><span class=\"line\">* hexo</span><br><span class=\"line\">  master</span><br></pre></td></tr></table></figure>\n\n<p>将目录 shajian.github.io 内的所有文件/目录全部删除，然后将 path/to/myblog内的全部内容复制过来，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf .</span><br><span class=\"line\"># do not use &quot;cp -R path/to/myblog/* ./&quot; which ignores hidden files/directories</span><br><span class=\"line\">$ cp -R path/to/myblog/. ./</span><br></pre></td></tr></table></figure>\n\n<p>然后可在使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new &quot;&lt;title&gt;&quot;</span><br></pre></td></tr></table></figure>\n\n<p>写新文章或直接去source/_posts下修改已有文章，<br>部署</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure>\n\n<p>然后提交到仓库的hexo分支，进行备份</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git add .</span><br><span class=\"line\">$ git commit -m &quot;new post &apos;title&apos;&quot;</span><br><span class=\"line\">$ git push origin hexo</span><br></pre></td></tr></table></figure>\n\n<p>然后就可以去 <a href=\"https://shajian.github.io\" target=\"_blank\" rel=\"noopener\">https://shajian.github.io</a> 浏览本地新增/修改文章内容了。</p>\n<p>在 computer B 上删除 path/to/myblog 目录，然后重新 clone 仓库，并切换到 hexo 分支，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br></pre></td></tr></table></figure>\n\n<p>如果仓库有 .gitignore 文件且包含 node_modules 目录，则执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install</span><br></pre></td></tr></table></figure>\n\n<p>此时，要修改还是新增文章，步骤均与上面 computer A上的操作一致。</p>\n<p>computer A 和 B 本地均有仓库后，以后每次修改还是新增文章，首先需要将仓库更新到最新</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">$ git pull origin master</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git pull origin hexo</span><br></pre></td></tr></table></figure>\n\n<p>切换到 hexo 分支后，可以进行修改和新增文章了。</p>\n<p>由于 .depoly_git 下其实就是对应 master 主分支的内容，这也是一个git 仓库目录，内含 .git 文件夹，所以提交的时候无法提交 .deploy_git 内部的文件/目录，不过这个没关系，例如前面，在 computer B 上 clone 仓库后，执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure>\n\n<p>由 hexo 向 .deploy_git 填充生成的文件/目录，而不需要在 hexo 分支上备份这些内容。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>场景：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在A, B两台电脑上同步Hexo博客</span><br></pre></td></tr></table></figure>\n\n<p>假设在 computer B 上已经初次建立hexo博客 <a href=\"https://shajian.github.io，\" target=\"_blank\" rel=\"noopener\">https://shajian.github.io，</a> computer B 本地的文件夹（hexo部署环境目录）为 path/to/myblog，其内部文件/目录如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_config.yml</span><br><span class=\"line\">db.json</span><br><span class=\"line\">node_modules</span><br><span class=\"line\">package.json</span><br><span class=\"line\">package-lock.json</span><br><span class=\"line\">public</span><br><span class=\"line\">scaffolds</span><br><span class=\"line\">source</span><br><span class=\"line\">themes</span><br></pre></td></tr></table></figure>\n\n<p>在github仓库 shajian.github.io 上新建branch，比如”hexo”，这样，”mater”主分支用于维护hexo生成的静态博客文件/目录，”hexo”分支用于维护hexo部署环境下的所有文件/目录。</p>\n<p>在 computer A 上 clone 这个仓库，并切换到 hexo 分支，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git branch</span><br><span class=\"line\">* hexo</span><br><span class=\"line\">  master</span><br></pre></td></tr></table></figure>\n\n<p>将目录 shajian.github.io 内的所有文件/目录全部删除，然后将 path/to/myblog内的全部内容复制过来，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -rf .</span><br><span class=\"line\"># do not use &quot;cp -R path/to/myblog/* ./&quot; which ignores hidden files/directories</span><br><span class=\"line\">$ cp -R path/to/myblog/. ./</span><br></pre></td></tr></table></figure>\n\n<p>然后可在使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new &quot;&lt;title&gt;&quot;</span><br></pre></td></tr></table></figure>\n\n<p>写新文章或直接去source/_posts下修改已有文章，<br>部署</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure>\n\n<p>然后提交到仓库的hexo分支，进行备份</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git add .</span><br><span class=\"line\">$ git commit -m &quot;new post &apos;title&apos;&quot;</span><br><span class=\"line\">$ git push origin hexo</span><br></pre></td></tr></table></figure>\n\n<p>然后就可以去 <a href=\"https://shajian.github.io\" target=\"_blank\" rel=\"noopener\">https://shajian.github.io</a> 浏览本地新增/修改文章内容了。</p>\n<p>在 computer B 上删除 path/to/myblog 目录，然后重新 clone 仓库，并切换到 hexo 分支，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github/shajian/shajian.github.io.git</span><br><span class=\"line\">$ cd shajian.github.io</span><br><span class=\"line\">$ git checkout hexo</span><br></pre></td></tr></table></figure>\n\n<p>如果仓库有 .gitignore 文件且包含 node_modules 目录，则执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install</span><br></pre></td></tr></table></figure>\n\n<p>此时，要修改还是新增文章，步骤均与上面 computer A上的操作一致。</p>\n<p>computer A 和 B 本地均有仓库后，以后每次修改还是新增文章，首先需要将仓库更新到最新</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git checkout master</span><br><span class=\"line\">$ git pull origin master</span><br><span class=\"line\">$ git checkout hexo</span><br><span class=\"line\">$ git pull origin hexo</span><br></pre></td></tr></table></figure>\n\n<p>切换到 hexo 分支后，可以进行修改和新增文章了。</p>\n<p>由于 .depoly_git 下其实就是对应 master 主分支的内容，这也是一个git 仓库目录，内含 .git 文件夹，所以提交的时候无法提交 .deploy_git 内部的文件/目录，不过这个没关系，例如前面，在 computer B 上 clone 仓库后，执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g -d</span><br></pre></td></tr></table></figure>\n\n<p>由 hexo 向 .deploy_git 填充生成的文件/目录，而不需要在 hexo 分支上备份这些内容。</p>\n"},{"title":"PyTorch_1","date":"2019-06-12T11:17:11.000Z","_content":"# 安装\n一直以来就对深度学习的框架源码有着浓厚兴趣，但是由于涉及到的领域较多，C++，python，CUDA，数学等，加上时间也比较零碎，就耽搁至今，后来意识到我不可能等完全弄明白之后再来写博客记录，毕竟能力不足，所以还是边看源码边记录，不求完全搞明白，但求能从整体上有个大致的理解，如果还能整明白一些数学计算上的代码实现，那就再好不过了。\n\n当前最流行的深度学习框架就是tensorflow和pytorch了，但是tensorflow据说代码工业化程度非常高，我等菜鸡先避其锋芒，来分析pytorch，希望能给自己带来点信心。\n\n下载源码\n```\ngit clone --recursive https://github.com/pytorch/pytorch\n```\n\n由于使用了子模块所以增加--recursive选项，记pytorch的root dir为$ROOT_DIR。\n\n根据安装步骤进行自上而下的阅读。Linux下安装使用命令\n```\ncd pytorch\npython setup.py install\n```\npytorch底层计算使用C++实现，并提供了python调用接口，所以这一命令就是使用setuptools安装python包，安装依赖库及修改配置项这里均跳过，故直接看$ROOT_DIR/setup.py中的setup()方法，但是在这个方法之前先执行了build_deps()用于生成有关 caffe2 的依赖库\n\n### build_deps()\n这个方法内部关键的一步为\n```\nbuild_caffe2(...)\n```\n查看这个方法的定义，发现build_caffe2做了如下几件事：\n1. run_cmake。执行cmake，这个命令的选项这里省略不展开，注意执行cmake这个命令的工作目录为$ROOD_DIR/build， cmake的Source Tree为$ROOD_DIR，这个 目录下存在top level的CMakeLists.txt\n2. 在$ROOT_DIR/build下编译并安装，使用make install或者 ninja install（cmake生成的Makefile中install这个target包含了build这个步骤）\n3. 将build/caffe2/proto下的所有.py文件 拷贝到caffe2/proto/下，这些.py文件是根据caffe2/proto/下的.proto文件生成\n\n这其中最复杂的部分就是run_cmake了，先是使用cmake的-D option设置一些cmake的变量，然后对source tree应用cmake， 查看top level的CMakeLists.txt，这个文件看着好像特别庞大，实际上做的事情也就那么几种：1)设置变量，根据不同操作系统设置或修改变量；2)设置include dir以及lib dir；3）加载.cmake文件以使用其中自定义的cmake函数；4）设置C++文件编译选项；5）安装配置文件/目录到指定位置等；我们注意比较关键的语句如下：\n```\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\nadd_subdirectory(modules)\n```\n这表明将c10,caffe2,modules等目录添加进build tree，这些目录下必定也有相应的CMakeLists.txt， 所以需要继续查看这些CMakeLists.txt中定义了哪些生成规则。\n\n另外，top level 中CMakeLists.txt中有这么一行\n```\ninclude(cmake/Dependencies.cmake)\n```\n这个Dependencies.cmake指明安装Caffe2所依赖的各种库，其中一些库位于本项目中如$ROOT_DIR/third_party或$ROOT_DIR/caffe2，还有一些库则是需要预先手动安装的，举个例子：\n1. 非本项目的公共库，比如添加BLAS库依赖，假设最开始设置了环境变量BLAS=OpenBLAS（环境变量的设置可参考setup.py文件头部注释）, 那么选择添加OpenBLAS库依赖，在Dependencies.cmake中代码为\n```\n...\nelseif(BLAS STREQUAL \"OpenBLAS\")\n  find_package(OpenBLAS REQUIRED)\n  include_directories(SYSTEM ${OpenBLAS_INCLUDE_DIR})\n  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS ${OpenBLAS_LIB})\n```\n这个find_package告诉我们去查看$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake，好的我们跳过去看一下这个.cmake文件，发现其定义了OpenBLAS的头文件和库文件的搜索路径，然后根据这些搜索路径分别搜索头文件cblas.h所在目录以及库名openblas， 分别使用变量OpenBLAS_INCLUDE_DIR和OpenBLAS_LIB保存，从上面的代码片段，我们知道搜索到的库名被添加到Caffe2_PUBLIC_DEPENDENCY_LIBS中，而我们再跳至$ROOT_DIR/caffe2/CMakeLists.txt发现其中有\n```\ntarget_link_libraries(caffe2 PUBLIC ${Caffe2_PUBLIC_DEPENDENCY_LIBS})\n```\n这就相当于能生成-lopenblas这样的链接选项。\n\n我们直接再看另一个库caffe2_pybind11_state的生成，因为下文会提到它，查看$ROOT_DIR/caffe2/CMakeLists.txt发现\n```\nadd_subdirectory(python)\n...\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\ninstall(TARGETS caffe2_pybind11_state DESTINATION \"${PYTHON_LIB_REL_PATH}/caffe2/python\")\n```\n其中Caffe2_CPU_PYTHON_SRCS在$ROOT_DIR/caffe2/python/CMakeLists.txt中设置， 类似地，还根据是否使用CUDA或者ROCM , 生成caffe2_pybind11_state_gpu或caffe2_pybind11_state_hip。生成这些库文件后，直接install到python的site-packages目录下的caffe2/python目录中\n\n以上就是build_dep()这个方法介绍，接着看$ROOT_DIR/setup.py中的setup方法。\n\n### setup()\nsetup方法（可以参考[setup()](https://docs.python.org/3/distutils/apiref.html)），其中几个值得说明的参数：\n1. ext_modules 有5个扩展库分别如下：\n- torch._C 指定了C++源文件，链接库，编译选项，链接选项和头文件/库dir\n- torch._dl 非WINDOWS平台下才有，指定了C源文件\n- caffe2.python.caffe2_pybind11_state\n- caffe2.python.caffe2_pybind11_state_gpu\n- caffe2.python.caffe2_pybind11_state_hip\n\n后三个库在上一步中其实已经生成好了，其中caffe2.python前缀表示两级目录（package），可以在$ROOT_DIR/build/caffe2/python目录下查看。扩展模块ext_modules在build_ext这个动作中生成。\n\n2. cmdclass，重写了build_ext, clean, install这几个action，这个action用在python setup.py <action> 命令中。install动作跟默认一致。 clean是清除编译过程中产生的临时文件，这些临时文件的pattern在.gitignore中给定。我们重点看一下build_ext这个动作对应的类build_ext，其中方法包含\n\n- create_compile_commands这是一个自定义方法，用于将compile_commands.json中的gcc编译器改为g++，修改原因代码注释写的很清楚，使用gcc编译s时不会include c++的头文件目录。 文件compile_commands.json是根据$ROOT_DIR/CMakeLists.txt中的set(CMAKE_EXPORT_COMPILE_COMMAND ON)这句代码而生成，所以位于$ROOT_DIR/build目录下，这个json文件中指明了编译各个文件时的工作路径（working directory），编译指令（command）以及被编译的原文件，格式如下\n```\n[\n{\n  \"directory\":\"<path/to/root>build/third_party/protobuf/cmake\",\n  \"command\": \"/usr/bin/c++ ... -I<path/to/root>/third_party/protobuf/src ... \n                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...\",\n  \"file\": \"<path/to/root>/third_party/protobuf/src/google/protobuf/arena.cc\"\n},\n...\n]\n```\n其中每个{...}块表示编译一个源文件到目标文件 .o。 将文件中gcc改为g++后重新保存为$ROOT_DIR/compile_commands.json。\n- run打印各library（比如 CUDA, CUDNN, NUMPY等）的使用情况，然后执行基类同名方法的逻辑\n- build_extensions 生成由ext_modules指定的python扩展库所用的方法\n\next_modules中添加了5个扩展，后三个扩展在build_deps()中已经生成并安装，当然，caffe2_pybind11_state_gpu和caffe2_pybind11_state_hip是根据配置决定是否生成，配置了CUDA则生成前者，配置了ROCM则生成后者，如果均未配置，则这两个扩展均不生成。既然在build_deps()中已经生成并安装，所以这里将其从ext_modules中删除，于是build_extensions实际上只生成torch._C, torch._dl这两个扩展库。\n\n然而，除了build_deps()方法还有其他方法可用于生成ext_modules中 的后三个扩展库，生成路径为$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/，所以需要判断在这个路径下是否存在后三个扩展库，若不在（此时就是前面所说的使用build_deps()生成），则将扩展库名称从ext_modules中予以删除， 若存在，则还需则将其拷贝到生成目录$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/下，并修改拷贝后的文件名称，以caffe2.python.caffe2_pybind11_state为例说明，两级前缀表示目录所以最终的目录为$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/，剩余的caffe2_pybind11_state表示扩展库的文件名，还需要添加后缀名，这个后缀名由系统平台和python版本，我这里是.cpython-37m-x86_64-linux-gnu.so，于是拷贝后得到文件$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so ，这样使用基类的build_extensions()方法才能将其进一步安装到 python的site-packages目录下，我这里是.../miniconda3/lib/python3.7/site-packages/caffe2/python/目录。\n\n3. packages 指定安装到python 的site-packages下的包\n```\npackages = find_packages(exclude=['tools', 'tools.*'])\n```\n\n由于PyTorch项目中除tools之外，只有caffe2和torch两个目录包含__init__.py，所以将caffe2和torch两个包安装到site-packages下。\n\n现在再回头看看ext_modules中指定的5个扩展，不难得知，其中torch._C, torch._dl这两个扩展安装到site-packages/torch下，扩展包名称分别为_C, _dl（省略了文件ext后缀），而另外三个caffe2有关的扩展则根据名称（.号切分，前面都是目录名，最后一个是文件名）知道其安装在site-packages/caffe2/python下。\n\n### 整理\n\n以上就是pytorch安装过程，主要分为两部分:\n\n1. 使用CMake生成c++库，对应build_deps()这个方法执行\n2. 使用python的setup方法生成扩展库，主要是build_ext。\n\n根据上面两点，重新整理一遍。\n```\ntop-level的CMakeLists.txt中\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\n```\n于是先看caffe2这个目录下的CMakeLists.txt， 寻找其中的关键语句，\n```\nadd_library(caffe2_proto STATIC $<TARGET_OBJECTS:Caffe2_PROTO>\nadd_library(thnvrtc SHARED ${TORCH_SRC_DIR}/csrc/jit/fuser/cuda/thnvrtc.cpp>\nadd_library(caffe2 ${Caffe2_CPU_SRCS})\nif (TORCH_STATIC)\n  add_library(torch STATIC ${DUMMY_EMPTY_FILE})\nelse()\n  add_library(torch SHARED ${DUMMY_EMPTY_FILE})\nendif()\ntorch_cuda_based_add_library(caffe2_gpu ${Caffe2_GPU_SRCS})\nhip_add_library(caffe2_hip ${Caffe2_HIP_SRCS})\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_gpu MODULE ${Caffe2_GPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_hip MODULE ${Caffe2_HIP_PYTHON_SRCS})\n```\n安装目录则寻找对应的install语句。此外，文件中还有一句\n```\nadd_subdirectory(../torch torch)\n```\n（实际上caffe2目录下CMakeLists.txt中存在很多add_subdirectory，但是都是类似的处理过程，所以不一一说明，仅以torch这个目录进行说明）\n\n于是查看torch目录下的CMakeLists.txt， 其中生成的库为\n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\n然后根据其中的\n```\nset(LIBSHM libshm)\nset(LIBSHM_SRCDIR ${TORCH_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\n继续查看torch/lib/libshm下的CMakeLists.txt，其中生成的库为\n```\nADD_LIBRARY(shm SHARED core.cpp)\n```\n有关的库依赖，分为预装库和本项目（pytorch）内包含的库，CMake生成规则位于cmake/Dependencies.cmake文件中，仔细查看该文件发现：\n- 预先装的库依赖，这些库名存在Caffe2_PUBLIC_DEPENDENCY_LIBS中。如上文所举例子OpenBLAS 那样添加g++的链接flag和 -I<include dir>flag。\n- 本项目内包含的库。包括：\n(1) tbb\n```\nadd_subdirectory(${CMAKE_SOURCE_DIR}/aten/src/ATen/cpu/tbb)    # 添加tbb库\n```\n(2) qnnpack\n```\n# 添加 qnnpack 库\n# source directory为${PROJECT_SOURCE_DIR}/third_party/QNNPACK\n# output directory为${PROJECT_BINARY_DIR}/confu-deps/QNNPACK\nadd_subdirectory(\"${QNNPACK_SOURCE_DIR}\" \"${CONFU_DEPENDENCIES_BINARY_DIR}/QNNPACK\")\nlist(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)\n```\n最后一行指引CMake去QNNPACK的目录（位于third_party下）去生成qnnpack库，然后回到Dependencies.cmake中添加到Caffe2_DEPENDENCY_LIBS中。\n(3) nnpack\n```\n# 添加 nnpack\ninclude(${CMAKE_CURRENT_LIST_DIR}/External/nnpack.cmake)\n```\n跳至nnpack.cmake文件，发现其中包含\n```\nadd_subdirectory(${NNPACK_SOURCE_DIR} ${CONFU_DEPENDENCIES_BINARY_DIR}/NNPACK)\n```\n找到包含NNPACK的代码目录位于third_party下，显然这个NNPACK也应该包含CMakeLists.txt文件指示CMake 生成nnpack库，然后回到Dependencies.cmake中将nnpack添加到Caffe2_DEPENDENCY_LIBS。\n\n(4) 类似地，还添加了 cpuinfo，gflag，glog::glog，googletest，fbgemm，fp16等。这些也不一定全部使用，是否使用还得看相应配置\n\n(5) LMDB。使用如下语句\n```\nfind_package(LMDB)\n```\n所以去cmake/Modules目录下寻找FindLMDB.cmake， 在这个.cmake文件中寻找lmdb库以及lmdb.h头文件（linux中已经安装，分别位于/usr/lib/x86_64-linux-gnu和/usr/include）, 将库名称和头文件目录分别保存于变量LMDB_LIBRARIES和LMDB_INCLUDE_DIR，然后回到Dependencies.cmake，照例执行\n```\ninclude_directories(SYSTEM ${LMDB_INCLUDE_DIR})\nlist(APPEND Caffe2_DEPENDENCY_LIBS ${LMDB_LIBRARIES})\n```\n类似的，还可以添加OPENCL，LEVELDB，NUMA，ZMQ，REDIS，OPENCV，FFMPEG，Python，MPI等。\n\n(6) pybind11。在Dependencies.cmake添加pybind11依赖，\n```\nfind_package(pybind11 CONFIG)# 配置模式下寻找，然而没有${pybind11_DIR}，也没有pybind11Config.cmake\nif(NOT pybind11_FOUND)\n  find_package(pybind11)     # 继续module模式下寻找\nendif()\n```\n虽然存在cmake/Modules/Findpybind11.cmake，然而其中find_path并没有找到pybind11/pybind11.h这个头文件，因为我没有预先安装pybind11，CMake自然是找不到的，于是在Dependencies.cmake中直接添加\n```\ninclude_directories(SYSTEM ${CMAKE_CURRENT_LIST_DIR}/../third_party/pybind11/include)\n\n```\n(7) OPENMP\n```\nFIND_PACKAGE(OpenMP QUIET)\n```\n如果找到OpenMP，那么${OpenMP_CXX_FLAGS} 和 ${OpenMP_CXX_LIBRARIES}分别存储头文件搜索路径和库文件链接flag，生成caffe2时可以用到OpenMP，用法是在caffe2/CMakeLists.txt中，\n```\ntarget_compile_options(caffe2 INTERFACE ${OpenMP_CXX_FLAGS})\ntarget_link_libraries(caffe2 PRIVATE ${OpenMP_CXX_LIBRARIES})\n```\n(8) CUDA。在Dependencies.cmake中有\n```\ninclude(${CMAKE_CURRENT_LIST_DIR}/public/cuda.cmake)\n```\n在这个cuda.cmake中，使用 find_library寻找cuda相关的库，找到后作为IMPORTED target进行库的添加，\n```\nadd_library(caffe2::cuda UNKNOWN IMPORTED)\n```\n其他cuda有关的库类似的进行添加，包括caffe2::cudart，caffe2::cudnn，caffe2::curand，caffe2::cufft，caffe2::tensorrt， caffe2::cublas，caffe2::nvrtc，当然这些库不一定全部添加，根据配置决定添加哪些库，然后回到Dependencies.cmake中，\n```\nlist(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)\n```\n保存到Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS，将来在caffe2/CMakeLists.txt用于链接。\n\n(9) 其他的依赖库如NCCL，CUB，GLOO等与上述某一点说明类似，不再一一罗列。\n\nDependencies.cmake中有很多库是作为生成caffe2库的依赖，比如QNNPACK，对这部分库添加到Caffe2_DEPENDENCY_LIBS（或Caffe2_PUBLIC_DEPENDENCY_LIBS，Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS），这个使用下面语句（位于caffe2/CMakeLists.txt）得到链接flag\n```\ntarget_link_libraries(caffe2 PRIVATE ${Caffe2_DEPENDENCY_LIBS})\n```\n2. 生成python的扩展库。首先后三个有关caffe2的扩展已经在上一步中生成并安装，所以对于剩下的两个扩展予以说明。\n\n- torch._C 链接的两个库为\n```\nmain_libraries=['shm', 'torch_python']\n```\n显然前面已经生成了这两个库。而使用的源文件则为\n```\nmain_sources=[\"torch/csrc/stub.cpp\"]\n```\n- torch._dl此扩展使用源文件torch/csrc/dl.c生成 。查看这个文件，发现就是添加了<dlfcn.h>中的三个常量到torch._dl库中，如下\n```\nRTLD_GLOBAL=0x100\nRTLD_NOW   =0x2\nRTLD_LAZY  =0x1\n```\n这三个常量指示动态加载（比如加载torch._C）的模式，用于dlopen()方法中，增加这三个常量是为了防止python 的os 模块中没有这些flag，并且也没有python的DLFCN模块，此时可以从torch._dl中得到这些flag。相当于把torch._dl当作备胎。\n\n### 还有...\n可能，大概了解清楚PyTorch的安装过程了，毕竟安装过程我也没试过（只试过较老版本的安装），没有看到最终生成的各种文件，仅供参考吧。","source":"_posts/PyTorch-1.md","raw":"---\ntitle: PyTorch_1\ndate: 2019-06-12 19:17:11\ntags: PyTorch\ncategory: DL Framework\n---\n# 安装\n一直以来就对深度学习的框架源码有着浓厚兴趣，但是由于涉及到的领域较多，C++，python，CUDA，数学等，加上时间也比较零碎，就耽搁至今，后来意识到我不可能等完全弄明白之后再来写博客记录，毕竟能力不足，所以还是边看源码边记录，不求完全搞明白，但求能从整体上有个大致的理解，如果还能整明白一些数学计算上的代码实现，那就再好不过了。\n\n当前最流行的深度学习框架就是tensorflow和pytorch了，但是tensorflow据说代码工业化程度非常高，我等菜鸡先避其锋芒，来分析pytorch，希望能给自己带来点信心。\n\n下载源码\n```\ngit clone --recursive https://github.com/pytorch/pytorch\n```\n\n由于使用了子模块所以增加--recursive选项，记pytorch的root dir为$ROOT_DIR。\n\n根据安装步骤进行自上而下的阅读。Linux下安装使用命令\n```\ncd pytorch\npython setup.py install\n```\npytorch底层计算使用C++实现，并提供了python调用接口，所以这一命令就是使用setuptools安装python包，安装依赖库及修改配置项这里均跳过，故直接看$ROOT_DIR/setup.py中的setup()方法，但是在这个方法之前先执行了build_deps()用于生成有关 caffe2 的依赖库\n\n### build_deps()\n这个方法内部关键的一步为\n```\nbuild_caffe2(...)\n```\n查看这个方法的定义，发现build_caffe2做了如下几件事：\n1. run_cmake。执行cmake，这个命令的选项这里省略不展开，注意执行cmake这个命令的工作目录为$ROOD_DIR/build， cmake的Source Tree为$ROOD_DIR，这个 目录下存在top level的CMakeLists.txt\n2. 在$ROOT_DIR/build下编译并安装，使用make install或者 ninja install（cmake生成的Makefile中install这个target包含了build这个步骤）\n3. 将build/caffe2/proto下的所有.py文件 拷贝到caffe2/proto/下，这些.py文件是根据caffe2/proto/下的.proto文件生成\n\n这其中最复杂的部分就是run_cmake了，先是使用cmake的-D option设置一些cmake的变量，然后对source tree应用cmake， 查看top level的CMakeLists.txt，这个文件看着好像特别庞大，实际上做的事情也就那么几种：1)设置变量，根据不同操作系统设置或修改变量；2)设置include dir以及lib dir；3）加载.cmake文件以使用其中自定义的cmake函数；4）设置C++文件编译选项；5）安装配置文件/目录到指定位置等；我们注意比较关键的语句如下：\n```\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\nadd_subdirectory(modules)\n```\n这表明将c10,caffe2,modules等目录添加进build tree，这些目录下必定也有相应的CMakeLists.txt， 所以需要继续查看这些CMakeLists.txt中定义了哪些生成规则。\n\n另外，top level 中CMakeLists.txt中有这么一行\n```\ninclude(cmake/Dependencies.cmake)\n```\n这个Dependencies.cmake指明安装Caffe2所依赖的各种库，其中一些库位于本项目中如$ROOT_DIR/third_party或$ROOT_DIR/caffe2，还有一些库则是需要预先手动安装的，举个例子：\n1. 非本项目的公共库，比如添加BLAS库依赖，假设最开始设置了环境变量BLAS=OpenBLAS（环境变量的设置可参考setup.py文件头部注释）, 那么选择添加OpenBLAS库依赖，在Dependencies.cmake中代码为\n```\n...\nelseif(BLAS STREQUAL \"OpenBLAS\")\n  find_package(OpenBLAS REQUIRED)\n  include_directories(SYSTEM ${OpenBLAS_INCLUDE_DIR})\n  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS ${OpenBLAS_LIB})\n```\n这个find_package告诉我们去查看$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake，好的我们跳过去看一下这个.cmake文件，发现其定义了OpenBLAS的头文件和库文件的搜索路径，然后根据这些搜索路径分别搜索头文件cblas.h所在目录以及库名openblas， 分别使用变量OpenBLAS_INCLUDE_DIR和OpenBLAS_LIB保存，从上面的代码片段，我们知道搜索到的库名被添加到Caffe2_PUBLIC_DEPENDENCY_LIBS中，而我们再跳至$ROOT_DIR/caffe2/CMakeLists.txt发现其中有\n```\ntarget_link_libraries(caffe2 PUBLIC ${Caffe2_PUBLIC_DEPENDENCY_LIBS})\n```\n这就相当于能生成-lopenblas这样的链接选项。\n\n我们直接再看另一个库caffe2_pybind11_state的生成，因为下文会提到它，查看$ROOT_DIR/caffe2/CMakeLists.txt发现\n```\nadd_subdirectory(python)\n...\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\ninstall(TARGETS caffe2_pybind11_state DESTINATION \"${PYTHON_LIB_REL_PATH}/caffe2/python\")\n```\n其中Caffe2_CPU_PYTHON_SRCS在$ROOT_DIR/caffe2/python/CMakeLists.txt中设置， 类似地，还根据是否使用CUDA或者ROCM , 生成caffe2_pybind11_state_gpu或caffe2_pybind11_state_hip。生成这些库文件后，直接install到python的site-packages目录下的caffe2/python目录中\n\n以上就是build_dep()这个方法介绍，接着看$ROOT_DIR/setup.py中的setup方法。\n\n### setup()\nsetup方法（可以参考[setup()](https://docs.python.org/3/distutils/apiref.html)），其中几个值得说明的参数：\n1. ext_modules 有5个扩展库分别如下：\n- torch._C 指定了C++源文件，链接库，编译选项，链接选项和头文件/库dir\n- torch._dl 非WINDOWS平台下才有，指定了C源文件\n- caffe2.python.caffe2_pybind11_state\n- caffe2.python.caffe2_pybind11_state_gpu\n- caffe2.python.caffe2_pybind11_state_hip\n\n后三个库在上一步中其实已经生成好了，其中caffe2.python前缀表示两级目录（package），可以在$ROOT_DIR/build/caffe2/python目录下查看。扩展模块ext_modules在build_ext这个动作中生成。\n\n2. cmdclass，重写了build_ext, clean, install这几个action，这个action用在python setup.py <action> 命令中。install动作跟默认一致。 clean是清除编译过程中产生的临时文件，这些临时文件的pattern在.gitignore中给定。我们重点看一下build_ext这个动作对应的类build_ext，其中方法包含\n\n- create_compile_commands这是一个自定义方法，用于将compile_commands.json中的gcc编译器改为g++，修改原因代码注释写的很清楚，使用gcc编译s时不会include c++的头文件目录。 文件compile_commands.json是根据$ROOT_DIR/CMakeLists.txt中的set(CMAKE_EXPORT_COMPILE_COMMAND ON)这句代码而生成，所以位于$ROOT_DIR/build目录下，这个json文件中指明了编译各个文件时的工作路径（working directory），编译指令（command）以及被编译的原文件，格式如下\n```\n[\n{\n  \"directory\":\"<path/to/root>build/third_party/protobuf/cmake\",\n  \"command\": \"/usr/bin/c++ ... -I<path/to/root>/third_party/protobuf/src ... \n                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...\",\n  \"file\": \"<path/to/root>/third_party/protobuf/src/google/protobuf/arena.cc\"\n},\n...\n]\n```\n其中每个{...}块表示编译一个源文件到目标文件 .o。 将文件中gcc改为g++后重新保存为$ROOT_DIR/compile_commands.json。\n- run打印各library（比如 CUDA, CUDNN, NUMPY等）的使用情况，然后执行基类同名方法的逻辑\n- build_extensions 生成由ext_modules指定的python扩展库所用的方法\n\next_modules中添加了5个扩展，后三个扩展在build_deps()中已经生成并安装，当然，caffe2_pybind11_state_gpu和caffe2_pybind11_state_hip是根据配置决定是否生成，配置了CUDA则生成前者，配置了ROCM则生成后者，如果均未配置，则这两个扩展均不生成。既然在build_deps()中已经生成并安装，所以这里将其从ext_modules中删除，于是build_extensions实际上只生成torch._C, torch._dl这两个扩展库。\n\n然而，除了build_deps()方法还有其他方法可用于生成ext_modules中 的后三个扩展库，生成路径为$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/，所以需要判断在这个路径下是否存在后三个扩展库，若不在（此时就是前面所说的使用build_deps()生成），则将扩展库名称从ext_modules中予以删除， 若存在，则还需则将其拷贝到生成目录$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/下，并修改拷贝后的文件名称，以caffe2.python.caffe2_pybind11_state为例说明，两级前缀表示目录所以最终的目录为$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/，剩余的caffe2_pybind11_state表示扩展库的文件名，还需要添加后缀名，这个后缀名由系统平台和python版本，我这里是.cpython-37m-x86_64-linux-gnu.so，于是拷贝后得到文件$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so ，这样使用基类的build_extensions()方法才能将其进一步安装到 python的site-packages目录下，我这里是.../miniconda3/lib/python3.7/site-packages/caffe2/python/目录。\n\n3. packages 指定安装到python 的site-packages下的包\n```\npackages = find_packages(exclude=['tools', 'tools.*'])\n```\n\n由于PyTorch项目中除tools之外，只有caffe2和torch两个目录包含__init__.py，所以将caffe2和torch两个包安装到site-packages下。\n\n现在再回头看看ext_modules中指定的5个扩展，不难得知，其中torch._C, torch._dl这两个扩展安装到site-packages/torch下，扩展包名称分别为_C, _dl（省略了文件ext后缀），而另外三个caffe2有关的扩展则根据名称（.号切分，前面都是目录名，最后一个是文件名）知道其安装在site-packages/caffe2/python下。\n\n### 整理\n\n以上就是pytorch安装过程，主要分为两部分:\n\n1. 使用CMake生成c++库，对应build_deps()这个方法执行\n2. 使用python的setup方法生成扩展库，主要是build_ext。\n\n根据上面两点，重新整理一遍。\n```\ntop-level的CMakeLists.txt中\nadd_subdirectory(c10)\nadd_subdirectory(caffe2)\n```\n于是先看caffe2这个目录下的CMakeLists.txt， 寻找其中的关键语句，\n```\nadd_library(caffe2_proto STATIC $<TARGET_OBJECTS:Caffe2_PROTO>\nadd_library(thnvrtc SHARED ${TORCH_SRC_DIR}/csrc/jit/fuser/cuda/thnvrtc.cpp>\nadd_library(caffe2 ${Caffe2_CPU_SRCS})\nif (TORCH_STATIC)\n  add_library(torch STATIC ${DUMMY_EMPTY_FILE})\nelse()\n  add_library(torch SHARED ${DUMMY_EMPTY_FILE})\nendif()\ntorch_cuda_based_add_library(caffe2_gpu ${Caffe2_GPU_SRCS})\nhip_add_library(caffe2_hip ${Caffe2_HIP_SRCS})\nadd_library(caffe2_pybind11_state MODULE ${Caffe2_CPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_gpu MODULE ${Caffe2_GPU_PYTHON_SRCS})\nadd_library(caffe2_pybind11_state_hip MODULE ${Caffe2_HIP_PYTHON_SRCS})\n```\n安装目录则寻找对应的install语句。此外，文件中还有一句\n```\nadd_subdirectory(../torch torch)\n```\n（实际上caffe2目录下CMakeLists.txt中存在很多add_subdirectory，但是都是类似的处理过程，所以不一一说明，仅以torch这个目录进行说明）\n\n于是查看torch目录下的CMakeLists.txt， 其中生成的库为\n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\n然后根据其中的\n```\nset(LIBSHM libshm)\nset(LIBSHM_SRCDIR ${TORCH_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\n继续查看torch/lib/libshm下的CMakeLists.txt，其中生成的库为\n```\nADD_LIBRARY(shm SHARED core.cpp)\n```\n有关的库依赖，分为预装库和本项目（pytorch）内包含的库，CMake生成规则位于cmake/Dependencies.cmake文件中，仔细查看该文件发现：\n- 预先装的库依赖，这些库名存在Caffe2_PUBLIC_DEPENDENCY_LIBS中。如上文所举例子OpenBLAS 那样添加g++的链接flag和 -I<include dir>flag。\n- 本项目内包含的库。包括：\n(1) tbb\n```\nadd_subdirectory(${CMAKE_SOURCE_DIR}/aten/src/ATen/cpu/tbb)    # 添加tbb库\n```\n(2) qnnpack\n```\n# 添加 qnnpack 库\n# source directory为${PROJECT_SOURCE_DIR}/third_party/QNNPACK\n# output directory为${PROJECT_BINARY_DIR}/confu-deps/QNNPACK\nadd_subdirectory(\"${QNNPACK_SOURCE_DIR}\" \"${CONFU_DEPENDENCIES_BINARY_DIR}/QNNPACK\")\nlist(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)\n```\n最后一行指引CMake去QNNPACK的目录（位于third_party下）去生成qnnpack库，然后回到Dependencies.cmake中添加到Caffe2_DEPENDENCY_LIBS中。\n(3) nnpack\n```\n# 添加 nnpack\ninclude(${CMAKE_CURRENT_LIST_DIR}/External/nnpack.cmake)\n```\n跳至nnpack.cmake文件，发现其中包含\n```\nadd_subdirectory(${NNPACK_SOURCE_DIR} ${CONFU_DEPENDENCIES_BINARY_DIR}/NNPACK)\n```\n找到包含NNPACK的代码目录位于third_party下，显然这个NNPACK也应该包含CMakeLists.txt文件指示CMake 生成nnpack库，然后回到Dependencies.cmake中将nnpack添加到Caffe2_DEPENDENCY_LIBS。\n\n(4) 类似地，还添加了 cpuinfo，gflag，glog::glog，googletest，fbgemm，fp16等。这些也不一定全部使用，是否使用还得看相应配置\n\n(5) LMDB。使用如下语句\n```\nfind_package(LMDB)\n```\n所以去cmake/Modules目录下寻找FindLMDB.cmake， 在这个.cmake文件中寻找lmdb库以及lmdb.h头文件（linux中已经安装，分别位于/usr/lib/x86_64-linux-gnu和/usr/include）, 将库名称和头文件目录分别保存于变量LMDB_LIBRARIES和LMDB_INCLUDE_DIR，然后回到Dependencies.cmake，照例执行\n```\ninclude_directories(SYSTEM ${LMDB_INCLUDE_DIR})\nlist(APPEND Caffe2_DEPENDENCY_LIBS ${LMDB_LIBRARIES})\n```\n类似的，还可以添加OPENCL，LEVELDB，NUMA，ZMQ，REDIS，OPENCV，FFMPEG，Python，MPI等。\n\n(6) pybind11。在Dependencies.cmake添加pybind11依赖，\n```\nfind_package(pybind11 CONFIG)# 配置模式下寻找，然而没有${pybind11_DIR}，也没有pybind11Config.cmake\nif(NOT pybind11_FOUND)\n  find_package(pybind11)     # 继续module模式下寻找\nendif()\n```\n虽然存在cmake/Modules/Findpybind11.cmake，然而其中find_path并没有找到pybind11/pybind11.h这个头文件，因为我没有预先安装pybind11，CMake自然是找不到的，于是在Dependencies.cmake中直接添加\n```\ninclude_directories(SYSTEM ${CMAKE_CURRENT_LIST_DIR}/../third_party/pybind11/include)\n\n```\n(7) OPENMP\n```\nFIND_PACKAGE(OpenMP QUIET)\n```\n如果找到OpenMP，那么${OpenMP_CXX_FLAGS} 和 ${OpenMP_CXX_LIBRARIES}分别存储头文件搜索路径和库文件链接flag，生成caffe2时可以用到OpenMP，用法是在caffe2/CMakeLists.txt中，\n```\ntarget_compile_options(caffe2 INTERFACE ${OpenMP_CXX_FLAGS})\ntarget_link_libraries(caffe2 PRIVATE ${OpenMP_CXX_LIBRARIES})\n```\n(8) CUDA。在Dependencies.cmake中有\n```\ninclude(${CMAKE_CURRENT_LIST_DIR}/public/cuda.cmake)\n```\n在这个cuda.cmake中，使用 find_library寻找cuda相关的库，找到后作为IMPORTED target进行库的添加，\n```\nadd_library(caffe2::cuda UNKNOWN IMPORTED)\n```\n其他cuda有关的库类似的进行添加，包括caffe2::cudart，caffe2::cudnn，caffe2::curand，caffe2::cufft，caffe2::tensorrt， caffe2::cublas，caffe2::nvrtc，当然这些库不一定全部添加，根据配置决定添加哪些库，然后回到Dependencies.cmake中，\n```\nlist(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)\n```\n保存到Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS，将来在caffe2/CMakeLists.txt用于链接。\n\n(9) 其他的依赖库如NCCL，CUB，GLOO等与上述某一点说明类似，不再一一罗列。\n\nDependencies.cmake中有很多库是作为生成caffe2库的依赖，比如QNNPACK，对这部分库添加到Caffe2_DEPENDENCY_LIBS（或Caffe2_PUBLIC_DEPENDENCY_LIBS，Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS），这个使用下面语句（位于caffe2/CMakeLists.txt）得到链接flag\n```\ntarget_link_libraries(caffe2 PRIVATE ${Caffe2_DEPENDENCY_LIBS})\n```\n2. 生成python的扩展库。首先后三个有关caffe2的扩展已经在上一步中生成并安装，所以对于剩下的两个扩展予以说明。\n\n- torch._C 链接的两个库为\n```\nmain_libraries=['shm', 'torch_python']\n```\n显然前面已经生成了这两个库。而使用的源文件则为\n```\nmain_sources=[\"torch/csrc/stub.cpp\"]\n```\n- torch._dl此扩展使用源文件torch/csrc/dl.c生成 。查看这个文件，发现就是添加了<dlfcn.h>中的三个常量到torch._dl库中，如下\n```\nRTLD_GLOBAL=0x100\nRTLD_NOW   =0x2\nRTLD_LAZY  =0x1\n```\n这三个常量指示动态加载（比如加载torch._C）的模式，用于dlopen()方法中，增加这三个常量是为了防止python 的os 模块中没有这些flag，并且也没有python的DLFCN模块，此时可以从torch._dl中得到这些flag。相当于把torch._dl当作备胎。\n\n### 还有...\n可能，大概了解清楚PyTorch的安装过程了，毕竟安装过程我也没试过（只试过较老版本的安装），没有看到最终生成的各种文件，仅供参考吧。","slug":"PyTorch-1","published":1,"updated":"2019-06-13T01:02:14.341Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjwu48im400037wvcek39ab0p","content":"<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>一直以来就对深度学习的框架源码有着浓厚兴趣，但是由于涉及到的领域较多，C++，python，CUDA，数学等，加上时间也比较零碎，就耽搁至今，后来意识到我不可能等完全弄明白之后再来写博客记录，毕竟能力不足，所以还是边看源码边记录，不求完全搞明白，但求能从整体上有个大致的理解，如果还能整明白一些数学计算上的代码实现，那就再好不过了。</p>\n<p>当前最流行的深度学习框架就是tensorflow和pytorch了，但是tensorflow据说代码工业化程度非常高，我等菜鸡先避其锋芒，来分析pytorch，希望能给自己带来点信心。</p>\n<p>下载源码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --recursive https://github.com/pytorch/pytorch</span><br></pre></td></tr></table></figure>\n\n<p>由于使用了子模块所以增加–recursive选项，记pytorch的root dir为$ROOT_DIR。</p>\n<p>根据安装步骤进行自上而下的阅读。Linux下安装使用命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd pytorch</span><br><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure>\n\n<p>pytorch底层计算使用C++实现，并提供了python调用接口，所以这一命令就是使用setuptools安装python包，安装依赖库及修改配置项这里均跳过，故直接看$ROOT_DIR/setup.py中的setup()方法，但是在这个方法之前先执行了build_deps()用于生成有关 caffe2 的依赖库</p>\n<h3 id=\"build-deps\"><a href=\"#build-deps\" class=\"headerlink\" title=\"build_deps()\"></a>build_deps()</h3><p>这个方法内部关键的一步为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">build_caffe2(...)</span><br></pre></td></tr></table></figure>\n\n<p>查看这个方法的定义，发现build_caffe2做了如下几件事：</p>\n<ol>\n<li>run_cmake。执行cmake，这个命令的选项这里省略不展开，注意执行cmake这个命令的工作目录为$ROOD_DIR/build， cmake的Source Tree为$ROOD_DIR，这个 目录下存在top level的CMakeLists.txt</li>\n<li>在$ROOT_DIR/build下编译并安装，使用make install或者 ninja install（cmake生成的Makefile中install这个target包含了build这个步骤）</li>\n<li>将build/caffe2/proto下的所有.py文件 拷贝到caffe2/proto/下，这些.py文件是根据caffe2/proto/下的.proto文件生成</li>\n</ol>\n<p>这其中最复杂的部分就是run_cmake了，先是使用cmake的-D option设置一些cmake的变量，然后对source tree应用cmake， 查看top level的CMakeLists.txt，这个文件看着好像特别庞大，实际上做的事情也就那么几种：1)设置变量，根据不同操作系统设置或修改变量；2)设置include dir以及lib dir；3）加载.cmake文件以使用其中自定义的cmake函数；4）设置C++文件编译选项；5）安装配置文件/目录到指定位置等；我们注意比较关键的语句如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br><span class=\"line\">add_subdirectory(modules)</span><br></pre></td></tr></table></figure>\n\n<p>这表明将c10,caffe2,modules等目录添加进build tree，这些目录下必定也有相应的CMakeLists.txt， 所以需要继续查看这些CMakeLists.txt中定义了哪些生成规则。</p>\n<p>另外，top level 中CMakeLists.txt中有这么一行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include(cmake/Dependencies.cmake)</span><br></pre></td></tr></table></figure>\n\n<p>这个Dependencies.cmake指明安装Caffe2所依赖的各种库，其中一些库位于本项目中如$ROOT_DIR/third_party或$ROOT_DIR/caffe2，还有一些库则是需要预先手动安装的，举个例子：</p>\n<ol>\n<li>非本项目的公共库，比如添加BLAS库依赖，假设最开始设置了环境变量BLAS=OpenBLAS（环境变量的设置可参考setup.py文件头部注释）, 那么选择添加OpenBLAS库依赖，在Dependencies.cmake中代码为<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">elseif(BLAS STREQUAL &quot;OpenBLAS&quot;)</span><br><span class=\"line\">  find_package(OpenBLAS REQUIRED)</span><br><span class=\"line\">  include_directories(SYSTEM $&#123;OpenBLAS_INCLUDE_DIR&#125;)</span><br><span class=\"line\">  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS $&#123;OpenBLAS_LIB&#125;)</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>这个find_package告诉我们去查看$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake，好的我们跳过去看一下这个.cmake文件，发现其定义了OpenBLAS的头文件和库文件的搜索路径，然后根据这些搜索路径分别搜索头文件cblas.h所在目录以及库名openblas， 分别使用变量OpenBLAS_INCLUDE_DIR和OpenBLAS_LIB保存，从上面的代码片段，我们知道搜索到的库名被添加到Caffe2_PUBLIC_DEPENDENCY_LIBS中，而我们再跳至$ROOT_DIR/caffe2/CMakeLists.txt发现其中有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PUBLIC $&#123;Caffe2_PUBLIC_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>这就相当于能生成-lopenblas这样的链接选项。</p>\n<p>我们直接再看另一个库caffe2_pybind11_state的生成，因为下文会提到它，查看$ROOT_DIR/caffe2/CMakeLists.txt发现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(python)</span><br><span class=\"line\">...</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">install(TARGETS caffe2_pybind11_state DESTINATION &quot;$&#123;PYTHON_LIB_REL_PATH&#125;/caffe2/python&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>其中Caffe2_CPU_PYTHON_SRCS在$ROOT_DIR/caffe2/python/CMakeLists.txt中设置， 类似地，还根据是否使用CUDA或者ROCM , 生成caffe2_pybind11_state_gpu或caffe2_pybind11_state_hip。生成这些库文件后，直接install到python的site-packages目录下的caffe2/python目录中</p>\n<p>以上就是build_dep()这个方法介绍，接着看$ROOT_DIR/setup.py中的setup方法。</p>\n<h3 id=\"setup\"><a href=\"#setup\" class=\"headerlink\" title=\"setup()\"></a>setup()</h3><p>setup方法（可以参考<a href=\"https://docs.python.org/3/distutils/apiref.html\" target=\"_blank\" rel=\"noopener\">setup()</a>），其中几个值得说明的参数：</p>\n<ol>\n<li>ext_modules 有5个扩展库分别如下：</li>\n</ol>\n<ul>\n<li>torch._C 指定了C++源文件，链接库，编译选项，链接选项和头文件/库dir</li>\n<li>torch._dl 非WINDOWS平台下才有，指定了C源文件</li>\n<li>caffe2.python.caffe2_pybind11_state</li>\n<li>caffe2.python.caffe2_pybind11_state_gpu</li>\n<li>caffe2.python.caffe2_pybind11_state_hip</li>\n</ul>\n<p>后三个库在上一步中其实已经生成好了，其中caffe2.python前缀表示两级目录（package），可以在$ROOT_DIR/build/caffe2/python目录下查看。扩展模块ext_modules在build_ext这个动作中生成。</p>\n<ol start=\"2\">\n<li>cmdclass，重写了build_ext, clean, install这几个action，这个action用在python setup.py <action> 命令中。install动作跟默认一致。 clean是清除编译过程中产生的临时文件，这些临时文件的pattern在.gitignore中给定。我们重点看一下build_ext这个动作对应的类build_ext，其中方法包含</action></li>\n</ol>\n<ul>\n<li>create_compile_commands这是一个自定义方法，用于将compile_commands.json中的gcc编译器改为g++，修改原因代码注释写的很清楚，使用gcc编译s时不会include c++的头文件目录。 文件compile_commands.json是根据$ROOT_DIR/CMakeLists.txt中的set(CMAKE_EXPORT_COMPILE_COMMAND ON)这句代码而生成，所以位于$ROOT_DIR/build目录下，这个json文件中指明了编译各个文件时的工作路径（working directory），编译指令（command）以及被编译的原文件，格式如下<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;directory&quot;:&quot;&lt;path/to/root&gt;build/third_party/protobuf/cmake&quot;,</span><br><span class=\"line\">  &quot;command&quot;: &quot;/usr/bin/c++ ... -I&lt;path/to/root&gt;/third_party/protobuf/src ... </span><br><span class=\"line\">                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...&quot;,</span><br><span class=\"line\">  &quot;file&quot;: &quot;&lt;path/to/root&gt;/third_party/protobuf/src/google/protobuf/arena.cc&quot;</span><br><span class=\"line\">&#125;,</span><br><span class=\"line\">...</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>其中每个{…}块表示编译一个源文件到目标文件 .o。 将文件中gcc改为g++后重新保存为$ROOT_DIR/compile_commands.json。</p>\n<ul>\n<li>run打印各library（比如 CUDA, CUDNN, NUMPY等）的使用情况，然后执行基类同名方法的逻辑</li>\n<li>build_extensions 生成由ext_modules指定的python扩展库所用的方法</li>\n</ul>\n<p>ext_modules中添加了5个扩展，后三个扩展在build_deps()中已经生成并安装，当然，caffe2_pybind11_state_gpu和caffe2_pybind11_state_hip是根据配置决定是否生成，配置了CUDA则生成前者，配置了ROCM则生成后者，如果均未配置，则这两个扩展均不生成。既然在build_deps()中已经生成并安装，所以这里将其从ext_modules中删除，于是build_extensions实际上只生成torch._C, torch._dl这两个扩展库。</p>\n<p>然而，除了build_deps()方法还有其他方法可用于生成ext_modules中 的后三个扩展库，生成路径为$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/，所以需要判断在这个路径下是否存在后三个扩展库，若不在（此时就是前面所说的使用build_deps()生成），则将扩展库名称从ext_modules中予以删除， 若存在，则还需则将其拷贝到生成目录$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/下，并修改拷贝后的文件名称，以caffe2.python.caffe2_pybind11_state为例说明，两级前缀表示目录所以最终的目录为$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/，剩余的caffe2_pybind11_state表示扩展库的文件名，还需要添加后缀名，这个后缀名由系统平台和python版本，我这里是.cpython-37m-x86_64-linux-gnu.so，于是拷贝后得到文件$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so ，这样使用基类的build_extensions()方法才能将其进一步安装到 python的site-packages目录下，我这里是…/miniconda3/lib/python3.7/site-packages/caffe2/python/目录。</p>\n<ol start=\"3\">\n<li>packages 指定安装到python 的site-packages下的包<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">packages = find_packages(exclude=[&apos;tools&apos;, &apos;tools.*&apos;])</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>由于PyTorch项目中除tools之外，只有caffe2和torch两个目录包含<strong>init</strong>.py，所以将caffe2和torch两个包安装到site-packages下。</p>\n<p>现在再回头看看ext_modules中指定的5个扩展，不难得知，其中torch._C, torch._dl这两个扩展安装到site-packages/torch下，扩展包名称分别为_C, _dl（省略了文件ext后缀），而另外三个caffe2有关的扩展则根据名称（.号切分，前面都是目录名，最后一个是文件名）知道其安装在site-packages/caffe2/python下。</p>\n<h3 id=\"整理\"><a href=\"#整理\" class=\"headerlink\" title=\"整理\"></a>整理</h3><p>以上就是pytorch安装过程，主要分为两部分:</p>\n<ol>\n<li>使用CMake生成c++库，对应build_deps()这个方法执行</li>\n<li>使用python的setup方法生成扩展库，主要是build_ext。</li>\n</ol>\n<p>根据上面两点，重新整理一遍。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top-level的CMakeLists.txt中</span><br><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br></pre></td></tr></table></figure>\n\n<p>于是先看caffe2这个目录下的CMakeLists.txt， 寻找其中的关键语句，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2_proto STATIC $&lt;TARGET_OBJECTS:Caffe2_PROTO&gt;</span><br><span class=\"line\">add_library(thnvrtc SHARED $&#123;TORCH_SRC_DIR&#125;/csrc/jit/fuser/cuda/thnvrtc.cpp&gt;</span><br><span class=\"line\">add_library(caffe2 $&#123;Caffe2_CPU_SRCS&#125;)</span><br><span class=\"line\">if (TORCH_STATIC)</span><br><span class=\"line\">  add_library(torch STATIC $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">else()</span><br><span class=\"line\">  add_library(torch SHARED $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">endif()</span><br><span class=\"line\">torch_cuda_based_add_library(caffe2_gpu $&#123;Caffe2_GPU_SRCS&#125;)</span><br><span class=\"line\">hip_add_library(caffe2_hip $&#123;Caffe2_HIP_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_gpu MODULE $&#123;Caffe2_GPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_hip MODULE $&#123;Caffe2_HIP_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>安装目录则寻找对应的install语句。此外，文件中还有一句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(../torch torch)</span><br></pre></td></tr></table></figure>\n\n<p>（实际上caffe2目录下CMakeLists.txt中存在很多add_subdirectory，但是都是类似的处理过程，所以不一一说明，仅以torch这个目录进行说明）</p>\n<p>于是查看torch目录下的CMakeLists.txt， 其中生成的库为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>然后根据其中的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;TORCH_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>继续查看torch/lib/libshm下的CMakeLists.txt，其中生成的库为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD_LIBRARY(shm SHARED core.cpp)</span><br></pre></td></tr></table></figure>\n\n<p>有关的库依赖，分为预装库和本项目（pytorch）内包含的库，CMake生成规则位于cmake/Dependencies.cmake文件中，仔细查看该文件发现：</p>\n<ul>\n<li>预先装的库依赖，这些库名存在Caffe2_PUBLIC_DEPENDENCY_LIBS中。如上文所举例子OpenBLAS 那样添加g++的链接flag和 -I<include dir>flag。</include></li>\n<li>本项目内包含的库。包括：<br>(1) tbb<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;/aten/src/ATen/cpu/tbb)    # 添加tbb库</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>(2) qnnpack</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加 qnnpack 库</span><br><span class=\"line\"># source directory为$&#123;PROJECT_SOURCE_DIR&#125;/third_party/QNNPACK</span><br><span class=\"line\"># output directory为$&#123;PROJECT_BINARY_DIR&#125;/confu-deps/QNNPACK</span><br><span class=\"line\">add_subdirectory(&quot;$&#123;QNNPACK_SOURCE_DIR&#125;&quot; &quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/QNNPACK&quot;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)</span><br></pre></td></tr></table></figure>\n\n<p>最后一行指引CMake去QNNPACK的目录（位于third_party下）去生成qnnpack库，然后回到Dependencies.cmake中添加到Caffe2_DEPENDENCY_LIBS中。<br>(3) nnpack</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加 nnpack</span><br><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/External/nnpack.cmake)</span><br></pre></td></tr></table></figure>\n\n<p>跳至nnpack.cmake文件，发现其中包含</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;NNPACK_SOURCE_DIR&#125; $&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/NNPACK)</span><br></pre></td></tr></table></figure>\n\n<p>找到包含NNPACK的代码目录位于third_party下，显然这个NNPACK也应该包含CMakeLists.txt文件指示CMake 生成nnpack库，然后回到Dependencies.cmake中将nnpack添加到Caffe2_DEPENDENCY_LIBS。</p>\n<p>(4) 类似地，还添加了 cpuinfo，gflag，glog::glog，googletest，fbgemm，fp16等。这些也不一定全部使用，是否使用还得看相应配置</p>\n<p>(5) LMDB。使用如下语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(LMDB)</span><br></pre></td></tr></table></figure>\n\n<p>所以去cmake/Modules目录下寻找FindLMDB.cmake， 在这个.cmake文件中寻找lmdb库以及lmdb.h头文件（linux中已经安装，分别位于/usr/lib/x86_64-linux-gnu和/usr/include）, 将库名称和头文件目录分别保存于变量LMDB_LIBRARIES和LMDB_INCLUDE_DIR，然后回到Dependencies.cmake，照例执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;LMDB_INCLUDE_DIR&#125;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS $&#123;LMDB_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>类似的，还可以添加OPENCL，LEVELDB，NUMA，ZMQ，REDIS，OPENCV，FFMPEG，Python，MPI等。</p>\n<p>(6) pybind11。在Dependencies.cmake添加pybind11依赖，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(pybind11 CONFIG)# 配置模式下寻找，然而没有$&#123;pybind11_DIR&#125;，也没有pybind11Config.cmake</span><br><span class=\"line\">if(NOT pybind11_FOUND)</span><br><span class=\"line\">  find_package(pybind11)     # 继续module模式下寻找</span><br><span class=\"line\">endif()</span><br></pre></td></tr></table></figure>\n\n<p>虽然存在cmake/Modules/Findpybind11.cmake，然而其中find_path并没有找到pybind11/pybind11.h这个头文件，因为我没有预先安装pybind11，CMake自然是找不到的，于是在Dependencies.cmake中直接添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../third_party/pybind11/include)</span><br></pre></td></tr></table></figure>\n\n<p>(7) OPENMP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FIND_PACKAGE(OpenMP QUIET)</span><br></pre></td></tr></table></figure>\n\n<p>如果找到OpenMP，那么${OpenMP_CXX_FLAGS} 和 ${OpenMP_CXX_LIBRARIES}分别存储头文件搜索路径和库文件链接flag，生成caffe2时可以用到OpenMP，用法是在caffe2/CMakeLists.txt中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_options(caffe2 INTERFACE $&#123;OpenMP_CXX_FLAGS&#125;)</span><br><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;OpenMP_CXX_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>(8) CUDA。在Dependencies.cmake中有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/public/cuda.cmake)</span><br></pre></td></tr></table></figure>\n\n<p>在这个cuda.cmake中，使用 find_library寻找cuda相关的库，找到后作为IMPORTED target进行库的添加，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2::cuda UNKNOWN IMPORTED)</span><br></pre></td></tr></table></figure>\n\n<p>其他cuda有关的库类似的进行添加，包括caffe2::cudart，caffe2::cudnn，caffe2::curand，caffe2::cufft，caffe2::tensorrt， caffe2::cublas，caffe2::nvrtc，当然这些库不一定全部添加，根据配置决定添加哪些库，然后回到Dependencies.cmake中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">list(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)</span><br></pre></td></tr></table></figure>\n\n<p>保存到Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS，将来在caffe2/CMakeLists.txt用于链接。</p>\n<p>(9) 其他的依赖库如NCCL，CUB，GLOO等与上述某一点说明类似，不再一一罗列。</p>\n<p>Dependencies.cmake中有很多库是作为生成caffe2库的依赖，比如QNNPACK，对这部分库添加到Caffe2_DEPENDENCY_LIBS（或Caffe2_PUBLIC_DEPENDENCY_LIBS，Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS），这个使用下面语句（位于caffe2/CMakeLists.txt）得到链接flag</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;Caffe2_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>生成python的扩展库。首先后三个有关caffe2的扩展已经在上一步中生成并安装，所以对于剩下的两个扩展予以说明。</li>\n</ol>\n<ul>\n<li>torch._C 链接的两个库为<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_libraries=[&apos;shm&apos;, &apos;torch_python&apos;]</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>显然前面已经生成了这两个库。而使用的源文件则为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_sources=[&quot;torch/csrc/stub.cpp&quot;]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>torch._dl此扩展使用源文件torch/csrc/dl.c生成 。查看这个文件，发现就是添加了&lt;dlfcn.h&gt;中的三个常量到torch._dl库中，如下<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RTLD_GLOBAL=0x100</span><br><span class=\"line\">RTLD_NOW   =0x2</span><br><span class=\"line\">RTLD_LAZY  =0x1</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>这三个常量指示动态加载（比如加载torch._C）的模式，用于dlopen()方法中，增加这三个常量是为了防止python 的os 模块中没有这些flag，并且也没有python的DLFCN模块，此时可以从torch._dl中得到这些flag。相当于把torch._dl当作备胎。</p>\n<h3 id=\"还有…\"><a href=\"#还有…\" class=\"headerlink\" title=\"还有…\"></a>还有…</h3><p>可能，大概了解清楚PyTorch的安装过程了，毕竟安装过程我也没试过（只试过较老版本的安装），没有看到最终生成的各种文件，仅供参考吧。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>一直以来就对深度学习的框架源码有着浓厚兴趣，但是由于涉及到的领域较多，C++，python，CUDA，数学等，加上时间也比较零碎，就耽搁至今，后来意识到我不可能等完全弄明白之后再来写博客记录，毕竟能力不足，所以还是边看源码边记录，不求完全搞明白，但求能从整体上有个大致的理解，如果还能整明白一些数学计算上的代码实现，那就再好不过了。</p>\n<p>当前最流行的深度学习框架就是tensorflow和pytorch了，但是tensorflow据说代码工业化程度非常高，我等菜鸡先避其锋芒，来分析pytorch，希望能给自己带来点信心。</p>\n<p>下载源码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone --recursive https://github.com/pytorch/pytorch</span><br></pre></td></tr></table></figure>\n\n<p>由于使用了子模块所以增加–recursive选项，记pytorch的root dir为$ROOT_DIR。</p>\n<p>根据安装步骤进行自上而下的阅读。Linux下安装使用命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd pytorch</span><br><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure>\n\n<p>pytorch底层计算使用C++实现，并提供了python调用接口，所以这一命令就是使用setuptools安装python包，安装依赖库及修改配置项这里均跳过，故直接看$ROOT_DIR/setup.py中的setup()方法，但是在这个方法之前先执行了build_deps()用于生成有关 caffe2 的依赖库</p>\n<h3 id=\"build-deps\"><a href=\"#build-deps\" class=\"headerlink\" title=\"build_deps()\"></a>build_deps()</h3><p>这个方法内部关键的一步为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">build_caffe2(...)</span><br></pre></td></tr></table></figure>\n\n<p>查看这个方法的定义，发现build_caffe2做了如下几件事：</p>\n<ol>\n<li>run_cmake。执行cmake，这个命令的选项这里省略不展开，注意执行cmake这个命令的工作目录为$ROOD_DIR/build， cmake的Source Tree为$ROOD_DIR，这个 目录下存在top level的CMakeLists.txt</li>\n<li>在$ROOT_DIR/build下编译并安装，使用make install或者 ninja install（cmake生成的Makefile中install这个target包含了build这个步骤）</li>\n<li>将build/caffe2/proto下的所有.py文件 拷贝到caffe2/proto/下，这些.py文件是根据caffe2/proto/下的.proto文件生成</li>\n</ol>\n<p>这其中最复杂的部分就是run_cmake了，先是使用cmake的-D option设置一些cmake的变量，然后对source tree应用cmake， 查看top level的CMakeLists.txt，这个文件看着好像特别庞大，实际上做的事情也就那么几种：1)设置变量，根据不同操作系统设置或修改变量；2)设置include dir以及lib dir；3）加载.cmake文件以使用其中自定义的cmake函数；4）设置C++文件编译选项；5）安装配置文件/目录到指定位置等；我们注意比较关键的语句如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br><span class=\"line\">add_subdirectory(modules)</span><br></pre></td></tr></table></figure>\n\n<p>这表明将c10,caffe2,modules等目录添加进build tree，这些目录下必定也有相应的CMakeLists.txt， 所以需要继续查看这些CMakeLists.txt中定义了哪些生成规则。</p>\n<p>另外，top level 中CMakeLists.txt中有这么一行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include(cmake/Dependencies.cmake)</span><br></pre></td></tr></table></figure>\n\n<p>这个Dependencies.cmake指明安装Caffe2所依赖的各种库，其中一些库位于本项目中如$ROOT_DIR/third_party或$ROOT_DIR/caffe2，还有一些库则是需要预先手动安装的，举个例子：</p>\n<ol>\n<li>非本项目的公共库，比如添加BLAS库依赖，假设最开始设置了环境变量BLAS=OpenBLAS（环境变量的设置可参考setup.py文件头部注释）, 那么选择添加OpenBLAS库依赖，在Dependencies.cmake中代码为<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">elseif(BLAS STREQUAL &quot;OpenBLAS&quot;)</span><br><span class=\"line\">  find_package(OpenBLAS REQUIRED)</span><br><span class=\"line\">  include_directories(SYSTEM $&#123;OpenBLAS_INCLUDE_DIR&#125;)</span><br><span class=\"line\">  list(APPEND Caffe2_PUBLIC_DEPENDENCY_LIBS $&#123;OpenBLAS_LIB&#125;)</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>这个find_package告诉我们去查看$ROOT_DIR/cmake/Modules/FindOpenBLAS.cmake，好的我们跳过去看一下这个.cmake文件，发现其定义了OpenBLAS的头文件和库文件的搜索路径，然后根据这些搜索路径分别搜索头文件cblas.h所在目录以及库名openblas， 分别使用变量OpenBLAS_INCLUDE_DIR和OpenBLAS_LIB保存，从上面的代码片段，我们知道搜索到的库名被添加到Caffe2_PUBLIC_DEPENDENCY_LIBS中，而我们再跳至$ROOT_DIR/caffe2/CMakeLists.txt发现其中有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PUBLIC $&#123;Caffe2_PUBLIC_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>这就相当于能生成-lopenblas这样的链接选项。</p>\n<p>我们直接再看另一个库caffe2_pybind11_state的生成，因为下文会提到它，查看$ROOT_DIR/caffe2/CMakeLists.txt发现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(python)</span><br><span class=\"line\">...</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">install(TARGETS caffe2_pybind11_state DESTINATION &quot;$&#123;PYTHON_LIB_REL_PATH&#125;/caffe2/python&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>其中Caffe2_CPU_PYTHON_SRCS在$ROOT_DIR/caffe2/python/CMakeLists.txt中设置， 类似地，还根据是否使用CUDA或者ROCM , 生成caffe2_pybind11_state_gpu或caffe2_pybind11_state_hip。生成这些库文件后，直接install到python的site-packages目录下的caffe2/python目录中</p>\n<p>以上就是build_dep()这个方法介绍，接着看$ROOT_DIR/setup.py中的setup方法。</p>\n<h3 id=\"setup\"><a href=\"#setup\" class=\"headerlink\" title=\"setup()\"></a>setup()</h3><p>setup方法（可以参考<a href=\"https://docs.python.org/3/distutils/apiref.html\" target=\"_blank\" rel=\"noopener\">setup()</a>），其中几个值得说明的参数：</p>\n<ol>\n<li>ext_modules 有5个扩展库分别如下：</li>\n</ol>\n<ul>\n<li>torch._C 指定了C++源文件，链接库，编译选项，链接选项和头文件/库dir</li>\n<li>torch._dl 非WINDOWS平台下才有，指定了C源文件</li>\n<li>caffe2.python.caffe2_pybind11_state</li>\n<li>caffe2.python.caffe2_pybind11_state_gpu</li>\n<li>caffe2.python.caffe2_pybind11_state_hip</li>\n</ul>\n<p>后三个库在上一步中其实已经生成好了，其中caffe2.python前缀表示两级目录（package），可以在$ROOT_DIR/build/caffe2/python目录下查看。扩展模块ext_modules在build_ext这个动作中生成。</p>\n<ol start=\"2\">\n<li>cmdclass，重写了build_ext, clean, install这几个action，这个action用在python setup.py <action> 命令中。install动作跟默认一致。 clean是清除编译过程中产生的临时文件，这些临时文件的pattern在.gitignore中给定。我们重点看一下build_ext这个动作对应的类build_ext，其中方法包含</action></li>\n</ol>\n<ul>\n<li>create_compile_commands这是一个自定义方法，用于将compile_commands.json中的gcc编译器改为g++，修改原因代码注释写的很清楚，使用gcc编译s时不会include c++的头文件目录。 文件compile_commands.json是根据$ROOT_DIR/CMakeLists.txt中的set(CMAKE_EXPORT_COMPILE_COMMAND ON)这句代码而生成，所以位于$ROOT_DIR/build目录下，这个json文件中指明了编译各个文件时的工作路径（working directory），编译指令（command）以及被编译的原文件，格式如下<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;directory&quot;:&quot;&lt;path/to/root&gt;build/third_party/protobuf/cmake&quot;,</span><br><span class=\"line\">  &quot;command&quot;: &quot;/usr/bin/c++ ... -I&lt;path/to/root&gt;/third_party/protobuf/src ... </span><br><span class=\"line\">                -o CMakeFiles/libprotobuf.dir/__/src/google/protobuf/arena.cc.o ...&quot;,</span><br><span class=\"line\">  &quot;file&quot;: &quot;&lt;path/to/root&gt;/third_party/protobuf/src/google/protobuf/arena.cc&quot;</span><br><span class=\"line\">&#125;,</span><br><span class=\"line\">...</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>其中每个{…}块表示编译一个源文件到目标文件 .o。 将文件中gcc改为g++后重新保存为$ROOT_DIR/compile_commands.json。</p>\n<ul>\n<li>run打印各library（比如 CUDA, CUDNN, NUMPY等）的使用情况，然后执行基类同名方法的逻辑</li>\n<li>build_extensions 生成由ext_modules指定的python扩展库所用的方法</li>\n</ul>\n<p>ext_modules中添加了5个扩展，后三个扩展在build_deps()中已经生成并安装，当然，caffe2_pybind11_state_gpu和caffe2_pybind11_state_hip是根据配置决定是否生成，配置了CUDA则生成前者，配置了ROCM则生成后者，如果均未配置，则这两个扩展均不生成。既然在build_deps()中已经生成并安装，所以这里将其从ext_modules中删除，于是build_extensions实际上只生成torch._C, torch._dl这两个扩展库。</p>\n<p>然而，除了build_deps()方法还有其他方法可用于生成ext_modules中 的后三个扩展库，生成路径为$ROOT_DIR/torch/lib/python3.7/site-packages/caffe2/python/，所以需要判断在这个路径下是否存在后三个扩展库，若不在（此时就是前面所说的使用build_deps()生成），则将扩展库名称从ext_modules中予以删除， 若存在，则还需则将其拷贝到生成目录$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/下，并修改拷贝后的文件名称，以caffe2.python.caffe2_pybind11_state为例说明，两级前缀表示目录所以最终的目录为$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/，剩余的caffe2_pybind11_state表示扩展库的文件名，还需要添加后缀名，这个后缀名由系统平台和python版本，我这里是.cpython-37m-x86_64-linux-gnu.so，于是拷贝后得到文件$ROOT_DIR/torch/build/lib.linux-x86_64-3.7/caffe2/python/caffe2_pybind11_state.cpython-37m-x86_64-linux-gnu.so ，这样使用基类的build_extensions()方法才能将其进一步安装到 python的site-packages目录下，我这里是…/miniconda3/lib/python3.7/site-packages/caffe2/python/目录。</p>\n<ol start=\"3\">\n<li>packages 指定安装到python 的site-packages下的包<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">packages = find_packages(exclude=[&apos;tools&apos;, &apos;tools.*&apos;])</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>由于PyTorch项目中除tools之外，只有caffe2和torch两个目录包含<strong>init</strong>.py，所以将caffe2和torch两个包安装到site-packages下。</p>\n<p>现在再回头看看ext_modules中指定的5个扩展，不难得知，其中torch._C, torch._dl这两个扩展安装到site-packages/torch下，扩展包名称分别为_C, _dl（省略了文件ext后缀），而另外三个caffe2有关的扩展则根据名称（.号切分，前面都是目录名，最后一个是文件名）知道其安装在site-packages/caffe2/python下。</p>\n<h3 id=\"整理\"><a href=\"#整理\" class=\"headerlink\" title=\"整理\"></a>整理</h3><p>以上就是pytorch安装过程，主要分为两部分:</p>\n<ol>\n<li>使用CMake生成c++库，对应build_deps()这个方法执行</li>\n<li>使用python的setup方法生成扩展库，主要是build_ext。</li>\n</ol>\n<p>根据上面两点，重新整理一遍。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top-level的CMakeLists.txt中</span><br><span class=\"line\">add_subdirectory(c10)</span><br><span class=\"line\">add_subdirectory(caffe2)</span><br></pre></td></tr></table></figure>\n\n<p>于是先看caffe2这个目录下的CMakeLists.txt， 寻找其中的关键语句，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2_proto STATIC $&lt;TARGET_OBJECTS:Caffe2_PROTO&gt;</span><br><span class=\"line\">add_library(thnvrtc SHARED $&#123;TORCH_SRC_DIR&#125;/csrc/jit/fuser/cuda/thnvrtc.cpp&gt;</span><br><span class=\"line\">add_library(caffe2 $&#123;Caffe2_CPU_SRCS&#125;)</span><br><span class=\"line\">if (TORCH_STATIC)</span><br><span class=\"line\">  add_library(torch STATIC $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">else()</span><br><span class=\"line\">  add_library(torch SHARED $&#123;DUMMY_EMPTY_FILE&#125;)</span><br><span class=\"line\">endif()</span><br><span class=\"line\">torch_cuda_based_add_library(caffe2_gpu $&#123;Caffe2_GPU_SRCS&#125;)</span><br><span class=\"line\">hip_add_library(caffe2_hip $&#123;Caffe2_HIP_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state MODULE $&#123;Caffe2_CPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_gpu MODULE $&#123;Caffe2_GPU_PYTHON_SRCS&#125;)</span><br><span class=\"line\">add_library(caffe2_pybind11_state_hip MODULE $&#123;Caffe2_HIP_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>安装目录则寻找对应的install语句。此外，文件中还有一句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory(../torch torch)</span><br></pre></td></tr></table></figure>\n\n<p>（实际上caffe2目录下CMakeLists.txt中存在很多add_subdirectory，但是都是类似的处理过程，所以不一一说明，仅以torch这个目录进行说明）</p>\n<p>于是查看torch目录下的CMakeLists.txt， 其中生成的库为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>然后根据其中的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;TORCH_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>继续查看torch/lib/libshm下的CMakeLists.txt，其中生成的库为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD_LIBRARY(shm SHARED core.cpp)</span><br></pre></td></tr></table></figure>\n\n<p>有关的库依赖，分为预装库和本项目（pytorch）内包含的库，CMake生成规则位于cmake/Dependencies.cmake文件中，仔细查看该文件发现：</p>\n<ul>\n<li>预先装的库依赖，这些库名存在Caffe2_PUBLIC_DEPENDENCY_LIBS中。如上文所举例子OpenBLAS 那样添加g++的链接flag和 -I<include dir>flag。</include></li>\n<li>本项目内包含的库。包括：<br>(1) tbb<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;CMAKE_SOURCE_DIR&#125;/aten/src/ATen/cpu/tbb)    # 添加tbb库</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>(2) qnnpack</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加 qnnpack 库</span><br><span class=\"line\"># source directory为$&#123;PROJECT_SOURCE_DIR&#125;/third_party/QNNPACK</span><br><span class=\"line\"># output directory为$&#123;PROJECT_BINARY_DIR&#125;/confu-deps/QNNPACK</span><br><span class=\"line\">add_subdirectory(&quot;$&#123;QNNPACK_SOURCE_DIR&#125;&quot; &quot;$&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/QNNPACK&quot;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS qnnpack)</span><br></pre></td></tr></table></figure>\n\n<p>最后一行指引CMake去QNNPACK的目录（位于third_party下）去生成qnnpack库，然后回到Dependencies.cmake中添加到Caffe2_DEPENDENCY_LIBS中。<br>(3) nnpack</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加 nnpack</span><br><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/External/nnpack.cmake)</span><br></pre></td></tr></table></figure>\n\n<p>跳至nnpack.cmake文件，发现其中包含</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_subdirectory($&#123;NNPACK_SOURCE_DIR&#125; $&#123;CONFU_DEPENDENCIES_BINARY_DIR&#125;/NNPACK)</span><br></pre></td></tr></table></figure>\n\n<p>找到包含NNPACK的代码目录位于third_party下，显然这个NNPACK也应该包含CMakeLists.txt文件指示CMake 生成nnpack库，然后回到Dependencies.cmake中将nnpack添加到Caffe2_DEPENDENCY_LIBS。</p>\n<p>(4) 类似地，还添加了 cpuinfo，gflag，glog::glog，googletest，fbgemm，fp16等。这些也不一定全部使用，是否使用还得看相应配置</p>\n<p>(5) LMDB。使用如下语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(LMDB)</span><br></pre></td></tr></table></figure>\n\n<p>所以去cmake/Modules目录下寻找FindLMDB.cmake， 在这个.cmake文件中寻找lmdb库以及lmdb.h头文件（linux中已经安装，分别位于/usr/lib/x86_64-linux-gnu和/usr/include）, 将库名称和头文件目录分别保存于变量LMDB_LIBRARIES和LMDB_INCLUDE_DIR，然后回到Dependencies.cmake，照例执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;LMDB_INCLUDE_DIR&#125;)</span><br><span class=\"line\">list(APPEND Caffe2_DEPENDENCY_LIBS $&#123;LMDB_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>类似的，还可以添加OPENCL，LEVELDB，NUMA，ZMQ，REDIS，OPENCV，FFMPEG，Python，MPI等。</p>\n<p>(6) pybind11。在Dependencies.cmake添加pybind11依赖，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find_package(pybind11 CONFIG)# 配置模式下寻找，然而没有$&#123;pybind11_DIR&#125;，也没有pybind11Config.cmake</span><br><span class=\"line\">if(NOT pybind11_FOUND)</span><br><span class=\"line\">  find_package(pybind11)     # 继续module模式下寻找</span><br><span class=\"line\">endif()</span><br></pre></td></tr></table></figure>\n\n<p>虽然存在cmake/Modules/Findpybind11.cmake，然而其中find_path并没有找到pybind11/pybind11.h这个头文件，因为我没有预先安装pybind11，CMake自然是找不到的，于是在Dependencies.cmake中直接添加</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include_directories(SYSTEM $&#123;CMAKE_CURRENT_LIST_DIR&#125;/../third_party/pybind11/include)</span><br></pre></td></tr></table></figure>\n\n<p>(7) OPENMP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FIND_PACKAGE(OpenMP QUIET)</span><br></pre></td></tr></table></figure>\n\n<p>如果找到OpenMP，那么${OpenMP_CXX_FLAGS} 和 ${OpenMP_CXX_LIBRARIES}分别存储头文件搜索路径和库文件链接flag，生成caffe2时可以用到OpenMP，用法是在caffe2/CMakeLists.txt中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_compile_options(caffe2 INTERFACE $&#123;OpenMP_CXX_FLAGS&#125;)</span><br><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;OpenMP_CXX_LIBRARIES&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>(8) CUDA。在Dependencies.cmake中有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">include($&#123;CMAKE_CURRENT_LIST_DIR&#125;/public/cuda.cmake)</span><br></pre></td></tr></table></figure>\n\n<p>在这个cuda.cmake中，使用 find_library寻找cuda相关的库，找到后作为IMPORTED target进行库的添加，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(caffe2::cuda UNKNOWN IMPORTED)</span><br></pre></td></tr></table></figure>\n\n<p>其他cuda有关的库类似的进行添加，包括caffe2::cudart，caffe2::cudnn，caffe2::curand，caffe2::cufft，caffe2::tensorrt， caffe2::cublas，caffe2::nvrtc，当然这些库不一定全部添加，根据配置决定添加哪些库，然后回到Dependencies.cmake中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">list(APPEND Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS caffe2::cuda caffe2::nvrtc)</span><br></pre></td></tr></table></figure>\n\n<p>保存到Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS，将来在caffe2/CMakeLists.txt用于链接。</p>\n<p>(9) 其他的依赖库如NCCL，CUB，GLOO等与上述某一点说明类似，不再一一罗列。</p>\n<p>Dependencies.cmake中有很多库是作为生成caffe2库的依赖，比如QNNPACK，对这部分库添加到Caffe2_DEPENDENCY_LIBS（或Caffe2_PUBLIC_DEPENDENCY_LIBS，Caffe2_PUBLIC_CUDA_DEPENDENCY_LIBS），这个使用下面语句（位于caffe2/CMakeLists.txt）得到链接flag</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">target_link_libraries(caffe2 PRIVATE $&#123;Caffe2_DEPENDENCY_LIBS&#125;)</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>生成python的扩展库。首先后三个有关caffe2的扩展已经在上一步中生成并安装，所以对于剩下的两个扩展予以说明。</li>\n</ol>\n<ul>\n<li>torch._C 链接的两个库为<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_libraries=[&apos;shm&apos;, &apos;torch_python&apos;]</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>显然前面已经生成了这两个库。而使用的源文件则为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main_sources=[&quot;torch/csrc/stub.cpp&quot;]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>torch._dl此扩展使用源文件torch/csrc/dl.c生成 。查看这个文件，发现就是添加了&lt;dlfcn.h&gt;中的三个常量到torch._dl库中，如下<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RTLD_GLOBAL=0x100</span><br><span class=\"line\">RTLD_NOW   =0x2</span><br><span class=\"line\">RTLD_LAZY  =0x1</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p>这三个常量指示动态加载（比如加载torch._C）的模式，用于dlopen()方法中，增加这三个常量是为了防止python 的os 模块中没有这些flag，并且也没有python的DLFCN模块，此时可以从torch._dl中得到这些flag。相当于把torch._dl当作备胎。</p>\n<h3 id=\"还有…\"><a href=\"#还有…\" class=\"headerlink\" title=\"还有…\"></a>还有…</h3><p>可能，大概了解清楚PyTorch的安装过程了，毕竟安装过程我也没试过（只试过较老版本的安装），没有看到最终生成的各种文件，仅供参考吧。</p>\n"},{"title":"PyTorch-2","date":"2019-06-13T02:19:52.000Z","_content":"# torch installization\n依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是\n```\nimport torch\n```\n于是阅读torch/__init__.py，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，\n```\nold_flags=sys.getdlopenflags()\nsys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)\nfrom torch._C import *\n__all__ += [name for name in dir(_C)\n            if name[0] != '_' and\n            not name.endswith('Base')]\nsys.setdlopenflags(old_flags)\n```\n<b>将torch._C中（不包括_开头和Base结尾）的属性导出到当前域。</b>\n\n__init__.py除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，\n```\nextern PyObject* initModule();\nPyMODINIT_FUNC PyInit__C()   // 在python脚本中，import _C 时调用\n{\n  return initModule();\n}\n```\n根据python3扩展库的规则可知，import torch._C ，调用PyInit__C函数（调用名为PyInit_<package>的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。\n\nshm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，\n```\nset(LIBSHM_SUBDIR libshm)\nset(LIBSHM_SRCDIR ${LIBSHM_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\n从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现\n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\nTORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。\n\ninitModule方法定义在torch/csrc/Module.cpp，\n```\n#ifdef USE_CUDA\nnamespace torch { namespace cuda {\nvoid initModule(PyObject* module);       // 模块中有关cuda部分的初始化函数声明\n}}\n#endif\n\nstatic std::vector<PyMethodDef> methods;\n\nPyObject* module;\nPyObject* initModule() {                 // 声明并定义模块初始化函数\n  // 向methods中添加方法定义\n  THPUtils_addPyMethodDefs(methods, TorchMethods);\n  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);\n  ...\n  // 真正的扩展模块定义\n  static struct PyModuleDef torchmodule = {\n    PyModuleDef_HEAD_INIT,\n    \"torch._C\",                          // 扩展模块名\n    nullptr,                           \n    -1,\n    methods.data()                       // 模块中的方法定义\n  };\n  ASSERT_TRUE(module = PyModule_Create(&torchmodule)); // 创建模块并确保创建成功\n  // 对模块进行各种初始化\n#ifdef USE_CUDA\n  torch::cuda::initModule(module);       // 执行cuda相关的初始化\n#endif\n  ...\n  // 定义模块的属性设置函数，setter\n  // 属性名为name，值为v，incref表示是否对值对象增加引用计数\n  // 设置成功返回1，否则返回0\n  auto set_module_attr = [&](const char* name, PyObject* v, bool incref = true) \n  {\n    if(incref) {\n      Py_INCREF(v);\n    }\n    return PyModule_AddObject(module, name, v) == 0;\n  }\n  // 设置模块属性\n  ...\n  ASSERT_TRUE(set_module_attr(\"has_cudnn\", has_cudnn));\n  // 向模块添加方法\n  auto py_module = py::reinterpret_borrow<py::module>(module);\n  py_module.def(\"_demangle\", &c10::demangle);\n  py_module.def(\"_log_api_usage_once\", &LogAPIUsageOnceFromPython);\n  ...    // 设置模块其他属性\n  ASSERT_TRUE(set_module_attr(\"default_generator\", \n        (PyObject*)THPDefaultGenerator, false));\n  torch::nn::init__THNN(module);  // 增加 _THNN 属性\n#ifdef USE_CUDA\n  torch::nn::init_THCUDD(module);\n#endif\n  return module;\n  ...\n}\n```\n从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。\n# methods/members in torch._C\n- 使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括\n```\n# TorchMethods \n_initExtension\n_autograd_init\n...\n# DataLoaderMethods \n_set_worker_signal_handlers\n_set_worker_pids\n...\n# torch::autograd::python_functions(), torch/csrc/autograd/init.cpp\nset_grad_enabled\nis_grad_enabled\nset_anomaly_enabled\nis_anomaly_enabled\n# torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp\n_multiprocessing_init\n# torch::distributed::c10d::python_functions()  同上类似\n...\n# THCPModule_method(), torch/csrc/cuda/Module.cpp\n_cuda_init\n_cuda_setDevice\n...\n_nccl_version\n...\n# THCUDNN_method()\n_cudnn_version\n# THDPModule_methods(), torch/csrc/distributed/Module.cpp\n_dist_init_extension\n_dist_init_process_group\n...\n```\n- 生成模块torch._C 后再向其添加如下成员：\n\na. 向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。\n\ntorch._C._TensorBase这个类型具有属性\n```\n_cdata\n_version\ngrad_fn\n_grad_fn\nis_leaf\ndata\n_grad\ngrad\n...\ndevice\nndim\n```\n并且具有以下方法\n```\n# variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp\n__add__\n__radd__\n...\napply_\nbyte\nchar\ncontiguous\n...\nwhere\nzero_\n# extra_method\n_make_subclass\n```\n类型torch._C._FunctionBase， 这个类型具有方法和属性为\n```\n# method\napply\n_do_forward\n_do_backward\n_register_hook_dict\nregister_hook\n# property\nsaved_tensors\nsaved_variables\n...\nrequires_grad\nmetadata\n```\n不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。\n\nb. 向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。\n\nc. 向torch._C添加模块， _nn，cpp，_onnx。\n\nd. 向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。\n\n# some installization w.r.t. torch._C\n### THPxxxStorage_init\ntorch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。\n\n注意到从Module.cpp文件中头文件引用：\n```\n#include <TH/TH.h>               // TH=TorcH\n#include <c10/util/Logging.h>\n#include <ATen/ATen.h>\n...\n#include <torch/csrc/THP.h>      // THP=TorcH Python\n...\n```\n可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。\n\n一方面，头文件 TH/TH.h 中引用了#include <TH/THGeneral.h>，在aten/src/TH目录下的CMakeLists.txt中有这么一行\n```\nCONFIGURE_FILE(THGeneral.h.in \"${CMAKE_CURRENT_BINARY_DIR}/THGeneral.h\")\n```\n在THGeneral.h中有如下宏定义\n```\n#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w\n#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND\n```\n另一方面，torch/csrc/THP.h 中引用了#include <torch/src/Storage.h>，在这个Storage.h中有如下语句\n```\n#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)\n...\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateAllType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateQTypes.h>\n```\n上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句\n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.h\"         // (0)\n#else\n...\nbool THPStorage_(init)(PyObject *module);                      // (1)\n...\n#endif\n```\n而文件TH/THGenerateAllType.h则包含语句\n```\n#include <TH/THGenerateFloatTypes.h>\n#include <TH/THGenerateIntTypes.h>\n...\n#undef TH_GENERIC_FILE\n```\n4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有\n```\n// 此时 TH_GENERIC_FILE是已定义的\n#include <TH/THGenerateFloatType.h>\n#include <TH/THGenerateDoubleType.h>\n#undef TH_GENERIC_FILE     // 这里将TH_GENERIC_FILE 设为未定义\n```\n以TH/THGenerateFloatType.h为例说明，此文件中有语句\n```\n#define Real Float\n...\n#line 1 TH_GENERIC_FILE\n#include TH_GENERIC_FILE         // (2)\n...\n#undef Real\n```\n注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换\n```\nbool THPStorage_(init)(PyObject *module);  ->\nbool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    ->\nbool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   ->\nbool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); ->\nbool THPFloatStorage_init(PyObject *module);\n```\n类似地，#include <TH/THGenerateDoubleType.h>，则得到THPDoubleStorage_init，\n\n#include <TH/THGenerateIntTypes.h> 得到\n```\nTHPByteStorage_init\nTHPCharStorage_init\nTHPShortStorage_init\nTHPIntStorage_init\nTHPLongStorage_init\n```\n对4组include中的其他三组，则得到\n```\nTHPHalfStorage_init\nTHPBoolStorage_init\nTHPQUInt8Storage_init\nTHPQInt8Storage_init\nTHPQInt32Storage_init\n```\n以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含\n```\n#include <TH/THStorageFunctions.hpp>\n#include <torch/csrc/THP.h>                   // include THPxxxStorage_init 函数声明\n...\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateAllTypes.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateQTypes.h>\n```\n又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，\n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.cpp\"              // (11)\n#else\n...                                                                   // (12)\nbool THPStorage_(init)(PyObject *module)\n{\n  static std::vector<PyMethodDef> methods;\n  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));\n#ifndef THD_GENERIC_FILE\n  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);\n#endif\n  \n  THPStorageType.tp_methods = methods.data();\n  THPStorageType.tp_members = THPStorage_(members);\n  THPStorageType.tp_getset = THPStorage_(properties);\n  if (PyType_Ready(&THPStorageType) < 0)\n    return false;\n  Py_INCREF(&THPStorageType);\n  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&THPStorageType);\n  THPStorage_(initCopyMethods)();\n  return true;\n}\n```\n上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏\n```\n#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)\n```\n在TH/THGeneral.h中存在宏定义\n```\n#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)\n#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y\n```\n由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为\"FloatStorageBase\"，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。\n\n以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据\n```\n#define Real Float\n...\n#include TH_GENERIC_FILE\n```\n即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。\n\n其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。\n\ntorch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。\n\n现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，\n```\nPyTypeObject THPStorageType = {\n  PyVarObject_HEAD_INIT(nullptr, 0)\n  \"torch._C.\" THPStorageBaseStr,               /* tp_name */\n  sizeof(THPStorage),                          /* tp_basicsize */\n  ...\n  THPStorage_(pynew),                          /* tp_new */\n}\n```\n可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义\n```\nstruct THPStorage {\n  PyObject_HEAD\n  THWStorage *cdata;\n};\n```\n（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）\n\n然后查看类创建 THPStorage_(pynew) 的定义\n```\nstatic PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)\n{\n  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // 可变长度参数的个数\n\n  THPStoragePtr self((THPStorage *)type->tp_alloc(type, 0); // 分配内存，让self指向这个内存块\n  ...\n  c10::Allocator * allocator = nullptr;\n\n  if (kwargs != nullptr) {                               // named arguments\n    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, \"allocator\"); // 获取参数allocator的值\n    if (allocator_ptr) {\n      THPUtils_assert(THPUtils_checkLong(allocator_ptr), \"invalid allocator\");\n      // 转为 c10::Allocator 指针\n      allocator = static_cast<c10::Allocator*>(PyLong_AsVoidPtr(allocator_ptr));\n      PyDict_DelItemString(kwargs, \"allocator\");\n    }\n    Py_ssize_t num_kwargs = PyDict_Size(kwargs);\n    if (num_args == 0) {\n      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, \"cdata\");\n      if (num_kwargs==1 && cdata_ptr && THPUtils_checkLong(cdata_ptr)) {   // 提供了cdata值\n        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);\n        self->cdata = ptr;\n        return (PyObject*)self.release();       // 返回THPStorage指针\n      }\n    }\n    THPUtils_assert(num_kwargs == 0, THPStoragePtr \"(): invalid keyword arguments\");\n  }\n\n  if (num_args == 0) {\n    if (allocator) {                            // 未提供cdata值，则需要创建THWStorage类型实例\n      self->cdata = THPStorage_(newWithAllocator)(0, allocator);\n    } else {\n      self->cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);\n    }\n    return (PyObject*)self.release();\n  }\n  ...     // 使用其他方法设置 self->cdata\n}   \n```\n从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义\n```\n#define THWStorage THStorage\n```\n转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，\n```\nStorage.cpp                 ->\n#include <TH/TH.h>          ->\n#include <TH/THStorageFunction.h>   ->\n#include <TH/generic/THStorage.h>   ->\n#include <c10/core/StorageImpl.h>\n```\n在 TH/generic/THStorage.h 中找到宏定义\n```\n#define THStorage at::StorageImpl\n```\n在 c10/core/StorageImpl.h 中找到结构定义\n```\nnamespace c10 {\nstruct C10_API StorageImpl final : public c10::intrusive_ptr_target {\n...\nprivate:\n  caffe2::TypeMeta  data_type_;  // 数据类型\n  DataPtr data_ptr_;             // 数据指针\n  int64_t numel_;                // 数据数量\n  bool resizable_;\n  bool received_cuda_;\n  Allocator* allocator_;         // 数据的内存分配器\n};\n}\n```\n所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为\n```\nnew                // 新建THStorage，未指定 size，即size=0，使用默认Allocator\nfree\nsize\nget\nset\ndata\nnewWithSize        // 新建THStorage，指定 size，使用默认Allocator\nnewWithAllocator   // 新建THStorage，指定 size 和 Allocator\ncopy_functions\ncopyByte\n...\ncopyCudaByte\n...\n```\n此外有宏定义\n```\n#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h\n#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h\n```\n函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。\n\n（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）\n\n以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义\n```\nTHStorage* THStorage_(newWithSize)(ptrdiff_t size)\n{\n  THStorage* storage = c10::make_instrusive<at::StorageImpl>(\n#ifdef THQUANTIZED\n    caffe2::TypeMeta::Make<quantized_t>(),\n#else\n    caffe2::TypeMeta::Make<scalar_t>(),        // 新建scalar_t 类型\n#endif\n    size,\n    getTHDefaultAllocator(),\n    true).release();\n  return storage;\n}\n```\n从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，\n```\nStorageImpl(\n    caffe2::TypeMeta data_type,\n    int64_4 numel,\n    at::Allocator* allocator,\n    bool resizable)\n...\n```\n我们看上上个代码片段中StorageImpl构造函数的实参，\n\n首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）\n```\n#define scalar_t float\n```\n于是，\n```\ncaffe2::TypeMeta::Make<scalar_t>()    // 假设 THQUANTIZED 未定义\n```\ncaffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，\n```\n#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\\n  namespace detail {                                                       \\\n  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\\n    _makeTypeMetaDataInstance<T>(_typeName<T>(#T));                        \\\n  }                                                                        \\\n  template<>                                                               \\\n  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                          \\\n    return &C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\\n  }\n  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)\n\n#define C10_CONCATENATE_IMPL(s1,s2) s1##s2\n#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)\n```\n经过宏替换，得到 _typeMetaDataInstance的模板函数定义\n```\ntemplate<>\nconst detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<T>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<T>(_typeName<T>(#T));\n}\n```\n还有一组宏，用于生成模板特例化，\n```\n#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\\n  template<>                                                           \\\n  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get<T>() {          \\\n    return TypeIdentifier(PreallocatedId);                             \\\n  }                                                                    \\\n  namespace detail {                                                   \\\n  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\\n    _typeMetaDataInstance_preallocated_,                               \\\n    PreallocatedId);                                                   \\\n  }                                                                    \\\n  template<>                                                           \\\n  inline const detail::TypeMetaData*                                   \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                      \\\n    return &C10_CONCATENATE(                                           \\\n      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\\n  }                                                                    \\\n#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\\n  namespace detail {                                                 \\\n  const TypeMetaData C10_CONCATENATE(                                \\\n    _typeMetaDataInstance_preallocated_,                             \\\n    PreallocatedId) = _makeTypeMetaDataInstance<T>(_typeName<T>(#T));\\\n  }                                                                  \n// 调用\nCAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)\n```\n对于系统内部变量如 float，得到函数模板特例化的定义\n```\n// 函数声明\nnamespace detail {\n__attrubyte((__visibility(\"default\"))) extern const TypeMetaData\n_typeMetaDataInstance_preallocated_Preallocated;\n}\n\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_typeMetaDataInstance_preallocated_Preallocated;\n}\n```\n另外，在c10/util/typeid.cpp中有如下调用\n```\nCAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)\n```\n经过宏替换得到\n```\nnamespace detail {                                                 \n  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId\n    = _makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}   \n```\n于是函数模板特例化最终形式为，\n```\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}\n```\ndetail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，\n```\nstruct TypeMetaData final {\n// 函数类型的别名\nusing New = void*();                            // new\nusing PlacementNew = void(void*, size_t);       // 占位new\nusing Copy = void(const void*, void*, size_t);  // 类型数组拷贝\nusing PlacementDelete = void(void*, size_t);\nusing Delete = void(void*);\n... //构造函数\n\nsize_t itemsize_;  // 类型占多少字节\nNew* new_;\nPlacementNew* placementNew_;   // 定位放置 new\nCopy* copy_;        // 类型拷贝\nDelete* delete_;    // 类型析构\nTypeIdentifier id_; // 类型全局唯一id\nconst char* name_;  // 类型名称\n};\n```\n我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义\n```\ntemplate <class T>\ninline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) {\n  return {sizeof(T),                 // 类型T占多少字节\n          _PickNew<T>(),             // 通过 new T\n          _PickPlacementNew<T>(),\n          _PickCopy<T>(),      \n          _PickPlacementDelete<T>(),\n          _PickDelete<T>(),\n          TypeIdentifier::Get<T>(),  // 获取类型的全局唯一id，\n          typeName};                 // 类型名称，例如float的名称为\"float\"\n```\n构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用\n```\nTypeIdentifier::Get<T>()\n```\n在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。\n\n对于其他类型如 int，double，int64_t等类似处理。\n\nPyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。\n\n至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为\n```\nsize,             // 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）\ngetTHDefaultAllocator(),  // 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配\ntrue                      // 被构造的StorageImpl可以resize\n```\n创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase\n\n记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。\n\nFloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。\n\n类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，\n```\n  torch::nn::init_THNN(module);\n#ifdef USE_CUDA\n  torch::nn::init_THCUNN(module);\n#endif\n```\n函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。\n\ntorch._C模块初始化过程到这里就完成了。回到 `torch/__init__.py`，继续看看 import torch时接下来做了哪些事情：\n\n1. 定义了模块函数 typename，is_tensor，is_storage等\n2. 导入torch下其他子模块\n3. 调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理\n4. 调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：\n    - 初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；\n    - 初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；\n    - 初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；\n    - 初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor\n    - 共享内存管理初始化，设置文件路径；\n    - 执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），\n        ```\n        torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, \n        TH_CONCAT_2(at::k, Real));\n        ```\n        其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，\n        ```\n        AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`\n        ```\n        这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。\n\n到这里，import torch 的工作全部完成。\n\n# 后记：\n初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。","source":"_posts/PyTorch-2.md","raw":"---\ntitle: PyTorch-2\ndate: 2019-06-13 10:19:52\ntags:\n---\n# torch installization\n依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是\n```\nimport torch\n```\n于是阅读torch/__init__.py，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，\n```\nold_flags=sys.getdlopenflags()\nsys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)\nfrom torch._C import *\n__all__ += [name for name in dir(_C)\n            if name[0] != '_' and\n            not name.endswith('Base')]\nsys.setdlopenflags(old_flags)\n```\n<b>将torch._C中（不包括_开头和Base结尾）的属性导出到当前域。</b>\n\n__init__.py除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，\n```\nextern PyObject* initModule();\nPyMODINIT_FUNC PyInit__C()   // 在python脚本中，import _C 时调用\n{\n  return initModule();\n}\n```\n根据python3扩展库的规则可知，import torch._C ，调用PyInit__C函数（调用名为PyInit_<package>的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。\n\nshm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，\n```\nset(LIBSHM_SUBDIR libshm)\nset(LIBSHM_SRCDIR ${LIBSHM_SRC_DIR}/lib/${LIBSHM_SUBDIR})\nadd_subdirectory(${LIBSHM_SRCDIR})\n```\n从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现\n```\nadd_library(torch_python SHARED ${TORCH_PYTHON_SRCS})\n```\nTORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。\n\ninitModule方法定义在torch/csrc/Module.cpp，\n```\n#ifdef USE_CUDA\nnamespace torch { namespace cuda {\nvoid initModule(PyObject* module);       // 模块中有关cuda部分的初始化函数声明\n}}\n#endif\n\nstatic std::vector<PyMethodDef> methods;\n\nPyObject* module;\nPyObject* initModule() {                 // 声明并定义模块初始化函数\n  // 向methods中添加方法定义\n  THPUtils_addPyMethodDefs(methods, TorchMethods);\n  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);\n  ...\n  // 真正的扩展模块定义\n  static struct PyModuleDef torchmodule = {\n    PyModuleDef_HEAD_INIT,\n    \"torch._C\",                          // 扩展模块名\n    nullptr,                           \n    -1,\n    methods.data()                       // 模块中的方法定义\n  };\n  ASSERT_TRUE(module = PyModule_Create(&torchmodule)); // 创建模块并确保创建成功\n  // 对模块进行各种初始化\n#ifdef USE_CUDA\n  torch::cuda::initModule(module);       // 执行cuda相关的初始化\n#endif\n  ...\n  // 定义模块的属性设置函数，setter\n  // 属性名为name，值为v，incref表示是否对值对象增加引用计数\n  // 设置成功返回1，否则返回0\n  auto set_module_attr = [&](const char* name, PyObject* v, bool incref = true) \n  {\n    if(incref) {\n      Py_INCREF(v);\n    }\n    return PyModule_AddObject(module, name, v) == 0;\n  }\n  // 设置模块属性\n  ...\n  ASSERT_TRUE(set_module_attr(\"has_cudnn\", has_cudnn));\n  // 向模块添加方法\n  auto py_module = py::reinterpret_borrow<py::module>(module);\n  py_module.def(\"_demangle\", &c10::demangle);\n  py_module.def(\"_log_api_usage_once\", &LogAPIUsageOnceFromPython);\n  ...    // 设置模块其他属性\n  ASSERT_TRUE(set_module_attr(\"default_generator\", \n        (PyObject*)THPDefaultGenerator, false));\n  torch::nn::init__THNN(module);  // 增加 _THNN 属性\n#ifdef USE_CUDA\n  torch::nn::init_THCUDD(module);\n#endif\n  return module;\n  ...\n}\n```\n从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。\n# methods/members in torch._C\n- 使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括\n```\n# TorchMethods \n_initExtension\n_autograd_init\n...\n# DataLoaderMethods \n_set_worker_signal_handlers\n_set_worker_pids\n...\n# torch::autograd::python_functions(), torch/csrc/autograd/init.cpp\nset_grad_enabled\nis_grad_enabled\nset_anomaly_enabled\nis_anomaly_enabled\n# torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp\n_multiprocessing_init\n# torch::distributed::c10d::python_functions()  同上类似\n...\n# THCPModule_method(), torch/csrc/cuda/Module.cpp\n_cuda_init\n_cuda_setDevice\n...\n_nccl_version\n...\n# THCUDNN_method()\n_cudnn_version\n# THDPModule_methods(), torch/csrc/distributed/Module.cpp\n_dist_init_extension\n_dist_init_process_group\n...\n```\n- 生成模块torch._C 后再向其添加如下成员：\n\na. 向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。\n\ntorch._C._TensorBase这个类型具有属性\n```\n_cdata\n_version\ngrad_fn\n_grad_fn\nis_leaf\ndata\n_grad\ngrad\n...\ndevice\nndim\n```\n并且具有以下方法\n```\n# variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp\n__add__\n__radd__\n...\napply_\nbyte\nchar\ncontiguous\n...\nwhere\nzero_\n# extra_method\n_make_subclass\n```\n类型torch._C._FunctionBase， 这个类型具有方法和属性为\n```\n# method\napply\n_do_forward\n_do_backward\n_register_hook_dict\nregister_hook\n# property\nsaved_tensors\nsaved_variables\n...\nrequires_grad\nmetadata\n```\n不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。\n\nb. 向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。\n\nc. 向torch._C添加模块， _nn，cpp，_onnx。\n\nd. 向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。\n\n# some installization w.r.t. torch._C\n### THPxxxStorage_init\ntorch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。\n\n注意到从Module.cpp文件中头文件引用：\n```\n#include <TH/TH.h>               // TH=TorcH\n#include <c10/util/Logging.h>\n#include <ATen/ATen.h>\n...\n#include <torch/csrc/THP.h>      // THP=TorcH Python\n...\n```\n可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。\n\n一方面，头文件 TH/TH.h 中引用了#include <TH/THGeneral.h>，在aten/src/TH目录下的CMakeLists.txt中有这么一行\n```\nCONFIGURE_FILE(THGeneral.h.in \"${CMAKE_CURRENT_BINARY_DIR}/THGeneral.h\")\n```\n在THGeneral.h中有如下宏定义\n```\n#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w\n#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND\n```\n另一方面，torch/csrc/THP.h 中引用了#include <torch/src/Storage.h>，在这个Storage.h中有如下语句\n```\n#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)\n...\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateAllType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.h>\n#include <TH/THGenerateQTypes.h>\n```\n上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句\n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.h\"         // (0)\n#else\n...\nbool THPStorage_(init)(PyObject *module);                      // (1)\n...\n#endif\n```\n而文件TH/THGenerateAllType.h则包含语句\n```\n#include <TH/THGenerateFloatTypes.h>\n#include <TH/THGenerateIntTypes.h>\n...\n#undef TH_GENERIC_FILE\n```\n4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有\n```\n// 此时 TH_GENERIC_FILE是已定义的\n#include <TH/THGenerateFloatType.h>\n#include <TH/THGenerateDoubleType.h>\n#undef TH_GENERIC_FILE     // 这里将TH_GENERIC_FILE 设为未定义\n```\n以TH/THGenerateFloatType.h为例说明，此文件中有语句\n```\n#define Real Float\n...\n#line 1 TH_GENERIC_FILE\n#include TH_GENERIC_FILE         // (2)\n...\n#undef Real\n```\n注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换\n```\nbool THPStorage_(init)(PyObject *module);  ->\nbool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    ->\nbool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   ->\nbool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); ->\nbool THPFloatStorage_init(PyObject *module);\n```\n类似地，#include <TH/THGenerateDoubleType.h>，则得到THPDoubleStorage_init，\n\n#include <TH/THGenerateIntTypes.h> 得到\n```\nTHPByteStorage_init\nTHPCharStorage_init\nTHPShortStorage_init\nTHPIntStorage_init\nTHPLongStorage_init\n```\n对4组include中的其他三组，则得到\n```\nTHPHalfStorage_init\nTHPBoolStorage_init\nTHPQUInt8Storage_init\nTHPQInt8Storage_init\nTHPQInt32Storage_init\n```\n以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含\n```\n#include <TH/THStorageFunctions.hpp>\n#include <torch/csrc/THP.h>                   // include THPxxxStorage_init 函数声明\n...\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateAllTypes.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateHalfType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateBoolType.h>\n\n#include <torch/csrc/generic/Storage.cpp>\n#include <TH/THGenerateQTypes.h>\n```\n又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，\n```\n#ifndef TH_GENERIC_FILE\n#define TH_GENERIC_FILE \"torch/csrc/generic/Storage.cpp\"              // (11)\n#else\n...                                                                   // (12)\nbool THPStorage_(init)(PyObject *module)\n{\n  static std::vector<PyMethodDef> methods;\n  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));\n#ifndef THD_GENERIC_FILE\n  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);\n#endif\n  \n  THPStorageType.tp_methods = methods.data();\n  THPStorageType.tp_members = THPStorage_(members);\n  THPStorageType.tp_getset = THPStorage_(properties);\n  if (PyType_Ready(&THPStorageType) < 0)\n    return false;\n  Py_INCREF(&THPStorageType);\n  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&THPStorageType);\n  THPStorage_(initCopyMethods)();\n  return true;\n}\n```\n上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏\n```\n#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)\n```\n在TH/THGeneral.h中存在宏定义\n```\n#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)\n#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y\n```\n由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为\"FloatStorageBase\"，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。\n\n以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据\n```\n#define Real Float\n...\n#include TH_GENERIC_FILE\n```\n即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。\n\n其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。\n\ntorch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。\n\n现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，\n```\nPyTypeObject THPStorageType = {\n  PyVarObject_HEAD_INIT(nullptr, 0)\n  \"torch._C.\" THPStorageBaseStr,               /* tp_name */\n  sizeof(THPStorage),                          /* tp_basicsize */\n  ...\n  THPStorage_(pynew),                          /* tp_new */\n}\n```\n可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义\n```\nstruct THPStorage {\n  PyObject_HEAD\n  THWStorage *cdata;\n};\n```\n（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）\n\n然后查看类创建 THPStorage_(pynew) 的定义\n```\nstatic PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)\n{\n  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // 可变长度参数的个数\n\n  THPStoragePtr self((THPStorage *)type->tp_alloc(type, 0); // 分配内存，让self指向这个内存块\n  ...\n  c10::Allocator * allocator = nullptr;\n\n  if (kwargs != nullptr) {                               // named arguments\n    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, \"allocator\"); // 获取参数allocator的值\n    if (allocator_ptr) {\n      THPUtils_assert(THPUtils_checkLong(allocator_ptr), \"invalid allocator\");\n      // 转为 c10::Allocator 指针\n      allocator = static_cast<c10::Allocator*>(PyLong_AsVoidPtr(allocator_ptr));\n      PyDict_DelItemString(kwargs, \"allocator\");\n    }\n    Py_ssize_t num_kwargs = PyDict_Size(kwargs);\n    if (num_args == 0) {\n      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, \"cdata\");\n      if (num_kwargs==1 && cdata_ptr && THPUtils_checkLong(cdata_ptr)) {   // 提供了cdata值\n        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);\n        self->cdata = ptr;\n        return (PyObject*)self.release();       // 返回THPStorage指针\n      }\n    }\n    THPUtils_assert(num_kwargs == 0, THPStoragePtr \"(): invalid keyword arguments\");\n  }\n\n  if (num_args == 0) {\n    if (allocator) {                            // 未提供cdata值，则需要创建THWStorage类型实例\n      self->cdata = THPStorage_(newWithAllocator)(0, allocator);\n    } else {\n      self->cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);\n    }\n    return (PyObject*)self.release();\n  }\n  ...     // 使用其他方法设置 self->cdata\n}   \n```\n从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义\n```\n#define THWStorage THStorage\n```\n转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，\n```\nStorage.cpp                 ->\n#include <TH/TH.h>          ->\n#include <TH/THStorageFunction.h>   ->\n#include <TH/generic/THStorage.h>   ->\n#include <c10/core/StorageImpl.h>\n```\n在 TH/generic/THStorage.h 中找到宏定义\n```\n#define THStorage at::StorageImpl\n```\n在 c10/core/StorageImpl.h 中找到结构定义\n```\nnamespace c10 {\nstruct C10_API StorageImpl final : public c10::intrusive_ptr_target {\n...\nprivate:\n  caffe2::TypeMeta  data_type_;  // 数据类型\n  DataPtr data_ptr_;             // 数据指针\n  int64_t numel_;                // 数据数量\n  bool resizable_;\n  bool received_cuda_;\n  Allocator* allocator_;         // 数据的内存分配器\n};\n}\n```\n所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为\n```\nnew                // 新建THStorage，未指定 size，即size=0，使用默认Allocator\nfree\nsize\nget\nset\ndata\nnewWithSize        // 新建THStorage，指定 size，使用默认Allocator\nnewWithAllocator   // 新建THStorage，指定 size 和 Allocator\ncopy_functions\ncopyByte\n...\ncopyCudaByte\n...\n```\n此外有宏定义\n```\n#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h\n#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h\n```\n函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。\n\n（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）\n\n以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义\n```\nTHStorage* THStorage_(newWithSize)(ptrdiff_t size)\n{\n  THStorage* storage = c10::make_instrusive<at::StorageImpl>(\n#ifdef THQUANTIZED\n    caffe2::TypeMeta::Make<quantized_t>(),\n#else\n    caffe2::TypeMeta::Make<scalar_t>(),        // 新建scalar_t 类型\n#endif\n    size,\n    getTHDefaultAllocator(),\n    true).release();\n  return storage;\n}\n```\n从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，\n```\nStorageImpl(\n    caffe2::TypeMeta data_type,\n    int64_4 numel,\n    at::Allocator* allocator,\n    bool resizable)\n...\n```\n我们看上上个代码片段中StorageImpl构造函数的实参，\n\n首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）\n```\n#define scalar_t float\n```\n于是，\n```\ncaffe2::TypeMeta::Make<scalar_t>()    // 假设 THQUANTIZED 未定义\n```\ncaffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，\n```\n#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\\n  namespace detail {                                                       \\\n  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\\n    _makeTypeMetaDataInstance<T>(_typeName<T>(#T));                        \\\n  }                                                                        \\\n  template<>                                                               \\\n  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                          \\\n    return &C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\\n  }\n  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)\n\n#define C10_CONCATENATE_IMPL(s1,s2) s1##s2\n#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)\n```\n经过宏替换，得到 _typeMetaDataInstance的模板函数定义\n```\ntemplate<>\nconst detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<T>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<T>(_typeName<T>(#T));\n}\n```\n还有一组宏，用于生成模板特例化，\n```\n#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\\n  template<>                                                           \\\n  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get<T>() {          \\\n    return TypeIdentifier(PreallocatedId);                             \\\n  }                                                                    \\\n  namespace detail {                                                   \\\n  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\\n    _typeMetaDataInstance_preallocated_,                               \\\n    PreallocatedId);                                                   \\\n  }                                                                    \\\n  template<>                                                           \\\n  inline const detail::TypeMetaData*                                   \\\n  TypeMeta::_typeMetaDataInstance<T>() noexcept {                      \\\n    return &C10_CONCATENATE(                                           \\\n      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\\n  }                                                                    \\\n#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\\n  namespace detail {                                                 \\\n  const TypeMetaData C10_CONCATENATE(                                \\\n    _typeMetaDataInstance_preallocated_,                             \\\n    PreallocatedId) = _makeTypeMetaDataInstance<T>(_typeName<T>(#T));\\\n  }                                                                  \n// 调用\nCAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)\n```\n对于系统内部变量如 float，得到函数模板特例化的定义\n```\n// 函数声明\nnamespace detail {\n__attrubyte((__visibility(\"default\"))) extern const TypeMetaData\n_typeMetaDataInstance_preallocated_Preallocated;\n}\n\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_typeMetaDataInstance_preallocated_Preallocated;\n}\n```\n另外，在c10/util/typeid.cpp中有如下调用\n```\nCAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)\n```\n经过宏替换得到\n```\nnamespace detail {                                                 \n  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId\n    = _makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}   \n```\n于是函数模板特例化最终形式为，\n```\ntemplate<>\ninline const detail::TypeMetaData*\nTypeMeta::_typeMetaDataInstance<float>() noexcept {\n  return &detail::_makeTypeMetaDataInstance<float>(_typeName<float>(\"float\"));\n}\n```\ndetail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，\n```\nstruct TypeMetaData final {\n// 函数类型的别名\nusing New = void*();                            // new\nusing PlacementNew = void(void*, size_t);       // 占位new\nusing Copy = void(const void*, void*, size_t);  // 类型数组拷贝\nusing PlacementDelete = void(void*, size_t);\nusing Delete = void(void*);\n... //构造函数\n\nsize_t itemsize_;  // 类型占多少字节\nNew* new_;\nPlacementNew* placementNew_;   // 定位放置 new\nCopy* copy_;        // 类型拷贝\nDelete* delete_;    // 类型析构\nTypeIdentifier id_; // 类型全局唯一id\nconst char* name_;  // 类型名称\n};\n```\n我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义\n```\ntemplate <class T>\ninline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) {\n  return {sizeof(T),                 // 类型T占多少字节\n          _PickNew<T>(),             // 通过 new T\n          _PickPlacementNew<T>(),\n          _PickCopy<T>(),      \n          _PickPlacementDelete<T>(),\n          _PickDelete<T>(),\n          TypeIdentifier::Get<T>(),  // 获取类型的全局唯一id，\n          typeName};                 // 类型名称，例如float的名称为\"float\"\n```\n构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用\n```\nTypeIdentifier::Get<T>()\n```\n在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。\n\n对于其他类型如 int，double，int64_t等类似处理。\n\nPyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。\n\n至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为\n```\nsize,             // 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）\ngetTHDefaultAllocator(),  // 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配\ntrue                      // 被构造的StorageImpl可以resize\n```\n创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase\n\n记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。\n\nFloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。\n\n类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，\n```\n  torch::nn::init_THNN(module);\n#ifdef USE_CUDA\n  torch::nn::init_THCUNN(module);\n#endif\n```\n函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。\n\ntorch._C模块初始化过程到这里就完成了。回到 `torch/__init__.py`，继续看看 import torch时接下来做了哪些事情：\n\n1. 定义了模块函数 typename，is_tensor，is_storage等\n2. 导入torch下其他子模块\n3. 调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理\n4. 调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：\n    - 初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；\n    - 初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；\n    - 初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；\n    - 初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor\n    - 共享内存管理初始化，设置文件路径；\n    - 执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），\n        ```\n        torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, \n        TH_CONCAT_2(at::k, Real));\n        ```\n        其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，\n        ```\n        AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`\n        ```\n        这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。\n\n到这里，import torch 的工作全部完成。\n\n# 后记：\n初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。","slug":"PyTorch-2","published":1,"updated":"2019-06-13T03:39:53.449Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjwu48imc00087wvc6n4olv9i","content":"<h1 id=\"torch-installization\"><a href=\"#torch-installization\" class=\"headerlink\" title=\"torch installization\"></a>torch installization</h1><p>依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import torch</span><br></pre></td></tr></table></figure>\n\n<p>于是阅读torch/<strong>init</strong>.py，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">old_flags=sys.getdlopenflags()</span><br><span class=\"line\">sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)</span><br><span class=\"line\">from torch._C import *</span><br><span class=\"line\">__all__ += [name for name in dir(_C)</span><br><span class=\"line\">            if name[0] != &apos;_&apos; and</span><br><span class=\"line\">            not name.endswith(&apos;Base&apos;)]</span><br><span class=\"line\">sys.setdlopenflags(old_flags)</span><br></pre></td></tr></table></figure>\n\n<p><b>将torch._C中（不包括_开头和Base结尾）的属性导出到当前域。</b></p>\n<p><strong>init</strong>.py除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">extern PyObject* initModule();</span><br><span class=\"line\">PyMODINIT_FUNC PyInit__C()   // 在python脚本中，import _C 时调用</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  return initModule();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>根据python3扩展库的规则可知，import torch.<em>C ，调用PyInit__C函数（调用名为PyInit</em><package>的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。</package></p>\n<p>shm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM_SUBDIR libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>TORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。</p>\n<p>initModule方法定义在torch/csrc/Module.cpp，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">namespace torch &#123; namespace cuda &#123;</span><br><span class=\"line\">void initModule(PyObject* module);       // 模块中有关cuda部分的初始化函数声明</span><br><span class=\"line\">&#125;&#125;</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\"></span><br><span class=\"line\">PyObject* module;</span><br><span class=\"line\">PyObject* initModule() &#123;                 // 声明并定义模块初始化函数</span><br><span class=\"line\">  // 向methods中添加方法定义</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // 真正的扩展模块定义</span><br><span class=\"line\">  static struct PyModuleDef torchmodule = &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    &quot;torch._C&quot;,                          // 扩展模块名</span><br><span class=\"line\">    nullptr,                           </span><br><span class=\"line\">    -1,</span><br><span class=\"line\">    methods.data()                       // 模块中的方法定义</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">  ASSERT_TRUE(module = PyModule_Create(&amp;torchmodule)); // 创建模块并确保创建成功</span><br><span class=\"line\">  // 对模块进行各种初始化</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::cuda::initModule(module);       // 执行cuda相关的初始化</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // 定义模块的属性设置函数，setter</span><br><span class=\"line\">  // 属性名为name，值为v，incref表示是否对值对象增加引用计数</span><br><span class=\"line\">  // 设置成功返回1，否则返回0</span><br><span class=\"line\">  auto set_module_attr = [&amp;](const char* name, PyObject* v, bool incref = true) </span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    if(incref) &#123;</span><br><span class=\"line\">      Py_INCREF(v);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return PyModule_AddObject(module, name, v) == 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // 设置模块属性</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));</span><br><span class=\"line\">  // 向模块添加方法</span><br><span class=\"line\">  auto py_module = py::reinterpret_borrow&lt;py::module&gt;(module);</span><br><span class=\"line\">  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);</span><br><span class=\"line\">  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);</span><br><span class=\"line\">  ...    // 设置模块其他属性</span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;, </span><br><span class=\"line\">        (PyObject*)THPDefaultGenerator, false));</span><br><span class=\"line\">  torch::nn::init__THNN(module);  // 增加 _THNN 属性</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUDD(module);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  return module;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。</p>\n<h1 id=\"methods-members-in-torch-C\"><a href=\"#methods-members-in-torch-C\" class=\"headerlink\" title=\"methods/members in torch._C\"></a>methods/members in torch._C</h1><ul>\n<li><p>使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># TorchMethods </span><br><span class=\"line\">_initExtension</span><br><span class=\"line\">_autograd_init</span><br><span class=\"line\">...</span><br><span class=\"line\"># DataLoaderMethods </span><br><span class=\"line\">_set_worker_signal_handlers</span><br><span class=\"line\">_set_worker_pids</span><br><span class=\"line\">...</span><br><span class=\"line\"># torch::autograd::python_functions(), torch/csrc/autograd/init.cpp</span><br><span class=\"line\">set_grad_enabled</span><br><span class=\"line\">is_grad_enabled</span><br><span class=\"line\">set_anomaly_enabled</span><br><span class=\"line\">is_anomaly_enabled</span><br><span class=\"line\"># torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp</span><br><span class=\"line\">_multiprocessing_init</span><br><span class=\"line\"># torch::distributed::c10d::python_functions()  同上类似</span><br><span class=\"line\">...</span><br><span class=\"line\"># THCPModule_method(), torch/csrc/cuda/Module.cpp</span><br><span class=\"line\">_cuda_init</span><br><span class=\"line\">_cuda_setDevice</span><br><span class=\"line\">...</span><br><span class=\"line\">_nccl_version</span><br><span class=\"line\">...</span><br><span class=\"line\"># THCUDNN_method()</span><br><span class=\"line\">_cudnn_version</span><br><span class=\"line\"># THDPModule_methods(), torch/csrc/distributed/Module.cpp</span><br><span class=\"line\">_dist_init_extension</span><br><span class=\"line\">_dist_init_process_group</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>生成模块torch._C 后再向其添加如下成员：</p>\n</li>\n</ul>\n<p>a. 向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。</p>\n<p>torch._C._TensorBase这个类型具有属性</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_cdata</span><br><span class=\"line\">_version</span><br><span class=\"line\">grad_fn</span><br><span class=\"line\">_grad_fn</span><br><span class=\"line\">is_leaf</span><br><span class=\"line\">data</span><br><span class=\"line\">_grad</span><br><span class=\"line\">grad</span><br><span class=\"line\">...</span><br><span class=\"line\">device</span><br><span class=\"line\">ndim</span><br></pre></td></tr></table></figure>\n\n<p>并且具有以下方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp</span><br><span class=\"line\">__add__</span><br><span class=\"line\">__radd__</span><br><span class=\"line\">...</span><br><span class=\"line\">apply_</span><br><span class=\"line\">byte</span><br><span class=\"line\">char</span><br><span class=\"line\">contiguous</span><br><span class=\"line\">...</span><br><span class=\"line\">where</span><br><span class=\"line\">zero_</span><br><span class=\"line\"># extra_method</span><br><span class=\"line\">_make_subclass</span><br></pre></td></tr></table></figure>\n\n<p>类型torch._C._FunctionBase， 这个类型具有方法和属性为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># method</span><br><span class=\"line\">apply</span><br><span class=\"line\">_do_forward</span><br><span class=\"line\">_do_backward</span><br><span class=\"line\">_register_hook_dict</span><br><span class=\"line\">register_hook</span><br><span class=\"line\"># property</span><br><span class=\"line\">saved_tensors</span><br><span class=\"line\">saved_variables</span><br><span class=\"line\">...</span><br><span class=\"line\">requires_grad</span><br><span class=\"line\">metadata</span><br></pre></td></tr></table></figure>\n\n<p>不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。</p>\n<p>b. 向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。</p>\n<p>c. 向torch._C添加模块， _nn，cpp，_onnx。</p>\n<p>d. 向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。</p>\n<h1 id=\"some-installization-w-r-t-torch-C\"><a href=\"#some-installization-w-r-t-torch-C\" class=\"headerlink\" title=\"some installization w.r.t. torch._C\"></a>some installization w.r.t. torch._C</h1><h3 id=\"THPxxxStorage-init\"><a href=\"#THPxxxStorage-init\" class=\"headerlink\" title=\"THPxxxStorage_init\"></a>THPxxxStorage_init</h3><p>torch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。</p>\n<p>注意到从Module.cpp文件中头文件引用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/TH.h&gt;               // TH=TorcH</span><br><span class=\"line\">#include &lt;c10/util/Logging.h&gt;</span><br><span class=\"line\">#include &lt;ATen/ATen.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;      // THP=TorcH Python</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。</p>\n<p>一方面，头文件 TH/TH.h 中引用了#include &lt;TH/THGeneral.h&gt;，在aten/src/TH目录下的CMakeLists.txt中有这么一行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/THGeneral.h&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>在THGeneral.h中有如下宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w</span><br><span class=\"line\">#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND</span><br></pre></td></tr></table></figure>\n\n<p>另一方面，torch/csrc/THP.h 中引用了#include &lt;torch/src/Storage.h&gt;，在这个Storage.h中有如下语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure>\n\n<p>上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.h&quot;         // (0)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module);                      // (1)</span><br><span class=\"line\">...</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure>\n\n<p>而文件TH/THGenerateAllType.h则包含语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THGenerateFloatTypes.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateIntTypes.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef TH_GENERIC_FILE</span><br></pre></td></tr></table></figure>\n\n<p>4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 此时 TH_GENERIC_FILE是已定义的</span><br><span class=\"line\">#include &lt;TH/THGenerateFloatType.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateDoubleType.h&gt;</span><br><span class=\"line\">#undef TH_GENERIC_FILE     // 这里将TH_GENERIC_FILE 设为未定义</span><br></pre></td></tr></table></figure>\n\n<p>以TH/THGenerateFloatType.h为例说明，此文件中有语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#line 1 TH_GENERIC_FILE</span><br><span class=\"line\">#include TH_GENERIC_FILE         // (2)</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef Real</span><br></pre></td></tr></table></figure>\n\n<p>注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool THPStorage_(init)(PyObject *module);  -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;</span><br><span class=\"line\">bool THPFloatStorage_init(PyObject *module);</span><br></pre></td></tr></table></figure>\n\n<p>类似地，#include &lt;TH/THGenerateDoubleType.h&gt;，则得到THPDoubleStorage_init，</p>\n<p>#include &lt;TH/THGenerateIntTypes.h&gt; 得到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPByteStorage_init</span><br><span class=\"line\">THPCharStorage_init</span><br><span class=\"line\">THPShortStorage_init</span><br><span class=\"line\">THPIntStorage_init</span><br><span class=\"line\">THPLongStorage_init</span><br></pre></td></tr></table></figure>\n\n<p>对4组include中的其他三组，则得到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPHalfStorage_init</span><br><span class=\"line\">THPBoolStorage_init</span><br><span class=\"line\">THPQUInt8Storage_init</span><br><span class=\"line\">THPQInt8Storage_init</span><br><span class=\"line\">THPQInt32Storage_init</span><br></pre></td></tr></table></figure>\n\n<p>以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THStorageFunctions.hpp&gt;</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;                   // include THPxxxStorage_init 函数声明</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllTypes.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure>\n\n<p>又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.cpp&quot;              // (11)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...                                                                   // (12)</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class=\"line\">#ifndef THD_GENERIC_FILE</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  </span><br><span class=\"line\">  THPStorageType.tp_methods = methods.data();</span><br><span class=\"line\">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class=\"line\">  THPStorageType.tp_getset = THPStorage_(properties);</span><br><span class=\"line\">  if (PyType_Ready(&amp;THPStorageType) &lt; 0)</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  Py_INCREF(&amp;THPStorageType);</span><br><span class=\"line\">  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);</span><br><span class=\"line\">  THPStorage_(initCopyMethods)();</span><br><span class=\"line\">  return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)</span><br></pre></td></tr></table></figure>\n\n<p>在TH/THGeneral.h中存在宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)</span><br><span class=\"line\">#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y</span><br></pre></td></tr></table></figure>\n\n<p>由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为”FloatStorageBase”，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。</p>\n<p>以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#include TH_GENERIC_FILE</span><br></pre></td></tr></table></figure>\n\n<p>即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。</p>\n<p>其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。</p>\n<p>torch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。</p>\n<p>现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyTypeObject THPStorageType = &#123;</span><br><span class=\"line\">  PyVarObject_HEAD_INIT(nullptr, 0)</span><br><span class=\"line\">  &quot;torch._C.&quot; THPStorageBaseStr,               /* tp_name */</span><br><span class=\"line\">  sizeof(THPStorage),                          /* tp_basicsize */</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  THPStorage_(pynew),                          /* tp_new */</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct THPStorage &#123;</span><br><span class=\"line\">  PyObject_HEAD</span><br><span class=\"line\">  THWStorage *cdata;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）</p>\n<p>然后查看类创建 THPStorage_(pynew) 的定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // 可变长度参数的个数</span><br><span class=\"line\"></span><br><span class=\"line\">  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); // 分配内存，让self指向这个内存块</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  c10::Allocator * allocator = nullptr;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (kwargs != nullptr) &#123;                               // named arguments</span><br><span class=\"line\">    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, &quot;allocator&quot;); // 获取参数allocator的值</span><br><span class=\"line\">    if (allocator_ptr) &#123;</span><br><span class=\"line\">      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);</span><br><span class=\"line\">      // 转为 c10::Allocator 指针</span><br><span class=\"line\">      allocator = static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));</span><br><span class=\"line\">      PyDict_DelItemString(kwargs, &quot;allocator&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Py_ssize_t num_kwargs = PyDict_Size(kwargs);</span><br><span class=\"line\">    if (num_args == 0) &#123;</span><br><span class=\"line\">      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, &quot;cdata&quot;);</span><br><span class=\"line\">      if (num_kwargs==1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   // 提供了cdata值</span><br><span class=\"line\">        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);</span><br><span class=\"line\">        self-&gt;cdata = ptr;</span><br><span class=\"line\">        return (PyObject*)self.release();       // 返回THPStorage指针</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    THPUtils_assert(num_kwargs == 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (num_args == 0) &#123;</span><br><span class=\"line\">    if (allocator) &#123;                            // 未提供cdata值，则需要创建THWStorage类型实例</span><br><span class=\"line\">      self-&gt;cdata = THPStorage_(newWithAllocator)(0, allocator);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      self-&gt;cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return (PyObject*)self.release();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...     // 使用其他方法设置 self-&gt;cdata</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage THStorage</span><br></pre></td></tr></table></figure>\n\n<p>转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Storage.cpp                 -&gt;</span><br><span class=\"line\">#include &lt;TH/TH.h&gt;          -&gt;</span><br><span class=\"line\">#include &lt;TH/THStorageFunction.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;TH/generic/THStorage.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;c10/core/StorageImpl.h&gt;</span><br></pre></td></tr></table></figure>\n\n<p>在 TH/generic/THStorage.h 中找到宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THStorage at::StorageImpl</span><br></pre></td></tr></table></figure>\n\n<p>在 c10/core/StorageImpl.h 中找到结构定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace c10 &#123;</span><br><span class=\"line\">struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">private:</span><br><span class=\"line\">  caffe2::TypeMeta  data_type_;  // 数据类型</span><br><span class=\"line\">  DataPtr data_ptr_;             // 数据指针</span><br><span class=\"line\">  int64_t numel_;                // 数据数量</span><br><span class=\"line\">  bool resizable_;</span><br><span class=\"line\">  bool received_cuda_;</span><br><span class=\"line\">  Allocator* allocator_;         // 数据的内存分配器</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">new                // 新建THStorage，未指定 size，即size=0，使用默认Allocator</span><br><span class=\"line\">free</span><br><span class=\"line\">size</span><br><span class=\"line\">get</span><br><span class=\"line\">set</span><br><span class=\"line\">data</span><br><span class=\"line\">newWithSize        // 新建THStorage，指定 size，使用默认Allocator</span><br><span class=\"line\">newWithAllocator   // 新建THStorage，指定 size 和 Allocator</span><br><span class=\"line\">copy_functions</span><br><span class=\"line\">copyByte</span><br><span class=\"line\">...</span><br><span class=\"line\">copyCudaByte</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>此外有宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h</span><br><span class=\"line\">#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h</span><br></pre></td></tr></table></figure>\n\n<p>函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。</p>\n<p>（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）</p>\n<p>以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THStorage* THStorage_(newWithSize)(ptrdiff_t size)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  THStorage* storage = c10::make_instrusive&lt;at::StorageImpl&gt;(</span><br><span class=\"line\">#ifdef THQUANTIZED</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),</span><br><span class=\"line\">#else</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        // 新建scalar_t 类型</span><br><span class=\"line\">#endif</span><br><span class=\"line\">    size,</span><br><span class=\"line\">    getTHDefaultAllocator(),</span><br><span class=\"line\">    true).release();</span><br><span class=\"line\">  return storage;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StorageImpl(</span><br><span class=\"line\">    caffe2::TypeMeta data_type,</span><br><span class=\"line\">    int64_4 numel,</span><br><span class=\"line\">    at::Allocator* allocator,</span><br><span class=\"line\">    bool resizable)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>我们看上上个代码片段中StorageImpl构造函数的实参，</p>\n<p>首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define scalar_t float</span><br></pre></td></tr></table></figure>\n\n<p>于是，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    // 假设 THQUANTIZED 未定义</span><br></pre></td></tr></table></figure>\n\n<p>caffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\</span><br><span class=\"line\">  namespace detail &#123;                                                       \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\</span><br><span class=\"line\">    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \\</span><br><span class=\"line\">  &#125;                                                                        \\</span><br><span class=\"line\">  template&lt;&gt;                                                               \\</span><br><span class=\"line\">  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)</span><br><span class=\"line\"></span><br><span class=\"line\">#define C10_CONCATENATE_IMPL(s1,s2) s1##s2</span><br><span class=\"line\">#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)</span><br></pre></td></tr></table></figure>\n\n<p>经过宏替换，得到 _typeMetaDataInstance的模板函数定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>还有一组宏，用于生成模板特例化，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \\</span><br><span class=\"line\">    return TypeIdentifier(PreallocatedId);                             \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  namespace detail &#123;                                                   \\</span><br><span class=\"line\">  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                               \\</span><br><span class=\"line\">    PreallocatedId);                                                   \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline const detail::TypeMetaData*                                   \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(                                           \\</span><br><span class=\"line\">      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\</span><br><span class=\"line\">  namespace detail &#123;                                                 \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(                                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                             \\</span><br><span class=\"line\">    PreallocatedId) = _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\\</span><br><span class=\"line\">  &#125;                                                                  </span><br><span class=\"line\">// 调用</span><br><span class=\"line\">CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)</span><br></pre></td></tr></table></figure>\n\n<p>对于系统内部变量如 float，得到函数模板特例化的定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 函数声明</span><br><span class=\"line\">namespace detail &#123;</span><br><span class=\"line\">__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData</span><br><span class=\"line\">_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>另外，在c10/util/typeid.cpp中有如下调用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)</span><br></pre></td></tr></table></figure>\n\n<p>经过宏替换得到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace detail &#123;                                                 </span><br><span class=\"line\">  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId</span><br><span class=\"line\">    = _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>于是函数模板特例化最终形式为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>detail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct TypeMetaData final &#123;</span><br><span class=\"line\">// 函数类型的别名</span><br><span class=\"line\">using New = void*();                            // new</span><br><span class=\"line\">using PlacementNew = void(void*, size_t);       // 占位new</span><br><span class=\"line\">using Copy = void(const void*, void*, size_t);  // 类型数组拷贝</span><br><span class=\"line\">using PlacementDelete = void(void*, size_t);</span><br><span class=\"line\">using Delete = void(void*);</span><br><span class=\"line\">... //构造函数</span><br><span class=\"line\"></span><br><span class=\"line\">size_t itemsize_;  // 类型占多少字节</span><br><span class=\"line\">New* new_;</span><br><span class=\"line\">PlacementNew* placementNew_;   // 定位放置 new</span><br><span class=\"line\">Copy* copy_;        // 类型拷贝</span><br><span class=\"line\">Delete* delete_;    // 类型析构</span><br><span class=\"line\">TypeIdentifier id_; // 类型全局唯一id</span><br><span class=\"line\">const char* name_;  // 类型名称</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template &lt;class T&gt;</span><br><span class=\"line\">inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;</span><br><span class=\"line\">  return &#123;sizeof(T),                 // 类型T占多少字节</span><br><span class=\"line\">          _PickNew&lt;T&gt;(),             // 通过 new T</span><br><span class=\"line\">          _PickPlacementNew&lt;T&gt;(),</span><br><span class=\"line\">          _PickCopy&lt;T&gt;(),      </span><br><span class=\"line\">          _PickPlacementDelete&lt;T&gt;(),</span><br><span class=\"line\">          _PickDelete&lt;T&gt;(),</span><br><span class=\"line\">          TypeIdentifier::Get&lt;T&gt;(),  // 获取类型的全局唯一id，</span><br><span class=\"line\">          typeName&#125;;                 // 类型名称，例如float的名称为&quot;float&quot;</span><br></pre></td></tr></table></figure>\n\n<p>构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TypeIdentifier::Get&lt;T&gt;()</span><br></pre></td></tr></table></figure>\n\n<p>在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。</p>\n<p>对于其他类型如 int，double，int64_t等类似处理。</p>\n<p>PyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。</p>\n<p>至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">size,             // 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）</span><br><span class=\"line\">getTHDefaultAllocator(),  // 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配</span><br><span class=\"line\">true                      // 被构造的StorageImpl可以resize</span><br></pre></td></tr></table></figure>\n\n<p>创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase</p>\n<p>记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。</p>\n<p>FloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。</p>\n<p>类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  torch::nn::init_THNN(module);</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUNN(module);</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure>\n\n<p>函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。</p>\n<p>torch.<em>C模块初始化过程到这里就完成了。回到 `torch/<em>_init</em></em>.py`，继续看看 import torch时接下来做了哪些事情：</p>\n<ol>\n<li><p>定义了模块函数 typename，is_tensor，is_storage等</p>\n</li>\n<li><p>导入torch下其他子模块</p>\n</li>\n<li><p>调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理</p>\n</li>\n<li><p>调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：</p>\n<ul>\n<li><p>初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；</p>\n</li>\n<li><p>初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；</p>\n</li>\n<li><p>初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；</p>\n</li>\n<li><p>初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor</p>\n</li>\n<li><p>共享内存管理初始化，设置文件路径；</p>\n</li>\n<li><p>执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, </span><br><span class=\"line\">TH_CONCAT_2(at::k, Real));</span><br></pre></td></tr></table></figure>\n\n<p>  其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`</span><br></pre></td></tr></table></figure>\n\n<p>  这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>到这里，import torch 的工作全部完成。</p>\n<h1 id=\"后记：\"><a href=\"#后记：\" class=\"headerlink\" title=\"后记：\"></a>后记：</h1><p>初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"torch-installization\"><a href=\"#torch-installization\" class=\"headerlink\" title=\"torch installization\"></a>torch installization</h1><p>依然采取自顶向下的原则剖析，借助PyTorch的python接口。我们知道使用PyTorch第一步都是</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import torch</span><br></pre></td></tr></table></figure>\n\n<p>于是阅读torch/<strong>init</strong>.py，发现需要加载torch._C这个库，但是需要以（RTLD_GLOBAL|RTLD_LAZY）这个模式动态加载，于是先将动态加载模式设置到（RTLD_GLOBAL|RTLD_LAZY）之后加载torch._C然后再恢复动态加载模式，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">old_flags=sys.getdlopenflags()</span><br><span class=\"line\">sys.setdlopenflags(_dl_flags.RTDL_GLOBAL | _dl_flags.RTLD_LAZY)</span><br><span class=\"line\">from torch._C import *</span><br><span class=\"line\">__all__ += [name for name in dir(_C)</span><br><span class=\"line\">            if name[0] != &apos;_&apos; and</span><br><span class=\"line\">            not name.endswith(&apos;Base&apos;)]</span><br><span class=\"line\">sys.setdlopenflags(old_flags)</span><br></pre></td></tr></table></figure>\n\n<p><b>将torch._C中（不包括_开头和Base结尾）的属性导出到当前域。</b></p>\n<p><strong>init</strong>.py除了import torch._C，还import了同目录下其他module，以及同目录下的package。首先看torch._C导入时做了什么， torch._C的源文件只有torch/csrc/stub.cpp，链接库为shm和torch_python，stub.cpp中仅仅是初始化模块，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">extern PyObject* initModule();</span><br><span class=\"line\">PyMODINIT_FUNC PyInit__C()   // 在python脚本中，import _C 时调用</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  return initModule();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>根据python3扩展库的规则可知，import torch.<em>C ，调用PyInit__C函数（调用名为PyInit</em><package>的函数），这个函数内部调用initModule，也就是说，具体的模块定义由initModule实现。看到extern知道initModule方法定义在外部，所以只能从shm和torch_python对应的源文件中寻找方法定义。</package></p>\n<p>shm库实现Domain Socket通信获得共享内存的句柄，解决多进程的内存分配问题，查看torch/CMakeLists.txt，发现生成shm相关语句为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set(LIBSHM_SUBDIR libshm)</span><br><span class=\"line\">set(LIBSHM_SRCDIR $&#123;LIBSHM_SRC_DIR&#125;/lib/$&#123;LIBSHM_SUBDIR&#125;)</span><br><span class=\"line\">add_subdirectory($&#123;LIBSHM_SRCDIR&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>从上面语句得知shm库的源码位于torch/lib/libshm目录下，这个跟torch._C模块定义没有关系，暂且不细展开，继续查看torch_python的源码以寻求initModule方法定义。在torch/CMakeLists.txt中发现</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">add_library(torch_python SHARED $&#123;TORCH_PYTHON_SRCS&#125;)</span><br></pre></td></tr></table></figure>\n\n<p>TORCH_PYTHON_SRCS是一个列表，存储了torch_python库的源文件，生成torch_python库所需要的源文件以及依赖库直接查看torch/CMakeLists.txt，这里不再展开一一说明。</p>\n<p>initModule方法定义在torch/csrc/Module.cpp，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">namespace torch &#123; namespace cuda &#123;</span><br><span class=\"line\">void initModule(PyObject* module);       // 模块中有关cuda部分的初始化函数声明</span><br><span class=\"line\">&#125;&#125;</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\"></span><br><span class=\"line\">PyObject* module;</span><br><span class=\"line\">PyObject* initModule() &#123;                 // 声明并定义模块初始化函数</span><br><span class=\"line\">  // 向methods中添加方法定义</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // 真正的扩展模块定义</span><br><span class=\"line\">  static struct PyModuleDef torchmodule = &#123;</span><br><span class=\"line\">    PyModuleDef_HEAD_INIT,</span><br><span class=\"line\">    &quot;torch._C&quot;,                          // 扩展模块名</span><br><span class=\"line\">    nullptr,                           </span><br><span class=\"line\">    -1,</span><br><span class=\"line\">    methods.data()                       // 模块中的方法定义</span><br><span class=\"line\">  &#125;;</span><br><span class=\"line\">  ASSERT_TRUE(module = PyModule_Create(&amp;torchmodule)); // 创建模块并确保创建成功</span><br><span class=\"line\">  // 对模块进行各种初始化</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::cuda::initModule(module);       // 执行cuda相关的初始化</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // 定义模块的属性设置函数，setter</span><br><span class=\"line\">  // 属性名为name，值为v，incref表示是否对值对象增加引用计数</span><br><span class=\"line\">  // 设置成功返回1，否则返回0</span><br><span class=\"line\">  auto set_module_attr = [&amp;](const char* name, PyObject* v, bool incref = true) </span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    if(incref) &#123;</span><br><span class=\"line\">      Py_INCREF(v);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return PyModule_AddObject(module, name, v) == 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // 设置模块属性</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;has_cudnn&quot;, has_cudnn));</span><br><span class=\"line\">  // 向模块添加方法</span><br><span class=\"line\">  auto py_module = py::reinterpret_borrow&lt;py::module&gt;(module);</span><br><span class=\"line\">  py_module.def(&quot;_demangle&quot;, &amp;c10::demangle);</span><br><span class=\"line\">  py_module.def(&quot;_log_api_usage_once&quot;, &amp;LogAPIUsageOnceFromPython);</span><br><span class=\"line\">  ...    // 设置模块其他属性</span><br><span class=\"line\">  ASSERT_TRUE(set_module_attr(&quot;default_generator&quot;, </span><br><span class=\"line\">        (PyObject*)THPDefaultGenerator, false));</span><br><span class=\"line\">  torch::nn::init__THNN(module);  // 增加 _THNN 属性</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUDD(module);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  return module;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从上面的代码中可见，定义并生成名为torch._C的模块，然后对这个模块设置attr，添加方法，添加子模块等。</p>\n<h1 id=\"methods-members-in-torch-C\"><a href=\"#methods-members-in-torch-C\" class=\"headerlink\" title=\"methods/members in torch._C\"></a>methods/members in torch._C</h1><ul>\n<li><p>使用 THPUtils_addPyMethodDefs 向torch._C 添加模块方法。包括</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># TorchMethods </span><br><span class=\"line\">_initExtension</span><br><span class=\"line\">_autograd_init</span><br><span class=\"line\">...</span><br><span class=\"line\"># DataLoaderMethods </span><br><span class=\"line\">_set_worker_signal_handlers</span><br><span class=\"line\">_set_worker_pids</span><br><span class=\"line\">...</span><br><span class=\"line\"># torch::autograd::python_functions(), torch/csrc/autograd/init.cpp</span><br><span class=\"line\">set_grad_enabled</span><br><span class=\"line\">is_grad_enabled</span><br><span class=\"line\">set_anomaly_enabled</span><br><span class=\"line\">is_anomaly_enabled</span><br><span class=\"line\"># torch::multiprocessing::python_functions(), torch/csrc/multiprocessing/init.cpp</span><br><span class=\"line\">_multiprocessing_init</span><br><span class=\"line\"># torch::distributed::c10d::python_functions()  同上类似</span><br><span class=\"line\">...</span><br><span class=\"line\"># THCPModule_method(), torch/csrc/cuda/Module.cpp</span><br><span class=\"line\">_cuda_init</span><br><span class=\"line\">_cuda_setDevice</span><br><span class=\"line\">...</span><br><span class=\"line\">_nccl_version</span><br><span class=\"line\">...</span><br><span class=\"line\"># THCUDNN_method()</span><br><span class=\"line\">_cudnn_version</span><br><span class=\"line\"># THDPModule_methods(), torch/csrc/distributed/Module.cpp</span><br><span class=\"line\">_dist_init_extension</span><br><span class=\"line\">_dist_init_process_group</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>生成模块torch._C 后再向其添加如下成员：</p>\n</li>\n</ul>\n<p>a. 向torch._C添加类型_PtrWrapper，Generator，FatalError，Size，dtype，iinfo，layout，memory_format，device，_LegacyVariableBase，_TensorBase，_VariableFunctions，_FunctionBase，_EngineBase，JITException，IODescriptor，_THNN，_THCUNN。</p>\n<p>torch._C._TensorBase这个类型具有属性</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_cdata</span><br><span class=\"line\">_version</span><br><span class=\"line\">grad_fn</span><br><span class=\"line\">_grad_fn</span><br><span class=\"line\">is_leaf</span><br><span class=\"line\">data</span><br><span class=\"line\">_grad</span><br><span class=\"line\">grad</span><br><span class=\"line\">...</span><br><span class=\"line\">device</span><br><span class=\"line\">ndim</span><br></pre></td></tr></table></figure>\n\n<p>并且具有以下方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># variable_methods, torch/csrc/autograd/generated/python_variable_methods.cpp</span><br><span class=\"line\">__add__</span><br><span class=\"line\">__radd__</span><br><span class=\"line\">...</span><br><span class=\"line\">apply_</span><br><span class=\"line\">byte</span><br><span class=\"line\">char</span><br><span class=\"line\">contiguous</span><br><span class=\"line\">...</span><br><span class=\"line\">where</span><br><span class=\"line\">zero_</span><br><span class=\"line\"># extra_method</span><br><span class=\"line\">_make_subclass</span><br></pre></td></tr></table></figure>\n\n<p>类型torch._C._FunctionBase， 这个类型具有方法和属性为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># method</span><br><span class=\"line\">apply</span><br><span class=\"line\">_do_forward</span><br><span class=\"line\">_do_backward</span><br><span class=\"line\">_register_hook_dict</span><br><span class=\"line\">register_hook</span><br><span class=\"line\"># property</span><br><span class=\"line\">saved_tensors</span><br><span class=\"line\">saved_variables</span><br><span class=\"line\">...</span><br><span class=\"line\">requires_grad</span><br><span class=\"line\">metadata</span><br></pre></td></tr></table></figure>\n\n<p>不难知道_TensorBase是Tensor的基类，包含了Tensor的各种操作，_FunctionBase则包括了前后向传播方法，从这里能将深度学习中的一些概念与代码实现建立一点点联系了。</p>\n<p>b. 向torch._C中添加函数 _wrap_tensor_impl，_tensor_impl_raw_handle，_demangle，_log_api_usage_once，以_jit开头的一系列函数。</p>\n<p>c. 向torch._C添加模块， _nn，cpp，_onnx。</p>\n<p>d. 向torch._C添加属性 has_cudnn，has_openmp，has_mkl，has_lapack，has_cuda，has_mkldnn，_GLIBCXX_USE_CXX11_API，default_generator。</p>\n<h1 id=\"some-installization-w-r-t-torch-C\"><a href=\"#some-installization-w-r-t-torch-C\" class=\"headerlink\" title=\"some installization w.r.t. torch._C\"></a>some installization w.r.t. torch._C</h1><h3 id=\"THPxxxStorage-init\"><a href=\"#THPxxxStorage-init\" class=\"headerlink\" title=\"THPxxxStorage_init\"></a>THPxxxStorage_init</h3><p>torch._C模块中各种Tensor的定义通过 THPxxxStorage_init 和 THCPxxxStorage_init 完成，在项目中是无法直接搜索到这两种函数定义的，下面讲解这两个函数的定义。</p>\n<p>注意到从Module.cpp文件中头文件引用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/TH.h&gt;               // TH=TorcH</span><br><span class=\"line\">#include &lt;c10/util/Logging.h&gt;</span><br><span class=\"line\">#include &lt;ATen/ATen.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;      // THP=TorcH Python</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>可以看出先引用ATen和c10库的头文件，然后再引用torch中的头文件，这是因为ATen [A Tensor Library的缩写] 实现了Tensor的运算等，c10 [表示caffe2和ATen] 实现了Tensor存储等，这两个库作为基础。</p>\n<p>一方面，头文件 TH/TH.h 中引用了#include &lt;TH/THGeneral.h&gt;，在aten/src/TH目录下的CMakeLists.txt中有这么一行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONFIGURE_FILE(THGeneral.h.in &quot;$&#123;CMAKE_CURRENT_BINARY_DIR&#125;/THGeneral.h&quot;)</span><br></pre></td></tr></table></figure>\n\n<p>在THGeneral.h中有如下宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_4_EXPAND(x,y,z,w) x ## y ## z ## w</span><br><span class=\"line\">#define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND</span><br></pre></td></tr></table></figure>\n\n<p>另一方面，torch/csrc/THP.h 中引用了#include &lt;torch/src/Storage.h&gt;，在这个Storage.h中有如下语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorage_(NAME) TH_CONCAT_4(THP, Real, Storage_, NAME)</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure>\n\n<p>上面是4组include操作（根据不同类型生成对应的方法声明/定义，这种策略，后面还会用到很多次），可以看到每组include一次 torch/csrc/generic/Storage.h，这是为什么呢？查看文件torch/csrc/generic/Storage.h 发现其包含语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.h&quot;         // (0)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module);                      // (1)</span><br><span class=\"line\">...</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure>\n\n<p>而文件TH/THGenerateAllType.h则包含语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THGenerateFloatTypes.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateIntTypes.h&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef TH_GENERIC_FILE</span><br></pre></td></tr></table></figure>\n\n<p>4组include操作中，每组的第二个被include的文件均包含#undef TH_GENERIC_FILE，这使得每组include操作中，include torch/csrc/generic/Storage.h时均执行语句 (0)，而非语句 (1)，继续进一步查看TH/THGenerateFloatTypes.h，发现有</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 此时 TH_GENERIC_FILE是已定义的</span><br><span class=\"line\">#include &lt;TH/THGenerateFloatType.h&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateDoubleType.h&gt;</span><br><span class=\"line\">#undef TH_GENERIC_FILE     // 这里将TH_GENERIC_FILE 设为未定义</span><br></pre></td></tr></table></figure>\n\n<p>以TH/THGenerateFloatType.h为例说明，此文件中有语句</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#line 1 TH_GENERIC_FILE</span><br><span class=\"line\">#include TH_GENERIC_FILE         // (2)</span><br><span class=\"line\">...</span><br><span class=\"line\">#undef Real</span><br></pre></td></tr></table></figure>\n\n<p>注意语句 (2) 是include torch/csrc/generic/Storate.h，而此时TH_GENERIC_FILE是已定义的，所以执行 语句 (1)， 于是按如下过程进行宏替换</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool THPStorage_(init)(PyObject *module);  -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Real, Storage_, init)(PyObject *module);    -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4(THP, Float, Storage_, init)(PyObject *module);   -&gt;</span><br><span class=\"line\">bool TH_CONCAT_4_EXPAND(THP, Float, Storage_, init)(PyObject *module); -&gt;</span><br><span class=\"line\">bool THPFloatStorage_init(PyObject *module);</span><br></pre></td></tr></table></figure>\n\n<p>类似地，#include &lt;TH/THGenerateDoubleType.h&gt;，则得到THPDoubleStorage_init，</p>\n<p>#include &lt;TH/THGenerateIntTypes.h&gt; 得到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPByteStorage_init</span><br><span class=\"line\">THPCharStorage_init</span><br><span class=\"line\">THPShortStorage_init</span><br><span class=\"line\">THPIntStorage_init</span><br><span class=\"line\">THPLongStorage_init</span><br></pre></td></tr></table></figure>\n\n<p>对4组include中的其他三组，则得到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THPHalfStorage_init</span><br><span class=\"line\">THPBoolStorage_init</span><br><span class=\"line\">THPQUInt8Storage_init</span><br><span class=\"line\">THPQInt8Storage_init</span><br><span class=\"line\">THPQInt32Storage_init</span><br></pre></td></tr></table></figure>\n\n<p>以上仅得到函数的声明，我们还需要弄清楚其定义，定义部分的构造与声明类似，首先查看torch/csrc/Storage.cpp，其中包含</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;TH/THStorageFunctions.hpp&gt;</span><br><span class=\"line\">#include &lt;torch/csrc/THP.h&gt;                   // include THPxxxStorage_init 函数声明</span><br><span class=\"line\">...</span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateAllTypes.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateHalfType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateBoolType.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;torch/csrc/generic/Storage.cpp&gt;</span><br><span class=\"line\">#include &lt;TH/THGenerateQTypes.h&gt;</span><br></pre></td></tr></table></figure>\n\n<p>又是4组include 操作，还是熟悉的配方，torch/csrc/generic/Storage.cpp中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#ifndef TH_GENERIC_FILE</span><br><span class=\"line\">#define TH_GENERIC_FILE &quot;torch/csrc/generic/Storage.cpp&quot;              // (11)</span><br><span class=\"line\">#else</span><br><span class=\"line\">...                                                                   // (12)</span><br><span class=\"line\">bool THPStorage_(init)(PyObject *module)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  static std::vector&lt;PyMethodDef&gt; methods;</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class=\"line\">#ifndef THD_GENERIC_FILE</span><br><span class=\"line\">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods);</span><br><span class=\"line\">#endif</span><br><span class=\"line\">  </span><br><span class=\"line\">  THPStorageType.tp_methods = methods.data();</span><br><span class=\"line\">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class=\"line\">  THPStorageType.tp_getset = THPStorage_(properties);</span><br><span class=\"line\">  if (PyType_Ready(&amp;THPStorageType) &lt; 0)</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  Py_INCREF(&amp;THPStorageType);</span><br><span class=\"line\">  PyModule_AddObject(module, THPStorageBaseStr, (PyObject*)&amp;THPStorageType);</span><br><span class=\"line\">  THPStorage_(initCopyMethods)();</span><br><span class=\"line\">  return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上述代码容易看出是向模块module添加字段THPStorageBaseStr， 在torch/csrc/Storage.h中有宏</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THPStorageBaseStr TH_CONCAT_STRING_2(Real, StorageBase)</span><br></pre></td></tr></table></figure>\n\n<p>在TH/THGeneral.h中存在宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define TH_CONCAT_STRING_2(x,y) TH_CONCAT_STRING_2_EXPAND(x,y)</span><br><span class=\"line\">#define TH_CONCAT_STRING_2_EXPAND(x,y) #x #y</span><br></pre></td></tr></table></figure>\n\n<p>由于StorageBase没有宏定义，Real则可以是 Int, Float, Double, Short, Char等（见前面THPxxxStorage_init的声明分析部分），以Real=Float为例，THPStorageBaseStr此时变为”FloatStorageBase”，所以实际上是向torch._C添加字段 FloatStorageBase， 此字段类型为python class torch._C.FloatStorageBase。</p>\n<p>以4组include操作的第一组为例说明，首次include torch/csrc/generic/Storage.cpp时，TH_GENERIC_FILE未定义，所以执行 (11)，然后include TH/THGenerateAllTypes.h，同样的，在TH/THGenerateFloatType.h中根据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define Real Float</span><br><span class=\"line\">...</span><br><span class=\"line\">#include TH_GENERIC_FILE</span><br></pre></td></tr></table></figure>\n\n<p>即，再一次include torch/csrc/generic/Storage.cpp，此时TH_GENERIC_FILE已定义，所以从 (12) 处开始执行，得到THPFloatStorage_init的函数定义，前面已经分析过，此函数用于向torch._C 模块添加类 FloatStorageBase。</p>\n<p>其他如Int，Char，Byte，Double，Half，QUInt8等类似处理。</p>\n<p>torch/csrc/Module.cpp中模块初始化initModule函数中还有一些 THCPxxxStorage_init 的函数，这些函数的声明和定义与 THPxxxStorage_init 的声明和定义 的生成方式一样，不再展开细讲，直接阅读torch/csrc/cuda/Storage.h 和 torch/csrc/cuda/Storage.cpp 两个文件。</p>\n<p>现在我们来看一下上面所述的torch._C模块中新增类到底是什么。以FloatStorageBase为例，查看torch/csrc/generic/Storage.cpp中 THPStorageType的定义，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PyTypeObject THPStorageType = &#123;</span><br><span class=\"line\">  PyVarObject_HEAD_INIT(nullptr, 0)</span><br><span class=\"line\">  &quot;torch._C.&quot; THPStorageBaseStr,               /* tp_name */</span><br><span class=\"line\">  sizeof(THPStorage),                          /* tp_basicsize */</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  THPStorage_(pynew),                          /* tp_new */</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可见python中的类型FloatStorageBase对应在C++中的类型为THPStorage，在 torch/csrc/StorageDef.h中查看THPStorage定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct THPStorage &#123;</span><br><span class=\"line\">  PyObject_HEAD</span><br><span class=\"line\">  THWStorage *cdata;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>（插播一下，torch/csrc/generic/Storage.cpp 这里如何找到 THPStorage的定义？首先，torch/csrc/Storage.cpp中include了文件 torch/csrc/THP.h，torch/csrc/generic/Storage.cpp，然后 torch/csrc/THP.h 中include 了文件torch/csrc/Storage.h，torch/csrc/Storage.h又include了torch/csrc/generic/Storage.h，最后在这个generic/Storage.h中include了 torch/csrc/StorageDef.h）</p>\n<p>然后查看类创建 THPStorage_(pynew) 的定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static PyObject* THPStorage_(pynew)(PyTypeObject *type, PyObject *args, PyObject *kwargs)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  Py_ssize_t num_args = args ? PyTuple_Size(args) : 0;   // 可变长度参数的个数</span><br><span class=\"line\"></span><br><span class=\"line\">  THPStoragePtr self((THPStorage *)type-&gt;tp_alloc(type, 0); // 分配内存，让self指向这个内存块</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  c10::Allocator * allocator = nullptr;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (kwargs != nullptr) &#123;                               // named arguments</span><br><span class=\"line\">    PyObject *allocator_ptr = PyDict_GetItemString(kwargs, &quot;allocator&quot;); // 获取参数allocator的值</span><br><span class=\"line\">    if (allocator_ptr) &#123;</span><br><span class=\"line\">      THPUtils_assert(THPUtils_checkLong(allocator_ptr), &quot;invalid allocator&quot;);</span><br><span class=\"line\">      // 转为 c10::Allocator 指针</span><br><span class=\"line\">      allocator = static_cast&lt;c10::Allocator*&gt;(PyLong_AsVoidPtr(allocator_ptr));</span><br><span class=\"line\">      PyDict_DelItemString(kwargs, &quot;allocator&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Py_ssize_t num_kwargs = PyDict_Size(kwargs);</span><br><span class=\"line\">    if (num_args == 0) &#123;</span><br><span class=\"line\">      PyObject *cdata_ptr = PyDict_GetItemString(kwargs, &quot;cdata&quot;);</span><br><span class=\"line\">      if (num_kwargs==1 &amp;&amp; cdata_ptr &amp;&amp; THPUtils_checkLong(cdata_ptr)) &#123;   // 提供了cdata值</span><br><span class=\"line\">        THWStorage *ptr = (THWStorage*)PyLong_AsVoidPtr(cdata_ptr);</span><br><span class=\"line\">        self-&gt;cdata = ptr;</span><br><span class=\"line\">        return (PyObject*)self.release();       // 返回THPStorage指针</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    THPUtils_assert(num_kwargs == 0, THPStoragePtr &quot;(): invalid keyword arguments&quot;);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  if (num_args == 0) &#123;</span><br><span class=\"line\">    if (allocator) &#123;                            // 未提供cdata值，则需要创建THWStorage类型实例</span><br><span class=\"line\">      self-&gt;cdata = THPStorage_(newWithAllocator)(0, allocator);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      self-&gt;cdata = THWStorage_(new)(LIBRARY_STATE_NOARGS);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return (PyObject*)self.release();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...     // 使用其他方法设置 self-&gt;cdata</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从上面的代码中可见，创建FloatStorageBase实例时，核心是设置 THPStorage.cdata的值，其指向一个THWStorage类型对象，在torch/csrc/THP.h中有宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage THStorage</span><br></pre></td></tr></table></figure>\n\n<p>转而去寻找 THStorage 的定义，我们从torch/csrc/Storage.cpp出发，逐级查看被include的文件，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Storage.cpp                 -&gt;</span><br><span class=\"line\">#include &lt;TH/TH.h&gt;          -&gt;</span><br><span class=\"line\">#include &lt;TH/THStorageFunction.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;TH/generic/THStorage.h&gt;   -&gt;</span><br><span class=\"line\">#include &lt;c10/core/StorageImpl.h&gt;</span><br></pre></td></tr></table></figure>\n\n<p>在 TH/generic/THStorage.h 中找到宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THStorage at::StorageImpl</span><br></pre></td></tr></table></figure>\n\n<p>在 c10/core/StorageImpl.h 中找到结构定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace c10 &#123;</span><br><span class=\"line\">struct C10_API StorageImpl final : public c10::intrusive_ptr_target &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">private:</span><br><span class=\"line\">  caffe2::TypeMeta  data_type_;  // 数据类型</span><br><span class=\"line\">  DataPtr data_ptr_;             // 数据指针</span><br><span class=\"line\">  int64_t numel_;                // 数据数量</span><br><span class=\"line\">  bool resizable_;</span><br><span class=\"line\">  bool received_cuda_;</span><br><span class=\"line\">  Allocator* allocator_;         // 数据的内存分配器</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>所以，THWStorage实际上是类型 at::StorageImpl，这个结构是数据存储实现，我们先不去深挖这个结构，转而继续 THPStorage_(pynew) 的定义，当未提供 cdata变量值时，需要创建 THWStorage 类型实例，使用THWStorage_(NAME)函数，NAME可能的值为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">new                // 新建THStorage，未指定 size，即size=0，使用默认Allocator</span><br><span class=\"line\">free</span><br><span class=\"line\">size</span><br><span class=\"line\">get</span><br><span class=\"line\">set</span><br><span class=\"line\">data</span><br><span class=\"line\">newWithSize        // 新建THStorage，指定 size，使用默认Allocator</span><br><span class=\"line\">newWithAllocator   // 新建THStorage，指定 size 和 Allocator</span><br><span class=\"line\">copy_functions</span><br><span class=\"line\">copyByte</span><br><span class=\"line\">...</span><br><span class=\"line\">copyCudaByte</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>此外有宏定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define THWStorage_(NAME) THStorage_(NAME)     // torch/csrc/THP.h</span><br><span class=\"line\">#define THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   // TH/THStorageFunctions.h</span><br></pre></td></tr></table></figure>\n\n<p>函数THStorage_(NAME) 声明分布在文件 TH/generic/THStorage.h，TH/generic/THStorageCopy.h，实现部分则位于相应的 cpp文件。</p>\n<p>（插播：在使用cuda的情况下，#define THWStorage_(NAME) THCStorage_(NAME)，后者的声明则分布在THC/generic/THCStorage.h，THC/generic/THCStorageCopy.h）</p>\n<p>以 THStorage_(newWithSize)函数为例说明，查看 TH/generic/THStorage.cpp，有定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">THStorage* THStorage_(newWithSize)(ptrdiff_t size)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  THStorage* storage = c10::make_instrusive&lt;at::StorageImpl&gt;(</span><br><span class=\"line\">#ifdef THQUANTIZED</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;quantized_t&gt;(),</span><br><span class=\"line\">#else</span><br><span class=\"line\">    caffe2::TypeMeta::Make&lt;scalar_t&gt;(),        // 新建scalar_t 类型</span><br><span class=\"line\">#endif</span><br><span class=\"line\">    size,</span><br><span class=\"line\">    getTHDefaultAllocator(),</span><br><span class=\"line\">    true).release();</span><br><span class=\"line\">  return storage;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>从这段代码中不难看出，创建StorageImpl对象，以及指向其的一个intrusive_ptr类型的指针，返回一个新的普通指针，指向这个StorageImpl，并销毁intrusive_ptr 内部指针，上文讲过有宏定义 THStorage 就是 at::StorageImpl，所以这个方法就是新建一个StorageImpl对象，并返回指向它的指针。根据c10::make_instrusive的函数定义，实际上是调用StorageImpl的构造函数完成这项工作，此构造函数为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StorageImpl(</span><br><span class=\"line\">    caffe2::TypeMeta data_type,</span><br><span class=\"line\">    int64_4 numel,</span><br><span class=\"line\">    at::Allocator* allocator,</span><br><span class=\"line\">    bool resizable)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>我们看上上个代码片段中StorageImpl构造函数的实参，</p>\n<p>首先回顾一下我们是从FloatStorageBase出发走到现在这里，所以在TH/THGenerateFloatType.h 文件中找到（如果理解上文所说的 4组include操作，就能理解为什么是在这个文件中）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define scalar_t float</span><br></pre></td></tr></table></figure>\n\n<p>于是，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">caffe2::TypeMeta::Make&lt;scalar_t&gt;()    // 假设 THQUANTIZED 未定义</span><br></pre></td></tr></table></figure>\n\n<p>caffe2::TypeMeta::Make 这个方法是创建caffe2::TypeMeta 对象，其内部维护一个detail::TypeMetaData* 变量data_，如何new 一个TypeMetaData对象暂且不表，我们先看一组宏，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, Counter)         \\</span><br><span class=\"line\">  namespace detail &#123;                                                       \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(_typeMetaDataInstance_, Counter) =    \\</span><br><span class=\"line\">    _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));                        \\</span><br><span class=\"line\">  &#125;                                                                        \\</span><br><span class=\"line\">  template&lt;&gt;                                                               \\</span><br><span class=\"line\">  EXPORT_IF_NOT_GCC const detail::TypeMetaData*                            \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                          \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(detail::_typeMetaDataInstance_, Counter);      \\</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE(T, __COUNTER__)</span><br><span class=\"line\"></span><br><span class=\"line\">#define C10_CONCATENATE_IMPL(s1,s2) s1##s2</span><br><span class=\"line\">#define C10_CONCATENATE(s1, s2) C10_CONCATENATE_IMPL(s1, s2)</span><br></pre></td></tr></table></figure>\n\n<p>经过宏替换，得到 _typeMetaDataInstance的模板函数定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>还有一组宏，用于生成模板特例化，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)       \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline C10_EXPORT TypeIdentifier TypeIdentifier::Get&lt;T&gt;() &#123;          \\</span><br><span class=\"line\">    return TypeIdentifier(PreallocatedId);                             \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  namespace detail &#123;                                                   \\</span><br><span class=\"line\">  C10_EXPORT extern const TypeMetaData C10_CONCATENATE(                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                               \\</span><br><span class=\"line\">    PreallocatedId);                                                   \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">  template&lt;&gt;                                                           \\</span><br><span class=\"line\">  inline const detail::TypeMetaData*                                   \\</span><br><span class=\"line\">  TypeMeta::_typeMetaDataInstance&lt;T&gt;() noexcept &#123;                      \\</span><br><span class=\"line\">    return &amp;C10_CONCATENATE(                                           \\</span><br><span class=\"line\">      detail::_typeMetaDataInstance_preallocated_, PreallocatedId);    \\</span><br><span class=\"line\">  &#125;                                                                    \\</span><br><span class=\"line\">#define CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(PreallocatedId, T)      \\</span><br><span class=\"line\">  namespace detail &#123;                                                 \\</span><br><span class=\"line\">  const TypeMetaData C10_CONCATENATE(                                \\</span><br><span class=\"line\">    _typeMetaDataInstance_preallocated_,                             \\</span><br><span class=\"line\">    PreallocatedId) = _makeTypeMetaDataInstance&lt;T&gt;(_typeName&lt;T&gt;(#T));\\</span><br><span class=\"line\">  &#125;                                                                  </span><br><span class=\"line\">// 调用</span><br><span class=\"line\">CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE(0, uint8_t)</span><br></pre></td></tr></table></figure>\n\n<p>对于系统内部变量如 float，得到函数模板特例化的定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 函数声明</span><br><span class=\"line\">namespace detail &#123;</span><br><span class=\"line\">__attrubyte((__visibility(&quot;default&quot;))) extern const TypeMetaData</span><br><span class=\"line\">_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_typeMetaDataInstance_preallocated_Preallocated;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>另外，在c10/util/typeid.cpp中有如下调用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CAFFE_DEFINE_PREALLOCATED_KNOWN_TYPE(0, float)</span><br></pre></td></tr></table></figure>\n\n<p>经过宏替换得到</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">namespace detail &#123;                                                 </span><br><span class=\"line\">  const TypeMetaData _typeMetaDataInstance_preallocated_PreallocatedId</span><br><span class=\"line\">    = _makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>于是函数模板特例化最终形式为，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template&lt;&gt;</span><br><span class=\"line\">inline const detail::TypeMetaData*</span><br><span class=\"line\">TypeMeta::_typeMetaDataInstance&lt;float&gt;() noexcept &#123;</span><br><span class=\"line\">  return &amp;detail::_makeTypeMetaDataInstance&lt;float&gt;(_typeName&lt;float&gt;(&quot;float&quot;));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>detail::_makeTypeMetaDataInstance是一个模板函数，根据模板参数提供的类型创建相应类型的TypeMetaData实例，TypeMetaData是类型元数据，指定了类型在内存占多少字节空间（比如 float四个字节），类型名称，类型的构造函数、析构函数和拷贝函数等，以及类型的全局id，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">struct TypeMetaData final &#123;</span><br><span class=\"line\">// 函数类型的别名</span><br><span class=\"line\">using New = void*();                            // new</span><br><span class=\"line\">using PlacementNew = void(void*, size_t);       // 占位new</span><br><span class=\"line\">using Copy = void(const void*, void*, size_t);  // 类型数组拷贝</span><br><span class=\"line\">using PlacementDelete = void(void*, size_t);</span><br><span class=\"line\">using Delete = void(void*);</span><br><span class=\"line\">... //构造函数</span><br><span class=\"line\"></span><br><span class=\"line\">size_t itemsize_;  // 类型占多少字节</span><br><span class=\"line\">New* new_;</span><br><span class=\"line\">PlacementNew* placementNew_;   // 定位放置 new</span><br><span class=\"line\">Copy* copy_;        // 类型拷贝</span><br><span class=\"line\">Delete* delete_;    // 类型析构</span><br><span class=\"line\">TypeIdentifier id_; // 类型全局唯一id</span><br><span class=\"line\">const char* name_;  // 类型名称</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>我们还以float为例，看看如何构造这个类型元数据的实例，根据以上分析查看detail::_makeTypeMetaDataInstance 模板函数的定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">template &lt;class T&gt;</span><br><span class=\"line\">inline TypeMetaData _makeTypeMetaDataInstance(const char* typeName) &#123;</span><br><span class=\"line\">  return &#123;sizeof(T),                 // 类型T占多少字节</span><br><span class=\"line\">          _PickNew&lt;T&gt;(),             // 通过 new T</span><br><span class=\"line\">          _PickPlacementNew&lt;T&gt;(),</span><br><span class=\"line\">          _PickCopy&lt;T&gt;(),      </span><br><span class=\"line\">          _PickPlacementDelete&lt;T&gt;(),</span><br><span class=\"line\">          _PickDelete&lt;T&gt;(),</span><br><span class=\"line\">          TypeIdentifier::Get&lt;T&gt;(),  // 获取类型的全局唯一id，</span><br><span class=\"line\">          typeName&#125;;                 // 类型名称，例如float的名称为&quot;float&quot;</span><br></pre></td></tr></table></figure>\n\n<p>构造struct结构实例，按照struct内字段顺序传入字段的值直接{}构造，类型的全局唯一id的获取使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TypeIdentifier::Get&lt;T&gt;()</span><br></pre></td></tr></table></figure>\n\n<p>在上述宏定义CAFFE_DECLARE_PREALLOCATED_KNOWN_TYPE中给出这个函数（模板特例化）定义 ，其是通过调用TypeIdentifer(PreallocatedId)获取，对于float，PreallocatedId的实参值为6。</p>\n<p>对于其他类型如 int，double，int64_t等类似处理。</p>\n<p>PyTorch源码中给定了一些预定义好的类型及其全局唯一id值，如果是自定义变量，那么其全局唯一id则通过宏_CAFFE_KNOWN_TYPE_DEFINE_TYPEMETADATA_INSTANCE得到，具体而言是通过TypeIdentifier::createTypeId()得到，这个函数从PyTorch中预定义好的类型全局唯一id最大值（为32，对应类型为虚构的一个类型_CaffeHighestPreallocatedTypeId）开始，每次对一个自定义类型，id值增1。</p>\n<p>至此完成TypeMetaData实例的创建，从而完成TypeMeta（其内部维护TypeMetaData指针）创建，得到构造StorageImpl的第一个实参，回到前面的THStorage_(newWithSize)(ptrdiff_t size)的函数体部分，构造StorageImpl后面的实参分别为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">size,             // 被构造的StorageImpl包含多少类型变量（类型在TypeMeta中指定，例如float）</span><br><span class=\"line\">getTHDefaultAllocator(),  // 使用默认内存分配器，最终是使用posix_memalign函数实现内存分配</span><br><span class=\"line\">true                      // 被构造的StorageImpl可以resize</span><br></pre></td></tr></table></figure>\n\n<p>创建了StorageImpl实例后，就完成了THPStorage实例构造（其内部维护StorageImpl的指针），而THPStorage就对应 torch._C 模块中新增的类型FloatStorageBase</p>\n<p>记住，这里仅以float为例说明，THPStorage还可以对应其他类型如IntStorageBase等。</p>\n<p>FloatStorageBase的methods, members, properties 参考generic/Storage.cpp中THPStorage_(int)(PyObject* module)函数定义。</p>\n<p>类型 _THNN 和 _THCUNN 分别通过如下函数调用添加到模型 torch._C中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  torch::nn::init_THNN(module);</span><br><span class=\"line\">#ifdef USE_CUDA</span><br><span class=\"line\">  torch::nn::init_THCUNN(module);</span><br><span class=\"line\">#endif</span><br></pre></td></tr></table></figure>\n\n<p>函数定义位于文件torch/csrc/nn目录下的THNN.cpp和THCUNN.cpp文件中，这两个文件是生成 torch_python 这个TARGET时使用 tools/setup_helpers/generate_code.py这个脚本生成的，具体参见 torch/CMakeLists.txt。</p>\n<p>torch.<em>C模块初始化过程到这里就完成了。回到 `torch/<em>_init</em></em>.py`，继续看看 import torch时接下来做了哪些事情：</p>\n<ol>\n<li><p>定义了模块函数 typename，is_tensor，is_storage等</p>\n</li>\n<li><p>导入torch下其他子模块</p>\n</li>\n<li><p>调用_C._init_name，这个函数在文件torch/csrc/Module.cpp 中实现，用于将torch模块中的DoubleStorage名称改为 torch.DoubleStorage，其他类型如FloatStorage，HalfStorage则同样这么处理</p>\n</li>\n<li><p>调用_C._initExtension，这个函数同样在文件torch/csrc/Module.cpp 中实现，（阅读源码其实不难理解）所做的事情如下：</p>\n<ul>\n<li><p>初始化布局layout，向torch模块添加strided、sparse_coo和_mkldnn布局；</p>\n</li>\n<li><p>初始化内存格式，向torch模块添加any_format、preserve_format、contiguous_format和channels_last内存格式；</p>\n</li>\n<li><p>初始化类型，向torch模块添加uint8、int8、float64、float32、int32、int64、int16、float16、complex32、complex64、complex128、bool、qint8、quint8、qint32等类型，其中部分类型有旧名称，所以将旧名称类型也添加进torch模块；</p>\n</li>\n<li><p>初始化python绑定：1）初始化PyTensorType 类型实例，每个PyTensorType实例对应一组Backend和ScalarType；2）初始化torch.tensortype类型，表示torch.FloatTensor等Tensor的metaclass；3）初始化python的各个Tensor类，如torch.FloatTensor等；4）将各个Tensor类添加到模块 torch 中；5）设置FloatTensor为默认Tensor</p>\n</li>\n<li><p>共享内存管理初始化，设置文件路径；</p>\n</li>\n<li><p>执行 THPxxxStorage_postInit(module)，其中xxx是类型名称，这些函数的定义可与THPxxxStorage_Init 类似地得到，其中module是torch（而非torch._C），调用这个函数注册类型相关的Python storage类（比如Float对应torch.FloatStorage），</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch::registerStoragePyTypeObject((PyTypeObject*)THPStorageClass, backend, </span><br><span class=\"line\">TH_CONCAT_2(at::k, Real));</span><br></pre></td></tr></table></figure>\n\n<p>  其中 TH_CONCAT_2(at::k, Real)，即at::kReal由以下宏展开得到，是一个常量，当Real=Float时，其值为at::ScalarType::Float，</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AT_FORALL_SCALAR_TYPES_WITH_COMPLEX(DEFINE_CONSTANT)`</span><br></pre></td></tr></table></figure>\n\n<p>  这个注册调用其实就是添加THPStorageClass与back+at::kReal之间的映射。</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>到这里，import torch 的工作全部完成。</p>\n<h1 id=\"后记：\"><a href=\"#后记：\" class=\"headerlink\" title=\"后记：\"></a>后记：</h1><p>初次阅读PyTorch源码，语言组织可能比较乱，加上鄙人还有很多东西没看懂，看懂的部分仅仅是零散分布的点，不一定能连成线，更加没有形成（知识）面，所以如果有错误，请直接指正，多谢。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjwu48im400037wvcek39ab0p","category_id":"cjwu48im600047wvc6o8bg3kc","_id":"cjwu48im800077wvct4wyn0qw"}],"PostTag":[{"post_id":"cjwu48ila00007wvclssm6cxn","tag_id":"cjwu48ilj00017wvc5z3apxt5","_id":"cjwu48ill00027wvce3rruars"},{"post_id":"cjwu48im400037wvcek39ab0p","tag_id":"cjwu48im700057wvcq6u7byzw","_id":"cjwu48im800067wvchsbv6bvp"}],"Tag":[{"name":"tool","_id":"cjwu48ilj00017wvc5z3apxt5"},{"name":"PyTorch","_id":"cjwu48im700057wvcq6u7byzw"}]}}